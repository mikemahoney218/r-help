From ss5505 at cumc.columbia.edu  Thu Feb  1 15:50:42 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Thu, 1 Feb 2018 14:50:42 +0000
Subject: [R] Error while working with png output on linux server
Message-ID: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>

I'm working on linux server:
Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64 GNU/Linux

I get error while creating png files. I'm sharing my commands and error while I run those commands:

>png("abc", type="cairo")
Error in .External2(C_X11, paste0("png::", filename), g$width, g$height,  :
  unable to start device PNG
In addition: Warning message:
In png("abc", type = "cairo") : unable to open connection to X11 display ''

> png("apoeqqplot.png", res=600)
Error in .External2(C_X11, paste0("png::", filename), g$width, g$height,  :
  unable to start device PNG
In addition: Warning message:
In png("apoeqqplot.png", res = 600) :
  unable to open connection to X11 display ''

dev.off()

R version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Matrix products: default
BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so

locale:
[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
[9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] CMplot_3.3.1

loaded via a namespace (and not attached):
[1] compiler_3.4.2 tools_3.4.2


How do I fix this?


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb  1 16:11:50 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Feb 2018 07:11:50 -0800
Subject: [R] Error while working with png output on linux server
In-Reply-To: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>

FAQ 7.19?

Also, read the Posting Guide, in particular about posting using plain text. 
-- 
Sent from my phone. Please excuse my brevity.

On February 1, 2018 6:50:42 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>I'm working on linux server:
>Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64
>GNU/Linux
>
>I get error while creating png files. I'm sharing my commands and error
>while I run those commands:
>
>>png("abc", type="cairo")
>Error in .External2(C_X11, paste0("png::", filename), g$width,
>g$height,  :
>  unable to start device PNG
>In addition: Warning message:
>In png("abc", type = "cairo") : unable to open connection to X11
>display ''
>
>> png("apoeqqplot.png", res=600)
>Error in .External2(C_X11, paste0("png::", filename), g$width,
>g$height,  :
>  unable to start device PNG
>In addition: Warning message:
>In png("apoeqqplot.png", res = 600) :
>  unable to open connection to X11 display ''
>
>dev.off()
>
>R version 3.4.2 (2017-09-28)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: Debian GNU/Linux 9 (stretch)
>
>Matrix products: default
>BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
>LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
>
>locale:
>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>[9] LC_ADDRESS=C               LC_TELEPHONE=C
>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>[1] CMplot_3.3.1
>
>loaded via a namespace (and not attached):
>[1] compiler_3.4.2 tools_3.4.2
>
>
>How do I fix this?
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ss5505 at cumc.columbia.edu  Thu Feb  1 16:18:18 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Thu, 1 Feb 2018 15:18:18 +0000
Subject: [R] Error while working with png output on linux server
In-Reply-To: <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>
References: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>
Message-ID: <BY1PR0201MB100013EEBF9D57BA1A9A734881FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>

Thanks for pointing to FAQ: I tried with cairo (shared in commands), unfortunately didn't work. 

--
Sanjeev Sariya


-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Thursday, February 01, 2018 10:12 AM
To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>; r-help at r-project.org
Subject: Re: [R] Error while working with png output on linux server

FAQ 7.19?

Also, read the Posting Guide, in particular about posting using plain text. 
--
Sent from my phone. Please excuse my brevity.

On February 1, 2018 6:50:42 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>I'm working on linux server:
>Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64 
>GNU/Linux
>
>I get error while creating png files. I'm sharing my commands and error 
>while I run those commands:
>
>>png("abc", type="cairo")
>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>g$height,  :
>  unable to start device PNG
>In addition: Warning message:
>In png("abc", type = "cairo") : unable to open connection to X11 
>display ''
>
>> png("apoeqqplot.png", res=600)
>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>g$height,  :
>  unable to start device PNG
>In addition: Warning message:
>In png("apoeqqplot.png", res = 600) :
>  unable to open connection to X11 display ''
>
>dev.off()
>
>R version 3.4.2 (2017-09-28)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: Debian GNU/Linux 9 (stretch)
>
>Matrix products: default
>BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
>LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
>
>locale:
>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>[9] LC_ADDRESS=C               LC_TELEPHONE=C
>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>[1] CMplot_3.3.1
>
>loaded via a namespace (and not attached):
>[1] compiler_3.4.2 tools_3.4.2
>
>
>How do I fix this?
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From thierry.onkelinx at inbo.be  Thu Feb  1 16:57:03 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 1 Feb 2018 16:57:03 +0100
Subject: [R] Error while working with png output on linux server
In-Reply-To: <BY1PR0201MB100013EEBF9D57BA1A9A734881FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>
 <BY1PR0201MB100013EEBF9D57BA1A9A734881FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <CAJuCY5yiFUoff48_p8QmR6tF7Dm1BG=VOUrLZWHrUL=4FG7ftw@mail.gmail.com>

Dear Sanjeev,

It seems that you system neither supports X11 devices nor cairo
devices. See http://lmgtfy.com/?q=R+unable+to+open+connection+to+X11
for possible solutions.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-01 16:18 GMT+01:00 Sariya, Sanjeev <ss5505 at cumc.columbia.edu>:
> Thanks for pointing to FAQ: I tried with cairo (shared in commands), unfortunately didn't work.
>
> --
> Sanjeev Sariya
>
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Thursday, February 01, 2018 10:12 AM
> To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>; r-help at r-project.org
> Subject: Re: [R] Error while working with png output on linux server
>
> FAQ 7.19?
>
> Also, read the Posting Guide, in particular about posting using plain text.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 1, 2018 6:50:42 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>>I'm working on linux server:
>>Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64
>>GNU/Linux
>>
>>I get error while creating png files. I'm sharing my commands and error
>>while I run those commands:
>>
>>>png("abc", type="cairo")
>>Error in .External2(C_X11, paste0("png::", filename), g$width,
>>g$height,  :
>>  unable to start device PNG
>>In addition: Warning message:
>>In png("abc", type = "cairo") : unable to open connection to X11
>>display ''
>>
>>> png("apoeqqplot.png", res=600)
>>Error in .External2(C_X11, paste0("png::", filename), g$width,
>>g$height,  :
>>  unable to start device PNG
>>In addition: Warning message:
>>In png("apoeqqplot.png", res = 600) :
>>  unable to open connection to X11 display ''
>>
>>dev.off()
>>
>>R version 3.4.2 (2017-09-28)
>>Platform: x86_64-pc-linux-gnu (64-bit)
>>Running under: Debian GNU/Linux 9 (stretch)
>>
>>Matrix products: default
>>BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
>>LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
>>
>>locale:
>>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>[9] LC_ADDRESS=C               LC_TELEPHONE=C
>>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>>attached base packages:
>>[1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>other attached packages:
>>[1] CMplot_3.3.1
>>
>>loaded via a namespace (and not attached):
>>[1] compiler_3.4.2 tools_3.4.2
>>
>>
>>How do I fix this?
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ss5505 at cumc.columbia.edu  Thu Feb  1 17:23:13 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Thu, 1 Feb 2018 16:23:13 +0000
Subject: [R] Error while working with png output on linux server
In-Reply-To: <CAJuCY5yiFUoff48_p8QmR6tF7Dm1BG=VOUrLZWHrUL=4FG7ftw@mail.gmail.com>
References: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>
 <BY1PR0201MB100013EEBF9D57BA1A9A734881FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <CAJuCY5yiFUoff48_p8QmR6tF7Dm1BG=VOUrLZWHrUL=4FG7ftw@mail.gmail.com>
Message-ID: <BY1PR0201MB10006CC80A15BF148578A8EA81FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>

Thanks for your reply. I searched for the error on Google before resorting to the R forum (help group).
I tried Sys.env(...) too, but didn't resolve the error I get. Hence I am looking for solution.


 
--


-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Sent: Thursday, February 01, 2018 10:57 AM
To: Sariya, Sanjeev <ss5505 at cumc.columbia.edu>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
Subject: Re: [R] Error while working with png output on linux server

Dear Sanjeev,

It seems that you system neither supports X11 devices nor cairo devices. See http://lmgtfy.com/?q=R+unable+to+open+connection+to+X11
for possible solutions.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-01 16:18 GMT+01:00 Sariya, Sanjeev <ss5505 at cumc.columbia.edu>:
> Thanks for pointing to FAQ: I tried with cairo (shared in commands), unfortunately didn't work.
>
> --
> Sanjeev Sariya
>
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Thursday, February 01, 2018 10:12 AM
> To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>; 
> r-help at r-project.org
> Subject: Re: [R] Error while working with png output on linux server
>
> FAQ 7.19?
>
> Also, read the Posting Guide, in particular about posting using plain text.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 1, 2018 6:50:42 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>>I'm working on linux server:
>>Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64 
>>GNU/Linux
>>
>>I get error while creating png files. I'm sharing my commands and 
>>error while I run those commands:
>>
>>>png("abc", type="cairo")
>>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>>g$height,  :
>>  unable to start device PNG
>>In addition: Warning message:
>>In png("abc", type = "cairo") : unable to open connection to X11 
>>display ''
>>
>>> png("apoeqqplot.png", res=600)
>>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>>g$height,  :
>>  unable to start device PNG
>>In addition: Warning message:
>>In png("apoeqqplot.png", res = 600) :
>>  unable to open connection to X11 display ''
>>
>>dev.off()
>>
>>R version 3.4.2 (2017-09-28)
>>Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian GNU/Linux 
>>9 (stretch)
>>
>>Matrix products: default
>>BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
>>LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
>>
>>locale:
>>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>[9] LC_ADDRESS=C               LC_TELEPHONE=C
>>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>>attached base packages:
>>[1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>other attached packages:
>>[1] CMplot_3.3.1
>>
>>loaded via a namespace (and not attached):
>>[1] compiler_3.4.2 tools_3.4.2
>>
>>
>>How do I fix this?
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From henrik.bengtsson at gmail.com  Thu Feb  1 17:44:59 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 1 Feb 2018 08:44:59 -0800
Subject: [R] Error while working with png output on linux server
In-Reply-To: <BY1PR0201MB10006CC80A15BF148578A8EA81FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>
 <BY1PR0201MB100013EEBF9D57BA1A9A734881FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <CAJuCY5yiFUoff48_p8QmR6tF7Dm1BG=VOUrLZWHrUL=4FG7ftw@mail.gmail.com>
 <BY1PR0201MB10006CC80A15BF148578A8EA81FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <CAFDcVCRaZsY980TSsapGJABqqX=AzQWCV69yPwAWueV6N+kNbQ@mail.gmail.com>

You could try with png2() in the R.devices package, which is just a
convenient wrapper around the bitmap() device which can also produce PNGs.
It's not perfect but it might get you going.

Henrik

On Feb 1, 2018 08:24, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:

> Thanks for your reply. I searched for the error on Google before resorting
> to the R forum (help group).
> I tried Sys.env(...) too, but didn't resolve the error I get. Hence I am
> looking for solution.
>
>
>
> --
>
>
> -----Original Message-----
> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Sent: Thursday, February 01, 2018 10:57 AM
> To: Sariya, Sanjeev <ss5505 at cumc.columbia.edu>
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
> Subject: Re: [R] Error while working with png output on linux server
>
> Dear Sanjeev,
>
> It seems that you system neither supports X11 devices nor cairo devices.
> See http://lmgtfy.com/?q=R+unable+to+open+connection+to+X11
> for possible solutions.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie &
> Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of
> anecdote is not data. ~ Roger Brinner The combination of some data and an
> aching desire for an answer does not ensure that a reasonable answer can be
> extracted from a given body of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
>
> 2018-02-01 16:18 GMT+01:00 Sariya, Sanjeev <ss5505 at cumc.columbia.edu>:
> > Thanks for pointing to FAQ: I tried with cairo (shared in commands),
> unfortunately didn't work.
> >
> > --
> > Sanjeev Sariya
> >
> >
> > -----Original Message-----
> > From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> > Sent: Thursday, February 01, 2018 10:12 AM
> > To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>;
> > r-help at r-project.org
> > Subject: Re: [R] Error while working with png output on linux server
> >
> > FAQ 7.19?
> >
> > Also, read the Posting Guide, in particular about posting using plain
> text.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On February 1, 2018 6:50:42 AM PST, "Sariya, Sanjeev" <
> ss5505 at cumc.columbia.edu> wrote:
> >>I'm working on linux server:
> >>Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64
> >>GNU/Linux
> >>
> >>I get error while creating png files. I'm sharing my commands and
> >>error while I run those commands:
> >>
> >>>png("abc", type="cairo")
> >>Error in .External2(C_X11, paste0("png::", filename), g$width,
> >>g$height,  :
> >>  unable to start device PNG
> >>In addition: Warning message:
> >>In png("abc", type = "cairo") : unable to open connection to X11
> >>display ''
> >>
> >>> png("apoeqqplot.png", res=600)
> >>Error in .External2(C_X11, paste0("png::", filename), g$width,
> >>g$height,  :
> >>  unable to start device PNG
> >>In addition: Warning message:
> >>In png("apoeqqplot.png", res = 600) :
> >>  unable to open connection to X11 display ''
> >>
> >>dev.off()
> >>
> >>R version 3.4.2 (2017-09-28)
> >>Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian GNU/Linux
> >>9 (stretch)
> >>
> >>Matrix products: default
> >>BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
> >>LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
> >>
> >>locale:
> >>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >>[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >>[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >>[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >>[9] LC_ADDRESS=C               LC_TELEPHONE=C
> >>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >>
> >>attached base packages:
> >>[1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >>other attached packages:
> >>[1] CMplot_3.3.1
> >>
> >>loaded via a namespace (and not attached):
> >>[1] compiler_3.4.2 tools_3.4.2
> >>
> >>
> >>How do I fix this?
> >>
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb  1 18:09:01 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Feb 2018 09:09:01 -0800
Subject: [R] Error while working with png output on linux server
In-Reply-To: <BY1PR0201MB10006CC80A15BF148578A8EA81FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
References: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>
 <BY1PR0201MB100013EEBF9D57BA1A9A734881FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <CAJuCY5yiFUoff48_p8QmR6tF7Dm1BG=VOUrLZWHrUL=4FG7ftw@mail.gmail.com>
 <BY1PR0201MB10006CC80A15BF148578A8EA81FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
Message-ID: <BC7BC149-EFA2-4008-A35B-39A8AFFFE636@dcn.davis.ca.us>

This is not an R issue so this is not a good venue... it has to do with which support software you have (not) installed. Try the R-sig-debian mailing list. Please clarify to them how you installed R... for Debian there are relevant deb packages and a corresponding Debian repository that provide the simplest route to a working system, but if you compile it yourself it is easy to miss dependencies.
-- 
Sent from my phone. Please excuse my brevity.

On February 1, 2018 8:23:13 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>Thanks for your reply. I searched for the error on Google before
>resorting to the R forum (help group).
>I tried Sys.env(...) too, but didn't resolve the error I get. Hence I
>am looking for solution.
>
>
> 
>--
>
>
>-----Original Message-----
>From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
>Sent: Thursday, February 01, 2018 10:57 AM
>To: Sariya, Sanjeev <ss5505 at cumc.columbia.edu>
>Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
>Subject: Re: [R] Error while working with png output on linux server
>
>Dear Sanjeev,
>
>It seems that you system neither supports X11 devices nor cairo
>devices. See http://lmgtfy.com/?q=R+unable+to+open+connection+to+X11
>for possible solutions.
>
>Best regards,
>
>ir. Thierry Onkelinx
>Statisticus / Statistician
>
>Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
>BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
>& Kwaliteitszorg / Team Biometrics & Quality Assurance
>thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
>///////////////////////////////////////////////////////////////////////////////////////////
>To call in the statistician after the experiment is done may be no more
>than asking him to perform a post-mortem examination: he may be able to
>say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural
>of anecdote is not data. ~ Roger Brinner The combination of some data
>and an aching desire for an answer does not ensure that a reasonable
>answer can be extracted from a given body of data. ~ John Tukey
>///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
>2018-02-01 16:18 GMT+01:00 Sariya, Sanjeev <ss5505 at cumc.columbia.edu>:
>> Thanks for pointing to FAQ: I tried with cairo (shared in commands),
>unfortunately didn't work.
>>
>> --
>> Sanjeev Sariya
>>
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Thursday, February 01, 2018 10:12 AM
>> To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>;
>
>> r-help at r-project.org
>> Subject: Re: [R] Error while working with png output on linux server
>>
>> FAQ 7.19?
>>
>> Also, read the Posting Guide, in particular about posting using plain
>text.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 1, 2018 6:50:42 AM PST, "Sariya, Sanjeev"
><ss5505 at cumc.columbia.edu> wrote:
>>>I'm working on linux server:
>>>Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64 
>>>GNU/Linux
>>>
>>>I get error while creating png files. I'm sharing my commands and 
>>>error while I run those commands:
>>>
>>>>png("abc", type="cairo")
>>>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>>>g$height,  :
>>>  unable to start device PNG
>>>In addition: Warning message:
>>>In png("abc", type = "cairo") : unable to open connection to X11 
>>>display ''
>>>
>>>> png("apoeqqplot.png", res=600)
>>>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>>>g$height,  :
>>>  unable to start device PNG
>>>In addition: Warning message:
>>>In png("apoeqqplot.png", res = 600) :
>>>  unable to open connection to X11 display ''
>>>
>>>dev.off()
>>>
>>>R version 3.4.2 (2017-09-28)
>>>Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian
>GNU/Linux 
>>>9 (stretch)
>>>
>>>Matrix products: default
>>>BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
>>>LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
>>>
>>>locale:
>>>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>[9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>>attached base packages:
>>>[1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>other attached packages:
>>>[1] CMplot_3.3.1
>>>
>>>loaded via a namespace (and not attached):
>>>[1] compiler_3.4.2 tools_3.4.2
>>>
>>>
>>>How do I fix this?
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ss5505 at cumc.columbia.edu  Thu Feb  1 18:11:15 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Thu, 1 Feb 2018 17:11:15 +0000
Subject: [R] Error while working with png output on linux server
In-Reply-To: <BC7BC149-EFA2-4008-A35B-39A8AFFFE636@dcn.davis.ca.us>
References: <BY1PR0201MB1000BCF329FA5BC0A4A0BBA981FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <D2E4A3B6-23A0-4319-9137-900DC793FD52@dcn.davis.ca.us>
 <BY1PR0201MB100013EEBF9D57BA1A9A734881FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <CAJuCY5yiFUoff48_p8QmR6tF7Dm1BG=VOUrLZWHrUL=4FG7ftw@mail.gmail.com>
 <BY1PR0201MB10006CC80A15BF148578A8EA81FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>
 <BC7BC149-EFA2-4008-A35B-39A8AFFFE636@dcn.davis.ca.us>
Message-ID: <BY1PR0201MB10004D0A113374F1E28E069B81FA0@BY1PR0201MB1000.namprd02.prod.outlook.com>

Thank you.

--
Sanjeev Sariya


-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Thursday, February 01, 2018 12:09 PM
To: Sariya, Sanjeev <ss5505 at cumc.columbia.edu>; Thierry Onkelinx <thierry.onkelinx at inbo.be>
Cc: r-help at r-project.org
Subject: RE: [R] Error while working with png output on linux server

This is not an R issue so this is not a good venue... it has to do with which support software you have (not) installed. Try the R-sig-debian mailing list. Please clarify to them how you installed R... for Debian there are relevant deb packages and a corresponding Debian repository that provide the simplest route to a working system, but if you compile it yourself it is easy to miss dependencies.
--
Sent from my phone. Please excuse my brevity.

On February 1, 2018 8:23:13 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>Thanks for your reply. I searched for the error on Google before 
>resorting to the R forum (help group).
>I tried Sys.env(...) too, but didn't resolve the error I get. Hence I 
>am looking for solution.
>
>
> 
>--
>
>
>-----Original Message-----
>From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
>Sent: Thursday, February 01, 2018 10:57 AM
>To: Sariya, Sanjeev <ss5505 at cumc.columbia.edu>
>Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
>Subject: Re: [R] Error while working with png output on linux server
>
>Dear Sanjeev,
>
>It seems that you system neither supports X11 devices nor cairo 
>devices. See http://lmgtfy.com/?q=R+unable+to+open+connection+to+X11
>for possible solutions.
>
>Best regards,
>
>ir. Thierry Onkelinx
>Statisticus / Statistician
>
>Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN 
>BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie 
>& Kwaliteitszorg / Team Biometrics & Quality Assurance 
>thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
>///////////////////////////////////////////////////////////////////////
>//////////////////// To call in the statistician after the experiment 
>is done may be no more than asking him to perform a post-mortem 
>examination: he may be able to say what the experiment died of. ~ Sir 
>Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger 
>Brinner The combination of some data and an aching desire for an answer 
>does not ensure that a reasonable answer can be extracted from a given 
>body of data. ~ John Tukey 
>///////////////////////////////////////////////////////////////////////
>////////////////////
>
>
>
>
>2018-02-01 16:18 GMT+01:00 Sariya, Sanjeev <ss5505 at cumc.columbia.edu>:
>> Thanks for pointing to FAQ: I tried with cairo (shared in commands),
>unfortunately didn't work.
>>
>> --
>> Sanjeev Sariya
>>
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Thursday, February 01, 2018 10:12 AM
>> To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>;
>
>> r-help at r-project.org
>> Subject: Re: [R] Error while working with png output on linux server
>>
>> FAQ 7.19?
>>
>> Also, read the Posting Guide, in particular about posting using plain
>text.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 1, 2018 6:50:42 AM PST, "Sariya, Sanjeev"
><ss5505 at cumc.columbia.edu> wrote:
>>>I'm working on linux server:
>>>Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64 
>>>GNU/Linux
>>>
>>>I get error while creating png files. I'm sharing my commands and 
>>>error while I run those commands:
>>>
>>>>png("abc", type="cairo")
>>>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>>>g$height,  :
>>>  unable to start device PNG
>>>In addition: Warning message:
>>>In png("abc", type = "cairo") : unable to open connection to X11 
>>>display ''
>>>
>>>> png("apoeqqplot.png", res=600)
>>>Error in .External2(C_X11, paste0("png::", filename), g$width, 
>>>g$height,  :
>>>  unable to start device PNG
>>>In addition: Warning message:
>>>In png("apoeqqplot.png", res = 600) :
>>>  unable to open connection to X11 display ''
>>>
>>>dev.off()
>>>
>>>R version 3.4.2 (2017-09-28)
>>>Platform: x86_64-pc-linux-gnu (64-bit) Running under: Debian
>GNU/Linux
>>>9 (stretch)
>>>
>>>Matrix products: default
>>>BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
>>>LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
>>>
>>>locale:
>>>[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>[9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>>attached base packages:
>>>[1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>other attached packages:
>>>[1] CMplot_3.3.1
>>>
>>>loaded via a namespace (and not attached):
>>>[1] compiler_3.4.2 tools_3.4.2
>>>
>>>
>>>How do I fix this?
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From Graeve.Nick at principal.com  Thu Feb  1 18:45:53 2018
From: Graeve.Nick at principal.com (Graeve, Nick)
Date: Thu, 1 Feb 2018 17:45:53 +0000
Subject: [R] Data Table Merge Help
In-Reply-To: <SN1PR10MB0382882BF229F0A4FD6C904CE4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
References: <SN1PR10MB0382882BF229F0A4FD6C904CE4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
Message-ID: <SN1PR10MB0382BD5D7600988BEED26D12E4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>

Hello

I'm not sure if this is an appropriate use of this mailing list or not, please let me know if it isn't.? I'm struggling to figure out how to merge two data tables based on max effective date logic compared to when a payment occurred.? My dtDistributions DT is a transactional dataset while dtDepartments is a domain data set containing all department names and the effective date of when department name changes have occurred.? For the Bob example below, there was a payment on 2016-01-01 which occurred in H229000.? In 2012, this department was named "Modified Name", in 2019 the department will be named "Final Name".? When I merge these two tables, I'd like it to pull the transactional data and match it up to department name "Modified Name" since that was the active department name at the time of that transaction.? I've read documentation on foverlaps, but I'm not sure if this problem is considered a range of dates or not.  At the bottom of this post is a temporarily solution that is working but it runs for a long time due to the amount of data in my actual source.

Here is some sample data to get started:
library(data.table)
dtDistributions <- data.table(PayeeName = c("Bob", "Tracy", "Tom"),
????????????????????????? Department = factor(c("H229000", "H135000", "H047800")),
????????????????????????? Amount = c(5, 34, 87),
????????????????????????? PaymentDT = as.Date(c("2016-01-01", "2015-01-01", "2015-01-01")))

dtDepartments <- data.table(Department = factor(c("H229000", "H229000", "H229000", "H135000", "H047800")),
??????????????????????? EffDT = as.Date(c("2019-01-01", "2012-01-01", "1901-01-01", "1901-01-01", "1901-01-01")),
??????????????????????? Descr = c("Final Name","Modified Name","Original Name","Payables","Postal"))

Here is the output I would like to see:
PayeeName? Department???? PaymentDT?? Amount
Bob??????? Modified Name ?2016-01-01 ?5
Tracy????? Payables????? ?2015-01-01 ?34
Tom??????? Postal??????? ?2015-01-01 ?87

I was able to get this working by using the sqldf library, but it runs for a very long time in my actual dataset and I'd like to use data.table if at all possible.
library(sqldf)
joinString <- "SELECT A.PayeeName, B.Descr, A.PaymentDT, A.Amount
?????? ?????FROM dtDistributions A, dtDepartments B
??????????? WHERE A.DEPARTMENT = B.Department
??????????? AND B.EffDT = (SELECT MAX(ED.EffDT)
??????????????????????????? FROM dtDepartments ED
??????????????????????????? WHERE B.Department = ED.Department
??? ????????????????????????AND ED.EffDT <= A.PaymentDT)"

finalDT <- data.table(sqldf(joinString))



-----Message Disclaimer-----

This e-mail message is intended only for the use of the individual or entity to which it is addressed, and may contain information that is privileged, confidential and exempt from disclosure under applicable law. If you are not the intended recipient, any dissemination, distribution or copying of this communication is strictly prohibited. If you have received this communication in error, please notify us immediately by reply email to Connect at principal.com and delete or destroy all copies of the original message and attachments thereto. Email sent to or from the Principal Financial Group or any of its member companies may be retained as required by law or regulation.

Nothing in this message is intended to constitute an Electronic signature for purposes of the Uniform Electronic Transactions Act (UETA) or the Electronic Signatures in Global and National Commerce Act ("E-Sign") unless a specific statement to the contrary is included in this message.

If you no longer wish to receive any further solicitation from the Principal Financial Group you may unsubscribe at https://www.principal.com/do-not-contact-form any time.

If you are a Canadian resident and no longer wish to receive commercial electronic messages you may unsubscribe at https://www.principal.com/do-not-email-request-canadian-residents any time.





This message was secured by Zix(R).


From bgunter.4567 at gmail.com  Thu Feb  1 22:01:16 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 1 Feb 2018 13:01:16 -0800
Subject: [R] Data Table Merge Help
In-Reply-To: <SN1PR10MB0382BD5D7600988BEED26D12E4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
References: <SN1PR10MB0382882BF229F0A4FD6C904CE4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
 <SN1PR10MB0382BD5D7600988BEED26D12E4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
Message-ID: <CAGxFJbTLpoh=ftKt6b6G9W7yeY-p8Fcv1Au0Dtu7145+nGAymg@mail.gmail.com>

Did you search first? (This is suggested by the posting guide -- below
-- prior to posting).

"merge 2 data.tables in R" brought up what looked like useful stuff,
in particular the  merge() function for data tables. If this does not
do what you want, it may help to explain why not.

Alternatively, there is a merge.data.frame function that may do the
job if you first convert your data.table to a data.frame.

As I do not use the data.table package, you or others may have to fill
in details to make these work -- if they *can* work.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 1, 2018 at 9:45 AM, Graeve, Nick <Graeve.Nick at principal.com> wrote:
> Hello
>
> I'm not sure if this is an appropriate use of this mailing list or not, please let me know if it isn't.  I'm struggling to figure out how to merge two data tables based on max effective date logic compared to when a payment occurred.  My dtDistributions DT is a transactional dataset while dtDepartments is a domain data set containing all department names and the effective date of when department name changes have occurred.  For the Bob example below, there was a payment on 2016-01-01 which occurred in H229000.  In 2012, this department was named "Modified Name", in 2019 the department will be named "Final Name".  When I merge these two tables, I'd like it to pull the transactional data and match it up to department name "Modified Name" since that was the active department name at the time of that transaction.  I've read documentation on foverlaps, but I'm not sure if this problem is considered a range of dates or not.  At the bottom of this post is a temporarily solution that is working but it runs for a long time due to the amount of data in my actual source.
>
> Here is some sample data to get started:
> library(data.table)
> dtDistributions <- data.table(PayeeName = c("Bob", "Tracy", "Tom"),
>                           Department = factor(c("H229000", "H135000", "H047800")),
>                           Amount = c(5, 34, 87),
>                           PaymentDT = as.Date(c("2016-01-01", "2015-01-01", "2015-01-01")))
>
> dtDepartments <- data.table(Department = factor(c("H229000", "H229000", "H229000", "H135000", "H047800")),
>                         EffDT = as.Date(c("2019-01-01", "2012-01-01", "1901-01-01", "1901-01-01", "1901-01-01")),
>                         Descr = c("Final Name","Modified Name","Original Name","Payables","Postal"))
>
> Here is the output I would like to see:
> PayeeName  Department     PaymentDT   Amount
> Bob        Modified Name  2016-01-01  5
> Tracy      Payables       2015-01-01  34
> Tom        Postal         2015-01-01  87
>
> I was able to get this working by using the sqldf library, but it runs for a very long time in my actual dataset and I'd like to use data.table if at all possible.
> library(sqldf)
> joinString <- "SELECT A.PayeeName, B.Descr, A.PaymentDT, A.Amount
>             FROM dtDistributions A, dtDepartments B
>             WHERE A.DEPARTMENT = B.Department
>             AND B.EffDT = (SELECT MAX(ED.EffDT)
>                             FROM dtDepartments ED
>                             WHERE B.Department = ED.Department
>                             AND ED.EffDT <= A.PaymentDT)"
>
> finalDT <- data.table(sqldf(joinString))
>
>
>
> -----Message Disclaimer-----
>
> This e-mail message is intended only for the use of the individual or entity to which it is addressed, and may contain information that is privileged, confidential and exempt from disclosure under applicable law. If you are not the intended recipient, any dissemination, distribution or copying of this communication is strictly prohibited. If you have received this communication in error, please notify us immediately by reply email to Connect at principal.com and delete or destroy all copies of the original message and attachments thereto. Email sent to or from the Principal Financial Group or any of its member companies may be retained as required by law or regulation.
>
> Nothing in this message is intended to constitute an Electronic signature for purposes of the Uniform Electronic Transactions Act (UETA) or the Electronic Signatures in Global and National Commerce Act ("E-Sign") unless a specific statement to the contrary is included in this message.
>
> If you no longer wish to receive any further solicitation from the Principal Financial Group you may unsubscribe at https://www.principal.com/do-not-contact-form any time.
>
> If you are a Canadian resident and no longer wish to receive commercial electronic messages you may unsubscribe at https://www.principal.com/do-not-email-request-canadian-residents any time.
>
>
>
>
>
> This message was secured by Zix(R).
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Thu Feb  1 22:34:39 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 1 Feb 2018 21:34:39 +0000
Subject: [R] Error while working with png output on linux server
Message-ID: <0430931C-B57F-4825-8F46-7E1E46877160@llnl.gov>

What does
   capabilities()
return?

For example, I get

> capabilities()
       jpeg         png        tiff       tcltk         X11 
       TRUE        TRUE        TRUE        TRUE        TRUE 
       aqua    http/ftp     sockets      libxml        fifo 
       TRUE        TRUE        TRUE        TRUE        TRUE 
     cledit       iconv         NLS     profmem       cairo 
      FALSE        TRUE        TRUE        TRUE        TRUE 
        ICU long.double     libcurl 
       TRUE        TRUE        TRUE

If you get FALSE for png or X11, then you do indeed have an issue with your installation. And probably, as Jeff Newmiller suggested, with which support software is or is not installed on the system.

-Don


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 
?On 2/1/18, 6:50 AM, "R-help on behalf of Sariya, Sanjeev" <r-help-bounces at r-project.org on behalf of ss5505 at cumc.columbia.edu> wrote:

    I'm working on linux server:
    Linux  4.9.0-4-amd64 #1 SMP Debian 4.9.51-1 (2017-09-28) x86_64 GNU/Linux
    
    I get error while creating png files. I'm sharing my commands and error while I run those commands:
    
    >png("abc", type="cairo")
    Error in .External2(C_X11, paste0("png::", filename), g$width, g$height,  :
      unable to start device PNG
    In addition: Warning message:
    In png("abc", type = "cairo") : unable to open connection to X11 display ''
    
    > png("apoeqqplot.png", res=600)
    Error in .External2(C_X11, paste0("png::", filename), g$width, g$height,  :
      unable to start device PNG
    In addition: Warning message:
    In png("apoeqqplot.png", res = 600) :
      unable to open connection to X11 display ''
    
    dev.off()
    
    R version 3.4.2 (2017-09-28)
    Platform: x86_64-pc-linux-gnu (64-bit)
    Running under: Debian GNU/Linux 9 (stretch)
    
    Matrix products: default
    BLAS: /mnt/mfs/cluster/bin/R-3.4/lib/libRblas.so
    LAPACK: /mnt/mfs/cluster/bin/R-3.4/lib/libRlapack.so
    
    locale:
    [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
    [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
    [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
    [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
    [9] LC_ADDRESS=C               LC_TELEPHONE=C
    [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
    
    attached base packages:
    [1] stats     graphics  grDevices utils     datasets  methods   base
    
    other attached packages:
    [1] CMplot_3.3.1
    
    loaded via a namespace (and not attached):
    [1] compiler_3.4.2 tools_3.4.2
    
    
    How do I fix this?
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewmil at dcn.davis.ca.us  Thu Feb  1 23:24:11 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Feb 2018 14:24:11 -0800
Subject: [R] Data Table Merge Help
In-Reply-To: <SN1PR10MB0382BD5D7600988BEED26D12E4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
References: <SN1PR10MB0382882BF229F0A4FD6C904CE4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
 <SN1PR10MB0382BD5D7600988BEED26D12E4FA0@SN1PR10MB0382.namprd10.prod.outlook.com>
Message-ID: <9264ED33-AFB0-4D87-A9F1-B1921353E752@dcn.davis.ca.us>

I rarely use data.table, but I think the vignette for the package discusses rolling joins. Also,  Google popped up [1].

[1] https://www.r-bloggers.com/understanding-data-table-rolling-joins/
-- 
Sent from my phone. Please excuse my brevity.

On February 1, 2018 9:45:53 AM PST, "Graeve, Nick" <Graeve.Nick at principal.com> wrote:
>Hello
>
>I'm not sure if this is an appropriate use of this mailing list or not,
>please let me know if it isn't.? I'm struggling to figure out how to
>merge two data tables based on max effective date logic compared to
>when a payment occurred.? My dtDistributions DT is a transactional
>dataset while dtDepartments is a domain data set containing all
>department names and the effective date of when department name changes
>have occurred.? For the Bob example below, there was a payment on
>2016-01-01 which occurred in H229000.? In 2012, this department was
>named "Modified Name", in 2019 the department will be named "Final
>Name".? When I merge these two tables, I'd like it to pull the
>transactional data and match it up to department name "Modified Name"
>since that was the active department name at the time of that
>transaction.? I've read documentation on foverlaps, but I'm not sure if
>this problem is considered a range of dates or not.  At the bottom of
>this post is a temporarily solution that is working but it runs for a
>long time due to the amount of data in my actual source.
>
>Here is some sample data to get started:
>library(data.table)
>dtDistributions <- data.table(PayeeName = c("Bob", "Tracy", "Tom"),
>????????????????????????? Department = factor(c("H229000", "H135000",
>"H047800")),
>????????????????????????? Amount = c(5, 34, 87),
>????????????????????????? PaymentDT = as.Date(c("2016-01-01",
>"2015-01-01", "2015-01-01")))
>
>dtDepartments <- data.table(Department = factor(c("H229000", "H229000",
>"H229000", "H135000", "H047800")),
>??????????????????????? EffDT = as.Date(c("2019-01-01", "2012-01-01",
>"1901-01-01", "1901-01-01", "1901-01-01")),
>??????????????????????? Descr = c("Final Name","Modified
>Name","Original Name","Payables","Postal"))
>
>Here is the output I would like to see:
>PayeeName? Department???? PaymentDT?? Amount
>Bob??????? Modified Name ?2016-01-01 ?5
>Tracy????? Payables????? ?2015-01-01 ?34
>Tom??????? Postal??????? ?2015-01-01 ?87
>
>I was able to get this working by using the sqldf library, but it runs
>for a very long time in my actual dataset and I'd like to use
>data.table if at all possible.
>library(sqldf)
>joinString <- "SELECT A.PayeeName, B.Descr, A.PaymentDT, A.Amount
>?????? ?????FROM dtDistributions A, dtDepartments B
>??????????? WHERE A.DEPARTMENT = B.Department
>??????????? AND B.EffDT = (SELECT MAX(ED.EffDT)
>??????????????????????????? FROM dtDepartments ED
>??????????????????????????? WHERE B.Department = ED.Department
>??? ????????????????????????AND ED.EffDT <= A.PaymentDT)"
>
>finalDT <- data.table(sqldf(joinString))
>
>
>
>-----Message Disclaimer-----
>
>This e-mail message is intended only for the use of the individual or
>entity to which it is addressed, and may contain information that is
>privileged, confidential and exempt from disclosure under applicable
>law. If you are not the intended recipient, any dissemination,
>distribution or copying of this communication is strictly prohibited.
>If you have received this communication in error, please notify us
>immediately by reply email to Connect at principal.com and delete or
>destroy all copies of the original message and attachments thereto.
>Email sent to or from the Principal Financial Group or any of its
>member companies may be retained as required by law or regulation.
>
>Nothing in this message is intended to constitute an Electronic
>signature for purposes of the Uniform Electronic Transactions Act
>(UETA) or the Electronic Signatures in Global and National Commerce Act
>("E-Sign") unless a specific statement to the contrary is included in
>this message.
>
>If you no longer wish to receive any further solicitation from the
>Principal Financial Group you may unsubscribe at
>https://www.principal.com/do-not-contact-form any time.
>
>If you are a Canadian resident and no longer wish to receive commercial
>electronic messages you may unsubscribe at
>https://www.principal.com/do-not-email-request-canadian-residents any
>time.
>
>
>
>
>
>This message was secured by Zix(R).
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From p_connolly at slingshot.co.nz  Fri Feb  2 08:00:01 2018
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Fri, 2 Feb 2018 20:00:01 +1300
Subject: [R] Updating Rcpp package when it is claimed by dplyr
Message-ID: <20180202070001.GC5360@slingshot.co.nz>

When i  tried to install the hunspell package, I got this error message:

Error: package ?Rcpp? 0.12.3 was found, but >= 0.12.12 is required by ?hunspell?

So I set about installing a new version of Rcpp but I get this message:

Error in unloadNamespace(pkg_name) : 
  namespace ?Rcpp? is imported by ?dplyr? so cannot be unloaded

How does one get around that?  I tried installing Rcpp in a vanilla
session but the result was the same.

TIA
Patrick


> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

Matrix products: default
BLAS: /home/pat/local/R-3.4.3/lib/libRblas.so
LAPACK: /home/pat/local/R-3.4.3/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
 [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
 [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] utils     stats     grDevices graphics  methods   base     

other attached packages:
[1] lattice_0.20-35

loaded via a namespace (and not attached):
 [1] compiler_3.4.3 magrittr_1.5   R6_2.1.2       assertthat_0.1 parallel_3.4.3
 [6] tools_3.4.3    DBI_0.3.1      dplyr_0.4.3    Rcpp_0.12.3    grid_3.4.3    


-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From jdnewmil at dcn.davis.ca.us  Fri Feb  2 08:15:34 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Feb 2018 23:15:34 -0800
Subject: [R] Updating Rcpp package when it is claimed by dplyr
In-Reply-To: <20180202070001.GC5360@slingshot.co.nz>
References: <20180202070001.GC5360@slingshot.co.nz>
Message-ID: <4CA0EDC2-B95D-4B37-9097-B9418D047F04@dcn.davis.ca.us>

Your last statement is extremely unlikely to be true. The dplyr package should not be present in a vanilla environment, so there should be no such conflict. 
-- 
Sent from my phone. Please excuse my brevity.

On February 1, 2018 11:00:01 PM PST, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>When i  tried to install the hunspell package, I got this error
>message:
>
>Error: package ?Rcpp? 0.12.3 was found, but >= 0.12.12 is required by
>?hunspell?
>
>So I set about installing a new version of Rcpp but I get this message:
>
>Error in unloadNamespace(pkg_name) : 
>  namespace ?Rcpp? is imported by ?dplyr? so cannot be unloaded
>
>How does one get around that?  I tried installing Rcpp in a vanilla
>session but the result was the same.
>
>TIA
>Patrick
>
>
>> sessionInfo()
>R version 3.4.3 (2017-11-30)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: Ubuntu 14.04.5 LTS
>
>Matrix products: default
>BLAS: /home/pat/local/R-3.4.3/lib/libRblas.so
>LAPACK: /home/pat/local/R-3.4.3/lib/libRlapack.so
>
>locale:
> [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
> [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
> [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
> [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
>
>attached base packages:
>[1] utils     stats     grDevices graphics  methods   base     
>
>other attached packages:
>[1] lattice_0.20-35
>
>loaded via a namespace (and not attached):
>[1] compiler_3.4.3 magrittr_1.5   R6_2.1.2       assertthat_0.1
>parallel_3.4.3
>[6] tools_3.4.3    DBI_0.3.1      dplyr_0.4.3    Rcpp_0.12.3   
>grid_3.4.3    
>
>
>-- 
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>  
>   ___    Patrick Connolly   
> {~._.~}                   Great minds discuss ideas    
> _( Y )_  	         Average minds discuss events 
>(:_~*~_:)                  Small minds discuss people  
> (_)-(_)  	                      ..... Eleanor Roosevelt
>	  
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Feb  2 10:25:03 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 2 Feb 2018 10:25:03 +0100
Subject: [R] Updating Rcpp package when it is claimed by dplyr
In-Reply-To: <4CA0EDC2-B95D-4B37-9097-B9418D047F04@dcn.davis.ca.us>
References: <20180202070001.GC5360@slingshot.co.nz>
 <4CA0EDC2-B95D-4B37-9097-B9418D047F04@dcn.davis.ca.us>
Message-ID: <D2BEDCD4-B20C-42E6-9348-CC4845EA1ED9@gmail.com>

Or, to avoid accusing you of lying. what you think is "vanilla" probably isn't. What exactly did you do? On Unix-likes, I would do something like this

echo 'options(repos=list(CRAN="cran.r-project.org"));install.packages("Rcpp")' | R --vanilla

(or maybe https://cloud.r-project.org is better...)

-pd



> On 2 Feb 2018, at 08:15 , Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
> 
> Your last statement is extremely unlikely to be true. The dplyr package should not be present in a vanilla environment, so there should be no such conflict. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 1, 2018 11:00:01 PM PST, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>> When i  tried to install the hunspell package, I got this error
>> message:
>> 
>> Error: package ?Rcpp? 0.12.3 was found, but >= 0.12.12 is required by
>> ?hunspell?
>> 
>> So I set about installing a new version of Rcpp but I get this message:
>> 
>> Error in unloadNamespace(pkg_name) : 
>> namespace ?Rcpp? is imported by ?dplyr? so cannot be unloaded
>> 
>> How does one get around that?  I tried installing Rcpp in a vanilla
>> session but the result was the same.
>> 
>> TIA
>> Patrick
>> 
>> 
>>> sessionInfo()
>> R version 3.4.3 (2017-11-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.5 LTS
>> 
>> Matrix products: default
>> BLAS: /home/pat/local/R-3.4.3/lib/libRblas.so
>> LAPACK: /home/pat/local/R-3.4.3/lib/libRlapack.so
>> 
>> locale:
>> [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
>> [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
>> [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
>> [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
>> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
>> 
>> attached base packages:
>> [1] utils     stats     grDevices graphics  methods   base     
>> 
>> other attached packages:
>> [1] lattice_0.20-35
>> 
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.3 magrittr_1.5   R6_2.1.2       assertthat_0.1
>> parallel_3.4.3
>> [6] tools_3.4.3    DBI_0.3.1      dplyr_0.4.3    Rcpp_0.12.3   
>> grid_3.4.3    
>> 
>> 
>> -- 
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>> 
>>  ___    Patrick Connolly   
>> {~._.~}                   Great minds discuss ideas    
>> _( Y )_  	         Average minds discuss events 
>> (:_~*~_:)                  Small minds discuss people  
>> (_)-(_)  	                      ..... Eleanor Roosevelt
>> 	  
>> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m.ashton at enduringinvestments.com  Fri Feb  2 13:52:25 2018
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 2 Feb 2018 12:52:25 +0000
Subject: [R] command line fails
Message-ID: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>

Hi - Think this is quick help. Not sure how to trap what is causing my simple script to run fine in R, but fail immediately when called from rscript. I can put all sorts of traps in the script itself, but when called from the command line the r window simply flashes and closes.

There's probably a way to find out why rscript is failing, but I don't know it and can't seem to find it online. To be clear, I'm not really trying to save the OUTPUT of the file...it never even executes as far as I can tell. I'm calling it with C:\Program Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV Tools\myfile.r" And again, it executes perfectly if I open the GUI first and then run it within R.

Thanks for the help!

Mike

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Feb  2 14:16:28 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 2 Feb 2018 08:16:28 -0500
Subject: [R] command line fails
In-Reply-To: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <7dd0d997-43d7-d7a9-3ec4-312fd0fc544e@gmail.com>

On 02/02/2018 7:52 AM, Michael Ashton wrote:
> Hi - Think this is quick help. Not sure how to trap what is causing my simple script to run fine in R, but fail immediately when called from rscript. I can put all sorts of traps in the script itself, but when called from the command line the r window simply flashes and closes.
> 
> There's probably a way to find out why rscript is failing, but I don't know it and can't seem to find it online. To be clear, I'm not really trying to save the OUTPUT of the file...it never even executes as far as I can tell. I'm calling it with C:\Program Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV Tools\myfile.r" And again, it executes perfectly if I open the GUI first and then run it within R.
> 

I'd try using forward slashes in the path, i.e. "P:/Investments/Trading 
Tools/RV Tools/myfile.r"  I don't remember if R processes the path to 
the script or whether it's done entirely by the shell, but they 
shouldn't hurt.

Spaces in file paths sometimes cause trouble.  If you put the script in 
a path with no spaces does that help?  If so, you can probably escape 
that space, but I can't remember what the escape sequence is.  (Escapes 
in Windows can be processed by the command shell or Rscript.exe or both, 
so it's hard to get them right.)  Another alternative might be to change 
directory to that path and then use a relative path for the R script.

Duncan Murdoch


From m.ashton at enduringinvestments.com  Fri Feb  2 14:20:59 2018
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 2 Feb 2018 13:20:59 +0000
Subject: [R] command line fails
In-Reply-To: <7dd0d997-43d7-d7a9-3ec4-312fd0fc544e@gmail.com>
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
 <7dd0d997-43d7-d7a9-3ec4-312fd0fc544e@gmail.com>
Message-ID: <de8bcc1222444992ac2eea175da80207@MBX084-W1-CA-3.exch084.serverpod.net>

I don't think it's the path or the slashes. I run other files in this same manner, with the same path to the script itself, and they go off without a hitch. Although this is the first time I am using 3.4.3, and the only script I am using that version of R for at the moment.

Having said that, I did TRY reversing the slashes and got the same result. :-)

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Friday, February 02, 2018 8:16 AM
To: Michael Ashton; r-help at r-project.org
Subject: Re: [R] command line fails

On 02/02/2018 7:52 AM, Michael Ashton wrote:
> Hi - Think this is quick help. Not sure how to trap what is causing my simple script to run fine in R, but fail immediately when called from rscript. I can put all sorts of traps in the script itself, but when called from the command line the r window simply flashes and closes.
> 
> There's probably a way to find out why rscript is failing, but I don't know it and can't seem to find it online. To be clear, I'm not really trying to save the OUTPUT of the file...it never even executes as far as I can tell. I'm calling it with C:\Program Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV Tools\myfile.r" And again, it executes perfectly if I open the GUI first and then run it within R.
> 

I'd try using forward slashes in the path, i.e. "P:/Investments/Trading Tools/RV Tools/myfile.r"  I don't remember if R processes the path to the script or whether it's done entirely by the shell, but they shouldn't hurt.

Spaces in file paths sometimes cause trouble.  If you put the script in a path with no spaces does that help?  If so, you can probably escape that space, but I can't remember what the escape sequence is.  (Escapes in Windows can be processed by the command shell or Rscript.exe or both, so it's hard to get them right.)  Another alternative might be to change directory to that path and then use a relative path for the R script.

Duncan Murdoch

From murdoch.duncan at gmail.com  Fri Feb  2 15:03:03 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 2 Feb 2018 09:03:03 -0500
Subject: [R] command line fails
In-Reply-To: <de8bcc1222444992ac2eea175da80207@MBX084-W1-CA-3.exch084.serverpod.net>
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
 <7dd0d997-43d7-d7a9-3ec4-312fd0fc544e@gmail.com>
 <de8bcc1222444992ac2eea175da80207@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <448bf5f6-5bb7-ce81-90cd-0dc1106786cd@gmail.com>

On 02/02/2018 8:20 AM, Michael Ashton wrote:
> I don't think it's the path or the slashes. I run other files in this same manner, with the same path to the script itself, and they go off without a hitch. Although this is the first time I am using 3.4.3, and the only script I am using that version of R for at the moment.
> 
> Having said that, I did TRY reversing the slashes and got the same result. :-)
> 

I'd try to determine if anything works with 3.4.3.  If nothing does, 
maybe you need to back out to the older version.  If some scripts work 
and some don't, then it shouldn't take long to find the offending line 
by bisection:  comment out the last half of the script, if it works, 
that's where the problem is, so comment only the last quarter, etc.

Duncan Murdoch


> Michael Ashton, CFA
> Managing Principal
> 
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
> 
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, February 02, 2018 8:16 AM
> To: Michael Ashton; r-help at r-project.org
> Subject: Re: [R] command line fails
> 
> On 02/02/2018 7:52 AM, Michael Ashton wrote:
>> Hi - Think this is quick help. Not sure how to trap what is causing my simple script to run fine in R, but fail immediately when called from rscript. I can put all sorts of traps in the script itself, but when called from the command line the r window simply flashes and closes.
>>
>> There's probably a way to find out why rscript is failing, but I don't know it and can't seem to find it online. To be clear, I'm not really trying to save the OUTPUT of the file...it never even executes as far as I can tell. I'm calling it with C:\Program Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV Tools\myfile.r" And again, it executes perfectly if I open the GUI first and then run it within R.
>>
> 
> I'd try using forward slashes in the path, i.e. "P:/Investments/Trading Tools/RV Tools/myfile.r"  I don't remember if R processes the path to the script or whether it's done entirely by the shell, but they shouldn't hurt.
> 
> Spaces in file paths sometimes cause trouble.  If you put the script in a path with no spaces does that help?  If so, you can probably escape that space, but I can't remember what the escape sequence is.  (Escapes in Windows can be processed by the command shell or Rscript.exe or both, so it's hard to get them right.)  Another alternative might be to change directory to that path and then use a relative path for the R script.
> 
> Duncan Murdoch
>


From syslog at citromail.hu  Fri Feb  2 14:47:19 2018
From: syslog at citromail.hu (=?UTF-8?B?c3lzbG9nIHN5c2xvZw==?=)
Date: Fri, 2 Feb 2018 14:47:19 +0100
Subject: [R] =?utf-8?q?mpfr_and_gsl_problem_on_SLES11_SP4?=
Message-ID: <20180202144719.2276@citromail.hu>

Dear Team,


Maybe somebody already tried to install mpfr and gsl packages for R on SLES.
Exactly I try to install Rmpfr_0.6-1.tar.gz and gsl_1.9-10.3.tar.gz on SLES11 SP4.


These are the available packages from official SLES SDK media:

rtest:/home/ruser # rpm -qa | grep -i gsl

gsl-devel-1.11-1.30

gsl-1.11-1.30

rtest:/home/ruser # 


As I understand gsl is from 1.11 till 1.30 level.

rtest:/home/ruser # rpm -qa | grep -i mpfr

libmpfr1-2.3.2-3.118.1

mpfr-devel-2.3.2-3.118.1

rtest:/home/ruser # 


GSL installation: https://cran.r-project.org/web/packages/gsl/index.html
SystemRequirements:
Gnu Scientific Library version &gt;= 1.12

rtest:/home/ruser # R CMD INSTALL gsl_1.9-10.3.tar.gz

* installing to library ?/usr/local/lib64/R/library?

* installing *source* package ?gsl? ...

** package ?gsl? successfully unpacked and MD5 sums checked

checking for gsl-config... /usr/bin/gsl-config

checking if GSL version &gt;= 1.12... checking for gcc... gcc

checking for C compiler default output file name... a.out

checking whether the C compiler works... yes

checking whether we are cross compiling... no

checking for suffix of executables... 

checking for suffix of object files... o

checking whether we are using the GNU C compiler... yes

checking whether gcc accepts -g... yes

checking for gcc option to accept ISO C89... none needed

configure: error: Need GSL version &gt;= 1.12
ERROR: configuration failed for package ?gsl?

* removing ?/usr/local/lib64/R/library/gsl?

rtest:/home/ruser # 


Rmpfr installation: https://cran.r-project.org/web/packages/Rmpfr/index.html
SystemRequirements:
gmp (&gt;= 4.2.3), mpfr (&gt;= 3.0.0)

rtest:/home/ruser # R CMD INSTALL Rmpfr_0.6-1.tar.gz

* installing to library ?/usr/local/lib64/R/library?

* installing *source* package ?Rmpfr? ...

** package ?Rmpfr? successfully unpacked and MD5 sums checked

checking for gcc... gcc -std=gnu99

checking whether the C compiler works... yes

checking for C compiler default output file name... a.out

checking for suffix of executables... 

checking whether we are cross compiling... no

checking for suffix of object files... o

checking whether we are using the GNU C compiler... yes

checking whether gcc -std=gnu99 accepts -g... yes

checking for gcc -std=gnu99 option to accept ISO C89... none needed

checking how to run the C preprocessor... gcc -std=gnu99 -E

checking for grep that handles long lines and -e... /usr/bin/grep

checking for egrep... /usr/bin/grep -E

checking for ANSI C header files... yes

checking for sys/types.h... yes

checking for sys/stat.h... yes

checking for stdlib.h... yes

checking for string.h... yes

checking for memory.h... yes

checking for strings.h... yes

checking for inttypes.h... yes

checking for stdint.h... yes

checking for unistd.h... yes

checking mpfr.h usability... yes

checking mpfr.h presence... yes

checking for mpfr.h... yes

checking gmp.h usability... yes

checking gmp.h presence... yes

checking for gmp.h... yes

checking for __gmpz_init in -lgmp... yes

checking for mpfr_init in -lmpfr... yes

checking for mpfr_digamma in -lmpfr... no

configure: error: MPFR Library must be at least version 3.0.0, see README

ERROR: configuration failed for package ?Rmpfr?

* removing ?/usr/local/lib64/R/library/Rmpfr?

rtest:/home/ruser # 


Maybe R detects the packages wrongly ?
Can I edit source to ignore ?
Can I use Rmpfr and gsl with original SLES SDK packages ?


Regards,

Gery

IT Specialist



_________________________________________

Citromail.hu levelez?rendszerb?l k?ldve

L?pj be vagy regisztr?lj

	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Fri Feb  2 15:52:11 2018
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 2 Feb 2018 14:52:11 +0000
Subject: [R] command line fails
In-Reply-To: <448bf5f6-5bb7-ce81-90cd-0dc1106786cd@gmail.com>
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
 <7dd0d997-43d7-d7a9-3ec4-312fd0fc544e@gmail.com>
 <de8bcc1222444992ac2eea175da80207@MBX084-W1-CA-3.exch084.serverpod.net>
 <448bf5f6-5bb7-ce81-90cd-0dc1106786cd@gmail.com>
Message-ID: <0f17cb9cfb4b4ee99b26ee51994dbe81@MBX084-W1-CA-3.exch084.serverpod.net>

Fascinating. The script runs fine in 3.2.5, but won't run in 3.4.3 even with ALL lines commented out.

I have no idea what that means. I can't imagine I found a 3.4.3 bug no one knows about.

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Friday, February 02, 2018 9:03 AM
To: Michael Ashton; r-help at r-project.org
Subject: Re: [R] command line fails

On 02/02/2018 8:20 AM, Michael Ashton wrote:
> I don't think it's the path or the slashes. I run other files in this same manner, with the same path to the script itself, and they go off without a hitch. Although this is the first time I am using 3.4.3, and the only script I am using that version of R for at the moment.
> 
> Having said that, I did TRY reversing the slashes and got the same 
> result. :-)
> 

I'd try to determine if anything works with 3.4.3.  If nothing does, maybe you need to back out to the older version.  If some scripts work and some don't, then it shouldn't take long to find the offending line by bisection:  comment out the last half of the script, if it works, that's where the problem is, so comment only the last quarter, etc.

Duncan Murdoch


> Michael Ashton, CFA
> Managing Principal
> 
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
> 
> 
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, February 02, 2018 8:16 AM
> To: Michael Ashton; r-help at r-project.org
> Subject: Re: [R] command line fails
> 
> On 02/02/2018 7:52 AM, Michael Ashton wrote:
>> Hi - Think this is quick help. Not sure how to trap what is causing my simple script to run fine in R, but fail immediately when called from rscript. I can put all sorts of traps in the script itself, but when called from the command line the r window simply flashes and closes.
>>
>> There's probably a way to find out why rscript is failing, but I don't know it and can't seem to find it online. To be clear, I'm not really trying to save the OUTPUT of the file...it never even executes as far as I can tell. I'm calling it with C:\Program Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV Tools\myfile.r" And again, it executes perfectly if I open the GUI first and then run it within R.
>>
> 
> I'd try using forward slashes in the path, i.e. "P:/Investments/Trading Tools/RV Tools/myfile.r"  I don't remember if R processes the path to the script or whether it's done entirely by the shell, but they shouldn't hurt.
> 
> Spaces in file paths sometimes cause trouble.  If you put the script in a path with no spaces does that help?  If so, you can probably escape that space, but I can't remember what the escape sequence is.  (Escapes in Windows can be processed by the command shell or Rscript.exe or both, so it's hard to get them right.)  Another alternative might be to change directory to that path and then use a relative path for the R script.
> 
> Duncan Murdoch
> 

From es at enricoschumann.net  Fri Feb  2 16:35:55 2018
From: es at enricoschumann.net (Enrico Schumann)
Date: Fri, 02 Feb 2018 16:35:55 +0100
Subject: [R] command line fails
In-Reply-To: <0f17cb9cfb4b4ee99b26ee51994dbe81@MBX084-W1-CA-3.exch084.serverpod.net>
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
 <7dd0d997-43d7-d7a9-3ec4-312fd0fc544e@gmail.com>
 <de8bcc1222444992ac2eea175da80207@MBX084-W1-CA-3.exch084.serverpod.net>
 <448bf5f6-5bb7-ce81-90cd-0dc1106786cd@gmail.com>
 <0f17cb9cfb4b4ee99b26ee51994dbe81@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <20180202163555.Horde.d0U5_JLpziVnAZpHNCRf5Al@webmail.your-server.de>


Quoting Michael Ashton <m.ashton at enduringinvestments.com>:

> Fascinating. The script runs fine in 3.2.5, but won't run in 3.4.3  
> even with ALL lines commented out.
>
> I have no idea what that means. I can't imagine I found a 3.4.3 bug  
> no one knows about.
>
> Michael Ashton, CFA
> Managing Principal
>
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006

Just a guess: Could you try the patched version?

There was some discussion concerning 3.4.3 and command-line
arguments on Windows:

https://stat.ethz.ch/pipermail/r-devel/2017-December/075194.html

Kind regards
     Enrico



>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, February 02, 2018 9:03 AM
> To: Michael Ashton; r-help at r-project.org
> Subject: Re: [R] command line fails
>
> On 02/02/2018 8:20 AM, Michael Ashton wrote:
>> I don't think it's the path or the slashes. I run other files in  
>> this same manner, with the same path to the script itself, and they  
>> go off without a hitch. Although this is the first time I am using  
>> 3.4.3, and the only script I am using that version of R for at the  
>> moment.
>>
>> Having said that, I did TRY reversing the slashes and got the same
>> result. :-)
>>
>
> I'd try to determine if anything works with 3.4.3.  If nothing does,  
> maybe you need to back out to the older version.  If some scripts  
> work and some don't, then it shouldn't take long to find the  
> offending line by bisection:  comment out the last half of the  
> script, if it works, that's where the problem is, so comment only  
> the last quarter, etc.
>
> Duncan Murdoch
>
>
>> Michael Ashton, CFA
>> Managing Principal
>>
>> Enduring Investments LLC
>> W: 973.457.4602
>> C: 551.655.8006
>>
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Friday, February 02, 2018 8:16 AM
>> To: Michael Ashton; r-help at r-project.org
>> Subject: Re: [R] command line fails
>>
>> On 02/02/2018 7:52 AM, Michael Ashton wrote:
>>> Hi - Think this is quick help. Not sure how to trap what is  
>>> causing my simple script to run fine in R, but fail immediately  
>>> when called from rscript. I can put all sorts of traps in the  
>>> script itself, but when called from the command line the r window  
>>> simply flashes and closes.
>>>
>>> There's probably a way to find out why rscript is failing, but I  
>>> don't know it and can't seem to find it online. To be clear, I'm  
>>> not really trying to save the OUTPUT of the file...it never even  
>>> executes as far as I can tell. I'm calling it with C:\Program  
>>> Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV  
>>> Tools\myfile.r" And again, it executes perfectly if I open the GUI  
>>> first and then run it within R.
>>>
>>
>> I'd try using forward slashes in the path, i.e.  
>> "P:/Investments/Trading Tools/RV Tools/myfile.r"  I don't remember  
>> if R processes the path to the script or whether it's done entirely  
>> by the shell, but they shouldn't hurt.
>>
>> Spaces in file paths sometimes cause trouble.  If you put the  
>> script in a path with no spaces does that help?  If so, you can  
>> probably escape that space, but I can't remember what the escape  
>> sequence is.  (Escapes in Windows can be processed by the command  
>> shell or Rscript.exe or both, so it's hard to get them right.)   
>> Another alternative might be to change directory to that path and  
>> then use a relative path for the R script.
>>
>> Duncan Murdoch
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From es at enricoschumann.net  Fri Feb  2 19:35:14 2018
From: es at enricoschumann.net (Enrico Schumann)
Date: Fri, 02 Feb 2018 19:35:14 +0100
Subject: [R] command line fails
In-Reply-To: <552e23010d70430f9db96c45d50d1e86@MBX084-W1-CA-3.exch084.serverpod.net>
 (Michael Ashton's message of "Fri, 2 Feb 2018 16:58:42 +0000")
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
 <7dd0d997-43d7-d7a9-3ec4-312fd0fc544e@gmail.com>
 <de8bcc1222444992ac2eea175da80207@MBX084-W1-CA-3.exch084.serverpod.net>
 <448bf5f6-5bb7-ce81-90cd-0dc1106786cd@gmail.com>
 <0f17cb9cfb4b4ee99b26ee51994dbe81@MBX084-W1-CA-3.exch084.serverpod.net>
 <20180202163555.Horde.d0U5_JLpziVnAZpHNCRf5Al@webmail.your-server.de>
 <552e23010d70430f9db96c45d50d1e86@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <87efm3b5p9.fsf@enricoschumann.net>

On Fri, 02 Feb 2018, Michael Ashton writes:

> Where can I get the patch? I've never installed a patch for R...usually just upgrade.
>
> Michael Ashton, CFA
> Managing Principal
>
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
>

The patched build (i.e. a complete version, not just
the patch) is available from the same CRAN site at
which you find the official release; just further
below.


> -----Original Message-----
> From: Enrico Schumann [mailto:es at enricoschumann.net] 
> Sent: Friday, February 02, 2018 10:36 AM
> To: Michael Ashton
> Cc: Duncan Murdoch; r-help at r-project.org
> Subject: Re: [R] command line fails
>
>
> Quoting Michael Ashton <m.ashton at enduringinvestments.com>:
>
>> Fascinating. The script runs fine in 3.2.5, but won't run in 3.4.3 
>> even with ALL lines commented out.
>>
>> I have no idea what that means. I can't imagine I found a 3.4.3 bug no 
>> one knows about.
>>
>> Michael Ashton, CFA
>> Managing Principal
>>
>> Enduring Investments LLC
>> W: 973.457.4602
>> C: 551.655.8006
>
> Just a guess: Could you try the patched version?
>
> There was some discussion concerning 3.4.3 and command-line arguments on Windows:
>
> https://stat.ethz.ch/pipermail/r-devel/2017-December/075194.html
>
> Kind regards
>      Enrico
>
>
>
>>
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: Friday, February 02, 2018 9:03 AM
>> To: Michael Ashton; r-help at r-project.org
>> Subject: Re: [R] command line fails
>>
>> On 02/02/2018 8:20 AM, Michael Ashton wrote:
>>> I don't think it's the path or the slashes. I run other files in this 
>>> same manner, with the same path to the script itself, and they go off 
>>> without a hitch. Although this is the first time I am using 3.4.3, 
>>> and the only script I am using that version of R for at the moment.
>>>
>>> Having said that, I did TRY reversing the slashes and got the same 
>>> result. :-)
>>>
>>
>> I'd try to determine if anything works with 3.4.3.  If nothing does, 
>> maybe you need to back out to the older version.  If some scripts work 
>> and some don't, then it shouldn't take long to find the offending line 
>> by bisection:  comment out the last half of the script, if it works, 
>> that's where the problem is, so comment only the last quarter, etc.
>>
>> Duncan Murdoch
>>
>>
>>> Michael Ashton, CFA
>>> Managing Principal
>>>
>>> Enduring Investments LLC
>>> W: 973.457.4602
>>> C: 551.655.8006
>>>
>>>
>>> -----Original Message-----
>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>> Sent: Friday, February 02, 2018 8:16 AM
>>> To: Michael Ashton; r-help at r-project.org
>>> Subject: Re: [R] command line fails
>>>
>>> On 02/02/2018 7:52 AM, Michael Ashton wrote:
>>>> Hi - Think this is quick help. Not sure how to trap what is causing 
>>>> my simple script to run fine in R, but fail immediately when called 
>>>> from rscript. I can put all sorts of traps in the script itself, but 
>>>> when called from the command line the r window simply flashes and 
>>>> closes.
>>>>
>>>> There's probably a way to find out why rscript is failing, but I 
>>>> don't know it and can't seem to find it online. To be clear, I'm not 
>>>> really trying to save the OUTPUT of the file...it never even 
>>>> executes as far as I can tell. I'm calling it with C:\Program 
>>>> Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV 
>>>> Tools\myfile.r" And again, it executes perfectly if I open the GUI 
>>>> first and then run it within R.
>>>>
>>>
>>> I'd try using forward slashes in the path, i.e.  
>>> "P:/Investments/Trading Tools/RV Tools/myfile.r"  I don't remember if 
>>> R processes the path to the script or whether it's done entirely by 
>>> the shell, but they shouldn't hurt.
>>>
>>> Spaces in file paths sometimes cause trouble.  If you put the script 
>>> in a path with no spaces does that help?  If so, you can probably 
>>> escape that space, but I can't remember what the escape sequence is.  
>>> (Escapes in Windows can be processed by the command
>>> shell or Rscript.exe or both, so it's hard to get them right.)   
>>> Another alternative might be to change directory to that path and 
>>> then use a relative path for the R script.
>>>
>>> Duncan Murdoch
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From p_connolly at slingshot.co.nz  Fri Feb  2 22:35:07 2018
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Sat, 3 Feb 2018 10:35:07 +1300
Subject: [R] Updating Rcpp package when it is claimed by dplyr
In-Reply-To: <D2BEDCD4-B20C-42E6-9348-CC4845EA1ED9@gmail.com>
References: <20180202070001.GC5360@slingshot.co.nz>
 <4CA0EDC2-B95D-4B37-9097-B9418D047F04@dcn.davis.ca.us>
 <D2BEDCD4-B20C-42E6-9348-CC4845EA1ED9@gmail.com>
Message-ID: <20180202213507.GD5360@slingshot.co.nz>

On Fri, 02-Feb-2018 at 10:25AM +0100, peter dalgaard wrote:

|> Or, to avoid accusing you of lying. what you think is "vanilla"
|> probably isn't. What exactly did you do? On Unix-likes, I would do
|> something like this

|> echo 'options(repos=list(CRAN="cran.r-project.org"));install.packages("Rcpp")' | R --vanilla
|> 
|> (or maybe https://cloud.r-project.org is better...)

Thanks for the suggestion.  

I simply did 
R -- vanilla

I tried it again this morning so that I could compare the output.
However, it *worked* fine -- just as I thought it would done
yesterday.  Why it didn't work yesterday is a mystery.

I've had a few other things behaving strangely on this machine so
there might be an OS issue, not an R issue.

Thanks for taking the time.

Patrick

|> 
|> -pd
|> 
|> 
|> 
|> > On 2 Feb 2018, at 08:15 , Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
|> > 
|> > Your last statement is extremely unlikely to be true. The dplyr package should not be present in a vanilla environment, so there should be no such conflict. 
|> > -- 
|> > Sent from my phone. Please excuse my brevity.
|> > 
|> > On February 1, 2018 11:00:01 PM PST, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> >> When i  tried to install the hunspell package, I got this error
|> >> message:
|> >> 
|> >> Error: package ?Rcpp? 0.12.3 was found, but >= 0.12.12 is required by
|> >> ?hunspell?
|> >> 
|> >> So I set about installing a new version of Rcpp but I get this message:
|> >> 
|> >> Error in unloadNamespace(pkg_name) : 
|> >> namespace ?Rcpp? is imported by ?dplyr? so cannot be unloaded
|> >> 
|> >> How does one get around that?  I tried installing Rcpp in a vanilla
|> >> session but the result was the same.
|> >> 
|> >> TIA
|> >> Patrick
|> >> 
|> >> 
|> >>> sessionInfo()
|> >> R version 3.4.3 (2017-11-30)
|> >> Platform: x86_64-pc-linux-gnu (64-bit)
|> >> Running under: Ubuntu 14.04.5 LTS
|> >> 
|> >> Matrix products: default
|> >> BLAS: /home/pat/local/R-3.4.3/lib/libRblas.so
|> >> LAPACK: /home/pat/local/R-3.4.3/lib/libRlapack.so
|> >> 
|> >> locale:
|> >> [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
|> >> [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
|> >> [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
|> >> [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
|> >> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
|> >> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
|> >> 
|> >> attached base packages:
|> >> [1] utils     stats     grDevices graphics  methods   base     
|> >> 
|> >> other attached packages:
|> >> [1] lattice_0.20-35
|> >> 
|> >> loaded via a namespace (and not attached):
|> >> [1] compiler_3.4.3 magrittr_1.5   R6_2.1.2       assertthat_0.1
|> >> parallel_3.4.3
|> >> [6] tools_3.4.3    DBI_0.3.1      dplyr_0.4.3    Rcpp_0.12.3   
|> >> grid_3.4.3    
|> >> 
|> >> 
|> >> -- 
|> >> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >> 
|> >>  ___    Patrick Connolly   
|> >> {~._.~}                   Great minds discuss ideas    
|> >> _( Y )_  	         Average minds discuss events 
|> >> (:_~*~_:)                  Small minds discuss people  
|> >> (_)-(_)  	                      ..... Eleanor Roosevelt
|> >> 	  
|> >> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >> 
|> >> ______________________________________________
|> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> >> https://stat.ethz.ch/mailman/listinfo/r-help
|> >> PLEASE do read the posting guide
|> >> http://www.R-project.org/posting-guide.html
|> >> and provide commented, minimal, self-contained, reproducible code.
|> > 
|> > ______________________________________________
|> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> > https://stat.ethz.ch/mailman/listinfo/r-help
|> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> > and provide commented, minimal, self-contained, reproducible code.
|> 
|> -- 
|> Peter Dalgaard, Professor,
|> Center for Statistics, Copenhagen Business School
|> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
|> Phone: (+45)38153501
|> Office: A 4.23
|> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
|> 
|> 
|> 
|> 
|> 
|> 
|> 
|> 
|> 

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From djnordlund at gmail.com  Fri Feb  2 22:43:36 2018
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Fri, 2 Feb 2018 13:43:36 -0800
Subject: [R] command line fails
In-Reply-To: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <b18d420c-f00c-249d-4e72-901e60412746@gmail.com>

On 2/2/2018 4:52 AM, Michael Ashton wrote:
> Hi - Think this is quick help. Not sure how to trap what is causing my simple script to run fine in R, but fail immediately when called from rscript. I can put all sorts of traps in the script itself, but when called from the command line the r window simply flashes and closes.
> 
> There's probably a way to find out why rscript is failing, but I don't know it and can't seem to find it online. To be clear, I'm not really trying to save the OUTPUT of the file...it never even executes as far as I can tell. I'm calling it with C:\Program Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV Tools\myfile.r" And again, it executes perfectly if I open the GUI first and then run it within R.
> 
> Thanks for the help!
> 
> Mike
> 
> Michael Ashton, CFA
> Managing Principal
> 
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Mike,

on Windows, anytime you send a path that contains a space to the command 
line it needs to be enclosed in double quotes.  Try a call like

"C:/Program Files/R/R-3.4.3/bin/Rscript.exe" "P:/Investments/Trading 
Tools/RV Tools/myfile.r"

I don't know how rscript handles the '\' character (i.e. as an escape or 
not) so I changed the '\' to '/' just to be safe.  And note, the program 
pathname and the file being passed need to be quoted separately.


Hope this helps,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From m.ashton at enduringinvestments.com  Fri Feb  2 22:49:17 2018
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 2 Feb 2018 21:49:17 +0000
Subject: [R] command line fails
In-Reply-To: <b18d420c-f00c-249d-4e72-901e60412746@gmail.com>
References: <509171c75ea94a88b73827bf61a5e2de@MBX084-W1-CA-3.exch084.serverpod.net>
 <b18d420c-f00c-249d-4e72-901e60412746@gmail.com>
Message-ID: <85d16184fc3e42a29400b281238548f3@MBX084-W1-CA-3.exch084.serverpod.net>

Thans Dan. It seems that it may be an issue with 3.4.3...I'm going to attempt a patch this weekend. The code works fine from the command line in 3.2.5!

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006


-----Original Message-----
From: Daniel Nordlund [mailto:djnordlund at gmail.com] 
Sent: Friday, February 02, 2018 4:44 PM
To: Michael Ashton; r-help at r-project.org
Subject: Re: [R] command line fails

On 2/2/2018 4:52 AM, Michael Ashton wrote:
> Hi - Think this is quick help. Not sure how to trap what is causing my simple script to run fine in R, but fail immediately when called from rscript. I can put all sorts of traps in the script itself, but when called from the command line the r window simply flashes and closes.
> 
> There's probably a way to find out why rscript is failing, but I don't know it and can't seem to find it online. To be clear, I'm not really trying to save the OUTPUT of the file...it never even executes as far as I can tell. I'm calling it with C:\Program Files\R\R-3.4.3\bin\Rscript.exe "P:\Investments\Trading Tools\RV Tools\myfile.r" And again, it executes perfectly if I open the GUI first and then run it within R.
> 
> Thanks for the help!
> 
> Mike
> 
> Michael Ashton, CFA
> Managing Principal
> 
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Mike,

on Windows, anytime you send a path that contains a space to the command line it needs to be enclosed in double quotes.  Try a call like

"C:/Program Files/R/R-3.4.3/bin/Rscript.exe" "P:/Investments/Trading Tools/RV Tools/myfile.r"

I don't know how rscript handles the '\' character (i.e. as an escape or
not) so I changed the '\' to '/' just to be safe.  And note, the program pathname and the file being passed need to be quoted separately.


Hope this helps,

Dan

--
Daniel Nordlund
Port Townsend, WA  USA

From jdnewmil at dcn.davis.ca.us  Fri Feb  2 23:51:19 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 02 Feb 2018 14:51:19 -0800
Subject: [R] Updating Rcpp package when it is claimed by dplyr
In-Reply-To: <20180202213507.GD5360@slingshot.co.nz>
References: <20180202070001.GC5360@slingshot.co.nz>
 <4CA0EDC2-B95D-4B37-9097-B9418D047F04@dcn.davis.ca.us>
 <D2BEDCD4-B20C-42E6-9348-CC4845EA1ED9@gmail.com>
 <20180202213507.GD5360@slingshot.co.nz>
Message-ID: <811C53FC-153F-4ACD-896D-D0606F0F2E6F@dcn.davis.ca.us>

Be sure to not put a space between the "---" and the "vanilla".
-- 
Sent from my phone. Please excuse my brevity.

On February 2, 2018 1:35:07 PM PST, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>On Fri, 02-Feb-2018 at 10:25AM +0100, peter dalgaard wrote:
>
>|> Or, to avoid accusing you of lying. what you think is "vanilla"
>|> probably isn't. What exactly did you do? On Unix-likes, I would do
>|> something like this
>
>|> echo
>'options(repos=list(CRAN="cran.r-project.org"));install.packages("Rcpp")'
>| R --vanilla
>|> 
>|> (or maybe https://cloud.r-project.org is better...)
>
>Thanks for the suggestion.  
>
>I simply did 
>R -- vanilla
>
>I tried it again this morning so that I could compare the output.
>However, it *worked* fine -- just as I thought it would done
>yesterday.  Why it didn't work yesterday is a mystery.
>
>I've had a few other things behaving strangely on this machine so
>there might be an OS issue, not an R issue.
>
>Thanks for taking the time.
>
>Patrick
>
>|> 
>|> -pd
>|> 
>|> 
>|> 
>|> > On 2 Feb 2018, at 08:15 , Jeff Newmiller
><jdnewmil at dcn.davis.CA.us> wrote:
>|> > 
>|> > Your last statement is extremely unlikely to be true. The dplyr
>package should not be present in a vanilla environment, so there should
>be no such conflict. 
>|> > -- 
>|> > Sent from my phone. Please excuse my brevity.
>|> > 
>|> > On February 1, 2018 11:00:01 PM PST, Patrick Connolly
><p_connolly at slingshot.co.nz> wrote:
>|> >> When i  tried to install the hunspell package, I got this error
>|> >> message:
>|> >> 
>|> >> Error: package ?Rcpp? 0.12.3 was found, but >= 0.12.12 is
>required by
>|> >> ?hunspell?
>|> >> 
>|> >> So I set about installing a new version of Rcpp but I get this
>message:
>|> >> 
>|> >> Error in unloadNamespace(pkg_name) : 
>|> >> namespace ?Rcpp? is imported by ?dplyr? so cannot be unloaded
>|> >> 
>|> >> How does one get around that?  I tried installing Rcpp in a
>vanilla
>|> >> session but the result was the same.
>|> >> 
>|> >> TIA
>|> >> Patrick
>|> >> 
>|> >> 
>|> >>> sessionInfo()
>|> >> R version 3.4.3 (2017-11-30)
>|> >> Platform: x86_64-pc-linux-gnu (64-bit)
>|> >> Running under: Ubuntu 14.04.5 LTS
>|> >> 
>|> >> Matrix products: default
>|> >> BLAS: /home/pat/local/R-3.4.3/lib/libRblas.so
>|> >> LAPACK: /home/pat/local/R-3.4.3/lib/libRlapack.so
>|> >> 
>|> >> locale:
>|> >> [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C              
>|> >> [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8    
>|> >> [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8   
>|> >> [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
>|> >> [9] LC_ADDRESS=C               LC_TELEPHONE=C            
>|> >> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
>|> >> 
>|> >> attached base packages:
>|> >> [1] utils     stats     grDevices graphics  methods   base     
>|> >> 
>|> >> other attached packages:
>|> >> [1] lattice_0.20-35
>|> >> 
>|> >> loaded via a namespace (and not attached):
>|> >> [1] compiler_3.4.3 magrittr_1.5   R6_2.1.2       assertthat_0.1
>|> >> parallel_3.4.3
>|> >> [6] tools_3.4.3    DBI_0.3.1      dplyr_0.4.3    Rcpp_0.12.3   
>|> >> grid_3.4.3    
>|> >> 
>|> >> 
>|> >> -- 
>|> >>
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>|> >> 
>|> >>  ___    Patrick Connolly   
>|> >> {~._.~}                   Great minds discuss ideas    
>|> >> _( Y )_  	         Average minds discuss events 
>|> >> (:_~*~_:)                  Small minds discuss people  
>|> >> (_)-(_)  	                      ..... Eleanor Roosevelt
>|> >> 	  
>|> >>
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>|> >> 
>|> >> ______________________________________________
>|> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>|> >> https://stat.ethz.ch/mailman/listinfo/r-help
>|> >> PLEASE do read the posting guide
>|> >> http://www.R-project.org/posting-guide.html
>|> >> and provide commented, minimal, self-contained, reproducible
>code.
>|> > 
>|> > ______________________________________________
>|> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>|> > https://stat.ethz.ch/mailman/listinfo/r-help
>|> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>|> > and provide commented, minimal, self-contained, reproducible code.
>|> 
>|> -- 
>|> Peter Dalgaard, Professor,
>|> Center for Statistics, Copenhagen Business School
>|> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>|> Phone: (+45)38153501
>|> Office: A 4.23
>|> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>|> 
>|> 
>|> 
>|> 
>|> 
>|> 
>|> 
>|> 
>|> 


From jknauer at bgc-jena.mpg.de  Fri Feb  2 15:51:02 2018
From: jknauer at bgc-jena.mpg.de (=?UTF-8?Q?J=c3=bcrgen_Knauer?=)
Date: Fri, 2 Feb 2018 15:51:02 +0100
Subject: [R] [R-pkgs] new R package bigleaf
Message-ID: <5A747AD6.2090703@bgc-jena.mpg.de>

Dear R users,

we are pleased to announce the release of the 'bigleaf' R package. This 
package is useful for the calculation of physical (e.g. aerodynamic 
conductance, surface temperature), and physiological (e.g. canopy 
conductance, intrinsic water-use efficiency) ecosystem properties from 
eddy covariance data. All calculations are based on a 'big-leaf' 
representation of the ecosystem.

The package is on CRAN. Further information can be found here: 
https://bitbucket.org/juergenknauer/bigleaf

Feedback is most welcome.
Best regards,

The bigleaf team
-- 
J?rgen Knauer
PhD Student

Max Planck Institute for Biogeochemistry
Department of Biogeochemical Integration

phone: +49 3641 576234
https://www.bgc-jena.mpg.de/bgi/index.php/People/JuergenKnauer

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From valkremk at gmail.com  Sat Feb  3 04:00:30 2018
From: valkremk at gmail.com (Val)
Date: Fri, 2 Feb 2018 21:00:30 -0600
Subject: [R] find unique and summerize
Message-ID: <CAJOiR6aq=VMHbmkE4s1yTPGy5WmmVbmm9EkU_Z1RY0E9LRJ6dg@mail.gmail.com>

Hi all,

I have a data set  need to be summarized by unique ID (count and sum of a
variable)
A unique individual ID (country name  Abbreviation  followed by an integer
numbers)  may  have observation in several countries. Then the  ID was
changed by adding the country code as a prefix  and  new ID was constructed
or recorded like (country code, + the original unique ID  Example
original ID   "CAN1540164" , if this ID has an observation in CANADA then
the ID was changed to    "1CAN1540164".   From this new ID I want get out
the country code  get the  original unique ID  and   summarize the data by
unique ID and country code

The data set look like
mydata <- read.table(textConnection("GR ID iflag Y
A 1CAN1540164 1 20
A 1CAN1540164 1 12
A 1CAN1540164 1 15
A 44CAN1540164 1 30
A 44CAN1540164 1 24
A 44CAN1540164 1 25
A 44CAN1540164 1 11
A 33CAN1540164 1 12
A 33CAN1540164 1 23
A 33CAN1540164 1 65
A 33CAN1540164 1 41
A 358CAN1540164 1 28
A 358CAN1540164 1 32
A 358CAN1540164 1 41
A 358CAN1540164 1 54
A 358CAN1540164 1 29
A 358CAN1540164 1 64
B 1USA1540165 1 125
B 1USA1540165 1 165
B 44USA1540165 1 171
B 33USA1540165 1 254
B 33USA1540165 1 241
B 33USA1540165 1 262
B 358USA1540165 1 321
C 358FIN1540166 1 225 "),header = TRUE ,stringsAsFactors = FALSE)

>From the above data there are three unique IDs and  four country codes (1,
44, 33 and 358)

I want the following two tables

Table 1. count  the  unique ID by country code
                          1   44   33   358     TOT
CAN1540164     3    4     4      6        17
USA1540165      2   1      3     1          7
FIN1540166       -     -       -      1         1
           TOT         5    5      7      8       25


Table 2  Sum of Y variable by unique ID and country. code

                          1       44       33      358      TOT
CAN1540164    47     90      141      248       526
USA1540165   290   171      757      321     1539
FIN1540166        -        -         -         225       225
            TOT      337     261      898    794     2290


How do I do it in R?

 The first step is to get the unique country codes unique ID by splitting
the new ID

Thank you in advance

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Feb  3 06:26:16 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 3 Feb 2018 05:26:16 +0000
Subject: [R] find unique and summerize
In-Reply-To: <CAJOiR6aq=VMHbmkE4s1yTPGy5WmmVbmm9EkU_Z1RY0E9LRJ6dg@mail.gmail.com>
References: <CAJOiR6aq=VMHbmkE4s1yTPGy5WmmVbmm9EkU_Z1RY0E9LRJ6dg@mail.gmail.com>
Message-ID: <a1805561-d8f2-c8ee-ba47-f5322089907d@sapo.pt>

Hello,

Thanks for the reproducible example.
See if the following does what you want.

IDNum <- sub("^(\\d+).*", "\\1", mydata$ID)
Country <- sub("^\\d+(.*)", "\\1", mydata$ID)

tbl1 <- table(Country, IDNum)
addmargins(tbl1)

tbl2 <- xtabs(Y ~ Country + IDNum, mydata)
addmargins(tbl2)


Hope this helps,

Rui Barradas

On 2/3/2018 3:00 AM, Val wrote:
> Hi all,
> 
> I have a data set  need to be summarized by unique ID (count and sum of a
> variable)
> A unique individual ID (country name  Abbreviation  followed by an integer
> numbers)  may  have observation in several countries. Then the  ID was
> changed by adding the country code as a prefix  and  new ID was constructed
> or recorded like (country code, + the original unique ID  Example
> original ID   "CAN1540164" , if this ID has an observation in CANADA then
> the ID was changed to    "1CAN1540164".   From this new ID I want get out
> the country code  get the  original unique ID  and   summarize the data by
> unique ID and country code
> 
> The data set look like
> mydata <- read.table(textConnection("GR ID iflag Y
> A 1CAN1540164 1 20
> A 1CAN1540164 1 12
> A 1CAN1540164 1 15
> A 44CAN1540164 1 30
> A 44CAN1540164 1 24
> A 44CAN1540164 1 25
> A 44CAN1540164 1 11
> A 33CAN1540164 1 12
> A 33CAN1540164 1 23
> A 33CAN1540164 1 65
> A 33CAN1540164 1 41
> A 358CAN1540164 1 28
> A 358CAN1540164 1 32
> A 358CAN1540164 1 41
> A 358CAN1540164 1 54
> A 358CAN1540164 1 29
> A 358CAN1540164 1 64
> B 1USA1540165 1 125
> B 1USA1540165 1 165
> B 44USA1540165 1 171
> B 33USA1540165 1 254
> B 33USA1540165 1 241
> B 33USA1540165 1 262
> B 358USA1540165 1 321
> C 358FIN1540166 1 225 "),header = TRUE ,stringsAsFactors = FALSE)
> 
>  From the above data there are three unique IDs and  four country codes (1,
> 44, 33 and 358)
> 
> I want the following two tables
> 
> Table 1. count  the  unique ID by country code
>                            1   44   33   358     TOT
> CAN1540164     3    4     4      6        17
> USA1540165      2   1      3     1          7
> FIN1540166       -     -       -      1         1
>             TOT         5    5      7      8       25
> 
> 
> Table 2  Sum of Y variable by unique ID and country. code
> 
>                            1       44       33      358      TOT
> CAN1540164    47     90      141      248       526
> USA1540165   290   171      757      321     1539
> FIN1540166        -        -         -         225       225
>              TOT      337     261      898    794     2290
> 
> 
> How do I do it in R?
> 
>   The first step is to get the unique country codes unique ID by splitting
> the new ID
> 
> Thank you in advance
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From valkremk at gmail.com  Sat Feb  3 17:42:50 2018
From: valkremk at gmail.com (Val)
Date: Sat, 3 Feb 2018 10:42:50 -0600
Subject: [R] find unique and summerize
In-Reply-To: <a1805561-d8f2-c8ee-ba47-f5322089907d@sapo.pt>
References: <CAJOiR6aq=VMHbmkE4s1yTPGy5WmmVbmm9EkU_Z1RY0E9LRJ6dg@mail.gmail.com>
 <a1805561-d8f2-c8ee-ba47-f5322089907d@sapo.pt>
Message-ID: <CAJOiR6azieiAcB-Q77NioTDhWk9-OA3pPMFF_tp3i=nTMiVeKA@mail.gmail.com>

Thank you so much Rui.

1. How do I export this table to excel file?
I used this
      tbl1 <- table(Country, IDNum)
      tbl2=addmargins(tbl1)
      write.xlsx(tbl2,"tt1.xlsx"),sheetName="summary", row.names=FALSE)
The above did not give me that table.


2. I want select those unique Ids that do have records in all countries.
 From the above data set, this ID  "FIN1540166"  should be excluded from
the summary table and the table looks like as follow

                IDNum
Country         1   33  358   44  Sum
  CAN1540164   47  141  248   90  526
  USA1540165  290  757  321  171 1539
  Sum         337  898  569  261 2065

Thank you again


On Fri, Feb 2, 2018 at 11:26 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Thanks for the reproducible example.
> See if the following does what you want.
>
> IDNum <- sub("^(\\d+).*", "\\1", mydata$ID)
> Country <- sub("^\\d+(.*)", "\\1", mydata$ID)
>
> tbl1 <- table(Country, IDNum)
> addmargins(tbl1)
>
> tbl2 <- xtabs(Y ~ Country + IDNum, mydata)
> addmargins(tbl2)
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> On 2/3/2018 3:00 AM, Val wrote:
>
>> Hi all,
>>
>> I have a data set  need to be summarized by unique ID (count and sum of a
>> variable)
>> A unique individual ID (country name  Abbreviation  followed by an integer
>> numbers)  may  have observation in several countries. Then the  ID was
>> changed by adding the country code as a prefix  and  new ID was
>> constructed
>> or recorded like (country code, + the original unique ID  Example
>> original ID   "CAN1540164" , if this ID has an observation in CANADA then
>> the ID was changed to    "1CAN1540164".   From this new ID I want get out
>> the country code  get the  original unique ID  and   summarize the data by
>> unique ID and country code
>>
>> The data set look like
>> mydata <- read.table(textConnection("GR ID iflag Y
>> A 1CAN1540164 1 20
>> A 1CAN1540164 1 12
>> A 1CAN1540164 1 15
>> A 44CAN1540164 1 30
>> A 44CAN1540164 1 24
>> A 44CAN1540164 1 25
>> A 44CAN1540164 1 11
>> A 33CAN1540164 1 12
>> A 33CAN1540164 1 23
>> A 33CAN1540164 1 65
>> A 33CAN1540164 1 41
>> A 358CAN1540164 1 28
>> A 358CAN1540164 1 32
>> A 358CAN1540164 1 41
>> A 358CAN1540164 1 54
>> A 358CAN1540164 1 29
>> A 358CAN1540164 1 64
>> B 1USA1540165 1 125
>> B 1USA1540165 1 165
>> B 44USA1540165 1 171
>> B 33USA1540165 1 254
>> B 33USA1540165 1 241
>> B 33USA1540165 1 262
>> B 358USA1540165 1 321
>> C 358FIN1540166 1 225 "),header = TRUE ,stringsAsFactors = FALSE)
>>
>>  From the above data there are three unique IDs and  four country codes
>> (1,
>> 44, 33 and 358)
>>
>> I want the following two tables
>>
>> Table 1. count  the  unique ID by country code
>>                            1   44   33   358     TOT
>> CAN1540164     3    4     4      6        17
>> USA1540165      2   1      3     1          7
>> FIN1540166       -     -       -      1         1
>>             TOT         5    5      7      8       25
>>
>>
>> Table 2  Sum of Y variable by unique ID and country. code
>>
>>                            1       44       33      358      TOT
>> CAN1540164    47     90      141      248       526
>> USA1540165   290   171      757      321     1539
>> FIN1540166        -        -         -         225       225
>>              TOT      337     261      898    794     2290
>>
>>
>> How do I do it in R?
>>
>>   The first step is to get the unique country codes unique ID by splitting
>> the new ID
>>
>> Thank you in advance
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From haenlein at escpeurope.eu  Sat Feb  3 18:51:48 2018
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Sat, 3 Feb 2018 18:51:48 +0100
Subject: [R] Speeding up npreg
Message-ID: <CAOyz9G4FMbFZ9WLmfbcO9aOLm8eG4yDykntOf+RWjaCtRsEtAw@mail.gmail.com>

Dear all,

I am using npreg from the np library to run a Kernel regression. My dataset
is relatively large and has about 3000 observations. The dependent variable
is continuous and I have a total of six independent variables -- two
continuous, two ordinal and two categorical.

The model converges without problems but it takes a very long time to do so
(nearly one hour).

Is there any way to speed up the npreg function to decrease the running
time? Or is there another function/ package for Kernel regression that may
be faster?

Any advice would be much appreciated

Thanks,

Michael

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Feb  3 20:05:43 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 3 Feb 2018 19:05:43 +0000
Subject: [R] find unique and summerize
In-Reply-To: <CAJOiR6azieiAcB-Q77NioTDhWk9-OA3pPMFF_tp3i=nTMiVeKA@mail.gmail.com>
References: <CAJOiR6aq=VMHbmkE4s1yTPGy5WmmVbmm9EkU_Z1RY0E9LRJ6dg@mail.gmail.com>
 <a1805561-d8f2-c8ee-ba47-f5322089907d@sapo.pt>
 <CAJOiR6azieiAcB-Q77NioTDhWk9-OA3pPMFF_tp3i=nTMiVeKA@mail.gmail.com>
Message-ID: <1ccce76d-49be-cd36-7707-2fbe2a230c66@sapo.pt>

Hello,

As for the first question, instead of writing a xlsx file, maybe it is 
easier to write a csv file and then open it with Excel.

tbl2 <- addmargins(tbl1)
write.csv(tbl2, "tt1.csv")

As for the second question, the following does it.

inx <- apply(tbl1, 1, function(x) all(x != 0))
tbl1b <- addmargins(tbl1[inx, ])
tbl1b


Hope this helps,

Rui Barradas

On 2/3/2018 4:42 PM, Val wrote:
> Thank you so much Rui.
> 
> 1. How do I export this table to excel file?
> I used this
>  ????? tbl1 <- table(Country, IDNum)
>  ????? tbl2=addmargins(tbl1)
>  ????? write.xlsx(tbl2,"tt1.xlsx"),sheetName="summary", row.names=FALSE)
> The above did not give me that table.
> 
> 
> 2. I want select those unique Ids that do have records in all countries.
>  ?From the above data set, this ID? "FIN1540166"? should be excluded 
> from the summary table and the table looks like as follow
> 
> IDNum Country 1 33 358 44 Sum CAN1540164 47 141 248 90 526 USA1540165 
> 290 757 321 171 1539 Sum 337 898 569 261 2065
> 
> Thank you again
> 
> 
> On Fri, Feb 2, 2018 at 11:26 PM, Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     Thanks for the reproducible example.
>     See if the following does what you want.
> 
>     IDNum <- sub("^(\\d+).*", "\\1", mydata$ID)
>     Country <- sub("^\\d+(.*)", "\\1", mydata$ID)
> 
>     tbl1 <- table(Country, IDNum)
>     addmargins(tbl1)
> 
>     tbl2 <- xtabs(Y ~ Country + IDNum, mydata)
>     addmargins(tbl2)
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     On 2/3/2018 3:00 AM, Val wrote:
> 
>         Hi all,
> 
>         I have a data set? need to be summarized by unique ID (count and
>         sum of a
>         variable)
>         A unique individual ID (country name? Abbreviation? followed by
>         an integer
>         numbers)? may? have observation in several countries. Then the 
>         ID was
>         changed by adding the country code as a prefix? and? new ID was
>         constructed
>         or recorded like (country code, + the original unique ID? Example
>         original ID? ?"CAN1540164" , if this ID has an observation in
>         CANADA then
>         the ID was changed to? ? "1CAN1540164".? ?From this new ID I
>         want get out
>         the country code? get the? original unique ID? and? ?summarize
>         the data by
>         unique ID and country code
> 
>         The data set look like
>         mydata <- read.table(textConnection("GR ID iflag Y
>         A 1CAN1540164 1 20
>         A 1CAN1540164 1 12
>         A 1CAN1540164 1 15
>         A 44CAN1540164 1 30
>         A 44CAN1540164 1 24
>         A 44CAN1540164 1 25
>         A 44CAN1540164 1 11
>         A 33CAN1540164 1 12
>         A 33CAN1540164 1 23
>         A 33CAN1540164 1 65
>         A 33CAN1540164 1 41
>         A 358CAN1540164 1 28
>         A 358CAN1540164 1 32
>         A 358CAN1540164 1 41
>         A 358CAN1540164 1 54
>         A 358CAN1540164 1 29
>         A 358CAN1540164 1 64
>         B 1USA1540165 1 125
>         B 1USA1540165 1 165
>         B 44USA1540165 1 171
>         B 33USA1540165 1 254
>         B 33USA1540165 1 241
>         B 33USA1540165 1 262
>         B 358USA1540165 1 321
>         C 358FIN1540166 1 225 "),header = TRUE ,stringsAsFactors = FALSE)
> 
>          ?From the above data there are three unique IDs and? four
>         country codes (1,
>         44, 33 and 358)
> 
>         I want the following two tables
> 
>         Table 1. count? the? unique ID by country code
>          ? ? ? ? ? ? ? ? ? ? ? ? ? ?1? ?44? ?33? ?358? ? ?TOT
>         CAN1540164? ? ?3? ? 4? ? ?4? ? ? 6? ? ? ? 17
>         USA1540165? ? ? 2? ?1? ? ? 3? ? ?1? ? ? ? ? 7
>         FIN1540166? ? ? ?-? ? ?-? ? ? ?-? ? ? 1? ? ? ? ?1
>          ? ? ? ? ? ? TOT? ? ? ? ?5? ? 5? ? ? 7? ? ? 8? ? ? ?25
> 
> 
>         Table 2? Sum of Y variable by unique ID and country. code
> 
>          ? ? ? ? ? ? ? ? ? ? ? ? ? ?1? ? ? ?44? ? ? ?33? ? ? 358? ? ? TOT
>         CAN1540164? ? 47? ? ?90? ? ? 141? ? ? 248? ? ? ?526
>         USA1540165? ?290? ?171? ? ? 757? ? ? 321? ? ?1539
>         FIN1540166? ? ? ? -? ? ? ? -? ? ? ? ?-? ? ? ? ?225? ? ? ?225
>          ? ? ? ? ? ? ?TOT? ? ? 337? ? ?261? ? ? 898? ? 794? ? ?2290
> 
> 
>         How do I do it in R?
> 
>          ? The first step is to get the unique country codes unique ID
>         by splitting
>         the new ID
> 
>         Thank you in advance
> 
>          ? ? ? ? [[alternative HTML version deleted]]
> 
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
> 
>


From batholdy at googlemail.com  Sun Feb  4 01:23:54 2018
From: batholdy at googlemail.com (Martin Batholdy)
Date: Sun, 4 Feb 2018 01:23:54 +0100
Subject: [R] copy/paste of large amount of code to terminal leads to
 scrambled/missing characters
Message-ID: <21AAE5EB-46D2-4843-96EE-90B181942D28@googlemail.com>

Dear R-users,

This question might not be restricted to R, but I hope that some might have experienced similar problems and could help me.

When using R, I usually work with a text-editor (textmate2) in which I prepare the script.
To execute code, I then copy and paste it to an R-session running in the terminal/shell (on Mac OS).

Unfortunately, when pasting too much code into the terminal (e.g. 60 lines), some characters are occasionally and randomly scrambled or missing.
For example "col <- ifelse(..." turns into "col < col < cse(?".

This happens very randomly, is difficult to predict, and while it only affects a hand full of characters in total, it leads to a lot of errors in the code execution along the way.
Apparently, it has to do with the buffer size and paste-speed of the terminal.

So far, I could not find any solution to the problem.

Therefore, I wanted to ask; 
Do others here use a similar workflow (i.e. having a text-editor for coding and using copy/paste to the terminal for code execution) and encountered similar problems with big chunks of code in the clipboard?
Are there any solutions for this problem, specifically for running R over the shell?

Thank you very much!


From jdnewmil at dcn.davis.ca.us  Sun Feb  4 01:51:37 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 03 Feb 2018 16:51:37 -0800
Subject: [R] copy/paste of large amount of code to terminal leads to
	scrambled/missing characters
In-Reply-To: <21AAE5EB-46D2-4843-96EE-90B181942D28@googlemail.com>
References: <21AAE5EB-46D2-4843-96EE-90B181942D28@googlemail.com>
Message-ID: <3F03D21C-D0A9-4019-9817-2D9340C49DD4@dcn.davis.ca.us>

This sounds like a problem with your editor or the OS clipboard support rather than R. You might get a response here, but R-sig-mac seems more appropriate to me for such discussion.
-- 
Sent from my phone. Please excuse my brevity.

On February 3, 2018 4:23:54 PM PST, Martin Batholdy via R-help <r-help at r-project.org> wrote:
>Dear R-users,
>
>This question might not be restricted to R, but I hope that some might
>have experienced similar problems and could help me.
>
>When using R, I usually work with a text-editor (textmate2) in which I
>prepare the script.
>To execute code, I then copy and paste it to an R-session running in
>the terminal/shell (on Mac OS).
>
>Unfortunately, when pasting too much code into the terminal (e.g. 60
>lines), some characters are occasionally and randomly scrambled or
>missing.
>For example "col <- ifelse(..." turns into "col < col < cse(?".
>
>This happens very randomly, is difficult to predict, and while it only
>affects a hand full of characters in total, it leads to a lot of errors
>in the code execution along the way.
>Apparently, it has to do with the buffer size and paste-speed of the
>terminal.
>
>So far, I could not find any solution to the problem.
>
>Therefore, I wanted to ask; 
>Do others here use a similar workflow (i.e. having a text-editor for
>coding and using copy/paste to the terminal for code execution) and
>encountered similar problems with big chunks of code in the clipboard?
>Are there any solutions for this problem, specifically for running R
>over the shell?
>
>Thank you very much!
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Feb  4 05:33:30 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 3 Feb 2018 20:33:30 -0800
Subject: [R] copy/paste of large amount of code to terminal leads to
 scrambled/missing characters
In-Reply-To: <3F03D21C-D0A9-4019-9817-2D9340C49DD4@dcn.davis.ca.us>
References: <21AAE5EB-46D2-4843-96EE-90B181942D28@googlemail.com>
 <3F03D21C-D0A9-4019-9817-2D9340C49DD4@dcn.davis.ca.us>
Message-ID: <CAGxFJbTP06pOM3w_smL6cVwD-Y_73mOR=DSo+kMz12JxatXj-g@mail.gmail.com>

Obvious suggestion: use a more capable IDE instead of Textmate2 with
copy/paste.

RStudio is very popular now, but there are many others . Search on e.g. "R
IDE For MAC" to see some alternatives.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Feb 3, 2018 at 4:51 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> This sounds like a problem with your editor or the OS clipboard support
> rather than R. You might get a response here, but R-sig-mac seems more
> appropriate to me for such discussion.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 3, 2018 4:23:54 PM PST, Martin Batholdy via R-help <
> r-help at r-project.org> wrote:
> >Dear R-users,
> >
> >This question might not be restricted to R, but I hope that some might
> >have experienced similar problems and could help me.
> >
> >When using R, I usually work with a text-editor (textmate2) in which I
> >prepare the script.
> >To execute code, I then copy and paste it to an R-session running in
> >the terminal/shell (on Mac OS).
> >
> >Unfortunately, when pasting too much code into the terminal (e.g. 60
> >lines), some characters are occasionally and randomly scrambled or
> >missing.
> >For example "col <- ifelse(..." turns into "col < col < cse(?".
> >
> >This happens very randomly, is difficult to predict, and while it only
> >affects a hand full of characters in total, it leads to a lot of errors
> >in the code execution along the way.
> >Apparently, it has to do with the buffer size and paste-speed of the
> >terminal.
> >
> >So far, I could not find any solution to the problem.
> >
> >Therefore, I wanted to ask;
> >Do others here use a similar workflow (i.e. having a text-editor for
> >coding and using copy/paste to the terminal for code execution) and
> >encountered similar problems with big chunks of code in the clipboard?
> >Are there any solutions for this problem, specifically for running R
> >over the shell?
> >
> >Thank you very much!
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Sun Feb  4 07:28:17 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 4 Feb 2018 08:28:17 +0200
Subject: [R] copy/paste of large amount of code to terminal leads to
 scrambled/missing characters
In-Reply-To: <CAGxFJbTP06pOM3w_smL6cVwD-Y_73mOR=DSo+kMz12JxatXj-g@mail.gmail.com>
References: <21AAE5EB-46D2-4843-96EE-90B181942D28@googlemail.com>
 <3F03D21C-D0A9-4019-9817-2D9340C49DD4@dcn.davis.ca.us>
 <CAGxFJbTP06pOM3w_smL6cVwD-Y_73mOR=DSo+kMz12JxatXj-g@mail.gmail.com>
Message-ID: <CAGgJW77SA2zd=JP1yTrmnUZJOmWDr9i2vrao4EH_A4N6bRkohQ@mail.gmail.com>

Hi Martin,
Why not just do the following?
In your editor after you create the script save it to a file, say "foo.R".
Then in your R session you give the command
> source("foo.R")

HTH,
Eric


On Sun, Feb 4, 2018 at 6:33 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Obvious suggestion: use a more capable IDE instead of Textmate2 with
> copy/paste.
>
> RStudio is very popular now, but there are many others . Search on e.g. "R
> IDE For MAC" to see some alternatives.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sat, Feb 3, 2018 at 4:51 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > This sounds like a problem with your editor or the OS clipboard support
> > rather than R. You might get a response here, but R-sig-mac seems more
> > appropriate to me for such discussion.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On February 3, 2018 4:23:54 PM PST, Martin Batholdy via R-help <
> > r-help at r-project.org> wrote:
> > >Dear R-users,
> > >
> > >This question might not be restricted to R, but I hope that some might
> > >have experienced similar problems and could help me.
> > >
> > >When using R, I usually work with a text-editor (textmate2) in which I
> > >prepare the script.
> > >To execute code, I then copy and paste it to an R-session running in
> > >the terminal/shell (on Mac OS).
> > >
> > >Unfortunately, when pasting too much code into the terminal (e.g. 60
> > >lines), some characters are occasionally and randomly scrambled or
> > >missing.
> > >For example "col <- ifelse(..." turns into "col < col < cse(?".
> > >
> > >This happens very randomly, is difficult to predict, and while it only
> > >affects a hand full of characters in total, it leads to a lot of errors
> > >in the code execution along the way.
> > >Apparently, it has to do with the buffer size and paste-speed of the
> > >terminal.
> > >
> > >So far, I could not find any solution to the problem.
> > >
> > >Therefore, I wanted to ask;
> > >Do others here use a similar workflow (i.e. having a text-editor for
> > >coding and using copy/paste to the terminal for code execution) and
> > >encountered similar problems with big chunks of code in the clipboard?
> > >Are there any solutions for this problem, specifically for running R
> > >over the shell?
> > >
> > >Thank you very much!
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sun Feb  4 10:53:44 2018
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 4 Feb 2018 10:53:44 +0100
Subject: [R] copy/paste of large amount of code to terminal leads to
 scrambled/missing characters
In-Reply-To: <21AAE5EB-46D2-4843-96EE-90B181942D28@googlemail.com>
References: <21AAE5EB-46D2-4843-96EE-90B181942D28@googlemail.com>
Message-ID: <6C6322E8-5D1B-455D-A2E2-600882D96411@xs4all.nl>


Why not use the R bundle for TextMate and run your script directly in TextMate? You'll get nice output.

And if you want to run R directly and get the output in a .Rout file you can add a command to the R bundle, create a small script that runs R in batch.
Create a new command in the R bundle, give it an appropriate name  and then put this in the body of the command:

#!/bin/bash
[[ -f "${TM_SUPPORT_PATH}/lib/bash_init.sh" ]] && . "${TM_SUPPORT_PATH}/lib/bash_init.sh"

if [[ ${#TM_DIRECTORY} -gt 0 ]]; then
	cd "${TM_DIRECTORY}"
else
    exit_show_tool_tip "Save file first!"    
fi

R CMD BATCH --encoding=UTF-8 --no-save --no-timing ${TM_FILENAME}
mate ${TM_FILENAME}out

Berend Hasselman

> On 4 Feb 2018, at 01:23, Martin Batholdy via R-help <r-help at r-project.org> wrote:
> 
> Dear R-users,
> 
> This question might not be restricted to R, but I hope that some might have experienced similar problems and could help me.
> 
> When using R, I usually work with a text-editor (textmate2) in which I prepare the script.
> To execute code, I then copy and paste it to an R-session running in the terminal/shell (on Mac OS).
> 
> Unfortunately, when pasting too much code into the terminal (e.g. 60 lines), some characters are occasionally and randomly scrambled or missing.
> For example "col <- ifelse(..." turns into "col < col < cse(?".
> 
> This happens very randomly, is difficult to predict, and while it only affects a hand full of characters in total, it leads to a lot of errors in the code execution along the way.
> Apparently, it has to do with the buffer size and paste-speed of the terminal.
> 
> So far, I could not find any solution to the problem.
> 
> Therefore, I wanted to ask; 
> Do others here use a similar workflow (i.e. having a text-editor for coding and using copy/paste to the terminal for code execution) and encountered similar problems with big chunks of code in the clipboard?
> Are there any solutions for this problem, specifically for running R over the shell?
> 
> Thank you very much!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From acefix at rocketmail.com  Sun Feb  4 22:56:57 2018
From: acefix at rocketmail.com (Fix Ace)
Date: Sun, 4 Feb 2018 21:56:57 +0000 (UTC)
Subject: [R] help with the plot overlay
References: <2116633968.3300050.1517781417332.ref@mail.yahoo.com>
Message-ID: <2116633968.3300050.1517781417332@mail.yahoo.com>

Dear R Community,
I recently read an article and found a plot as attached. It has scatterplot, barplot, and error bar. Could anyone help me to figure out what package I can use in R to generate such plot?
Thank you very much for any inputs!
Kind regards,
Ace
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2018-02-04 at 6.38.14  AM.png
Type: image/png
Size: 36795 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180204/277012d7/attachment.png>

From michael77allen at gmail.com  Sun Feb  4 23:45:07 2018
From: michael77allen at gmail.com (Michael)
Date: Sun, 4 Feb 2018 22:45:07 +0000
Subject: [R] Unexpected behaviour from read.table
Message-ID: <795BD212-E290-4A24-AC4A-45F0D14B820E@gmail.com>

I?ve been struggling with seemingly ?corrupt? data.frames for a few days, and believe I?ve narrowed the problem down to some odd behaviour from read.table

I receive a tab delimited file from an external provider where strings are encoded as =?content?. Not sure why, perhaps as most users open it in Excel. 
My specific issue is that trailing spaces in any of the strings are causing strange results from read.table

# No trailing spaces
read.table(text="ID\tValue\n=\"Total\"\t1000\n=\"CJ01\"\t550\n=\"CF02\"\t450",header=FALSE,sep='\t?)
      V1    V2
1     ID Value
2 =Total  1000
3  =CJ01   550
4  =CF02   450

# Now with trailing spaces in line 3
read.table(text="ID\tValue\n=\"Total\"\t1000\n=\"CJ01   \"\t550\n=\"CF02\"\t450",header=FALSE,sep='\t')
        V1    V2
1    =CF02   450
2       ID Value
3   =Total  1000
4 =CJ01      550
5    =CF02   450

I solved my specific problem by setting quote=??, and extracting the string content after calling read.table. As my original code had header=TRUE, I was finding random rows were being used as column names! 

Flagging a potential issue with read.table, although I can easily accept I'm missing something obvious here. 

Best,
 Michael

R version 3.4.3 (2017-11-30)
Platform: x86_64-apple-darwin15.6.0 (64-bit)  / x86_64-pc-linux-gnu (64-bit)
Running under: macOS High Sierra 10.13.2 /  Ubuntu 16.04.3 LTS







	[[alternative HTML version deleted]]


From valkremk at gmail.com  Mon Feb  5 02:20:49 2018
From: valkremk at gmail.com (Val)
Date: Sun, 4 Feb 2018 19:20:49 -0600
Subject: [R] find unique and summerize
In-Reply-To: <2d429874-1883-d23e-34e9-c1be00bbdfa9@sapo.pt>
References: <CAJOiR6aq=VMHbmkE4s1yTPGy5WmmVbmm9EkU_Z1RY0E9LRJ6dg@mail.gmail.com>
 <a1805561-d8f2-c8ee-ba47-f5322089907d@sapo.pt>
 <CAJOiR6azieiAcB-Q77NioTDhWk9-OA3pPMFF_tp3i=nTMiVeKA@mail.gmail.com>
 <1ccce76d-49be-cd36-7707-2fbe2a230c66@sapo.pt>
 <CAJOiR6adMO4L+ApSjWiOiN57w8Yn1G4+opevq7fL0fDrFaqE9Q@mail.gmail.com>
 <2d429874-1883-d23e-34e9-c1be00bbdfa9@sapo.pt>
Message-ID: <CAJOiR6ZD=H+ptT8nDfDXCqwEXEagntseDzNWB2fV43pTM5kx-w@mail.gmail.com>

Thank you so much Rui!

On Sun, Feb 4, 2018 at 12:20 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Please always cc the list.
>
> As for the question, I believe the following does it.
>
> a <- strsplit(mydata$ID, "[[:alpha:]]+")
> b <- strsplit(mydata$ID, "[[:digit:]]+")
>
> a <- sapply(a, `[`, 1)
> c <- sapply(a, `[`, 2)
> b <- sapply(b, function(x) x[x != ""])
>
> c2 <- sprintf("%010d", as.integer(c))
>
> newID <- paste0(a, b, c2)
>
>
> Hope this helps,
>
> Rui Barradas
>
> On 2/4/2018 2:01 AM, Val wrote:
>
>> Thank you so much again for your help!
>>
>> I have one more question related to this.
>>
>> 1. How do I further split  this "358USA1540165 " into three parts.
>> a) 358
>> b) USA
>> c) 1540165
>>
>> I want to add leading zeros to the third part  like "0001540165"
>> and then combine   b and c  to get this USA1540165
>> so USA1540165  changed to USA1540165
>>
>> The other one is that the data set has several country codes and if I
>> want to limit my data set to only certain country codes , how do I do that.
>>
>> Thank you again
>>
>>
>>
>>
>> On Sat, Feb 3, 2018 at 1:05 PM, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>
>>     Hello,
>>
>>     As for the first question, instead of writing a xlsx file, maybe it
>>     is easier to write a csv file and then open it with Excel.
>>
>>     tbl2 <- addmargins(tbl1)
>>     write.csv(tbl2, "tt1.csv")
>>
>>     As for the second question, the following does it.
>>
>>     inx <- apply(tbl1, 1, function(x) all(x != 0))
>>     tbl1b <- addmargins(tbl1[inx, ])
>>     tbl1b
>>
>>
>>     Hope this helps,
>>
>>     Rui Barradas
>>
>>     On 2/3/2018 4:42 PM, Val wrote:
>>
>>         Thank you so much Rui.
>>
>>         1. How do I export this table to excel file?
>>         I used this
>>                 tbl1 <- table(Country, IDNum)
>>                 tbl2=addmargins(tbl1)
>>                 write.xlsx(tbl2,"tt1.xlsx"),sheetName="summary",
>>         row.names=FALSE)
>>         The above did not give me that table.
>>
>>
>>         2. I want select those unique Ids that do have records in all
>>         countries.
>>            From the above data set, this ID  "FIN1540166"  should be
>>         excluded from the summary table and the table looks like as follow
>>
>>         IDNum Country 1 33 358 44 Sum CAN1540164 47 141 248 90 526
>>         USA1540165 290 757 321 171 1539 Sum 337 898 569 261 2065
>>
>>         Thank you again
>>
>>
>>         On Fri, Feb 2, 2018 at 11:26 PM, Rui Barradas
>>         <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>
>>         <mailto:ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>>
>> wrote:
>>
>>              Hello,
>>
>>              Thanks for the reproducible example.
>>              See if the following does what you want.
>>
>>              IDNum <- sub("^(\\d+).*", "\\1", mydata$ID)
>>              Country <- sub("^\\d+(.*)", "\\1", mydata$ID)
>>
>>              tbl1 <- table(Country, IDNum)
>>              addmargins(tbl1)
>>
>>              tbl2 <- xtabs(Y ~ Country + IDNum, mydata)
>>              addmargins(tbl2)
>>
>>
>>              Hope this helps,
>>
>>              Rui Barradas
>>
>>
>>              On 2/3/2018 3:00 AM, Val wrote:
>>
>>                  Hi all,
>>
>>                  I have a data set  need to be summarized by unique ID
>>         (count and
>>                  sum of a
>>                  variable)
>>                  A unique individual ID (country name  Abbreviation
>>    followed by
>>                  an integer
>>                  numbers)  may  have observation in several countries.
>>         Then the         ID was
>>                  changed by adding the country code as a prefix  and
>>    new ID was
>>                  constructed
>>                  or recorded like (country code, + the original unique
>>         ID  Example
>>                  original ID   "CAN1540164" , if this ID has an
>>         observation in
>>                  CANADA then
>>                  the ID was changed to    "1CAN1540164".   From this new
>>         ID I
>>                  want get out
>>                  the country code  get the  original unique ID  and
>>      summarize
>>                  the data by
>>                  unique ID and country code
>>
>>                  The data set look like
>>                  mydata <- read.table(textConnection("GR ID iflag Y
>>                  A 1CAN1540164 1 20
>>                  A 1CAN1540164 1 12
>>                  A 1CAN1540164 1 15
>>                  A 44CAN1540164 1 30
>>                  A 44CAN1540164 1 24
>>                  A 44CAN1540164 1 25
>>                  A 44CAN1540164 1 11
>>                  A 33CAN1540164 1 12
>>                  A 33CAN1540164 1 23
>>                  A 33CAN1540164 1 65
>>                  A 33CAN1540164 1 41
>>                  A 358CAN1540164 1 28
>>                  A 358CAN1540164 1 32
>>                  A 358CAN1540164 1 41
>>                  A 358CAN1540164 1 54
>>                  A 358CAN1540164 1 29
>>                  A 358CAN1540164 1 64
>>                  B 1USA1540165 1 125
>>                  B 1USA1540165 1 165
>>                  B 44USA1540165 1 171
>>                  B 33USA1540165 1 254
>>                  B 33USA1540165 1 241
>>                  B 33USA1540165 1 262
>>                  B 358USA1540165 1 321
>>                  C 358FIN1540166 1 225 "),header = TRUE
>>         ,stringsAsFactors = FALSE)
>>
>>                    From the above data there are three unique IDs and
>> four
>>                  country codes (1,
>>                  44, 33 and 358)
>>
>>                  I want the following two tables
>>
>>                  Table 1. count  the  unique ID by country code
>>                                              1   44   33   358     TOT
>>                  CAN1540164     3    4     4      6        17
>>                  USA1540165      2   1      3     1          7
>>                  FIN1540166       -     -       -      1         1
>>                               TOT         5    5      7      8       25
>>
>>
>>                  Table 2  Sum of Y variable by unique ID and country. code
>>
>>                                              1       44       33
>>    358      TOT
>>                  CAN1540164    47     90      141      248       526
>>                  USA1540165   290   171      757      321     1539
>>                  FIN1540166        -        -         -         225
>>          225
>>                                TOT      337     261      898    794
>>  2290
>>
>>
>>                  How do I do it in R?
>>
>>                     The first step is to get the unique country codes
>>         unique ID
>>                  by splitting
>>                  the new ID
>>
>>                  Thank you in advance
>>
>>                           [[alternative HTML version deleted]]
>>
>>                  ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org>
>>         <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>         mailing list
>>                  -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>                  <https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>                  PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>                  <http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>>
>>                  and provide commented, minimal, self-contained,
>>         reproducible code.
>>
>>
>>
>>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Feb  5 03:59:02 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 5 Feb 2018 13:59:02 +1100
Subject: [R] help with the plot overlay
In-Reply-To: <2116633968.3300050.1517781417332@mail.yahoo.com>
References: <2116633968.3300050.1517781417332.ref@mail.yahoo.com>
 <2116633968.3300050.1517781417332@mail.yahoo.com>
Message-ID: <CA+8X3fW-SLfti_+4K3UffE3ejkXmoeo7QM_eAc3yEtodRy7CPg@mail.gmail.com>

Hi Ace,
You can do it with plotrix:

library(plotrix)
barpos<-barp(c(1,5,38),width=0.5,col=c("white","lightgray","darkgray"),ylim=c(0,70))
ehplot(c(1,0.8,0.9,0.8,1.1,1,4,3,5,14,3,2,32,27,33,30,50,61),
 c(1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3),median=FALSE,add=TRUE,cex=2,
 pch=21,bg="white")
dispersion(barpos$x,barpos$y,c(0.1,1,5),lwd=2,arrow.cap=0.03)
lines(c(barpos$x[2],barpos$x[2],barpos$x[3],barpos$x[3]),c(18,63,63,62))
lines(c(barpos$x[1],barpos$x[1],barpos$x[3],barpos$x[3]),c(4,66,66,65))
text(2,68,"**",cex=2)
text(2.5,64.5,"**",cex=2)

Jim


On Mon, Feb 5, 2018 at 8:56 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> Dear R Community,
> I recently read an article and found a plot as attached. It has scatterplot, barplot, and error bar. Could anyone help me to figure out what package I can use in R to generate such plot?
> Thank you very much for any inputs!
> Kind regards,
> Ace
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Feb  5 10:57:06 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 5 Feb 2018 10:57:06 +0100
Subject: [R] Unexpected behaviour from read.table
In-Reply-To: <795BD212-E290-4A24-AC4A-45F0D14B820E@gmail.com>
References: <795BD212-E290-4A24-AC4A-45F0D14B820E@gmail.com>
Message-ID: <E137C1A8-E0FF-4D65-A50A-BCAC45CCA27E@gmail.com>

This looks like a bug. Specifically, inside read.table

    lines <- .External(C_readtablehead, file, nlines, comment.char, 
        blank.lines.skip, quote, sep, skipNul)

returns "lines" as

[1] "ID\tValue"                         "=\"Total\"\t1000"                 
[3] "=\"CJ01   \"\t550\n=\"CF02\"\t450"

Notice the embedded \n in the 3rd line. I.e., there are really 4 lines there. This gets pushed back twice and the first 3 (not 4) lines get read again as part of the header logic. Then when it comes to reading the data proper, the 4th line has ended up duplicated as the top row...

As you suggest, it seems that something is up with the quote matching logic.

-pd


> On 4 Feb 2018, at 23:45 , Michael <michael77allen at gmail.com> wrote:
> 
> I?ve been struggling with seemingly ?corrupt? data.frames for a few days, and believe I?ve narrowed the problem down to some odd behaviour from read.table
> 
> I receive a tab delimited file from an external provider where strings are encoded as =?content?. Not sure why, perhaps as most users open it in Excel. 
> My specific issue is that trailing spaces in any of the strings are causing strange results from read.table
> 
> # No trailing spaces
> read.table(text="ID\tValue\n=\"Total\"\t1000\n=\"CJ01\"\t550\n=\"CF02\"\t450",header=FALSE,sep='\t?)
>      V1    V2
> 1     ID Value
> 2 =Total  1000
> 3  =CJ01   550
> 4  =CF02   450
> 
> # Now with trailing spaces in line 3
> read.table(text="ID\tValue\n=\"Total\"\t1000\n=\"CJ01   \"\t550\n=\"CF02\"\t450",header=FALSE,sep='\t')
>        V1    V2
> 1    =CF02   450
> 2       ID Value
> 3   =Total  1000
> 4 =CJ01      550
> 5    =CF02   450
> 
> I solved my specific problem by setting quote=??, and extracting the string content after calling read.table. As my original code had header=TRUE, I was finding random rows were being used as column names! 
> 
> Flagging a potential issue with read.table, although I can easily accept I'm missing something obvious here. 
> 
> Best,
> Michael
> 
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)  / x86_64-pc-linux-gnu (64-bit)
> Running under: macOS High Sierra 10.13.2 /  Ubuntu 16.04.3 LTS
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ackrite55 at hotmail.com  Mon Feb  5 17:02:54 2018
From: ackrite55 at hotmail.com (Colonel Sanders)
Date: Mon, 5 Feb 2018 16:02:54 +0000
Subject: [R] Package sgd
Message-ID: <BY2PR14MB034417E78330F6F5C84BED4AACFE0@BY2PR14MB0344.namprd14.prod.outlook.com>

Good morning,

Is there a package that replaces the sgd package to explore the  Gradient Descent (SGD) t echnique ?


Best regards,

*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~

Tony

*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*

	[[alternative HTML version deleted]]


From jsc.eco at gmail.com  Mon Feb  5 18:04:23 2018
From: jsc.eco at gmail.com (Janet Choate)
Date: Mon, 5 Feb 2018 09:04:23 -0800
Subject: [R] pulling recessions out of a hydrograph
Message-ID: <CAEqw1VyO-3sh00NHQAcGpr99Sr2MD5hd2jc=c8OSc1_PhOH-8Q@mail.gmail.com>

Dear R community,

I'm hoping someone out there has perhaps done this and can share their code
and/or expertise with me.

I need to pull recession periods out of a hydrograph - can anyone help me
with this?
I want to create a subset from streamflow data that consists of just the
recession curves - the decreasing runoff after the passage of a peak flow.

would really appreciate any help on this!
Janet
-- 
Tague Team Lab Manager
1005 Bren Hall
UCSB, Santa Barbara, CA.

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Mon Feb  5 18:09:25 2018
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 5 Feb 2018 12:09:25 -0500
Subject: [R] pulling recessions out of a hydrograph
In-Reply-To: <CAEqw1VyO-3sh00NHQAcGpr99Sr2MD5hd2jc=c8OSc1_PhOH-8Q@mail.gmail.com>
References: <CAEqw1VyO-3sh00NHQAcGpr99Sr2MD5hd2jc=c8OSc1_PhOH-8Q@mail.gmail.com>
Message-ID: <CADKEMqgdEynBQAYhJyn7aOjb9xAqgr2ApcWJ2RzW+ukxNJqTkg@mail.gmail.com>

I have done this. I would use zoo for the time series part, and I think I
wrote a function using the min max after a period to locate the peak, go to
the peak, and calculate the slope 4 hours afterward. If I can locate the
code I don't mind sharing, but it is buried on my PhD machine.

On Feb 5, 2018 12:04 PM, "Janet Choate" <jsc.eco at gmail.com> wrote:

> Dear R community,
>
> I'm hoping someone out there has perhaps done this and can share their code
> and/or expertise with me.
>
> I need to pull recession periods out of a hydrograph - can anyone help me
> with this?
> I want to create a subset from streamflow data that consists of just the
> recession curves - the decreasing runoff after the passage of a peak flow.
>
> would really appreciate any help on this!
> Janet
> --
> Tague Team Lab Manager
> 1005 Bren Hall
> UCSB, Santa Barbara, CA.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb  5 19:23:29 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Feb 2018 10:23:29 -0800
Subject: [R] Package sgd
In-Reply-To: <BY2PR14MB034417E78330F6F5C84BED4AACFE0@BY2PR14MB0344.namprd14.prod.outlook.com>
References: <BY2PR14MB034417E78330F6F5C84BED4AACFE0@BY2PR14MB0344.namprd14.prod.outlook.com>
Message-ID: <CAGxFJbRyoTO7c=g-03Tz=dHNhNCZz+nPtNjE7920HkhLPUS6kQ@mail.gmail.com>

1. It might help if you could state more specifically what you want to do.

2. Maybe check here if you haven't already done so:

https://cran.r-project.org/web/views/

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Feb 5, 2018 at 8:02 AM, Colonel Sanders <ackrite55 at hotmail.com>
wrote:

> Good morning,
>
> Is there a package that replaces the sgd package to explore the  Gradient
> Descent (SGD) t echnique ?
>
>
> Best regards,
>
> *~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~
>
> Tony
>
> *~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb  5 19:25:51 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Feb 2018 10:25:51 -0800
Subject: [R] Package sgd
In-Reply-To: <CAGxFJbRyoTO7c=g-03Tz=dHNhNCZz+nPtNjE7920HkhLPUS6kQ@mail.gmail.com>
References: <BY2PR14MB034417E78330F6F5C84BED4AACFE0@BY2PR14MB0344.namprd14.prod.outlook.com>
 <CAGxFJbRyoTO7c=g-03Tz=dHNhNCZz+nPtNjE7920HkhLPUS6kQ@mail.gmail.com>
Message-ID: <CAGxFJbRDf4tXfWMarKn7fbjULxp7XF0FOevchewsDXAhdSD=tg@mail.gmail.com>

A web search on "gradient descent R" also brought up a bunch of stuff. Is
any of this what you want?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Feb 5, 2018 at 10:23 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1. It might help if you could state more specifically what you want to do.
>
> 2. Maybe check here if you haven't already done so:
>
> https://cran.r-project.org/web/views/
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Feb 5, 2018 at 8:02 AM, Colonel Sanders <ackrite55 at hotmail.com>
> wrote:
>
>> Good morning,
>>
>> Is there a package that replaces the sgd package to explore the  Gradient
>> Descent (SGD) t echnique ?
>>
>>
>> Best regards,
>>
>> *~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~
>>
>> Tony
>>
>> *~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From nicolas.degallier at free.fr  Mon Feb  5 19:40:08 2018
From: nicolas.degallier at free.fr (Nicolas Degallier)
Date: Mon, 5 Feb 2018 19:40:08 +0100
Subject: [R] Concatening two maps/shapefiles...
Message-ID: <B363F5A6-D796-495C-BB79-1A8144348A1E@free.fr>

Dear All,
I'm new with mapping and using shapefiles in R.

I use the version: R 3.2.1 GUI 1.66 with Snow Leopard Mac OS (6956)

I want to build a map of the countries of Africa, in order to add points of collecting species of beetles, for later publishing.

library(maptools)
library(mapdata)

When I put the extreme coordinates of Africa, the map began only at longitude 0? and thus lacks the west africa part:

x<-map('world2Hires', xlim=c(-18,52), ylim=c(-35,38))

I attempted with the following script:


E<-map('world2Hires', xlim=c(0,52), ylim=c(-35,38))
W<-map('world2Hires', xlim=c(342,360), ylim=c(-35,38))

It ran fine but now I don't know how to get these two maps jointed.
I guess it may be trivial but I didn't found nothing about this in the available tutorials.
Cheers,
Nicolas Degallier



Nicolas Degallier
120 rue de Charonne
F-75011 Paris

nicolas.degallier at free.fr
Publications :
http://www.documentation.ird.fr/hor/DEGALLIER,NICOLAS/tout


From macqueen1 at llnl.gov  Mon Feb  5 21:54:01 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 5 Feb 2018 20:54:01 +0000
Subject: [R] Concatening two maps/shapefiles...
In-Reply-To: <B363F5A6-D796-495C-BB79-1A8144348A1E@free.fr>
References: <B363F5A6-D796-495C-BB79-1A8144348A1E@free.fr>
Message-ID: <72D1E294-406A-42FF-9C75-75CD90ECB378@llnl.gov>

I would try using the xlim, ylim arguments in your first map() command, and then using the add argument in the second one. See the help page for the map function.

This assumes that the map() function you are using comes from the maps package.

Otherwise, perhaps you should be using the rgdal package to load your shapefiles into R (you did mention shapefiles), and the basic plot() command to plot them. Depending on whether you choose to use the 'sp' package or the 'sf' package.

See also the R-sig-geo mailing list.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 
?On 2/5/18, 10:40 AM, "R-help on behalf of Nicolas Degallier" <r-help-bounces at r-project.org on behalf of nicolas.degallier at free.fr> wrote:

    Dear All,
    I'm new with mapping and using shapefiles in R.
    
    I use the version: R 3.2.1 GUI 1.66 with Snow Leopard Mac OS (6956)
    
    I want to build a map of the countries of Africa, in order to add points of collecting species of beetles, for later publishing.
    
    library(maptools)
    library(mapdata)
    
    When I put the extreme coordinates of Africa, the map began only at longitude 0? and thus lacks the west africa part:
    
    x<-map('world2Hires', xlim=c(-18,52), ylim=c(-35,38))
    
    I attempted with the following script:
    
    
    E<-map('world2Hires', xlim=c(0,52), ylim=c(-35,38))
    W<-map('world2Hires', xlim=c(342,360), ylim=c(-35,38))
    
    It ran fine but now I don't know how to get these two maps jointed.
    I guess it may be trivial but I didn't found nothing about this in the available tutorials.
    Cheers,
    Nicolas Degallier
    
    
    
    Nicolas Degallier
    120 rue de Charonne
    F-75011 Paris
    
    nicolas.degallier at free.fr
    Publications :
    http://www.documentation.ird.fr/hor/DEGALLIER,NICOLAS/tout
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From macqueen1 at llnl.gov  Mon Feb  5 22:07:51 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 5 Feb 2018 21:07:51 +0000
Subject: [R] Package sgd
In-Reply-To: <CAGxFJbRDf4tXfWMarKn7fbjULxp7XF0FOevchewsDXAhdSD=tg@mail.gmail.com>
References: <BY2PR14MB034417E78330F6F5C84BED4AACFE0@BY2PR14MB0344.namprd14.prod.outlook.com>
 <CAGxFJbRyoTO7c=g-03Tz=dHNhNCZz+nPtNjE7920HkhLPUS6kQ@mail.gmail.com>
 <CAGxFJbRDf4tXfWMarKn7fbjULxp7XF0FOevchewsDXAhdSD=tg@mail.gmail.com>
Message-ID: <BC611386-AC71-41FE-BDBD-F0AC1D5892D5@llnl.gov>

For that matter, a simple within-browser search for "gradient" on the CRAN packages-by-name webpage, finds

  Gradient Descent for Regression Tasks
  Holonomic Gradient Method and Gradient Descent
  Continuous Generalized Gradient Descent

And a few more that might or might not be relevant.

Plus, you could download sgd from the CRAN archives, and try building it yourself.

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 
?On 2/5/18, 10:25 AM, "R-help on behalf of Bert Gunter" <r-help-bounces at r-project.org on behalf of bgunter.4567 at gmail.com> wrote:

    A web search on "gradient descent R" also brought up a bunch of stuff. Is
    any of this what you want?
    
    Cheers,
    Bert
    
    
    
    Bert Gunter
    
    "The trouble with having an open mind is that people keep coming along and
    sticking things into it."
    -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    
    On Mon, Feb 5, 2018 at 10:23 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    
    > 1. It might help if you could state more specifically what you want to do.
    >
    > 2. Maybe check here if you haven't already done so:
    >
    > https://cran.r-project.org/web/views/
    >
    > Cheers,
    > Bert
    >
    >
    >
    > Bert Gunter
    >
    > "The trouble with having an open mind is that people keep coming along and
    > sticking things into it."
    > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    >
    > On Mon, Feb 5, 2018 at 8:02 AM, Colonel Sanders <ackrite55 at hotmail.com>
    > wrote:
    >
    >> Good morning,
    >>
    >> Is there a package that replaces the sgd package to explore the  Gradient
    >> Descent (SGD) t echnique ?
    >>
    >>
    >> Best regards,
    >>
    >> *~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~
    >>
    >> Tony
    >>
    >> *~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*~*
    >>
    >>         [[alternative HTML version deleted]]
    >>
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posti
    >> ng-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >>
    >
    >
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From btyner at gmail.com  Tue Feb  6 04:34:17 2018
From: btyner at gmail.com (Benjamin Tyner)
Date: Mon, 5 Feb 2018 22:34:17 -0500
Subject: [R] rJava garbage collect
Message-ID: <d9419586-2f78-95f4-9ebb-3a1e930117d3@gmail.com>

Hi

Does rJava offer a way to instruct the JVM to perform a garbage collection?

Regards

Ben


From jdnewmil at dcn.davis.ca.us  Tue Feb  6 05:53:59 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 05 Feb 2018 20:53:59 -0800
Subject: [R] rJava garbage collect
In-Reply-To: <d9419586-2f78-95f4-9ebb-3a1e930117d3@gmail.com>
References: <d9419586-2f78-95f4-9ebb-3a1e930117d3@gmail.com>
Message-ID: <77F704B0-AAF2-4047-9A9C-DCE12A3E4BFA@dcn.davis.ca.us>

rJava offers a mechanism to call arbitrary methods in Java. Wouldn't you use that mechanism to call whatever you would call if you were programming in Java (e.g. System.gc)? 
-- 
Sent from my phone. Please excuse my brevity.

On February 5, 2018 7:34:17 PM PST, Benjamin Tyner <btyner at gmail.com> wrote:
>Hi
>
>Does rJava offer a way to instruct the JVM to perform a garbage
>collection?
>
>Regards
>
>Ben
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From alain.guillet at uclouvain.be  Tue Feb  6 09:20:03 2018
From: alain.guillet at uclouvain.be (Alain Guillet)
Date: Tue, 6 Feb 2018 09:20:03 +0100
Subject: [R] Aggregate behaviour inconsistent (?) when FUN=table
Message-ID: <223384a8-6964-61e8-1b40-d633839f385c@uclouvain.be>

Dear R users,

When I use aggregate with table as FUN, I get what I would call a 
strange behaviour if it involves numerical vectors and one "level" of it 
is not present for every "levels" of the "by" variable:

---------------------------

 > df <- 
data.frame(A=c(1,1,1,1,0,0,0,0),B=c(1,0,1,0,0,0,1,0),C=c(1,0,1,0,0,1,1,1))
 > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
 ? Group.1 A.0 A.1??? B
1?????? 0?? 1?? 2??? 3
2?????? 1?? 3?? 2 2, 3

 > table(df$C,df$B)

 ??? 0 1
 ? 0 3 0
 ? 1 2 3

---------------

As you can see, a comma appears in the column with the variable B in the 
aggregate whereas when I call table I obtain the same result as if B was 
defined as a factor (I suppose it comes from the fact "non-factor 
arguments a are coerced via factor" according to the details of the 
table help). I find it completely normal if I remember that aggregate 
first splits the data into subsets and then compute the table. But then 
I don't understand why it works differently with character vectors. 
Indeed if I use character vectors, I get the same result as with factors:

------------------------

 > df <- 
data.frame(A=factor(c("1","1","1","1","0","0","0","0")),B=factor(c("1","0","1","0","0","0","1","0")),C=factor(c("1","0","1","0","0","1","1","1")))
 > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
 ? Group.1 A.0 A.1 B.0 B.1
1?????? 0?? 1?? 2?? 3?? 0
2?????? 1?? 3?? 2?? 2?? 3

 > df <- 
data.frame(A=factor(c(1,1,1,1,0,0,0,0)),B=factor(c(1,0,1,0,0,0,1,0)),C=factor(c(1,0,1,0,0,1,1,1)))
 > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
 ? Group.1 A.0 A.1 B.0 B.1
1?????? 0?? 1?? 2?? 3?? 0
2?????? 1?? 3?? 2?? 2?? 3

---------------------

Is it possible to precise anything about this behaviour in the aggregate 
help since the result is not completely compatible with the expectation 
of result we can have according to the table help? Or would it be 
possible to have the same results independently of the vector type? This 
post was rejected on the R-devel mailing list so I ask my question here 
as suggested.


Best regards,
Alain Guillet

-- 
Alain Guillet
Statistician and Computer Scientist

SMCS - IMMAQ - Universit? catholique de Louvain
http://www.uclouvain.be/smcs

Bureau c.316
Voie du Roman Pays, 20 (bte L1.04.01)
B-1348 Louvain-la-Neuve
Belgium

Tel: +32 10 47 30 50

Acc?s: http://www.uclouvain.be/323631.html


From traxplayer at gmail.com  Tue Feb  6 13:09:08 2018
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Tue, 6 Feb 2018 13:09:08 +0100
Subject: [R] rJava garbage collect
In-Reply-To: <d9419586-2f78-95f4-9ebb-3a1e930117d3@gmail.com>
References: <d9419586-2f78-95f4-9ebb-3a1e930117d3@gmail.com>
Message-ID: <CAGAA5bc6D0UbyWCE+_r+aO1COMfLUCsR3RD4z4d9zJ3vJKYqwg@mail.gmail.com>

On 6 February 2018 at 04:34, Benjamin Tyner <btyner at gmail.com> wrote:
> Hi
>
> Does rJava offer a way to instruct the JVM to perform a garbage collection?

Do you really, really need to run the garbage collector?

Consider reading:
https://stackoverflow.com/questions/5086800/java-garbage-collection

Regards
Martin


From loris.bennett at fu-berlin.de  Tue Feb  6 15:01:08 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 06 Feb 2018 15:01:08 +0100
Subject: [R] gdistance::shortestPath throws error "not a symmetric matrix"
Message-ID: <87607ai5ej.fsf@hornfels.zedat.fu-berlin.de>

Hi,

Calling

  gdistance::shortestPath

gives me the error

  Error in asMethod(object) : 
    not a symmetric matrix; consider forceSymmetric() or symmpart()

The output of dput(.traceback()) is

  pairlist("stop(\"not a symmetric matrix; consider forceSymmetric() or symmpart()\")",
  "asMethod(object)",
  "as(Laplacian,\"symmetricMatrix\")",
  ".Laplacian(x)", ".flowMap(x, ci, cj, tc)",
  ".local(x, origin, goal, ...)",
  c("passage(conduct_Tobler, origin =sites at coords[5, ], goal = sites at coords[3, ", " ])"),
  c("passage(conduct_Tobler, origin = sites at coords[5, ], goal = sites at coords[3, ", " ])"),
  "eval(ei, envir)", "eval(ei, envir)",
  "withVisible(eval(ei, envir))",
  "source(\"./Skript.R\")")

Is that enough for anyone to point me in the right direction?

I am aware that this question would be probably better posted on
r-sig-geo, but as I am just an HPC janitor trying to help a customer and
am not a geo-scientist myself, I thought I'd ask here first before
signing up to (yet another) list.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From jdnewmil at dcn.davis.ca.us  Tue Feb  6 15:46:32 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Feb 2018 06:46:32 -0800
Subject: [R] 
 gdistance::shortestPath throws error "not a symmetric matrix"
In-Reply-To: <87607ai5ej.fsf@hornfels.zedat.fu-berlin.de>
References: <87607ai5ej.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <D763DCC7-A5B3-4A2E-844F-E89FAAD2C209@dcn.davis.ca.us>

It is really hard to help you fix a function usage error if you don't show us how you used the function. [1][2][3]

As for helping a customer by asking for help on the wrong list... you are not an expert on the topic, and are asking a group that might or might not know the theory behind your question. You might achieve success, but it might also be better to remove at least one handicap by either or both strategies of having the customer ask themselves or asking on the right list. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On February 6, 2018 6:01:08 AM PST, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
>Hi,
>
>Calling
>
>  gdistance::shortestPath
>
>gives me the error
>
>  Error in asMethod(object) : 
>    not a symmetric matrix; consider forceSymmetric() or symmpart()
>
>The output of dput(.traceback()) is
>
>pairlist("stop(\"not a symmetric matrix; consider forceSymmetric() or
>symmpart()\")",
>  "asMethod(object)",
>  "as(Laplacian,\"symmetricMatrix\")",
>  ".Laplacian(x)", ".flowMap(x, ci, cj, tc)",
>  ".local(x, origin, goal, ...)",
>c("passage(conduct_Tobler, origin =sites at coords[5, ], goal =
>sites at coords[3, ", " ])"),
>c("passage(conduct_Tobler, origin = sites at coords[5, ], goal =
>sites at coords[3, ", " ])"),
>  "eval(ei, envir)", "eval(ei, envir)",
>  "withVisible(eval(ei, envir))",
>  "source(\"./Skript.R\")")
>
>Is that enough for anyone to point me in the right direction?
>
>I am aware that this question would be probably better posted on
>r-sig-geo, but as I am just an HPC janitor trying to help a customer
>and
>am not a geo-scientist myself, I thought I'd ask here first before
>signing up to (yet another) list.
>
>Cheers,
>
>Loris


From jdnewmil at dcn.davis.ca.us  Tue Feb  6 16:33:45 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Feb 2018 07:33:45 -0800
Subject: [R] Aggregate behaviour inconsistent (?) when FUN=table
In-Reply-To: <223384a8-6964-61e8-1b40-d633839f385c@uclouvain.be>
References: <223384a8-6964-61e8-1b40-d633839f385c@uclouvain.be>
Message-ID: <C23025E4-7155-46EE-AFAF-BBD7D97987C9@dcn.davis.ca.us>

The normal input to a factory that builds cars is car parts. Feeding whole trucks into such a factory is likely to yield odd-looking results.

Both aggregate and table do similar kinds of things, but yield differently constructed outputs. The output of the table function is not well-suited to be used as the aggregated value to be compiled into a data frame by the aggregate function, so having aggregate call the table function will yield surprises.

I am having some difficulty deciphering what it is you are trying to accomplish with all this, so I will guess that you are trying to reproduce the information output from

table( df$C, df$B )

so

aggregate( df$A, df[ , c( "C", "B" ) ], length )

but if that isn't what you want then perhaps you can clarify what result you want to see and we can help you get there. 
-- 
Sent from my phone. Please excuse my brevity.

On February 6, 2018 12:20:03 AM PST, Alain Guillet <alain.guillet at uclouvain.be> wrote:
>Dear R users,
>
>When I use aggregate with table as FUN, I get what I would call a 
>strange behaviour if it involves numerical vectors and one "level" of
>it 
>is not present for every "levels" of the "by" variable:
>
>---------------------------
>
> > df <- 
>data.frame(A=c(1,1,1,1,0,0,0,0),B=c(1,0,1,0,0,0,1,0),C=c(1,0,1,0,0,1,1,1))
> > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
> ? Group.1 A.0 A.1??? B
>1?????? 0?? 1?? 2??? 3
>2?????? 1?? 3?? 2 2, 3
>
> > table(df$C,df$B)
>
> ??? 0 1
> ? 0 3 0
> ? 1 2 3
>
>---------------
>
>As you can see, a comma appears in the column with the variable B in
>the 
>aggregate whereas when I call table I obtain the same result as if B
>was 
>defined as a factor (I suppose it comes from the fact "non-factor 
>arguments a are coerced via factor" according to the details of the 
>table help). I find it completely normal if I remember that aggregate 
>first splits the data into subsets and then compute the table. But then
>
>I don't understand why it works differently with character vectors. 
>Indeed if I use character vectors, I get the same result as with
>factors:
>
>------------------------
>
> > df <- 
>data.frame(A=factor(c("1","1","1","1","0","0","0","0")),B=factor(c("1","0","1","0","0","0","1","0")),C=factor(c("1","0","1","0","0","1","1","1")))
> > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
> ? Group.1 A.0 A.1 B.0 B.1
>1?????? 0?? 1?? 2?? 3?? 0
>2?????? 1?? 3?? 2?? 2?? 3
>
> > df <- 
>data.frame(A=factor(c(1,1,1,1,0,0,0,0)),B=factor(c(1,0,1,0,0,0,1,0)),C=factor(c(1,0,1,0,0,1,1,1)))
> > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
> ? Group.1 A.0 A.1 B.0 B.1
>1?????? 0?? 1?? 2?? 3?? 0
>2?????? 1?? 3?? 2?? 2?? 3
>
>---------------------
>
>Is it possible to precise anything about this behaviour in the
>aggregate 
>help since the result is not completely compatible with the expectation
>
>of result we can have according to the table help? Or would it be 
>possible to have the same results independently of the vector type?
>This 
>post was rejected on the R-devel mailing list so I ask my question here
>
>as suggested.
>
>
>Best regards,
>Alain Guillet


From wdunlap at tibco.com  Tue Feb  6 18:07:26 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Feb 2018 09:07:26 -0800
Subject: [R] Aggregate behaviour inconsistent (?) when FUN=table
In-Reply-To: <223384a8-6964-61e8-1b40-d633839f385c@uclouvain.be>
References: <223384a8-6964-61e8-1b40-d633839f385c@uclouvain.be>
Message-ID: <CAF8bMcb6c0TWBwUzQzwByE+pckwBLyuwE5rSai7eRDYOMDrf1w@mail.gmail.com>

Don't use aggregate's simplify=TRUE when FUN() produces return
values of various dimensions.  In your case, the shape of table(subset)'s
return value depends on the number of levels in the factor 'subset'.
If you make B a factor before splitting it by C, each split will have the
same number of levels (2).  If you split it and then let table convert
each split to a factor, one split will have 1 level and the other 2.  To see
the details of the output , use str() instead of print().


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Feb 6, 2018 at 12:20 AM, Alain Guillet <alain.guillet at uclouvain.be>
wrote:

> Dear R users,
>
> When I use aggregate with table as FUN, I get what I would call a strange
> behaviour if it involves numerical vectors and one "level" of it is not
> present for every "levels" of the "by" variable:
>
> ---------------------------
>
> > df <- data.frame(A=c(1,1,1,1,0,0,0,0),B=c(1,0,1,0,0,0,1,0),C=c(1,0
> ,1,0,0,1,1,1))
> > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
>   Group.1 A.0 A.1    B
> 1       0   1   2    3
> 2       1   3   2 2, 3
>
> > table(df$C,df$B)
>
>     0 1
>   0 3 0
>   1 2 3
>
> ---------------
>
> As you can see, a comma appears in the column with the variable B in the
> aggregate whereas when I call table I obtain the same result as if B was
> defined as a factor (I suppose it comes from the fact "non-factor arguments
> a are coerced via factor" according to the details of the table help). I
> find it completely normal if I remember that aggregate first splits the
> data into subsets and then compute the table. But then I don't understand
> why it works differently with character vectors. Indeed if I use character
> vectors, I get the same result as with factors:
>
> ------------------------
>
> > df <- data.frame(A=factor(c("1","1","1","1","0","0","0","0")),B=fa
> ctor(c("1","0","1","0","0","0","1","0")),C=factor(c("1","0",
> "1","0","0","1","1","1")))
> > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
>   Group.1 A.0 A.1 B.0 B.1
> 1       0   1   2   3   0
> 2       1   3   2   2   3
>
> > df <- data.frame(A=factor(c(1,1,1,1,0,0,0,0)),B=factor(c(1,0,1,0,0
> ,0,1,0)),C=factor(c(1,0,1,0,0,1,1,1)))
> > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
>   Group.1 A.0 A.1 B.0 B.1
> 1       0   1   2   3   0
> 2       1   3   2   2   3
>
> ---------------------
>
> Is it possible to precise anything about this behaviour in the aggregate
> help since the result is not completely compatible with the expectation of
> result we can have according to the table help? Or would it be possible to
> have the same results independently of the vector type? This post was
> rejected on the R-devel mailing list so I ask my question here as suggested.
>
>
> Best regards,
> Alain Guillet
>
> --
> Alain Guillet
> Statistician and Computer Scientist
>
> SMCS - IMMAQ - Universit? catholique de Louvain
> http://www.uclouvain.be/smcs
>
> Bureau c.316
> Voie du Roman Pays, 20 (bte L1.04.01)
> B-1348 Louvain-la-Neuve
> Belgium
>
> Tel: +32 10 47 30 50
>
> Acc?s: http://www.uclouvain.be/323631.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alain.guillet at uclouvain.be  Tue Feb  6 18:17:08 2018
From: alain.guillet at uclouvain.be (Alain Guillet)
Date: Tue, 6 Feb 2018 18:17:08 +0100
Subject: [R] Aggregate behaviour inconsistent (?) when FUN=table
In-Reply-To: <CAF8bMcb6c0TWBwUzQzwByE+pckwBLyuwE5rSai7eRDYOMDrf1w@mail.gmail.com>
References: <223384a8-6964-61e8-1b40-d633839f385c@uclouvain.be>
 <CAF8bMcb6c0TWBwUzQzwByE+pckwBLyuwE5rSai7eRDYOMDrf1w@mail.gmail.com>
Message-ID: <9d86f9a4-e9dd-199f-823c-dfb1f9a32abe@uclouvain.be>

Thank you for your response. Note that with R 3.4.3, I get the same 
result with simplify=TRUE or simplify=FALSE.

My problem was the behaviour was different if I define my columns as 
character or as numeric but for now some minutes I discovered there also 
is a stringsAsFactors option in the function data.frame. So yes, it was 
a stupid question and I apologize for it.


On 06/02/2018 18:07, William Dunlap wrote:
> Don't use aggregate's simplify=TRUE when FUN() produces return
> values of various dimensions.? In your case, the shape of table(subset)'s
> return value depends on the number of levels in the factor 'subset'.
> If you make B a factor before splitting it by C, each split will have the
> same number of levels (2).? If you split it and then let table convert
> each split to a factor, one split will have 1 level and the other 2.? 
> To see
> the details of the output , use str() instead of print().
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Tue, Feb 6, 2018 at 12:20 AM, Alain Guillet 
> <alain.guillet at uclouvain.be <mailto:alain.guillet at uclouvain.be>> wrote:
>
>     Dear R users,
>
>     When I use aggregate with table as FUN, I get what I would call a
>     strange behaviour if it involves numerical vectors and one "level"
>     of it is not present for every "levels" of the "by" variable:
>
>     ---------------------------
>
>     > df <-
>     data.frame(A=c(1,1,1,1,0,0,0,0),B=c(1,0,1,0,0,0,1,0),C=c(1,0,1,0,0,1,1,1))
>     > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
>     ? Group.1 A.0 A.1??? B
>     1?????? 0?? 1?? 2??? 3
>     2?????? 1?? 3?? 2 2, 3
>
>     > table(df$C,df$B)
>
>     ??? 0 1
>     ? 0 3 0
>     ? 1 2 3
>
>     ---------------
>
>     As you can see, a comma appears in the column with the variable B
>     in the aggregate whereas when I call table I obtain the same
>     result as if B was defined as a factor (I suppose it comes from
>     the fact "non-factor arguments a are coerced via factor" according
>     to the details of the table help). I find it completely normal if
>     I remember that aggregate first splits the data into subsets and
>     then compute the table. But then I don't understand why it works
>     differently with character vectors. Indeed if I use character
>     vectors, I get the same result as with factors:
>
>     ------------------------
>
>     > df <-
>     data.frame(A=factor(c("1","1","1","1","0","0","0","0")),B=factor(c("1","0","1","0","0","0","1","0")),C=factor(c("1","0","1","0","0","1","1","1")))
>     > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
>     ? Group.1 A.0 A.1 B.0 B.1
>     1?????? 0?? 1?? 2?? 3?? 0
>     2?????? 1?? 3?? 2?? 2?? 3
>
>     > df <-
>     data.frame(A=factor(c(1,1,1,1,0,0,0,0)),B=factor(c(1,0,1,0,0,0,1,0)),C=factor(c(1,0,1,0,0,1,1,1)))
>     > aggregate(df[1:2],list(df$C),table,simplify = TRUE,drop=TRUE)
>     ? Group.1 A.0 A.1 B.0 B.1
>     1?????? 0?? 1?? 2?? 3?? 0
>     2?????? 1?? 3?? 2?? 2?? 3
>
>     ---------------------
>
>     Is it possible to precise anything about this behaviour in the
>     aggregate help since the result is not completely compatible with
>     the expectation of result we can have according to the table help?
>     Or would it be possible to have the same results independently of
>     the vector type? This post was rejected on the R-devel mailing
>     list so I ask my question here as suggested.
>
>
>     Best regards,
>     Alain Guillet
>
>     -- 
>


From hannah.hlx at gmail.com  Tue Feb  6 19:32:33 2018
From: hannah.hlx at gmail.com (li li)
Date: Tue, 6 Feb 2018 13:32:33 -0500
Subject: [R] question with integrate function
Message-ID: <CAHLnndaUpTT4hidVwEe7GNV-uMbqNJqHAod+h3h=u4qfS3F36w@mail.gmail.com>

Hi all,
  The function h below is a function of c and it should be a monotone
increasing function since the integrand is nonnegative and integral is
taken from c to infinity. However, as we can see from the plot, it is not
shown to be monotone. Something wrong with the usage of integrate function?
Thanks so much for your help.
    Hanna



h <- function(c){
    g <- function(x){pnorm(x-8.8, mean=0.4, sd=0.3,
lower.tail=TRUE)*dnorm(x, mean=9,sd=0.15)}
    integrate(g, lower=c, upper=Inf)$value}

xx <- seq(-20,20,by=0.001)
y <- xx
for (i in 1:length(xx)){y[i] <- h(xx[i])}
plot(xx, y)

	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Tue Feb  6 19:40:20 2018
From: hannah.hlx at gmail.com (li li)
Date: Tue, 6 Feb 2018 13:40:20 -0500
Subject: [R] question with integrate function
In-Reply-To: <CAHLnndaUpTT4hidVwEe7GNV-uMbqNJqHAod+h3h=u4qfS3F36w@mail.gmail.com>
References: <CAHLnndaUpTT4hidVwEe7GNV-uMbqNJqHAod+h3h=u4qfS3F36w@mail.gmail.com>
Message-ID: <CAHLnndaXMReOBoqryL4tXX42JAO9OsT-_ZPqUahKNG8A2P2DFg@mail.gmail.com>

Sorry. I meant in the previous email that the function h() is a monotone
decreasing function. Thanks very much.

2018-02-06 13:32 GMT-05:00 li li <hannah.hlx at gmail.com>:

> Hi all,
>   The function h below is a function of c and it should be a monotone
> increasing function since the integrand is nonnegative and integral is
> taken from c to infinity. However, as we can see from the plot, it is not
> shown to be monotone. Something wrong with the usage of integrate function?
> Thanks so much for your help.
>     Hanna
>
>
>
> h <- function(c){
>     g <- function(x){pnorm(x-8.8, mean=0.4, sd=0.3,
> lower.tail=TRUE)*dnorm(x, mean=9,sd=0.15)}
>     integrate(g, lower=c, upper=Inf)$value}
>
> xx <- seq(-20,20,by=0.001)
> y <- xx
> for (i in 1:length(xx)){y[i] <- h(xx[i])}
> plot(xx, y)
>
>

	[[alternative HTML version deleted]]


From goran.brostrom at umu.se  Tue Feb  6 20:33:10 2018
From: goran.brostrom at umu.se (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Tue, 6 Feb 2018 20:33:10 +0100
Subject: [R] question with integrate function
In-Reply-To: <CAHLnndaXMReOBoqryL4tXX42JAO9OsT-_ZPqUahKNG8A2P2DFg@mail.gmail.com>
References: <CAHLnndaUpTT4hidVwEe7GNV-uMbqNJqHAod+h3h=u4qfS3F36w@mail.gmail.com>
 <CAHLnndaXMReOBoqryL4tXX42JAO9OsT-_ZPqUahKNG8A2P2DFg@mail.gmail.com>
Message-ID: <72ba8080-7933-2ac0-f86c-634802b66202@umu.se>

Hi Hanna,

your function is essentially zero outside a short interval around 9. And 
the help page states: "If the function is approximately constant (in 
particular, zero) over nearly all its range it is possible that the 
result and error estimate may be seriously wrong."

You could try to integrate over a finite interval, say (7, 12).

G?ran Brostr?m

On 2018-02-06 19:40, li li wrote:
> Sorry. I meant in the previous email that the function h() is a monotone
> decreasing function. Thanks very much.
> 
> 2018-02-06 13:32 GMT-05:00 li li <hannah.hlx at gmail.com>:
> 
>> Hi all,
>>    The function h below is a function of c and it should be a monotone
>> increasing function since the integrand is nonnegative and integral is
>> taken from c to infinity. However, as we can see from the plot, it is not
>> shown to be monotone. Something wrong with the usage of integrate function?
>> Thanks so much for your help.
>>      Hanna
>>
>>
>>
>> h <- function(c){
>>      g <- function(x){pnorm(x-8.8, mean=0.4, sd=0.3,
>> lower.tail=TRUE)*dnorm(x, mean=9,sd=0.15)}
>>      integrate(g, lower=c, upper=Inf)$value}
>>
>> xx <- seq(-20,20,by=0.001)
>> y <- xx
>> for (i in 1:length(xx)){y[i] <- h(xx[i])}
>> plot(xx, y)
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hannah.hlx at gmail.com  Tue Feb  6 20:36:54 2018
From: hannah.hlx at gmail.com (li li)
Date: Tue, 6 Feb 2018 14:36:54 -0500
Subject: [R] question with integrate function
In-Reply-To: <72ba8080-7933-2ac0-f86c-634802b66202@umu.se>
References: <CAHLnndaUpTT4hidVwEe7GNV-uMbqNJqHAod+h3h=u4qfS3F36w@mail.gmail.com>
 <CAHLnndaXMReOBoqryL4tXX42JAO9OsT-_ZPqUahKNG8A2P2DFg@mail.gmail.com>
 <72ba8080-7933-2ac0-f86c-634802b66202@umu.se>
Message-ID: <CAHLnndat5t7-fRJ8CjWvZ-ZEr-abEVOyQtZ7025wz8GCibr63Q@mail.gmail.com>

Oh ok. Thanks very much. I will have to restrict to a shorter interval.
    Hanna

2018-02-06 14:33 GMT-05:00 G?ran Brostr?m <goran.brostrom at umu.se>:

> Hi Hanna,
>
> your function is essentially zero outside a short interval around 9. And
> the help page states: "If the function is approximately constant (in
> particular, zero) over nearly all its range it is possible that the result
> and error estimate may be seriously wrong."
>
> You could try to integrate over a finite interval, say (7, 12).
>
> G?ran Brostr?m
>
>
> On 2018-02-06 19:40, li li wrote:
>
>> Sorry. I meant in the previous email that the function h() is a monotone
>> decreasing function. Thanks very much.
>>
>> 2018-02-06 13:32 GMT-05:00 li li <hannah.hlx at gmail.com>:
>>
>> Hi all,
>>>    The function h below is a function of c and it should be a monotone
>>> increasing function since the integrand is nonnegative and integral is
>>> taken from c to infinity. However, as we can see from the plot, it is not
>>> shown to be monotone. Something wrong with the usage of integrate
>>> function?
>>> Thanks so much for your help.
>>>      Hanna
>>>
>>>
>>>
>>> h <- function(c){
>>>      g <- function(x){pnorm(x-8.8, mean=0.4, sd=0.3,
>>> lower.tail=TRUE)*dnorm(x, mean=9,sd=0.15)}
>>>      integrate(g, lower=c, upper=Inf)$value}
>>>
>>> xx <- seq(-20,20,by=0.001)
>>> y <- xx
>>> for (i in 1:length(xx)){y[i] <- h(xx[i])}
>>> plot(xx, y)
>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Wed Feb  7 02:06:46 2018
From: davidsmi at microsoft.com (David Smith (CDA))
Date: Wed, 7 Feb 2018 01:06:46 +0000
Subject: [R] Revolutions blog: January 2018 roundup
Message-ID: <SN6PR2101MB09279B50B90A4CF9A3AC4686C8FC0@SN6PR2101MB0927.namprd21.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have
written about R at the Revolutions blog (http://blog.revolutionanalytics.com)
and every month I post a summary of articles from the previous month of
particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of January:

Josh Katz and Peter Aldhous used R to analyze the content and presentation of
the most recent State of the Union speech from the US president:
http://blog.revolutionanalytics.com/2018/01/trump-sotu.html

Slides for my presentation "Speeding up R with Parallel Processing in the
Cloud", with applications of the doAzureParallel and sparklyr packages:
http://blog.revolutionanalytics.com/2018/01/r-parallel-cloud.html

An example of using the doAzureParallel package to speed up a statistical
simulation:
http://blog.revolutionanalytics.com/2018/01/doazureparallel-simulations.html

5 lines of R code to create a list of US Representatives from a Wikipedia table:
http://blog.revolutionanalytics.com/2018/01/scraping-with-5-lines-r.html

A package to visualize routes from activities recorded with a Strava device:
http://blog.revolutionanalytics.com/2018/01/strava-visualization.html

The call for papers and registration is now open for useR!2018 in Brisbane:
http://blog.revolutionanalytics.com/2018/01/user2018-reg-open.html

Microsoft R Open 3.4.3 is now available:
http://blog.revolutionanalytics.com/2018/01/microsoft-r-open-343-now-available.html

A simple command-line tool to launch a cluster in Azure for use with sparklyr:
http://blog.revolutionanalytics.com/2018/01/azure-sparklyr-aztk.html

A review of cloud-based tools for building intelligent applications with R:
http://blog.revolutionanalytics.com/2018/01/r-cloud-tools.html

A guide to implementing deep neural networks from scratch in R:
http://blog.revolutionanalytics.com/2018/01/neural-networks-r6.html

R leaps to its highest position -- 8th -- in the TIOBE language rankings:
http://blog.revolutionanalytics.com/2018/01/tiobe-2017.html

A field guide to the ecosystem surrounding R:
http://blog.revolutionanalytics.com/2018/01/a-field-guide-to-the-r-ecosystem.html

Using the Rcpp package to parallelize an association rules problem:
http://blog.revolutionanalytics.com/2018/01/parallelize-rcpp.html

Various R tricks used at Etsy to speed up an A/B testing system:
http://blog.revolutionanalytics.com/2018/01/r-faster-case-study.html

Some useful advice from Jenny Bryan on setting up a reproducible R workflow:
http://blog.revolutionanalytics.com/2018/01/bryan-workflow.html

And some general interest stories (not necessarily related to R):

* A Japanese artist makes "paintings" with Excel:
  http://blog.revolutionanalytics.com/2018/01/because-its-friday-excel-painter.html

* A presentation on why companies' stated principles and values actually matter:
  http://blog.revolutionanalytics.com/2018/01/because-its-friday-principles-and-values.html 

* Some impressive formation acrobatics with kites:
  http://blog.revolutionanalytics.com/2018/01/kite-ballet.html 

* A new Harry Potter chapter, written with a predictive text algorithm:
  http://blog.revolutionanalytics.com/2018/01/because-its-friday-harry-potter-was-the-time-to-come.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From btyner at gmail.com  Wed Feb  7 02:14:51 2018
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 6 Feb 2018 20:14:51 -0500
Subject: [R] rJava garbage collect
In-Reply-To: <77F704B0-AAF2-4047-9A9C-DCE12A3E4BFA@dcn.davis.ca.us>
References: <d9419586-2f78-95f4-9ebb-3a1e930117d3@gmail.com>
 <77F704B0-AAF2-4047-9A9C-DCE12A3E4BFA@dcn.davis.ca.us>
Message-ID: <3c1d2acb-a924-6d2e-9445-a966c92928a3@gmail.com>

Thanks Jeff; indeed it works:

 ?? .jcall("java/lang/System", method = "gc")


On 02/05/2018 11:53 PM, Jeff Newmiller wrote:
> rJava offers a mechanism to call arbitrary methods in Java. Wouldn't you use that mechanism to call whatever you would call if you were programming in Java (e.g. System.gc)?


From btyner at gmail.com  Wed Feb  7 02:27:44 2018
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 6 Feb 2018 20:27:44 -0500
Subject: [R] rJava garbage collect
In-Reply-To: <CAGAA5bc6D0UbyWCE+_r+aO1COMfLUCsR3RD4z4d9zJ3vJKYqwg@mail.gmail.com>
References: <CAGAA5bc6D0UbyWCE+_r+aO1COMfLUCsR3RD4z4d9zJ3vJKYqwg@mail.gmail.com>
Message-ID: <a8f9257c-916b-6e4a-2f72-8c828d79b4da@gmail.com>

Hi Martin,

Thanks for providing the reference.

In this particular case, it helped me to discover that 13 JVM threads 
were garbage collecting in parallel, occasionally resulting in a race 
condition. Setting

 ??? options(java.parameters = "-XS:ParallelGCThreads=1")

appears to resolve the issue.

Regards

Ben

> ------------------------------------------------------------------------
> On 6 February 2018 at 04:34, Benjamin Tyner <btyner at gmail.com <https://stat.ethz.ch/mailman/listinfo/r-help>> wrote:
> >/Hi />//>/Does rJava offer a way to instruct the JVM to perform a garbage 
> collection? /
> Do you really, really need to run the garbage collector?
>
> Consider reading:
> https://stackoverflow.com/questions/5086800/java-garbage-collection
>
> Regards
> Martin
>


From unwin at math.uni-augsburg.de  Tue Feb  6 12:22:07 2018
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Tue, 6 Feb 2018 12:22:07 +0100
Subject: [R] [R-pkgs] OutliersO3 version 0.5.3 released
Message-ID: <583D6397-80AF-46D7-B1D4-04C936614149@math.uni-augsburg.de>

Dear all,

A revised version of OutliersO3 is available on CRAN:
<https://cran.r-project.org/web/packages/OutliersO3/index.html <https://cran.r-project.org/web/packages/OutliersO3/index.html>>.

The package has been restructured.  The default is now that the tolerance level is set individually for each of the (six) outlier methods included.  Plots have been added, as have outlier tables and scores for further analysis.  It is also possible to draw an O3 plot using your own outlier identification method, see the vignette for more details.

There are four vignettes to illustrate the use of the package.

Queries, comments, suggestions are welcome.  Thanks to Michael Friendly, Tae-Rae Kim, Nina Wu, and, in particular, Bill Venables for their comments on the old version.

Regards

Antony

Professor Antony Unwin
Mathematics Institute,
University of Augsburg, 
86135 Augsburg, Germany
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From yvonne.yock at gmail.com  Wed Feb  7 17:22:07 2018
From: yvonne.yock at gmail.com (Yvonne Yock)
Date: Thu, 8 Feb 2018 00:22:07 +0800
Subject: [R] Error when running duplicate scale imputation for multilevel
 data
Message-ID: <CAC9xtfFxL3JgXupY5_TZND4jnQ+_UhvdPfqPtWfy7EuXqCoeeA@mail.gmail.com>

Hi,

I am working with a multiple-item questionnaire. I have previously done
item-level multiple imputation using MICE in R and right now I am
attempting duplicate-scale imputation based on the guidelines listed in
Enders's applied missing data analysis book.

I use MICE to do MI as it allows me to specify school effect as I am
working with multilevel data; my respondents come from different schools.

I had no problem running the item-level MI with the school effect. However,
I encounter problem running the duplicate-scale MI when I included the
school effect. I saw this error message '*Error in x + diag(diag(x) *
ridge) : non-conformable arrays*'. I did not get any error message when I
re-ran without school effect.

What could be the reason why I am facing difficulties running duplicate
scale imputation when I specify school effect?

Thanks. ( I have not included any codes as I am not sure if it will be
useful)
Regards,
Yvonne

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Thu Feb  8 08:13:35 2018
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 8 Feb 2018 10:13:35 +0300
Subject: [R] plotting the regression coefficients
Message-ID: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>

Hi Dear all;

I would like to create a plot for regression coefficients with each
independent variable (x) along the side and the phenotypes (y) across the
top (as given below). For each data point, direction and magnitude of
effect could be color and significance could be the size of the circle? Is
this possible?


I would greatly be appreciated your help.

Thanks,

Greg



  y1 y2 y3 y4 y5 y6
x1
x2
x3
x4
x5
x6
x7
x8
x9
x10
x11
x12
x13
x14
x15
x16
x17
.
.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Feb  8 08:19:36 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 8 Feb 2018 07:19:36 +0000
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
Message-ID: <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>

Hi

Example, example, example - preferably working.

Wild guess - did you try ggplot?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg holly
> Sent: Thursday, February 8, 2018 8:14 AM
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] plotting the regression coefficients
>
> Hi Dear all;
>
> I would like to create a plot for regression coefficients with each independent
> variable (x) along the side and the phenotypes (y) across the top (as given
> below). For each data point, direction and magnitude of effect could be color
> and significance could be the size of the circle? Is this possible?
>
>
> I would greatly be appreciated your help.
>
> Thanks,
>
> Greg
>
>
>
>   y1 y2 y3 y4 y5 y6
> x1
> x2
> x3
> x4
> x5
> x6
> x7
> x8
> x9
> x10
> x11
> x12
> x13
> x14
> x15
> x16
> x17
> .
> .
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From mak.hholly at gmail.com  Thu Feb  8 09:23:16 2018
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 8 Feb 2018 11:23:16 +0300
Subject: [R] plotting the regression coefficients
In-Reply-To: <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>

 Hi Petr;

Thanks for your reply. It is much appreciated. A small example is given
below for 4 independent and 4 dependent variables only. The values given
are regression coefficients.I have looked ggplot documents before writing
to you. Unfortunately, I could not figure out as my experience in ggplot is
ignorable

Regards.
Greg

y1 y2 y3 y4
x1 -0.19 0.40 -0.06 0.13
x2 0.45 -0.75 -8.67 -0.46
x3 -0.09 0.14 1.42 0.06
x4 -0.16 -0.01 2.21 0.06


On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Example, example, example - preferably working.
>
> Wild guess - did you try ggplot?
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
> holly
> > Sent: Thursday, February 8, 2018 8:14 AM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] plotting the regression coefficients
> >
> > Hi Dear all;
> >
> > I would like to create a plot for regression coefficients with each
> independent
> > variable (x) along the side and the phenotypes (y) across the top (as
> given
> > below). For each data point, direction and magnitude of effect could be
> color
> > and significance could be the size of the circle? Is this possible?
> >
> >
> > I would greatly be appreciated your help.
> >
> > Thanks,
> >
> > Greg
> >
> >
> >
> >   y1 y2 y3 y4 y5 y6
> > x1
> > x2
> > x3
> > x4
> > x5
> > x6
> > x7
> > x8
> > x9
> > x10
> > x11
> > x12
> > x13
> > x14
> > x15
> > x16
> > x17
> > .
> > .
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Feb  8 11:29:16 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 8 Feb 2018 10:29:16 +0000
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
Message-ID: <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>

Hi
I copied your values to R, here it is

> dput(temp)

temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
"x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
    y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
    2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
"y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
-4L))

For plotting it need to be reshaped

library(reshape2)
library(ggplot2)

temp <- melt(temp)
p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
p+geom_point()

Is this what you wanted?

Cheers
Petr
And preferably do not post in HTML, the email content could be scrambled.

From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Thursday, February 8, 2018 9:23 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] plotting the regression coefficients

Hi Petr;

Thanks for your reply. It is much appreciated. A small example is given below for 4 independent and 4 dependent variables only. The values given are regression coefficients.I have looked ggplot documents before writing to you. Unfortunately, I could not figure out as my experience in ggplot is ignorable

Regards.
Greg

y1 y2 y3 y4
x1 -0.19 0.40 -0.06 0.13
x2 0.45 -0.75 -8.67 -0.46
x3 -0.09 0.14 1.42 0.06
x4 -0.16 -0.01 2.21 0.06


On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Example, example, example - preferably working.

Wild guess - did you try ggplot?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
> Sent: Thursday, February 8, 2018 8:14 AM
> To: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] plotting the regression coefficients
>
> Hi Dear all;
>
> I would like to create a plot for regression coefficients with each independent
> variable (x) along the side and the phenotypes (y) across the top (as given
> below). For each data point, direction and magnitude of effect could be color
> and significance could be the size of the circle? Is this possible?
>
>
> I would greatly be appreciated your help.
>
> Thanks,
>
> Greg
>
>
>
>   y1 y2 y3 y4 y5 y6
> x1
> x2
> x3
> x4
> x5
> x6
> x7
> x8
> x9
> x10
> x11
> x12
> x13
> x14
> x15
> x16
> x17
> .
> .
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From nourdinekabouch at yahoo.com  Thu Feb  8 11:01:11 2018
From: nourdinekabouch at yahoo.com (Kabouch Nourdine)
Date: Thu, 8 Feb 2018 10:01:11 +0000 (UTC)
Subject: [R] Information
References: <1447064283.910656.1518084071009.ref@mail.yahoo.com>
Message-ID: <1447064283.910656.1518084071009@mail.yahoo.com>

I have a time series of 1095 data corresponding to a daily data of three years.
I want to know how to use ma(timeserie, order=??, centre=??) to detect the trend:
which order is suitable and what is the difference between centre= true or false.

How to avoid these errors:
1-Error in timeserie - trend :
? argument non num?rique pour un op?rateur binaire="non-numeric argument for a binary operator"

timeserie:
??????? Mean
1??? 3874.000
2??? 3869.000
3??? 3885.000
.???? .
.???? .
.???? .
trend:
???????? [,1]
?? [1,]?????? NA
?? [2,]?????? NA
?? [3,]?????? NA
???? .??????? .
???? .??????? .
???? .??????? .
2-m = t(matrix(data = detrend, nrow = 30))
seasonal = colMeans(m, na.rm = T)
Error in colMeans(m, na.rm = T) : 'x' doit ?tre num?rique=" 'x' must be numeric"




	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Feb  8 11:52:14 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 8 Feb 2018 10:52:14 +0000
Subject: [R] Information
In-Reply-To: <1447064283.910656.1518084071009@mail.yahoo.com>
References: <1447064283.910656.1518084071009.ref@mail.yahoo.com>
 <1447064283.910656.1518084071009@mail.yahoo.com>
Message-ID: <9c557235d20e41c49f33e118bf82c55f@SRVEXCHCM1301.precheza.cz>

Hi

The errors are self explanatory. Function needs to be fed by numeric values.

What is the result of

str(m) or str(detrend)
Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kabouch
> Nourdine via R-help
> Sent: Thursday, February 8, 2018 11:01 AM
> To: r-help at r-project.org
> Subject: [R] Information
>
> I have a time series of 1095 data corresponding to a daily data of three years.
> I want to know how to use ma(timeserie, order=??, centre=??) to detect the
> trend:
> which order is suitable and what is the difference between centre= true or
> false.
>
> How to avoid these errors:
> 1-Error in timeserie - trend :
>   argument non num?rique pour un op?rateur binaire="non-numeric argument
> for a binary operator"
>
> timeserie:
>         Mean
> 1    3874.000
> 2    3869.000
> 3    3885.000
> .     .
> .     .
> .     .
> trend:
>          [,1]
>    [1,]       NA
>    [2,]       NA
>    [3,]       NA
>      .        .
>      .        .
>      .        .
> 2-m = t(matrix(data = detrend, nrow = 30))
> seasonal = colMeans(m, na.rm = T)
> Error in colMeans(m, na.rm = T) : 'x' doit ?tre num?rique=" 'x' must be numeric"
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bgunter.4567 at gmail.com  Thu Feb  8 13:29:34 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Feb 2018 04:29:34 -0800
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
Message-ID: <CAGxFJbTqtGzARTZiPOjv4sd9TnEp4cD0Na8PkCxvfooKdUsthg@mail.gmail.com>

Fwiw, encoding magnitude in color is generally a bad idea. Using area(*not*
radius) is also not great, but maybe it will work for you.

See here for some explanation:
https://www.amazon.com/Visual-Display-Quantitative-Information/dp/0961392142/ref=sr_1_1?s=books&ie=UTF8&qid=1518092778&sr=1-1&keywords=Tufte

Bert



On Feb 7, 2018 11:13 PM, "greg holly" <mak.hholly at gmail.com> wrote:

> Hi Dear all;
>
> I would like to create a plot for regression coefficients with each
> independent variable (x) along the side and the phenotypes (y) across the
> top (as given below). For each data point, direction and magnitude of
> effect could be color and significance could be the size of the circle? Is
> this possible?
>
>
> I would greatly be appreciated your help.
>
> Thanks,
>
> Greg
>
>
>
>   y1 y2 y3 y4 y5 y6
> x1
> x2
> x3
> x4
> x5
> x6
> x7
> x8
> x9
> x10
> x11
> x12
> x13
> x14
> x15
> x16
> x17
> .
> .
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Thu Feb  8 14:33:15 2018
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 8 Feb 2018 16:33:15 +0300
Subject: [R] plotting the regression coefficients
In-Reply-To: <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>

Hi Petr;

Thanks so much. Exactly this is what I need. I will play to change color
and so on but this backbound is perfect to me. I do appreciate your help
and support.

Regards,
Greg

On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> I copied your values to R, here it is
>
>
>
> > dput(temp)
>
>
>
> temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
>
> "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
>
>     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
>
>     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
>
> "y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
>
> -4L))
>
>
>
> For plotting it need to be reshaped
>
>
>
> library(reshape2)
>
> library(ggplot2)
>
>
>
> temp <- melt(temp)
>
> p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value),
> colour=factor(sign(value))))
>
> p+geom_point()
>
>
>
> Is this what you wanted?
>
>
>
> Cheers
>
> Petr
>
> And preferably do not post in HTML, the email content could be scrambled.
>
>
>
> *From:* greg holly [mailto:mak.hholly at gmail.com]
> *Sent:* Thursday, February 8, 2018 9:23 AM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* r-help mailing list <r-help at r-project.org>
> *Subject:* Re: [R] plotting the regression coefficients
>
>
>
> Hi Petr;
>
>
>
> Thanks for your reply. It is much appreciated. A small example is given
> below for 4 independent and 4 dependent variables only. The values given
> are regression coefficients.I have looked ggplot documents before writing
> to you. Unfortunately, I could not figure out as my experience in ggplot is
> ignorable
>
>
>
> Regards.
>
> Greg
>
>
>
> y1 y2 y3 y4
>
> x1 -0.19 0.40 -0.06 0.13
>
> x2 0.45 -0.75 -8.67 -0.46
>
> x3 -0.09 0.14 1.42 0.06
>
> x4 -0.16 -0.01 2.21 0.06
>
>
>
>
>
> On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Hi
>
> Example, example, example - preferably working.
>
> Wild guess - did you try ggplot?
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
> holly
> > Sent: Thursday, February 8, 2018 8:14 AM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] plotting the regression coefficients
> >
> > Hi Dear all;
> >
> > I would like to create a plot for regression coefficients with each
> independent
> > variable (x) along the side and the phenotypes (y) across the top (as
> given
> > below). For each data point, direction and magnitude of effect could be
> color
> > and significance could be the size of the circle? Is this possible?
> >
> >
> > I would greatly be appreciated your help.
> >
> > Thanks,
> >
> > Greg
> >
> >
> >
> >   y1 y2 y3 y4 y5 y6
> > x1
> > x2
> > x3
> > x4
> > x5
> > x6
> > x7
> > x8
> > x9
> > x10
> > x11
> > x12
> > x13
> > x14
> > x15
> > x16
> > x17
> > .
> > .
> >
>
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Thu Feb  8 14:34:49 2018
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 8 Feb 2018 16:34:49 +0300
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAGxFJbTqtGzARTZiPOjv4sd9TnEp4cD0Na8PkCxvfooKdUsthg@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <CAGxFJbTqtGzARTZiPOjv4sd9TnEp4cD0Na8PkCxvfooKdUsthg@mail.gmail.com>
Message-ID: <CAM9Qe4hV7cpYvkyEoo6US8Gy79666XxwfBMTTB=aqQNJc3C=Sw@mail.gmail.com>

Hi Bert;

Thanks so much for this. It is much appreciated.

Regards,
Greg

On Thu, Feb 8, 2018 at 3:29 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Fwiw, encoding magnitude in color is generally a bad idea. Using
> area(*not* radius) is also not great, but maybe it will work for you.
>
> See here for some explanation: https://www.amazon.com/Visual-Display-
> Quantitative-Information/dp/0961392142/ref=sr_1_1?s=books&
> ie=UTF8&qid=1518092778&sr=1-1&keywords=Tufte
>
> Bert
>
>
>
> On Feb 7, 2018 11:13 PM, "greg holly" <mak.hholly at gmail.com> wrote:
>
>> Hi Dear all;
>>
>> I would like to create a plot for regression coefficients with each
>> independent variable (x) along the side and the phenotypes (y) across the
>> top (as given below). For each data point, direction and magnitude of
>> effect could be color and significance could be the size of the circle? Is
>> this possible?
>>
>>
>> I would greatly be appreciated your help.
>>
>> Thanks,
>>
>> Greg
>>
>>
>>
>>   y1 y2 y3 y4 y5 y6
>> x1
>> x2
>> x3
>> x4
>> x5
>> x6
>> x7
>> x8
>> x9
>> x10
>> x11
>> x12
>> x13
>> x14
>> x15
>> x16
>> x17
>> .
>> .
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From paolo.pili at student.unife.it  Thu Feb  8 15:04:40 2018
From: paolo.pili at student.unife.it (PAOLO PILI)
Date: Thu, 8 Feb 2018 15:04:40 +0100
Subject: [R] plm package
Message-ID: <CAPNAnS-f0gASu98rCFzfCz_MEBfzEWg9K+frxOd9Qdx0x61FkQ@mail.gmail.com>

Hello,
I got a problem using package plm. When I give the command

"grun.fe<-plm(Y~X1+X2...+Xn, data=data, model="within")"

I got this answer:

"Error: cannot allocate vector of size 289.7 Gb".

The database that I am using is not so big, so I don't understand to what
it refers to.
Can you help me, please?
thank you! have a nice day

	[[alternative HTML version deleted]]


From edoardo.baldoni at gmail.com  Thu Feb  8 15:29:34 2018
From: edoardo.baldoni at gmail.com (Edoardo Baldoni)
Date: Thu, 8 Feb 2018 15:29:34 +0100
Subject: [R] plm package
In-Reply-To: <CAPNAnS-f0gASu98rCFzfCz_MEBfzEWg9K+frxOd9Qdx0x61FkQ@mail.gmail.com>
References: <CAPNAnS-f0gASu98rCFzfCz_MEBfzEWg9K+frxOd9Qdx0x61FkQ@mail.gmail.com>
Message-ID: <CAOcqoUOH_Z71UcFpxh6Arest8P+PpwdEde1rA4FE-GQXu_KcDg@mail.gmail.com>

Hi, maybe the function do not automatically understand, as well as you do,
what are the N and T dimensions of your panel data frame. You could try
using the index parameter of the function to specify your id and time
variables.

Edoardo

2018-02-08 15:04 GMT+01:00 PAOLO PILI <paolo.pili at student.unife.it>:

> Hello,
> I got a problem using package plm. When I give the command
>
> "grun.fe<-plm(Y~X1+X2...+Xn, data=data, model="within")"
>
> I got this answer:
>
> "Error: cannot allocate vector of size 289.7 Gb".
>
> The database that I am using is not so big, so I don't understand to what
> it refers to.
> Can you help me, please?
> thank you! have a nice day
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Feb  9 06:54:52 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 9 Feb 2018 05:54:52 +0000
Subject: [R] Information
In-Reply-To: <1777234275.997002.1518098492014@mail.yahoo.com>
References: <1447064283.910656.1518084071009.ref@mail.yahoo.com>
 <1447064283.910656.1518084071009@mail.yahoo.com>
 <9c557235d20e41c49f33e118bf82c55f@SRVEXCHCM1301.precheza.cz>
 <1777234275.997002.1518098492014@mail.yahoo.com>
Message-ID: <6cf74d5b35d74515983c1758e7856b6e@SRVEXCHCM1301.precheza.cz>

Hi
Copy your messages to r help, others may give you better advice.
Strange, I do not get such error. Beside, from
m = t(matrix(data = detrend, nrow = 30))
I expect matrix result, but your str shows that m is list.

> m<-list(a=rep(NA, 20), b=rep(1,20))
> colMeans(m, na.rm=T)
Error in colMeans(m, na.rm = T) :
  'x' must be an array of at least two dimensions
So as colMeans help page clearly states, it expects as input

an array of two or more dimensions, containing numeric, complex, integer or logical values, or a numeric data frame. For .colSums() etc, a numeric, integer or logical matrix (or vector of length m * n).

I fish in murky waters. If you fail to provide enogh information you cannot expect reasonable answer.

My guess is that your original data are not what you think they are.
Cheers
Petr

From: Kabouch Nourdine [mailto:nourdinekabouch at yahoo.com]
Sent: Thursday, February 8, 2018 3:02 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: RE: [R] Information

Hi
str(detrend)
'data.frame':   1095 obs. of  1 variable:
 $ Mean: num  NA NA NA NA NA NA NA NA NA NA ...

str(m)
List of 365
 $ : num [1:1095] NA NA NA NA NA NA NA NA NA NA ...
 $ : num [1:1095] NA NA NA NA NA NA NA NA NA NA ...
....................................................................................
$ : num [1:1095] NA NA NA NA NA NA NA NA NA NA ...
 $ : num [1:1095] NA NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
 - attr(*, "dim")= int [1:2] 1 365


On Thursday, February 8, 2018, 11:52:21 AM GMT+1, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:


Hi

The errors are self explanatory. Function needs to be fed by numeric values.

What is the result of

str(m) or str(detrend)
Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Kabouch
> Nourdine via R-help
> Sent: Thursday, February 8, 2018 11:01 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Information
>
> I have a time series of 1095 data corresponding to a daily data of three years.
> I want to know how to use ma(timeserie, order=??, centre=??) to detect the
> trend:
> which order is suitable and what is the difference between centre= true or
> false.
>
> How to avoid these errors:
> 1-Error in timeserie - trend :
>  argument non num?rique pour un op?rateur binaire="non-numeric argument
> for a binary operator"
>
> timeserie:
>        Mean
> 1    3874.000
> 2    3869.000
> 3    3885.000
> .    .
> .    .
> .    .
> trend:
>          [,1]
>    [1,]      NA
>    [2,]      NA
>    [3,]      NA
>      .        .
>      .        .
>      .        .
> 2-m = t(matrix(data = detrend, nrow = 30))
> seasonal = colMeans(m, na.rm = T)
> Error in colMeans(m, na.rm = T) : 'x' doit ?tre num?rique=" 'x' must be numeric"

>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Fri Feb  9 13:57:20 2018
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 9 Feb 2018 13:57:20 +0100
Subject: [R] Convolutional neural networks (CNN) - build a model and After?
Message-ID: <CALJKBv9k4gUpp+Oj2XWCNEZJsxHussJiqCKK4Xf0uv+vSBNoTQ@mail.gmail.com>

Hi,
I am learning CNN using MXNet R package. I am following this great tutorial
about olivetti_faces reconnaissance
<https://www.r-bloggers.com/image-recognition-tutorial-in-r-using-deep-convolutional-neural-networks-mxnet-package/>.

In the end after building model and testing the final score was 0.975.
It is great score but what can do after with this model?
How can use this model for other set on images?
Is it used to recognize which person in the training data or classify new
images if it content faces or not?
Thanks
Karim

	[[alternative HTML version deleted]]


From Marios.BARLAS at cea.fr  Fri Feb  9 15:05:22 2018
From: Marios.BARLAS at cea.fr (BARLAS Marios 247554)
Date: Fri, 9 Feb 2018 14:05:22 +0000
Subject: [R] Optim function returning always initial value for parameter to
 be optimized
Message-ID: <01BFC0B2B4ABFC4CB432008F852D76610D5CB97A@EXDAG0-A1.intra.cea.fr>

Hello,

I'm trying to fminimize the following problem:

You have a data frame with 2 columns.

data.input= data.frame(state1 = (1:500), state2 = (201:700) )

with data that partially overlap in terms of values. 

I want to minimize the assessment error of each state by using this function:

err.th.scalar <- function(threshold, data){
  
  state1 <- data$state1
  state2 <- data$state2
  
  op1l <- length(state1)
  op2l <- length(state2)
  
  op1.err <- sum(state1 <= threshold)/op1l
  op2.err <- sum(state2 >= threshold)/op2l
  
  total.err <- (op1.err + op2.err)

  return(total.err)
}


SO I'm trying to minimize the total error. This Total Error should be a U shape essentially.


I'm using optim as follows: 

optim(par = 300, fn=err.th.scalar, data = data.input, method = "BFGS")

For some reason that's driving me crazy, in the first trial it worked but right now the output of optim for the parameter to get optimized is EXACTLY the same as the initial estimate whatever the initial estimate value is. 

Please, any ideas why ? 

I can't see the error at this moment.


Thanks in advance,
Marios Barlas

From profjcnash at gmail.com  Fri Feb  9 15:29:58 2018
From: profjcnash at gmail.com (ProfJCNash)
Date: Fri, 9 Feb 2018 09:29:58 -0500
Subject: [R] 
 Optim function returning always initial value for parameter to
 be optimized
In-Reply-To: <01BFC0B2B4ABFC4CB432008F852D76610D5CB97A@EXDAG0-A1.intra.cea.fr>
References: <01BFC0B2B4ABFC4CB432008F852D76610D5CB97A@EXDAG0-A1.intra.cea.fr>
Message-ID: <8a055f5f-e876-1598-6947-a310030c3b01@gmail.com>

Did you check the gradient? I don't think so. It's zero, so of course
you end up where you start.

Try

data.input= data.frame(state1 = (1:500), state2 = (201:700) )
err.th.scalar <- function(threshold, data){

    state1 <- data$state1
    state2 <- data$state2

    op1l <- length(state1)
    op2l <- length(state2)

    op1.err <- sum(state1 <= threshold)/op1l
    op2.err <- sum(state2 >= threshold)/op2l

    total.err <- (op1.err + op2.err)

    return(total.err)
}

soln <- optim(par = 300, fn=err.th.scalar, data = data.input, method =
"BFGS")
soln
require("numDeriv")
gtest <- grad(err.th.scalar, x=300, data = data.input)
gtest


On 2018-02-09 09:05 AM, BARLAS Marios 247554 wrote:
> data.input= data.frame(state1 = (1:500), state2 = (201:700) )
> 
> with data that partially overlap in terms of values. 
> 
> I want to minimize the assessment error of each state by using this function:
> 
> err.th.scalar <- function(threshold, data){
>   
>   state1 <- data$state1
>   state2 <- data$state2
>   
>   op1l <- length(state1)
>   op2l <- length(state2)
>   
>   op1.err <- sum(state1 <= threshold)/op1l
>   op2.err <- sum(state2 >= threshold)/op2l
>   
>   total.err <- (op1.err + op2.err)
> 
>   return(total.err)
> }
> 
> 
> SO I'm trying to minimize the total error. This Total Error should be a U shape essentially.
> 
> 
> I'm using optim as follows: 
> 
> optim(par = 300, fn=err.th.scalar, data = data.input, method = "BFGS")


Maybe develop an analytic gradient if it is very small, as the numeric
approximation can then be zero even when the true gradient is not.

JN


From chiara.malavasi at live.it  Fri Feb  9 16:36:35 2018
From: chiara.malavasi at live.it (Chiara Malavasi)
Date: Fri, 9 Feb 2018 15:36:35 +0000
Subject: [R] Covariates in fuzzy RDD with rddtools
Message-ID: <HE1PR07MB07799FFC2FA34C184D32B242EDF20@HE1PR07MB0779.eurprd07.prod.outlook.com>

Hello!
I am having trouble including covariates in a fuzzy RDD model in R with rddtools. I run the following commands:

    library(rddtools)

    data.complete2 <- as.data.frame(cbind(GDPpc.rel, GR.rate, fitval.firstStage)) colnames(data.complete2) <- c("GDPpc.rel", "GR.rate", "FitTreat")

    data.RDD<-rdd_data(x=data.complete2$GDPpc.rel, y=data.complete2$GR.rate, z=data.complete2$FitTreat, covar=dummytime, cutpoint = 0.75)
    data.RDD1<-rdd_data(x=data.complete2$GDPpc.rel, y=data.complete2$GR.rate, z=data.complete2$FitTreat, covar=cbind(dummytime, dummyreg), cutpoint = 0.75)

    reg_para <- rdd_reg_lm(rdd_object=data.RDD, covar.opt = list(strategy= "include"), order = 4)
    reg_para1 <- rdd_reg_lm(rdd_object=data.RDD1,  covar.opt = list(strategy = "include"), order = 4)

where dummytime and dummyreg are two dummy variables considering time and regional effects.

The problem is that looking at the summary of the two regressions, they seem to be exactly the same and the coefficient which should refer to the dummy variables is not reported. My guess is that I did not actually implement the covariates in the regression, but I cannot understand where is the problem. Any suggestion?

Thank you in advance.

Best regards,

Chiara Malavasi


	[[alternative HTML version deleted]]


From ycding at coh.org  Sat Feb 10 05:43:03 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Sat, 10 Feb 2018 04:43:03 +0000
Subject: [R] please help me a little
Message-ID: <A86C6438FB909A409DDEF926277952B6A67371@PPWEXCH2KX14.coh.org>

Hi R Users,

I am very frustrated with the following code. Please do me a favor to run it.

after reading into the test data set (I also pasted the data set below), the first line of code for "res_coxphf" did not work and generated the error code below. but the other three line worked well.   the second line for "res_coxphf2" should be the same as the first line; I need to run more than 100 variables in a loop, so I want to do test[, i], that is why I want to use the first line.

however, the fourth line for "res_coxphf_cnaRate " also worked well after I added one variable "cna.rate" to first line. Can you run them and tell me why the first line does not run correctly?

please install coxphf package if you do not have it installed.

Thank you very much!!!

Ding

test<-read.csv("data_coxphf.csv", head=T)
res_coxphf <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~test[, 6], data=test)
res_coxphf2 <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ test$FAM138A.chr1, data=test)

res_coxph <- coxph(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ test[, 6], data=test)
res_coxphf_cnaRate <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ test[, 6]+ cna.rate, data=test)


> test<-read.csv("data_coxphf.csv", head=T)
> res_coxphf <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ test[, 6], data=test)
Error in mm1[, !colInter, drop = FALSE] :
  (subscript) logical subscript too long
> res_coxph <- coxph(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ test[, 6], data=test)
> res_coxphf_cnaRate <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ test[, 6]+ cna.rate, data=test)
> res_coxphf2 <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~ test$FAM138A.chr1, data=test)
>



id      cna.rate        RFS_days2       OV_Had_a_Recurrence_CODE        DDX11L1.chr1    FAM138A.chr1    FAM138F.chr1
sn1     150     560     1       0       0       0
sn10    216     581     1       0       0       0
sn11    191     455     1       0       0       0
sn12    135     118     1       0       0       0
sn13    199     2550    0       0       0       0
sn14    312     477     1       0       0       0
sn15    260     216     1       0       0       0
sn16    400     1056    1       0       0       0
sn17    350     398     1       1       1       1
sn18    324     583     1       0       0       0
sn19    174     136     1       0       0       0
sn20    262     98      1       0       0       0
sn21    172     516     1       0       0       0
sn22    490     1439    1       0       0       0
sn23    165     365     1       0       0       0
sn24    185     168     1       0       0       0
sn25    396     1663    1       0       0       0
sn26    240     299     1       0       0       0
sn27    114     2917    0       0       0       0
sn28    128     50      1       0       0       0
sn29    190     654     1       0       0       0
sn3     435     429     1       0       0       0
sn30    268     31      1       0       0       0
sn31    175     3407    0       0       0       0
sn32    248     277     1       0       0       0
sn33    116     306     1       0       0       0
sn34    122     52      1       0       0       0
sn35    222     77      1       0       0       0
sn36    414     242     1       0       0       0
sn37    300     1034    1       1       1       1
sn38    268     3298    0       0       0       0
sn4     556     2424    0       0       0       0
sn40    274     201     1       0       0       0
sn41    267     268     1       0       0       0
sn42    325     147     1       0       0       0
sn43    323     2611    0       0       0       0
sn44    115     573     1       0       0       0
sn45    265     215     1       0       0       0
sn48    129     259     1       0       0       0
sn5     114     183     1       0       0       0
sn51    183     219     1       0       0       0
sn52    314     271     1       0       0       0
sn53    465     2071    0       0       0       0
sn54    207     44      1       0       0       0
sn55    321     347     1       0       0       0
sn56    217     1257    0       0       0       0
sn57    209     262     1       0       0       0
sn58    227     1811    0       0       0       0
sn59    130     463     1       0       0       0
sn6     320     306     1       0       0       0
sn60    136     456     1       0       0       0
sn62    208     48      1       0       0       0
sn63    253     452     1       0       0       0
sn64    326     282     1       0       0       0
sn67    260     229     1       0       0       0
sn68    329     661     0       0       0       0
sn69    478     44      1       0       0       0
sn7     263     582     1       0       0       0
sn70    309     741     1       0       0       0
sn8     223     1070    0       0       0       0
sn9     211     216     1       0       0       0


---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
---------------------------------------------------------------------


From mashranga at yahoo.com  Sat Feb 10 06:22:06 2018
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sat, 10 Feb 2018 05:22:06 +0000 (UTC)
Subject: [R] How  to label a polygon window (spatstat package)
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F471ED8D1@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F471ED85C@ESINO.regionemarche.intra>
 <B68F2E32-0A2F-449A-9E70-D3A3B9E99CF4@bigelow.org>
 <8B435C9568170B469AE31E8891E8CC4F471ED8D1@ESINO.regionemarche.intra>
Message-ID: <1994625069.35610.1518240126102@mail.yahoo.com>

Hi,?
I want to label a polygon (circle or polygon) inside.
As for example code?

library(spatstat)
x <- runif(20)
y <- runif(20)
X <- ppp(x, y, window=disc(0.7))
plot(X)

Now I want to label that circle inside . Can some one please help me ??
Thanks.?

Regards.............
Tanvir Ahamed 
Stockholm, Sweden???? |??mashranga at yahoo.com


From mdsumner at gmail.com  Sat Feb 10 06:35:46 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 10 Feb 2018 05:35:46 +0000
Subject: [R] How to label a polygon window (spatstat package)
In-Reply-To: <1994625069.35610.1518240126102@mail.yahoo.com>
References: <8B435C9568170B469AE31E8891E8CC4F471ED85C@ESINO.regionemarche.intra>
 <B68F2E32-0A2F-449A-9E70-D3A3B9E99CF4@bigelow.org>
 <8B435C9568170B469AE31E8891E8CC4F471ED8D1@ESINO.regionemarche.intra>
 <1994625069.35610.1518240126102@mail.yahoo.com>
Message-ID: <CAAcGz99_8wMqgL_OZkMYNLqS7rN81Xu2FP1Q+Xp3OPTySD8Ezg@mail.gmail.com>

Try

text(0.5, 0.5, label = "?text")

On Sat, 10 Feb 2018, 16:22 Mohammad Tanvir Ahamed via R-help, <
r-help at r-project.org> wrote:

> Hi,
> I want to label a polygon (circle or polygon) inside.
> As for example code
>
> library(spatstat)
> x <- runif(20)
> y <- runif(20)
> X <- ppp(x, y, window=disc(0.7))
> plot(X)
>
> Now I want to label that circle inside . Can some one please help me ?
> Thanks.
>
> Regards.............
> Tanvir Ahamed
> Stockholm, Sweden     |  mashranga at yahoo.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Sat Feb 10 06:43:23 2018
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sat, 10 Feb 2018 05:43:23 +0000 (UTC)
Subject: [R] How to label a polygon window (spatstat package)
In-Reply-To: <CAAcGz99_8wMqgL_OZkMYNLqS7rN81Xu2FP1Q+Xp3OPTySD8Ezg@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F471ED85C@ESINO.regionemarche.intra>
 <B68F2E32-0A2F-449A-9E70-D3A3B9E99CF4@bigelow.org>
 <8B435C9568170B469AE31E8891E8CC4F471ED8D1@ESINO.regionemarche.intra>
 <1994625069.35610.1518240126102@mail.yahoo.com>
 <CAAcGz99_8wMqgL_OZkMYNLqS7rN81Xu2FP1Q+Xp3OPTySD8Ezg@mail.gmail.com>
Message-ID: <992571113.52593.1518241403716@mail.yahoo.com>

Thanks.
when there is multiple polygon , it a problem .
looking for something more .

Regards.............
Tanvir Ahamed 
Stockholm, Sweden???? |??mashranga at yahoo.com 






On Saturday, February 10, 2018, 6:35:59 AM GMT+1, Michael Sumner <mdsumner at gmail.com> wrote: 





Try

text(0.5, 0.5, label = "?text") 

On Sat, 10 Feb 2018, 16:22 Mohammad Tanvir Ahamed via R-help, <r-help at r-project.org> wrote:
> Hi,?
> I want to label a polygon (circle or polygon) inside.
> As for example code?
> 
> library(spatstat)
> x <- runif(20)
> y <- runif(20)
> X <- ppp(x, y, window=disc(0.7))
> plot(X)
> 
> Now I want to label that circle inside . Can some one please help me ??
> Thanks.?
> 
> Regards.............
> Tanvir Ahamed
> Stockholm, Sweden???? |??mashranga at yahoo.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia


From jdnewmil at dcn.davis.ca.us  Sat Feb 10 06:58:56 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 09 Feb 2018 21:58:56 -0800
Subject: [R] please help me a little
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A67371@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A67371@PPWEXCH2KX14.coh.org>
Message-ID: <E75F319A-E553-4630-845B-1E95A8742C6A@dcn.davis.ca.us>

I don't use coxphf, but it is generally a bad idea to reference variables via multiple environments (e.g. global and the data= argument in this case) directly from within a formula. Just use FAM138A.chr wherever you have used test[,6] and it should work. 
-- 
Sent from my phone. Please excuse my brevity.

On February 9, 2018 8:43:03 PM PST, "Ding, Yuan Chun" <ycding at coh.org> wrote:
>Hi R Users,
>
>I am very frustrated with the following code. Please do me a favor to
>run it.
>
>after reading into the test data set (I also pasted the data set
>below), the first line of code for "res_coxphf" did not work and
>generated the error code below. but the other three line worked well.  
>the second line for "res_coxphf2" should be the same as the first line;
>I need to run more than 100 variables in a loop, so I want to do test[,
>i], that is why I want to use the first line.
>
>however, the fourth line for "res_coxphf_cnaRate " also worked well
>after I added one variable "cna.rate" to first line. Can you run them
>and tell me why the first line does not run correctly?
>
>please install coxphf package if you do not have it installed.
>
>Thank you very much!!!
>
>Ding
>
>test<-read.csv("data_coxphf.csv", head=T)
>res_coxphf <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE)
>~test[, 6], data=test)
>res_coxphf2 <- coxphf(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE)
>~ test$FAM138A.chr1, data=test)
>
>res_coxph <- coxph(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE) ~
>test[, 6], data=test)
>res_coxphf_cnaRate <- coxphf(formula=Surv(RFS_days2,
>OV_Had_a_Recurrence_CODE) ~ test[, 6]+ cna.rate, data=test)
>
>
>> test<-read.csv("data_coxphf.csv", head=T)
>> res_coxphf <- coxphf(formula=Surv(RFS_days2,
>OV_Had_a_Recurrence_CODE) ~ test[, 6], data=test)
>Error in mm1[, !colInter, drop = FALSE] :
>  (subscript) logical subscript too long
>> res_coxph <- coxph(formula=Surv(RFS_days2, OV_Had_a_Recurrence_CODE)
>~ test[, 6], data=test)
>> res_coxphf_cnaRate <- coxphf(formula=Surv(RFS_days2,
>OV_Had_a_Recurrence_CODE) ~ test[, 6]+ cna.rate, data=test)
>> res_coxphf2 <- coxphf(formula=Surv(RFS_days2,
>OV_Had_a_Recurrence_CODE) ~ test$FAM138A.chr1, data=test)
>>
>
>
>
>id      cna.rate        RFS_days2       OV_Had_a_Recurrence_CODE       
>DDX11L1.chr1    FAM138A.chr1    FAM138F.chr1
>sn1     150     560     1       0       0       0
>sn10    216     581     1       0       0       0
>sn11    191     455     1       0       0       0
>sn12    135     118     1       0       0       0
>sn13    199     2550    0       0       0       0
>sn14    312     477     1       0       0       0
>sn15    260     216     1       0       0       0
>sn16    400     1056    1       0       0       0
>sn17    350     398     1       1       1       1
>sn18    324     583     1       0       0       0
>sn19    174     136     1       0       0       0
>sn20    262     98      1       0       0       0
>sn21    172     516     1       0       0       0
>sn22    490     1439    1       0       0       0
>sn23    165     365     1       0       0       0
>sn24    185     168     1       0       0       0
>sn25    396     1663    1       0       0       0
>sn26    240     299     1       0       0       0
>sn27    114     2917    0       0       0       0
>sn28    128     50      1       0       0       0
>sn29    190     654     1       0       0       0
>sn3     435     429     1       0       0       0
>sn30    268     31      1       0       0       0
>sn31    175     3407    0       0       0       0
>sn32    248     277     1       0       0       0
>sn33    116     306     1       0       0       0
>sn34    122     52      1       0       0       0
>sn35    222     77      1       0       0       0
>sn36    414     242     1       0       0       0
>sn37    300     1034    1       1       1       1
>sn38    268     3298    0       0       0       0
>sn4     556     2424    0       0       0       0
>sn40    274     201     1       0       0       0
>sn41    267     268     1       0       0       0
>sn42    325     147     1       0       0       0
>sn43    323     2611    0       0       0       0
>sn44    115     573     1       0       0       0
>sn45    265     215     1       0       0       0
>sn48    129     259     1       0       0       0
>sn5     114     183     1       0       0       0
>sn51    183     219     1       0       0       0
>sn52    314     271     1       0       0       0
>sn53    465     2071    0       0       0       0
>sn54    207     44      1       0       0       0
>sn55    321     347     1       0       0       0
>sn56    217     1257    0       0       0       0
>sn57    209     262     1       0       0       0
>sn58    227     1811    0       0       0       0
>sn59    130     463     1       0       0       0
>sn6     320     306     1       0       0       0
>sn60    136     456     1       0       0       0
>sn62    208     48      1       0       0       0
>sn63    253     452     1       0       0       0
>sn64    326     282     1       0       0       0
>sn67    260     229     1       0       0       0
>sn68    329     661     0       0       0       0
>sn69    478     44      1       0       0       0
>sn7     263     582     1       0       0       0
>sn70    309     741     1       0       0       0
>sn8     223     1070    0       0       0       0
>sn9     211     216     1       0       0       0
>
>
>---------------------------------------------------------------------
>-SECURITY/CONFIDENTIALITY WARNING-
>This message (and any attachments) are intended solely ...{{dropped:28}}


From pgilbert902 at gmail.com  Sat Feb 10 16:58:26 2018
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sat, 10 Feb 2018 10:58:26 -0500
Subject: [R] 
 Optim function returning always initial value for parameter to
 be optimized
In-Reply-To: <mailman.348460.1.1518260401.30253.r-help@r-project.org>
References: <mailman.348460.1.1518260401.30253.r-help@r-project.org>
Message-ID: <f4e81a12-4f23-1064-9d43-b687c693646a@gmail.com>



On 02/10/2018 06:00 AM, r-help-request at r-project.org wrote:
> Did you check the gradient? I don't think so. It's zero, so of course
> you end up where you start.
> 
> Try
> 
> data.input= data.frame(state1 = (1:500), state2 = (201:700) )
> err.th.scalar <- function(threshold, data){
> 
>      state1 <- data$state1
>      state2 <- data$state2
> 
>      op1l <- length(state1)
>      op2l <- length(state2)
> 
>      op1.err <- sum(state1 <= threshold)/op1l
>      op2.err <- sum(state2 >= threshold)/op2l

I think this function is not smooth, and not even continuous. Gradient 
methods require differentiable (smooth) functions. A numerical 
approximation will be zero unless you are right near a jump point, so 
you are unlikely to move from your initial guess.

Paul
> 
>      total.err <- (op1.err + op2.err)
> 
>      return(total.err)
> }
> 
> soln <- optim(par = 300, fn=err.th.scalar, data = data.input, method =
> "BFGS")
> soln
> require("numDeriv")
> gtest <- grad(err.th.scalar, x=300, data = data.input)
> gtest
> 
> 
> On 2018-02-09 09:05 AM, BARLAS Marios 247554 wrote:
>> data.input= data.frame(state1 = (1:500), state2 = (201:700) )
>>
>> with data that partially overlap in terms of values.
>>
>> I want to minimize the assessment error of each state by using this function:
>>
>> err.th.scalar <- function(threshold, data){
>>    
>>    state1 <- data$state1
>>    state2 <- data$state2
>>    
>>    op1l <- length(state1)
>>    op2l <- length(state2)
>>    
>>    op1.err <- sum(state1 <= threshold)/op1l
>>    op2.err <- sum(state2 >= threshold)/op2l
>>    
>>    total.err <- (op1.err + op2.err)
>>
>>    return(total.err)
>> }
>>
>>
>> SO I'm trying to minimize the total error. This Total Error should be a U shape essentially.
>>
>>
>> I'm using optim as follows:
>>
>> optim(par = 300, fn=err.th.scalar, data = data.input, method = "BFGS")
> 
> Maybe develop an analytic gradient if it is very small, as the numeric
> approximation can then be zero even when the true gradient is not.
> 
> JN
> 
>


From mak.hholly at gmail.com  Sat Feb 10 21:04:30 2018
From: mak.hholly at gmail.com (greg holly)
Date: Sat, 10 Feb 2018 23:04:30 +0300
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
Message-ID: <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>

Hi Peter;

The R code you provided works very well. Once again thanks so much for
this. The number of variables in my data set that should appear on the
y-axis is 733 and they are not numerical (for example the name of one
variable is *palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]**. So, the
plot looks very messy in one page. How can I make the plot to print out on
multiple pages?

Regards,

Greg

On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com> wrote:

> Hi Petr;
>
> Thanks so much. Exactly this is what I need. I will play to change color
> and so on but this backbound is perfect to me. I do appreciate your help
> and support.
>
> Regards,
> Greg
>
> On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> I copied your values to R, here it is
>>
>>
>>
>> > dput(temp)
>>
>>
>>
>> temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
>>
>> "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
>>
>>     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
>>
>>     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
>>
>> "y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
>>
>> -4L))
>>
>>
>>
>> For plotting it need to be reshaped
>>
>>
>>
>> library(reshape2)
>>
>> library(ggplot2)
>>
>>
>>
>> temp <- melt(temp)
>>
>> p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value),
>> colour=factor(sign(value))))
>>
>> p+geom_point()
>>
>>
>>
>> Is this what you wanted?
>>
>>
>>
>> Cheers
>>
>> Petr
>>
>> And preferably do not post in HTML, the email content could be scrambled.
>>
>>
>>
>> *From:* greg holly [mailto:mak.hholly at gmail.com]
>> *Sent:* Thursday, February 8, 2018 9:23 AM
>> *To:* PIKAL Petr <petr.pikal at precheza.cz>
>> *Cc:* r-help mailing list <r-help at r-project.org>
>> *Subject:* Re: [R] plotting the regression coefficients
>>
>>
>>
>> Hi Petr;
>>
>>
>>
>> Thanks for your reply. It is much appreciated. A small example is given
>> below for 4 independent and 4 dependent variables only. The values given
>> are regression coefficients.I have looked ggplot documents before writing
>> to you. Unfortunately, I could not figure out as my experience in ggplot is
>> ignorable
>>
>>
>>
>> Regards.
>>
>> Greg
>>
>>
>>
>> y1 y2 y3 y4
>>
>> x1 -0.19 0.40 -0.06 0.13
>>
>> x2 0.45 -0.75 -8.67 -0.46
>>
>> x3 -0.09 0.14 1.42 0.06
>>
>> x4 -0.16 -0.01 2.21 0.06
>>
>>
>>
>>
>>
>> On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz>
>> wrote:
>>
>> Hi
>>
>> Example, example, example - preferably working.
>>
>> Wild guess - did you try ggplot?
>>
>> Cheers
>> Petr
>>
>>
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
>> holly
>> > Sent: Thursday, February 8, 2018 8:14 AM
>> > To: r-help mailing list <r-help at r-project.org>
>> > Subject: [R] plotting the regression coefficients
>> >
>> > Hi Dear all;
>> >
>> > I would like to create a plot for regression coefficients with each
>> independent
>> > variable (x) along the side and the phenotypes (y) across the top (as
>> given
>> > below). For each data point, direction and magnitude of effect could be
>> color
>> > and significance could be the size of the circle? Is this possible?
>> >
>> >
>> > I would greatly be appreciated your help.
>> >
>> > Thanks,
>> >
>> > Greg
>> >
>> >
>> >
>> >   y1 y2 y3 y4 y5 y6
>> > x1
>> > x2
>> > x3
>> > x4
>> > x5
>> > x6
>> > x7
>> > x8
>> > x9
>> > x10
>> > x11
>> > x12
>> > x13
>> > x14
>> > x15
>> > x16
>> > x17
>> > .
>> > .
>> >
>>
>> > [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>> strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to
>> enter into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>>
>>
>> ------------------------------
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>> strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to
>> enter into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>
>

	[[alternative HTML version deleted]]


From paolo.pili at student.unife.it  Sun Feb 11 13:18:34 2018
From: paolo.pili at student.unife.it (PAOLO PILI)
Date: Sun, 11 Feb 2018 13:18:34 +0100
Subject: [R] Hausman test
Message-ID: <CAPNAnS_otGG3ofshpa90erk_oo-_KxRkU-ZTxpXefqEvOxRmkw@mail.gmail.com>

Hello,

I have a problem with Hausman test. I am performing my analysis with these
commands:

> library(plm)
> data<-read.csv2("paolo.csv",header=TRUE)
> data<
pdata.frame(data,index=c("FIRM","YEAR"),drop.index=TRUE,row.names=TRUE)
>
RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+TURN+GPROF+GPROF2
>
grun.fe<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
> grun.re
<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="random")
>
gw<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
>
gr<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="random")
> phtest(gw,gr)

I got this answer:

Error in solve.default(dvcov) :

how can I solve this problem?

Thank you

	[[alternative HTML version deleted]]


From thomas.mailund at gmail.com  Sun Feb 11 16:48:40 2018
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Sun, 11 Feb 2018 16:48:40 +0100
Subject: [R] Parallel assignments and goto
Message-ID: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>

Hi guys,

I am working on some code for automatically translating recursive functions into looping functions to implemented tail-recursion optimisations. See https://github.com/mailund/tailr

As a toy-example, consider the factorial function

factorial <- function(n, acc = 1) {
    if (n <= 1) acc
    else factorial(n - 1, acc * n)
}

I can automatically translate this into the loop-version

factorial_tr_1 <- function (n, acc = 1) 
{
    repeat {
        if (n <= 1) 
            return(acc)
        else {
            .tailr_n <- n - 1
            .tailr_acc <- acc * acc
            n <- .tailr_n
            acc <- .tailr_acc
            next
        }
    }
}

which will run faster and not have problems with recursion depths. However, I?m not entirely happy with this version for two reasons: I am not happy with introducing the temporary variables and this rewrite will not work if I try to over-scope an evaluation context.

I have two related questions, one related to parallel assignments ? i.e. expressions to variables so the expression uses the old variable values and not the new values until the assignments are all done ? and one related to restarting a loop from nested loops or from nested expressions in `with` expressions or similar.

I can implement parallel assignment using something like rlang::env_bind:

factorial_tr_2 <- function (n, acc = 1) 
{
    .tailr_env <- rlang::get_env()
    repeat {
        if (n <= 1) 
            return(acc)
        else {
            rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
            next
        }
    }
}

This reduces the number of additional variables I need to one, but is a couple of orders of magnitude slower than the first version.

> microbenchmark::microbenchmark(factorial(100),
+                                factorial_tr_1(100),
+                                factorial_tr_2(100))
Unit: microseconds
                     expr      min       lq       mean    median       uq      max neval
      factorial(100)   53.978   60.543   77.76203   71.0635   85.947  180.251   100
 factorial_tr_1(100)    9.022    9.903   11.52563   11.0430   11.984   28.464   100
 factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463 8177.635   100


Is there another way to do parallel assignments that doesn?t cost this much in running time?

My other problem is the use of `next`. I would like to combine tail-recursion optimisation with pattern matching as in https://github.com/mailund/pmatch where I can, for example, define a linked list like this:

devtools::install_github("mailund/pmatch?)
library(pmatch)
llist := NIL | CONS(car, cdr : llist)

and define a function for computing the length of a list like this:

list_length <- function(lst, acc = 0) {
  force(acc)
  cases(lst,
        NIL -> acc,
        CONS(car, cdr) -> list_length(cdr, acc + 1))
}

The `cases` function creates an environment that binds variables in a pattern-description that over-scopes the expression to the right of `->`, so the recursive call in this example have access to the variables `cdr` and `car`.

I can transform a `cases` call to one that creates the environment containing the bound variables and then evaluate this using `eval` or `with`, but in either case, a call to `next` will not work in such a context. The expression will be evaluated inside `bind` or `with`, and not in the `list_lenght` function.

A version that *will* work, is something like this

factorial_tr_3 <- function (n, acc = 1) 
{
    .tailr_env <- rlang::get_env()
    .tailr_frame <- rlang::current_frame()
    repeat {
        if (n <= 1) 
            rlang::return_from(.tailr_frame, acc)
        else {
            rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
            rlang::return_to(.tailr_frame)
        }
    }
}

Here, again, for the factorial function since this is easier to follow than the list-length function.

This solution will also work if you return values from inside loops, where `next` wouldn?t work either.

Using `rlang::return_from` and `rlang::return_to` implements the right semantics, but costs me another order of magnitude in running time.

microbenchmark::microbenchmark(factorial(100),
                               factorial_tr_1(100),
                               factorial_tr_2(100),
                               factorial_tr_3(100))
Unit: microseconds
                expr       min         lq        mean     median        uq        max neval
      factorial(100)    52.479    60.2640    93.43069    67.5130    83.925   2062.481   100
 factorial_tr_1(100)     8.875     9.6525    49.19595    10.6945    11.217   3818.823   100
 factorial_tr_2(100)  5296.350  5525.0745  5973.77664  5737.8730  6260.128   8471.301   100
 factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725 89859.169 171039.228   100

I can live with the ?introducing extra variables? solution to parallel assignment, and I could hack my way out of using `with` or `bind` in rewriting `cases`, but restarting a `repeat` loop would really make for a nicer solution. I know that `goto` is considered harmful, but really, in this case, it is what I want.

A `callCC` version also solves the problem

factorial_tr_4 <- function(n, acc = 1) {
    function_body <- function(continuation) {
        if (n <= 1) {
            continuation(acc)
        } else {
            continuation(list("continue", n = n - 1, acc = acc * n))
        }
    }
    repeat {
        result <- callCC(function_body)
        if (is.list(result) && result[[1]] == "continue") {
            n <- result$n
            acc <- result$acc
            next
        } else {
            return(result)
        }
    }
}

But this requires that I know how to distinguish between a valid return value and a tag for ?next? and is still a lot slower than the `next` solution

microbenchmark::microbenchmark(factorial(100),
                               factorial_tr_1(100),
                               factorial_tr_2(100),
                               factorial_tr_3(100),
                               factorial_tr_4(100))
Unit: microseconds
                expr       min         lq        mean     median        uq        max neval
      factorial(100)    54.109    61.8095    81.33167    81.8785    89.748    243.554   100
 factorial_tr_1(100)     9.025     9.9035    11.38607    11.1990    12.008     22.375   100
 factorial_tr_2(100)  5272.524  5798.3965  6302.40467  6077.7180  6492.959   9967.237   100
 factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665 75405.054 203785.673   100
 factorial_tr_4(100)   270.978   302.7890   337.48763   313.9930   334.096   1425.702   100

I don?t necessarily need the tail-recursion optimisation to be faster than the recursive version; just getting out of the problem of too deep recursions is a benefit, but I would rather not pay with an order of magnitude for it. I could, of course, try to handle cases that works with `next` in one way, and other cases using `callCC`, but I feel it should be possible with a version that handles all cases the same way.

Is there any way to achieve this?

Cheers
	Thomas


From bgunter.4567 at gmail.com  Sun Feb 11 16:54:31 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 11 Feb 2018 07:54:31 -0800
Subject: [R] Hausman test
In-Reply-To: <CAPNAnS_otGG3ofshpa90erk_oo-_KxRkU-ZTxpXefqEvOxRmkw@mail.gmail.com>
References: <CAPNAnS_otGG3ofshpa90erk_oo-_KxRkU-ZTxpXefqEvOxRmkw@mail.gmail.com>
Message-ID: <CAGxFJbQvd33z50QPMcLJCnLhmgfV6-iHA-FS4CQwPW=BrFDeKQ@mail.gmail.com>

Note the typo in your 3rd line: data <

Don't  know if this means anything...

Bert



On Feb 11, 2018 7:33 AM, "PAOLO PILI" <paolo.pili at student.unife.it> wrote:

> Hello,
>
> I have a problem with Hausman test. I am performing my analysis with these
> commands:
>
> > library(plm)
> > data<-read.csv2("paolo.csv",header=TRUE)
> > data<
> pdata.frame(data,index=c("FIRM","YEAR"),drop.index=TRUE,row.names=TRUE)
> >
> RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+
> TURN+GPROF+GPROF2
> >
> grun.fe<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+
> PGROWTH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
> > grun.re
> <-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+
> NGROWTH+TURN+GPROF+GPROF2,data=data,model="random")
> >
> gw<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+
> PGROWTH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
> >
> gr<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+
> PGROWTH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="random")
> > phtest(gw,gr)
>
> I got this answer:
>
> Error in solve.default(dvcov) :
>
> how can I solve this problem?
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From paolo.pili at student.unife.it  Sun Feb 11 17:29:57 2018
From: paolo.pili at student.unife.it (PAOLO PILI)
Date: Sun, 11 Feb 2018 17:29:57 +0100
Subject: [R] Hausman test
In-Reply-To: <CAGxFJbQvd33z50QPMcLJCnLhmgfV6-iHA-FS4CQwPW=BrFDeKQ@mail.gmail.com>
References: <CAPNAnS_otGG3ofshpa90erk_oo-_KxRkU-ZTxpXefqEvOxRmkw@mail.gmail.com>
 <CAGxFJbQvd33z50QPMcLJCnLhmgfV6-iHA-FS4CQwPW=BrFDeKQ@mail.gmail.com>
Message-ID: <CAPNAnS80vOHG9zjru3aWN9wxieE98azvVDOjn2sRtShEbdud4A@mail.gmail.com>

you are right about the 3rd line but it doesn't help me for my problem. I
remove the 3rd line but there is still the same problem:

Error in solve.default (dvcov):
   the system is numerically unique: reciprocity condition value =
1.63418e-19

Paolo

2018-02-11 16:54 GMT+01:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Note the typo in your 3rd line: data <
>
> Don't  know if this means anything...
>
> Bert
>
>
>
> On Feb 11, 2018 7:33 AM, "PAOLO PILI" <paolo.pili at student.unife.it> wrote:
>
>> Hello,
>>
>> I have a problem with Hausman test. I am performing my analysis with these
>> commands:
>>
>> > library(plm)
>> > data<-read.csv2("paolo.csv",header=TRUE)
>> > data<
>> pdata.frame(data,index=c("FIRM","YEAR"),drop.index=TRUE,row.names=TRUE)
>> >
>> RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+TU
>> RN+GPROF+GPROF2
>> >
>> grun.fe<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROW
>> TH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
>> > grun.re
>> <-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGRO
>> WTH+TURN+GPROF+GPROF2,data=data,model="random")
>> >
>> gw<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+
>> NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
>> >
>> gr<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+
>> NGROWTH+TURN+GPROF+GPROF2,data=data,model="random")
>> > phtest(gw,gr)
>>
>> I got this answer:
>>
>> Error in solve.default(dvcov) :
>>
>> how can I solve this problem?
>>
>> Thank you
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Feb 11 18:15:26 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 11 Feb 2018 09:15:26 -0800
Subject: [R] Hausman test
In-Reply-To: <CAPNAnS80vOHG9zjru3aWN9wxieE98azvVDOjn2sRtShEbdud4A@mail.gmail.com>
References: <CAPNAnS_otGG3ofshpa90erk_oo-_KxRkU-ZTxpXefqEvOxRmkw@mail.gmail.com>
 <CAGxFJbQvd33z50QPMcLJCnLhmgfV6-iHA-FS4CQwPW=BrFDeKQ@mail.gmail.com>
 <CAPNAnS80vOHG9zjru3aWN9wxieE98azvVDOjn2sRtShEbdud4A@mail.gmail.com>
Message-ID: <FB1074DB-6B16-4FE7-8972-362EE58DD3E6@comcast.net>


> On Feb 11, 2018, at 8:29 AM, PAOLO PILI <paolo.pili at student.unife.it> wrote:
> 
> you are right about the 3rd line but it doesn't help me for my problem. I
> remove the 3rd line but there is still the same problem:
> 
> Error in solve.default (dvcov):
>   the system is numerically unique: reciprocity condition value =
> 1.63418e-19

That suggests inclusion of too many categorical (factor) variables relative to the sample size in the predictor variables. Use tabular methods to investigate. Unable to be more specific in the absence of a proper description of the data situation.

-- 
David.
> 
> Paolo
> 
> 2018-02-11 16:54 GMT+01:00 Bert Gunter <bgunter.4567 at gmail.com>:
> 
>> Note the typo in your 3rd line: data <
>> 
>> Don't  know if this means anything...
>> 
>> Bert
>> 
>> 
>> 
>> On Feb 11, 2018 7:33 AM, "PAOLO PILI" <paolo.pili at student.unife.it> wrote:
>> 
>>> Hello,
>>> 
>>> I have a problem with Hausman test. I am performing my analysis with these
>>> commands:
>>> 
>>>> library(plm)
>>>> data<-read.csv2("paolo.csv",header=TRUE)
>>>> data<
>>> pdata.frame(data,index=c("FIRM","YEAR"),drop.index=TRUE,row.names=TRUE)
>>>> 
>>> RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGROWTH+TU
>>> RN+GPROF+GPROF2
>>>> 
>>> grun.fe<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROW
>>> TH+NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
>>>> grun.re
>>> <-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+NGRO
>>> WTH+TURN+GPROF+GPROF2,data=data,model="random")
>>>> 
>>> gw<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+
>>> NGROWTH+TURN+GPROF+GPROF2,data=data,model="within")
>>>> 
>>> gr<-plm(RECEIV~LSIZE+LAGE+LAGE2+CFLOW+STLEV+FCOST+PGROWTH+
>>> NGROWTH+TURN+GPROF+GPROF2,data=data,model="random")
>>>> phtest(gw,gr)
>>> 
>>> I got this answer:
>>> 
>>> Error in solve.default(dvcov) :
>>> 
>>> how can I solve this problem?
>>> 
>>> Thank you
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwinsemius at comcast.net  Sun Feb 11 18:19:33 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 11 Feb 2018 09:19:33 -0800
Subject: [R] Parallel assignments and goto
In-Reply-To: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
References: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
Message-ID: <5CECF926-7C9F-46DD-A7EE-44D16075E269@comcast.net>


> On Feb 11, 2018, at 7:48 AM, Thomas Mailund <thomas.mailund at gmail.com> wrote:
> 
> Hi guys,
> 
> I am working on some code for automatically translating recursive functions into looping functions to implemented tail-recursion optimisations. See https://github.com/mailund/tailr
> 
> As a toy-example, consider the factorial function
> 
> factorial <- function(n, acc = 1) {
>    if (n <= 1) acc
>    else factorial(n - 1, acc * n)
> }
> 
> I can automatically translate this into the loop-version
> 
> factorial_tr_1 <- function (n, acc = 1) 
> {
>    repeat {
>        if (n <= 1) 
>            return(acc)
>        else {
>            .tailr_n <- n - 1
>            .tailr_acc <- acc * acc
>            n <- .tailr_n
>            acc <- .tailr_acc
>            next
>        }
>    }
> }
> 
> which will run faster and not have problems with recursion depths. However, I?m not entirely happy with this version for two reasons: I am not happy with introducing the temporary variables and this rewrite will not work if I try to over-scope an evaluation context.
> 
> I have two related questions, one related to parallel assignments ? i.e. expressions to variables so the expression uses the old variable values and not the new values until the assignments are all done ? and one related to restarting a loop from nested loops or from nested expressions in `with` expressions or similar.
> 
> I can implement parallel assignment using something like rlang::env_bind:
> 
> factorial_tr_2 <- function (n, acc = 1) 
> {
>    .tailr_env <- rlang::get_env()
>    repeat {
>        if (n <= 1) 
>            return(acc)
>        else {
>            rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
>            next
>        }
>    }
> }
> 
> This reduces the number of additional variables I need to one, but is a couple of orders of magnitude slower than the first version.
> 
>> microbenchmark::microbenchmark(factorial(100),
> +                                factorial_tr_1(100),
> +                                factorial_tr_2(100))
> Unit: microseconds
>                     expr      min       lq       mean    median       uq      max neval
>      factorial(100)   53.978   60.543   77.76203   71.0635   85.947  180.251   100
> factorial_tr_1(100)    9.022    9.903   11.52563   11.0430   11.984   28.464   100
> factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463 8177.635   100
> 
> 
> Is there another way to do parallel assignments that doesn?t cost this much in running time?
> 
> My other problem is the use of `next`. I would like to combine tail-recursion optimisation with pattern matching as in https://github.com/mailund/pmatch where I can, for example, define a linked list like this:
> 
> devtools::install_github("mailund/pmatch?)
> library(pmatch)
> llist := NIL | CONS(car, cdr : llist)
> 
> and define a function for computing the length of a list like this:
> 
> list_length <- function(lst, acc = 0) {
>  force(acc)
>  cases(lst,
>        NIL -> acc,
>        CONS(car, cdr) -> list_length(cdr, acc + 1))
> }
> 
> The `cases` function creates an environment that binds variables in a pattern-description that over-scopes the expression to the right of `->`, so the recursive call in this example have access to the variables `cdr` and `car`.
> 
> I can transform a `cases` call to one that creates the environment containing the bound variables and then evaluate this using `eval` or `with`, but in either case, a call to `next` will not work in such a context. The expression will be evaluated inside `bind` or `with`, and not in the `list_lenght` function.
> 
> A version that *will* work, is something like this
> 
> factorial_tr_3 <- function (n, acc = 1) 
> {
>    .tailr_env <- rlang::get_env()
>    .tailr_frame <- rlang::current_frame()
>    repeat {
>        if (n <= 1) 
>            rlang::return_from(.tailr_frame, acc)
>        else {
>            rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
>            rlang::return_to(.tailr_frame)
>        }
>    }
> }
> 
> Here, again, for the factorial function since this is easier to follow than the list-length function.
> 
> This solution will also work if you return values from inside loops, where `next` wouldn?t work either.
> 
> Using `rlang::return_from` and `rlang::return_to` implements the right semantics, but costs me another order of magnitude in running time.
> 
> microbenchmark::microbenchmark(factorial(100),
>                               factorial_tr_1(100),
>                               factorial_tr_2(100),
>                               factorial_tr_3(100))
> Unit: microseconds
>                expr       min         lq        mean     median        uq        max neval
>      factorial(100)    52.479    60.2640    93.43069    67.5130    83.925   2062.481   100
> factorial_tr_1(100)     8.875     9.6525    49.19595    10.6945    11.217   3818.823   100
> factorial_tr_2(100)  5296.350  5525.0745  5973.77664  5737.8730  6260.128   8471.301   100
> factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725 89859.169 171039.228   100
> 
> I can live with the ?introducing extra variables? solution to parallel assignment, and I could hack my way out of using `with` or `bind` in rewriting `cases`, but restarting a `repeat` loop would really make for a nicer solution. I know that `goto` is considered harmful, but really, in this case, it is what I want.
> 
> A `callCC` version also solves the problem
> 
> factorial_tr_4 <- function(n, acc = 1) {
>    function_body <- function(continuation) {
>        if (n <= 1) {
>            continuation(acc)
>        } else {
>            continuation(list("continue", n = n - 1, acc = acc * n))
>        }
>    }
>    repeat {
>        result <- callCC(function_body)
>        if (is.list(result) && result[[1]] == "continue") {
>            n <- result$n
>            acc <- result$acc
>            next
>        } else {
>            return(result)
>        }
>    }
> }
> 
> But this requires that I know how to distinguish between a valid return value and a tag for ?next? and is still a lot slower than the `next` solution
> 
> microbenchmark::microbenchmark(factorial(100),
>                               factorial_tr_1(100),
>                               factorial_tr_2(100),
>                               factorial_tr_3(100),
>                               factorial_tr_4(100))
> Unit: microseconds
>                expr       min         lq        mean     median        uq        max neval
>      factorial(100)    54.109    61.8095    81.33167    81.8785    89.748    243.554   100
> factorial_tr_1(100)     9.025     9.9035    11.38607    11.1990    12.008     22.375   100
> factorial_tr_2(100)  5272.524  5798.3965  6302.40467  6077.7180  6492.959   9967.237   100
> factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665 75405.054 203785.673   100
> factorial_tr_4(100)   270.978   302.7890   337.48763   313.9930   334.096   1425.702   100
> 
> I don?t necessarily need the tail-recursion optimisation to be faster than the recursive version; just getting out of the problem of too deep recursions is a benefit, but I would rather not pay with an order of magnitude for it. I could, of course, try to handle cases that works with `next` in one way, and other cases using `callCC`, but I feel it should be possible with a version that handles all cases the same way.
> 
> Is there any way to achieve this?
> 
> Cheers
> 	Thomas

I didn't see any reference to the R `Recall` or `local` functions. I don't remember that tail optimization is something that R provides, however.


David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From thomas.mailund at gmail.com  Sun Feb 11 18:25:52 2018
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Sun, 11 Feb 2018 18:25:52 +0100
Subject: [R] Parallel assignments and goto
In-Reply-To: <5CECF926-7C9F-46DD-A7EE-44D16075E269@comcast.net>
References: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
 <5CECF926-7C9F-46DD-A7EE-44D16075E269@comcast.net>
Message-ID: <de5babe0-ed46-44ba-be49-6072c3968c95@Spark>

I admit I didn?t know about Recall, but you are right, there is no direct support for this tail-recursion optimisation. For good reasons ? it would break a lot of NSE. I am not attempting to solve tail-recursion optimisation for all cases. That wouldn?t work by just rewriting functions. It might be doable with JIT or something like that, but my goal is less ambitious.

Using local, though, might be an approach. I will play around with that tomorrow.

Cheers

On 11 Feb 2018, 18.19 +0100, David Winsemius <dwinsemius at comcast.net>, wrote:
>
> > On Feb 11, 2018, at 7:48 AM, Thomas Mailund <thomas.mailund at gmail.com> wrote:
> >
> > Hi guys,
> >
> > I am working on some code for automatically translating recursive functions into looping functions to implemented tail-recursion optimisations. See https://github.com/mailund/tailr
> >
> > As a toy-example, consider the factorial function
> >
> > factorial <- function(n, acc = 1) {
> > if (n <= 1) acc
> > else factorial(n - 1, acc * n)
> > }
> >
> > I can automatically translate this into the loop-version
> >
> > factorial_tr_1 <- function (n, acc = 1)
> > {
> > repeat {
> > if (n <= 1)
> > return(acc)
> > else {
> > .tailr_n <- n - 1
> > .tailr_acc <- acc * acc
> > n <- .tailr_n
> > acc <- .tailr_acc
> > next
> > }
> > }
> > }
> >
> > which will run faster and not have problems with recursion depths. However, I?m not entirely happy with this version for two reasons: I am not happy with introducing the temporary variables and this rewrite will not work if I try to over-scope an evaluation context.
> >
> > I have two related questions, one related to parallel assignments ? i.e. expressions to variables so the expression uses the old variable values and not the new values until the assignments are all done ? and one related to restarting a loop from nested loops or from nested expressions in `with` expressions or similar.
> >
> > I can implement parallel assignment using something like rlang::env_bind:
> >
> > factorial_tr_2 <- function (n, acc = 1)
> > {
> > .tailr_env <- rlang::get_env()
> > repeat {
> > if (n <= 1)
> > return(acc)
> > else {
> > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > next
> > }
> > }
> > }
> >
> > This reduces the number of additional variables I need to one, but is a couple of orders of magnitude slower than the first version.
> >
> > > microbenchmark::microbenchmark(factorial(100),
> > + factorial_tr_1(100),
> > + factorial_tr_2(100))
> > Unit: microseconds
> > expr min lq mean median uq max neval
> > factorial(100) 53.978 60.543 77.76203 71.0635 85.947 180.251 100
> > factorial_tr_1(100) 9.022 9.903 11.52563 11.0430 11.984 28.464 100
> > factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463 8177.635 100
> >
> >
> > Is there another way to do parallel assignments that doesn?t cost this much in running time?
> >
> > My other problem is the use of `next`. I would like to combine tail-recursion optimisation with pattern matching as in https://github.com/mailund/pmatch where I can, for example, define a linked list like this:
> >
> > devtools::install_github("mailund/pmatch?)
> > library(pmatch)
> > llist := NIL | CONS(car, cdr : llist)
> >
> > and define a function for computing the length of a list like this:
> >
> > list_length <- function(lst, acc = 0) {
> > force(acc)
> > cases(lst,
> > NIL -> acc,
> > CONS(car, cdr) -> list_length(cdr, acc + 1))
> > }
> >
> > The `cases` function creates an environment that binds variables in a pattern-description that over-scopes the expression to the right of `->`, so the recursive call in this example have access to the variables `cdr` and `car`.
> >
> > I can transform a `cases` call to one that creates the environment containing the bound variables and then evaluate this using `eval` or `with`, but in either case, a call to `next` will not work in such a context. The expression will be evaluated inside `bind` or `with`, and not in the `list_lenght` function.
> >
> > A version that *will* work, is something like this
> >
> > factorial_tr_3 <- function (n, acc = 1)
> > {
> > .tailr_env <- rlang::get_env()
> > .tailr_frame <- rlang::current_frame()
> > repeat {
> > if (n <= 1)
> > rlang::return_from(.tailr_frame, acc)
> > else {
> > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > rlang::return_to(.tailr_frame)
> > }
> > }
> > }
> >
> > Here, again, for the factorial function since this is easier to follow than the list-length function.
> >
> > This solution will also work if you return values from inside loops, where `next` wouldn?t work either.
> >
> > Using `rlang::return_from` and `rlang::return_to` implements the right semantics, but costs me another order of magnitude in running time.
> >
> > microbenchmark::microbenchmark(factorial(100),
> > factorial_tr_1(100),
> > factorial_tr_2(100),
> > factorial_tr_3(100))
> > Unit: microseconds
> > expr min lq mean median uq max neval
> > factorial(100) 52.479 60.2640 93.43069 67.5130 83.925 2062.481 100
> > factorial_tr_1(100) 8.875 9.6525 49.19595 10.6945 11.217 3818.823 100
> > factorial_tr_2(100) 5296.350 5525.0745 5973.77664 5737.8730 6260.128 8471.301 100
> > factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725 89859.169 171039.228 100
> >
> > I can live with the ?introducing extra variables? solution to parallel assignment, and I could hack my way out of using `with` or `bind` in rewriting `cases`, but restarting a `repeat` loop would really make for a nicer solution. I know that `goto` is considered harmful, but really, in this case, it is what I want.
> >
> > A `callCC` version also solves the problem
> >
> > factorial_tr_4 <- function(n, acc = 1) {
> > function_body <- function(continuation) {
> > if (n <= 1) {
> > continuation(acc)
> > } else {
> > continuation(list("continue", n = n - 1, acc = acc * n))
> > }
> > }
> > repeat {
> > result <- callCC(function_body)
> > if (is.list(result) && result[[1]] == "continue") {
> > n <- result$n
> > acc <- result$acc
> > next
> > } else {
> > return(result)
> > }
> > }
> > }
> >
> > But this requires that I know how to distinguish between a valid return value and a tag for ?next? and is still a lot slower than the `next` solution
> >
> > microbenchmark::microbenchmark(factorial(100),
> > factorial_tr_1(100),
> > factorial_tr_2(100),
> > factorial_tr_3(100),
> > factorial_tr_4(100))
> > Unit: microseconds
> > expr min lq mean median uq max neval
> > factorial(100) 54.109 61.8095 81.33167 81.8785 89.748 243.554 100
> > factorial_tr_1(100) 9.025 9.9035 11.38607 11.1990 12.008 22.375 100
> > factorial_tr_2(100) 5272.524 5798.3965 6302.40467 6077.7180 6492.959 9967.237 100
> > factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665 75405.054 203785.673 100
> > factorial_tr_4(100) 270.978 302.7890 337.48763 313.9930 334.096 1425.702 100
> >
> > I don?t necessarily need the tail-recursion optimisation to be faster than the recursive version; just getting out of the problem of too deep recursions is a benefit, but I would rather not pay with an order of magnitude for it. I could, of course, try to handle cases that works with `next` in one way, and other cases using `callCC`, but I feel it should be possible with a version that handles all cases the same way.
> >
> > Is there any way to achieve this?
> >
> > Cheers
> > Thomas
>
> I didn't see any reference to the R `Recall` or `local` functions. I don't remember that tail optimization is something that R provides, however.
>
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Sun Feb 11 19:04:20 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 11 Feb 2018 10:04:20 -0800
Subject: [R] PSOCK cluster and renice
In-Reply-To: <87609nt73i.fsf@ukes-ams26-134.ams.med.uni.goettingen.de>
References: <87d13vtbas.fsf@ukes-ams26-134.ams.med.uni.goettingen.de>
 <CAFDcVCTNPKx=xPnt7rbYVw6AXCYj4kqaf-fDJdRnzqNg-9ENZw@mail.gmail.com>
 <87609nt73i.fsf@ukes-ams26-134.ams.med.uni.goettingen.de>
Message-ID: <CAFDcVCR34za1rraLSzpeRxHweFjWzsT6A=omXGie+xY+fZswhw@mail.gmail.com>

As a follow up, future 1.7.0 was just released on CRAN allowing you
specify 'renice' as expected.  Example (skip 'dryrun = TRUE' for
actually usage):

> cl <- future::makeClusterPSOCK(2L, renice = 19, dryrun = TRUE)

----------------------------------------------------------------------
Manually start worker #1 on 'localhost' with:
  nice --adjustment=19 '/usr/lib/R/bin/Rscript'
--default-packages=datasets,utils,grDevices,graphics,stats,methods -e
'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11414 OUT=/dev/null
TIMEOUT=2592000 XDR=TRUE
----------------------------------------------------------------------
Manually start worker #2 on 'localhost' with:
  nice --adjustment=19 '/usr/lib/R/bin/Rscript'
--default-packages=datasets,utils,grDevices,graphics,stats,methods -e
'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11414 OUT=/dev/null
TIMEOUT=2592000 XDR=TRUE

/Henrik

On Sun, Dec 3, 2017 at 9:06 PM, Andreas Leha
<andreas.leha at med.uni-goettingen.de> wrote:
> Hi Henrik,
>
> Thanks for the detailed in fast reply!
>
> My guess would be that the confusion comes from the different use of nice and renice.
>
> The workraund you provided work fine!  Thanks a lot.
>
> Best,
> Andreas
>
>
>
> Henrik Bengtsson <henrik.bengtsson at gmail.com> writes:
>
>> Looks like a bug to me due to wrong assumptions about 'nice'
>> arguments, but could be because a "non-standard" 'nice' is used.  If
>> we do:
>>
>>> trace(system, tracer = quote(print(command)))
>> Tracing function "system" in package "base"
>>
>> we see that the system call used is:
>>
>>> cl <- parallel::makePSOCKcluster(2L, renice = 19)
>> Tracing system(cmd, wait = FALSE) on entry
>> [1] "nice +19 '/usr/lib/R/bin/Rscript'
>> --default-packages=datasets,utils,grDevices,graphics,stats,methods -e
>> 'parallel:::.slaveRSOCK()' MASTER=localhost PORT=11146 OUT=/dev/null
>> TIMEOUT=2592000 XDR=TRUE"
>> nice: ?+19?: No such file or directory
>> ^C
>>
>> The code that prepends that 'nice +19' is in parallel:::newPSOCKnode:
>>
>>     if (!is.na(renice) && renice)
>>         cmd <- sprintf("nice +%d %s", as.integer(renice), cmd)
>>
>> I don't know where that originates from and on what platform it was
>> tests/validated.  On Ubuntu 16.04, CentOS 6.6, and CentOS 7.4, I have
>> 'nice' from "GNU coreutils" and they all complain about using '+',
>> e.g.
>>
>> $ nice +19 date
>> nice: +19: No such file or directory
>>
>> but '-' works:
>>
>> $ nice -19 date
>> Sun Dec  3 20:01:31 PST 2017
>>
>> Neither 'nice --help' nor 'man help' mention the use of a +n option.
>>
>>
>> WORKAROUND:  As a workaround, you can use:
>>
>> cl <- future::makeClusterPSOCK(2L, rscript = c("nice",
>> "--adjustment=10", file.path(R.home("bin"), "Rscript")))
>>
>> which is backward compatible with parallel::makePSOCKcluster() but
>> provides you with more detailed control.  Try adding verbose = TRUE to
>> see what the exact call looks like.
>>
>> /Henrik
>>
>>
>> On Sun, Dec 3, 2017 at 7:35 PM, Andreas Leha
>> <andreas.leha at med.uni-goettingen.de> wrote:
>>> Hi all,
>>>
>>> Is it possible to use the 'renice' option together with parallel
>>> clusters of type 'PSOCK'?  The help page for parallel::makeCluster is
>>> not specific about which options are supported on which types and I am
>>> getting the following message when passing renice = 19 :
>>>
>>>> cl <- parallel::makeCluster(2, renice = 19)
>>> nice: ?+19?: No such file or directory
>>>
>>> Kind regards,
>>> Andreas
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Feb 12 08:12:08 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 12 Feb 2018 07:12:08 +0000
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
Message-ID: <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>

Hi

Maybe there are other ways but I would split data to several chunks e.g. in list and use for cycle to fill multipage pdf.

With the toy data something like

library(reshape2)
library(ggplot2)
temp <- melt(temp)
temp.s<-split(temp, cut(1:nrow(temp), 2))

pdf("temp.pdf")
for (i in 1: length(temp.s)) {
p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
print(p+geom_point())
}
dev.off()

But the real code partly depends on your real data.

Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Saturday, February 10, 2018 9:05 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] plotting the regression coefficients

Hi Peter;

The R code you provided works very well. Once again thanks so much for this. The number of variables in my data set that should appear on the y-axis is 733 and they are not numerical (for example the name of one variable is palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]*. So, the plot looks very messy in one page. How can I make the plot to print out on multiple pages?

Regards,

Greg

On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>> wrote:
Hi Petr;

Thanks so much. Exactly this is what I need. I will play to change color and so on but this backbound is perfect to me. I do appreciate your help and support.

Regards,
Greg

On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi
I copied your values to R, here it is

> dput(temp)

temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
"x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
    y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
    2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
"y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
-4L))

For plotting it need to be reshaped

library(reshape2)
library(ggplot2)

temp <- melt(temp)
p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
p+geom_point()

Is this what you wanted?

Cheers
Petr
And preferably do not post in HTML, the email content could be scrambled.

From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
Sent: Thursday, February 8, 2018 9:23 AM
To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] plotting the regression coefficients

Hi Petr;

Thanks for your reply. It is much appreciated. A small example is given below for 4 independent and 4 dependent variables only. The values given are regression coefficients.I have looked ggplot documents before writing to you. Unfortunately, I could not figure out as my experience in ggplot is ignorable

Regards.
Greg

y1 y2 y3 y4
x1 -0.19 0.40 -0.06 0.13
x2 0.45 -0.75 -8.67 -0.46
x3 -0.09 0.14 1.42 0.06
x4 -0.16 -0.01 2.21 0.06


On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Example, example, example - preferably working.

Wild guess - did you try ggplot?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
> Sent: Thursday, February 8, 2018 8:14 AM
> To: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] plotting the regression coefficients
>
> Hi Dear all;
>
> I would like to create a plot for regression coefficients with each independent
> variable (x) along the side and the phenotypes (y) across the top (as given
> below). For each data point, direction and magnitude of effect could be color
> and significance could be the size of the circle? Is this possible?
>
>
> I would greatly be appreciated your help.
>
> Thanks,
>
> Greg
>
>
>
>   y1 y2 y3 y4 y5 y6
> x1
> x2
> x3
> x4
> x5
> x6
> x7
> x8
> x9
> x10
> x11
> x12
> x13
> x14
> x15
> x16
> x17
> .
> .
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Mon Feb 12 08:51:40 2018
From: mak.hholly at gmail.com (greg holly)
Date: Mon, 12 Feb 2018 10:51:40 +0300
Subject: [R] plotting the regression coefficients
In-Reply-To: <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
 <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>

Hi Petr;

Thanks so much. This is great! Although last Sunday, alternatively, I have
solved the problem using the following statement at the very end of the
program.

* ggsave('circle.pdf', p4, height = 70, width = 8, device=pdf, limitsize =
F, dpi=300).*

This works very well too.

Asa my categorical variables are in my Y axis, my R program reorders the
names on Y-axis. However, I would like have and plot output with the names
as they are. Is there any way to have plot without ordering the names of
variables on Y-axis?

Regards,
Greg.

On Mon, Feb 12, 2018 at 10:12 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> Maybe there are other ways but I would split data to several chunks e.g.
> in list and use for cycle to fill multipage pdf.
>
>
>
> With the toy data something like
>
>
>
> library(reshape2)
>
> library(ggplot2)
>
> temp <- melt(temp)
>
> temp.s<-split(temp, cut(1:nrow(temp), 2))
>
>
>
> pdf("temp.pdf")
>
> for (i in 1: length(temp.s)) {
>
> p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value),
> colour=factor(sign(value))))
>
> print(p+geom_point())
>
> }
>
> dev.off()
>
>
>
> But the real code partly depends on your real data.
>
>
>
> Cheers
>
> Petr
>
>
>
> *From:* greg holly [mailto:mak.hholly at gmail.com]
> *Sent:* Saturday, February 10, 2018 9:05 PM
>
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* r-help mailing list <r-help at r-project.org>
> *Subject:* Re: [R] plotting the regression coefficients
>
>
>
> Hi Peter;
>
>
>
> The R code you provided works very well. Once again thanks so much for
> this. The number of variables in my data set that should appear on the
> y-axis is 733 and they are not numerical (for example the name of one
> variable is *palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]**. So, the
> plot looks very messy in one page. How can I make the plot to print out on
> multiple pages?
>
>
>
> Regards,
>
>
>
> Greg
>
>
>
> On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com> wrote:
>
> Hi Petr;
>
>
>
> Thanks so much. Exactly this is what I need. I will play to change color
> and so on but this backbound is perfect to me. I do appreciate your help
> and support.
>
>
>
> Regards,
>
> Greg
>
>
>
> On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> I copied your values to R, here it is
>
>
>
> > dput(temp)
>
>
>
> temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
>
> "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
>
>     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
>
>     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
>
> "y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
>
> -4L))
>
>
>
> For plotting it need to be reshaped
>
>
>
> library(reshape2)
>
> library(ggplot2)
>
>
>
> temp <- melt(temp)
>
> p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value),
> colour=factor(sign(value))))
>
> p+geom_point()
>
>
>
> Is this what you wanted?
>
>
>
> Cheers
>
> Petr
>
> And preferably do not post in HTML, the email content could be scrambled.
>
>
>
> *From:* greg holly [mailto:mak.hholly at gmail.com]
> *Sent:* Thursday, February 8, 2018 9:23 AM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* r-help mailing list <r-help at r-project.org>
> *Subject:* Re: [R] plotting the regression coefficients
>
>
>
> Hi Petr;
>
>
>
> Thanks for your reply. It is much appreciated. A small example is given
> below for 4 independent and 4 dependent variables only. The values given
> are regression coefficients.I have looked ggplot documents before writing
> to you. Unfortunately, I could not figure out as my experience in ggplot is
> ignorable
>
>
>
> Regards.
>
> Greg
>
>
>
> y1 y2 y3 y4
>
> x1 -0.19 0.40 -0.06 0.13
>
> x2 0.45 -0.75 -8.67 -0.46
>
> x3 -0.09 0.14 1.42 0.06
>
> x4 -0.16 -0.01 2.21 0.06
>
>
>
>
>
> On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Hi
>
> Example, example, example - preferably working.
>
> Wild guess - did you try ggplot?
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
> holly
> > Sent: Thursday, February 8, 2018 8:14 AM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] plotting the regression coefficients
> >
> > Hi Dear all;
> >
> > I would like to create a plot for regression coefficients with each
> independent
> > variable (x) along the side and the phenotypes (y) across the top (as
> given
> > below). For each data point, direction and magnitude of effect could be
> color
> > and significance could be the size of the circle? Is this possible?
> >
> >
> > I would greatly be appreciated your help.
> >
> > Thanks,
> >
> > Greg
> >
> >
> >
> >   y1 y2 y3 y4 y5 y6
> > x1
> > x2
> > x3
> > x4
> > x5
> > x6
> > x7
> > x8
> > x9
> > x10
> > x11
> > x12
> > x13
> > x14
> > x15
> > x16
> > x17
> > .
> > .
> >
>
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
>
>
> ------------------------------
>
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb 12 09:49:59 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 12 Feb 2018 08:49:59 +0000
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
 <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>
Message-ID: <0313f929ce0d42b2a55bbab7e25e8969@SRVEXCHCM1301.precheza.cz>

Hi

After melt you can change levels of your factor variable. Again with the toy example.

> levels(temp$variable)
[1] "y1" "y2" "y3" "y4"
> levels(temp$variable) <- levels(temp$variable)[c(2,4,1,3)]
> levels(temp$variable)
[1] "y2" "y4" "y1" "y3"
>

And you will get graphs with this new levels ordering.

Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Monday, February 12, 2018 8:52 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] plotting the regression coefficients

Hi Petr;

Thanks so much. This is great! Although last Sunday, alternatively, I have solved the problem using the following statement at the very end of the program.

 ggsave('circle.pdf', p4, height = 70, width = 8, device=pdf, limitsize = F, dpi=300).

This works very well too.

Asa my categorical variables are in my Y axis, my R program reorders the names on Y-axis. However, I would like have and plot output with the names as they are. Is there any way to have plot without ordering the names of variables on Y-axis?

Regards,
Greg.

On Mon, Feb 12, 2018 at 10:12 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Maybe there are other ways but I would split data to several chunks e.g. in list and use for cycle to fill multipage pdf.

With the toy data something like

library(reshape2)
library(ggplot2)
temp <- melt(temp)
temp.s<-split(temp, cut(1:nrow(temp), 2))

pdf("temp.pdf")
for (i in 1: length(temp.s)) {
p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
print(p+geom_point())
}
dev.off()

But the real code partly depends on your real data.

Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
Sent: Saturday, February 10, 2018 9:05 PM

To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] plotting the regression coefficients

Hi Peter;

The R code you provided works very well. Once again thanks so much for this. The number of variables in my data set that should appear on the y-axis is 733 and they are not numerical (for example the name of one variable is palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]*. So, the plot looks very messy in one page. How can I make the plot to print out on multiple pages?

Regards,

Greg

On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>> wrote:
Hi Petr;

Thanks so much. Exactly this is what I need. I will play to change color and so on but this backbound is perfect to me. I do appreciate your help and support.

Regards,
Greg

On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi
I copied your values to R, here it is

> dput(temp)

temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
"x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
    y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
    2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
"y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
-4L))

For plotting it need to be reshaped

library(reshape2)
library(ggplot2)

temp <- melt(temp)
p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
p+geom_point()

Is this what you wanted?

Cheers
Petr
And preferably do not post in HTML, the email content could be scrambled.

From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
Sent: Thursday, February 8, 2018 9:23 AM
To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] plotting the regression coefficients

Hi Petr;

Thanks for your reply. It is much appreciated. A small example is given below for 4 independent and 4 dependent variables only. The values given are regression coefficients.I have looked ggplot documents before writing to you. Unfortunately, I could not figure out as my experience in ggplot is ignorable

Regards.
Greg

y1 y2 y3 y4
x1 -0.19 0.40 -0.06 0.13
x2 0.45 -0.75 -8.67 -0.46
x3 -0.09 0.14 1.42 0.06
x4 -0.16 -0.01 2.21 0.06


On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Example, example, example - preferably working.

Wild guess - did you try ggplot?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
> Sent: Thursday, February 8, 2018 8:14 AM
> To: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] plotting the regression coefficients
>
> Hi Dear all;
>
> I would like to create a plot for regression coefficients with each independent
> variable (x) along the side and the phenotypes (y) across the top (as given
> below). For each data point, direction and magnitude of effect could be color
> and significance could be the size of the circle? Is this possible?
>
>
> I would greatly be appreciated your help.
>
> Thanks,
>
> Greg
>
>
>
>   y1 y2 y3 y4 y5 y6
> x1
> x2
> x3
> x4
> x5
> x6
> x7
> x8
> x9
> x10
> x11
> x12
> x13
> x14
> x15
> x16
> x17
> .
> .
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From rmh at temple.edu  Mon Feb 12 18:10:22 2018
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 12 Feb 2018 12:10:22 -0500
Subject: [R] plotting the regression coefficients
In-Reply-To: <0313f929ce0d42b2a55bbab7e25e8969@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
 <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>
 <0313f929ce0d42b2a55bbab7e25e8969@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAGx1TMALCEDvc-ta+8H34QCQWCijYHMqNChKGa2DxAPUHEp4Sw@mail.gmail.com>

Petr, there was a thinko in your response.


tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
tmp
tmp$m <- factor(tmp$m, levels=c("c","b","a","d")) ## right
tmp[order(tmp$m),]

tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
levels(tmp$m) <- c("c","b","a","d") ## wrong
tmp[order(tmp$m),]

changing levels directly changes the names only, not the ordering.
You must redefine the factor to retain the relationship of factor
names with the numerical values.

Rich


On Mon, Feb 12, 2018 at 3:49 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> After melt you can change levels of your factor variable. Again with the toy example.
>
>> levels(temp$variable)
> [1] "y1" "y2" "y3" "y4"
>> levels(temp$variable) <- levels(temp$variable)[c(2,4,1,3)]
>> levels(temp$variable)
> [1] "y2" "y4" "y1" "y3"
>>
>
> And you will get graphs with this new levels ordering.
>
> Cheers
> Petr
>
> From: greg holly [mailto:mak.hholly at gmail.com]
> Sent: Monday, February 12, 2018 8:52 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] plotting the regression coefficients
>
> Hi Petr;
>
> Thanks so much. This is great! Although last Sunday, alternatively, I have solved the problem using the following statement at the very end of the program.
>
>  ggsave('circle.pdf', p4, height = 70, width = 8, device=pdf, limitsize = F, dpi=300).
>
> This works very well too.
>
> Asa my categorical variables are in my Y axis, my R program reorders the names on Y-axis. However, I would like have and plot output with the names as they are. Is there any way to have plot without ordering the names of variables on Y-axis?
>
> Regards,
> Greg.
>
> On Mon, Feb 12, 2018 at 10:12 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> Hi
>
> Maybe there are other ways but I would split data to several chunks e.g. in list and use for cycle to fill multipage pdf.
>
> With the toy data something like
>
> library(reshape2)
> library(ggplot2)
> temp <- melt(temp)
> temp.s<-split(temp, cut(1:nrow(temp), 2))
>
> pdf("temp.pdf")
> for (i in 1: length(temp.s)) {
> p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
> print(p+geom_point())
> }
> dev.off()
>
> But the real code partly depends on your real data.
>
> Cheers
> Petr
>
> From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
> Sent: Saturday, February 10, 2018 9:05 PM
>
> To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] plotting the regression coefficients
>
> Hi Peter;
>
> The R code you provided works very well. Once again thanks so much for this. The number of variables in my data set that should appear on the y-axis is 733 and they are not numerical (for example the name of one variable is palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]*. So, the plot looks very messy in one page. How can I make the plot to print out on multiple pages?
>
> Regards,
>
> Greg
>
> On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>> wrote:
> Hi Petr;
>
> Thanks so much. Exactly this is what I need. I will play to change color and so on but this backbound is perfect to me. I do appreciate your help and support.
>
> Regards,
> Greg
>
> On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> Hi
> I copied your values to R, here it is
>
>> dput(temp)
>
> temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
> "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
>     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
>     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
> "y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
> -4L))
>
> For plotting it need to be reshaped
>
> library(reshape2)
> library(ggplot2)
>
> temp <- melt(temp)
> p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
> p+geom_point()
>
> Is this what you wanted?
>
> Cheers
> Petr
> And preferably do not post in HTML, the email content could be scrambled.
>
> From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
> Sent: Thursday, February 8, 2018 9:23 AM
> To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] plotting the regression coefficients
>
> Hi Petr;
>
> Thanks for your reply. It is much appreciated. A small example is given below for 4 independent and 4 dependent variables only. The values given are regression coefficients.I have looked ggplot documents before writing to you. Unfortunately, I could not figure out as my experience in ggplot is ignorable
>
> Regards.
> Greg
>
> y1 y2 y3 y4
> x1 -0.19 0.40 -0.06 0.13
> x2 0.45 -0.75 -8.67 -0.46
> x3 -0.09 0.14 1.42 0.06
> x4 -0.16 -0.01 2.21 0.06
>
>
> On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> Hi
>
> Example, example, example - preferably working.
>
> Wild guess - did you try ggplot?
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
>> Sent: Thursday, February 8, 2018 8:14 AM
>> To: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
>> Subject: [R] plotting the regression coefficients
>>
>> Hi Dear all;
>>
>> I would like to create a plot for regression coefficients with each independent
>> variable (x) along the side and the phenotypes (y) across the top (as given
>> below). For each data point, direction and magnitude of effect could be color
>> and significance could be the size of the circle? Is this possible?
>>
>>
>> I would greatly be appreciated your help.
>>
>> Thanks,
>>
>> Greg
>>
>>
>>
>>   y1 y2 y3 y4 y5 y6
>> x1
>> x2
>> x3
>> x4
>> x5
>> x6
>> x7
>> x8
>> x9
>> x10
>> x11
>> x12
>> x13
>> x14
>> x15
>> x16
>> x17
>> .
>> .
>>
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mak.hholly at gmail.com  Mon Feb 12 19:07:12 2018
From: mak.hholly at gmail.com (greg holly)
Date: Mon, 12 Feb 2018 21:07:12 +0300
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAGx1TMALCEDvc-ta+8H34QCQWCijYHMqNChKGa2DxAPUHEp4Sw@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
 <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>
 <0313f929ce0d42b2a55bbab7e25e8969@SRVEXCHCM1301.precheza.cz>
 <CAGx1TMALCEDvc-ta+8H34QCQWCijYHMqNChKGa2DxAPUHEp4Sw@mail.gmail.com>
Message-ID: <CAM9Qe4jq+NHRtJgpMwZoJ5gXtXZodqaCJqPMnYyukeQ6mXZCLQ@mail.gmail.com>

Hi Petr and Richard;

Thanks for your responses and supports.  I just faced a different problem.
I have the following R codes and work well.

p <- ggplot(a, aes(x=Phenotypes, y=Metabolites, size=abs(Beta),
colour=factor(sign(Beta)))) +
theme(axis.text=element_text(size = 5))
p1<-p+geom_point()
p2<-p1+theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          axis.ticks = element_blank())

p3<-p2+theme(panel.grid.major = element_blank(), panel.grid.minor =
element_blank(),
panel.background = element_blank(), axis.line = element_line(colour =
"black"))

p4<-p3+scale_color_manual(breaks = c("-1", "0", "1"),
                        values=c("darkblue", "green", "red"))


*My question is:*
What if I was to repeat the analysis and standardize the beta (z-score) so
they are comparable across phenotypes (I have 8 phenotypes). We could then
?bin? the betas to represent shades of red and blue.

Regards,

Greg


On Mon, Feb 12, 2018 at 8:10 PM, Richard M. Heiberger <rmh at temple.edu>
wrote:

> Petr, there was a thinko in your response.
>
>
> tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
> tmp
> tmp$m <- factor(tmp$m, levels=c("c","b","a","d")) ## right
> tmp[order(tmp$m),]
>
> tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
> levels(tmp$m) <- c("c","b","a","d") ## wrong
> tmp[order(tmp$m),]
>
> changing levels directly changes the names only, not the ordering.
> You must redefine the factor to retain the relationship of factor
> names with the numerical values.
>
> Rich
>
>
> On Mon, Feb 12, 2018 at 3:49 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hi
> >
> > After melt you can change levels of your factor variable. Again with the
> toy example.
> >
> >> levels(temp$variable)
> > [1] "y1" "y2" "y3" "y4"
> >> levels(temp$variable) <- levels(temp$variable)[c(2,4,1,3)]
> >> levels(temp$variable)
> > [1] "y2" "y4" "y1" "y3"
> >>
> >
> > And you will get graphs with this new levels ordering.
> >
> > Cheers
> > Petr
> >
> > From: greg holly [mailto:mak.hholly at gmail.com]
> > Sent: Monday, February 12, 2018 8:52 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Petr;
> >
> > Thanks so much. This is great! Although last Sunday, alternatively, I
> have solved the problem using the following statement at the very end of
> the program.
> >
> >  ggsave('circle.pdf', p4, height = 70, width = 8, device=pdf, limitsize
> = F, dpi=300).
> >
> > This works very well too.
> >
> > Asa my categorical variables are in my Y axis, my R program reorders the
> names on Y-axis. However, I would like have and plot output with the names
> as they are. Is there any way to have plot without ordering the names of
> variables on Y-axis?
> >
> > Regards,
> > Greg.
> >
> > On Mon, Feb 12, 2018 at 10:12 AM, PIKAL Petr <petr.pikal at precheza.cz<
> mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> >
> > Maybe there are other ways but I would split data to several chunks e.g.
> in list and use for cycle to fill multipage pdf.
> >
> > With the toy data something like
> >
> > library(reshape2)
> > library(ggplot2)
> > temp <- melt(temp)
> > temp.s<-split(temp, cut(1:nrow(temp), 2))
> >
> > pdf("temp.pdf")
> > for (i in 1: length(temp.s)) {
> > p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value),
> colour=factor(sign(value))))
> > print(p+geom_point())
> > }
> > dev.off()
> >
> > But the real code partly depends on your real data.
> >
> > Cheers
> > Petr
> >
> > From: greg holly [mailto:mak.hholly at gmail.com<mailto:
> mak.hholly at gmail.com>]
> > Sent: Saturday, February 10, 2018 9:05 PM
> >
> > To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> > Cc: r-help mailing list <r-help at r-project.org<mailto:r
> -help at r-project.org>>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Peter;
> >
> > The R code you provided works very well. Once again thanks so much for
> this. The number of variables in my data set that should appear on the
> y-axis is 733 and they are not numerical (for example the name of one
> variable is palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]*. So, the
> plot looks very messy in one page. How can I make the plot to print out on
> multiple pages?
> >
> > Regards,
> >
> > Greg
> >
> > On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com<mailto:
> mak.hholly at gmail.com>> wrote:
> > Hi Petr;
> >
> > Thanks so much. Exactly this is what I need. I will play to change color
> and so on but this backbound is perfect to me. I do appreciate your help
> and support.
> >
> > Regards,
> > Greg
> >
> > On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz<
> mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> > I copied your values to R, here it is
> >
> >> dput(temp)
> >
> > temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
> > "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
> >     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
> >     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
> > "y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
> > -4L))
> >
> > For plotting it need to be reshaped
> >
> > library(reshape2)
> > library(ggplot2)
> >
> > temp <- melt(temp)
> > p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value),
> colour=factor(sign(value))))
> > p+geom_point()
> >
> > Is this what you wanted?
> >
> > Cheers
> > Petr
> > And preferably do not post in HTML, the email content could be scrambled.
> >
> > From: greg holly [mailto:mak.hholly at gmail.com<mailto:
> mak.hholly at gmail.com>]
> > Sent: Thursday, February 8, 2018 9:23 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> > Cc: r-help mailing list <r-help at r-project.org<mailto:r
> -help at r-project.org>>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Petr;
> >
> > Thanks for your reply. It is much appreciated. A small example is given
> below for 4 independent and 4 dependent variables only. The values given
> are regression coefficients.I have looked ggplot documents before writing
> to you. Unfortunately, I could not figure out as my experience in ggplot is
> ignorable
> >
> > Regards.
> > Greg
> >
> > y1 y2 y3 y4
> > x1 -0.19 0.40 -0.06 0.13
> > x2 0.45 -0.75 -8.67 -0.46
> > x3 -0.09 0.14 1.42 0.06
> > x4 -0.16 -0.01 2.21 0.06
> >
> >
> > On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz<
> mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> >
> > Example, example, example - preferably working.
> >
> > Wild guess - did you try ggplot?
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-
> bounces at r-project.org>] On Behalf Of greg holly
> >> Sent: Thursday, February 8, 2018 8:14 AM
> >> To: r-help mailing list <r-help at r-project.org<mailto:r
> -help at r-project.org>>
> >> Subject: [R] plotting the regression coefficients
> >>
> >> Hi Dear all;
> >>
> >> I would like to create a plot for regression coefficients with each
> independent
> >> variable (x) along the side and the phenotypes (y) across the top (as
> given
> >> below). For each data point, direction and magnitude of effect could be
> color
> >> and significance could be the size of the circle? Is this possible?
> >>
> >>
> >> I would greatly be appreciated your help.
> >>
> >> Thanks,
> >>
> >> Greg
> >>
> >>
> >>
> >>   y1 y2 y3 y4 y5 y6
> >> x1
> >> x2
> >> x3
> >> x4
> >> x5
> >> x6
> >> x7
> >> x8
> >> x9
> >> x10
> >> x11
> >> x12
> >> x13
> >> x14
> >> x15
> >> x16
> >> x17
> >> .
> >> .
> >>
> >
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fisher at plessthan.com  Tue Feb 13 03:22:39 2018
From: fisher at plessthan.com (Dennis Fisher)
Date: Mon, 12 Feb 2018 18:22:39 -0800
Subject: [R] Help with regular expressions
Message-ID: <BC18EF5D-2B1D-4345-863C-036BD34257FF@plessthan.com>

R 3.4.2
OS X

Colleagues

I would appreciate some help with regular expressions.

I have string that looks like:
	" ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1,1)             ,SIGMA(2,1)             ,SIGMA(2,2)?

In the entries that contain:
	(X,Y)			# for example, SIGMA(1,1)
I would like to replace the comma with a period, e.g., SIGMA(1.1) but NOT the other commas

The end-result would be:
	" ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1.1)             ,SIGMA(2.1)             ,SIGMA(2.2)?

Can someone provide the regular expression code to accomplish this?
Thanks.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From drjimlemon at gmail.com  Tue Feb 13 03:34:39 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 13 Feb 2018 13:34:39 +1100
Subject: [R] Help with regular expressions
In-Reply-To: <BC18EF5D-2B1D-4345-863C-036BD34257FF@plessthan.com>
References: <BC18EF5D-2B1D-4345-863C-036BD34257FF@plessthan.com>
Message-ID: <CA+8X3fUJo_GYbFKZRSMdV5MqRx9KrBDS4JSjOB_SgHPBxrw36g@mail.gmail.com>

Hi Dennis,
How about:


# define the two values to search for
x<-2
y<-3
# create your search string and replacement string
repstring<-paste(x,y,sep=",")
newstring<-paste(x,y,sep=".")
# this is the string that you want to change
thetastring<-"SIGMA(2,3)"
sub(repstring,newstring,thetastring)
[1] "SIGMA(2.3)"

Use gsub if you want to change multiple values

Jim

On Tue, Feb 13, 2018 at 1:22 PM, Dennis Fisher <fisher at plessthan.com> wrote:
> R 3.4.2
> OS X
>
> Colleagues
>
> I would appreciate some help with regular expressions.
>
> I have string that looks like:
>         " ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1,1)             ,SIGMA(2,1)             ,SIGMA(2,2)?
>
> In the entries that contain:
>         (X,Y)                   # for example, SIGMA(1,1)
> I would like to replace the comma with a period, e.g., SIGMA(1.1) but NOT the other commas
>
> The end-result would be:
>         " ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1.1)             ,SIGMA(2.1)             ,SIGMA(2.2)?
>
> Can someone provide the regular expression code to accomplish this?
> Thanks.
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Feb 13 03:36:53 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 12 Feb 2018 18:36:53 -0800
Subject: [R] Help with regular expressions
In-Reply-To: <BC18EF5D-2B1D-4345-863C-036BD34257FF@plessthan.com>
References: <BC18EF5D-2B1D-4345-863C-036BD34257FF@plessthan.com>
Message-ID: <FA05569D-1046-41A5-82A0-3B4B992485AC@comcast.net>


> On Feb 12, 2018, at 6:22 PM, Dennis Fisher <fisher at plessthan.com> wrote:
> 
> R 3.4.2
> OS X
> 
> Colleagues
> 
> I would appreciate some help with regular expressions.
> 
> I have string that looks like:
> 	" ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1,1)             ,SIGMA(2,1)             ,SIGMA(2,2)?
> 
> In the entries that contain:
> 	(X,Y)			# for example, SIGMA(1,1)
> I would like to replace the comma with a period, e.g., SIGMA(1.1) but NOT the other commas
> 
> The end-result would be:
> 	" ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1.1)             ,SIGMA(2.1)             ,SIGMA(2.2)?
> 
> Can someone provide the regular expression code to accomplish this?

gsub( "([(]\\d+)([,])(\\d+[)])", "\\1.\\3", x)\
#-----------
[1] "ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6         ,THETA7                 ,SIGMA(1.1)             ,SIGMA(2.1)             ,SIGMA(2.2)"


> Thanks.
> 
> Dennis
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From boris.steipe at utoronto.ca  Tue Feb 13 03:38:14 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 12 Feb 2018 21:38:14 -0500
Subject: [R] Help with regular expressions
In-Reply-To: <CA+8X3fUJo_GYbFKZRSMdV5MqRx9KrBDS4JSjOB_SgHPBxrw36g@mail.gmail.com>
References: <BC18EF5D-2B1D-4345-863C-036BD34257FF@plessthan.com>
 <CA+8X3fUJo_GYbFKZRSMdV5MqRx9KrBDS4JSjOB_SgHPBxrw36g@mail.gmail.com>
Message-ID: <E96D85C4-0D7D-4ED0-8FF6-4A61F09D7936@utoronto.ca>

You can either use positive lookahead/lookbehind - but support for that is a bit flaky. Or write a proper regex, and use
backreferences to keep what you need.

R > x <- "abc 1,1 ,1 1, x,y 2,3 "

R > gsub("(\\d),(\\d)", "\\1.\\2", x, perl = TRUE)
[1] "abc 1.1 ,1 1, x,y 2.3 "


B.



> On Feb 12, 2018, at 9:34 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Dennis,
> How about:
> 
> 
> # define the two values to search for
> x<-2
> y<-3
> # create your search string and replacement string
> repstring<-paste(x,y,sep=",")
> newstring<-paste(x,y,sep=".")
> # this is the string that you want to change
> thetastring<-"SIGMA(2,3)"
> sub(repstring,newstring,thetastring)
> [1] "SIGMA(2.3)"
> 
> Use gsub if you want to change multiple values
> 
> Jim
> 
> On Tue, Feb 13, 2018 at 1:22 PM, Dennis Fisher <fisher at plessthan.com> wrote:
>> R 3.4.2
>> OS X
>> 
>> Colleagues
>> 
>> I would appreciate some help with regular expressions.
>> 
>> I have string that looks like:
>>        " ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1,1)             ,SIGMA(2,1)             ,SIGMA(2,2)?
>> 
>> In the entries that contain:
>>        (X,Y)                   # for example, SIGMA(1,1)
>> I would like to replace the comma with a period, e.g., SIGMA(1.1) but NOT the other commas
>> 
>> The end-result would be:
>>        " ITERATION              ,THETA1                 ,THETA2                 ,THETA3                 ,THETA4                 ,THETA5                 ,THETA6                 ,THETA7                 ,SIGMA(1.1)             ,SIGMA(2.1)             ,SIGMA(2.2)?
>> 
>> Can someone provide the regular expression code to accomplish this?
>> Thanks.
>> 
>> Dennis
>> 
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Tue Feb 13 06:53:41 2018
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 13 Feb 2018 05:53:41 +0000
Subject: [R] Help with regular expressions
In-Reply-To: <E96D85C4-0D7D-4ED0-8FF6-4A61F09D7936@utoronto.ca>
References: <BC18EF5D-2B1D-4345-863C-036BD34257FF@plessthan.com>
 <CA+8X3fUJo_GYbFKZRSMdV5MqRx9KrBDS4JSjOB_SgHPBxrw36g@mail.gmail.com>
 <E96D85C4-0D7D-4ED0-8FF6-4A61F09D7936@utoronto.ca>
Message-ID: <CAKVAULPM+BM8W+x1=6xvPuOK0tHpWGFGza_tpDLAX=8wAiaCew@mail.gmail.com>

I think I would replace all , with . and subsequently replace all first .
with , using ^\\.

x <- gsub(",", ".", x)
gsub("^\\.", ",", x)

It's not so elegant, but it is easier to understand than backreferences and
complex regex.

Best,
Ulrik

On Tue, 13 Feb 2018, 03:38 Boris Steipe, <boris.steipe at utoronto.ca> wrote:

> You can either use positive lookahead/lookbehind - but support for that is
> a bit flaky. Or write a proper regex, and use
> backreferences to keep what you need.
>
> R > x <- "abc 1,1 ,1 1, x,y 2,3 "
>
> R > gsub("(\\d),(\\d)", "\\1.\\2", x, perl = TRUE)
> [1] "abc 1.1 ,1 1, x,y 2.3 "
>
>
> B.
>
>
>
> > On Feb 12, 2018, at 9:34 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Dennis,
> > How about:
> >
> >
> > # define the two values to search for
> > x<-2
> > y<-3
> > # create your search string and replacement string
> > repstring<-paste(x,y,sep=",")
> > newstring<-paste(x,y,sep=".")
> > # this is the string that you want to change
> > thetastring<-"SIGMA(2,3)"
> > sub(repstring,newstring,thetastring)
> > [1] "SIGMA(2.3)"
> >
> > Use gsub if you want to change multiple values
> >
> > Jim
> >
> > On Tue, Feb 13, 2018 at 1:22 PM, Dennis Fisher <fisher at plessthan.com>
> wrote:
> >> R 3.4.2
> >> OS X
> >>
> >> Colleagues
> >>
> >> I would appreciate some help with regular expressions.
> >>
> >> I have string that looks like:
> >>        " ITERATION              ,THETA1                 ,THETA2
>          ,THETA3                 ,THETA4                 ,THETA5
>      ,THETA6                 ,THETA7                 ,SIGMA(1,1)
>  ,SIGMA(2,1)             ,SIGMA(2,2)?
> >>
> >> In the entries that contain:
> >>        (X,Y)                   # for example, SIGMA(1,1)
> >> I would like to replace the comma with a period, e.g., SIGMA(1.1) but
> NOT the other commas
> >>
> >> The end-result would be:
> >>        " ITERATION              ,THETA1                 ,THETA2
>          ,THETA3                 ,THETA4                 ,THETA5
>      ,THETA6                 ,THETA7                 ,SIGMA(1.1)
>  ,SIGMA(2.1)             ,SIGMA(2.2)?
> >>
> >> Can someone provide the regular expression code to accomplish this?
> >> Thanks.
> >>
> >> Dennis
> >>
> >> Dennis Fisher MD
> >> P < (The "P Less Than" Company)
> >> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> >> www.PLessThan.com
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sigbert at wiwi.hu-berlin.de  Tue Feb 13 09:18:33 2018
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Tue, 13 Feb 2018 09:18:33 +0100
Subject: [R] Syntax highlighting
Message-ID: <ea1a87a2-79d5-3705-b17b-47aa954873f6@wiwi.hu-berlin.de>

Hi,

I would like know if there are any plans for some "standardized" syntax 
highlighting of R code?

* Currently I'm using minted for my LaTeX slides with pygmentize and I 
do not know what scheme is used for highlighting the R code.
* RStudio uses (as default) TextMate (Text editor for MacOS) 
highlighting for R code.
* The R package "highr" just defines CSS classes and does not provide 
any default CSS file, but embeds andre simons Highlight 3.42 Software

Of course, for my students I would like to have approximately the same 
highlighting in the slides, in RStudio and in shiny.

Best Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From loris.bennett at fu-berlin.de  Tue Feb 13 11:00:11 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 13 Feb 2018 11:00:11 +0100
Subject: [R] Syntax highlighting
In-Reply-To: <ea1a87a2-79d5-3705-b17b-47aa954873f6@wiwi.hu-berlin.de> (Sigbert
 Klinke's message of "Tue, 13 Feb 2018 09:18:33 +0100")
References: <ea1a87a2-79d5-3705-b17b-47aa954873f6@wiwi.hu-berlin.de>
Message-ID: <87o9ktqkes.fsf@hornfels.zedat.fu-berlin.de>

Hi Sigbert,

Sigbert Klinke <sigbert at wiwi.hu-berlin.de> writes:

> Hi,
>
> I would like know if there are any plans for some "standardized"
> syntax highlighting of R code?
>
> * Currently I'm using minted for my LaTeX slides with pygmentize and I
> do not know what scheme is used for highlighting the R code.
> * RStudio uses (as default) TextMate (Text editor for MacOS)
> highlighting for R code.
> * The R package "highr" just defines CSS classes and does not provide
> any default CSS file, but embeds andre simons Highlight 3.42 Software
>
> Of course, for my students I would like to have approximately the same
> highlighting in the slides, in RStudio and in shiny.

I'm not in a position to know whether anyone has such plans, but I
assume that trying to standardise syntax highlighting is probably a can
of worms that no-one would want to open, as it is just too subjective an
issue.  However, I seem to remember that you can use /setminted to set
the style and

  pygmentize -L styles

will give you a list of predefined styles.  Maybe one of them is suitable.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From petr.pikal at precheza.cz  Tue Feb 13 15:25:47 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 13 Feb 2018 14:25:47 +0000
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAGx1TMALCEDvc-ta+8H34QCQWCijYHMqNChKGa2DxAPUHEp4Sw@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
 <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>
 <0313f929ce0d42b2a55bbab7e25e8969@SRVEXCHCM1301.precheza.cz>
 <CAGx1TMALCEDvc-ta+8H34QCQWCijYHMqNChKGa2DxAPUHEp4Sw@mail.gmail.com>
Message-ID: <bbce2f96e1a348dca234ee455ba8bc0b@SRVEXCHCM1301.precheza.cz>

Hi Richard

Yes you are right, I did not check my answer enough.

Cheers
Petr

> -----Original Message-----
> From: Richard M. Heiberger [mailto:rmh at temple.edu]
> Sent: Monday, February 12, 2018 6:10 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: greg holly <mak.hholly at gmail.com>; r-help mailing list <r-help at r-
> project.org>
> Subject: Re: [R] plotting the regression coefficients
>
> Petr, there was a thinko in your response.
>
>
> tmp <- data.frame(m=factor(letters[1:4]), n=1:4) tmp tmp$m <- factor(tmp$m,
> levels=c("c","b","a","d")) ## right tmp[order(tmp$m),]
>
> tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
> levels(tmp$m) <- c("c","b","a","d") ## wrong tmp[order(tmp$m),]
>
> changing levels directly changes the names only, not the ordering.
> You must redefine the factor to retain the relationship of factor names with the
> numerical values.
>
> Rich
>
>
> On Mon, Feb 12, 2018 at 3:49 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > Hi
> >
> > After melt you can change levels of your factor variable. Again with the toy
> example.
> >
> >> levels(temp$variable)
> > [1] "y1" "y2" "y3" "y4"
> >> levels(temp$variable) <- levels(temp$variable)[c(2,4,1,3)]
> >> levels(temp$variable)
> > [1] "y2" "y4" "y1" "y3"
> >>
> >
> > And you will get graphs with this new levels ordering.
> >
> > Cheers
> > Petr
> >
> > From: greg holly [mailto:mak.hholly at gmail.com]
> > Sent: Monday, February 12, 2018 8:52 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Petr;
> >
> > Thanks so much. This is great! Although last Sunday, alternatively, I have
> solved the problem using the following statement at the very end of the
> program.
> >
> >  ggsave('circle.pdf', p4, height = 70, width = 8, device=pdf, limitsize = F,
> dpi=300).
> >
> > This works very well too.
> >
> > Asa my categorical variables are in my Y axis, my R program reorders the
> names on Y-axis. However, I would like have and plot output with the names as
> they are. Is there any way to have plot without ordering the names of variables
> on Y-axis?
> >
> > Regards,
> > Greg.
> >
> > On Mon, Feb 12, 2018 at 10:12 AM, PIKAL Petr
> <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> >
> > Maybe there are other ways but I would split data to several chunks e.g. in
> list and use for cycle to fill multipage pdf.
> >
> > With the toy data something like
> >
> > library(reshape2)
> > library(ggplot2)
> > temp <- melt(temp)
> > temp.s<-split(temp, cut(1:nrow(temp), 2))
> >
> > pdf("temp.pdf")
> > for (i in 1: length(temp.s)) {
> > p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value),
> > colour=factor(sign(value))))
> > print(p+geom_point())
> > }
> > dev.off()
> >
> > But the real code partly depends on your real data.
> >
> > Cheers
> > Petr
> >
> > From: greg holly
> > [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
> > Sent: Saturday, February 10, 2018 9:05 PM
> >
> > To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> > Cc: r-help mailing list
> > <r-help at r-project.org<mailto:r-help at r-project.org>>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Peter;
> >
> > The R code you provided works very well. Once again thanks so much for this.
> The number of variables in my data set that should appear on the y-axis is 733
> and they are not numerical (for example the name of one variable is palmitoyl-
> arachidonoyl-glycerol (16:0/20:4) [1]*. So, the plot looks very messy in one
> page. How can I make the plot to print out on multiple pages?
> >
> > Regards,
> >
> > Greg
> >
> > On Thu, Feb 8, 2018 at 4:33 PM, greg holly
> <mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>> wrote:
> > Hi Petr;
> >
> > Thanks so much. Exactly this is what I need. I will play to change color and so
> on but this backbound is perfect to me. I do appreciate your help and support.
> >
> > Regards,
> > Greg
> >
> > On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr
> <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> > I copied your values to R, here it is
> >
> >> dput(temp)
> >
> > temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2",
> > "x3", "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
> >     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
> >     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1", "y1",
> > "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
> > -4L))
> >
> > For plotting it need to be reshaped
> >
> > library(reshape2)
> > library(ggplot2)
> >
> > temp <- melt(temp)
> > p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value),
> > colour=factor(sign(value))))
> > p+geom_point()
> >
> > Is this what you wanted?
> >
> > Cheers
> > Petr
> > And preferably do not post in HTML, the email content could be scrambled.
> >
> > From: greg holly
> > [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
> > Sent: Thursday, February 8, 2018 9:23 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> > Cc: r-help mailing list
> > <r-help at r-project.org<mailto:r-help at r-project.org>>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Petr;
> >
> > Thanks for your reply. It is much appreciated. A small example is
> > given below for 4 independent and 4 dependent variables only. The
> > values given are regression coefficients.I have looked ggplot
> > documents before writing to you. Unfortunately, I could not figure out
> > as my experience in ggplot is ignorable
> >
> > Regards.
> > Greg
> >
> > y1 y2 y3 y4
> > x1 -0.19 0.40 -0.06 0.13
> > x2 0.45 -0.75 -8.67 -0.46
> > x3 -0.09 0.14 1.42 0.06
> > x4 -0.16 -0.01 2.21 0.06
> >
> >
> > On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr
> <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> >
> > Example, example, example - preferably working.
> >
> > Wild guess - did you try ggplot?
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help
> >> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.
> >> org>] On Behalf Of greg holly
> >> Sent: Thursday, February 8, 2018 8:14 AM
> >> To: r-help mailing list
> >> <r-help at r-project.org<mailto:r-help at r-project.org>>
> >> Subject: [R] plotting the regression coefficients
> >>
> >> Hi Dear all;
> >>
> >> I would like to create a plot for regression coefficients with each
> >> independent variable (x) along the side and the phenotypes (y) across
> >> the top (as given below). For each data point, direction and
> >> magnitude of effect could be color and significance could be the size of the
> circle? Is this possible?
> >>
> >>
> >> I would greatly be appreciated your help.
> >>
> >> Thanks,
> >>
> >> Greg
> >>
> >>
> >>
> >>   y1 y2 y3 y4 y5 y6
> >> x1
> >> x2
> >> x3
> >> x4
> >> x5
> >> x6
> >> x7
> >> x8
> >> x9
> >> x10
> >> x11
> >> x12
> >> x13
> >> x14
> >> x15
> >> x16
> >> x17
> >> .
> >> .
> >>
> >
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Feb 13 15:34:21 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 13 Feb 2018 14:34:21 +0000
Subject: [R] plotting the regression coefficients
In-Reply-To: <CAM9Qe4jq+NHRtJgpMwZoJ5gXtXZodqaCJqPMnYyukeQ6mXZCLQ@mail.gmail.com>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
 <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>
 <0313f929ce0d42b2a55bbab7e25e8969@SRVEXCHCM1301.precheza.cz>
 <CAGx1TMALCEDvc-ta+8H34QCQWCijYHMqNChKGa2DxAPUHEp4Sw@mail.gmail.com>
 <CAM9Qe4jq+NHRtJgpMwZoJ5gXtXZodqaCJqPMnYyukeQ6mXZCLQ@mail.gmail.com>
Message-ID: <ffd01f64e7f64bc6895ddd83dba830be@SRVEXCHCM1301.precheza.cz>

Hi
scale_colour_gradient(?red?, ?blue?)
should do the trick.
Actually I found it by Google
ggplot colour
http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/
http://www.sthda.com/english/wiki/ggplot2-colors-how-to-change-colors-automatically-and-manually#gradient-colors-for-scatter-plots
question. So you could find it too and probably far more quickly then myself as I have also other duties.
Cheers
Petr
BTW, you still post in HTML which could be sometimes problematic in this text only list.

From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Monday, February 12, 2018 7:07 PM
To: Richard M. Heiberger <rmh at temple.edu>
Cc: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] plotting the regression coefficients

Hi Petr and Richard;

Thanks for your responses and supports.  I just faced a different problem. I have the following R codes and work well.

p <- ggplot(a, aes(x=Phenotypes, y=Metabolites, size=abs(Beta), colour=factor(sign(Beta)))) +
theme(axis.text=element_text(size = 5))
p1<-p+geom_point()
p2<-p1+theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          axis.ticks = element_blank())

p3<-p2+theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))

p4<-p3+scale_color_manual(breaks = c("-1", "0", "1"),
                        values=c("darkblue", "green", "red"))


My question is:
What if I was to repeat the analysis and standardize the beta (z-score) so they are comparable across phenotypes (I have 8 phenotypes). We could then ?bin? the betas to represent shades of red and blue.

Regards,

Greg


On Mon, Feb 12, 2018 at 8:10 PM, Richard M. Heiberger <rmh at temple.edu<mailto:rmh at temple.edu>> wrote:
Petr, there was a thinko in your response.


tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
tmp
tmp$m <- factor(tmp$m, levels=c("c","b","a","d")) ## right
tmp[order(tmp$m),]

tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
levels(tmp$m) <- c("c","b","a","d") ## wrong
tmp[order(tmp$m),]

changing levels directly changes the names only, not the ordering.
You must redefine the factor to retain the relationship of factor
names with the numerical values.

Rich


On Mon, Feb 12, 2018 at 3:49 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
> Hi
>
> After melt you can change levels of your factor variable. Again with the toy example.
>
>> levels(temp$variable)
> [1] "y1" "y2" "y3" "y4"
>> levels(temp$variable) <- levels(temp$variable)[c(2,4,1,3)]
>> levels(temp$variable)
> [1] "y2" "y4" "y1" "y3"
>>
>
> And you will get graphs with this new levels ordering.
>
> Cheers
> Petr
>
> From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
> Sent: Monday, February 12, 2018 8:52 AM
> To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] plotting the regression coefficients
>
> Hi Petr;
>
> Thanks so much. This is great! Although last Sunday, alternatively, I have solved the problem using the following statement at the very end of the program.
>
>  ggsave('circle.pdf', p4, height = 70, width = 8, device=pdf, limitsize = F, dpi=300).
>
> This works very well too.
>
> Asa my categorical variables are in my Y axis, my R program reorders the names on Y-axis. However, I would like have and plot output with the names as they are. Is there any way to have plot without ordering the names of variables on Y-axis?
>
> Regards,
> Greg.
>
> On Mon, Feb 12, 2018 at 10:12 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz><mailto:petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>> wrote:
> Hi
>
> Maybe there are other ways but I would split data to several chunks e.g. in list and use for cycle to fill multipage pdf.
>
> With the toy data something like
>
> library(reshape2)
> library(ggplot2)
> temp <- melt(temp)
> temp.s<-split(temp, cut(1:nrow(temp), 2))
>
> pdf("temp.pdf")
> for (i in 1: length(temp.s)) {
> p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
> print(p+geom_point())
> }
> dev.off()
>
> But the real code partly depends on your real data.
>
> Cheers
> Petr
>
> From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com><mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>>]
> Sent: Saturday, February 10, 2018 9:05 PM
>
> To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz><mailto:petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org><mailto:r-help at r-project.org<mailto:r-help at r-project.org>>>
> Subject: Re: [R] plotting the regression coefficients
>
> Hi Peter;
>
> The R code you provided works very well. Once again thanks so much for this. The number of variables in my data set that should appear on the y-axis is 733 and they are not numerical (for example the name of one variable is palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]*. So, the plot looks very messy in one page. How can I make the plot to print out on multiple pages?
>
> Regards,
>
> Greg
>
> On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com<mailto:mak.hholly at gmail.com><mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>>> wrote:
> Hi Petr;
>
> Thanks so much. Exactly this is what I need. I will play to change color and so on but this backbound is perfect to me. I do appreciate your help and support.
>
> Regards,
> Greg
>
> On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz><mailto:petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>> wrote:
> Hi
> I copied your values to R, here it is
>
>> dput(temp)
>
> temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
> "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
>     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
>     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
> "y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
> -4L))
>
> For plotting it need to be reshaped
>
> library(reshape2)
> library(ggplot2)
>
> temp <- melt(temp)
> p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value), colour=factor(sign(value))))
> p+geom_point()
>
> Is this what you wanted?
>
> Cheers
> Petr
> And preferably do not post in HTML, the email content could be scrambled.
>
> From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com><mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>>]
> Sent: Thursday, February 8, 2018 9:23 AM
> To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz><mailto:petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>>
> Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org><mailto:r-help at r-project.org<mailto:r-help at r-project.org>>>
> Subject: Re: [R] plotting the regression coefficients
>
> Hi Petr;
>
> Thanks for your reply. It is much appreciated. A small example is given below for 4 independent and 4 dependent variables only. The values given are regression coefficients.I have looked ggplot documents before writing to you. Unfortunately, I could not figure out as my experience in ggplot is ignorable
>
> Regards.
> Greg
>
> y1 y2 y3 y4
> x1 -0.19 0.40 -0.06 0.13
> x2 0.45 -0.75 -8.67 -0.46
> x3 -0.09 0.14 1.42 0.06
> x4 -0.16 -0.01 2.21 0.06
>
>
> On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz><mailto:petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>> wrote:
> Hi
>
> Example, example, example - preferably working.
>
> Wild guess - did you try ggplot?
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org><mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>>] On Behalf Of greg holly
>> Sent: Thursday, February 8, 2018 8:14 AM
>> To: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org><mailto:r-help at r-project.org<mailto:r-help at r-project.org>>>
>> Subject: [R] plotting the regression coefficients
>>
>> Hi Dear all;
>>
>> I would like to create a plot for regression coefficients with each independent
>> variable (x) along the side and the phenotypes (y) across the top (as given
>> below). For each data point, direction and magnitude of effect could be color
>> and significance could be the size of the circle? Is this possible?
>>
>>
>> I would greatly be appreciated your help.
>>
>> Thanks,
>>
>> Greg
>>
>>
>>
>>   y1 y2 y3 y4 y5 y6
>> x1
>> x2
>> x3
>> x4
>> x5
>> x6
>> x7
>> x8
>> x9
>> x10
>> x11
>> x12
>> x13
>> x14
>> x15
>> x16
>> x17
>> .
>> .
>>



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From samuel.knapp at tum.de  Tue Feb 13 19:31:49 2018
From: samuel.knapp at tum.de (Samuel Knapp)
Date: Tue, 13 Feb 2018 19:31:49 +0100
Subject: [R] Suppress horizontal mean line in beanplot()
Message-ID: <942f7926-0419-0117-1125-4f85f5b886c4@tum.de>

Hi,

I would like to use the beanplot() function from the beanplot package. 
Unfortunately, I can't find out how to suppress the dashed horizontal 
line, that shows the overall mean.

In the help I've found the argument "overallline", but it only allows 
for "mean" or "median" .

I have tried overallline = F, overallline="n", and overallline="", but 
without success.

Strangely, I could also not find any suggestions on the internet.

Does anybody know how to do this?

Thanks,

Samuel

## Example code using the dataset InsectSprays from datasets package

library(beanplot)

beanplot(count ~ spray, data = InsectSprays)

# How to remove the dashed horizonal line?



-- 
Samuel Knapp

Lehrstuhl f?r Pflanzenern?hrung
Technische Universit?t M?nchen
(Chair of Plant Nutrition
Technical University of Munich)

Emil-Ramann-Strasse 2
D-85354 Freising

Tel. +49 8161 71-3578	
samuel.knapp at tum.de
www.researchgate.net/profile/Samuel_Knapp


From paul at stat.auckland.ac.nz  Tue Feb 13 19:48:08 2018
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 14 Feb 2018 07:48:08 +1300
Subject: [R] [FORGED]  Suppress horizontal mean line in beanplot()
In-Reply-To: <942f7926-0419-0117-1125-4f85f5b886c4@tum.de>
References: <942f7926-0419-0117-1125-4f85f5b886c4@tum.de>
Message-ID: <38394d55-0b28-970e-906d-093a10204c54@stat.auckland.ac.nz>

Hi

Does this do the trick ... ?

library(beanplot)
beanplot(count ~ spray, data = InsectSprays)

library(gridGraphics)
grid.echo()
grid.remove("abline", grep=TRUE)

Paul

On 14/02/18 07:31, Samuel Knapp wrote:
> Hi,
> 
> I would like to use the beanplot() function from the beanplot package. 
> Unfortunately, I can't find out how to suppress the dashed horizontal 
> line, that shows the overall mean.
> 
> In the help I've found the argument "overallline", but it only allows 
> for "mean" or "median" .
> 
> I have tried overallline = F, overallline="n", and overallline="", but 
> without success.
> 
> Strangely, I could also not find any suggestions on the internet.
> 
> Does anybody know how to do this?
> 
> Thanks,
> 
> Samuel
> 
> ## Example code using the dataset InsectSprays from datasets package
> 
> library(beanplot)
> 
> beanplot(count ~ spray, data = InsectSprays)
> 
> # How to remove the dashed horizonal line?
> 
> 
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From mak.hholly at gmail.com  Tue Feb 13 19:00:34 2018
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 13 Feb 2018 21:00:34 +0300
Subject: [R] plotting the regression coefficients
In-Reply-To: <ffd01f64e7f64bc6895ddd83dba830be@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4hb208Bn9fqJp7etp2OfdiMSxMABczT=Wu=ocdUHTidwA@mail.gmail.com>
 <438c814448e14a0fa533537e23c28fc5@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4hf-mSj_w3bKFB5B7mLknqZA3GyrYMzt6K3bceGa7rTMQ@mail.gmail.com>
 <2a1c4bec6870487099537613d0b770e8@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4g2Hx9y8LYDSeaUVf6ba71qSAmJ+1+6ZvfAJFQRZXwRVQ@mail.gmail.com>
 <CAM9Qe4jgp783+qFaer3e=1ux6BkA3fnrHm+zToZGqNYyEFU=yg@mail.gmail.com>
 <011484e03c8c495589b20752719f073e@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4gGNwZnsp60q-RwNgmPqygNT7sdy8kk6=R54W7awhzoyA@mail.gmail.com>
 <0313f929ce0d42b2a55bbab7e25e8969@SRVEXCHCM1301.precheza.cz>
 <CAGx1TMALCEDvc-ta+8H34QCQWCijYHMqNChKGa2DxAPUHEp4Sw@mail.gmail.com>
 <CAM9Qe4jq+NHRtJgpMwZoJ5gXtXZodqaCJqPMnYyukeQ6mXZCLQ@mail.gmail.com>
 <ffd01f64e7f64bc6895ddd83dba830be@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAM9Qe4isY7qcoHGyXu3NCYYBs-bU-yzd_vuTWPzVCGd4WQCcZA@mail.gmail.com>

Hi Petr;

Thanks for this. I have used  scale_colour_gradient before but could not
get what I am looking for. I will check the links you provide to get Idea.
Once again thanks for your support and help.

Rgerads,
Greg



On Tue, Feb 13, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> scale_colour_gradient(?red?, ?blue?)
>
> should do the trick.
>
> Actually I found it by Google
>
> ggplot colour
>
> http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/
>
> http://www.sthda.com/english/wiki/ggplot2-colors-how-to-
> change-colors-automatically-and-manually#gradient-colors-for-scatter-plots
>
> question. So you could find it too and probably far more quickly then
> myself as I have also other duties.
>
> Cheers
>
> Petr
>
> BTW, you still post in HTML which could be sometimes problematic in this
> text only list.
>
>
>
> *From:* greg holly [mailto:mak.hholly at gmail.com]
> *Sent:* Monday, February 12, 2018 7:07 PM
> *To:* Richard M. Heiberger <rmh at temple.edu>
> *Cc:* PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <
> r-help at r-project.org>
>
> *Subject:* Re: [R] plotting the regression coefficients
>
>
>
> Hi Petr and Richard;
>
>
>
> Thanks for your responses and supports.  I just faced a different problem.
> I have the following R codes and work well.
>
>
>
> p <- ggplot(a, aes(x=Phenotypes, y=Metabolites, size=abs(Beta),
> colour=factor(sign(Beta)))) +
>
> theme(axis.text=element_text(size = 5))
>
> p1<-p+geom_point()
>
> p2<-p1+theme(panel.grid.major = element_blank(),
>
>           panel.grid.minor = element_blank(),
>
>           panel.border = element_blank(),
>
>           axis.ticks = element_blank())
>
>
>
> p3<-p2+theme(panel.grid.major = element_blank(), panel.grid.minor =
> element_blank(),
>
> panel.background = element_blank(), axis.line = element_line(colour =
> "black"))
>
>
>
> p4<-p3+scale_color_manual(breaks = c("-1", "0", "1"),
>
>                         values=c("darkblue", "green", "red"))
>
>
>
>
>
> *My question is:*
>
> What if I was to repeat the analysis and standardize the beta (z-score) so
> they are comparable across phenotypes (I have 8 phenotypes). We could then
> ?bin? the betas to represent shades of red and blue.
>
>
>
> Regards,
>
>
>
> Greg
>
>
>
>
>
> On Mon, Feb 12, 2018 at 8:10 PM, Richard M. Heiberger <rmh at temple.edu>
> wrote:
>
> Petr, there was a thinko in your response.
>
>
> tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
> tmp
> tmp$m <- factor(tmp$m, levels=c("c","b","a","d")) ## right
> tmp[order(tmp$m),]
>
> tmp <- data.frame(m=factor(letters[1:4]), n=1:4)
> levels(tmp$m) <- c("c","b","a","d") ## wrong
> tmp[order(tmp$m),]
>
> changing levels directly changes the names only, not the ordering.
> You must redefine the factor to retain the relationship of factor
> names with the numerical values.
>
> Rich
>
>
> On Mon, Feb 12, 2018 at 3:49 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hi
> >
> > After melt you can change levels of your factor variable. Again with the
> toy example.
> >
> >> levels(temp$variable)
> > [1] "y1" "y2" "y3" "y4"
> >> levels(temp$variable) <- levels(temp$variable)[c(2,4,1,3)]
> >> levels(temp$variable)
> > [1] "y2" "y4" "y1" "y3"
> >>
> >
> > And you will get graphs with this new levels ordering.
> >
> > Cheers
> > Petr
> >
> > From: greg holly [mailto:mak.hholly at gmail.com]
> > Sent: Monday, February 12, 2018 8:52 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Petr;
> >
> > Thanks so much. This is great! Although last Sunday, alternatively, I
> have solved the problem using the following statement at the very end of
> the program.
> >
> >  ggsave('circle.pdf', p4, height = 70, width = 8, device=pdf, limitsize
> = F, dpi=300).
> >
> > This works very well too.
> >
> > Asa my categorical variables are in my Y axis, my R program reorders the
> names on Y-axis. However, I would like have and plot output with the names
> as they are. Is there any way to have plot without ordering the names of
> variables on Y-axis?
> >
> > Regards,
> > Greg.
> >
> > On Mon, Feb 12, 2018 at 10:12 AM, PIKAL Petr <petr.pikal at precheza.cz<
> mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> >
> > Maybe there are other ways but I would split data to several chunks e.g.
> in list and use for cycle to fill multipage pdf.
> >
> > With the toy data something like
> >
> > library(reshape2)
> > library(ggplot2)
> > temp <- melt(temp)
> > temp.s<-split(temp, cut(1:nrow(temp), 2))
> >
> > pdf("temp.pdf")
> > for (i in 1: length(temp.s)) {
> > p <- ggplot(temp.s[[i]], aes(x=par1, y=variable, size=abs(value),
> colour=factor(sign(value))))
> > print(p+geom_point())
> > }
> > dev.off()
> >
> > But the real code partly depends on your real data.
> >
> > Cheers
> > Petr
> >
> > From: greg holly [mailto:mak.hholly at gmail.com<mailto:
> mak.hholly at gmail.com>]
> > Sent: Saturday, February 10, 2018 9:05 PM
> >
> > To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> > Cc: r-help mailing list <r-help at r-project.org<mailto:r
> -help at r-project.org>>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Peter;
> >
> > The R code you provided works very well. Once again thanks so much for
> this. The number of variables in my data set that should appear on the
> y-axis is 733 and they are not numerical (for example the name of one
> variable is palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]*. So, the
> plot looks very messy in one page. How can I make the plot to print out on
> multiple pages?
> >
> > Regards,
> >
> > Greg
> >
> > On Thu, Feb 8, 2018 at 4:33 PM, greg holly <mak.hholly at gmail.com<mailto:
> mak.hholly at gmail.com>> wrote:
> > Hi Petr;
> >
> > Thanks so much. Exactly this is what I need. I will play to change color
> and so on but this backbound is perfect to me. I do appreciate your help
> and support.
> >
> > Regards,
> > Greg
> >
> > On Thu, Feb 8, 2018 at 1:29 PM, PIKAL Petr <petr.pikal at precheza.cz<
> mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> > I copied your values to R, here it is
> >
> >> dput(temp)
> >
> > temp <- structure(list(par1 = structure(1:4, .Label = c("x1", "x2", "x3",
> > "x4"), class = "factor"), y1 = c(-0.19, 0.45, -0.09, -0.16),
> >     y2 = c(0.4, -0.75, 0.14, -0.01), y3 = c(-0.06, -8.67, 1.42,
> >     2.21), y4 = c(0.13, -0.46, 0.06, 0.06)), .Names = c("par1",
> > "y1", "y2", "y3", "y4"), class = "data.frame", row.names = c(NA,
> > -4L))
> >
> > For plotting it need to be reshaped
> >
> > library(reshape2)
> > library(ggplot2)
> >
> > temp <- melt(temp)
> > p <- ggplot(temp, aes(x=par1, y=variable, size=abs(value),
> colour=factor(sign(value))))
> > p+geom_point()
> >
> > Is this what you wanted?
> >
> > Cheers
> > Petr
> > And preferably do not post in HTML, the email content could be scrambled.
> >
> > From: greg holly [mailto:mak.hholly at gmail.com<mailto:
> mak.hholly at gmail.com>]
> > Sent: Thursday, February 8, 2018 9:23 AM
> > To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
> > Cc: r-help mailing list <r-help at r-project.org<mailto:r
> -help at r-project.org>>
> > Subject: Re: [R] plotting the regression coefficients
> >
> > Hi Petr;
> >
> > Thanks for your reply. It is much appreciated. A small example is given
> below for 4 independent and 4 dependent variables only. The values given
> are regression coefficients.I have looked ggplot documents before writing
> to you. Unfortunately, I could not figure out as my experience in ggplot is
> ignorable
> >
> > Regards.
> > Greg
> >
> > y1 y2 y3 y4
> > x1 -0.19 0.40 -0.06 0.13
> > x2 0.45 -0.75 -8.67 -0.46
> > x3 -0.09 0.14 1.42 0.06
> > x4 -0.16 -0.01 2.21 0.06
> >
> >
> > On Thu, Feb 8, 2018 at 10:19 AM, PIKAL Petr <petr.pikal at precheza.cz<
> mailto:petr.pikal at precheza.cz>> wrote:
> > Hi
> >
> > Example, example, example - preferably working.
> >
> > Wild guess - did you try ggplot?
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-
> bounces at r-project.org>] On Behalf Of greg holly
> >> Sent: Thursday, February 8, 2018 8:14 AM
>
> >> To: r-help mailing list <r-help at r-project.org<mailto:r
> -help at r-project.org>>
> >> Subject: [R] plotting the regression coefficients
> >>
> >> Hi Dear all;
> >>
> >> I would like to create a plot for regression coefficients with each
> independent
> >> variable (x) along the side and the phenotypes (y) across the top (as
> given
> >> below). For each data point, direction and magnitude of effect could be
> color
> >> and significance could be the size of the circle? Is this possible?
> >>
> >>
> >> I would greatly be appreciated your help.
> >>
> >> Thanks,
> >>
> >> Greg
> >>
> >>
> >>
> >>   y1 y2 y3 y4 y5 y6
> >> x1
> >> x2
> >> x3
> >> x4
> >> x5
> >> x6
> >> x7
> >> x8
> >> x9
> >> x10
> >> x11
> >> x12
> >> x13
> >> x14
> >> x15
> >> x16
> >> x17
> >> .
> >> .
> >>
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From mashranga at yahoo.com  Tue Feb 13 19:55:56 2018
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Tue, 13 Feb 2018 18:55:56 +0000 (UTC)
Subject: [R] Suppress horizontal mean line in beanplot()
In-Reply-To: <942f7926-0419-0117-1125-4f85f5b886c4@tum.de>
References: <942f7926-0419-0117-1125-4f85f5b886c4@tum.de>
Message-ID: <445980961.264753.1518548156844@mail.yahoo.com>

hi,?

Check this?

beanplot(count ~ spray, data = InsectSprays, what = c(FALSE, TRUE, TRUE, TRUE))

>From R function help :?
what :? a vector of four booleans describing what to plot. In the following order, these booleans stand for the total average line, the beans, the bean average, and the beanlines. For example, what=c(0,0,0,1) produces a stripchart


ggplot can be helpful

library(ggplot2)
p <- ggplot(InsectSprays, aes(factor(spray), count, fill=factor(spray) ))+ geom_violin()
print(p)

Regards.............
Tanvir Ahamed 
Stockholm, Sweden???? |??mashranga at yahoo.com 






On Tuesday, February 13, 2018, 7:32:22 PM GMT+1, Samuel Knapp <samuel.knapp at tum.de> wrote: 





Hi,

I would like to use the beanplot() function from the beanplot package. 
Unfortunately, I can't find out how to suppress the dashed horizontal 
line, that shows the overall mean.

In the help I've found the argument "overallline", but it only allows 
for "mean" or "median" .

I have tried overallline = F, overallline="n", and overallline="", but 
without success.

Strangely, I could also not find any suggestions on the internet.

Does anybody know how to do this?

Thanks,

Samuel

## Example code using the dataset InsectSprays from datasets package

library(beanplot)

beanplot(count ~ spray, data = InsectSprays)

# How to remove the dashed horizonal line?



-- 
Samuel Knapp

Lehrstuhl f?r Pflanzenern?hrung
Technische Universit?t M?nchen
(Chair of Plant Nutrition
Technical University of Munich)

Emil-Ramann-Strasse 2
D-85354 Freising

Tel. +49 8161 71-3578??? 
samuel.knapp at tum.de
www.researchgate.net/profile/Samuel_Knapp

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb 13 20:02:58 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Feb 2018 11:02:58 -0800
Subject: [R] Suppress horizontal mean line in beanplot()
In-Reply-To: <942f7926-0419-0117-1125-4f85f5b886c4@tum.de>
References: <942f7926-0419-0117-1125-4f85f5b886c4@tum.de>
Message-ID: <CAGxFJbTwcF4081fY8d8Zn_J3eo7FYy+jwHmDGwCeG962uaYDFg@mail.gmail.com>

The package docs seem to provide your answer -- you just need to read them
more carefully:
See the "what" argument of ?beanplot.
Setting the first entry of the vector to 0 would seem to suppress the
overall mean.

Apologies if I've misread/misinterpreted.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 13, 2018 at 10:31 AM, Samuel Knapp <samuel.knapp at tum.de> wrote:

> Hi,
>
> I would like to use the beanplot() function from the beanplot package.
> Unfortunately, I can't find out how to suppress the dashed horizontal line,
> that shows the overall mean.
>
> In the help I've found the argument "overallline", but it only allows for
> "mean" or "median" .
>
> I have tried overallline = F, overallline="n", and overallline="", but
> without success.
>
> Strangely, I could also not find any suggestions on the internet.
>
> Does anybody know how to do this?
>
> Thanks,
>
> Samuel
>
> ## Example code using the dataset InsectSprays from datasets package
>
> library(beanplot)
>
> beanplot(count ~ spray, data = InsectSprays)
>
> # How to remove the dashed horizonal line?
>
>
>
> --
> Samuel Knapp
>
> Lehrstuhl f?r Pflanzenern?hrung
> Technische Universit?t M?nchen
> (Chair of Plant Nutrition
> Technical University of Munich)
>
> Emil-Ramann-Strasse 2
> D-85354 Freising
>
> Tel. +49 8161 71-3578
> samuel.knapp at tum.de
> www.researchgate.net/profile/Samuel_Knapp
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pmwansa at shaw.ca  Tue Feb 13 20:17:06 2018
From: pmwansa at shaw.ca (Pius Mwansa)
Date: Tue, 13 Feb 2018 12:17:06 -0700
Subject: [R] LSmeans and lsmeans
Message-ID: <009101d3a4ff$3dd3c1e0$b97b45a0$@shaw.ca>

Is there a difference between LSmeans and lsmeans functions in R?

Thanks,

Pius


From rjames at sk.com  Tue Feb 13 20:55:56 2018
From: rjames at sk.com (JamesRyan(Ryan James)/E&P North America Business Division)
Date: Tue, 13 Feb 2018 19:55:56 +0000
Subject: [R] Best Optimization Routines
Message-ID: <a7f88e623cb04744bfe3bceb030eff16@sk.com>

I have a set of data, the production of oil from a well.? And an equation to predict that forecast.? 

The equation requires 5 input variables which are real numbers with upper and lower bounds, 1 input variable which must be an integer and 1 input variable which can be 1 of 2 string variables.? 

What is the best optimization routine (I am using nlminb) to use in R to determine the best set of inputs and how to I handle the integer and string inputs when optimizing? ?

I have attached a plot of what I am trying to accomplish as well as my sample code.  

Thanks,

Ryan



-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.pdf
Type: application/pdf
Size: 4470 bytes
Desc: Rplot.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180213/885e45d5/attachment.pdf>

From rssmith218 at gmail.com  Tue Feb 13 22:35:04 2018
From: rssmith218 at gmail.com (Rachel S Smith)
Date: Tue, 13 Feb 2018 16:35:04 -0500
Subject: [R] Tukey and extracting letters in multcomp
Message-ID: <E0E51C75-B16B-492B-8879-259676599571@gmail.com>

Hi Lauren, 

Did you ever receive an answer on this? I?ve been having the same errors, and am stumped, so I?d love to hear how you sorted this out with your models. Thanks for your help!

Cheers, 

Rachel

--
Rachel Smith
PhD Candidate
Odum School of Ecology
University of Georgia
Athens, GA 30602

From bgunter.4567 at gmail.com  Wed Feb 14 00:16:15 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Feb 2018 15:16:15 -0800
Subject: [R] LSmeans and lsmeans
In-Reply-To: <009101d3a4ff$3dd3c1e0$b97b45a0$@shaw.ca>
References: <009101d3a4ff$3dd3c1e0$b97b45a0$@shaw.ca>
Message-ID: <CAGxFJbSVbYM=9FvE3JZNKR89BvAyaViTnJoXSQb_7x=nvsWcVQ@mail.gmail.com>

In what packages?

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 13, 2018 at 11:17 AM, Pius Mwansa <pmwansa at shaw.ca> wrote:

> Is there a difference between LSmeans and lsmeans functions in R?
>
> Thanks,
>
> Pius
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 14 00:32:11 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Feb 2018 15:32:11 -0800
Subject: [R] LSmeans and lsmeans
In-Reply-To: <000201d3a521$344c5d40$9ce517c0$@shaw.ca>
References: <009101d3a4ff$3dd3c1e0$b97b45a0$@shaw.ca>
 <CAGxFJbSVbYM=9FvE3JZNKR89BvAyaViTnJoXSQb_7x=nvsWcVQ@mail.gmail.com>
 <000201d3a521$344c5d40$9ce517c0$@shaw.ca>
Message-ID: <CAGxFJbTLqOFXguRSfTeAi=hRptJxN1a-6TbdzQ-S91-KPBQs2w@mail.gmail.com>

Always cc the list unless there is good reason to keep your reply private.

There is no LSmeans() function in the lsmeans package.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 13, 2018 at 3:20 PM, Pius Mwansa <pmwansa at shaw.ca> wrote:

> They are in the lsmeans package.
>
>
>
> Pius
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Tuesday, February 13, 2018 4:16 PM
> *To:* Pius Mwansa <pmwansa at shaw.ca>
> *Cc:* R-help <r-help at r-project.org>
> *Subject:* Re: [R] LSmeans and lsmeans
>
>
>
> In what packages?
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
> On Tue, Feb 13, 2018 at 11:17 AM, Pius Mwansa <pmwansa at shaw.ca> wrote:
>
> Is there a difference between LSmeans and lsmeans functions in R?
>
> Thanks,
>
> Pius
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 14 00:41:37 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Feb 2018 15:41:37 -0800
Subject: [R] LSmeans and lsmeans
In-Reply-To: <000901d3a523$c0401560$40c04020$@shaw.ca>
References: <009101d3a4ff$3dd3c1e0$b97b45a0$@shaw.ca>
 <CAGxFJbSVbYM=9FvE3JZNKR89BvAyaViTnJoXSQb_7x=nvsWcVQ@mail.gmail.com>
 <000201d3a521$344c5d40$9ce517c0$@shaw.ca>
 <CAGxFJbTLqOFXguRSfTeAi=hRptJxN1a-6TbdzQ-S91-KPBQs2w@mail.gmail.com>
 <000901d3a523$c0401560$40c04020$@shaw.ca>
Message-ID: <CAGxFJbT75wTNp1vEr9Wsgb+F2t7shDMQkM9kTy8w3kbhfDFYMQ@mail.gmail.com>

A cursory reading indicates that they are identical; but others more
knowledgeable than I need to confirm or deny this.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 13, 2018 at 3:38 PM, Pius Mwansa <pmwansa at shaw.ca> wrote:

> It is in the doBy package.
>
>
>
> Thanks
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Tuesday, February 13, 2018 4:32 PM
>
> *To:* Pius Mwansa <pmwansa at shaw.ca>
> *Cc:* R-help <r-help at r-project.org>
> *Subject:* Re: [R] LSmeans and lsmeans
>
>
>
> Always cc the list unless there is good reason to keep your reply private.
>
> There is no LSmeans() function in the lsmeans package.
>
> Cheers,
>
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
> On Tue, Feb 13, 2018 at 3:20 PM, Pius Mwansa <pmwansa at shaw.ca> wrote:
>
> They are in the lsmeans package.
>
>
>
> Pius
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Tuesday, February 13, 2018 4:16 PM
> *To:* Pius Mwansa <pmwansa at shaw.ca>
> *Cc:* R-help <r-help at r-project.org>
> *Subject:* Re: [R] LSmeans and lsmeans
>
>
>
> In what packages?
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
> On Tue, Feb 13, 2018 at 11:17 AM, Pius Mwansa <pmwansa at shaw.ca> wrote:
>
> Is there a difference between LSmeans and lsmeans functions in R?
>
> Thanks,
>
> Pius
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From arrayprofile at yahoo.com  Wed Feb 14 01:02:06 2018
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 14 Feb 2018 00:02:06 +0000 (UTC)
Subject: [R] Fleming-Harrington weighted log rank test
References: <1927370176.471494.1518566526278.ref@mail.yahoo.com>
Message-ID: <1927370176.471494.1518566526278@mail.yahoo.com>

Hi all,?

The survdiff() from survival package has an argument "rho" that implements Fleming-Harrington weighted long rank test.?

But according to several sources including "survminer" package (https://cran.r-project.org/web/packages/survminer/vignettes/Specifiying_weights_in_log-rank_comparisons.html), Fleming-Harrington weighted log-rank test should have 2 parameters "p" and "q" to control the weighting for earlier vs later times in the follow-up.

For example, setting rho=1 in survdiff() uses the Peto-Peto modification of Gehan-Wilcox weights, which I can confirm by setting p=1 & 1=0 in comp() from survminer package. similarly rho=0 is equivalent to p=0 & q=0

I am interested in putting more weights on survival difference in later follow-up time. According to comp() from survminer package, that would set p=0 & q=1 for Fleming-Harrington weights.?

My question is how I can do the same by setting certain values for "rho" in the regular survival() function?

Thank you,

John


From pmwansa at shaw.ca  Wed Feb 14 00:38:27 2018
From: pmwansa at shaw.ca (Pius Mwansa)
Date: Tue, 13 Feb 2018 16:38:27 -0700
Subject: [R] LSmeans and lsmeans
In-Reply-To: <CAGxFJbTLqOFXguRSfTeAi=hRptJxN1a-6TbdzQ-S91-KPBQs2w@mail.gmail.com>
References: <009101d3a4ff$3dd3c1e0$b97b45a0$@shaw.ca>
 <CAGxFJbSVbYM=9FvE3JZNKR89BvAyaViTnJoXSQb_7x=nvsWcVQ@mail.gmail.com>
 <000201d3a521$344c5d40$9ce517c0$@shaw.ca>
 <CAGxFJbTLqOFXguRSfTeAi=hRptJxN1a-6TbdzQ-S91-KPBQs2w@mail.gmail.com>
Message-ID: <000901d3a523$c0401560$40c04020$@shaw.ca>

It is in the doBy package.

 

Thanks

 

From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Tuesday, February 13, 2018 4:32 PM
To: Pius Mwansa <pmwansa at shaw.ca>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] LSmeans and lsmeans

 

Always cc the list unless there is good reason to keep your reply private.

There is no LSmeans() function in the lsmeans package.

Cheers,

Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

 

On Tue, Feb 13, 2018 at 3:20 PM, Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> > wrote:

They are in the lsmeans package.

 

Pius

 

From: Bert Gunter [mailto:bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com> ] 
Sent: Tuesday, February 13, 2018 4:16 PM
To: Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> >
Cc: R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: Re: [R] LSmeans and lsmeans

 

In what packages?

-- Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

 

On Tue, Feb 13, 2018 at 11:17 AM, Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> > wrote:

Is there a difference between LSmeans and lsmeans functions in R?

Thanks,

Pius

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.






	[[alternative HTML version deleted]]


From pmwansa at shaw.ca  Wed Feb 14 00:47:33 2018
From: pmwansa at shaw.ca (Pius Mwansa)
Date: Tue, 13 Feb 2018 16:47:33 -0700
Subject: [R] LSmeans and lsmeans
In-Reply-To: <CAGxFJbT75wTNp1vEr9Wsgb+F2t7shDMQkM9kTy8w3kbhfDFYMQ@mail.gmail.com>
References: <009101d3a4ff$3dd3c1e0$b97b45a0$@shaw.ca>
 <CAGxFJbSVbYM=9FvE3JZNKR89BvAyaViTnJoXSQb_7x=nvsWcVQ@mail.gmail.com>
 <000201d3a521$344c5d40$9ce517c0$@shaw.ca>
 <CAGxFJbTLqOFXguRSfTeAi=hRptJxN1a-6TbdzQ-S91-KPBQs2w@mail.gmail.com>
 <000901d3a523$c0401560$40c04020$@shaw.ca>
 <CAGxFJbT75wTNp1vEr9Wsgb+F2t7shDMQkM9kTy8w3kbhfDFYMQ@mail.gmail.com>
Message-ID: <001201d3a525$05a8adf0$10fa09d0$@shaw.ca>

Thanks Bert.

 

From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Tuesday, February 13, 2018 4:42 PM
To: Pius Mwansa <pmwansa at shaw.ca>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] LSmeans and lsmeans

 

A cursory reading indicates that they are identical; but others more knowledgeable than I need to confirm or deny this.

-- Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

 

On Tue, Feb 13, 2018 at 3:38 PM, Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> > wrote:

It is in the doBy package.

 

Thanks

 

From: Bert Gunter [mailto:bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com> ] 
Sent: Tuesday, February 13, 2018 4:32 PM


To: Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> >
Cc: R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: Re: [R] LSmeans and lsmeans

 

Always cc the list unless there is good reason to keep your reply private.

There is no LSmeans() function in the lsmeans package.

Cheers,

Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

 

On Tue, Feb 13, 2018 at 3:20 PM, Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> > wrote:

They are in the lsmeans package.

 

Pius

 

From: Bert Gunter [mailto:bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com> ] 
Sent: Tuesday, February 13, 2018 4:16 PM
To: Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> >
Cc: R-help <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: Re: [R] LSmeans and lsmeans

 

In what packages?

-- Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

 

On Tue, Feb 13, 2018 at 11:17 AM, Pius Mwansa <pmwansa at shaw.ca <mailto:pmwansa at shaw.ca> > wrote:

Is there a difference between LSmeans and lsmeans functions in R?

Thanks,

Pius

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.








	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Wed Feb 14 07:55:40 2018
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 14 Feb 2018 19:55:40 +1300
Subject: [R] Using gutenbergr with a firewall
Message-ID: <20180214065540.GA7936@slingshot.co.nz>

I can use the gutenberg_download() function in the gutenbergr package
on a computer that doeson't use a firewall, but on an almost identical
installation that is behind a firewall, nothing happens, not even a
time-out.

Has anyone succeeded in using gutenberg_download() successfully with a
firewall?  I tried raising an issue at
https://github.com/ropenscilabs/gutenbergr/issues/17 with no usable
response.  I also tried contacting the maintainer but got no response.

The firewall might be a red-herring, but I thought it worthwhile
eliminating it as a factor.

I would welcome any information on anyone else's experience.

Thank you.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From jdnewmil at dcn.davis.ca.us  Wed Feb 14 08:25:35 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 13 Feb 2018 23:25:35 -0800
Subject: [R] Using gutenbergr with a firewall
In-Reply-To: <20180214065540.GA7936@slingshot.co.nz>
References: <20180214065540.GA7936@slingshot.co.nz>
Message-ID: <B93F28D1-A843-4665-8EA2-9D132C27EAD0@dcn.davis.ca.us>

Saying "a firewall" is like saying "a weapon". Some firewalls are much more strict than others, and yours may be different than any someone here might have encountered. You might also be having trouble with anti virus software.
-- 
Sent from my phone. Please excuse my brevity.

On February 13, 2018 10:55:40 PM PST, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>I can use the gutenberg_download() function in the gutenbergr package
>on a computer that doeson't use a firewall, but on an almost identical
>installation that is behind a firewall, nothing happens, not even a
>time-out.
>
>Has anyone succeeded in using gutenberg_download() successfully with a
>firewall?  I tried raising an issue at
>https://github.com/ropenscilabs/gutenbergr/issues/17 with no usable
>response.  I also tried contacting the maintainer but got no response.
>
>The firewall might be a red-herring, but I thought it worthwhile
>eliminating it as a factor.
>
>I would welcome any information on anyone else's experience.
>
>Thank you.


From ayhanyuksel78 at gmail.com  Wed Feb 14 08:47:48 2018
From: ayhanyuksel78 at gmail.com (Ayhan yuksel)
Date: Wed, 14 Feb 2018 10:47:48 +0300
Subject: [R] How to turn off warnings about class name conflicts
Message-ID: <CALj2E8WXXHjA3xfZ541cNr+QcpYL-2S27_sTr=yvSbBfggrC5w@mail.gmail.com>

Hi,

I am using two packages (quantmod and FRAPO)

Quantmod and FRAPO both have a class names "zoo"

R is displaying the following warning when I manipulate an object of class
zoo:

Found more than one class "zoo" in cache; using the first, from namespace
'quantmod'
Also defined by ?FRAPO?

The warning is displayed every time I manipulate a zoo object and becomes
pretty annoying.

I searched for a solution but couldn't found.

A related but unanswered question is here:
http://r.789695.n4.nabble.com/setOldClass-quot-xts-quot-td4714332.html

How can I turn off the warning?

Reproducible example:

library(quantmod)
library(FRAPO)
z<-zoo(runif(100),1:100)


Session Info (I am using Microsoft R):

R version 3.4.3 (2017-11-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] FRAPO_0.4-1           timeSeries_3022.101.2 timeDate_3012.100
 Rglpk_0.6-2
 [5] slam_0.1-40           cccp_0.2-4            quantmod_0.4-12
 TTR_0.23-2
 [9] xts_0.10-1            zoo_1.8-0             RevoUtils_10.0.7
RevoUtilsMath_10.0.1

loaded via a namespace (and not attached):
[1] Rcpp_0.12.10     lattice_0.20-35  codetools_0.2-15 grid_3.4.3
 curl_3.1
[6] tools_3.4.3      compiler_3.4.3

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Wed Feb 14 10:16:13 2018
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Wed, 14 Feb 2018 01:16:13 -0800
Subject: [R] How to turn off warnings about class name conflicts
In-Reply-To: <CALj2E8WXXHjA3xfZ541cNr+QcpYL-2S27_sTr=yvSbBfggrC5w@mail.gmail.com>
References: <CALj2E8WXXHjA3xfZ541cNr+QcpYL-2S27_sTr=yvSbBfggrC5w@mail.gmail.com>
Message-ID: <db3369ef-c38f-ccba-a78b-6b480a5aabab@gmail.com>

On 2/13/2018 11:47 PM, Ayhan yuksel wrote:
> Hi,
> 
> I am using two packages (quantmod and FRAPO)
> 
> Quantmod and FRAPO both have a class names "zoo"
> 
> R is displaying the following warning when I manipulate an object of class
> zoo:
> 
> Found more than one class "zoo" in cache; using the first, from namespace
> 'quantmod'
> Also defined by ?FRAPO?
> 
> The warning is displayed every time I manipulate a zoo object and becomes
> pretty annoying.
> 
> I searched for a solution but couldn't found.
> 
> A related but unanswered question is here:
> http://r.789695.n4.nabble.com/setOldClass-quot-xts-quot-td4714332.html
> 
> How can I turn off the warning?
> 
> Reproducible example:
> 
> library(quantmod)
> library(FRAPO)
> z<-zoo(runif(100),1:100)
> 
> 
> Session Info (I am using Microsoft R):
> 
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> 
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
>   [1] FRAPO_0.4-1           timeSeries_3022.101.2 timeDate_3012.100
>   Rglpk_0.6-2
>   [5] slam_0.1-40           cccp_0.2-4            quantmod_0.4-12
>   TTR_0.23-2
>   [9] xts_0.10-1            zoo_1.8-0             RevoUtils_10.0.7
> RevoUtilsMath_10.0.1
> 
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.10     lattice_0.20-35  codetools_0.2-15 grid_3.4.3
>   curl_3.1
> [6] tools_3.4.3      compiler_3.4.3
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

I tried your example (in a clean session) under R-3.4.3 from CRAN and 
Microsoft R Open 3.4.3.0 and did not get the message you are getting.  I 
suspect you have something in your workspace that is causing the problem.

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From kevin.thorpe at utoronto.ca  Wed Feb 14 15:43:53 2018
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 14 Feb 2018 09:43:53 -0500
Subject: [R] Unexpected behaviour in rms::lrtest
Message-ID: <44d5df6e-bb82-9ea8-cb3a-c3e7736412d2@utoronto.ca>

Hello.

One of my teaching assistants was experimenting and encountered 
unexpected behaviour with the lrtest function in the rms package. It 
appears that when you have a pair of non-nested models that employ an 
RCS, the error checking for non-nested models appears not to work.

Here is a reproducible example.

 > library(rms)
Loading required package: Hmisc
Loading required package: lattice
Loading required package: survival
Loading required package: Formula
Loading required package: ggplot2

Attaching package: ?Hmisc?

The following objects are masked from ?package:base?:

     format.pval, units

Loading required package: SparseM

Attaching package: ?SparseM?

The following object is masked from ?package:base?:

     backsolve

 >
 > ### Code below that generates the data taken from the
 > ### help page for lrm()
 >
 > n <- 1000    # define sample size
 > set.seed(17) # so can reproduce the results
 > age            <- rnorm(n, 50, 10)
 > blood.pressure <- rnorm(n, 120, 15)
 > cholesterol    <- rnorm(n, 200, 25)
 > sex            <- factor(sample(c('female','male'), n,TRUE))
 > label(age)            <- 'Age'      # label is in Hmisc
 > label(cholesterol)    <- 'Total Cholesterol'
 > label(blood.pressure) <- 'Systolic Blood Pressure'
 > label(sex)            <- 'Sex'
 > units(cholesterol)    <- 'mg/dl'   # uses units.default in Hmisc
 > units(blood.pressure) <- 'mmHg'
 >
 > # Specify population model for log odds that Y=1
 > L <- .4*(sex=='male') + .045*(age-50) +
+      (log(cholesterol - 10)-5.2)*(-2*(sex=='female') + 2*(sex=='male'))
 > # Simulate binary y to have Prob(y=1) = 1/[1+exp(-L)]
 > y <- ifelse(runif(n) < plogis(L), 1, 0)
 >
 > exdata <- 
data.frame(y=y,age=age,blood.pressure=blood.pressure,cholesterol=cholesterol,sex=sex)
 >
 > ###
 > ### Example
 > ###
 >
 > fit1 <- lrm(y ~ blood.pressure + sex * age + cholesterol, data = exdata)
 > fit2 <- lrm(y ~ blood.pressure + age + sex * cholesterol, data = exdata)
 > lrtest(fit1, fit2) # error as expected
Error in lrtest(fit1, fit2) : models are not nested
 > fit3 <- lrm(y ~ blood.pressure + sex * age + rcs(cholesterol, 4), 
data = exdata)
 > fit4 <- lrm(y ~ blood.pressure + age + sex * rcs(cholesterol, 4), 
data = exdata)
 > lrtest(fit3,fit4) # gives result for apparently non-nested models

Model 1: y ~ blood.pressure + sex * age + rcs(cholesterol, 4)
Model 2: y ~ blood.pressure + age + sex * rcs(cholesterol, 4)

   L.R. Chisq         d.f.            P
2.043630e+01 2.000000e+00 3.650168e-05

For reference, here is my sessionInfo() although my TA got the same 
results and I do not know what his sessionInfo() was.

 > sessionInfo()
R version 3.4.3 Patched (2017-12-12 r73903)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Slackware 14.2

Matrix products: default
BLAS: /usr/local/lib64/R/lib/libRblas.so
LAPACK: /usr/local/lib64/R/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rms_5.1-2       SparseM_1.77    Hmisc_4.1-1     ggplot2_2.2.1
[5] Formula_1.2-2   survival_2.41-3 lattice_0.20-35 knitr_1.18

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.14        pillar_1.0.1        compiler_3.4.3
  [4] RColorBrewer_1.1-2  plyr_1.8.4          base64enc_0.1-3
  [7] tools_3.4.3         rpart_4.1-11        digest_0.6.13
[10] polspline_1.1.12    nlme_3.1-131        tibble_1.4.1
[13] gtable_0.2.0        htmlTable_1.11.1    checkmate_1.8.5
[16] rlang_0.1.6         Matrix_1.2-12       rstudioapi_0.7
[19] mvtnorm_1.0-6       gridExtra_2.3       stringr_1.2.0
[22] cluster_2.0.6       MatrixModels_0.4-1  htmlwidgets_0.9
[25] grid_3.4.3          nnet_7.3-12         data.table_1.10.4-3
[28] foreign_0.8-69      multcomp_1.4-8      TH.data_1.0-8
[31] latticeExtra_0.6-28 magrittr_1.5        codetools_0.2-15
[34] MASS_7.3-48         scales_0.5.0        backports_1.1.2
[37] htmltools_0.3.6     splines_3.4.3       colorspace_1.3-2
[40] quantreg_5.34       sandwich_2.4-0      stringi_1.1.6
[43] acepack_1.4.1       lazyeval_0.2.1      munsell_0.4.3
[46] zoo_1.8-1


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From ayhanyuksel78 at gmail.com  Wed Feb 14 10:22:43 2018
From: ayhanyuksel78 at gmail.com (Ayhan yuksel)
Date: Wed, 14 Feb 2018 12:22:43 +0300
Subject: [R] How to turn off warnings about class name conflicts
In-Reply-To: <db3369ef-c38f-ccba-a78b-6b480a5aabab@gmail.com>
References: <CALj2E8WXXHjA3xfZ541cNr+QcpYL-2S27_sTr=yvSbBfggrC5w@mail.gmail.com>
 <db3369ef-c38f-ccba-a78b-6b480a5aabab@gmail.com>
Message-ID: <CALj2E8VSA+pBsmTP5OdftpjDUsaU+dLLYd6U+X6zCwz-yRM+rg@mail.gmail.com>

Thanks Daniel for your reply

However I get these warnings even I start with a fresh R session and remove
all objects (including hidden ones) before executing the mentioned codes

I also tried reinstalling these libraries including zoo and xts libraries,
but the problem continues

I guess this is a generic problem when we load two libraries with same
defined class names

Any idea ?

On 14 February 2018 at 12:16, Daniel Nordlund <djnordlund at gmail.com> wrote:

> On 2/13/2018 11:47 PM, Ayhan yuksel wrote:
>
>> Hi,
>>
>> I am using two packages (quantmod and FRAPO)
>>
>> Quantmod and FRAPO both have a class names "zoo"
>>
>> R is displaying the following warning when I manipulate an object of class
>> zoo:
>>
>> Found more than one class "zoo" in cache; using the first, from namespace
>> 'quantmod'
>> Also defined by ?FRAPO?
>>
>> The warning is displayed every time I manipulate a zoo object and becomes
>> pretty annoying.
>>
>> I searched for a solution but couldn't found.
>>
>> A related but unanswered question is here:
>> http://r.789695.n4.nabble.com/setOldClass-quot-xts-quot-td4714332.html
>>
>> How can I turn off the warning?
>>
>> Reproducible example:
>>
>> library(quantmod)
>> library(FRAPO)
>> z<-zoo(runif(100),1:100)
>>
>>
>> Session Info (I am using Microsoft R):
>>
>> R version 3.4.3 (2017-11-30)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252
>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>   [1] FRAPO_0.4-1           timeSeries_3022.101.2 timeDate_3012.100
>>   Rglpk_0.6-2
>>   [5] slam_0.1-40           cccp_0.2-4            quantmod_0.4-12
>>   TTR_0.23-2
>>   [9] xts_0.10-1            zoo_1.8-0             RevoUtils_10.0.7
>> RevoUtilsMath_10.0.1
>>
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.10     lattice_0.20-35  codetools_0.2-15 grid_3.4.3
>>   curl_3.1
>> [6] tools_3.4.3      compiler_3.4.3
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> I tried your example (in a clean session) under R-3.4.3 from CRAN and
> Microsoft R Open 3.4.3.0 and did not get the message you are getting.  I
> suspect you have something in your workspace that is causing the problem.
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>

	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Wed Feb 14 16:43:51 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Wed, 14 Feb 2018 16:43:51 +0100
Subject: [R] long vectors not supported yet
Message-ID: <87mv0b7f0o.fsf@hornfels.zedat.fu-berlin.de>

Hi,

I am running R 3.3.3 and getting the following error:

  Error in add_edges(res, edges = t(as.matrix(el[, 1:2])), attr = weight) : 
    long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138

when passing a 13 GB TransitionLayer object to shortestPath from the
package 'gdistance'.

The error, albeit in a different context, is discussed here:

  https://github.com/tidyverse/readr/issues/309
  https://github.com/tidyverse/readr/pull/433

However it is not clear to me quite what the fix was and what kind of
limit may still exist in subsequent R versions.

Is this a general problem/issue with R, or is this something more
package-specific which should be addressed on R-sig-Geo?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From jdnewmil at dcn.davis.ca.us  Wed Feb 14 18:34:29 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Feb 2018 09:34:29 -0800
Subject: [R] long vectors not supported yet
In-Reply-To: <87mv0b7f0o.fsf@hornfels.zedat.fu-berlin.de>
References: <87mv0b7f0o.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <9732AE21-32CF-4F96-BBC5-3F24DDAD79CB@dcn.davis.ca.us>

This looks to me like a package development issue... which may be under discussion in R-sig-geo (search the archives), but more likely to be appropriate to discuss with the maintainer by email or through their development repository (R-forge, though it looks unused).
-- 
Sent from my phone. Please excuse my brevity.

On February 14, 2018 7:43:51 AM PST, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
>Hi,
>
>I am running R 3.3.3 and getting the following error:
>
>Error in add_edges(res, edges = t(as.matrix(el[, 1:2])), attr = weight)
>: 
>   long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138
>
>when passing a 13 GB TransitionLayer object to shortestPath from the
>package 'gdistance'.
>
>The error, albeit in a different context, is discussed here:
>
>  https://github.com/tidyverse/readr/issues/309
>  https://github.com/tidyverse/readr/pull/433
>
>However it is not clear to me quite what the fix was and what kind of
>limit may still exist in subsequent R versions.
>
>Is this a general problem/issue with R, or is this something more
>package-specific which should be addressed on R-sig-Geo?
>
>Cheers,
>
>Loris


From acefix at rocketmail.com  Wed Feb 14 17:24:03 2018
From: acefix at rocketmail.com (Fix Ace)
Date: Wed, 14 Feb 2018 16:24:03 +0000 (UTC)
Subject: [R] help with the plot overlay
In-Reply-To: <CA+8X3fW-SLfti_+4K3UffE3ejkXmoeo7QM_eAc3yEtodRy7CPg@mail.gmail.com>
References: <2116633968.3300050.1517781417332.ref@mail.yahoo.com>
 <2116633968.3300050.1517781417332@mail.yahoo.com>
 <CA+8X3fW-SLfti_+4K3UffE3ejkXmoeo7QM_eAc3yEtodRy7CPg@mail.gmail.com>
Message-ID: <126180921.887274.1518625443133@mail.yahoo.com>

Hi, JIm,
Thank you so much! Such a convenient tool!
A. 

    On Sunday, February 4, 2018 9:59 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
 

 Hi Ace,
You can do it with plotrix:

library(plotrix)
barpos<-barp(c(1,5,38),width=0.5,col=c("white","lightgray","darkgray"),ylim=c(0,70))
ehplot(c(1,0.8,0.9,0.8,1.1,1,4,3,5,14,3,2,32,27,33,30,50,61),
 c(1,1,1,1,1,1,2,2,2,2,2,2,3,3,3,3,3,3),median=FALSE,add=TRUE,cex=2,
 pch=21,bg="white")
dispersion(barpos$x,barpos$y,c(0.1,1,5),lwd=2,arrow.cap=0.03)
lines(c(barpos$x[2],barpos$x[2],barpos$x[3],barpos$x[3]),c(18,63,63,62))
lines(c(barpos$x[1],barpos$x[1],barpos$x[3],barpos$x[3]),c(4,66,66,65))
text(2,68,"**",cex=2)
text(2.5,64.5,"**",cex=2)

Jim


On Mon, Feb 5, 2018 at 8:56 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> Dear R Community,
> I recently read an article and found a plot as attached. It has scatterplot, barplot, and error bar. Could anyone help me to figure out what package I can use in R to generate such plot?
> Thank you very much for any inputs!
> Kind regards,
> Ace
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Feb 14 20:14:06 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 14 Feb 2018 19:14:06 +0000
Subject: [R] Parallel assignments and goto
In-Reply-To: <9389_1518364134_w1BFmrh6018357_60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
References: <9389_1518364134_w1BFmrh6018357_60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836772B08@FHSDB2D11-2.csu.mcmaster.ca>

Dear Thomas,

This looks like a really interesting project, and I don't think that anyone responded to your message, though I may be mistaken.

I took at a look at implementing parallel assignment, and came up with:

passign <- function(..., envir=parent.frame()){
    exprs <- list(...)
    vars <- names(exprs)
    exprs <- lapply(exprs, FUN=eval, envir=envir)
    for (i in seq_along(exprs)){
        assign(vars[i], exprs[[i]], envir=envir)
    }
}

For example,

> fun <- function(){
+     a <- 10
+     passign(a=1, b=a + 2, c=3)
+     cat("a =", a, " b =", b, " c =", c, "\n")
+ }
> fun()
a = 1  b = 12  c = 3

This proves to be faster than what you tried, but still much slower than using a local variable (or variables) -- see below. I wouldn't be surprised if someone can come up with a faster implementation, but I suspect that the overhead of function calls will be hard to overcome. BTW, a version of my passign() that uses mapply() in place of a for loop (not shown) is even slower.

> factorial_tr_3 <- function (n, acc = 1) {
+     repeat {
+         if (n <= 1) 
+             return(acc)
+         else {
+             passign(n = n - 1, acc = acc * n)
+             next
+         }
+     }
+ }

> microbenchmark::microbenchmark(factorial(100),
+ factorial_tr_1(100),
+ factorial_tr_2(100),
+ factorial_tr_3(100))
Unit: microseconds
                expr       min        lq       mean     median        uq       max neval cld
      factorial(100)    55.009    69.290   100.4507   104.5515   131.174   228.496   100 a  
 factorial_tr_1(100)    10.227    11.637    14.4967    13.7530    15.515    89.565   100 a  
 factorial_tr_2(100) 21523.751 23038.417 24477.1734 24058.3635 25041.988 45814.136   100   c
 factorial_tr_3(100)   806.789   861.797   914.3651   879.9565   925.444  2139.329   100  b

Best,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
> Mailund
> Sent: Sunday, February 11, 2018 10:49 AM
> To: r-help at r-project.org
> Subject: [R] Parallel assignments and goto
> 
> Hi guys,
> 
> I am working on some code for automatically translating recursive functions into
> looping functions to implemented tail-recursion optimisations. See
> https://github.com/mailund/tailr
> 
> As a toy-example, consider the factorial function
> 
> factorial <- function(n, acc = 1) {
>     if (n <= 1) acc
>     else factorial(n - 1, acc * n)
> }
> 
> I can automatically translate this into the loop-version
> 
> factorial_tr_1 <- function (n, acc = 1) {
>     repeat {
>         if (n <= 1)
>             return(acc)
>         else {
>             .tailr_n <- n - 1
>             .tailr_acc <- acc * acc
>             n <- .tailr_n
>             acc <- .tailr_acc
>             next
>         }
>     }
> }
> 
> which will run faster and not have problems with recursion depths. However,
> I?m not entirely happy with this version for two reasons: I am not happy with
> introducing the temporary variables and this rewrite will not work if I try to
> over-scope an evaluation context.
> 
> I have two related questions, one related to parallel assignments ? i.e.
> expressions to variables so the expression uses the old variable values and not
> the new values until the assignments are all done ? and one related to
> restarting a loop from nested loops or from nested expressions in `with`
> expressions or similar.
> 
> I can implement parallel assignment using something like rlang::env_bind:
> 
> factorial_tr_2 <- function (n, acc = 1) {
>     .tailr_env <- rlang::get_env()
>     repeat {
>         if (n <= 1)
>             return(acc)
>         else {
>             rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
>             next
>         }
>     }
> }
> 
> This reduces the number of additional variables I need to one, but is a couple of
> orders of magnitude slower than the first version.
> 
> > microbenchmark::microbenchmark(factorial(100),
> +                                factorial_tr_1(100),
> +                                factorial_tr_2(100))
> Unit: microseconds
>                      expr      min       lq       mean    median       uq      max neval
>       factorial(100)   53.978   60.543   77.76203   71.0635   85.947  180.251   100
>  factorial_tr_1(100)    9.022    9.903   11.52563   11.0430   11.984   28.464
> 100
>  factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463
> 8177.635   100
> 
> 
> Is there another way to do parallel assignments that doesn?t cost this much in
> running time?
> 
> My other problem is the use of `next`. I would like to combine tail-recursion
> optimisation with pattern matching as in https://github.com/mailund/pmatch
> where I can, for example, define a linked list like this:
> 
> devtools::install_github("mailund/pmatch?)
> library(pmatch)
> llist := NIL | CONS(car, cdr : llist)
> 
> and define a function for computing the length of a list like this:
> 
> list_length <- function(lst, acc = 0) {
>   force(acc)
>   cases(lst,
>         NIL -> acc,
>         CONS(car, cdr) -> list_length(cdr, acc + 1)) }
> 
> The `cases` function creates an environment that binds variables in a pattern-
> description that over-scopes the expression to the right of `->`, so the recursive
> call in this example have access to the variables `cdr` and `car`.
> 
> I can transform a `cases` call to one that creates the environment containing the
> bound variables and then evaluate this using `eval` or `with`, but in either case,
> a call to `next` will not work in such a context. The expression will be evaluated
> inside `bind` or `with`, and not in the `list_lenght` function.
> 
> A version that *will* work, is something like this
> 
> factorial_tr_3 <- function (n, acc = 1) {
>     .tailr_env <- rlang::get_env()
>     .tailr_frame <- rlang::current_frame()
>     repeat {
>         if (n <= 1)
>             rlang::return_from(.tailr_frame, acc)
>         else {
>             rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
>             rlang::return_to(.tailr_frame)
>         }
>     }
> }
> 
> Here, again, for the factorial function since this is easier to follow than the list-
> length function.
> 
> This solution will also work if you return values from inside loops, where `next`
> wouldn?t work either.
> 
> Using `rlang::return_from` and `rlang::return_to` implements the right
> semantics, but costs me another order of magnitude in running time.
> 
> microbenchmark::microbenchmark(factorial(100),
>                                factorial_tr_1(100),
>                                factorial_tr_2(100),
>                                factorial_tr_3(100))
> Unit: microseconds
>                 expr       min         lq        mean     median        uq        max neval
>       factorial(100)    52.479    60.2640    93.43069    67.5130    83.925   2062.481
> 100
>  factorial_tr_1(100)     8.875     9.6525    49.19595    10.6945    11.217
> 3818.823   100
>  factorial_tr_2(100)  5296.350  5525.0745  5973.77664  5737.8730  6260.128
> 8471.301   100
>  factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725
> 89859.169 171039.228   100
> 
> I can live with the ?introducing extra variables? solution to parallel assignment,
> and I could hack my way out of using `with` or `bind` in rewriting `cases`, but
> restarting a `repeat` loop would really make for a nicer solution. I know that
> `goto` is considered harmful, but really, in this case, it is what I want.
> 
> A `callCC` version also solves the problem
> 
> factorial_tr_4 <- function(n, acc = 1) {
>     function_body <- function(continuation) {
>         if (n <= 1) {
>             continuation(acc)
>         } else {
>             continuation(list("continue", n = n - 1, acc = acc * n))
>         }
>     }
>     repeat {
>         result <- callCC(function_body)
>         if (is.list(result) && result[[1]] == "continue") {
>             n <- result$n
>             acc <- result$acc
>             next
>         } else {
>             return(result)
>         }
>     }
> }
> 
> But this requires that I know how to distinguish between a valid return value
> and a tag for ?next? and is still a lot slower than the `next` solution
> 
> microbenchmark::microbenchmark(factorial(100),
>                                factorial_tr_1(100),
>                                factorial_tr_2(100),
>                                factorial_tr_3(100),
>                                factorial_tr_4(100))
> Unit: microseconds
>                 expr       min         lq        mean     median        uq        max neval
>       factorial(100)    54.109    61.8095    81.33167    81.8785    89.748    243.554
> 100
>  factorial_tr_1(100)     9.025     9.9035    11.38607    11.1990    12.008     22.375
> 100
>  factorial_tr_2(100)  5272.524  5798.3965  6302.40467  6077.7180  6492.959
> 9967.237   100
>  factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665
> 75405.054 203785.673   100
>  factorial_tr_4(100)   270.978   302.7890   337.48763   313.9930   334.096
> 1425.702   100
> 
> I don?t necessarily need the tail-recursion optimisation to be faster than the
> recursive version; just getting out of the problem of too deep recursions is a
> benefit, but I would rather not pay with an order of magnitude for it. I could, of
> course, try to handle cases that works with `next` in one way, and other cases
> using `callCC`, but I feel it should be possible with a version that handles all cases
> the same way.
> 
> Is there any way to achieve this?
> 
> Cheers
> 	Thomas
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From Alexander.Herr at csiro.au  Thu Feb 15 01:16:19 2018
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Thu, 15 Feb 2018 00:16:19 +0000
Subject: [R] using cat to log to file with sapply
Message-ID: <d3103d6b96a244d69b004d9f7b9be204@exch1-mel.nexus.csiro.au>

Hi List,
I am trying to write unsuccessfully to a logfile with cat. Here my example code:

letters[1:5]->x
logf<-"test.txt"
cat('%%%%%%%%%%%%%%%%%%%%%%%%%%\n',file=logf)
catf<-function(x,...,logfile='log.txt', append=TRUE){ cat(x,'\n', file=logfile, append=append)}
testit<-function(x,...){
  paste0('this is x: ',x)->y
  return(y)
  catf("++++++++++++++++++test=============",...)
  }  
sapply(x, function(x) testit(x, logfile=logf))

Any suggestions appreciated.

Thanks
Herry

From wdunlap at tibco.com  Thu Feb 15 01:45:58 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 14 Feb 2018 16:45:58 -0800
Subject: [R] using cat to log to file with sapply
In-Reply-To: <d3103d6b96a244d69b004d9f7b9be204@exch1-mel.nexus.csiro.au>
References: <d3103d6b96a244d69b004d9f7b9be204@exch1-mel.nexus.csiro.au>
Message-ID: <CAF8bMcZevSQwxPV9E_nqb+WaP9dXnsC3iMue2uEDJAH_qfvJ2Q@mail.gmail.com>

testit<-function(x,...){
  paste0('this is x: ',x)->y
  return(y)
  catf("++++++++++++++++++test=============",...)
  }

You return from the function before calling catf().  Remove the 'return(y)'
and make 'y' the last expression in the function.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 14, 2018 at 4:16 PM, <Alexander.Herr at csiro.au> wrote:

> Hi List,
> I am trying to write unsuccessfully to a logfile with cat. Here my example
> code:
>
> letters[1:5]->x
> logf<-"test.txt"
> cat('%%%%%%%%%%%%%%%%%%%%%%%%%%\n',file=logf)
> catf<-function(x,...,logfile='log.txt', append=TRUE){ cat(x,'\n',
> file=logfile, append=append)}
> testit<-function(x,...){
>   paste0('this is x: ',x)->y
>   return(y)
>   catf("++++++++++++++++++test=============",...)
>   }
> sapply(x, function(x) testit(x, logfile=logf))
>
> Any suggestions appreciated.
>
> Thanks
> Herry
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb 15 01:56:59 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Feb 2018 16:56:59 -0800
Subject: [R] using cat to log to file with sapply
In-Reply-To: <d3103d6b96a244d69b004d9f7b9be204@exch1-mel.nexus.csiro.au>
References: <d3103d6b96a244d69b004d9f7b9be204@exch1-mel.nexus.csiro.au>
Message-ID: <23C5E9F7-6152-418D-A9C0-9903426ACF31@dcn.davis.ca.us>

Your call to catf in testit is after the return,  so it is never called. 

FWIW my antibugging strategy (and readability strategy) is to never use the return function... I structure my logic to end up at the end with my desired function result in a variable and I simply put that variable on the last line of the function.
-- 
Sent from my phone. Please excuse my brevity.

On February 14, 2018 4:16:19 PM PST, Alexander.Herr at csiro.au wrote:
>Hi List,
>I am trying to write unsuccessfully to a logfile with cat. Here my
>example code:
>
>letters[1:5]->x
>logf<-"test.txt"
>cat('%%%%%%%%%%%%%%%%%%%%%%%%%%\n',file=logf)
>catf<-function(x,...,logfile='log.txt', append=TRUE){ cat(x,'\n',
>file=logfile, append=append)}
>testit<-function(x,...){
>  paste0('this is x: ',x)->y
>  return(y)
>  catf("++++++++++++++++++test=============",...)
>  }  
>sapply(x, function(x) testit(x, logfile=logf))
>
>Any suggestions appreciated.
>
>Thanks
>Herry
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Feb 15 01:57:39 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 14 Feb 2018 16:57:39 -0800
Subject: [R] using cat to log to file with sapply
In-Reply-To: <d3103d6b96a244d69b004d9f7b9be204@exch1-mel.nexus.csiro.au>
References: <d3103d6b96a244d69b004d9f7b9be204@exch1-mel.nexus.csiro.au>
Message-ID: <CAGxFJbQh4vuddz9ppunh0YyiZ49akxX_jYwQ2LFE8Z2f0e9XPQ@mail.gmail.com>

Not sure what you wanted to do.Note that you have  "test'txt" and "log.txt"
in your code. Using only "test.txt", the following worked fine for me:

letters[1:5]->x
logf<-"test.txt"
cat('%%%%%%%%%%%%%%%%%%%%%%%%%%\n',file=logf)
catf<-function(x,...,logfile='test.txt', append=TRUE){ cat(x,'\n',
file=logfile, append=append)}
testit<-function(x,...){
   paste0('this is x: ',x)->y
   catf(y)
}
sapply(x, function(x) testit(x, logfile=logf))

If you do not see the file in your working directory (found by getwd() ),
maybe you have write permissions issues.

Note also that you may need none of this: see ?sink

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Feb 14, 2018 at 4:16 PM, <Alexander.Herr at csiro.au> wrote:

> Hi List,
> I am trying to write unsuccessfully to a logfile with cat. Here my example
> code:
>
> letters[1:5]->x
> logf<-"test.txt"
> cat('%%%%%%%%%%%%%%%%%%%%%%%%%%\n',file=logf)
> catf<-function(x,...,logfile='log.txt', append=TRUE){ cat(x,'\n',
> file=logfile, append=append)}
> testit<-function(x,...){
>   paste0('this is x: ',x)->y
>   return(y)
>   catf("++++++++++++++++++test=============",...)
>   }
> sapply(x, function(x) testit(x, logfile=logf))
>
> Any suggestions appreciated.
>
> Thanks
> Herry
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Feb 15 02:26:36 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Feb 2018 17:26:36 -0800
Subject: [R] Fleming-Harrington weighted log rank test
In-Reply-To: <1927370176.471494.1518566526278@mail.yahoo.com>
References: <1927370176.471494.1518566526278.ref@mail.yahoo.com>
 <1927370176.471494.1518566526278@mail.yahoo.com>
Message-ID: <075D5963-B20B-4B05-9EE5-25F7A87D24C0@comcast.net>


> On Feb 13, 2018, at 4:02 PM, array chip via R-help <r-help at r-project.org> wrote:
> 
> Hi all, 
> 
> The survdiff() from survival package has an argument "rho" that implements Fleming-Harrington weighted long rank test. 
> 
> But according to several sources including "survminer" package (https://cran.r-project.org/web/packages/survminer/vignettes/Specifiying_weights_in_log-rank_comparisons.html), Fleming-Harrington weighted log-rank test should have 2 parameters "p" and "q" to control the weighting for earlier vs later times in the follow-up.
> 
> For example, setting rho=1 in survdiff() uses the Peto-Peto modification of Gehan-Wilcox weights, which I can confirm by setting p=1 & 1=0 in comp() from survminer package. similarly rho=0 is equivalent to p=0 & q=0
> 
> I am interested in putting more weights on survival difference in later follow-up time. According to comp() from survminer package, that would set p=0 & q=1 for Fleming-Harrington weights. 
> 
> My question is how I can do the same by setting certain values for "rho" in the regular survival() function?

I think that survdiff uses a different version than what you have found. The G-rho family weights are:

w_j = [S?(tj)]^?

So rather than two parameters on S(t) and (1-S(t)) as in the p,q version, you only have one parameter applied to S(t). This class handout says that the G-rho,gamma weighting scheme is not available in survdiff.

-- 
David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwinsemius at comcast.net  Thu Feb 15 03:05:44 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Feb 2018 18:05:44 -0800
Subject: [R] Fleming-Harrington weighted log rank test
In-Reply-To: <075D5963-B20B-4B05-9EE5-25F7A87D24C0@comcast.net>
References: <1927370176.471494.1518566526278.ref@mail.yahoo.com>
 <1927370176.471494.1518566526278@mail.yahoo.com>
 <075D5963-B20B-4B05-9EE5-25F7A87D24C0@comcast.net>
Message-ID: <74C39504-08EF-4598-90BC-32415BA1307A@comcast.net>


> On Feb 14, 2018, at 5:26 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Feb 13, 2018, at 4:02 PM, array chip via R-help <r-help at r-project.org> wrote:
>> 
>> Hi all, 
>> 
>> The survdiff() from survival package has an argument "rho" that implements Fleming-Harrington weighted long rank test. 
>> 
>> But according to several sources including "survminer" package (https://cran.r-project.org/web/packages/survminer/vignettes/Specifiying_weights_in_log-rank_comparisons.html), Fleming-Harrington weighted log-rank test should have 2 parameters "p" and "q" to control the weighting for earlier vs later times in the follow-up.
>> 
>> For example, setting rho=1 in survdiff() uses the Peto-Peto modification of Gehan-Wilcox weights, which I can confirm by setting p=1 & 1=0 in comp() from survminer package. similarly rho=0 is equivalent to p=0 & q=0
>> 
>> I am interested in putting more weights on survival difference in later follow-up time. According to comp() from survminer package, that would set p=0 & q=1 for Fleming-Harrington weights. 
>> 
>> My question is how I can do the same by setting certain values for "rho" in the regular survival() function?
> 
> I think that survdiff uses a different version than what you have found. The G-rho family weights are:
> 
> w_j = [S?(tj)]^?
> 
> So rather than two parameters on S(t) and (1-S(t)) as in the p,q version, you only have one parameter applied to S(t). This class handout says that the G-rho,gamma weighting scheme is not available in survdiff.
> 

Forgot to paste the link:

http://www.ics.uci.edu/~dgillen/STAT255/Handouts/lecture4.pdf

> -- 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From shajujacob at yahoo.com  Thu Feb 15 10:28:42 2018
From: shajujacob at yahoo.com (shaju jacob)
Date: Thu, 15 Feb 2018 09:28:42 +0000 (UTC)
Subject: [R] Codes to conduct network meta-analysis, gemtc package
References: <2007548353.1418728.1518686922983.ref@mail.yahoo.com>
Message-ID: <2007548353.1418728.1518686922983@mail.yahoo.com>

Hi,I want codes that could help me do NMA from the data. I would appreciate if you could give a dummy table with which I could practice the codes that would help read the data and calculateOdds ratio (OR)
Mean difference (MD)
forest plot
Density plot of posterior samples
Estimates of ranks probabilities
Rank probabilities plot (rankogram)?
Network plots?

The manual by?Gert van Valkenhoef is difficult for me to understand and comprehend.
	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Thu Feb 15 13:33:13 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 15 Feb 2018 13:33:13 +0100
Subject: [R] long vectors not supported yet
In-Reply-To: <9732AE21-32CF-4F96-BBC5-3F24DDAD79CB@dcn.davis.ca.us> (Jeff
 Newmiller's message of "Wed, 14 Feb 2018 09:34:29 -0800")
References: <87mv0b7f0o.fsf@hornfels.zedat.fu-berlin.de>
 <9732AE21-32CF-4F96-BBC5-3F24DDAD79CB@dcn.davis.ca.us>
Message-ID: <87y3ju301i.fsf@hornfels.zedat.fu-berlin.de>

Hi Jeff,

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

>> Hi,
>> 
>> I am running R 3.3.3 and getting the following error:
>> 
>> Error in add_edges(res, edges = t(as.matrix(el[, 1:2])), attr = weight)
>> : 
>>    long vectors not supported yet: ../../src/include/Rinlinedfuns.h:138
>> 
>> when passing a 13 GB TransitionLayer object to shortestPath from the
>> package 'gdistance'.
>> 
>> The error, albeit in a different context, is discussed here:
>> 
>>   https://github.com/tidyverse/readr/issues/309
>>   https://github.com/tidyverse/readr/pull/433
>> 
>> However it is not clear to me quite what the fix was and what kind of
>> limit may still exist in subsequent R versions.
>> 
>> Is this a general problem/issue with R, or is this something more
>> package-specific which should be addressed on R-sig-Geo?

> This looks to me like a package development issue... which may be
> under discussion in R-sig-geo (search the archives), but more likely
> to be appropriate to discuss with the maintainer by email or through
> their development repository (R-forge, though it looks unused).

Thanks for the information.  I reported the issue to the developers of
'igraph', which is where 'add_edges' comes from, here

  https://github.com/igraph/rigraph/issues/255

The response there to the question of whether it is an R core or an
igraph issue was

  R core for sure, but probably both.

Is this indeed the case for R core?  To my naive eye, the error message
suggests more of a known limitation, rather than a bona fide bug.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From phhs80 at gmail.com  Thu Feb 15 14:12:19 2018
From: phhs80 at gmail.com (Paul Smith)
Date: Thu, 15 Feb 2018 13:12:19 +0000
Subject: [R] Best Optimization Routines
In-Reply-To: <a7f88e623cb04744bfe3bceb030eff16@sk.com>
References: <a7f88e623cb04744bfe3bceb030eff16@sk.com>
Message-ID: <CALS=5mrFN2CwH5CBdEd2gYKCokwT63JVDDoA-wi6sSdPc3L9_Q@mail.gmail.com>

On Tue, Feb 13, 2018 at 7:55 PM, JamesRyan(Ryan James)/E&P North
America Business Division <rjames at sk.com> wrote:
> I have a set of data, the production of oil from a well.  And an equation to predict that forecast.
>
> The equation requires 5 input variables which are real numbers with upper and lower bounds, 1 input variable which must be an integer and 1 input variable which can be 1 of 2 string variables.
>
> What is the best optimization routine (I am using nlminb) to use in R to determine the best set of inputs and how to I handle the integer and string inputs when optimizing?
>
> I have attached a plot of what I am trying to accomplish as well as my sample code.

If I understand correctly your problem, your equation is linear, and
you have continuous and integer variables (the string input can be
coded as a binary integer variable). Thus, you can use a package to
deal with mixed integer programming:

http://blog.revolutionanalytics.com/2016/12/mixed-integer-programming-in-r-with-the-ompr-package.html

Hope this helps you,

Paul


From mak.hholly at gmail.com  Thu Feb 15 15:58:02 2018
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 15 Feb 2018 17:58:02 +0300
Subject: [R] Putting 733 discrete categories on Y-axis in qqplot2 as they are
Message-ID: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>

Hi all;

I have 733 discrete categories that will go on y-axis in ggplot2. I used
the following command to put the name of x-axis.

scale_x_discrete (limits = c("SI", "HOMAIR",
"AIR","HOMAB","SG","DI","FI","FG"))

Since there are only 8 categories on x it was easy to do. Is there any way
to do the same for 733 discrete categories for y-axis. Essentially I did
not want to order categories. I would like to put the name of categories as
they are.

Best regards,

Greg

	[[alternative HTML version deleted]]


From p.graf at consolinno.de  Thu Feb 15 16:21:38 2018
From: p.graf at consolinno.de (Philipp Graf)
Date: Thu, 15 Feb 2018 16:21:38 +0100
Subject: [R] Help with factorized argument in solve.QP
Message-ID: <000001d3a670$acc90700$065b1500$@consolinno.de>

Hello David,

 

same problem here with solve.QP. 

dykstra is causing problems as well and giving for the value NA if
factorized = TRUE:

 

library(quadprog)

library(Dykstra)

R<-cbind(c(1,1),c(0,1));

d<-c(t(R)%*%R%*%c(2,1))

solve.QP(solve(R),d,-as.matrix(c(1,1)),-2,1,factorized = TRUE)

S<-t(R)%*%R;

solve.QP(S,d,-as.matrix(c(1,1)),-2,1)

dykstra(solve(R),d,-as.matrix(c(1,1)),-2,1,factorized = TRUE)

dykstra(S,d,-as.matrix(c(1,1)),-2,1)

 

Nevertheless, factorized = TRUE yields false results, see 

solve.QP(t(R)%*%R,rep(0,2),diag(2),rep(2,2))

solve.QP(solve(R),rep(0,2),diag(2),rep(2,2),factorized = TRUE)

where you see that the first is correct and agrees with 

dykstra(t(R)%*%R,rep(0,2),diag(2),rep(2,2))

 

Best regards

 

Philipp


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb 15 16:46:03 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Feb 2018 07:46:03 -0800
Subject: [R] long vectors not supported yet
In-Reply-To: <87y3ju301i.fsf@hornfels.zedat.fu-berlin.de>
References: <87mv0b7f0o.fsf@hornfels.zedat.fu-berlin.de>
 <9732AE21-32CF-4F96-BBC5-3F24DDAD79CB@dcn.davis.ca.us>
 <87y3ju301i.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <DE20E99F-C540-4528-B2BB-25681DFC4F9F@dcn.davis.ca.us>

It does appear to be an error message from R [1] regarding the difference between the maximum length of a data vector (~2^59) and the maximum length of a matrix/array/data frame dimension (~2^31).

As to whether this is under consideration for change, I don't know but I would not want such information to affect how I work around the limitation today because it may come with bugs initially anyway. 

[1] https://stackoverflow.com/questions/24335692/large-matrices-in-r-long-vectors-not-supported-yet
-- 
Sent from my phone. Please excuse my brevity.

On February 15, 2018 4:33:13 AM PST, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
>Hi Jeff,
>
>Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:
>
>>> Hi,
>>> 
>>> I am running R 3.3.3 and getting the following error:
>>> 
>>> Error in add_edges(res, edges = t(as.matrix(el[, 1:2])), attr =
>weight)
>>> : 
>>>    long vectors not supported yet:
>../../src/include/Rinlinedfuns.h:138
>>> 
>>> when passing a 13 GB TransitionLayer object to shortestPath from the
>>> package 'gdistance'.
>>> 
>>> The error, albeit in a different context, is discussed here:
>>> 
>>>   https://github.com/tidyverse/readr/issues/309
>>>   https://github.com/tidyverse/readr/pull/433
>>> 
>>> However it is not clear to me quite what the fix was and what kind
>of
>>> limit may still exist in subsequent R versions.
>>> 
>>> Is this a general problem/issue with R, or is this something more
>>> package-specific which should be addressed on R-sig-Geo?
>
>> This looks to me like a package development issue... which may be
>> under discussion in R-sig-geo (search the archives), but more likely
>> to be appropriate to discuss with the maintainer by email or through
>> their development repository (R-forge, though it looks unused).
>
>Thanks for the information.  I reported the issue to the developers of
>'igraph', which is where 'add_edges' comes from, here
>
>  https://github.com/igraph/rigraph/issues/255
>
>The response there to the question of whether it is an R core or an
>igraph issue was
>
>  R core for sure, but probably both.
>
>Is this indeed the case for R core?  To my naive eye, the error message
>suggests more of a known limitation, rather than a bona fide bug.
>
>Cheers,
>
>Loris


From bgunter.4567 at gmail.com  Thu Feb 15 16:48:40 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Feb 2018 07:48:40 -0800
Subject: [R] Codes to conduct network meta-analysis, gemtc package
In-Reply-To: <2007548353.1418728.1518686922983@mail.yahoo.com>
References: <2007548353.1418728.1518686922983.ref@mail.yahoo.com>
 <2007548353.1418728.1518686922983@mail.yahoo.com>
Message-ID: <CAGxFJbR8PRY=6M2igQ2eiHWj2t28rqzf2J1SgRTvo3v9pxOS_g@mail.gmail.com>

This is not a free consulting service. You are expected to put in the work
yourself and **may** receive help here if you have specific questions that
you need help with when you do so. See the posting guide linked below for
details.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Feb 15, 2018 at 1:28 AM, shaju jacob via R-help <
r-help at r-project.org> wrote:

> Hi,I want codes that could help me do NMA from the data. I would
> appreciate if you could give a dummy table with which I could practice the
> codes that would help read the data and calculateOdds ratio (OR)
> Mean difference (MD)
> forest plot
> Density plot of posterior samples
> Estimates of ranks probabilities
> Rank probabilities plot (rankogram)
> Network plots
>
> The manual by Gert van Valkenhoef is difficult for me to understand and
> comprehend.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aclopezrosero at hotmail.com  Thu Feb 15 18:23:58 2018
From: aclopezrosero at hotmail.com (Andrea Lopez)
Date: Thu, 15 Feb 2018 17:23:58 +0000
Subject: [R] RV: Problem_graphic
In-Reply-To: <BN6PR19MB14104ADC1FA1BF77328E80B9B7F40@BN6PR19MB1410.namprd19.prod.outlook.com>
References: <BN6PR19MB14104ADC1FA1BF77328E80B9B7F40@BN6PR19MB1410.namprd19.prod.outlook.com>
Message-ID: <BN6PR19MB1410CCF6D55D2BC95BDC220EB7F40@BN6PR19MB1410.namprd19.prod.outlook.com>

Hi everyone,


I am beginner using R but I try to learn more.

I need this graphic or similar but instead of tropical and temperate are three ontogenetic states


                    Larva            Met             Juv


CTMAX



CTMIN



                     SP                     SP               SP


This is my scrip:



Ex = subset(Expr, Outlayer=="N")
Ex2 = subset (Ex, S0 == 1)
Ex3 = subset(Ex2, Experimento == "CTMIN")
Ex4 = subset(Ex2, Experimento == "CTMAX")
Ex3$Stage <- ordered(Ex3$Stage, levels=c("LARVA", "MET", "JUV"))
Ex4$Stage <- ordered(Ex4$Stage, levels=c("LARVA", "MET", "JUV"))
par(mfrow=c(2,1))
boxplot(Temp ~ Stage, data = Ex4, col = "red",  main="CTmax", ylim=range(30:45))
boxplot(Temp ~ Stage, data = Ex3, col = "blue", main="CTmin", ylim=range(-3:1))

When I run de scrip some species disappear and it doesn't come out as I need


Please if someone can help me,

Thank you



Lic. Andrea L?pez-Rosero
Investigadora asociada
Centro de investigaci?n para la Salud en Am?rica Latina (CISeAL)
Pontificia Universidad Cat?lica del Ecuador
Quito - Ecuador
Tel: (593) 22991700, ext. 2926


Andrea L?pez-Rosero
Research associate
Center for Health Research in Latin Am?rica (CISeAL)
Pontifical Catholic University of Ecuador
Quito - Ecuador
Tel: (593) 22991700, ext. 2926



	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Feb 15 19:07:15 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 15 Feb 2018 13:07:15 -0500
Subject: [R] Problem_graphic
In-Reply-To: <BN6PR19MB1410CCF6D55D2BC95BDC220EB7F40@BN6PR19MB1410.namprd19.prod.outlook.com>
References: <BN6PR19MB14104ADC1FA1BF77328E80B9B7F40@BN6PR19MB1410.namprd19.prod.outlook.com>
 <BN6PR19MB1410CCF6D55D2BC95BDC220EB7F40@BN6PR19MB1410.namprd19.prod.outlook.com>
Message-ID: <AA585794-1E17-420D-9D54-97EC72FA1D7C@utoronto.ca>

I haven't been able to reproduce this because you posted in HTML and no data arrived. Use the dput() function if you want to post data.

But: a frequent and trivial reason for disappearing category labels is that the plot window is too small to print them all. Try increasing the plotting window, or reducing the character size of the labels.

B.




> On Feb 15, 2018, at 12:23 PM, Andrea Lopez <aclopezrosero at hotmail.com> wrote:
> 
> Hi everyone,
> 
> 
> I am beginner using R but I try to learn more.
> 
> I need this graphic or similar but instead of tropical and temperate are three ontogenetic states
> 
> 
>                    Larva            Met             Juv
> 
> 
> CTMAX
> 
> 
> 
> CTMIN
> 
> 
> 
>                     SP                     SP               SP
> 
> 
> This is my scrip:
> 
> 
> 
> Ex = subset(Expr, Outlayer=="N")
> Ex2 = subset (Ex, S0 == 1)
> Ex3 = subset(Ex2, Experimento == "CTMIN")
> Ex4 = subset(Ex2, Experimento == "CTMAX")
> Ex3$Stage <- ordered(Ex3$Stage, levels=c("LARVA", "MET", "JUV"))
> Ex4$Stage <- ordered(Ex4$Stage, levels=c("LARVA", "MET", "JUV"))
> par(mfrow=c(2,1))
> boxplot(Temp ~ Stage, data = Ex4, col = "red",  main="CTmax", ylim=range(30:45))
> boxplot(Temp ~ Stage, data = Ex3, col = "blue", main="CTmin", ylim=range(-3:1))
> 
> When I run de scrip some species disappear and it doesn't come out as I need
> 
> 
> Please if someone can help me,
> 
> Thank you
> 
> 
> 
> Lic. Andrea L?pez-Rosero
> Investigadora asociada
> Centro de investigaci?n para la Salud en Am?rica Latina (CISeAL)
> Pontificia Universidad Cat?lica del Ecuador
> Quito - Ecuador
> Tel: (593) 22991700, ext. 2926
> 
> 
> Andrea L?pez-Rosero
> Research associate
> Center for Health Research in Latin Am?rica (CISeAL)
> Pontifical Catholic University of Ecuador
> Quito - Ecuador
> Tel: (593) 22991700, ext. 2926
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From samuel.granjeaud at inserm.fr  Thu Feb 15 18:58:21 2018
From: samuel.granjeaud at inserm.fr (Samuel GRANJEAUD IR/INSERM)
Date: Thu, 15 Feb 2018 18:58:21 +0100
Subject: [R] Identify does sort the locations
Message-ID: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>

Hi,

Using identify function, I think I should get the index of the selected 
points in the order I clicked them. This is what I read in the help. But 
I feel they are ordered. Please let me know what I missed.

In the following example, I clicked on the points labelled 7, 5 and 1, 
but I get 1, 5, 7 as output.

> set.seed(0); x = rnorm(10); y = rnorm(10); plot(x,y); text(x, y, 
> seq(x)); sel = identify(x,y); sel
[1] 1 5 7

Any help appreciated,
Samuel

R version 3.4.3 (2017-11-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United 
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3


From jpolo at mail.usf.edu  Thu Feb 15 20:39:43 2018
From: jpolo at mail.usf.edu (john polo)
Date: Thu, 15 Feb 2018 11:39:43 -0800
Subject: [R] package MonteCarlo error: object 'packages' not found
Message-ID: <9741aa66-72e6-c9be-c017-f0a54f4594f1@mail.usf.edu>

R-users,

I can't tell what's causing the following error. The vignette does not 
make a reference to a "packages" option or parameter.

 > library(MonteCarlo)
Loading required package: abind
Loading required package: codetools
Loading required package: rlecuyer
Loading required package: snow
Loading required package: snowfall

 > infest_kud_fun<-function(x,A,B){
+?? equation1=exp(A-(B*x))
+?? return(list("equation1"=equation1))
+ }


 > x_grid<-c(0.5,10) #distances kudzu could grow
 > A_grid<-rnorm(1000) #probabilities
 > B_grid<- rnorm(1000) #probabilities


 > #put parameters in a list
 > param_list_kud=list("x"=x_grid, "A"=A_grid, "B"=B_grid)

 > #run MC simulation
 > 
MC_result_kud<-MonteCarlo(func=infest_kud_fun,nrep=10000,param_list=param_list_kud)
Error in MonteCarlo(func = infest_kud_fun, nrep = 10000, param_list = 
param_list_kud) :
 ? object 'packages' not found

 > sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets methods?? base

other attached packages:
[1] MonteCarlo_1.0.2? snowfall_1.84-6.1 snow_0.4-2 rlecuyer_0.3-4
[5] codetools_0.2-15? abind_1.4-5


best,

john

-- 
Enlightenment is ego's ultimate disappointment.
-Chogyam Trungpa


From bgunter.4567 at gmail.com  Thu Feb 15 20:58:15 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Feb 2018 11:58:15 -0800
Subject: [R] package MonteCarlo error: object 'packages' not found
In-Reply-To: <9741aa66-72e6-c9be-c017-f0a54f4594f1@mail.usf.edu>
References: <9741aa66-72e6-c9be-c017-f0a54f4594f1@mail.usf.edu>
Message-ID: <CAGxFJbSPLEqinbfDtcDYW7baeEzGf4EF34bDPgW79uMBW_=ksQ@mail.gmail.com>

This looks like the sort of thing that you should ask the package
maintainer (?maintainer).

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Feb 15, 2018 at 11:39 AM, john polo <jpolo at mail.usf.edu> wrote:

> R-users,
>
> I can't tell what's causing the following error. The vignette does not
> make a reference to a "packages" option or parameter.
>
> > library(MonteCarlo)
> Loading required package: abind
> Loading required package: codetools
> Loading required package: rlecuyer
> Loading required package: snow
> Loading required package: snowfall
>
> > infest_kud_fun<-function(x,A,B){
> +   equation1=exp(A-(B*x))
> +   return(list("equation1"=equation1))
> + }
>
>
> > x_grid<-c(0.5,10) #distances kudzu could grow
> > A_grid<-rnorm(1000) #probabilities
> > B_grid<- rnorm(1000) #probabilities
>
>
> > #put parameters in a list
> > param_list_kud=list("x"=x_grid, "A"=A_grid, "B"=B_grid)
>
> > #run MC simulation
> > MC_result_kud<-MonteCarlo(func=infest_kud_fun,nrep=10000,
> param_list=param_list_kud)
> Error in MonteCarlo(func = infest_kud_fun, nrep = 10000, param_list =
> param_list_kud) :
>   object 'packages' not found
>
> > sessionInfo()
> R version 3.4.3 (2017-11-30)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets methods   base
>
> other attached packages:
> [1] MonteCarlo_1.0.2  snowfall_1.84-6.1 snow_0.4-2 rlecuyer_0.3-4
> [5] codetools_0.2-15  abind_1.4-5
>
>
> best,
>
> john
>
> --
> Enlightenment is ego's ultimate disappointment.
> -Chogyam Trungpa
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Thu Feb 15 21:04:20 2018
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 16 Feb 2018 09:04:20 +1300
Subject: [R] Identify does sort the locations
In-Reply-To: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>
References: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>
Message-ID: <b717c1c7-f04b-17a4-68bb-7b86cab7defd@stat.auckland.ac.nz>

Hi

Indeed the help page says ...

"the indices of the identified points, in the order they were identified"

... and that is a complete lie.

Sorry about that :(

The simplest thing would be to correct the help page.

It would be possible to have identify() return the order, though for 
backward compatibility that should not be the default, so would require 
another argument to identify().

Paul

On 16/02/18 06:58, Samuel GRANJEAUD IR/INSERM wrote:
> Hi,
> 
> Using identify function, I think I should get the index of the selected 
> points in the order I clicked them. This is what I read in the help. But 
> I feel they are ordered. Please let me know what I missed.
> 
> In the following example, I clicked on the points labelled 7, 5 and 1, 
> but I get 1, 5, 7 as output.
> 
>> set.seed(0); x = rnorm(10); y = rnorm(10); plot(x,y); text(x, y, 
>> seq(x)); sel = identify(x,y); sel
> [1] 1 5 7
> 
> Any help appreciated,
> Samuel
> 
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252? LC_CTYPE=English_United 
> Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.3
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From paul at stat.auckland.ac.nz  Thu Feb 15 21:50:37 2018
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 16 Feb 2018 09:50:37 +1300
Subject: [R] Identify does sort the locations
In-Reply-To: <12a9ee9c8823180b98ce960ac8c3be2c@inserm.fr>
References: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>
 <b717c1c7-f04b-17a4-68bb-7b86cab7defd@stat.auckland.ac.nz>
 <12a9ee9c8823180b98ce960ac8c3be2c@inserm.fr>
Message-ID: <7df79732-41d9-ef17-8b0d-d4439c982a21@stat.auckland.ac.nz>

Hi

Sorry, I think this has always been the behaviour (and the documentation 
has always been wrong).

Using locator() yourself could be a workaround (with a little more 
effort required to determine the closest data point).

Paul

On 16/02/18 09:32, Samuel GRANJEAUD IR/INSERM wrote:
> Hi Paul,
> 
> Thanks for your answer. I am wondering if in the previous versions, 
> let's say 2.1x, the data were in the selection order... Let me know if 
> there a R fonction taht I can code. Do you think I should use locator 
> function and match points on my own?
> 
> Best,
> Samuel

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From samuel.granjeaud at inserm.fr  Thu Feb 15 21:32:25 2018
From: samuel.granjeaud at inserm.fr (Samuel GRANJEAUD IR/INSERM)
Date: Thu, 15 Feb 2018 21:32:25 +0100
Subject: [R] Identify does sort the locations
In-Reply-To: <b717c1c7-f04b-17a4-68bb-7b86cab7defd@stat.auckland.ac.nz>
References: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>
 <b717c1c7-f04b-17a4-68bb-7b86cab7defd@stat.auckland.ac.nz>
Message-ID: <12a9ee9c8823180b98ce960ac8c3be2c@inserm.fr>

Hi Paul,

Thanks for your answer. I am wondering if in the previous versions, 
let's say 2.1x, the data were in the selection order... Let me know if 
there a R fonction taht I can code. Do you think I should use locator 
function and match points on my own?

Best,
Samuel


From samuel.granjeaud at inserm.fr  Thu Feb 15 22:16:59 2018
From: samuel.granjeaud at inserm.fr (Samuel GRANJEAUD IR/INSERM)
Date: Thu, 15 Feb 2018 22:16:59 +0100
Subject: [R] Identify does sort the locations
In-Reply-To: <7df79732-41d9-ef17-8b0d-d4439c982a21@stat.auckland.ac.nz>
References: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>
 <b717c1c7-f04b-17a4-68bb-7b86cab7defd@stat.auckland.ac.nz>
 <12a9ee9c8823180b98ce960ac8c3be2c@inserm.fr>
 <7df79732-41d9-ef17-8b0d-d4439c982a21@stat.auckland.ac.nz>
Message-ID: <a095a5b71723e6dcfea05a9340832ca4@inserm.fr>

Thanks Paul. I have started using locator().

I also found the gatepoints package that sounds interestering.
https://CRAN.R-project.org/package=gatepoints

Happy R,
Samuel

On 15-02-2018 21:50, Paul Murrell wrote:
> Hi
> 
> Sorry, I think this has always been the behaviour (and the
> documentation has always been wrong).
> 
> Using locator() yourself could be a workaround (with a little more
> effort required to determine the closest data point).
> 
> Paul


From rjames at sk.com  Thu Feb 15 23:00:01 2018
From: rjames at sk.com (JamesRyan(Ryan James)/E&P North America Business Division)
Date: Thu, 15 Feb 2018 22:00:01 +0000
Subject: [R] Best Optimization Routines
In-Reply-To: <CALS=5mrFN2CwH5CBdEd2gYKCokwT63JVDDoA-wi6sSdPc3L9_Q@mail.gmail.com>
References: <a7f88e623cb04744bfe3bceb030eff16@sk.com>
 <CALS=5mrFN2CwH5CBdEd2gYKCokwT63JVDDoA-wi6sSdPc3L9_Q@mail.gmail.com>
Message-ID: <2c427e70379341088e7db2b0d9ff6b6b@sk.com>

Thanks Paul.  Appreciate the help.  I'll give this a shot.  

Ryan James
D: 713.395.1794
M: 214.843.7301

-----Original Message-----
From: Paul Smith [mailto:phhs80 at gmail.com] 
Sent: Thursday, February 15, 2018 7:12 AM
To: Ryan James/E&P North America Business Division/SKI
Cc: r-help at r-project.org
Subject: Re: [R] Best Optimization Routines

On Tue, Feb 13, 2018 at 7:55 PM, JamesRyan(Ryan James)/E&P North America Business Division <rjames at sk.com> wrote:
> I have a set of data, the production of oil from a well.  And an equation to predict that forecast.
>
> The equation requires 5 input variables which are real numbers with upper and lower bounds, 1 input variable which must be an integer and 1 input variable which can be 1 of 2 string variables.
>
> What is the best optimization routine (I am using nlminb) to use in R to determine the best set of inputs and how to I handle the integer and string inputs when optimizing?
>
> I have attached a plot of what I am trying to accomplish as well as my sample code.

If I understand correctly your problem, your equation is linear, and you have continuous and integer variables (the string input can be coded as a binary integer variable). Thus, you can use a package to deal with mixed integer programming:

http://blog.revolutionanalytics.com/2016/12/mixed-integer-programming-in-r-with-the-ompr-package.html

Hope this helps you,

Paul

From bretschr at xs4all.nl  Thu Feb 15 23:24:35 2018
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Thu, 15 Feb 2018 23:24:35 +0100
Subject: [R] Identify does sort the locations
In-Reply-To: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>
References: <bfe2b41bada1582be76e86d5a62cae24@inserm.fr>
Message-ID: <445CE146-F3F0-4AD0-B8A4-0FCD1DCA3749@xs4all.nl>

Hi Samuel GRANJEAUD,



Isn't this loop more simple to retain the click-order:


result = numeric(n)
for (i in 1:n) {
	id = identify(x, y, n=1)
	result[i] = id
	}

Hope this helps,

Best regards,


Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From arrayprofile at yahoo.com  Thu Feb 15 23:55:46 2018
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 15 Feb 2018 22:55:46 +0000 (UTC)
Subject: [R] Fleming-Harrington weighted log rank test
In-Reply-To: <74C39504-08EF-4598-90BC-32415BA1307A@comcast.net>
References: <1927370176.471494.1518566526278.ref@mail.yahoo.com>
 <1927370176.471494.1518566526278@mail.yahoo.com>
 <075D5963-B20B-4B05-9EE5-25F7A87D24C0@comcast.net>
 <74C39504-08EF-4598-90BC-32415BA1307A@comcast.net>
Message-ID: <1544135294.1911563.1518735346148@mail.yahoo.com>

 Thank you David!
    On Wednesday, February 14, 2018, 6:05:46 PM PST, David Winsemius <dwinsemius at comcast.net> wrote:  
 
 
> On Feb 14, 2018, at 5:26 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Feb 13, 2018, at 4:02 PM, array chip via R-help <r-help at r-project.org> wrote:
>> 
>> Hi all, 
>> 
>> The survdiff() from survival package has an argument "rho" that implements Fleming-Harrington weighted long rank test. 
>> 
>> But according to several sources including "survminer" package (https://cran.r-project.org/web/packages/survminer/vignettes/Specifiying_weights_in_log-rank_comparisons.html), Fleming-Harrington weighted log-rank test should have 2 parameters "p" and "q" to control the weighting for earlier vs later times in the follow-up.
>> 
>> For example, setting rho=1 in survdiff() uses the Peto-Peto modification of Gehan-Wilcox weights, which I can confirm by setting p=1 & 1=0 in comp() from survminer package. similarly rho=0 is equivalent to p=0 & q=0
>> 
>> I am interested in putting more weights on survival difference in later follow-up time. According to comp() from survminer package, that would set p=0 & q=1 for Fleming-Harrington weights. 
>> 
>> My question is how I can do the same by setting certain values for "rho" in the regular survival() function?
> 
> I think that survdiff uses a different version than what you have found. The G-rho family weights are:
> 
> w_j = [S?(tj)]^?
> 
> So rather than two parameters on S(t) and (1-S(t)) as in the p,q version, you only have one parameter applied to S(t). This class handout says that the G-rho,gamma weighting scheme is not available in survdiff.
> 

Forgot to paste the link:

http://www.ics.uci.edu/~dgillen/STAT255/Handouts/lecture4.pdf

> -- 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law




  
	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Feb 16 00:14:20 2018
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Thu, 15 Feb 2018 23:14:20 +0000
Subject: [R] Codes to conduct network meta-analysis, gemtc package
In-Reply-To: <CAGxFJbR8PRY=6M2igQ2eiHWj2t28rqzf2J1SgRTvo3v9pxOS_g@mail.gmail.com>
References: <2007548353.1418728.1518686922983.ref@mail.yahoo.com>
 <2007548353.1418728.1518686922983@mail.yahoo.com>
 <CAGxFJbR8PRY=6M2igQ2eiHWj2t28rqzf2J1SgRTvo3v9pxOS_g@mail.gmail.com>
Message-ID: <ac725c54d28c4fcb84723729bffb182f@UM-MAIL3214.unimaas.nl>

This aside, there is the R-sig-meta-analysis mailing list where this probably belongs:

https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
>Gunter
>Sent: Thursday, 15 February, 2018 16:49
>To: shaju jacob
>Cc: R-help
>Subject: Re: [R] Codes to conduct network meta-analysis, gemtc package
>
>This is not a free consulting service. You are expected to put in the
>work
>yourself and **may** receive help here if you have specific questions
>that
>you need help with when you do so. See the posting guide linked below for
>details.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Thu, Feb 15, 2018 at 1:28 AM, shaju jacob via R-help <
>r-help at r-project.org> wrote:
>
>> Hi,I want codes that could help me do NMA from the data. I would
>> appreciate if you could give a dummy table with which I could practice
>the
>> codes that would help read the data and calculateOdds ratio (OR)
>> Mean difference (MD)
>> forest plot
>> Density plot of posterior samples
>> Estimates of ranks probabilities
>> Rank probabilities plot (rankogram)
>> Network plots
>>
>> The manual by Gert van Valkenhoef is difficult for me to understand and
>> comprehend.


From jpolo at mail.usf.edu  Fri Feb 16 00:26:20 2018
From: jpolo at mail.usf.edu (john polo)
Date: Thu, 15 Feb 2018 15:26:20 -0800
Subject: [R] package MonteCarlo error: object 'packages' not found
In-Reply-To: <CAGxFJbSPLEqinbfDtcDYW7baeEzGf4EF34bDPgW79uMBW_=ksQ@mail.gmail.com>
References: <9741aa66-72e6-c9be-c017-f0a54f4594f1@mail.usf.edu>
 <CAGxFJbSPLEqinbfDtcDYW7baeEzGf4EF34bDPgW79uMBW_=ksQ@mail.gmail.com>
Message-ID: <ee250c48-33ca-9bf3-4892-a1eb7642ae81@mail.usf.edu>

Will do, Bert.

Thank you,
John

On 2/15/2018 11:58 AM, Bert Gunter wrote:
> This looks like the sort of thing that you should ask the package 
> maintainer (?maintainer).
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Feb 15, 2018 at 11:39 AM, john polo <jpolo at mail.usf.edu 
> <mailto:jpolo at mail.usf.edu>> wrote:
>
>     R-users,
>
>     I can't tell what's causing the following error. The vignette does
>     not make a reference to a "packages" option or parameter.
>
>     > library(MonteCarlo)
>     Loading required package: abind
>     Loading required package: codetools
>     Loading required package: rlecuyer
>     Loading required package: snow
>     Loading required package: snowfall
>
>     > infest_kud_fun<-function(x,A,B){
>     +?? equation1=exp(A-(B*x))
>     +?? return(list("equation1"=equation1))
>     + }
>
>
>     > x_grid<-c(0.5,10) #distances kudzu could grow
>     > A_grid<-rnorm(1000) #probabilities
>     > B_grid<- rnorm(1000) #probabilities
>
>
>     > #put parameters in a list
>     > param_list_kud=list("x"=x_grid, "A"=A_grid, "B"=B_grid)
>
>     > #run MC simulation
>     >
>     MC_result_kud<-MonteCarlo(func=infest_kud_fun,nrep=10000,param_list=param_list_kud)
>     Error in MonteCarlo(func = infest_kud_fun, nrep = 10000,
>     param_list = param_list_kud) :
>     ? object 'packages' not found
>
>     > sessionInfo()
>     R version 3.4.3 (2017-11-30)
>     Platform: i386-w64-mingw32/i386 (32-bit)
>     Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>     Matrix products: default
>
>     locale:
>     [1] LC_COLLATE=English_United States.1252
>     [2] LC_CTYPE=English_United States.1252
>     [3] LC_MONETARY=English_United States.1252
>     [4] LC_NUMERIC=C
>     [5] LC_TIME=English_United States.1252
>
>     attached base packages:
>     [1] stats???? graphics? grDevices utils???? datasets methods?? base
>
>     other attached packages:
>     [1] MonteCarlo_1.0.2? snowfall_1.84-6.1 snow_0.4-2 rlecuyer_0.3-4
>     [5] codetools_0.2-15? abind_1.4-5
>
>
>     best,
>
>     john
>
>     -- 
>     Enlightenment is ego's ultimate disappointment.
>     -Chogyam Trungpa
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Enlightenment is ego's ultimate disappointment.
-Chogyam Trungpa


	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Feb 16 01:43:53 2018
From: chocold12 at gmail.com (lily li)
Date: Thu, 15 Feb 2018 17:43:53 -0700
Subject: [R] error in loading rgdal package
Message-ID: <CAN5afy8bAdrvhhsYjTxDufWzM1zMqNu8oTMNrJGJcc=MUCsABg@mail.gmail.com>

Hi R users,

Could you help me to see this problem? I could now load "rgdal" even though
I downloaded the compressed folder. Thanks for your help.

Loading required package: sp
Error in dyn.load(file, DLLpath = DLLpath, ...) :
  unable to load shared object
'/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgdal/libs/rgdal.so':

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Fri Feb 16 02:27:13 2018
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 16 Feb 2018 02:27:13 +0100
Subject: [R] SE for all levels (including reference) of a factor atfer a GLM
Message-ID: <005921c9-4ba0-1f87-92cc-961d08a2c82e@yahoo.fr>

Dear R-er,

I try to get the standard error of fitted parameters for factors with a 
glm, even the reference one:

a <- runif(100)
b <- sample(x=c("0", "1", "2"), size=100, replace = TRUE)
df <- data.frame(A=a, B=b, stringsAsFactors = FALSE)

g <- glm(a ~ b, data=df)
summary(g)$coefficients

# I don't get SE for the reference factor, here 0:

 ????????????? Estimate Std. Error??? t value???? Pr(>|t|)
(Intercept)? 0.50384827 0.05616631? 8.9706490 2.236684e-14
b1????????? -0.03598386 0.07496151 -0.4800311 6.322860e-01
b2?????????? 0.03208039 0.07063113? 0.4541962 6.507023e-01

# Then I try to change the order of factors, for example:

df$B[df$B=="0"] <- "3"
g <- glm(a ~ b, data=df)
summary(g)$coefficients

By I get the same...

Any idea ?

Thanks

Marc


From bgunter.4567 at gmail.com  Fri Feb 16 03:28:54 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Feb 2018 18:28:54 -0800
Subject: [R] 
 SE for all levels (including reference) of a factor atfer a GLM
In-Reply-To: <005921c9-4ba0-1f87-92cc-961d08a2c82e@yahoo.fr>
References: <005921c9-4ba0-1f87-92cc-961d08a2c82e@yahoo.fr>
Message-ID: <CAGxFJbTssd8gvQqukRJqVz0ZaCK-ArZZDspk5LVkQNh+KPvQ+A@mail.gmail.com>

This is really a statistical issue. What do you think the Intercept term
represents? See ?contrasts.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Feb 15, 2018 at 5:27 PM, Marc Girondot via R-help <
r-help at r-project.org> wrote:

> Dear R-er,
>
> I try to get the standard error of fitted parameters for factors with a
> glm, even the reference one:
>
> a <- runif(100)
> b <- sample(x=c("0", "1", "2"), size=100, replace = TRUE)
> df <- data.frame(A=a, B=b, stringsAsFactors = FALSE)
>
> g <- glm(a ~ b, data=df)
> summary(g)$coefficients
>
> # I don't get SE for the reference factor, here 0:
>
>               Estimate Std. Error    t value     Pr(>|t|)
> (Intercept)  0.50384827 0.05616631  8.9706490 2.236684e-14
> b1          -0.03598386 0.07496151 -0.4800311 6.322860e-01
> b2           0.03208039 0.07063113  0.4541962 6.507023e-01
>
> # Then I try to change the order of factors, for example:
>
> df$B[df$B=="0"] <- "3"
> g <- glm(a ~ b, data=df)
> summary(g)$coefficients
>
> By I get the same...
>
> Any idea ?
>
> Thanks
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Feb 16 05:02:09 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 16 Feb 2018 17:02:09 +1300
Subject: [R] [FORGED] Re: SE for all levels (including reference) of a
 factor atfer a GLM
In-Reply-To: <CAGxFJbTssd8gvQqukRJqVz0ZaCK-ArZZDspk5LVkQNh+KPvQ+A@mail.gmail.com>
References: <005921c9-4ba0-1f87-92cc-961d08a2c82e@yahoo.fr>
 <CAGxFJbTssd8gvQqukRJqVz0ZaCK-ArZZDspk5LVkQNh+KPvQ+A@mail.gmail.com>
Message-ID: <d14880fb-c340-11bc-9a8d-a5b1e0cdf6da@auckland.ac.nz>


On 16/02/18 15:28, Bert Gunter wrote:

> This is really a statistical issue. What do you think the Intercept term
> represents? See ?contrasts.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

It's a *little* bit R-ish in that the results depend on the 
parametrisation of the model which by default in R is formed using the 
so-called "treatment" contrasts.

To wander from R into statistics (sorry Bert) the problem arises because
the "usual" parametrisation of the model is the "over-parametrised" form:

Y_ij = mu + beta_i + E_ij (i = 1, ..., I, j = 1, ..., J_i)

where Y_ij is the j-th observation corresponding to the i-th "treatment" 
or group.  (Things get a bit more complicated in "multi-way" models; 
let's not go there.)

The parameter "mu" is the "grand mean" and the "beta_i" are the 
"treatment" effects.

The trouble with this parametrisation is that the parameters are 
meaningless!  (The usual jargon is to say that they are "not estimable",
but "meaningless"  is a more accurate description.)

In order to ascribe unique values to the parameters, one must apply a 
"constraint".  With the "treatment contrasts" the constraint is that
beta_1 = 0.

As a result the mean for the first treatment is mu, that for the second
treatment is mu + beta_2, and so on.

Consequently the SE corresponding to "(Intercept)" is the SE of 
estimated mean for treatment 1.  The SE corresponding to beta_2 is the 
SE of the estimated *difference* between the mean for treatment 2 and 
that for treatment 1, and so on.

Frequently the constraint beta_1 + ...+ beta_I = 0 is used.  This
sort of treats all of the beta_i equally. At this point it gets R-ish 
again. You can impose the foregoing constraint by using either "sum" or 
"Helmert" contrasts.  You can get the "more natural", "fully" (rather 
than "over") parametrised model via the syntax:

     g <- glm(a ~ 0 + b, data=df)

or

     g <- glm(a ~ b - 1, data=df)

This syntax actually imposes the constraint that mu = 0.

(Here "contrasts" don't get involved --- a bit counterintuitive, that.)

The foregoing expressions will give you estimates labelled "b0", "b1", 
"b2" (nothing labelled "(Intercept)") and these estimate are of the 
treatment means and the SEs are straightforward to interpret.

There *is* a rationale for the use of the over-parametrised model, but I 
won't try to explain it here.  I've raved on long enough.

Marc:  I hope this helps.

cheers,

Rolf

P.S. It is bad form to call a data frame "df" since this is the name of 
the density function for the family of F-distributions.  There are 
circumstances in which such usage can lead to error messages which are 
impossible to interpret, e.g. "object of type 'closure' is not 
subsettable". (!!!)

R.

> 
> On Thu, Feb 15, 2018 at 5:27 PM, Marc Girondot via R-help <
> r-help at r-project.org> wrote:
> 
>> Dear R-er,
>>
>> I try to get the standard error of fitted parameters for factors with a
>> glm, even the reference one:
>>
>> a <- runif(100)
>> b <- sample(x=c("0", "1", "2"), size=100, replace = TRUE)
>> df <- data.frame(A=a, B=b, stringsAsFactors = FALSE)
>>
>> g <- glm(a ~ b, data=df)
>> summary(g)$coefficients
>>
>> # I don't get SE for the reference factor, here 0:
>>
>>                Estimate Std. Error    t value     Pr(>|t|)
>> (Intercept)  0.50384827 0.05616631  8.9706490 2.236684e-14
>> b1          -0.03598386 0.07496151 -0.4800311 6.322860e-01
>> b2           0.03208039 0.07063113  0.4541962 6.507023e-01
>>
>> # Then I try to change the order of factors, for example:
>>
>> df$B[df$B=="0"] <- "3"
>> g <- glm(a ~ b, data=df)
>> summary(g)$coefficients
>>
>> By I get the same...
>>
>> Any idea ?
>>
>> Thanks
>>
>> Marc


From p_connolly at slingshot.co.nz  Thu Feb 15 09:40:16 2018
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 15 Feb 2018 21:40:16 +1300
Subject: [R] Using gutenbergr with a firewall
In-Reply-To: <B93F28D1-A843-4665-8EA2-9D132C27EAD0@dcn.davis.ca.us>
References: <20180214065540.GA7936@slingshot.co.nz>
 <B93F28D1-A843-4665-8EA2-9D132C27EAD0@dcn.davis.ca.us>
Message-ID: <20180215084016.GB7936@slingshot.co.nz>


My question was to ascertain whether anyone had a similar problem with
their firewall before I make a request to the controllers of our
firewall.  With any luck, I might get information that will be useful
in ascertaining where the bottle-neck is.

So far, nobody has indicated that they can use gutenberg_download if
they're behind a firewall, which might indicate that it is not
possible to do, whatever the firewall settings are.  If that's the
case, I may as well not bother trying to get our firewall warrior to
work out what can be changed and still achieve what is considered
necessary.

Anyone succeed?



On Tue, 13-Feb-2018 at 11:25PM -0800, Jeff Newmiller wrote:

|> Saying "a firewall" is like saying "a weapon". Some firewalls are
|> much more strict than others, and yours may be different than any
|> someone here might have encountered. You might also be having
|> trouble with anti virus software.  --


|> Sent from my phone. Please excuse my brevity.
|> 
|> On February 13, 2018 10:55:40 PM PST, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> >I can use the gutenberg_download() function in the gutenbergr package
|> >on a computer that doeson't use a firewall, but on an almost identical
|> >installation that is behind a firewall, nothing happens, not even a
|> >time-out.
|> >
|> >Has anyone succeeded in using gutenberg_download() successfully with a
|> >firewall?  I tried raising an issue at
|> >https://github.com/ropenscilabs/gutenbergr/issues/17 with no usable
|> >response.  I also tried contacting the maintainer but got no response.
|> >
|> >The firewall might be a red-herring, but I thought it worthwhile
|> >eliminating it as a factor.
|> >
|> >I would welcome any information on anyone else's experience.
|> >
|> >Thank you.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From shajujacob at yahoo.com  Fri Feb 16 00:49:32 2018
From: shajujacob at yahoo.com (shaju jacob)
Date: Thu, 15 Feb 2018 23:49:32 +0000 (UTC)
Subject: [R] Codes to conduct network meta-analysis, gemtc package
In-Reply-To: <ac725c54d28c4fcb84723729bffb182f@UM-MAIL3214.unimaas.nl>
References: <2007548353.1418728.1518686922983.ref@mail.yahoo.com>
 <2007548353.1418728.1518686922983@mail.yahoo.com>
 <CAGxFJbR8PRY=6M2igQ2eiHWj2t28rqzf2J1SgRTvo3v9pxOS_g@mail.gmail.com>
 <ac725c54d28c4fcb84723729bffb182f@UM-MAIL3214.unimaas.nl>
Message-ID: <1741155580.1935061.1518738572265@mail.yahoo.com>

Thank you so much. Apologies for coming in this with this so basic query. Thanks again?

Sent from Yahoo Mail on Android 
 
  On Fri, 16 Feb 2018 at 7:14 AM, Viechtbauer Wolfgang (SP)<wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:   This aside, there is the R-sig-meta-analysis mailing list where this probably belongs:

https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis

Best,
Wolfgang

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
>Gunter
>Sent: Thursday, 15 February, 2018 16:49
>To: shaju jacob
>Cc: R-help
>Subject: Re: [R] Codes to conduct network meta-analysis, gemtc package
>
>This is not a free consulting service. You are expected to put in the
>work
>yourself and **may** receive help here if you have specific questions
>that
>you need help with when you do so. See the posting guide linked below for
>details.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Thu, Feb 15, 2018 at 1:28 AM, shaju jacob via R-help <
>r-help at r-project.org> wrote:
>
>> Hi,I want codes that could help me do NMA from the data. I would
>> appreciate if you could give a dummy table with which I could practice
>the
>> codes that would help read the data and calculateOdds ratio (OR)
>> Mean difference (MD)
>> forest plot
>> Density plot of posterior samples
>> Estimates of ranks probabilities
>> Rank probabilities plot (rankogram)
>> Network plots
>>
>> The manual by Gert van Valkenhoef is difficult for me to understand and
>> comprehend.  

	[[alternative HTML version deleted]]


From somyajain697 at yahoo.com  Fri Feb 16 06:25:12 2018
From: somyajain697 at yahoo.com (Tanya Goyal )
Date: Fri, 16 Feb 2018 10:55:12 +0530
Subject: [R] All Language Translation Solution !!
Message-ID: <0df701d3a6e6$9dff75d0$d9fe6170$@com>

Hi, r-help at stat.math.ethz.ch

Did you receive my last email?

Actually I haven't received any response from your side please let me know
if you are interested in our services (Like- Translation,
Localization.Interpretation, Content Writing,Certified Translation,CAD
Services,Desktop Publishing,Proofreading & Editing,Content Moderation)

Will be a pleasure to assist you. 

Looking to hear from you soon. 

Thank You

On, fri, Mon- 12, 2018 at 11:21 AM, Tanya Goyal wrote: 

Hi,  

Hope you're doing well,

I am representing a Translation Company that has expertise in the
Translation, Interpretation and Localization sector since 2002.

We provide translation services in more than 100 languages like Russian,
Polish, Chinese, German, Swedish, Spanish, Ukrainian, Italian, Arabic,
Japanese, Thai, Dutch, French, Vietnamese, Swedish, Korean and regional
Languages.  

Major Sectors: Medical Translation, Marketing Material Translation, Academic
Translation, Book Translation, Financial Translation, Technical Translation,
Legal Translation, E-learning course translation, Website and Software
Localization.

Major Clientele: HP, NIIT, Samsung Engineering, Fluor, Schneider Electric,
ABB Ltd,  Posco, TOYO, Sulzer, Emerson, TATA, Petrofac, BHEL, Siemens Ltd,
Larsen & Toubro.

 Thanks & Regards,

Tanya Goyal 

Dept.-Tr & In

 


	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Fri Feb 16 07:49:39 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Fri, 16 Feb 2018 07:49:39 +0100
Subject: [R] error in loading rgdal package
In-Reply-To: <CAN5afy8bAdrvhhsYjTxDufWzM1zMqNu8oTMNrJGJcc=MUCsABg@mail.gmail.com>
 (lily li's message of "Thu, 15 Feb 2018 17:43:53 -0700")
References: <CAN5afy8bAdrvhhsYjTxDufWzM1zMqNu8oTMNrJGJcc=MUCsABg@mail.gmail.com>
Message-ID: <87fu61mnss.fsf@hornfels.zedat.fu-berlin.de>

Hi Lily,

lily li <chocold12 at gmail.com> writes:

> Hi R users,
>
> Could you help me to see this problem? I could now load "rgdal" even though
> I downloaded the compressed folder. Thanks for your help.
>
> Loading required package: sp
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>   unable to load shared object
> '/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rgdal/libs/rgdal.so':

Have you installed the GDAL library itself?  The R package rgdal needs
this.  See the "SystemRequirements" section on the CPAN page:

  https://CRAN.R-project.org/package=rgdal

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From leif.ruckman at kau.se  Fri Feb 16 09:18:07 2018
From: leif.ruckman at kau.se (Leif Ruckman)
Date: Fri, 16 Feb 2018 08:18:07 +0000
Subject: [R] stem - strange leaves
Message-ID: <d8a50128e909451fafd3a8cae35a6d4c@kau.se>

> x
[1] 8.0 7.9 7.5 7.0 8.0 7.3 8.0 7.2 7.4 7.3 7.8 8.0 7.7 8.3 7.8 7.8 7.1 7.7 6.9 7.5 7.5 7.3 7.2 7.5 7.2
> stem(x)

  The decimal point is at the |

  6 | 9
  7 | 012223334
  7 | 5555778889
  8 | 00003

> y <- c(x, 8)
> stem(y)

  The decimal point is 1 digit(s) to the left of the |

  68 | 0
  70 | 00
  72 | 000000
  74 | 00000
  76 | 00
  78 | 0000
  80 | 00000
  82 | 0
The first stem is as I want it to be and expect it to be. When I add one more observation R seems to add an extra decimal zero to my observations and all leaves are now zero. Why does this happen?

Regards
Leif

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Feb 16 10:24:26 2018
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Fri, 16 Feb 2018 10:24:26 +0100
Subject: [R] [FORGED] Re: SE for all levels (including reference) of a
 factor atfer a GLM
In-Reply-To: <d14880fb-c340-11bc-9a8d-a5b1e0cdf6da@auckland.ac.nz>
References: <005921c9-4ba0-1f87-92cc-961d08a2c82e@yahoo.fr>
 <CAGxFJbTssd8gvQqukRJqVz0ZaCK-ArZZDspk5LVkQNh+KPvQ+A@mail.gmail.com>
 <d14880fb-c340-11bc-9a8d-a5b1e0cdf6da@auckland.ac.nz>
Message-ID: <EEEB40F6-1E2B-44C8-BFD0-757A1A722E68@gmail.com>


To give a short answer to the original question:

> On 16 Feb 2018, at 05:02 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> In order to ascribe unique values to the parameters, one must apply a "constraint".  With the "treatment contrasts" the constraint is that
> beta_1 = 0.

...and consequently, being a constant, has an s.e. of 0.  


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marc_grt at yahoo.fr  Fri Feb 16 10:32:47 2018
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 16 Feb 2018 10:32:47 +0100
Subject: [R] [FORGED] Re: SE for all levels (including reference) of a
 factor atfer a GLM
In-Reply-To: <EEEB40F6-1E2B-44C8-BFD0-757A1A722E68@gmail.com>
References: <005921c9-4ba0-1f87-92cc-961d08a2c82e@yahoo.fr>
 <CAGxFJbTssd8gvQqukRJqVz0ZaCK-ArZZDspk5LVkQNh+KPvQ+A@mail.gmail.com>
 <d14880fb-c340-11bc-9a8d-a5b1e0cdf6da@auckland.ac.nz>
 <EEEB40F6-1E2B-44C8-BFD0-757A1A722E68@gmail.com>
Message-ID: <c31b7c0f-cdb9-d9c2-d510-1f8eccc4e9d7@yahoo.fr>

Le 16/02/2018 ? 10:24, Peter Dalgaard a ?crit?:
> To give a short answer to the original question:
>
>> On 16 Feb 2018, at 05:02 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> In order to ascribe unique values to the parameters, one must apply a "constraint".  With the "treatment contrasts" the constraint is that
>> beta_1 = 0.
> ...and consequently, being a constant, has an s.e. of 0.
>
>
It makes sense !

Thanks for the precision !

Marc


From amalraj.raja at abdn.ac.uk  Fri Feb 16 11:36:31 2018
From: amalraj.raja at abdn.ac.uk (Raja, Dr. Edwin Amalraj)
Date: Fri, 16 Feb 2018 10:36:31 +0000
Subject: [R] Competing risks - calibration curve
Message-ID: <VI1PR0402MB3822AAB37683366D81335DCFA1CB0@VI1PR0402MB3822.eurprd04.prod.outlook.com>

Dear R users,

    I am new to R and wanted to apply competing risk methods in my research work. I used the R code given by Zhang et al in his paper 'Nomogram for survival analysis in the presence of competing risks published in Ann Trans Med 2017:5(20):403.

I am struggling with getting calibration curve thro' internal validation.   I am happy to receive suggestion in the coding as well as any reference

Can someone help with it?

Regards
Amalraj Raja
University of Aberdeen


The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

From amalraj.raja at abdn.ac.uk  Fri Feb 16 13:29:49 2018
From: amalraj.raja at abdn.ac.uk (Raja, Dr. Edwin Amalraj)
Date: Fri, 16 Feb 2018 12:29:49 +0000
Subject: [R] Competing risks - calibration curve
Message-ID: <VI1PR0402MB3822CDE0E48239F4293701BAA1CB0@VI1PR0402MB3822.eurprd04.prod.outlook.com>

Hi,

Sorry not to provide R-code in my previous mail.  R code is below


#install.packages("rms")
require(rms)
#install.packages("mstate")
library(mstate)
require(splines)
library(ggplot2)
library(survival)
library(splines)
#install.packages("survsim")
require(survsim)
set.seed(10)
df<-crisk.sim(n=500, foltime=10, dist.ev=rep("lnorm",2), anc.ev=c(1.48,0.53),beta0.ev = c(3.80,2.54), dist.cens = "lnorm", anc.cens = 3.5, beta0.cens = 5.42, z=NULL, beta = list(c(0.21, 0.017), c(0.37, 0.016)), x=list(c("normal",0,1), c("bern",0.564)), nsit=2)

table(status)
table(cause)

df$cause<-ifelse(is.na(df$cause),0,df$cause)
table(df$cause)

df.w<-crprep("time","cause", data=df, trans=c(1,2), cens=0, id="nid", keep=c("x", "x.1"))

with(df.w,table(failcode,status))
ddist<-datadist(df.w)
options(datadist='ddist')
mod<-cph(Surv(Tstart,Tstop,status==1)~rcs(x,3)+x.1,data=df.w, weight=weight.cens, subset=failcode==1, x=T, y=T, surv=T, time.inc = 2.5) mod2<-cph(Surv(Tstart,Tstop,status==1)~(x.1+rcs(x,3))^2,data=df.w, weight=weight.cens, subset=failcode==1, x=T, y=T, surv=T, time.inc = 2.5)
mod2

##########################  To develop nomogram
surv<-Survival(mod)
nom.sur<-nomogram(mod,fun=list(function(x) 1-surv(3,x), function(x) 1-surv(5,x), function(x) 1-surv(7,x), function(x) 1-surv(9,x)), funlabel=c("3-year event 1 Prob.", "5-year event 1 Prob.", "7-year event 1 Prob.", "9-year event 1 Prob."), lp=T) #plot(nom.sur, fun.side=list(rep(1,8), c(1,1,1,3,1,3,1,3,1,3,1,3,1,3,1),rep(1,10),rep(1,12))x)
plot(nom.sur)
#plot(nom.sur, fun.side=list(rep(1,8),c(1,1,1,3,1,3,1,3,1,3,1,3,1,3,1)))

#plot(nom.sur, fun.side=list(rep(1,10), c(1,1,1,1,3,1,3,1,3,1,3,1,3,1,3,1), rep(1,10), rep(1,10)))


#table(status)
###########################
#or f <- psm(S ~ ...)
pa <-  'polspline'%in% row.names(installed.packages())
if(pa) {
  cal <- calibrate(mod, u=2.5, m=20, B=20)  # cmethod=  '  hare  '
  plot(cal)
}

####################################
#         validate

v<-validate(mod, method='boot', B=5)
v
####################################
####################################
#         Calibration
set.seed(717)

cal<-calibrate(mod, method="boot", u=1, B=120, pr=FALSE, force=NULL, estimates=TRUE,
               bw=FALSE, aics=0, what="observed-predicted", tol=1e-12, maxdim=5) plot(cal, subtitles=FALSE)
plot(cal)
cal.km <- calibrate(mod, u=1, cmethod='KM', m=10, B=10, pr=FALSE)
plot(cal.km)
cal.hare = calibrate(mod, u=1, cmethod='hare', m=20, B=20)
plot(cal.hare)
#####################################

Regards
Amalraj

From: Raja, Dr. Edwin Amalraj
Sent: 16 February 2018 10:37
To: 'r-help at r-project.org' <r-help at r-project.org>
Subject: Competing risks - calibration curve

Dear R users,

    I am new to R and wanted to apply competing risk methods in my research work. I used the R code given by Zhang et al in his paper 'Nomogram for survival analysis in the presence of competing risks published in Ann Trans Med 2017:5(20):403.

I am struggling with getting calibration curve thro' internal validation.   I am happy to receive suggestion in the coding as well as any reference

Can someone help with it?

Regards
Amalraj Raja
University of Aberdeen


The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Feb 16 13:39:24 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Feb 2018 12:39:24 +0000
Subject: [R] 
 Putting 733 discrete categories on Y-axis in qqplot2 as they are
In-Reply-To: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>
References: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>
Message-ID: <deb8bcbfbdff47a0947a394d8116df48@SRVEXCHCM1301.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg holly
> Sent: Thursday, February 15, 2018 3:58 PM
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] Putting 733 discrete categories on Y-axis in qqplot2 as they are
>
> Hi all;
>
> I have 733 discrete categories that will go on y-axis in ggplot2. I used the
> following command to put the name of x-axis.
>
> scale_x_discrete (limits = c("SI", "HOMAIR",
> "AIR","HOMAB","SG","DI","FI","FG"))
>
> Since there are only 8 categories on x it was easy to do. Is there any way to do
> the same for 733 discrete categories for y-axis. Essentially I did not want to
> order categories. I would like to put the name of categories as they are.

You probably can achieve the y axis with 733 levels if you do not use limits in scale.

Just from curiosity, standard page has 30 lines, so your axis should stretch to more than 20 pages. Or you need to shrink your y axis 20 times. Both options will give you unreadable results.

Cheers
Petr

>
> Best regards,
>
> Greg
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Feb 16 13:52:14 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Feb 2018 12:52:14 +0000
Subject: [R] stem - strange leaves
In-Reply-To: <d8a50128e909451fafd3a8cae35a6d4c@kau.se>
References: <d8a50128e909451fafd3a8cae35a6d4c@kau.se>
Message-ID: <3c92016d08be4081b3a8b84f8cd9a785@SRVEXCHCM1301.precheza.cz>

Hi

I do not know why does it happen but you can control the behaviour by setting scale to 0.5.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Leif Ruckman
> Sent: Friday, February 16, 2018 9:18 AM
> To: r-help at r-project.org
> Subject: [R] stem - strange leaves
>
> > x
> [1] 8.0 7.9 7.5 7.0 8.0 7.3 8.0 7.2 7.4 7.3 7.8 8.0 7.7 8.3 7.8 7.8 7.1 7.7 6.9 7.5
> 7.5 7.3 7.2 7.5 7.2
> > stem(x)
>
>   The decimal point is at the |
>
>   6 | 9
>   7 | 012223334
>   7 | 5555778889
>   8 | 00003
>
> > y <- c(x, 8)
> > stem(y)
>
>   The decimal point is 1 digit(s) to the left of the |
>
>   68 | 0
>   70 | 00
>   72 | 000000
>   74 | 00000
>   76 | 00
>   78 | 0000
>   80 | 00000
>   82 | 0
> The first stem is as I want it to be and expect it to be. When I add one more
> observation R seems to add an extra decimal zero to my observations and all
> leaves are now zero. Why does this happen?
>
> Regards
> Leif
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From mak.hholly at gmail.com  Fri Feb 16 15:55:38 2018
From: mak.hholly at gmail.com (greg holly)
Date: Fri, 16 Feb 2018 17:55:38 +0300
Subject: [R] 
 Putting 733 discrete categories on Y-axis in qqplot2 as they are
In-Reply-To: <deb8bcbfbdff47a0947a394d8116df48@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>
 <deb8bcbfbdff47a0947a394d8116df48@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAM9Qe4jBCoEQoXeRpOOBSz-myYhj4VBz74CYsu_ZnLbOwGDmbw@mail.gmail.com>

Hi Petr;

Thanks. I do save the result in pdf by using the following command.

   ggsave("z7.pdf", p4, height = 95, width = 8, device=pdf, limitsize =
F,dpi=300)

 I can achieve the y axis with 733 levels. But I need get the plot WITHOUT
reordering the names.

Regards,

Greg

On Fri, Feb 16, 2018 at 3:39 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
> holly
> > Sent: Thursday, February 15, 2018 3:58 PM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] Putting 733 discrete categories on Y-axis in qqplot2 as
> they are
> >
> > Hi all;
> >
> > I have 733 discrete categories that will go on y-axis in ggplot2. I used
> the
> > following command to put the name of x-axis.
> >
> > scale_x_discrete (limits = c("SI", "HOMAIR",
> > "AIR","HOMAB","SG","DI","FI","FG"))
> >
> > Since there are only 8 categories on x it was easy to do. Is there any
> way to do
> > the same for 733 discrete categories for y-axis. Essentially I did not
> want to
> > order categories. I would like to put the name of categories as they are.
>
> You probably can achieve the y axis with 733 levels if you do not use
> limits in scale.
>
> Just from curiosity, standard page has 30 lines, so your axis should
> stretch to more than 20 pages. Or you need to shrink your y axis 20 times.
> Both options will give you unreadable results.
>
> Cheers
> Petr
>
> >
> > Best regards,
> >
> > Greg
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Fri Feb 16 16:08:45 2018
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 16 Feb 2018 15:08:45 +0000
Subject: [R] weighed Fleming-Harrington log rank test
Message-ID: <fd55f7$8tblvc@ironport10.mayo.edu>

You are correct that the survreg routine only supports 'rho' of the Fleming-Harrington G-rho tests.  This is a function of age -- I wrote the original code back when I was working with Tom (Fleming), and he was only using 1 parameter.  Later he and David expanded the test to two parameters.  This might be only the second request for the feature in the 30+ years since that date.

Terry Therneau

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Feb 16 16:13:50 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Feb 2018 15:13:50 +0000
Subject: [R] 
 Putting 733 discrete categories on Y-axis in qqplot2 as they are
In-Reply-To: <CAM9Qe4jBCoEQoXeRpOOBSz-myYhj4VBz74CYsu_ZnLbOwGDmbw@mail.gmail.com>
References: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>
 <deb8bcbfbdff47a0947a394d8116df48@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4jBCoEQoXeRpOOBSz-myYhj4VBz74CYsu_ZnLbOwGDmbw@mail.gmail.com>
Message-ID: <1aa1bd784ab7433d86f3bfeecf6620d7@SRVEXCHCM1301.precheza.cz>

Hi

What do you mean ?without reordering the names?. Factor variable is ordered according to its levels and you can freely change the ordering. This is why factors are useful and worth to use in many cases instead of character vectors.

See this result

> iris$MySpecies<-factor(iris$Species, levels(iris$Species)[c(2,3,1)])
> p<-ggplot(iris, aes(x=Sepal.Length, y=Species))
> p+geom_point()
> p<-ggplot(iris, aes(x=Sepal.Length, y=MySpecies))
> p+geom_point()
>
Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Friday, February 16, 2018 3:56 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Putting 733 discrete categories on Y-axis in qqplot2 as they are

Hi Petr;

Thanks. I do save the result in pdf by using the following command.

   ggsave("z7.pdf", p4, height = 95, width = 8, device=pdf, limitsize = F,dpi=300)

 I can achieve the y axis with 733 levels. But I need get the plot WITHOUT reordering the names.

Regards,

Greg

On Fri, Feb 16, 2018 at 3:39 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
> Sent: Thursday, February 15, 2018 3:58 PM
> To: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Putting 733 discrete categories on Y-axis in qqplot2 as they are
>
> Hi all;
>
> I have 733 discrete categories that will go on y-axis in ggplot2. I used the
> following command to put the name of x-axis.
>
> scale_x_discrete (limits = c("SI", "HOMAIR",
> "AIR","HOMAB","SG","DI","FI","FG"))
>
> Since there are only 8 categories on x it was easy to do. Is there any way to do
> the same for 733 discrete categories for y-axis. Essentially I did not want to
> order categories. I would like to put the name of categories as they are.

You probably can achieve the y axis with 733 levels if you do not use limits in scale.

Just from curiosity, standard page has 30 lines, so your axis should stretch to more than 20 pages. Or you need to shrink your y axis 20 times. Both options will give you unreadable results.

Cheers
Petr

>
> Best regards,
>
> Greg
>



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Feb 16 16:17:50 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 16 Feb 2018 15:17:50 +0000
Subject: [R] stem - strange leaves
In-Reply-To: <2726d2fdfc8a473596f342adaa47d194@kau.se>
References: <d8a50128e909451fafd3a8cae35a6d4c@kau.se>
 <3c92016d08be4081b3a8b84f8cd9a785@SRVEXCHCM1301.precheza.cz>
 <2726d2fdfc8a473596f342adaa47d194@kau.se>
Message-ID: <ea8b0cfb19814c63ac7e82ae162ffcce@SRVEXCHCM1301.precheza.cz>

Hi

R is open source so you could dig into the code. However the actual stem function is probably written in C, so it is beyond my expertise. If you replied to the list there could be experts who are able to provide explanation.

> stem
function (x, scale = 1, width = 80, atom = 1e-08)
{
    if (!is.numeric(x))
        stop("'x' must be numeric")
    x <- x[is.finite(x)]
    n <- as.integer(length(x))
    if (is.na(n))
        stop("invalid length(x)")
    if (n == 0)
        stop("no finite and non-missing values")
    if (scale <= 0)
        stop("'scale' must be positive")
    .Call(C_StemLeaf, as.double(x), scale, width, atom)
    invisible(NULL)
}
<bytecode: 0x000000000dea62e0>
<environment: namespace:graphics>
>
Cheers
Petr

> -----Original Message-----
> From: Leif Ruckman [mailto:leif.ruckman at kau.se]
> Sent: Friday, February 16, 2018 3:27 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Subject: RE: stem - strange leaves
>
> Thank you, I also found that solution but I think it is strange that this happens
> at all. I have tried different data and sometimes this happens and sometimes it
> doesn't so I would like to understand why.
>
> Regards
>
> Leif Ruckman
>
>
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: den 16 februari 2018 13:52
> To: Leif Ruckman <leif.ruckman at kau.se>; r-help at r-project.org
> Subject: RE: stem - strange leaves
>
> Hi
>
> I do not know why does it happen but you can control the behaviour by setting
> scale to 0.5.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Leif
> > Ruckman
> > Sent: Friday, February 16, 2018 9:18 AM
> > To: r-help at r-project.org
> > Subject: [R] stem - strange leaves
> >
> > > x
> > [1] 8.0 7.9 7.5 7.0 8.0 7.3 8.0 7.2 7.4 7.3 7.8 8.0 7.7 8.3 7.8 7.8
> > 7.1 7.7 6.9 7.5
> > 7.5 7.3 7.2 7.5 7.2
> > > stem(x)
> >
> >   The decimal point is at the |
> >
> >   6 | 9
> >   7 | 012223334
> >   7 | 5555778889
> >   8 | 00003
> >
> > > y <- c(x, 8)
> > > stem(y)
> >
> >   The decimal point is 1 digit(s) to the left of the |
> >
> >   68 | 0
> >   70 | 00
> >   72 | 000000
> >   74 | 00000
> >   76 | 00
> >   78 | 0000
> >   80 | 00000
> >   82 | 0
> > The first stem is as I want it to be and expect it to be. When I add
> > one more observation R seems to add an extra decimal zero to my
> > observations and all leaves are now zero. Why does this happen?
> >
> > Regards
> > Leif
> >
> > [[alternative HTML version deleted]]
> >

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dcarlson at tamu.edu  Fri Feb 16 16:33:54 2018
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 16 Feb 2018 15:33:54 +0000
Subject: [R] stem - strange leaves
In-Reply-To: <3c92016d08be4081b3a8b84f8cd9a785@SRVEXCHCM1301.precheza.cz>
References: <d8a50128e909451fafd3a8cae35a6d4c@kau.se>
 <3c92016d08be4081b3a8b84f8cd9a785@SRVEXCHCM1301.precheza.cz>
Message-ID: <b0034bfc99bf4c33b5335908123125a4@exch-2p-mbx-w4.ads.tamu.edu>

In addition to stem() in the graphics package, there are other implementations of stem-and-leaf plots that add additional features such as stem.leaf() in package aplpack which will includes a function to produce back to back stem and leaf plots.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Friday, February 16, 2018 6:52 AM
To: Leif Ruckman <leif.ruckman at kau.se>; r-help at r-project.org
Subject: Re: [R] stem - strange leaves

Hi

I do not know why does it happen but you can control the behaviour by setting scale to 0.5.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Leif 
> Ruckman
> Sent: Friday, February 16, 2018 9:18 AM
> To: r-help at r-project.org
> Subject: [R] stem - strange leaves
>
> > x
> [1] 8.0 7.9 7.5 7.0 8.0 7.3 8.0 7.2 7.4 7.3 7.8 8.0 7.7 8.3 7.8 7.8 
> 7.1 7.7 6.9 7.5
> 7.5 7.3 7.2 7.5 7.2
> > stem(x)
>
>   The decimal point is at the |
>
>   6 | 9
>   7 | 012223334
>   7 | 5555778889
>   8 | 00003
>
> > y <- c(x, 8)
> > stem(y)
>
>   The decimal point is 1 digit(s) to the left of the |
>
>   68 | 0
>   70 | 00
>   72 | 000000
>   74 | 00000
>   76 | 00
>   78 | 0000
>   80 | 00000
>   82 | 0
> The first stem is as I want it to be and expect it to be. When I add 
> one more observation R seems to add an extra decimal zero to my 
> observations and all leaves are now zero. Why does this happen?
>
> Regards
> Leif
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From S.Ellison at LGCGroup.com  Fri Feb 16 16:55:16 2018
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 16 Feb 2018 15:55:16 +0000
Subject: [R] stem - strange leaves
In-Reply-To: <3c92016d08be4081b3a8b84f8cd9a785@SRVEXCHCM1301.precheza.cz>
References: <d8a50128e909451fafd3a8cae35a6d4c@kau.se>
 <3c92016d08be4081b3a8b84f8cd9a785@SRVEXCHCM1301.precheza.cz>
Message-ID: <1A8C1289955EF649A09086A153E267240C3FD91469@GBTEDVPEXCMB04.corp.lgc-group.com>

> > From: Leif Ruckman [mailto:leif.ruckman at kau.se]
> > Sent: Friday, February 16, 2018 3:27 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Subject: RE: stem - strange leaves
> >
> > Thank you, I also found that solution but I think it is strange that
> > this happens at all. I have tried different data and sometimes this
> > happens and sometimes it doesn't so I would like to understand why.

C code is at 
https://github.com/wch/r-source/blob/trunk/src/library/graphics/src/stem.c

stem() sets the bin width for a 'pretty' number of categories, taking some account of the number of data points. There are (inevitably) some  somewhat arbitrary choices in there about what looks right. But the important thing is that changing the number of items can trigger a threshold change in bin width. One of those triggers relies in part on >= tests applied to a value calculated (in part) from 150/(n + 50). That would be (within available precision) exactly 2 for n=25; slightly smaller for n=26.
In your case, your extra data point takes you from n=25 to n=26 values - in turn triggering a change in bin width for your particular data range. That in turn triggers a decimal place shift to leave two significant digits left of the '|' marker. 

Since all your data are rounded to the first decimal place, with an implied trailing zero, you only have zeroes after the first two significant digits. So - with due deference to 'California dreaming' - all the leaves are zero. 

Steve Ellison





*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From mak.hholly at gmail.com  Fri Feb 16 18:28:27 2018
From: mak.hholly at gmail.com (greg holly)
Date: Fri, 16 Feb 2018 20:28:27 +0300
Subject: [R] 
 Putting 733 discrete categories on Y-axis in qqplot2 as they are
In-Reply-To: <1aa1bd784ab7433d86f3bfeecf6620d7@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>
 <deb8bcbfbdff47a0947a394d8116df48@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4jBCoEQoXeRpOOBSz-myYhj4VBz74CYsu_ZnLbOwGDmbw@mail.gmail.com>
 <1aa1bd784ab7433d86f3bfeecf6620d7@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAM9Qe4iu6t6wEUUEf925pt2tkvm7ccAy64KMHFA+i9OYS_6YUQ@mail.gmail.com>

Hi Petr;

I would like to get a plot with names as they are in the original file.
They are chemical names and I have 733 in the my file. For example, let me
give to chemical names "*2-hydroxybutyrate/2-hydroxyisobutyrate*" and
"*palmitoyl-arachidonoyl-glycerol
(16:0/20:4) [1]**" .So, what should I put  [c(2,3,1)] part in the command:
iris$MySpecies<-factor(iris$Species, levels(iris$Species)[c(2,3,1)])

Regards,

Greg

On Fri, Feb 16, 2018 at 6:13 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> What do you mean ?without reordering the names?. Factor variable is
> ordered according to its levels and you can freely change the ordering.
> This is why factors are useful and worth to use in many cases instead of
> character vectors.
>
>
>
> See this result
>
>
>
> > iris$MySpecies<-factor(iris$Species, levels(iris$Species)[c(2,3,1)])
>
> > p<-ggplot(iris, aes(x=Sepal.Length, y=Species))
>
> > p+geom_point()
>
> > p<-ggplot(iris, aes(x=Sepal.Length, y=MySpecies))
>
> > p+geom_point()
>
> >
>
> Cheers
>
> Petr
>
>
>
> *From:* greg holly [mailto:mak.hholly at gmail.com]
> *Sent:* Friday, February 16, 2018 3:56 PM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* r-help mailing list <r-help at r-project.org>
> *Subject:* Re: [R] Putting 733 discrete categories on Y-axis in qqplot2
> as they are
>
>
>
> Hi Petr;
>
>
>
> Thanks. I do save the result in pdf by using the following command.
>
>
>
>    ggsave("z7.pdf", p4, height = 95, width = 8, device=pdf, limitsize =
> F,dpi=300)
>
>
>
>  I can achieve the y axis with 733 levels. But I need get the plot
> WITHOUT reordering the names.
>
>
>
> Regards,
>
>
>
> Greg
>
>
>
> On Fri, Feb 16, 2018 at 3:39 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Hi
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
> holly
> > Sent: Thursday, February 15, 2018 3:58 PM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] Putting 733 discrete categories on Y-axis in qqplot2 as
> they are
> >
> > Hi all;
> >
> > I have 733 discrete categories that will go on y-axis in ggplot2. I used
> the
> > following command to put the name of x-axis.
> >
> > scale_x_discrete (limits = c("SI", "HOMAIR",
> > "AIR","HOMAB","SG","DI","FI","FG"))
> >
> > Since there are only 8 categories on x it was easy to do. Is there any
> way to do
> > the same for 733 discrete categories for y-axis. Essentially I did not
> want to
> > order categories. I would like to put the name of categories as they are.
>
> You probably can achieve the y axis with 733 levels if you do not use
> limits in scale.
>
> Just from curiosity, standard page has 30 lines, so your axis should
> stretch to more than 20 pages. Or you need to shrink your y axis 20 times.
> Both options will give you unreadable results.
>
> Cheers
> Petr
>
> >
> > Best regards,
> >
> > Greg
> >
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From arrayprofile at yahoo.com  Fri Feb 16 19:18:50 2018
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 16 Feb 2018 18:18:50 +0000 (UTC)
Subject: [R] weighed Fleming-Harrington log rank test
In-Reply-To: <fd55f7$8tblvd@ironport10.mayo.edu>
References: <fd55f7$8tblvd@ironport10.mayo.edu>
Message-ID: <628720152.2373652.1518805130505@mail.yahoo.com>

 Thank you Terry. Right now I can use comp() from survMisc package to do the 2-parameter version of F-H weighting. I think both SAS and stata offer the 2-parameter version, so just?thought it would be nice if survdiff() can have that option given it's standard package in R.?
Thanks!
John
    On Friday, February 16, 2018, 7:08:46 AM PST, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:  
 
  
You are correct that the survreg routine only supports 'rho' of the Fleming-Harrington G-rho tests.? This is a function of age -- I wrote the original code back when I was working with Tom (Fleming), and he was only using 1 parameter. ?Later he and David expanded the test to two parameters.? This might be only the second request for the feature in the 30+ years since that date.?
 
 ?
 
Terry Therneau
   
	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Feb 16 19:34:45 2018
From: chocold12 at gmail.com (lily li)
Date: Fri, 16 Feb 2018 11:34:45 -0700
Subject: [R] error in loading rgdal package
In-Reply-To: <87fu61mnss.fsf@hornfels.zedat.fu-berlin.de>
References: <CAN5afy8bAdrvhhsYjTxDufWzM1zMqNu8oTMNrJGJcc=MUCsABg@mail.gmail.com>
 <87fu61mnss.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <CAN5afy_3hTsGMpk-X4E6B+7LVt4yn-9EeQgJazFmuvMCiumeYA@mail.gmail.com>

Hi Loris,
Thanks. I tried to update the R software and reinstalled the GDAL library.
It works now.


On Thu, Feb 15, 2018 at 11:49 PM, Loris Bennett <loris.bennett at fu-berlin.de>
wrote:

> Hi Lily,
>
> lily li <chocold12 at gmail.com> writes:
>
> > Hi R users,
> >
> > Could you help me to see this problem? I could now load "rgdal" even
> though
> > I downloaded the compressed folder. Thanks for your help.
> >
> > Loading required package: sp
> > Error in dyn.load(file, DLLpath = DLLpath, ...) :
> >   unable to load shared object
> > '/Library/Frameworks/R.framework/Versions/3.3/
> Resources/library/rgdal/libs/rgdal.so':
>
> Have you installed the GDAL library itself?  The R package rgdal needs
> this.  See the "SystemRequirements" section on the CPAN page:
>
>   https://CRAN.R-project.org/package=rgdal
>
> Cheers,
>
> Loris
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jhwilson.nb at gmail.com  Fri Feb 16 19:54:55 2018
From: jhwilson.nb at gmail.com (John Wilson)
Date: Fri, 16 Feb 2018 14:54:55 -0400
Subject: [R] hurdle model - count and response predictions
Message-ID: <CABdA5Q1K2uCxWEq2sz-R_HDF4ShOkQzWy6e4n_toc+YO2U6y7g@mail.gmail.com>

Hello,

I'm using pscl to run a hurdle model. Everything works great until I get to
the point of making predictions. All of my "count" predictions are lower
than my actual data, and lower than the "response" predictions, similar to
the issue described here (
https://stat.ethz.ch/pipermail/r-help/2012-August/320426.html) and here (
https://stackoverflow.com/questions/48794622/hurdle-model-prediction-count-vs-response
).

Since the issue is the same (and not resolved), I'll just use the example
from the second link:

library("pscl")
data("RecreationDemand", package = "AER")

## model
m <- hurdle(trips ~ quality | ski, data = RecreationDemand, dist = "negbin")
nd <- data.frame(quality = 0:5, ski = "no")
predict(m, newdata = nd, type = "count")
predict(m, newdata = nd, type = "response")

The presence/absence part of the model gives identical estimates to a
logistic model run on the data. However, I thought that the negbin part of
the hurdle should give identical estimates to a separate, glm.nb model of
the positive data. But I get completely different values...

library(MASS)
m.nb <- glm.nb(trips ~ quality, data =
RecreationDemand[RecreationDemand$trips > 0,])
predict(m, newdata = nd, type = "count") ## hurdle
predict(m.nb, newdata = nd, type = "response") ## positive counts only

Any help would be appreciated.

	[[alternative HTML version deleted]]


From orzack at freshpond.org  Fri Feb 16 22:14:51 2018
From: orzack at freshpond.org (Steven Orzack)
Date: Fri, 16 Feb 2018 16:14:51 -0500
Subject: [R] analysis of covariance and constrained parameters
Message-ID: <0be3decd-2c23-9212-6075-a458617dab2d@freshpond.org>

Consider an analysis of covariance involving age and cohort. The goal is 
to assess whether the influence of cohort

depends upon the age. The simplest case involves data as follows

value Age Cohort

x1 ????? 1?????? 3

x2?????? 1?????? 4

x3?????? 1?????? 5

x4 ????? 2 ????? 3

x5 ????? 2 ????? 4

x6 ????? 2 ????? 5

etc.

Age is a factor. The numeric response variable is value and Cohort is a 
numeric predictor. So, (pseudo-code) commands to

estimate the age=specific relationship between value and Cohort could be


glm(value ~ Age/Cohort -? 1, family =......, data = .....)

glm(value ~ Age/(Cohort + I(Cohort^2)) - 1, family =......, data = .....).


The latter commands would provide estimates of the age-specific 
intercept, linear, and quadratic coefficients, as in


value_Age1 <- intercept_Age1 + linear_Age1*Cohort + quad_Age1*Cohort^2

value_Age2 <- intercept_Age2 + linear_Age2*Cohort + quad_Age2*Cohort^2


This is standard. One would choose among the above models via analysis 
of variance or AIC.


Now assume that I have external knowledge that tells me that there is NO 
influence of Cohort on value for Age1 and that

there could be up to a quadratic influence for Age2. Accordingly, I 
would like to

fit a model which estimates these relationships:


value_Age1 <- intercept_Age1 (+ 0*Cohort + 0*Cohort^2) 
 ??????????????????????????? (which is, of course, value_Age1 <- 
intercept_Age1)

value_Age2 <- intercept_Age2 + linear_Age2*Cohort + quad_Age2*Cohort^2


What is the glm syntax to fit this model? It is a model in which we have 
constraints that (two) coefficients for one level of the factor must 
have a particular value (0) and

there is no such constraint for the second level of the factor.

Please note that I understand that


glm(value ~ Age/(Cohort + I(Cohort^2)) - 1, family =......, data = .....).


generates point estimates of the linear and quadratic coefficients for 
Age1 (as above) and one could inspect them to determine whether they are 
statistically equivalent to 0.

However, I want to incorporate the knowledge that these coefficients 
MUST BE 0 into my hypothesis testing. Knowing that these coefficients 
are 0 could influence the results of

anova and AIC comparisons since it reduces the number of degrees of 
freedom associated with model.

Many thanks for suggestions in advance!


-- 
Steven Orzack
Fresh Pond Research Institute
173 Harvey Street
Cambridge, MA 02140
617 864-4307

www.freshpond.org


From Achim.Zeileis at uibk.ac.at  Sat Feb 17 00:46:15 2018
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 17 Feb 2018 00:46:15 +0100 (CET)
Subject: [R] hurdle model - count and response predictions
In-Reply-To: <CABdA5Q1K2uCxWEq2sz-R_HDF4ShOkQzWy6e4n_toc+YO2U6y7g@mail.gmail.com>
References: <CABdA5Q1K2uCxWEq2sz-R_HDF4ShOkQzWy6e4n_toc+YO2U6y7g@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1802170044370.14032@paninaro>

I answered the question on SO. In short the differences come from 
truncated vs. untruncated models and conditional vs. unconditional 
expectations. Feel free to follow-up on SO or here on the list...

On Fri, 16 Feb 2018, John Wilson wrote:

> Hello,
>
> I'm using pscl to run a hurdle model. Everything works great until I get to
> the point of making predictions. All of my "count" predictions are lower
> than my actual data, and lower than the "response" predictions, similar to
> the issue described here (
> https://stat.ethz.ch/pipermail/r-help/2012-August/320426.html) and here (
> https://stackoverflow.com/questions/48794622/hurdle-model-prediction-count-vs-response
> ).
>
> Since the issue is the same (and not resolved), I'll just use the example
> from the second link:
>
> library("pscl")
> data("RecreationDemand", package = "AER")
>
> ## model
> m <- hurdle(trips ~ quality | ski, data = RecreationDemand, dist = "negbin")
> nd <- data.frame(quality = 0:5, ski = "no")
> predict(m, newdata = nd, type = "count")
> predict(m, newdata = nd, type = "response")
>
> The presence/absence part of the model gives identical estimates to a
> logistic model run on the data. However, I thought that the negbin part of
> the hurdle should give identical estimates to a separate, glm.nb model of
> the positive data. But I get completely different values...
>
> library(MASS)
> m.nb <- glm.nb(trips ~ quality, data =
> RecreationDemand[RecreationDemand$trips > 0,])
> predict(m, newdata = nd, type = "count") ## hurdle
> predict(m.nb, newdata = nd, type = "response") ## positive counts only
>
> Any help would be appreciated.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From peter.meilstrup at gmail.com  Sat Feb 17 08:53:13 2018
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Fri, 16 Feb 2018 23:53:13 -0800
Subject: [R] Problem installing libxml2 under Homebrew
Message-ID: <CAJoaRharR7vMdnzY8Baij-a=q7EMP4iFKmWtqHR+c43xjcwWFg@mail.gmail.com>

i am trying to install xml2 from CRAN, and it is throwing an error
that it cannot find the libxml2 library configuration.

The thing is that pkg-config seems to be set up correctly:

$ echo $PKG_CONFIG_PATH
:/usr/local/opt/libxml2/lib/pkgconfig:/usr/local/opt/libxml2/lib/pkgconfig

$ pkg-config --cflags --libs libxml-2.0
-I/usr/local/Cellar/libxml2/2.9.7/include/libxml2
-L/usr/local/Cellar/libxml2/2.9.7/lib -lx

Output of install.packages:

> install.packages("xml2")
--- Please select a CRAN mirror for use in this session ---
trying URL 'https://cloud.r-project.org/src/contrib/xml2_1.2.0.tar.gz'
Content type 'application/x-gzip' length 251614 bytes (245 KB)
==================================================
downloaded 245 KB

* installing *source* package ?xml2? ...
** package ?xml2? successfully unpacked and MD5 sums checked
Found pkg-config cflags and libs!
Using PKG_CFLAGS=-I/usr/include/libxml2
Using PKG_LIBS=-L/usr/lib -lxml2 -lz -lpthread -licucore -lm
------------------------- ANTICONF ERROR ---------------------------
Configuration failed because libxml-2.0 was not found. Try installing:
 * deb: libxml2-dev (Debian, Ubuntu, etc)
 * rpm: libxml2-devel (Fedora, CentOS, RHEL)
 * csw: libxml2_dev (Solaris)
If libxml-2.0 is already installed, check that 'pkg-config' is in your
PATH and PKG_CONFIG_PATH contains a libxml-2.0.pc file. If pkg-config
is unavailable you can set INCLUDE_DIR and LIB_DIR manually via:
R CMD INSTALL --configure-vars='INCLUDE_DIR=... LIB_DIR=...'
--------------------------------------------------------------------
ERROR: configuration failed for package ?xml2?

Homebrew package info:

dekkera:pkgconfig peter$ brew info libxml2 R
libxml2: stable 2.9.7 (bottled), HEAD [keg-only]
GNOME XML library
http://xmlsoft.org
/usr/local/Cellar/libxml2/2.9.7 (281 files, 10.4MB)
  Poured from bottle on 2018-02-16 at 22:42:54
From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/libxml2.rb
==> Options
--HEAD
    Install HEAD version
==> Caveats
This formula is keg-only, which means it was not symlinked into /usr/local,
because macOS already provides this software and installing another version in
parallel can cause all kinds of trouble.

If you need to have this software first in your PATH run:
  echo 'export PATH="/usr/local/opt/libxml2/bin:$PATH"' >> ~/.bash_profile

For compilers to find this software you may need to set:
    LDFLAGS:  -L/usr/local/opt/libxml2/lib
    CPPFLAGS: -I/usr/local/opt/libxml2/include
For pkg-config to find this software you may need to set:
    PKG_CONFIG_PATH: /usr/local/opt/libxml2/lib/pkgconfig

If you need Python to find bindings for this keg-only formula, run:
  echo /usr/local/opt/libxml2/lib/python2.7/site-packages >>
/usr/local/lib/python2.7/site-packages/libxml2.pth
  mkdir -p /Users/peter/Library/Python/2.7/lib/python/site-packages
  echo 'import site;
site.addsitedir("/usr/local/lib/python2.7/site-packages")' >>
/Users/peter/Library/Python/2.7/lib/python/site-packages/homebrew.pth

R: stable 3.4.3 (bottled)
Software environment for statistical computing
https://www.r-project.org/
/usr/local/Cellar/R/3.4.0_1 (2,246 files, 59.1MB)
  Poured from bottle on 2017-05-20 at 17:10:29
/usr/local/Cellar/R/3.4.1_2 (2,114 files, 55.3MB)
  Poured from bottle on 2017-09-19 at 03:23:33
/usr/local/Cellar/R/3.4.2 (2,111 files, 55.1MB)
  Poured from bottle on 2017-11-13 at 22:23:36
/usr/local/Cellar/R/3.4.3 (2,110 files, 55.1MB)
  Poured from bottle on 2017-12-02 at 23:20:16
/usr/local/Cellar/R/3.4.3_1 (3,773 files, 115.4MB)
  Built from source on 2018-02-08 at 22:01:49 with: --with-x11
--with-cairo --with-java
From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/r.rb
==> Dependencies
Build: pkg-config ?
Required: gcc ?, gettext ?, jpeg ?, libpng ?, pcre ?, readline ?, xz ?
Optional: openblas ?
==> Requirements
Optional: java ?
==> Options
--with-java
    Build with java support
--with-openblas
    Build with openblas support


From h.wickham at gmail.com  Sat Feb 17 23:56:03 2018
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 17 Feb 2018 16:56:03 -0600
Subject: [R] Problem installing libxml2 under Homebrew
In-Reply-To: <CAJoaRharR7vMdnzY8Baij-a=q7EMP4iFKmWtqHR+c43xjcwWFg@mail.gmail.com>
References: <CAJoaRharR7vMdnzY8Baij-a=q7EMP4iFKmWtqHR+c43xjcwWFg@mail.gmail.com>
Message-ID: <CABdHhvEF_pm31NwchcwSa3ZUzya02Mkv_Fb9WiDDJmBhFQ7MNA@mail.gmail.com>

Is there a reason that you can't use the binary provided by CRAN?
That's the easiest way to get xml2.
Hadley

On Sat, Feb 17, 2018 at 1:53 AM, Peter Meilstrup
<peter.meilstrup at gmail.com> wrote:
> i am trying to install xml2 from CRAN, and it is throwing an error
> that it cannot find the libxml2 library configuration.
>
> The thing is that pkg-config seems to be set up correctly:
>
> $ echo $PKG_CONFIG_PATH
> :/usr/local/opt/libxml2/lib/pkgconfig:/usr/local/opt/libxml2/lib/pkgconfig
>
> $ pkg-config --cflags --libs libxml-2.0
> -I/usr/local/Cellar/libxml2/2.9.7/include/libxml2
> -L/usr/local/Cellar/libxml2/2.9.7/lib -lx
>
> Output of install.packages:
>
>> install.packages("xml2")
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'https://cloud.r-project.org/src/contrib/xml2_1.2.0.tar.gz'
> Content type 'application/x-gzip' length 251614 bytes (245 KB)
> ==================================================
> downloaded 245 KB
>
> * installing *source* package ?xml2? ...
> ** package ?xml2? successfully unpacked and MD5 sums checked
> Found pkg-config cflags and libs!
> Using PKG_CFLAGS=-I/usr/include/libxml2
> Using PKG_LIBS=-L/usr/lib -lxml2 -lz -lpthread -licucore -lm
> ------------------------- ANTICONF ERROR ---------------------------
> Configuration failed because libxml-2.0 was not found. Try installing:
>  * deb: libxml2-dev (Debian, Ubuntu, etc)
>  * rpm: libxml2-devel (Fedora, CentOS, RHEL)
>  * csw: libxml2_dev (Solaris)
> If libxml-2.0 is already installed, check that 'pkg-config' is in your
> PATH and PKG_CONFIG_PATH contains a libxml-2.0.pc file. If pkg-config
> is unavailable you can set INCLUDE_DIR and LIB_DIR manually via:
> R CMD INSTALL --configure-vars='INCLUDE_DIR=... LIB_DIR=...'
> --------------------------------------------------------------------
> ERROR: configuration failed for package ?xml2?
>
> Homebrew package info:
>
> dekkera:pkgconfig peter$ brew info libxml2 R
> libxml2: stable 2.9.7 (bottled), HEAD [keg-only]
> GNOME XML library
> http://xmlsoft.org
> /usr/local/Cellar/libxml2/2.9.7 (281 files, 10.4MB)
>   Poured from bottle on 2018-02-16 at 22:42:54
> From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/libxml2.rb
> ==> Options
> --HEAD
>     Install HEAD version
> ==> Caveats
> This formula is keg-only, which means it was not symlinked into /usr/local,
> because macOS already provides this software and installing another version in
> parallel can cause all kinds of trouble.
>
> If you need to have this software first in your PATH run:
>   echo 'export PATH="/usr/local/opt/libxml2/bin:$PATH"' >> ~/.bash_profile
>
> For compilers to find this software you may need to set:
>     LDFLAGS:  -L/usr/local/opt/libxml2/lib
>     CPPFLAGS: -I/usr/local/opt/libxml2/include
> For pkg-config to find this software you may need to set:
>     PKG_CONFIG_PATH: /usr/local/opt/libxml2/lib/pkgconfig
>
> If you need Python to find bindings for this keg-only formula, run:
>   echo /usr/local/opt/libxml2/lib/python2.7/site-packages >>
> /usr/local/lib/python2.7/site-packages/libxml2.pth
>   mkdir -p /Users/peter/Library/Python/2.7/lib/python/site-packages
>   echo 'import site;
> site.addsitedir("/usr/local/lib/python2.7/site-packages")' >>
> /Users/peter/Library/Python/2.7/lib/python/site-packages/homebrew.pth
>
> R: stable 3.4.3 (bottled)
> Software environment for statistical computing
> https://www.r-project.org/
> /usr/local/Cellar/R/3.4.0_1 (2,246 files, 59.1MB)
>   Poured from bottle on 2017-05-20 at 17:10:29
> /usr/local/Cellar/R/3.4.1_2 (2,114 files, 55.3MB)
>   Poured from bottle on 2017-09-19 at 03:23:33
> /usr/local/Cellar/R/3.4.2 (2,111 files, 55.1MB)
>   Poured from bottle on 2017-11-13 at 22:23:36
> /usr/local/Cellar/R/3.4.3 (2,110 files, 55.1MB)
>   Poured from bottle on 2017-12-02 at 23:20:16
> /usr/local/Cellar/R/3.4.3_1 (3,773 files, 115.4MB)
>   Built from source on 2018-02-08 at 22:01:49 with: --with-x11
> --with-cairo --with-java
> From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/r.rb
> ==> Dependencies
> Build: pkg-config ?
> Required: gcc ?, gettext ?, jpeg ?, libpng ?, pcre ?, readline ?, xz ?
> Optional: openblas ?
> ==> Requirements
> Optional: java ?
> ==> Options
> --with-java
>     Build with java support
> --with-openblas
>     Build with openblas support
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From spencer.graves at effectivedefense.org  Sun Feb 18 03:46:59 2018
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sat, 17 Feb 2018 20:46:59 -0600
Subject: [R] Draft proposal for Searching R Packages
In-Reply-To: <CA+mbi1ctsGUMFVaWC9jqwdwRf6bSZrpGHn8=gEB2HPjMjSkKsw@mail.gmail.com>
References: <9a34c09a-a531-38ba-5e77-d6e3d848064a@prodsyse.com>
 <9617D71649BB1F4FB51D5CA6B6C1FECB704B8B90@CHH-EX2K10-1>
 <20180201190912.GB20849@upenn.edu> <20180201191735.GC20849@upenn.edu>
 <e8dae538-bfdd-c671-2bfc-3296bb785ab9@prodsyse.com>
 <20180201203227.GA22934@upenn.edu>
 <2d7b3b8a-ea9d-df77-b3ff-80e119a3bc92@prodsyse.com>
 <CA+mbi1ctsGUMFVaWC9jqwdwRf6bSZrpGHn8=gEB2HPjMjSkKsw@mail.gmail.com>
Message-ID: <bf3d0337-a6f1-f756-bd2e-734a9514f238@effectivedefense.org>

Hello, All:


 ????? I just posted a "Draft Proposal for improving the ability of R 
users to search R packages" to Wikiversity 
(https://en.wikiversity.org/wiki/Draft_Proposal_for_improving_the_ability_of_R_users_to_search_R_packages). 



 ????? You are all invited to rewrite it in any way you think is more 
likely to produce the most useful result.? Wikimedia invites 
contributors to "be bold but not reckless", writing from a neutral point 
of view citing credible sources.? I do NOT want to do this project:? I 
think the world will be better if it is done, and I think others are 
better equipped to actually do it -- or manage others doing it -- than I 
am.


 ????? If you read this, you will see that it contains critical gaps.? I 
hope one or more of you will fill these critical gaps or help find 
others who will.


 ????? As indicated there, the next major deadline is April 1.? This 
sounds like lots of time, except that the key thing that is missing in 
this draft proposal is principal investigator(s).? Without PI(s), it 
won't fly.


 ????? Thanks,
 ????? Spencer Graves, PhD
 ????? Founder
 ????? EffectivedDefense.org
 ????? 7300 W. 107th St. # 506
 ????? Overland Park, KS 66212
ph:? 408-655-4567


From chiara.malavasi at live.it  Sun Feb 18 19:23:29 2018
From: chiara.malavasi at live.it (Chiara Malavasi)
Date: Sun, 18 Feb 2018 18:23:29 +0000
Subject: [R] Instrument in rddtools
Message-ID: <HE1PR07MB0779B0410B47D74D9A2178AFEDC90@HE1PR07MB0779.eurprd07.prod.outlook.com>

Hello!
I have encountered some problems in implementing the function "rdd_reg_lm" (for the fuzzy case) in the rddtools R package. By looking at the function, I understood that an IV regression is actually implemented automatically by the function but I did not understand where to specify the instrument to be used to clear my treatment variable from endogeneity. The command I used to perform the regression is the following:

rdd_reg_lm(rdd_object=rdd_gr, covar.opt = list(strategy = "include"),  order = 4)

where rdd_gr is defined as:

rdd_gr <- rdd_data(x= GDPpc_rel, y= GR.rate, data=data.complete1, covar=Z0, cutpoint = 0.75, z= Treat)

Any help would be very appreciated!


	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Mon Feb 19 03:06:16 2018
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Sun, 18 Feb 2018 18:06:16 -0800
Subject: [R] Include pre-existing PDF files as vignettes in an R package?
Message-ID: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>

Greetings.  The group that I work with has just started using the approach
outlined in Karl Broman's handy primer:

    http://kbroman.org/pkg_primer/pages/vignettes.html

to create vignettes for a couple of R packages.

This works fine as long as we have a current Rmd version of the vignette.  But
we have some old PDF documents that we'd like to include as vignettes as well.
I'd like to know if there's a way to include such PDF files as vignettes.

We *do* have the source files for the PDF files in question, but it would be
tedious to convert those source files to Rmd format.

My first thought was simply to add the PDF files to the .../vignettes
subdirectory and run the devtools::build_vignettes() function (mentioned in
the Broman tutorial), but that doesn't work.  I.e., the PDF files don't appear
in the list of vignettes for the package.

And after running devtools::build_vignettes I see that there's a lot of
additional stuff in:

    ...lib/R/site-library/<package_name>/...

so I don't see any obvious way to "fool" R into using the PDF files that
haven't gone through the whole knitr/rmarkdown process.  (Not to mention that
such an approach would be fragile at best.)

Suggestions welcome.  Thanks.

-- Mike


From istazahn at gmail.com  Mon Feb 19 03:15:44 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 18 Feb 2018 21:15:44 -0500
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
Message-ID: <CA+vqiLGQh7WdwWaancTPNknfkR11Zafo4PB3HQtRwPaeH=KWkw@mail.gmail.com>

Hi Mike,

Did you read the relevant section of the official "Writing R
Extensions" manual? If so, what about the instructions provided there
do you find lacking?

Best,
Ista

On Sun, Feb 18, 2018 at 9:06 PM, Michael Hannon
<jmhannon.ucdavis at gmail.com> wrote:
> Greetings.  The group that I work with has just started using the approach
> outlined in Karl Broman's handy primer:
>
>     http://kbroman.org/pkg_primer/pages/vignettes.html
>
> to create vignettes for a couple of R packages.
>
> This works fine as long as we have a current Rmd version of the vignette.  But
> we have some old PDF documents that we'd like to include as vignettes as well.
> I'd like to know if there's a way to include such PDF files as vignettes.
>
> We *do* have the source files for the PDF files in question, but it would be
> tedious to convert those source files to Rmd format.
>
> My first thought was simply to add the PDF files to the .../vignettes
> subdirectory and run the devtools::build_vignettes() function (mentioned in
> the Broman tutorial), but that doesn't work.  I.e., the PDF files don't appear
> in the list of vignettes for the package.
>
> And after running devtools::build_vignettes I see that there's a lot of
> additional stuff in:
>
>     ...lib/R/site-library/<package_name>/...
>
> so I don't see any obvious way to "fool" R into using the PDF files that
> haven't gone through the whole knitr/rmarkdown process.  (Not to mention that
> such an approach would be fragile at best.)
>
> Suggestions welcome.  Thanks.
>
> -- Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Feb 19 10:20:50 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Feb 2018 04:20:50 -0500
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
Message-ID: <146e8ef8-c45c-26ab-04d1-a03b5ee24220@gmail.com>

On 18/02/2018 9:06 PM, Michael Hannon wrote:
> Greetings.  The group that I work with has just started using the approach
> outlined in Karl Broman's handy primer:
> 
>      http://kbroman.org/pkg_primer/pages/vignettes.html
> 
> to create vignettes for a couple of R packages.
> 
> This works fine as long as we have a current Rmd version of the vignette.  But
> we have some old PDF documents that we'd like to include as vignettes as well.
> I'd like to know if there's a way to include such PDF files as vignettes.
> 
> We *do* have the source files for the PDF files in question, but it would be
> tedious to convert those source files to Rmd format.
> 
> My first thought was simply to add the PDF files to the .../vignettes
> subdirectory and run the devtools::build_vignettes() function (mentioned in
> the Broman tutorial), but that doesn't work.  I.e., the PDF files don't appear
> in the list of vignettes for the package.
> 
> And after running devtools::build_vignettes I see that there's a lot of
> additional stuff in:
> 
>      ...lib/R/site-library/<package_name>/...
> 
> so I don't see any obvious way to "fool" R into using the PDF files that
> haven't gone through the whole knitr/rmarkdown process.  (Not to mention that
> such an approach would be fragile at best.)

You don't say what format the source is, but if it is LaTeX, you just 
need to add some comments at the beginning, rename ending in .Rnw, and R 
will recognize plain LaTeX files as Sweave vignettes.

See the Writing R Extensions manual, section 1.4.

Duncan Murdoch

> 
> Suggestions welcome.  Thanks.
> 
> -- Mike
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jmhannon.ucdavis at gmail.com  Mon Feb 19 11:44:25 2018
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 19 Feb 2018 02:44:25 -0800
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <CA+vqiLGQh7WdwWaancTPNknfkR11Zafo4PB3HQtRwPaeH=KWkw@mail.gmail.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
 <CA+vqiLGQh7WdwWaancTPNknfkR11Zafo4PB3HQtRwPaeH=KWkw@mail.gmail.com>
Message-ID: <CACdH2ZYcAKemAKa9aW86oHNrFR3-PbLwAs7Y0+P2v_9g6BpF1g@mail.gmail.com>

Heh.  Thanks, Ista, for your diplomatically-phrased suggestion :-)  In
fact, I *did* read the "vignettes" section of the Extensions manual,
but evidently not closely enough.

Upon further review, I see that one can use
".../vignettes/.install_extras" to list additional files that should
be copied to ".../inst/doc/".  I tried that, and it seems to work, but
the files from .install_extras are not listed as vignettes.

Hence, this seems like a convenient way to distribute the additional
files.  I.e., we would be asking people to use
"devtools::install_github" to get the packages, but I still don't see
how to make the additional files readily available to the end user.

-- Mike

On Sun, Feb 18, 2018 at 6:15 PM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi Mike,
>
> Did you read the relevant section of the official "Writing R
> Extensions" manual? If so, what about the instructions provided there
> do you find lacking?
>
> Best,
> Ista
>
> On Sun, Feb 18, 2018 at 9:06 PM, Michael Hannon
> <jmhannon.ucdavis at gmail.com> wrote:
>> Greetings.  The group that I work with has just started using the approach
>> outlined in Karl Broman's handy primer:
>>
>>     http://kbroman.org/pkg_primer/pages/vignettes.html
>>
>> to create vignettes for a couple of R packages.
>>
>> This works fine as long as we have a current Rmd version of the vignette.  But
>> we have some old PDF documents that we'd like to include as vignettes as well.
>> I'd like to know if there's a way to include such PDF files as vignettes.
>>
>> We *do* have the source files for the PDF files in question, but it would be
>> tedious to convert those source files to Rmd format.
>>
>> My first thought was simply to add the PDF files to the .../vignettes
>> subdirectory and run the devtools::build_vignettes() function (mentioned in
>> the Broman tutorial), but that doesn't work.  I.e., the PDF files don't appear
>> in the list of vignettes for the package.
>>
>> And after running devtools::build_vignettes I see that there's a lot of
>> additional stuff in:
>>
>>     ...lib/R/site-library/<package_name>/...
>>
>> so I don't see any obvious way to "fool" R into using the PDF files that
>> haven't gone through the whole knitr/rmarkdown process.  (Not to mention that
>> such an approach would be fragile at best.)
>>
>> Suggestions welcome.  Thanks.
>>
>> -- Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Mon Feb 19 11:47:52 2018
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 19 Feb 2018 02:47:52 -0800
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <146e8ef8-c45c-26ab-04d1-a03b5ee24220@gmail.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
 <146e8ef8-c45c-26ab-04d1-a03b5ee24220@gmail.com>
Message-ID: <CACdH2ZYSPOxZy_wW2DTei=+Da0T5Rbbat8KdOM9M6f_5rUUgFw@mail.gmail.com>

Thanks, Duncan.  The files in question are Emacs Org-mode files, and I
think these are more or less isomorphic to Rmd files, but I haven't
used Org-mode in a long time, so I think the mapping (Org-mode ==>
Rmd) would be painful.

-- Mike


On Mon, Feb 19, 2018 at 1:20 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 18/02/2018 9:06 PM, Michael Hannon wrote:
>>
>> Greetings.  The group that I work with has just started using the approach
>> outlined in Karl Broman's handy primer:
>>
>>      http://kbroman.org/pkg_primer/pages/vignettes.html
>>
>> to create vignettes for a couple of R packages.
>>
>> This works fine as long as we have a current Rmd version of the vignette.
>> But
>> we have some old PDF documents that we'd like to include as vignettes as
>> well.
>> I'd like to know if there's a way to include such PDF files as vignettes.
>>
>> We *do* have the source files for the PDF files in question, but it would
>> be
>> tedious to convert those source files to Rmd format.
>>
>> My first thought was simply to add the PDF files to the .../vignettes
>> subdirectory and run the devtools::build_vignettes() function (mentioned
>> in
>> the Broman tutorial), but that doesn't work.  I.e., the PDF files don't
>> appear
>> in the list of vignettes for the package.
>>
>> And after running devtools::build_vignettes I see that there's a lot of
>> additional stuff in:
>>
>>      ...lib/R/site-library/<package_name>/...
>>
>> so I don't see any obvious way to "fool" R into using the PDF files that
>> haven't gone through the whole knitr/rmarkdown process.  (Not to mention
>> that
>> such an approach would be fragile at best.)
>
>
> You don't say what format the source is, but if it is LaTeX, you just need
> to add some comments at the beginning, rename ending in .Rnw, and R will
> recognize plain LaTeX files as Sweave vignettes.
>
> See the Writing R Extensions manual, section 1.4.
>
> Duncan Murdoch
>
>>
>> Suggestions welcome.  Thanks.
>>
>> -- Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From berenger at bioreg.kyushu-u.ac.jp  Mon Feb 19 08:51:27 2018
From: berenger at bioreg.kyushu-u.ac.jp (Francois BERENGER)
Date: Mon, 19 Feb 2018 16:51:27 +0900
Subject: [R] questions regarding the svmpath package (functions svmpath and
 predict)
Message-ID: <34710a9f-0602-c98c-f874-7c05bf964a7c@bioreg.kyushu-u.ac.jp>

Hello,

I have two questions.

The svmpath package provides a svmpath function:
---
fit <- svmpath(xtrain, ytrain, kernel.function = radial.kernel, param.kernel = 0.8)
---
1) How to get the optimal lambda value out of this result?

The svmpath package also provides a predict function:
---
ytest <- predict(fit, xtest)
---

How to get a score (or a probability of belonging to one of the two classes)
instead of a label as the prediction output?

Thanks a lot,
Francois.


From murdoch.duncan at gmail.com  Mon Feb 19 12:25:45 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Feb 2018 06:25:45 -0500
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <CACdH2ZYSPOxZy_wW2DTei=+Da0T5Rbbat8KdOM9M6f_5rUUgFw@mail.gmail.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
 <146e8ef8-c45c-26ab-04d1-a03b5ee24220@gmail.com>
 <CACdH2ZYSPOxZy_wW2DTei=+Da0T5Rbbat8KdOM9M6f_5rUUgFw@mail.gmail.com>
Message-ID: <9d2d4ff5-a322-6853-ff26-f80146f0cce6@gmail.com>

On 19/02/2018 5:47 AM, Michael Hannon wrote:
> Thanks, Duncan.  The files in question are Emacs Org-mode files, and I
> think these are more or less isomorphic to Rmd files, but I haven't
> used Org-mode in a long time, so I think the mapping (Org-mode ==>
> Rmd) would be painful.

If they aren't LaTeX then they won't be able to masquerade as Sweave 
files, so things are more complicated.

I think there are two possibilities.  The better but harder one is to 
write your own "vignette engine".  Section 1.4.2 of the manual describes 
the process, and ?tools::vignetteEngine describes what is needed in your 
engine.

The other possibility is to manually edit an inst/doc/index.html file to 
include links to your documents.  They won't be treated as vignettes, 
but at least users will be able to find them.  The other disadvantage of 
this approach is that you'll need to edit it for all vignettes, not just 
the strange ones.

Duncan Murdoch


> -- Mike
> 
> 
> On Mon, Feb 19, 2018 at 1:20 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 18/02/2018 9:06 PM, Michael Hannon wrote:
>>>
>>> Greetings.  The group that I work with has just started using the approach
>>> outlined in Karl Broman's handy primer:
>>>
>>>       http://kbroman.org/pkg_primer/pages/vignettes.html
>>>
>>> to create vignettes for a couple of R packages.
>>>
>>> This works fine as long as we have a current Rmd version of the vignette.
>>> But
>>> we have some old PDF documents that we'd like to include as vignettes as
>>> well.
>>> I'd like to know if there's a way to include such PDF files as vignettes.
>>>
>>> We *do* have the source files for the PDF files in question, but it would
>>> be
>>> tedious to convert those source files to Rmd format.
>>>
>>> My first thought was simply to add the PDF files to the .../vignettes
>>> subdirectory and run the devtools::build_vignettes() function (mentioned
>>> in
>>> the Broman tutorial), but that doesn't work.  I.e., the PDF files don't
>>> appear
>>> in the list of vignettes for the package.
>>>
>>> And after running devtools::build_vignettes I see that there's a lot of
>>> additional stuff in:
>>>
>>>       ...lib/R/site-library/<package_name>/...
>>>
>>> so I don't see any obvious way to "fool" R into using the PDF files that
>>> haven't gone through the whole knitr/rmarkdown process.  (Not to mention
>>> that
>>> such an approach would be fragile at best.)
>>
>>
>> You don't say what format the source is, but if it is LaTeX, you just need
>> to add some comments at the beginning, rename ending in .Rnw, and R will
>> recognize plain LaTeX files as Sweave vignettes.
>>
>> See the Writing R Extensions manual, section 1.4.
>>
>> Duncan Murdoch
>>
>>>
>>> Suggestions welcome.  Thanks.
>>>
>>> -- Mike
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From rainer_krug at icloud.com  Mon Feb 19 12:38:17 2018
From: rainer_krug at icloud.com (Rainer Krug)
Date: Mon, 19 Feb 2018 12:38:17 +0100
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <9d2d4ff5-a322-6853-ff26-f80146f0cce6@gmail.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
 <146e8ef8-c45c-26ab-04d1-a03b5ee24220@gmail.com>
 <CACdH2ZYSPOxZy_wW2DTei=+Da0T5Rbbat8KdOM9M6f_5rUUgFw@mail.gmail.com>
 <9d2d4ff5-a322-6853-ff26-f80146f0cce6@gmail.com>
Message-ID: <C081D16F-AF02-406D-92F8-3C2E85071ECD@icloud.com>



> On 19 Feb 2018, at 12:25, Duncan Murdoch <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> 
> On 19/02/2018 5:47 AM, Michael Hannon wrote:
>> Thanks, Duncan.  The files in question are Emacs Org-mode files, and I
>> think these are more or less isomorphic to Rmd files, but I haven't
>> used Org-mode in a long time, so I think the mapping (Org-mode ==>
>> Rmd) would be painful.

That should be easy - you can export org-mode files directly to LaTex. I haven?t used org-mode for some time, but I think it is Ctrl - C - E and than follow the prompts (obviously in emacs).

Rainer


> 
> If they aren't LaTeX then they won't be able to masquerade as Sweave files, so things are more complicated.
> 
> I think there are two possibilities.  The better but harder one is to write your own "vignette engine".  Section 1.4.2 of the manual describes the process, and ?tools::vignetteEngine describes what is needed in your engine.
> 
> The other possibility is to manually edit an inst/doc/index.html file to include links to your documents.  They won't be treated as vignettes, but at least users will be able to find them.  The other disadvantage of this approach is that you'll need to edit it for all vignettes, not just the strange ones.
> 
> Duncan Murdoch
> 
> 
>> -- Mike
>> On Mon, Feb 19, 2018 at 1:20 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>> On 18/02/2018 9:06 PM, Michael Hannon wrote:
>>>> 
>>>> Greetings.  The group that I work with has just started using the approach
>>>> outlined in Karl Broman's handy primer:
>>>> 
>>>>      http://kbroman.org/pkg_primer/pages/vignettes.html <http://kbroman.org/pkg_primer/pages/vignettes.html>
>>>> 
>>>> to create vignettes for a couple of R packages.
>>>> 
>>>> This works fine as long as we have a current Rmd version of the vignette.
>>>> But
>>>> we have some old PDF documents that we'd like to include as vignettes as
>>>> well.
>>>> I'd like to know if there's a way to include such PDF files as vignettes.
>>>> 
>>>> We *do* have the source files for the PDF files in question, but it would
>>>> be
>>>> tedious to convert those source files to Rmd format.
>>>> 
>>>> My first thought was simply to add the PDF files to the .../vignettes
>>>> subdirectory and run the devtools::build_vignettes() function (mentioned
>>>> in
>>>> the Broman tutorial), but that doesn't work.  I.e., the PDF files don't
>>>> appear
>>>> in the list of vignettes for the package.
>>>> 
>>>> And after running devtools::build_vignettes I see that there's a lot of
>>>> additional stuff in:
>>>> 
>>>>      ...lib/R/site-library/<package_name>/...
>>>> 
>>>> so I don't see any obvious way to "fool" R into using the PDF files that
>>>> haven't gone through the whole knitr/rmarkdown process.  (Not to mention
>>>> that
>>>> such an approach would be fragile at best.)
>>> 
>>> 
>>> You don't say what format the source is, but if it is LaTeX, you just need
>>> to add some comments at the beginning, rename ending in .Rnw, and R will
>>> recognize plain LaTeX files as Sweave vignettes.
>>> 
>>> See the Writing R Extensions manual, section 1.4.
>>> 
>>> Duncan Murdoch
>>> 
>>>> 
>>>> Suggestions welcome.  Thanks.
>>>> 
>>>> -- Mike
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email: ? ? ?Rainer at krugs.de <mailto:Rainer at krugs.de>
Skype:      RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From ssefick at gmail.com  Mon Feb 19 13:22:12 2018
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 19 Feb 2018 06:22:12 -0600
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <C081D16F-AF02-406D-92F8-3C2E85071ECD@icloud.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
 <146e8ef8-c45c-26ab-04d1-a03b5ee24220@gmail.com>
 <CACdH2ZYSPOxZy_wW2DTei=+Da0T5Rbbat8KdOM9M6f_5rUUgFw@mail.gmail.com>
 <9d2d4ff5-a322-6853-ff26-f80146f0cce6@gmail.com>
 <C081D16F-AF02-406D-92F8-3C2E85071ECD@icloud.com>
Message-ID: <CADKEMqj3-nN5zT-caf-VE5cYBddwqZpmjgyFii+niNuFEYc_iw@mail.gmail.com>

Yes, 'C-c C-e l l' I think, but follow the pop-up, and everything should be
ok.

On Feb 19, 2018 07:05, "Rainer Krug" <rainer_krug at icloud.com> wrote:

>
>
> > On 19 Feb 2018, at 12:25, Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>> wrote:
> >
> > On 19/02/2018 5:47 AM, Michael Hannon wrote:
> >> Thanks, Duncan.  The files in question are Emacs Org-mode files, and I
> >> think these are more or less isomorphic to Rmd files, but I haven't
> >> used Org-mode in a long time, so I think the mapping (Org-mode ==>
> >> Rmd) would be painful.
>
> That should be easy - you can export org-mode files directly to LaTex. I
> haven?t used org-mode for some time, but I think it is Ctrl - C - E and
> than follow the prompts (obviously in emacs).
>
> Rainer
>
>
> >
> > If they aren't LaTeX then they won't be able to masquerade as Sweave
> files, so things are more complicated.
> >
> > I think there are two possibilities.  The better but harder one is to
> write your own "vignette engine".  Section 1.4.2 of the manual describes
> the process, and ?tools::vignetteEngine describes what is needed in your
> engine.
> >
> > The other possibility is to manually edit an inst/doc/index.html file to
> include links to your documents.  They won't be treated as vignettes, but
> at least users will be able to find them.  The other disadvantage of this
> approach is that you'll need to edit it for all vignettes, not just the
> strange ones.
> >
> > Duncan Murdoch
> >
> >
> >> -- Mike
> >> On Mon, Feb 19, 2018 at 1:20 AM, Duncan Murdoch
> >> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> >>> On 18/02/2018 9:06 PM, Michael Hannon wrote:
> >>>>
> >>>> Greetings.  The group that I work with has just started using the
> approach
> >>>> outlined in Karl Broman's handy primer:
> >>>>
> >>>>      http://kbroman.org/pkg_primer/pages/vignettes.html <
> http://kbroman.org/pkg_primer/pages/vignettes.html>
> >>>>
> >>>> to create vignettes for a couple of R packages.
> >>>>
> >>>> This works fine as long as we have a current Rmd version of the
> vignette.
> >>>> But
> >>>> we have some old PDF documents that we'd like to include as vignettes
> as
> >>>> well.
> >>>> I'd like to know if there's a way to include such PDF files as
> vignettes.
> >>>>
> >>>> We *do* have the source files for the PDF files in question, but it
> would
> >>>> be
> >>>> tedious to convert those source files to Rmd format.
> >>>>
> >>>> My first thought was simply to add the PDF files to the .../vignettes
> >>>> subdirectory and run the devtools::build_vignettes() function
> (mentioned
> >>>> in
> >>>> the Broman tutorial), but that doesn't work.  I.e., the PDF files
> don't
> >>>> appear
> >>>> in the list of vignettes for the package.
> >>>>
> >>>> And after running devtools::build_vignettes I see that there's a lot
> of
> >>>> additional stuff in:
> >>>>
> >>>>      ...lib/R/site-library/<package_name>/...
> >>>>
> >>>> so I don't see any obvious way to "fool" R into using the PDF files
> that
> >>>> haven't gone through the whole knitr/rmarkdown process.  (Not to
> mention
> >>>> that
> >>>> such an approach would be fragile at best.)
> >>>
> >>>
> >>> You don't say what format the source is, but if it is LaTeX, you just
> need
> >>> to add some comments at the beginning, rename ending in .Rnw, and R
> will
> >>> recognize plain LaTeX files as Sweave vignettes.
> >>>
> >>> See the Writing R Extensions manual, section 1.4.
> >>>
> >>> Duncan Murdoch
> >>>
> >>>>
> >>>> Suggestions welcome.  Thanks.
> >>>>
> >>>> -- Mike
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> University of Z?rich
>
> Cell:       +41 (0)78 630 66 57
> email:      Rainer at krugs.de <mailto:Rainer at krugs.de>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jeroenooms at gmail.com  Mon Feb 19 13:55:25 2018
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 19 Feb 2018 13:55:25 +0100
Subject: [R] Problem installing libxml2 under Homebrew
In-Reply-To: <CAJoaRharR7vMdnzY8Baij-a=q7EMP4iFKmWtqHR+c43xjcwWFg@mail.gmail.com>
References: <CAJoaRharR7vMdnzY8Baij-a=q7EMP4iFKmWtqHR+c43xjcwWFg@mail.gmail.com>
Message-ID: <CABFfbXtRD-QxWsg7kWvpX8Wi7-0vW1rmPLDRwTM2xBRqVWPr2g@mail.gmail.com>

You probably have a malconfigured homebrew installation of R. On MacOS
it is recommended to use the CRAN version of R
https://cran.r-project.org/bin/macosx/. The homebrew version depends
on gcc compilers and does not support cran binary packages.

If you really want to use the homebrew R try ruling out the following problems:

 - Check for conflicting compilers in your path (gcc, ccache, clang4).
Unless you have good reasons not to, you should use the native xcode
compilers to build R packages.
 - Comment out custom compilers/flags that you may have in your
~/.R/Makevars file.

Use the following script to check why the configuration is failing:

  CPP=$(R CMD config CPP)
  CFLAGS=$(xml2-config --cflags)
  echo '#include <libxml/tree.h>' | $CPP $CFLAGS -E -xc - > /dev/null




On Sat, Feb 17, 2018 at 8:53 AM, Peter Meilstrup
<peter.meilstrup at gmail.com> wrote:
> i am trying to install xml2 from CRAN, and it is throwing an error
> that it cannot find the libxml2 library configuration.
>
> The thing is that pkg-config seems to be set up correctly:
>
> $ echo $PKG_CONFIG_PATH
> :/usr/local/opt/libxml2/lib/pkgconfig:/usr/local/opt/libxml2/lib/pkgconfig
>
> $ pkg-config --cflags --libs libxml-2.0
> -I/usr/local/Cellar/libxml2/2.9.7/include/libxml2
> -L/usr/local/Cellar/libxml2/2.9.7/lib -lx
>
> Output of install.packages:
>
>> install.packages("xml2")
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'https://cloud.r-project.org/src/contrib/xml2_1.2.0.tar.gz'
> Content type 'application/x-gzip' length 251614 bytes (245 KB)
> ==================================================
> downloaded 245 KB
>
> * installing *source* package ?xml2? ...
> ** package ?xml2? successfully unpacked and MD5 sums checked
> Found pkg-config cflags and libs!
> Using PKG_CFLAGS=-I/usr/include/libxml2
> Using PKG_LIBS=-L/usr/lib -lxml2 -lz -lpthread -licucore -lm
> ------------------------- ANTICONF ERROR ---------------------------
> Configuration failed because libxml-2.0 was not found. Try installing:
>  * deb: libxml2-dev (Debian, Ubuntu, etc)
>  * rpm: libxml2-devel (Fedora, CentOS, RHEL)
>  * csw: libxml2_dev (Solaris)
> If libxml-2.0 is already installed, check that 'pkg-config' is in your
> PATH and PKG_CONFIG_PATH contains a libxml-2.0.pc file. If pkg-config
> is unavailable you can set INCLUDE_DIR and LIB_DIR manually via:
> R CMD INSTALL --configure-vars='INCLUDE_DIR=... LIB_DIR=...'
> --------------------------------------------------------------------
> ERROR: configuration failed for package ?xml2?
>
> Homebrew package info:
>
> dekkera:pkgconfig peter$ brew info libxml2 R
> libxml2: stable 2.9.7 (bottled), HEAD [keg-only]
> GNOME XML library
> http://xmlsoft.org
> /usr/local/Cellar/libxml2/2.9.7 (281 files, 10.4MB)
>   Poured from bottle on 2018-02-16 at 22:42:54
> From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/libxml2.rb
> ==> Options
> --HEAD
>     Install HEAD version
> ==> Caveats
> This formula is keg-only, which means it was not symlinked into /usr/local,
> because macOS already provides this software and installing another version in
> parallel can cause all kinds of trouble.
>
> If you need to have this software first in your PATH run:
>   echo 'export PATH="/usr/local/opt/libxml2/bin:$PATH"' >> ~/.bash_profile
>
> For compilers to find this software you may need to set:
>     LDFLAGS:  -L/usr/local/opt/libxml2/lib
>     CPPFLAGS: -I/usr/local/opt/libxml2/include
> For pkg-config to find this software you may need to set:
>     PKG_CONFIG_PATH: /usr/local/opt/libxml2/lib/pkgconfig
>
> If you need Python to find bindings for this keg-only formula, run:
>   echo /usr/local/opt/libxml2/lib/python2.7/site-packages >>
> /usr/local/lib/python2.7/site-packages/libxml2.pth
>   mkdir -p /Users/peter/Library/Python/2.7/lib/python/site-packages
>   echo 'import site;
> site.addsitedir("/usr/local/lib/python2.7/site-packages")' >>
> /Users/peter/Library/Python/2.7/lib/python/site-packages/homebrew.pth
>
> R: stable 3.4.3 (bottled)
> Software environment for statistical computing
> https://www.r-project.org/
> /usr/local/Cellar/R/3.4.0_1 (2,246 files, 59.1MB)
>   Poured from bottle on 2017-05-20 at 17:10:29
> /usr/local/Cellar/R/3.4.1_2 (2,114 files, 55.3MB)
>   Poured from bottle on 2017-09-19 at 03:23:33
> /usr/local/Cellar/R/3.4.2 (2,111 files, 55.1MB)
>   Poured from bottle on 2017-11-13 at 22:23:36
> /usr/local/Cellar/R/3.4.3 (2,110 files, 55.1MB)
>   Poured from bottle on 2017-12-02 at 23:20:16
> /usr/local/Cellar/R/3.4.3_1 (3,773 files, 115.4MB)
>   Built from source on 2018-02-08 at 22:01:49 with: --with-x11
> --with-cairo --with-java
> From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/r.rb
> ==> Dependencies
> Build: pkg-config ?
> Required: gcc ?, gettext ?, jpeg ?, libpng ?, pcre ?, readline ?, xz ?
> Optional: openblas ?
> ==> Requirements
> Optional: java ?
> ==> Options
> --with-java
>     Build with java support
> --with-openblas
>     Build with openblas support
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Feb 19 14:04:52 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 19 Feb 2018 13:04:52 +0000
Subject: [R] 
 Putting 733 discrete categories on Y-axis in qqplot2 as they are
In-Reply-To: <CAM9Qe4iu6t6wEUUEf925pt2tkvm7ccAy64KMHFA+i9OYS_6YUQ@mail.gmail.com>
References: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>
 <deb8bcbfbdff47a0947a394d8116df48@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4jBCoEQoXeRpOOBSz-myYhj4VBz74CYsu_ZnLbOwGDmbw@mail.gmail.com>
 <1aa1bd784ab7433d86f3bfeecf6620d7@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4iu6t6wEUUEf925pt2tkvm7ccAy64KMHFA+i9OYS_6YUQ@mail.gmail.com>
Message-ID: <5e3d906a463b47f59ff11d510eca75dd@SRVEXCHCM1301.precheza.cz>

Hi

When you load external file to R, character variables are converted to factors by default and alphabetically sorted. I have limited connection to internet, so I cannot find the answer, you could try it yourself. Maybe you could try not to convert vector with names to factor, which, for plotting issue is not different from factor coding.

See ?read.table for details

However I am not sure if it stays in original order.

Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com]
Sent: Friday, February 16, 2018 6:28 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Putting 733 discrete categories on Y-axis in qqplot2 as they are

Hi Petr;

I would like to get a plot with names as they are in the original file. They are chemical names and I have 733 in the my file. For example, let me give to chemical names "2-hydroxybutyrate/2-hydroxyisobutyrate" and  "palmitoyl-arachidonoyl-glycerol (16:0/20:4) [1]*" .So, what should I put  [c(2,3,1)] part in the command:  iris$MySpecies<-factor(iris$Species, levels(iris$Species)[c(2,3,1)])

Regards,

Greg

On Fri, Feb 16, 2018 at 6:13 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

What do you mean ?without reordering the names?. Factor variable is ordered according to its levels and you can freely change the ordering. This is why factors are useful and worth to use in many cases instead of character vectors.

See this result

> iris$MySpecies<-factor(iris$Species, levels(iris$Species)[c(2,3,1)])
> p<-ggplot(iris, aes(x=Sepal.Length, y=Species))
> p+geom_point()
> p<-ggplot(iris, aes(x=Sepal.Length, y=MySpecies))
> p+geom_point()
>
Cheers
Petr

From: greg holly [mailto:mak.hholly at gmail.com<mailto:mak.hholly at gmail.com>]
Sent: Friday, February 16, 2018 3:56 PM
To: PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
Cc: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Putting 733 discrete categories on Y-axis in qqplot2 as they are

Hi Petr;

Thanks. I do save the result in pdf by using the following command.

   ggsave("z7.pdf", p4, height = 95, width = 8, device=pdf, limitsize = F,dpi=300)

 I can achieve the y axis with 733 levels. But I need get the plot WITHOUT reordering the names.

Regards,

Greg

On Fri, Feb 16, 2018 at 3:39 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of greg holly
> Sent: Thursday, February 15, 2018 3:58 PM
> To: r-help mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Putting 733 discrete categories on Y-axis in qqplot2 as they are
>
> Hi all;
>
> I have 733 discrete categories that will go on y-axis in ggplot2. I used the
> following command to put the name of x-axis.
>
> scale_x_discrete (limits = c("SI", "HOMAIR",
> "AIR","HOMAB","SG","DI","FI","FG"))
>
> Since there are only 8 categories on x it was easy to do. Is there any way to do
> the same for 733 discrete categories for y-axis. Essentially I did not want to
> order categories. I would like to put the name of categories as they are.

You probably can achieve the y axis with 733 levels if you do not use limits in scale.

Just from curiosity, standard page has 30 lines, so your axis should stretch to more than 20 pages. Or you need to shrink your y axis 20 times. Both options will give you unreadable results.

Cheers
Petr

>
> Best regards,
>
> Greg
>


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Mon Feb 19 22:43:52 2018
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 20 Feb 2018 00:43:52 +0300
Subject: [R] 
 Putting 733 discrete categories on Y-axis in qqplot2 as they are
In-Reply-To: <5e3d906a463b47f59ff11d510eca75dd@SRVEXCHCM1301.precheza.cz>
References: <CAM9Qe4j82wfFWnqALetB5XJ-xUY7Q-ZMMCPUpgH0CK+DgY9rqQ@mail.gmail.com>
 <deb8bcbfbdff47a0947a394d8116df48@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4jBCoEQoXeRpOOBSz-myYhj4VBz74CYsu_ZnLbOwGDmbw@mail.gmail.com>
 <1aa1bd784ab7433d86f3bfeecf6620d7@SRVEXCHCM1301.precheza.cz>
 <CAM9Qe4iu6t6wEUUEf925pt2tkvm7ccAy64KMHFA+i9OYS_6YUQ@mail.gmail.com>
 <5e3d906a463b47f59ff11d510eca75dd@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAM9Qe4g47ZRMLkBeo-wzZ8zk-o=9DGz9OCVNjRT+oOyfBL4FVA@mail.gmail.com>

Hi Petr;

Thanks for this. I have used the following code to overcome with the problem


a$Meta <- factor(a$Meta, levels=a[order(a$Superpath,decreasing=T),]$Meta)

Regards,
Greg


On Mon, Feb 19, 2018 at 4:04 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> When you load external file to R, character variables are converted to
> factors by default and alphabetically sorted. I have limited connection to
> internet, so I cannot find the answer, you could try it yourself. Maybe you
> could try not to convert vector with names to factor, which, for plotting
> issue is not different from factor coding.
>
>
>
> See ?read.table for details
>
>
>
> However I am not sure if it stays in original order.
>
>
>
> Cheers
>
> Petr
>
>
>
> *From:* greg holly [mailto:mak.hholly at gmail.com]
> *Sent:* Friday, February 16, 2018 6:28 PM
>
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* r-help mailing list <r-help at r-project.org>
> *Subject:* Re: [R] Putting 733 discrete categories on Y-axis in qqplot2
> as they are
>
>
>
> Hi Petr;
>
>
>
> I would like to get a plot with names as they are in the original file.
> They are chemical names and I have 733 in the my file. For example, let me
> give to chemical names "*2-hydroxybutyrate/2-hydroxyisobutyrate*" and  "*palmitoyl-arachidonoyl-glycerol
> (16:0/20:4) [1]**" .So, what should I put  [c(2,3,1)] part in the
> command:  iris$MySpecies<-factor(iris$Species,
> levels(iris$Species)[c(2,3,1)])
>
>
>
> Regards,
>
>
>
> Greg
>
>
>
> On Fri, Feb 16, 2018 at 6:13 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Hi
>
>
>
> What do you mean ?without reordering the names?. Factor variable is
> ordered according to its levels and you can freely change the ordering.
> This is why factors are useful and worth to use in many cases instead of
> character vectors.
>
>
>
> See this result
>
>
>
> > iris$MySpecies<-factor(iris$Species, levels(iris$Species)[c(2,3,1)])
>
> > p<-ggplot(iris, aes(x=Sepal.Length, y=Species))
>
> > p+geom_point()
>
> > p<-ggplot(iris, aes(x=Sepal.Length, y=MySpecies))
>
> > p+geom_point()
>
> >
>
> Cheers
>
> Petr
>
>
>
> *From:* greg holly [mailto:mak.hholly at gmail.com]
> *Sent:* Friday, February 16, 2018 3:56 PM
> *To:* PIKAL Petr <petr.pikal at precheza.cz>
> *Cc:* r-help mailing list <r-help at r-project.org>
> *Subject:* Re: [R] Putting 733 discrete categories on Y-axis in qqplot2
> as they are
>
>
>
> Hi Petr;
>
>
>
> Thanks. I do save the result in pdf by using the following command.
>
>
>
>    ggsave("z7.pdf", p4, height = 95, width = 8, device=pdf, limitsize =
> F,dpi=300)
>
>
>
>  I can achieve the y axis with 733 levels. But I need get the plot
> WITHOUT reordering the names.
>
>
>
> Regards,
>
>
>
> Greg
>
>
>
> On Fri, Feb 16, 2018 at 3:39 PM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Hi
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
> holly
> > Sent: Thursday, February 15, 2018 3:58 PM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] Putting 733 discrete categories on Y-axis in qqplot2 as
> they are
> >
> > Hi all;
> >
> > I have 733 discrete categories that will go on y-axis in ggplot2. I used
> the
> > following command to put the name of x-axis.
> >
> > scale_x_discrete (limits = c("SI", "HOMAIR",
> > "AIR","HOMAB","SG","DI","FI","FG"))
> >
> > Since there are only 8 categories on x it was easy to do. Is there any
> way to do
> > the same for 733 discrete categories for y-axis. Essentially I did not
> want to
> > order categories. I would like to put the name of categories as they are.
>
> You probably can achieve the y axis with 733 levels if you do not use
> limits in scale.
>
> Just from curiosity, standard page has 30 lines, so your axis should
> stretch to more than 20 pages. Or you need to shrink your y axis 20 times.
> Both options will give you unreadable results.
>
> Cheers
> Petr
>
> >
> > Best regards,
> >
> > Greg
> >
>
>
>
>
> ------------------------------
>
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Mon Feb 19 23:34:47 2018
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Mon, 19 Feb 2018 14:34:47 -0800
Subject: [R] 
 Include pre-existing PDF files as vignettes in an R package?
In-Reply-To: <CADKEMqj3-nN5zT-caf-VE5cYBddwqZpmjgyFii+niNuFEYc_iw@mail.gmail.com>
References: <CACdH2ZZ4LN=sRRu_x3S6ixYQWPaDzV_RMjHcxEW32vR3mptg0w@mail.gmail.com>
 <146e8ef8-c45c-26ab-04d1-a03b5ee24220@gmail.com>
 <CACdH2ZYSPOxZy_wW2DTei=+Da0T5Rbbat8KdOM9M6f_5rUUgFw@mail.gmail.com>
 <9d2d4ff5-a322-6853-ff26-f80146f0cce6@gmail.com>
 <C081D16F-AF02-406D-92F8-3C2E85071ECD@icloud.com>
 <CADKEMqj3-nN5zT-caf-VE5cYBddwqZpmjgyFii+niNuFEYc_iw@mail.gmail.com>
Message-ID: <CACdH2Za=ZVysQp1vi_d7e5Qk3g9Wiwn8=7DbkzJ-hKj_xEvauA@mail.gmail.com>

Exporting to LaTeX is a good idea.  Thanks, guys.


On Mon, Feb 19, 2018 at 4:22 AM, stephen sefick <ssefick at gmail.com> wrote:
> Yes, 'C-c C-e l l' I think, but follow the pop-up, and everything should be
> ok.
>
> On Feb 19, 2018 07:05, "Rainer Krug" <rainer_krug at icloud.com> wrote:
>
>>
>>
>> > On 19 Feb 2018, at 12:25, Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>> >
>> > On 19/02/2018 5:47 AM, Michael Hannon wrote:
>> >> Thanks, Duncan.  The files in question are Emacs Org-mode files, and I
>> >> think these are more or less isomorphic to Rmd files, but I haven't
>> >> used Org-mode in a long time, so I think the mapping (Org-mode ==>
>> >> Rmd) would be painful.
>>
>> That should be easy - you can export org-mode files directly to LaTex. I
>> haven?t used org-mode for some time, but I think it is Ctrl - C - E and
>> than follow the prompts (obviously in emacs).
>>
>> Rainer
>>
>>
>> >
>> > If they aren't LaTeX then they won't be able to masquerade as Sweave
>> files, so things are more complicated.
>> >
>> > I think there are two possibilities.  The better but harder one is to
>> write your own "vignette engine".  Section 1.4.2 of the manual describes
>> the process, and ?tools::vignetteEngine describes what is needed in your
>> engine.
>> >
>> > The other possibility is to manually edit an inst/doc/index.html file to
>> include links to your documents.  They won't be treated as vignettes, but
>> at least users will be able to find them.  The other disadvantage of this
>> approach is that you'll need to edit it for all vignettes, not just the
>> strange ones.
>> >
>> > Duncan Murdoch
>> >
>> >
>> >> -- Mike
>> >> On Mon, Feb 19, 2018 at 1:20 AM, Duncan Murdoch
>> >> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>> >>> On 18/02/2018 9:06 PM, Michael Hannon wrote:
>> >>>>
>> >>>> Greetings.  The group that I work with has just started using the
>> approach
>> >>>> outlined in Karl Broman's handy primer:
>> >>>>
>> >>>>      http://kbroman.org/pkg_primer/pages/vignettes.html <
>> http://kbroman.org/pkg_primer/pages/vignettes.html>
>> >>>>
>> >>>> to create vignettes for a couple of R packages.
>> >>>>
>> >>>> This works fine as long as we have a current Rmd version of the
>> vignette.
>> >>>> But
>> >>>> we have some old PDF documents that we'd like to include as vignettes
>> as
>> >>>> well.
>> >>>> I'd like to know if there's a way to include such PDF files as
>> vignettes.
>> >>>>
>> >>>> We *do* have the source files for the PDF files in question, but it
>> would
>> >>>> be
>> >>>> tedious to convert those source files to Rmd format.
>> >>>>
>> >>>> My first thought was simply to add the PDF files to the .../vignettes
>> >>>> subdirectory and run the devtools::build_vignettes() function
>> (mentioned
>> >>>> in
>> >>>> the Broman tutorial), but that doesn't work.  I.e., the PDF files
>> don't
>> >>>> appear
>> >>>> in the list of vignettes for the package.
>> >>>>
>> >>>> And after running devtools::build_vignettes I see that there's a lot
>> of
>> >>>> additional stuff in:
>> >>>>
>> >>>>      ...lib/R/site-library/<package_name>/...
>> >>>>
>> >>>> so I don't see any obvious way to "fool" R into using the PDF files
>> that
>> >>>> haven't gone through the whole knitr/rmarkdown process.  (Not to
>> mention
>> >>>> that
>> >>>> such an approach would be fragile at best.)
>> >>>
>> >>>
>> >>> You don't say what format the source is, but if it is LaTeX, you just
>> need
>> >>> to add some comments at the beginning, rename ending in .Rnw, and R
>> will
>> >>> recognize plain LaTeX files as Sweave vignettes.
>> >>>
>> >>> See the Writing R Extensions manual, section 1.4.
>> >>>
>> >>> Duncan Murdoch
>> >>>
>> >>>>
>> >>>> Suggestions welcome.  Thanks.
>> >>>>
>> >>>> -- Mike
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>> To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help <
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>> >>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>
>> >
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help <
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>> Biology, UCT), Dipl. Phys. (Germany)
>>
>> University of Z?rich
>>
>> Cell:       +41 (0)78 630 66 57
>> email:      Rainer at krugs.de <mailto:Rainer at krugs.de>
>> Skype:      RMkrug
>>
>> PGP: 0x0F52F982
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From coetzeeJ at phru.co.za  Tue Feb 20 06:03:58 2018
From: coetzeeJ at phru.co.za (Jenny Coetzee)
Date: Tue, 20 Feb 2018 05:03:58 +0000
Subject: [R] JGR not installed. Attempting to install from CRAN...
Message-ID: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za>

Hello

I am new to R, and am running a programme called RDS Analyst which uses R. When trying to open RDS i am getting the following message: JGR not installed. Attempting to install from CRAN?

I am not sure if the issue is a Java one or an R one?

I am working off a Mac using High Sierra

Any help please..?

thanks

Jen




Jenny Coetzee (PhD Candidate)
Head of Prevention in Key Populations & Head of the Soweto Sex Worker Project
Perinatal HIV Research Unit (PHRU)
New Nurses Home
Chris Hani Baragwanath Academic Hospital
Soweto

B: +27 11 989 9821
M: +27 84 761 1193
E: coetzeej at phru.co.za<mailto:coetzeej at phru.co.za>

"Here's to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes ... the ones who see things differently - they're not fond of rules, and they have no respect for the status quo. ... You can quote them, disagree with them, glorify or vilify them, but the only thing you can't do is ignore them because they change things. ... They push the human race forward, and while some may see them as the crazy ones, we see genius, because the people who are crazy enough to think that they can change the world, are the ones who do."
(Steve Jobs)


	[[alternative HTML version deleted]]


From loris.bennett at fu-berlin.de  Tue Feb 20 08:16:30 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 20 Feb 2018 08:16:30 +0100
Subject: [R] JGR not installed. Attempting to install from CRAN...
In-Reply-To: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za> (Jenny
 Coetzee's message of "Tue, 20 Feb 2018 05:03:58 +0000")
References: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za>
Message-ID: <87fu5w6shd.fsf@hornfels.zedat.fu-berlin.de>

Hi Jenny,

Jenny Coetzee <coetzeeJ at phru.co.za> writes:

> Hello
>
> I am new to R, and am running a programme called RDS Analyst which
> uses R. When trying to open RDS i am getting the following message:
> JGR not installed. Attempting to install from CRAN?
>
> I am not sure if the issue is a Java one or an R one?
>
> I am working off a Mac using High Sierra
>
> Any help please..?

Here

  http://rforge.net/JGR/

it says that you need two bits: the R package from CRAN and the launcher
for MacOS.  You should be able to install the R package using

  install.packages("JGR")

from the R shell and the launcher just like a regular binary.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From loris.bennett at fu-berlin.de  Tue Feb 20 09:05:43 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 20 Feb 2018 09:05:43 +0100
Subject: [R] JGR not installed. Attempting to install from CRAN...
In-Reply-To: <AE9844A4-8768-4BC4-B541-5318A1B9D00F@phru.co.za> (Jenny
 Coetzee's message of "Tue, 20 Feb 2018 07:55:43 +0000")
References: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za>
 <87fu5w6shd.fsf@hornfels.zedat.fu-berlin.de>
 <AE9844A4-8768-4BC4-B541-5318A1B9D00F@phru.co.za>
Message-ID: <87tvucytk8.fsf@hornfels.zedat.fu-berlin.de>

Hi Jenny,

Jenny Coetzee <coetzeeJ at phru.co.za> writes:

> Loris, thank you thank you so much!!! 
>
> do you know which CRAN mirror i select? There are loads - all related to various countries..
>
> so appreciate the help

It shouldn't really matter, although I'd choose one that is
geographically close.  Occasionally there can be problems with HTTP
vs. HTTPS, which can lead to spurious errors about a packages not being
available for your version of R.  Because R caches the mirror, if you
run into any issues you might have to exit R and start again.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From coetzeeJ at phru.co.za  Tue Feb 20 08:55:43 2018
From: coetzeeJ at phru.co.za (Jenny Coetzee)
Date: Tue, 20 Feb 2018 07:55:43 +0000
Subject: [R] JGR not installed. Attempting to install from CRAN...
In-Reply-To: <87fu5w6shd.fsf@hornfels.zedat.fu-berlin.de>
References: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za>
 <87fu5w6shd.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <AE9844A4-8768-4BC4-B541-5318A1B9D00F@phru.co.za>

Loris, thank you thank you so much!!!

do you know which CRAN mirror i select? There are loads - all related to various countries..

so appreciate the help

Jenny




Jenny Coetzee (PhD Candidate)
Head of Prevention in Key Populations & Head of the Soweto Sex Worker Project
Perinatal HIV Research Unit (PHRU)
New Nurses Home
Chris Hani Baragwanath Academic Hospital
Soweto

B: +27 11 989 9821
M: +27 84 761 1193
E: coetzeej at phru.co.za<mailto:coetzeej at phru.co.za>

"Here's to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes ... the ones who see things differently - they're not fond of rules, and they have no respect for the status quo. ... You can quote them, disagree with them, glorify or vilify them, but the only thing you can't do is ignore them because they change things. ... They push the human race forward, and while some may see them as the crazy ones, we see genius, because the people who are crazy enough to think that they can change the world, are the ones who do."
(Steve Jobs)

On 20 Feb 2018, at 09:16, Loris Bennett <loris.bennett at fu-berlin.de<mailto:loris.bennett at fu-berlin.de>> wrote:

Hi Jenny,

Jenny Coetzee <coetzeeJ at phru.co.za<mailto:coetzeeJ at phru.co.za>> writes:

Hello

I am new to R, and am running a programme called RDS Analyst which
uses R. When trying to open RDS i am getting the following message:
JGR not installed. Attempting to install from CRAN?

I am not sure if the issue is a Java one or an R one?

I am working off a Mac using High Sierra

Any help please..?

Here

 http://rforge.net/JGR/

it says that you need two bits: the R package from CRAN and the launcher
for MacOS.  You should be able to install the R package using

 install.packages("JGR")

from the R shell and the launcher just like a regular binary.

Cheers,

Loris

--
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de<mailto:loris.bennett at fu-berlin.de>


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Feb 20 12:38:07 2018
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 20 Feb 2018 11:38:07 +0000
Subject: [R] JGR not installed. Attempting to install from CRAN...
In-Reply-To: <AE9844A4-8768-4BC4-B541-5318A1B9D00F@phru.co.za>
References: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za>
 <87fu5w6shd.fsf@hornfels.zedat.fu-berlin.de>
 <AE9844A4-8768-4BC4-B541-5318A1B9D00F@phru.co.za>
Message-ID: <1efe540e-5500-cbe3-1187-d42e06b4d13f@dewey.myzen.co.uk>

Dear Jenny

 From your email address I would have thought one of the two South 
African ones would be best. In the unlikely event of your chosen mirror 
not being up-to-date, try another one.

Michael

On 20/02/2018 07:55, Jenny Coetzee wrote:
> Loris, thank you thank you so much!!!
> 
> do you know which CRAN mirror i select? There are loads - all related to various countries..
> 
> so appreciate the help
> 
> Jenny
> 
> 
> 
> 
> Jenny Coetzee (PhD Candidate)
> Head of Prevention in Key Populations & Head of the Soweto Sex Worker Project
> Perinatal HIV Research Unit (PHRU)
> New Nurses Home
> Chris Hani Baragwanath Academic Hospital
> Soweto
> 
> B: +27 11 989 9821
> M: +27 84 761 1193
> E: coetzeej at phru.co.za<mailto:coetzeej at phru.co.za>
> 
> "Here's to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes ... the ones who see things differently - they're not fond of rules, and they have no respect for the status quo. ... You can quote them, disagree with them, glorify or vilify them, but the only thing you can't do is ignore them because they change things. ... They push the human race forward, and while some may see them as the crazy ones, we see genius, because the people who are crazy enough to think that they can change the world, are the ones who do."
> (Steve Jobs)
> 
> On 20 Feb 2018, at 09:16, Loris Bennett <loris.bennett at fu-berlin.de<mailto:loris.bennett at fu-berlin.de>> wrote:
> 
> Hi Jenny,
> 
> Jenny Coetzee <coetzeeJ at phru.co.za<mailto:coetzeeJ at phru.co.za>> writes:
> 
> Hello
> 
> I am new to R, and am running a programme called RDS Analyst which
> uses R. When trying to open RDS i am getting the following message:
> JGR not installed. Attempting to install from CRAN?
> 
> I am not sure if the issue is a Java one or an R one?
> 
> I am working off a Mac using High Sierra
> 
> Any help please..?
> 
> Here
> 
>   http://rforge.net/JGR/
> 
> it says that you need two bits: the R package from CRAN and the launcher
> for MacOS.  You should be able to install the R package using
> 
>   install.packages("JGR")
> 
> from the R shell and the launcher just like a regular binary.
> 
> Cheers,
> 
> Loris
> 
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de<mailto:loris.bennett at fu-berlin.de>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From loris.bennett at fu-berlin.de  Tue Feb 20 12:52:14 2018
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 20 Feb 2018 12:52:14 +0100
Subject: [R] JGR not installed. Attempting to install from CRAN...
In-Reply-To: <3AA43B06-C4BA-4711-BE9A-6B19BF918770@phru.co.za> (Jenny
 Coetzee's message of "Tue, 20 Feb 2018 10:39:26 +0000")
References: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za>
 <87fu5w6shd.fsf@hornfels.zedat.fu-berlin.de>
 <AE9844A4-8768-4BC4-B541-5318A1B9D00F@phru.co.za>
 <87tvucytk8.fsf@hornfels.zedat.fu-berlin.de>
 <3AA43B06-C4BA-4711-BE9A-6B19BF918770@phru.co.za>
Message-ID: <87vaeryj2p.fsf@hornfels.zedat.fu-berlin.de>

Jenny Coetzee <coetzeeJ at phru.co.za> writes:

> thanks Loris 
>
> you are bering so helpful!
>
> So, i have done what you explained, but the RDS package that runs
> ?using or through? R is now just closing each time i open it. I have
> googled and seen that i need to to the following:
>
> Tips: The recent updates to the Apple Mac OS (Sierra and High Sierra)
> have reorganized the ways apps, like RDS Analyst, work. So sometimes
> RDS Analyst will not be configured correctly and will not start (e.g.,
> bouncing icon or no response to double clicking). Most of these relate
> to how Java works on the Mac. The first thing to try is to open the
> Terminal and type in : R CMD javareconf This asks R to check on the
> configuration of Java and try to get in sync with it.  off website:
> http://wiki.stat.ucla.edu/hpmrg/index.php/RDS_Analyst_Install
>
> BUT, when i do enter R CMD javareconf, i get the following error:
> Error: unexpected symbol in "R CMD?
>
> so what should i do now?

I'll have to guess now, because I don't know much about Macs or Java.  I
assume there is something wrong with your java installation.  You can
check by writing the following in a terminal:

  java -version

If the output of this isn't something sensible, then you probably need
to (re-)install Java.

Otherwise there is some information here (Point 3. "Configure Java for
R"):

  https://www.ibm.com/support/knowledgecenter/en/SSPT3X_3.0.0/com.ibm.swg.im.infosphere.biginsights.install.doc/doc/install_install_r.html

If that doesn't help (and probably even if it does) you should consider
joining the RDS Users Group, if you haven't already:

  http://wiki.stat.ucla.edu/hpmrg/index.php/RDS_Analyst_Users_Group

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From coetzeeJ at phru.co.za  Tue Feb 20 11:39:26 2018
From: coetzeeJ at phru.co.za (Jenny Coetzee)
Date: Tue, 20 Feb 2018 10:39:26 +0000
Subject: [R] JGR not installed. Attempting to install from CRAN...
In-Reply-To: <87tvucytk8.fsf@hornfels.zedat.fu-berlin.de>
References: <A0BB0A22-E5F3-4FE4-9CF7-CBCB52CAD1D9@phru.co.za>
 <87fu5w6shd.fsf@hornfels.zedat.fu-berlin.de>
 <AE9844A4-8768-4BC4-B541-5318A1B9D00F@phru.co.za>
 <87tvucytk8.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <3AA43B06-C4BA-4711-BE9A-6B19BF918770@phru.co.za>

thanks Loris

you are bering so helpful!

So, i have done what you explained, but the RDS package that runs ?using or through? R is now just closing each time i open it. I have googled and seen that i need to to the following:

 Tips: The recent updates to the Apple Mac OS (Sierra and High Sierra) have reorganized the ways apps, like RDS Analyst, work. So sometimes RDS Analyst will not be configured correctly and will not start (e.g., bouncing icon or no response to double clicking). Most of these relate to how Java works on the Mac. The first thing to try is to open the Terminal and type in :
R CMD javareconf
This asks R to check on the configuration of Java and try to get in sync with it.
off website:
http://wiki.stat.ucla.edu/hpmrg/index.php/RDS_Analyst_Install


BUT, when i do enter  R CMD javareconf, i get the following error:
Error: unexpected symbol in "R CMD?

so what should i do now?

thanks


Jen





Jenny Coetzee (PhD Candidate)
Head of Prevention in Key Populations & Head of the Soweto Sex Worker Project
Perinatal HIV Research Unit (PHRU)
New Nurses Home
Chris Hani Baragwanath Academic Hospital
Soweto

B: +27 11 989 9821
M: +27 84 761 1193
E: coetzeej at phru.co.za<mailto:coetzeej at phru.co.za>

"Here's to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes ... the ones who see things differently - they're not fond of rules, and they have no respect for the status quo. ... You can quote them, disagree with them, glorify or vilify them, but the only thing you can't do is ignore them because they change things. ... They push the human race forward, and while some may see them as the crazy ones, we see genius, because the people who are crazy enough to think that they can change the world, are the ones who do."
(Steve Jobs)

On 20 Feb 2018, at 10:05, Loris Bennett <loris.bennett at fu-berlin.de<mailto:loris.bennett at fu-berlin.de>> wrote:

Hi Jenny,

Jenny Coetzee <coetzeeJ at phru.co.za<mailto:coetzeeJ at phru.co.za>> writes:

Loris, thank you thank you so much!!!

do you know which CRAN mirror i select? There are loads - all related to various countries..

so appreciate the help

It shouldn't really matter, although I'd choose one that is
geographically close.  Occasionally there can be problems with HTTP
vs. HTTPS, which can lead to spurious errors about a packages not being
available for your version of R.  Because R caches the mirror, if you
run into any issues you might have to exit R and start again.

Cheers,

Loris

--
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de<mailto:loris.bennett at fu-berlin.de>


	[[alternative HTML version deleted]]


From akshay_e4 at hotmail.com  Tue Feb 20 13:25:07 2018
From: akshay_e4 at hotmail.com (akshay kulkarni)
Date: Tue, 20 Feb 2018 12:25:07 +0000
Subject: [R] getQuote in quantmod malfunctioning
Message-ID: <SL2P216MB0091AA24389729614176C48BC8CF0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,

               I have a list of stocks by name snlcq2:


 snlcq2 <- c("ICICIBANK.NS"  "IBULHSGFIN.NS" "INDUSINDBK.NS" "INFY.NS"       "KOTAKBANK.NS"  "LTI.NS"        "LT.NS"         "LUPIN.NS"  "M&M.NS"        "M&MFIN.NS"     "NTPC.NS"       "ONGC.NS"       "POWERGRID.NS"  "RELIANCE.NS"   "SBIN.NS"       "SUNPHARMA.NS"  "TCS.NS"        "TATAMOTORS.NS" "TATAMTRDVR.NS" "TATAPOWER.NS"  "TATASTEEL.NS"  "TECHM.NS"      "ULTRACEMCO.NS" "VEDL.NS"  "WIPRO.NS"      "YESBANK.NS"    "UPL.NS"        "ZEEL.NS" )

getQuote(snlcq2)     is not working and is returning the following error:


Error in data.frame(Qposix, sq[, QF]) :
  arguments imply differing number of rows: 2, 9
In addition: Warning message:
In getQuote.yahoo(Symbols = c("ICICIBANK.NS", "IBULHSGFIN.NS", "INDUSINDBK.NS",  :
  symbols have different timezones; converting to local time

However when getQuote is run independently through all stocks of snlcq2, it is working fine...

please help......
very many thanks for your time

yours sincerely,
AKSHAY M KULKARNI


	[[alternative HTML version deleted]]


From milujisb at gmail.com  Tue Feb 20 15:55:16 2018
From: milujisb at gmail.com (Miluji Sb)
Date: Tue, 20 Feb 2018 15:55:16 +0100
Subject: [R] Take the maximum of every 12 columns
Message-ID: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>

 Dear all,

I have monthly data in wide format, I am only providing data (at the bottom
of the email) for the first 24 columns but I have 2880 columns in total.

I would like to take max of every 12 columns. I have taken the mean of
every 12 columns with the following code:

byapply <- function(x, by, fun, ...)
{
  # Create index list
  if (length(by) == 1)
  {
    nc <- ncol(x)
    split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
  } else # 'by' is a vector of groups
  {
    nc <- length(by)
    split.index <- by
  }
  index.list <- split(seq(from = 1, to = nc), split.index)

  # Pass index list to fun using sapply() and return object
  sapply(index.list, function(i)
  {
    do.call(fun, list(x[, i], ...))
  })
}

## Compute annual means
y <- byapply(df, 12, rowMeans)

How can I switch rowMeans with a command that takes the maximum? I am a bit
baffled. Any help will be appreciated. Thank you.

Sincerely,

Milu

###
dput(droplevels(head(x, 5)))
structure(list(X0 = c(295.812103271484, 297.672424316406, 299.006805419922,
297.631500244141, 298.372741699219), X1 = c(295.361328125,
297.345092773438,
298.067504882812, 297.285339355469, 298.275268554688), X2 =
c(294.279602050781,
296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
293.916229248047, 296.129943847656), X4 = c(288.525024414062,
291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
288.393951416016, 291.710266113281), X6 = c(285.550537109375,
288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
291.796203613281, 293.423248291016), X8 = c(292.410003662109,
292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
296.963531494141, 296.036224365234), X10 = c(294.532531738281,
295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
297.627593994141, 297.964935302734), X12 = c(295.986236572266,
297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
297.704925537109, 298.819091796875), X14 = c(294.654327392578,
296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
294.172149658203, 296.117095947266), X16 = c(288.400726318359,
291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
288.105285644531, 291.429382324219), X18 = c(285.971252441406,
288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
291.449066162109, 293.095275878906), X20 = c(291.999877929688,
292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
296.447387695312, 295.824615478516), X22 = c(294.719848632812,
295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
"X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
"X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
"X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Mail
priva di virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 20 16:04:53 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 07:04:53 -0800
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
Message-ID: <CAGxFJbSeJqTyBnXYPkjR_5pLALKE25ae_ZYoWez5AL15ZUM_-g@mail.gmail.com>

?pmax

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 6:55 AM, Miluji Sb <milujisb at gmail.com> wrote:

>  Dear all,
>
> I have monthly data in wide format, I am only providing data (at the bottom
> of the email) for the first 24 columns but I have 2880 columns in total.
>
> I would like to take max of every 12 columns. I have taken the mean of
> every 12 columns with the following code:
>
> byapply <- function(x, by, fun, ...)
> {
>   # Create index list
>   if (length(by) == 1)
>   {
>     nc <- ncol(x)
>     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>   } else # 'by' is a vector of groups
>   {
>     nc <- length(by)
>     split.index <- by
>   }
>   index.list <- split(seq(from = 1, to = nc), split.index)
>
>   # Pass index list to fun using sapply() and return object
>   sapply(index.list, function(i)
>   {
>     do.call(fun, list(x[, i], ...))
>   })
> }
>
> ## Compute annual means
> y <- byapply(df, 12, rowMeans)
>
> How can I switch rowMeans with a command that takes the maximum? I am a bit
> baffled. Any help will be appreciated. Thank you.
>
> Sincerely,
>
> Milu
>
> ###
> dput(droplevels(head(x, 5)))
> structure(list(X0 = c(295.812103271484, 297.672424316406, 299.006805419922,
> 297.631500244141, 298.372741699219), X1 = c(295.361328125,
> 297.345092773438,
> 298.067504882812, 297.285339355469, 298.275268554688), X2 =
> c(294.279602050781,
> 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
> ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
> 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
> 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
> ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
> 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
> 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
> ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
> 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
> 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
> ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
> 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
> 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
> ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
> 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
> 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
> ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
> 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
> 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
> ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
> 294.172149658203, 296.117095947266), X16 = c(288.400726318359,
> 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
> ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
> 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
> 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
> ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
> 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
> 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
> ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
> 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
> 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
> ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
> 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
> "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
> "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
> "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> Mail
> priva di virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Feb 20 16:05:29 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 20 Feb 2018 16:05:29 +0100
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
Message-ID: <CAJuCY5weX=4kTLcjex_fhBpZujWLd9MvGEffWh3ykXagb=zh2w@mail.gmail.com>

The maximum over twelve columns is the maximum of the twelve maxima of
each of the columns.

single_col_max <- apply(x, 2, max)
twelve_col_max <- apply(
  matrix(single_col_max, nrow = 12),
  2,
  max
)

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-20 15:55 GMT+01:00 Miluji Sb <milujisb at gmail.com>:
>  Dear all,
>
> I have monthly data in wide format, I am only providing data (at the bottom
> of the email) for the first 24 columns but I have 2880 columns in total.
>
> I would like to take max of every 12 columns. I have taken the mean of
> every 12 columns with the following code:
>
> byapply <- function(x, by, fun, ...)
> {
>   # Create index list
>   if (length(by) == 1)
>   {
>     nc <- ncol(x)
>     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>   } else # 'by' is a vector of groups
>   {
>     nc <- length(by)
>     split.index <- by
>   }
>   index.list <- split(seq(from = 1, to = nc), split.index)
>
>   # Pass index list to fun using sapply() and return object
>   sapply(index.list, function(i)
>   {
>     do.call(fun, list(x[, i], ...))
>   })
> }
>
> ## Compute annual means
> y <- byapply(df, 12, rowMeans)
>
> How can I switch rowMeans with a command that takes the maximum? I am a bit
> baffled. Any help will be appreciated. Thank you.
>
> Sincerely,
>
> Milu
>
> ###
> dput(droplevels(head(x, 5)))
> structure(list(X0 = c(295.812103271484, 297.672424316406, 299.006805419922,
> 297.631500244141, 298.372741699219), X1 = c(295.361328125,
> 297.345092773438,
> 298.067504882812, 297.285339355469, 298.275268554688), X2 =
> c(294.279602050781,
> 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
> ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
> 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
> 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
> ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
> 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
> 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
> ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
> 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
> 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
> ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
> 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
> 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
> ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
> 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
> 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
> ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
> 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
> 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
> ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
> 294.172149658203, 296.117095947266), X16 = c(288.400726318359,
> 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
> ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
> 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
> 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
> ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
> 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
> 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
> ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
> 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
> 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
> ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
> 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
> "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
> "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
> "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Mail
> priva di virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb 20 16:38:45 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 07:38:45 -0800
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAJuCY5weX=4kTLcjex_fhBpZujWLd9MvGEffWh3ykXagb=zh2w@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CAJuCY5weX=4kTLcjex_fhBpZujWLd9MvGEffWh3ykXagb=zh2w@mail.gmail.com>
Message-ID: <CAGxFJbTNtE6v7tp5N43BEuUc45zRa-g3beGd+7+oaVq2LLruoQ@mail.gmail.com>

Don't do this (sorry Thierry)! max() already does this -- see ?max

> x <- data.frame(a =rnorm(10), b = rnorm(10))
> max(x)
[1] 1.799644

> max(sapply(x,max))
[1] 1.799644

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 7:05 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> The maximum over twelve columns is the maximum of the twelve maxima of
> each of the columns.
>
> single_col_max <- apply(x, 2, max)
> twelve_col_max <- apply(
>   matrix(single_col_max, nrow = 12),
>   2,
>   max
> )
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
>
> 2018-02-20 15:55 GMT+01:00 Miluji Sb <milujisb at gmail.com>:
> >  Dear all,
> >
> > I have monthly data in wide format, I am only providing data (at the
> bottom
> > of the email) for the first 24 columns but I have 2880 columns in total.
> >
> > I would like to take max of every 12 columns. I have taken the mean of
> > every 12 columns with the following code:
> >
> > byapply <- function(x, by, fun, ...)
> > {
> >   # Create index list
> >   if (length(by) == 1)
> >   {
> >     nc <- ncol(x)
> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
> >   } else # 'by' is a vector of groups
> >   {
> >     nc <- length(by)
> >     split.index <- by
> >   }
> >   index.list <- split(seq(from = 1, to = nc), split.index)
> >
> >   # Pass index list to fun using sapply() and return object
> >   sapply(index.list, function(i)
> >   {
> >     do.call(fun, list(x[, i], ...))
> >   })
> > }
> >
> > ## Compute annual means
> > y <- byapply(df, 12, rowMeans)
> >
> > How can I switch rowMeans with a command that takes the maximum? I am a
> bit
> > baffled. Any help will be appreciated. Thank you.
> >
> > Sincerely,
> >
> > Milu
> >
> > ###
> > dput(droplevels(head(x, 5)))
> > structure(list(X0 = c(295.812103271484, 297.672424316406,
> 299.006805419922,
> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
> > 297.345092773438,
> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
> > c(294.279602050781,
> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
> > 294.172149658203, 296.117095947266), X16 = c(288.400726318359,
> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
> >
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > Mail
> > priva di virus. www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Tue Feb 20 16:59:20 2018
From: milujisb at gmail.com (Miluji Sb)
Date: Tue, 20 Feb 2018 16:59:20 +0100
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAGxFJbTNtE6v7tp5N43BEuUc45zRa-g3beGd+7+oaVq2LLruoQ@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CAJuCY5weX=4kTLcjex_fhBpZujWLd9MvGEffWh3ykXagb=zh2w@mail.gmail.com>
 <CAGxFJbTNtE6v7tp5N43BEuUc45zRa-g3beGd+7+oaVq2LLruoQ@mail.gmail.com>
Message-ID: <CAMLwc7OGBZO6yhs5TW05EaGWGZrwktCgyrHR20FfQoWZHLJ68A@mail.gmail.com>

Thank you for your kind replies. Maybe I was not clear with my question (I
apologize) or I did not understand...

I would like to take the max for X0...X11 and X12...X24 in my dataset. When
I use pmax with the function byapply as in

byapply(df, 12, pmax)

I get back a list which I cannot convert to a dataframe. Am I missing
something? Thanks again!

Sincerely,

Milu

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Mail
priva di virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Tue, Feb 20, 2018 at 4:38 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Don't do this (sorry Thierry)! max() already does this -- see ?max
>
> > x <- data.frame(a =rnorm(10), b = rnorm(10))
> > max(x)
> [1] 1.799644
>
> > max(sapply(x,max))
> [1] 1.799644
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Feb 20, 2018 at 7:05 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> The maximum over twelve columns is the maximum of the twelve maxima of
>> each of the columns.
>>
>> single_col_max <- apply(x, 2, max)
>> twelve_col_max <- apply(
>>   matrix(single_col_max, nrow = 12),
>>   2,
>>   max
>> )
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>>
>>
>>
>> 2018-02-20 15:55 GMT+01:00 Miluji Sb <milujisb at gmail.com>:
>> >  Dear all,
>> >
>> > I have monthly data in wide format, I am only providing data (at the
>> bottom
>> > of the email) for the first 24 columns but I have 2880 columns in total.
>> >
>> > I would like to take max of every 12 columns. I have taken the mean of
>> > every 12 columns with the following code:
>> >
>> > byapply <- function(x, by, fun, ...)
>> > {
>> >   # Create index list
>> >   if (length(by) == 1)
>> >   {
>> >     nc <- ncol(x)
>> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>> >   } else # 'by' is a vector of groups
>> >   {
>> >     nc <- length(by)
>> >     split.index <- by
>> >   }
>> >   index.list <- split(seq(from = 1, to = nc), split.index)
>> >
>> >   # Pass index list to fun using sapply() and return object
>> >   sapply(index.list, function(i)
>> >   {
>> >     do.call(fun, list(x[, i], ...))
>> >   })
>> > }
>> >
>> > ## Compute annual means
>> > y <- byapply(df, 12, rowMeans)
>> >
>> > How can I switch rowMeans with a command that takes the maximum? I am a
>> bit
>> > baffled. Any help will be appreciated. Thank you.
>> >
>> > Sincerely,
>> >
>> > Milu
>> >
>> > ###
>> > dput(droplevels(head(x, 5)))
>> > structure(list(X0 = c(295.812103271484, 297.672424316406,
>> 299.006805419922,
>> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
>> > 297.345092773438,
>> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
>> > c(294.279602050781,
>> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
>> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
>> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
>> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
>> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
>> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
>> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
>> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
>> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
>> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
>> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
>> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
>> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
>> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
>> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
>> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
>> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
>> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
>> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
>> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
>> > 294.172149658203, 296.117095947266 <(709)%20594-7266>), X16 =
>> c(288.400726318359,
>> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
>> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
>> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
>> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
>> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
>> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
>> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
>> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
>> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
>> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
>> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
>> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
>> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
>> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
>> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>> >
>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>> =link&utm_campaign=sig-email&utm_content=webmail>
>> > Mail
>> > priva di virus. www.avast.com
>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>> =link&utm_campaign=sig-email&utm_content=webmail>
>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Feb 20 17:10:13 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 20 Feb 2018 11:10:13 -0500
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
Message-ID: <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>

Hi Milu,

byapply(df, 12, function(x) apply(x, 1, max))

You might also be interested in the matrixStats package.

Best,
Ista

On Tue, Feb 20, 2018 at 9:55 AM, Miluji Sb <milujisb at gmail.com> wrote:
>  Dear all,
>
> I have monthly data in wide format, I am only providing data (at the bottom
> of the email) for the first 24 columns but I have 2880 columns in total.
>
> I would like to take max of every 12 columns. I have taken the mean of
> every 12 columns with the following code:
>
> byapply <- function(x, by, fun, ...)
> {
>   # Create index list
>   if (length(by) == 1)
>   {
>     nc <- ncol(x)
>     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>   } else # 'by' is a vector of groups
>   {
>     nc <- length(by)
>     split.index <- by
>   }
>   index.list <- split(seq(from = 1, to = nc), split.index)
>
>   # Pass index list to fun using sapply() and return object
>   sapply(index.list, function(i)
>   {
>     do.call(fun, list(x[, i], ...))
>   })
> }
>
> ## Compute annual means
> y <- byapply(df, 12, rowMeans)
>
> How can I switch rowMeans with a command that takes the maximum? I am a bit
> baffled. Any help will be appreciated. Thank you.
>
> Sincerely,
>
> Milu
>
> ###
> dput(droplevels(head(x, 5)))
> structure(list(X0 = c(295.812103271484, 297.672424316406, 299.006805419922,
> 297.631500244141, 298.372741699219), X1 = c(295.361328125,
> 297.345092773438,
> 298.067504882812, 297.285339355469, 298.275268554688), X2 =
> c(294.279602050781,
> 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
> ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
> 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
> 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
> ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
> 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
> 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
> ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
> 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
> 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
> ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
> 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
> 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
> ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
> 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
> 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
> ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
> 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
> 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
> ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
> 294.172149658203, 296.117095947266), X16 = c(288.400726318359,
> 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
> ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
> 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
> 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
> ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
> 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
> 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
> ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
> 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
> 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
> ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
> 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
> "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
> "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
> "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Mail
> priva di virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb 20 17:10:52 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 08:10:52 -0800
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAMLwc7OGBZO6yhs5TW05EaGWGZrwktCgyrHR20FfQoWZHLJ68A@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CAJuCY5weX=4kTLcjex_fhBpZujWLd9MvGEffWh3ykXagb=zh2w@mail.gmail.com>
 <CAGxFJbTNtE6v7tp5N43BEuUc45zRa-g3beGd+7+oaVq2LLruoQ@mail.gmail.com>
 <CAMLwc7OGBZO6yhs5TW05EaGWGZrwktCgyrHR20FfQoWZHLJ68A@mail.gmail.com>
Message-ID: <CAGxFJbT9gwngfJ0LVPh88vNw2NZ1VH+VzvtBaE06Z0ypir9wEQ@mail.gmail.com>

 Do you want the max of all the data in all 12 columns -- 1 number -- or
the parallel max of the 12 columns -- a vector of length the number of rows.

In the first case,
max(df[,1:12])
will do (R uses 1-based indexing,not 0-based) ;

in the second case,
pmax(df[, 1:12])
will do.

If either of these is what you want, all your code is nonsense. Of course
you can change the indexing to march through the data frame in whatever way
you like. If this is not what you want, maybe someone wiser than I can
interpret your query.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 7:59 AM, Miluji Sb <milujisb at gmail.com> wrote:

> Thank you for your kind replies. Maybe I was not clear with my question (I
> apologize) or I did not understand...
>
> I would like to take the max for X0...X11 and X12...X24 in my dataset.
> When I use pmax with the function byapply as in
>
> byapply(df, 12, pmax)
>
> I get back a list which I cannot convert to a dataframe. Am I missing
> something? Thanks again!
>
> Sincerely,
>
> Milu
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Mail
> priva di virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#m_-2971460967079739222_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> On Tue, Feb 20, 2018 at 4:38 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Don't do this (sorry Thierry)! max() already does this -- see ?max
>>
>> > x <- data.frame(a =rnorm(10), b = rnorm(10))
>> > max(x)
>> [1] 1.799644
>>
>> > max(sapply(x,max))
>> [1] 1.799644
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Tue, Feb 20, 2018 at 7:05 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> The maximum over twelve columns is the maximum of the twelve maxima of
>>> each of the columns.
>>>
>>> single_col_max <- apply(x, 2, max)
>>> twelve_col_max <- apply(
>>>   matrix(single_col_max, nrow = 12),
>>>   2,
>>>   max
>>> )
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given body
>>> of data. ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>>
>>>
>>>
>>> 2018-02-20 15:55 GMT+01:00 Miluji Sb <milujisb at gmail.com>:
>>> >  Dear all,
>>> >
>>> > I have monthly data in wide format, I am only providing data (at the
>>> bottom
>>> > of the email) for the first 24 columns but I have 2880 columns in
>>> total.
>>> >
>>> > I would like to take max of every 12 columns. I have taken the mean of
>>> > every 12 columns with the following code:
>>> >
>>> > byapply <- function(x, by, fun, ...)
>>> > {
>>> >   # Create index list
>>> >   if (length(by) == 1)
>>> >   {
>>> >     nc <- ncol(x)
>>> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>>> >   } else # 'by' is a vector of groups
>>> >   {
>>> >     nc <- length(by)
>>> >     split.index <- by
>>> >   }
>>> >   index.list <- split(seq(from = 1, to = nc), split.index)
>>> >
>>> >   # Pass index list to fun using sapply() and return object
>>> >   sapply(index.list, function(i)
>>> >   {
>>> >     do.call(fun, list(x[, i], ...))
>>> >   })
>>> > }
>>> >
>>> > ## Compute annual means
>>> > y <- byapply(df, 12, rowMeans)
>>> >
>>> > How can I switch rowMeans with a command that takes the maximum? I am
>>> a bit
>>> > baffled. Any help will be appreciated. Thank you.
>>> >
>>> > Sincerely,
>>> >
>>> > Milu
>>> >
>>> > ###
>>> > dput(droplevels(head(x, 5)))
>>> > structure(list(X0 = c(295.812103271484, 297.672424316406,
>>> 299.006805419922,
>>> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
>>> > 297.345092773438,
>>> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
>>> > c(294.279602050781,
>>> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
>>> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
>>> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
>>> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
>>> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
>>> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
>>> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
>>> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
>>> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
>>> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
>>> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
>>> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
>>> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
>>> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
>>> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
>>> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
>>> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
>>> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
>>> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
>>> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
>>> > 294.172149658203, 296.117095947266 <(709)%20594-7266>), X16 =
>>> c(288.400726318359,
>>> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
>>> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
>>> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
>>> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
>>> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
>>> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
>>> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
>>> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
>>> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
>>> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
>>> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
>>> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
>>> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
>>> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
>>> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>>> >
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>> > Mail
>>> > priva di virus. www.avast.com
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Tue Feb 20 17:16:49 2018
From: milujisb at gmail.com (Miluji Sb)
Date: Tue, 20 Feb 2018 17:16:49 +0100
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>
Message-ID: <CAMLwc7M-g51TOgnTLmshs_OY7wMSBNNier198WVrCVQ=57JYgw@mail.gmail.com>

This is what I was looking for. Thank you everyone!

Sincerely,

Milu

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Mail
priva di virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Tue, Feb 20, 2018 at 5:10 PM, Ista Zahn <istazahn at gmail.com> wrote:

> Hi Milu,
>
> byapply(df, 12, function(x) apply(x, 1, max))
>
> You might also be interested in the matrixStats package.
>
> Best,
> Ista
>
> On Tue, Feb 20, 2018 at 9:55 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >  Dear all,
> >
> > I have monthly data in wide format, I am only providing data (at the
> bottom
> > of the email) for the first 24 columns but I have 2880 columns in total.
> >
> > I would like to take max of every 12 columns. I have taken the mean of
> > every 12 columns with the following code:
> >
> > byapply <- function(x, by, fun, ...)
> > {
> >   # Create index list
> >   if (length(by) == 1)
> >   {
> >     nc <- ncol(x)
> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
> >   } else # 'by' is a vector of groups
> >   {
> >     nc <- length(by)
> >     split.index <- by
> >   }
> >   index.list <- split(seq(from = 1, to = nc), split.index)
> >
> >   # Pass index list to fun using sapply() and return object
> >   sapply(index.list, function(i)
> >   {
> >     do.call(fun, list(x[, i], ...))
> >   })
> > }
> >
> > ## Compute annual means
> > y <- byapply(df, 12, rowMeans)
> >
> > How can I switch rowMeans with a command that takes the maximum? I am a
> bit
> > baffled. Any help will be appreciated. Thank you.
> >
> > Sincerely,
> >
> > Milu
> >
> > ###
> > dput(droplevels(head(x, 5)))
> > structure(list(X0 = c(295.812103271484, 297.672424316406,
> 299.006805419922,
> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
> > 297.345092773438,
> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
> > c(294.279602050781,
> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
> > 294.172149658203, 296.117095947266), X16 = c(288.400726318359,
> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
> >
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > Mail
> > priva di virus. www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 20 17:58:52 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 08:58:52 -0800
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAMLwc7M-g51TOgnTLmshs_OY7wMSBNNier198WVrCVQ=57JYgw@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>
 <CAMLwc7M-g51TOgnTLmshs_OY7wMSBNNier198WVrCVQ=57JYgw@mail.gmail.com>
Message-ID: <CAGxFJbQ5qR_fiH_xwfTP9M11J1--WFYOVha3zFNQDZoeRR--3Q@mail.gmail.com>

Ista, et. al: efficiency?
(Note: I needed to correct my previous post: do.call() is required for
pmax() over the data frame)

> x <- data.frame(matrix(runif(12e6), ncol=12))

> system.time(r1 <- do.call(pmax,x))
   user  system elapsed
  0.049   0.000   0.049

> identical(r1,r2)
[1] FALSE
> system.time(r2 <- apply(x,1,max))
   user  system elapsed
  2.162   0.045   2.207

## 150 times slower!

> identical(r1,r2)
[1] TRUE

pmax() is there for a reason.
Or is there something I am missing?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 8:16 AM, Miluji Sb <milujisb at gmail.com> wrote:

> This is what I was looking for. Thank you everyone!
>
> Sincerely,
>
> Milu
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Mail
> priva di virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#m_6071581590498622123_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> On Tue, Feb 20, 2018 at 5:10 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
>> Hi Milu,
>>
>> byapply(df, 12, function(x) apply(x, 1, max))
>>
>> You might also be interested in the matrixStats package.
>>
>> Best,
>> Ista
>>
>> On Tue, Feb 20, 2018 at 9:55 AM, Miluji Sb <milujisb at gmail.com> wrote:
>> >  Dear all,
>> >
>> > I have monthly data in wide format, I am only providing data (at the
>> bottom
>> > of the email) for the first 24 columns but I have 2880 columns in total.
>> >
>> > I would like to take max of every 12 columns. I have taken the mean of
>> > every 12 columns with the following code:
>> >
>> > byapply <- function(x, by, fun, ...)
>> > {
>> >   # Create index list
>> >   if (length(by) == 1)
>> >   {
>> >     nc <- ncol(x)
>> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>> >   } else # 'by' is a vector of groups
>> >   {
>> >     nc <- length(by)
>> >     split.index <- by
>> >   }
>> >   index.list <- split(seq(from = 1, to = nc), split.index)
>> >
>> >   # Pass index list to fun using sapply() and return object
>> >   sapply(index.list, function(i)
>> >   {
>> >     do.call(fun, list(x[, i], ...))
>> >   })
>> > }
>> >
>> > ## Compute annual means
>> > y <- byapply(df, 12, rowMeans)
>> >
>> > How can I switch rowMeans with a command that takes the maximum? I am a
>> bit
>> > baffled. Any help will be appreciated. Thank you.
>> >
>> > Sincerely,
>> >
>> > Milu
>> >
>> > ###
>> > dput(droplevels(head(x, 5)))
>> > structure(list(X0 = c(295.812103271484, 297.672424316406,
>> 299.006805419922,
>> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
>> > 297.345092773438,
>> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
>> > c(294.279602050781,
>> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
>> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
>> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
>> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
>> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
>> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
>> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
>> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
>> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
>> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
>> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
>> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
>> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
>> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
>> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
>> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
>> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
>> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
>> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
>> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
>> > 294.172149658203, 296.117095947266 <(709)%20594-7266>), X16 =
>> c(288.400726318359,
>> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
>> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
>> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
>> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
>> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
>> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
>> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
>> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
>> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
>> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
>> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
>> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
>> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
>> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
>> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>> >
>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>> =link&utm_campaign=sig-email&utm_content=webmail>
>> > Mail
>> > priva di virus. www.avast.com
>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>> =link&utm_campaign=sig-email&utm_content=webmail>
>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 20 18:00:09 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 09:00:09 -0800
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAGxFJbQ5qR_fiH_xwfTP9M11J1--WFYOVha3zFNQDZoeRR--3Q@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>
 <CAMLwc7M-g51TOgnTLmshs_OY7wMSBNNier198WVrCVQ=57JYgw@mail.gmail.com>
 <CAGxFJbQ5qR_fiH_xwfTP9M11J1--WFYOVha3zFNQDZoeRR--3Q@mail.gmail.com>
Message-ID: <CAGxFJbQdU9CrkOenX5UgnGLMPUQQojJQqsccBGvEebo=vG7DZw@mail.gmail.com>

Sorry, previous code should be:

> x <- data.frame(matrix(runif(12e6), ncol=12))
> system.time(r1 <- do.call(pmax,x))
   user  system elapsed
  0.049   0.000   0.049

> system.time(r2 <- apply(x,1,max))
   user  system elapsed
  2.162   0.045   2.207

> identical(r1,r2)
[1] TRUE

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 8:58 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Ista, et. al: efficiency?
> (Note: I needed to correct my previous post: do.call() is required for
> pmax() over the data frame)
>
> > x <- data.frame(matrix(runif(12e6), ncol=12))
>
> > system.time(r1 <- do.call(pmax,x))
>    user  system elapsed
>   0.049   0.000   0.049
>
> > identical(r1,r2)
> [1] FALSE
> > system.time(r2 <- apply(x,1,max))
>    user  system elapsed
>   2.162   0.045   2.207
>
> ## 150 times slower!
>
> > identical(r1,r2)
> [1] TRUE
>
> pmax() is there for a reason.
> Or is there something I am missing?
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Feb 20, 2018 at 8:16 AM, Miluji Sb <milujisb at gmail.com> wrote:
>
>> This is what I was looking for. Thank you everyone!
>>
>> Sincerely,
>>
>> Milu
>>
>>
>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Mail
>> priva di virus. www.avast.com
>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>> <#m_7564601492398332906_m_6071581590498622123_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>> On Tue, Feb 20, 2018 at 5:10 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>>> Hi Milu,
>>>
>>> byapply(df, 12, function(x) apply(x, 1, max))
>>>
>>> You might also be interested in the matrixStats package.
>>>
>>> Best,
>>> Ista
>>>
>>> On Tue, Feb 20, 2018 at 9:55 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>> >  Dear all,
>>> >
>>> > I have monthly data in wide format, I am only providing data (at the
>>> bottom
>>> > of the email) for the first 24 columns but I have 2880 columns in
>>> total.
>>> >
>>> > I would like to take max of every 12 columns. I have taken the mean of
>>> > every 12 columns with the following code:
>>> >
>>> > byapply <- function(x, by, fun, ...)
>>> > {
>>> >   # Create index list
>>> >   if (length(by) == 1)
>>> >   {
>>> >     nc <- ncol(x)
>>> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>>> >   } else # 'by' is a vector of groups
>>> >   {
>>> >     nc <- length(by)
>>> >     split.index <- by
>>> >   }
>>> >   index.list <- split(seq(from = 1, to = nc), split.index)
>>> >
>>> >   # Pass index list to fun using sapply() and return object
>>> >   sapply(index.list, function(i)
>>> >   {
>>> >     do.call(fun, list(x[, i], ...))
>>> >   })
>>> > }
>>> >
>>> > ## Compute annual means
>>> > y <- byapply(df, 12, rowMeans)
>>> >
>>> > How can I switch rowMeans with a command that takes the maximum? I am
>>> a bit
>>> > baffled. Any help will be appreciated. Thank you.
>>> >
>>> > Sincerely,
>>> >
>>> > Milu
>>> >
>>> > ###
>>> > dput(droplevels(head(x, 5)))
>>> > structure(list(X0 = c(295.812103271484, 297.672424316406,
>>> 299.006805419922,
>>> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
>>> > 297.345092773438,
>>> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
>>> > c(294.279602050781,
>>> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
>>> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
>>> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
>>> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
>>> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
>>> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
>>> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
>>> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
>>> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
>>> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
>>> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
>>> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
>>> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
>>> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
>>> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
>>> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
>>> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
>>> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
>>> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
>>> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
>>> > 294.172149658203, 296.117095947266 <(709)%20594-7266>), X16 =
>>> c(288.400726318359,
>>> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
>>> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
>>> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
>>> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
>>> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
>>> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
>>> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
>>> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
>>> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
>>> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
>>> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
>>> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
>>> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
>>> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
>>> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>>> >
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>> > Mail
>>> > priva di virus. www.avast.com
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Feb 20 19:00:26 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 20 Feb 2018 13:00:26 -0500
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAGxFJbQ5qR_fiH_xwfTP9M11J1--WFYOVha3zFNQDZoeRR--3Q@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>
 <CAMLwc7M-g51TOgnTLmshs_OY7wMSBNNier198WVrCVQ=57JYgw@mail.gmail.com>
 <CAGxFJbQ5qR_fiH_xwfTP9M11J1--WFYOVha3zFNQDZoeRR--3Q@mail.gmail.com>
Message-ID: <CA+vqiLFS2Z3r4KCDbyP0PAmm4eB2hkTFNxkTtmjAX4ny+zeCTg@mail.gmail.com>

On Tue, Feb 20, 2018 at 11:58 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> Ista, et. al: efficiency?
> (Note: I needed to correct my previous post: do.call() is required for
> pmax() over the data frame)
>
> > x <- data.frame(matrix(runif(12e6), ncol=12))
>
> > system.time(r1 <- do.call(pmax,x))
>    user  system elapsed
>   0.049   0.000   0.049
>
> > identical(r1,r2)
> [1] FALSE
> > system.time(r2 <- apply(x,1,max))
>    user  system elapsed
>   2.162   0.045   2.207
>
> ## 150 times slower!
>
> > identical(r1,r2)
> [1] TRUE
>
> pmax() is there for a reason.
> Or is there something I am missing?
>


?Personal preference I think. I prefer the consistency of apply. If speed
is an issue matrixStats is both consistent and fast:?

?library(matrixStats)
x <- matrix(runif(12e6), ncol=12)

system.time(r1 <- do.call(pmax,as.data.frame(x)))
  ##  user  system elapsed
  ## 0.109   0.000   0.109
system.time(r2 <- apply(x,1,max))
  ##  user  system elapsed
  ## 1.292   0.024   1.321
system.time(r3 <- rowMaxs(x))
  ##  user  system elapsed
  ## 0.044   0.000   0.044
?
?pmax is a fine alternative? for max special case.

Best,
Ista



>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Feb 20, 2018 at 8:16 AM, Miluji Sb <milujisb at gmail.com> wrote:
>
>> This is what I was looking for. Thank you everyone!
>>
>> Sincerely,
>>
>> Milu
>>
>>
>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Mail
>> priva di virus. www.avast.com
>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>> <#m_4297398466082743447_m_6071581590498622123_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>> On Tue, Feb 20, 2018 at 5:10 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>
>>> Hi Milu,
>>>
>>> byapply(df, 12, function(x) apply(x, 1, max))
>>>
>>> You might also be interested in the matrixStats package.
>>>
>>> Best,
>>> Ista
>>>
>>> On Tue, Feb 20, 2018 at 9:55 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>> >  Dear all,
>>> >
>>> > I have monthly data in wide format, I am only providing data (at the
>>> bottom
>>> > of the email) for the first 24 columns but I have 2880 columns in
>>> total.
>>> >
>>> > I would like to take max of every 12 columns. I have taken the mean of
>>> > every 12 columns with the following code:
>>> >
>>> > byapply <- function(x, by, fun, ...)
>>> > {
>>> >   # Create index list
>>> >   if (length(by) == 1)
>>> >   {
>>> >     nc <- ncol(x)
>>> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>>> >   } else # 'by' is a vector of groups
>>> >   {
>>> >     nc <- length(by)
>>> >     split.index <- by
>>> >   }
>>> >   index.list <- split(seq(from = 1, to = nc), split.index)
>>> >
>>> >   # Pass index list to fun using sapply() and return object
>>> >   sapply(index.list, function(i)
>>> >   {
>>> >     do.call(fun, list(x[, i], ...))
>>> >   })
>>> > }
>>> >
>>> > ## Compute annual means
>>> > y <- byapply(df, 12, rowMeans)
>>> >
>>> > How can I switch rowMeans with a command that takes the maximum? I am
>>> a bit
>>> > baffled. Any help will be appreciated. Thank you.
>>> >
>>> > Sincerely,
>>> >
>>> > Milu
>>> >
>>> > ###
>>> > dput(droplevels(head(x, 5)))
>>> > structure(list(X0 = c(295.812103271484, 297.672424316406,
>>> 299.006805419922,
>>> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
>>> > 297.345092773438,
>>> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
>>> > c(294.279602050781,
>>> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
>>> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
>>> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
>>> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
>>> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
>>> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
>>> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
>>> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
>>> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
>>> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
>>> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
>>> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
>>> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
>>> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
>>> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
>>> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
>>> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
>>> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
>>> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
>>> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
>>> > 294.172149658203, 296.117095947266 <(709)%20594-7266>), X16 =
>>> c(288.400726318359,
>>> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
>>> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
>>> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
>>> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
>>> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
>>> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
>>> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
>>> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
>>> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
>>> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
>>> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
>>> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
>>> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
>>> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
>>> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>>> >
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>> > Mail
>>> > priva di virus. www.avast.com
>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From dungnguyen.ivi at gmail.com  Tue Feb 20 20:44:12 2018
From: dungnguyen.ivi at gmail.com (Dung Nguyen)
Date: Tue, 20 Feb 2018 20:44:12 +0100
Subject: [R] "Within" model in plm package: is the reported R-squared
 correct?
Message-ID: <CAGY_TUbU-hxmq8c0qXUFKqOvzSKze9veD4nnq7wFRiBy78faPA@mail.gmail.com>

Hi everyone,

I am doing panel data analysis using the 'plm' package. However, I have
noticed that the plm() function reports a different value of R-squared from
the R-squared of the lm() function with time-demeaned data. To be clear, I
have tried to compute the within model both manually (run an OLS regression
with time-demeaned data using lm()) and by using plm(). The two methods
give me 2 different values of R-squared and I am not sure which one is the
correct one for the fixed-effect estimation.

I am new to R and panel data analysis thus it will be so great if someone
can explain the difference to me.

Thank you in advance.

Bests,

MiYung

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 20 21:58:18 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 12:58:18 -0800
Subject: [R] "Within" model in plm package: is the reported R-squared
 correct?
In-Reply-To: <CAGY_TUbU-hxmq8c0qXUFKqOvzSKze9veD4nnq7wFRiBy78faPA@mail.gmail.com>
References: <CAGY_TUbU-hxmq8c0qXUFKqOvzSKze9veD4nnq7wFRiBy78faPA@mail.gmail.com>
Message-ID: <CAGxFJbQc63LdnQe7yLU8=dHoy19sZ4A8vsfOS0OmY9UVJ+VW9A@mail.gmail.com>

Generally speaking, statistical questions are O/T here, but sometimes they
intersect with on-topic R programming issues and do get responses. So if
you do not get a response here, try a statistics forum, like
stats.stackexchange.com  .

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 11:44 AM, Dung Nguyen <dungnguyen.ivi at gmail.com>
wrote:

> Hi everyone,
>
> I am doing panel data analysis using the 'plm' package. However, I have
> noticed that the plm() function reports a different value of R-squared from
> the R-squared of the lm() function with time-demeaned data. To be clear, I
> have tried to compute the within model both manually (run an OLS regression
> with time-demeaned data using lm()) and by using plm(). The two methods
> give me 2 different values of R-squared and I am not sure which one is the
> correct one for the fixed-effect estimation.
>
> I am new to R and panel data analysis thus it will be so great if someone
> can explain the difference to me.
>
> Thank you in advance.
>
> Bests,
>
> MiYung
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Tue Feb 20 22:12:32 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 20 Feb 2018 13:12:32 -0800
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CA+vqiLFS2Z3r4KCDbyP0PAmm4eB2hkTFNxkTtmjAX4ny+zeCTg@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>
 <CAMLwc7M-g51TOgnTLmshs_OY7wMSBNNier198WVrCVQ=57JYgw@mail.gmail.com>
 <CAGxFJbQ5qR_fiH_xwfTP9M11J1--WFYOVha3zFNQDZoeRR--3Q@mail.gmail.com>
 <CA+vqiLFS2Z3r4KCDbyP0PAmm4eB2hkTFNxkTtmjAX4ny+zeCTg@mail.gmail.com>
Message-ID: <CAFDcVCT_VmGwYg4R71aRyraDxA1qcC4Birk2xt55ym6ufoY1NA@mail.gmail.com>

It looks like OP uses a data.frame, so in order to use matrixStats
(I'm the author) one would have to pay the price to coerce to a matrix
before using matrixStats::rowMaxs().  However, if it is that the
original data could equally well live in a matrix, then matrixStats
should be computational efficient for this task.  (I've seen cases
where an original matrix was turned into a data.frame just because
that is what is commonly used elsewhere and because the user may not
pay attention to the differences between matrices and data.frame.)

If the original data would be a matrix 'X', then one can do the
following with matrixStats:

Y <- sapply(seq(from = 0, to = 2880, by = 12), FUN = function(offset) {
   rowMaxs(X, cols = offset + 1:12)
})

which avoids internal temporary copies required when using regular
subsetting, e.g.

Y <- sapply(seq(from = 0, to = 2880, by = 12), FUN = function(offset) {
   rowMaxs(X[, offset + 1:12])
})

Subsetting data frames by columns is already efficient, so the same
argument does not apply there.

/Henrik

On Tue, Feb 20, 2018 at 10:00 AM, Ista Zahn <istazahn at gmail.com> wrote:
> On Tue, Feb 20, 2018 at 11:58 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Ista, et. al: efficiency?
>> (Note: I needed to correct my previous post: do.call() is required for
>> pmax() over the data frame)
>>
>> > x <- data.frame(matrix(runif(12e6), ncol=12))
>>
>> > system.time(r1 <- do.call(pmax,x))
>>    user  system elapsed
>>   0.049   0.000   0.049
>>
>> > identical(r1,r2)
>> [1] FALSE
>> > system.time(r2 <- apply(x,1,max))
>>    user  system elapsed
>>   2.162   0.045   2.207
>>
>> ## 150 times slower!
>>
>> > identical(r1,r2)
>> [1] TRUE
>>
>> pmax() is there for a reason.
>> Or is there something I am missing?
>>
>
>
> Personal preference I think. I prefer the consistency of apply. If speed
> is an issue matrixStats is both consistent and fast:
>
> library(matrixStats)
> x <- matrix(runif(12e6), ncol=12)
>
> system.time(r1 <- do.call(pmax,as.data.frame(x)))
>   ##  user  system elapsed
>   ## 0.109   0.000   0.109
> system.time(r2 <- apply(x,1,max))
>   ##  user  system elapsed
>   ## 1.292   0.024   1.321
> system.time(r3 <- rowMaxs(x))
>   ##  user  system elapsed
>   ## 0.044   0.000   0.044
>
> pmax is a fine alternative for max special case.
>
> Best,
> Ista
>
>
>
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Tue, Feb 20, 2018 at 8:16 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>
>>> This is what I was looking for. Thank you everyone!
>>>
>>> Sincerely,
>>>
>>> Milu
>>>
>>>
>>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Mail
>>> priva di virus. www.avast.com
>>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>>> <#m_4297398466082743447_m_6071581590498622123_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>>
>>> On Tue, Feb 20, 2018 at 5:10 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>>
>>>> Hi Milu,
>>>>
>>>> byapply(df, 12, function(x) apply(x, 1, max))
>>>>
>>>> You might also be interested in the matrixStats package.
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>> On Tue, Feb 20, 2018 at 9:55 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>>> >  Dear all,
>>>> >
>>>> > I have monthly data in wide format, I am only providing data (at the
>>>> bottom
>>>> > of the email) for the first 24 columns but I have 2880 columns in
>>>> total.
>>>> >
>>>> > I would like to take max of every 12 columns. I have taken the mean of
>>>> > every 12 columns with the following code:
>>>> >
>>>> > byapply <- function(x, by, fun, ...)
>>>> > {
>>>> >   # Create index list
>>>> >   if (length(by) == 1)
>>>> >   {
>>>> >     nc <- ncol(x)
>>>> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out = nc)
>>>> >   } else # 'by' is a vector of groups
>>>> >   {
>>>> >     nc <- length(by)
>>>> >     split.index <- by
>>>> >   }
>>>> >   index.list <- split(seq(from = 1, to = nc), split.index)
>>>> >
>>>> >   # Pass index list to fun using sapply() and return object
>>>> >   sapply(index.list, function(i)
>>>> >   {
>>>> >     do.call(fun, list(x[, i], ...))
>>>> >   })
>>>> > }
>>>> >
>>>> > ## Compute annual means
>>>> > y <- byapply(df, 12, rowMeans)
>>>> >
>>>> > How can I switch rowMeans with a command that takes the maximum? I am
>>>> a bit
>>>> > baffled. Any help will be appreciated. Thank you.
>>>> >
>>>> > Sincerely,
>>>> >
>>>> > Milu
>>>> >
>>>> > ###
>>>> > dput(droplevels(head(x, 5)))
>>>> > structure(list(X0 = c(295.812103271484, 297.672424316406,
>>>> 299.006805419922,
>>>> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
>>>> > 297.345092773438,
>>>> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
>>>> > c(294.279602050781,
>>>> > 296.401550292969, 296.777984619141, 296.089111328125, 297.540374755859
>>>> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
>>>> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
>>>> > 291.274505615234, 289.502777099609, 290.723388671875, 293.615112304688
>>>> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
>>>> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
>>>> > 288.159149169922, 285.976501464844, 287.999816894531, 291.228271484375
>>>> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
>>>> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
>>>> > 292.701263427734, 294.25244140625, 295.320404052734, 295.248199462891
>>>> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
>>>> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
>>>> > 295.366607666016, 297.677551269531, 296.715911865234, 296.564178466797
>>>> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
>>>> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
>>>> > 297.675567626953, 299.056671142578, 297.598907470703, 298.481842041016
>>>> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
>>>> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
>>>> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
>>>> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
>>>> > 294.172149658203, 296.117095947266 <(709)%20594-7266>), X16 =
>>>> c(288.400726318359,
>>>> > 291.029113769531, 289.361907958984, 290.566772460938, 293.554016113281
>>>> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
>>>> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
>>>> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
>>>> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
>>>> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
>>>> > 292.838348388672, 293.840362548828, 294.412322998047, 294.941253662109
>>>> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
>>>> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
>>>> > 295.392028808594, 297.453216552734, 297.114288330078, 296.883209228516
>>>> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
>>>> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
>>>> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
>>>> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
>>>> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
>>>> >
>>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>>> > Mail
>>>> > priva di virus. www.avast.com
>>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
>>>> =link&utm_campaign=sig-email&utm_content=webmail>
>>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hannahvnoort at gmail.com  Tue Feb 20 22:19:59 2018
From: hannahvnoort at gmail.com (Hannah van Noort)
Date: Tue, 20 Feb 2018 22:19:59 +0100
Subject: [R] question regarding the AICcmodavg package
Message-ID: <CAO1bxth_VL3KOVy4OySM_gvdLzjCY3zA7kphaz-ps8ajLAHxXA@mail.gmail.com>

Dear moderator,

If possible I would like to send in the following question for R-help:

I am analyzing a small data set using PGLS with phylogenetic uncertainty
taken into account and thereby including 100 potential phylogenetic tree
scenarios. I've managed to run models on all of the different trees and
performed model averaging to get parameter estimates for the intercept and
most of the predictor variable slopes using the *AICcmodavg* package and
*APE*, but I seem to get stuck with some of the variables that are also
included in a two-way interaction in the model. I can obtain values for the
two-way interaction but not for the variables separately.

The error I receive is:

?Error in modavg.AICgls(parm = "agefirstbreed", cand.set = Cand.models4, :

Some models include more than one instance of the parameter of interest.
This may be due to the presence of interaction/polynomial terms, or
variables with similar names: see "?modavg" for details on variable
specification and "exclude" argument?



I'm familiar with the *exclude* function of the *AICcmodavg* package, but
this only works when different models have been specified including ones
without these specific two-way interactions and my models are all similar
with regards to the interactions, only the phylogenetic tree scenarios
differ.



I was wondering if there is another method to obtain these averaged
parameter estimates for the concerning predictor variable slopes? Not
excluding the (significant) two-way interaction in which they are also
involved?
Thank you in advance for your reply.

Kind regards,

Hannah van Noort

	[[alternative HTML version deleted]]


From cadeb at usgs.gov  Tue Feb 20 22:57:01 2018
From: cadeb at usgs.gov (Cade, Brian)
Date: Tue, 20 Feb 2018 14:57:01 -0700
Subject: [R] question regarding the AICcmodavg package
In-Reply-To: <CAO1bxth_VL3KOVy4OySM_gvdLzjCY3zA7kphaz-ps8ajLAHxXA@mail.gmail.com>
References: <CAO1bxth_VL3KOVy4OySM_gvdLzjCY3zA7kphaz-ps8ajLAHxXA@mail.gmail.com>
Message-ID: <CAM5M9BQeV9O6K8vPs_vifUsLuGHJGCtRgFmytpTJrDZ3xsb6TQ@mail.gmail.com>

Do not model average the regression coefficients.  This makes no sense (see
Cade 2015.  Model averaging and muddled multimodel inferences).  And, no
there is no reasonable way to model average regression coefficients ala
Burnham and Anderson approach when some of your models include interactions
among predictors and some don't.  Stick to model averaging the predicted
responses and you can do something that is sensible and that can be applied
to any combination of predictor variables including those with interactions.

Brian Cade

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Tue, Feb 20, 2018 at 2:19 PM, Hannah van Noort <hannahvnoort at gmail.com>
wrote:

> Dear moderator,
>
> If possible I would like to send in the following question for R-help:
>
> I am analyzing a small data set using PGLS with phylogenetic uncertainty
> taken into account and thereby including 100 potential phylogenetic tree
> scenarios. I've managed to run models on all of the different trees and
> performed model averaging to get parameter estimates for the intercept and
> most of the predictor variable slopes using the *AICcmodavg* package and
> *APE*, but I seem to get stuck with some of the variables that are also
> included in a two-way interaction in the model. I can obtain values for the
> two-way interaction but not for the variables separately.
>
> The error I receive is:
>
> ?Error in modavg.AICgls(parm = "agefirstbreed", cand.set = Cand.models4, :
>
> Some models include more than one instance of the parameter of interest.
> This may be due to the presence of interaction/polynomial terms, or
> variables with similar names: see "?modavg" for details on variable
> specification and "exclude" argument?
>
>
>
> I'm familiar with the *exclude* function of the *AICcmodavg* package, but
> this only works when different models have been specified including ones
> without these specific two-way interactions and my models are all similar
> with regards to the interactions, only the phylogenetic tree scenarios
> differ.
>
>
>
> I was wondering if there is another method to obtain these averaged
> parameter estimates for the concerning predictor variable slopes? Not
> excluding the (significant) two-way interaction in which they are also
> involved?
> Thank you in advance for your reply.
>
> Kind regards,
>
> Hannah van Noort
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Tue Feb 20 23:36:50 2018
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Tue, 20 Feb 2018 16:36:50 -0600
Subject: [R] deparseDots to get names of all arguments?
Message-ID: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>

Hi, All:


 ????? How can I get the names of all the arguments in dots(...)?


 ????? I'm able to get the name of the first argument but not the second:



deparseDots <- function(...){
 ? deparse(substitute(...))
}
a <- 1
b <- 2
deparseDots(a, b)
[1] "a"


 ????? I'd like to get c('a', 'b').


 ????? Thanks,
 ????? Spencer Graves


 > sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS High Sierra 10.13.3

Matrix products: default
BLAS: 
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: 
/Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

loaded via a namespace (and not attached):
[1] compiler_3.4.3 tools_3.4.3??? yaml_2.1.16


From r.turner at auckland.ac.nz  Tue Feb 20 23:47:39 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 21 Feb 2018 11:47:39 +1300
Subject: [R] deparseDots to get names of all arguments?
In-Reply-To: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
References: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
Message-ID: <d3324bab-de5a-244d-6e83-3474cb6638a8@auckland.ac.nz>

On 21/02/18 11:36, Spencer Graves wrote:
> Hi, All:
> 
> 
>  ????? How can I get the names of all the arguments in dots(...)?
> 
> 
>  ????? I'm able to get the name of the first argument but not the second:
> 
> 
> 
> deparseDots <- function(...){
>  ? deparse(substitute(...))
> }
> a <- 1
> b <- 2
> deparseDots(a, b)
> [1] "a"
> 
>  >  ????? I'd like to get c('a', 'b').

Does

     names(list(...))

do what you want?

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Wed Feb 21 01:00:19 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 20 Feb 2018 19:00:19 -0500
Subject: [R] deparseDots to get names of all arguments?
In-Reply-To: <d3324bab-de5a-244d-6e83-3474cb6638a8@auckland.ac.nz>
References: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
 <d3324bab-de5a-244d-6e83-3474cb6638a8@auckland.ac.nz>
Message-ID: <f6560e8e-546c-5480-9acc-920ed07e8666@gmail.com>

On 20/02/2018 5:47 PM, Rolf Turner wrote:
> On 21/02/18 11:36, Spencer Graves wrote:
>> Hi, All:
>>
>>
>>   ????? How can I get the names of all the arguments in dots(...)?
>>
>>
>>   ????? I'm able to get the name of the first argument but not the second:
>>
>>
>>
>> deparseDots <- function(...){
>>   ? deparse(substitute(...))
>> }
>> a <- 1
>> b <- 2
>> deparseDots(a, b)
>> [1] "a"
>>
>>   >  ????? I'd like to get c('a', 'b').
> 
> Does
> 
>       names(list(...))
> 
> do what you want?

No, that does what he asked for, not what he wants :-).  Spencer, you 
want to deparse all of the expressions in ..., not their names.

I think base R doesn't have a way to do this (but I may be wrong).  You 
can do it using some the rlang package.  For example, this seems to work:

deparseDots <- function(...) {
   unname(sapply(rlang::exprs(...), deparse))
}

Duncan Murdoch


From bgunter.4567 at gmail.com  Wed Feb 21 01:01:27 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 16:01:27 -0800
Subject: [R] deparseDots to get names of all arguments?
In-Reply-To: <d3324bab-de5a-244d-6e83-3474cb6638a8@auckland.ac.nz>
References: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
 <d3324bab-de5a-244d-6e83-3474cb6638a8@auckland.ac.nz>
Message-ID: <CAGxFJbRPh49CnHLh4Oz7309XRhnWL2NOHqjWXD_RFg1Jnxnmzg@mail.gmail.com>

If you want to avoid the inefficiency and memory overhead of first
constructing the list and work directly on the language, then I think
?match.call is the tool you want. e.g.


> f <- function(...){
    z <- as.list(match.call())[-1]
    vapply(z,deparse,"a")
 }

> a <- 1
> b <- 2

> f(a,b)
[1] "a" "b"

I am sure that there are packages that may do this more elegantly and
perhaps reliably, though.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 2:47 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 21/02/18 11:36, Spencer Graves wrote:
>
>> Hi, All:
>>
>>
>>        How can I get the names of all the arguments in dots(...)?
>>
>>
>>        I'm able to get the name of the first argument but not the second:
>>
>>
>>
>> deparseDots <- function(...){
>>    deparse(substitute(...))
>> }
>> a <- 1
>> b <- 2
>> deparseDots(a, b)
>> [1] "a"
>>
>>  >        I'd like to get c('a', 'b').
>>
>
> Does
>
>     names(list(...))
>
> do what you want?
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 21 01:17:48 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 16:17:48 -0800
Subject: [R] deparseDots to get names of all arguments?
In-Reply-To: <f6560e8e-546c-5480-9acc-920ed07e8666@gmail.com>
References: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
 <d3324bab-de5a-244d-6e83-3474cb6638a8@auckland.ac.nz>
 <f6560e8e-546c-5480-9acc-920ed07e8666@gmail.com>
Message-ID: <CAGxFJbSH1DakWeiVyGXOMphbA-gr1M_GypSj4nzJoyXmqQvrgg@mail.gmail.com>

Duncan et.al:

Referring to my previous suggestion for f:

> f(log(x),x^2)
[1] "log(x)" "x^2"

Is this not what you want?

Cheers,
Bert


On Tue, Feb 20, 2018 at 4:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 20/02/2018 5:47 PM, Rolf Turner wrote:
>
>> On 21/02/18 11:36, Spencer Graves wrote:
>>
>>> Hi, All:
>>>
>>>
>>>         How can I get the names of all the arguments in dots(...)?
>>>
>>>
>>>         I'm able to get the name of the first argument but not the
>>> second:
>>>
>>>
>>>
>>> deparseDots <- function(...){
>>>     deparse(substitute(...))
>>> }
>>> a <- 1
>>> b <- 2
>>> deparseDots(a, b)
>>> [1] "a"
>>>
>>>   >        I'd like to get c('a', 'b').
>>>
>>
>> Does
>>
>>       names(list(...))
>>
>> do what you want?
>>
>
> No, that does what he asked for, not what he wants :-).  Spencer, you want
> to deparse all of the expressions in ..., not their names.
>
> I think base R doesn't have a way to do this (but I may be wrong).  You
> can do it using some the rlang package.  For example, this seems to work:
>
> deparseDots <- function(...) {
>   unname(sapply(rlang::exprs(...), deparse))
> }
>
> Duncan Murdoch
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From esawiek at gmail.com  Wed Feb 21 03:33:35 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Tue, 20 Feb 2018 21:33:35 -0500
Subject: [R] Aggregate over multiple and unequal column length data frames
Message-ID: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>

 Hi All--

I have generated several 2 column data frames with variable length. The
data frames have the same column names and variable types. I was trying to
aggregate over the 2nd column for all the date frames, but could not figure
out how.

I thought i could make them all of equal length then combine them in 1 data
frame where i can use aggregate, the formula version
Or to put them in a list and loop use lapply but did not know how to do
that and thought there might be a simpler way.

Below is an example of 3 data frames and the desired result; note that some
levels don't appear in all and may be null over all variable, like the case
of dd on the desired result which i would like to list all levels even if
some are all null.

Thanks in advance,

EK

   df1           df2          df3

c1 c2 c1 c2 c1 c2
1 aa 1 bb 1 aa
2 aa 2 bb 2 aa
3 bb 3 cc
4 cc 4 bb
5 bb

desired result

c1 c2 c2 c2
aa 2 2
bb 1 2 2
cc 1 1
dd

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Feb 21 03:52:22 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 20 Feb 2018 18:52:22 -0800
Subject: [R] deparseDots to get names of all arguments?
In-Reply-To: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
References: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
Message-ID: <CAF8bMcZ5aXzqtcF+5_9EbJ=cQvgiJkLf6xzYaprEAxM8JDND_A@mail.gmail.com>

Does substitute(...()) do what you want?

> myFunc <- function(x, ...) substitute(...())
> myFunc(y=1/(1:10), x=sin(3:1), z=stop("Oops"), "untagged arg")
$y
1/(1:10)

$z
stop("Oops")

[[3]]
[1] "untagged arg"

> names(.Last.value)
[1] "y" "z" ""


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Feb 20, 2018 at 2:36 PM, Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

> Hi, All:
>
>
>       How can I get the names of all the arguments in dots(...)?
>
>
>       I'm able to get the name of the first argument but not the second:
>
>
>
> deparseDots <- function(...){
>   deparse(substitute(...))
> }
> a <- 1
> b <- 2
> deparseDots(a, b)
> [1] "a"
>
>
>       I'd like to get c('a', 'b').
>
>
>       Thanks,
>       Spencer Graves
>
>
> > sessionInfo()
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS High Sierra 10.13.3
>
> Matrix products: default
> BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/
> Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/
> libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.3 tools_3.4.3    yaml_2.1.16
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Wed Feb 21 04:28:22 2018
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Tue, 20 Feb 2018 21:28:22 -0600
Subject: [R] deparseDots to get names of all arguments?
In-Reply-To: <CAF8bMcZ5aXzqtcF+5_9EbJ=cQvgiJkLf6xzYaprEAxM8JDND_A@mail.gmail.com>
References: <71a97341-b7ce-bc81-bdd8-9c97e4f3a4f2@effectivedefense.org>
 <CAF8bMcZ5aXzqtcF+5_9EbJ=cQvgiJkLf6xzYaprEAxM8JDND_A@mail.gmail.com>
Message-ID: <0825cb0e-3b89-0d38-19b0-b7cb977b848a@effectivedefense.org>



On 2018-02-20 20:52, William Dunlap wrote:
> Does substitute(...()) do what you want?


 ????? That's the key.? Thanks very much.
 ????? Spencer Graves

>
> > myFunc <- function(x, ...) substitute(...())
> > myFunc(y=1/(1:10), x=sin(3:1), z=stop("Oops"), "untagged arg")
> $y
> 1/(1:10)
>
> $z
> stop("Oops")
>
> [[3]]
> [1] "untagged arg"
>
> > names(.Last.value)
> [1] "y" "z" ""
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Tue, Feb 20, 2018 at 2:36 PM, Spencer Graves 
> <spencer.graves at effectivedefense.org 
> <mailto:spencer.graves at effectivedefense.org>> wrote:
>
>     Hi, All:
>
>
>     ????? How can I get the names of all the arguments in dots(...)?
>
>
>     ????? I'm able to get the name of the first argument but not the
>     second:
>
>
>
>     deparseDots <- function(...){
>     ? deparse(substitute(...))
>     }
>     a <- 1
>     b <- 2
>     deparseDots(a, b)
>     [1] "a"
>
>
>     ????? I'd like to get c('a', 'b').
>
>
>     ????? Thanks,
>     ????? Spencer Graves
>
>
>     > sessionInfo()
>     R version 3.4.3 (2017-11-30)
>     Platform: x86_64-apple-darwin15.6.0 (64-bit)
>     Running under: macOS High Sierra 10.13.3
>
>     Matrix products: default
>     BLAS:
>     /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
>     LAPACK:
>     /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
>
>     locale:
>     [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>     attached base packages:
>     [1] stats???? graphics? grDevices utils???? datasets methods base
>
>     loaded via a namespace (and not attached):
>     [1] compiler_3.4.3 tools_3.4.3??? yaml_2.1.16
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 21 04:31:54 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 19:31:54 -0800
Subject: [R] 
 Aggregate over multiple and unequal column length data frames
In-Reply-To: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
References: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
Message-ID: <CAGxFJbRs0=ixJh-FRpcHO_TkVdrGum=2fjpdepJTGAerEkaTZg@mail.gmail.com>

All columns in a data.frame **must** have the same length. So you cannot do
this unless empty values are filled with missings (NA's).

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 6:33 PM, Ek Esawi <esawiek at gmail.com> wrote:

>  Hi All--
>
> I have generated several 2 column data frames with variable length. The
> data frames have the same column names and variable types. I was trying to
> aggregate over the 2nd column for all the date frames, but could not figure
> out how.
>
> I thought i could make them all of equal length then combine them in 1 data
> frame where i can use aggregate, the formula version
> Or to put them in a list and loop use lapply but did not know how to do
> that and thought there might be a simpler way.
>
> Below is an example of 3 data frames and the desired result; note that some
> levels don't appear in all and may be null over all variable, like the case
> of dd on the desired result which i would like to list all levels even if
> some are all null.
>
> Thanks in advance,
>
> EK
>
>    df1           df2          df3
>
> c1 c2 c1 c2 c1 c2
> 1 aa 1 bb 1 aa
> 2 aa 2 bb 2 aa
> 3 bb 3 cc
> 4 cc 4 bb
> 5 bb
>
> desired result
>
> c1 c2 c2 c2
> aa 2 2
> bb 1 2 2
> cc 1 1
> dd
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Wed Feb 21 06:19:52 2018
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Wed, 21 Feb 2018 00:19:52 -0500
Subject: [R] regex for "[2440810] / www.tinyurl.com/hgaco4fha3"
Message-ID: <CAM-xyZjA8oFAdDkUSyMnNx=j9N7mw3tT5c8yiQLwyudw5TJyLw@mail.gmail.com>

Hi, I need help for cleaning this:

"[2440810] / www.tinyurl.com/hgaco4fha3"

My desired output is:

"[2440810] / tinyurl".

My attemps:

stringa <- "[2440810] / www.tinyurl.com/hgaco4fha3"

b <- sub('^www.', '', stringa) #wanted  to get rid of "www." part. Until
first dot.

b <- sub('[.].*', '', b) #clean from ".com" until the end.

b #returns ""[2440810] / www"

Thank you.

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Wed Feb 21 07:15:27 2018
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 21 Feb 2018 06:15:27 +0000
Subject: [R] regex for "[2440810] / www.tinyurl.com/hgaco4fha3"
In-Reply-To: <CAM-xyZjA8oFAdDkUSyMnNx=j9N7mw3tT5c8yiQLwyudw5TJyLw@mail.gmail.com>
References: <CAM-xyZjA8oFAdDkUSyMnNx=j9N7mw3tT5c8yiQLwyudw5TJyLw@mail.gmail.com>
Message-ID: <CAKVAULP7=uUALq1qQxHe2U=Nev0ynMAeD0KZrf+OuPnOaKCASw@mail.gmail.com>

Hi Omar,

you are almost there.... but! Your first substitution looks 'www' as the
start of the line followed by anything (which then do nothing), so your
second substitution removes everything from the first '.' to be found
(which is the one after www).

What you want to do is
x <- "[2440810] / www.tinyurl.com/hgaco4fha3"

y <- sub('www\\.', '', x) # Note the escape of '.'
y <- sub('\\..*', '', y)
y

Altrenatively, all in one (if all addresses are .com)
gsub("(www\\.|\\.com.*)", "", x)

And the same using stringr
library(stringr)
x %>% str_replace_all("(www\\.|\\.com.*)", "")

HTH
Ulrik


On Wed, 21 Feb 2018 at 06:20 Omar Andr? Gonz?les D?az <
oma.gonzales at gmail.com> wrote:

> Hi, I need help for cleaning this:
>
> "[2440810] / www.tinyurl.com/hgaco4fha3"
>
> My desired output is:
>
> "[2440810] / tinyurl".
>
> My attemps:
>
> stringa <- "[2440810] / www.tinyurl.com/hgaco4fha3"
>
> b <- sub('^www.', '', stringa) #wanted  to get rid of "www." part. Until
> first dot.
>
> b <- sub('[.].*', '', b) #clean from ".com" until the end.
>
> b #returns ""[2440810] / www"
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 21 07:18:25 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Feb 2018 22:18:25 -0800
Subject: [R] regex for "[2440810] / www.tinyurl.com/hgaco4fha3"
In-Reply-To: <CAM-xyZjA8oFAdDkUSyMnNx=j9N7mw3tT5c8yiQLwyudw5TJyLw@mail.gmail.com>
References: <CAM-xyZjA8oFAdDkUSyMnNx=j9N7mw3tT5c8yiQLwyudw5TJyLw@mail.gmail.com>
Message-ID: <CAGxFJbSGw=WMKZcwdoh-3gZq8UPLWCZkCtSWrsgV2QAkVSboCw@mail.gmail.com>

These are always kind of fun, not least because of the variety of different
replies that "work" at least somewhat. Here's mine:

> stringa <- "[2440810] / www.tinyurl.com/hgaco4fha3"

> sub("^(.+)www\\.(.+)\\.com.+","\\1\\2",stringa)
[1] "[2440810] / tinyurl"

Note the use of doubled backslashes to escape the regex metacharacters. See
?regexp for details.

Cheers,
Bert





On Tue, Feb 20, 2018 at 9:19 PM, Omar Andr? Gonz?les D?az <
oma.gonzales at gmail.com> wrote:

> Hi, I need help for cleaning this:
>
> "[2440810] / www.tinyurl.com/hgaco4fha3"
>
> My desired output is:
>
> "[2440810] / tinyurl".
>
> My attemps:
>
> stringa <- "[2440810] / www.tinyurl.com/hgaco4fha3"
>
> b <- sub('^www.', '', stringa) #wanted  to get rid of "www." part. Until
> first dot.
>
> b <- sub('[.].*', '', b) #clean from ".com" until the end.
>
> b #returns ""[2440810] / www"
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From surajkeshri at gmail.com  Wed Feb 21 05:06:12 2018
From: surajkeshri at gmail.com (suraj keshri)
Date: Tue, 20 Feb 2018 23:06:12 -0500
Subject: [R] Specify multiple nested random effects in lme with
 heteroskedastic variance across group
Message-ID: <CABkv+1f4WuqcsQi6d-Gta6W-Em0yZzdPBYBMh-JT4HymD_c_Lg@mail.gmail.com>

I want to fit a random effects model with two separate nested random
effects. I can easily do this using the `lmer` package in R. Here's how:

    model<-lmer(y ~ 1 + x + (1 | oid/gid) + (1 | did/gid), data=data)

Here, I'm fitting a random intercept for `oid` nested within `gid` and
`did` nested within `gid`. This works well. However, I want to fit a model
where the variance of the intercept changes with the `gid` for both the
random effects. `nlme` package is capable of doing that. However, it's not
clear how. The best I could do is like so:

    model <- lme(y ~ 1 + x, random=list(gid=~1, oid=~1, did=~1),
weights=varIdent(form=~1|gid), data = data)

but this nests the `did` within `oid` and `gid` nested together. I tried to
use the idea from a similar [question][1], which seems like a close problem
but the answer has not been explained well in that question. I hope someone
can figure this out.


  [1]:
https://stats.stackexchange.com/questions/58669/specifying-multiple-separate-random-effects-in-lme

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Wed Feb 21 12:00:38 2018
From: milujisb at gmail.com (Miluji Sb)
Date: Wed, 21 Feb 2018 12:00:38 +0100
Subject: [R] Take the maximum of every 12 columns
In-Reply-To: <CAFDcVCT_VmGwYg4R71aRyraDxA1qcC4Birk2xt55ym6ufoY1NA@mail.gmail.com>
References: <CAMLwc7NsoRWCiuoLYPhiefCXbuLBYaw=b19d3kHbvZZ3GqWcEA@mail.gmail.com>
 <CA+vqiLHBP=+rXYdd38OHydob7UznM-wJMyXrwyvZsXio6oCmdg@mail.gmail.com>
 <CAMLwc7M-g51TOgnTLmshs_OY7wMSBNNier198WVrCVQ=57JYgw@mail.gmail.com>
 <CAGxFJbQ5qR_fiH_xwfTP9M11J1--WFYOVha3zFNQDZoeRR--3Q@mail.gmail.com>
 <CA+vqiLFS2Z3r4KCDbyP0PAmm4eB2hkTFNxkTtmjAX4ny+zeCTg@mail.gmail.com>
 <CAFDcVCT_VmGwYg4R71aRyraDxA1qcC4Birk2xt55ym6ufoY1NA@mail.gmail.com>
Message-ID: <CAMLwc7MWNnWaD0DCWJbZOoOy+6PbTa6nyXRXGvtoV7Yw6McHuQ@mail.gmail.com>

Dear Henrik,

This is great - thank you so much!

Sincerely,

Milu

On Tue, Feb 20, 2018 at 10:12 PM, Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> It looks like OP uses a data.frame, so in order to use matrixStats
> (I'm the author) one would have to pay the price to coerce to a matrix
> before using matrixStats::rowMaxs().  However, if it is that the
> original data could equally well live in a matrix, then matrixStats
> should be computational efficient for this task.  (I've seen cases
> where an original matrix was turned into a data.frame just because
> that is what is commonly used elsewhere and because the user may not
> pay attention to the differences between matrices and data.frame.)
>
> If the original data would be a matrix 'X', then one can do the
> following with matrixStats:
>
> Y <- sapply(seq(from = 0, to = 2880, by = 12), FUN = function(offset) {
>    rowMaxs(X, cols = offset + 1:12)
> })
>
> which avoids internal temporary copies required when using regular
> subsetting, e.g.
>
> Y <- sapply(seq(from = 0, to = 2880, by = 12), FUN = function(offset) {
>    rowMaxs(X[, offset + 1:12])
> })
>
> Subsetting data frames by columns is already efficient, so the same
> argument does not apply there.
>
> /Henrik
>
> On Tue, Feb 20, 2018 at 10:00 AM, Ista Zahn <istazahn at gmail.com> wrote:
> > On Tue, Feb 20, 2018 at 11:58 AM, Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> >> Ista, et. al: efficiency?
> >> (Note: I needed to correct my previous post: do.call() is required for
> >> pmax() over the data frame)
> >>
> >> > x <- data.frame(matrix(runif(12e6), ncol=12))
> >>
> >> > system.time(r1 <- do.call(pmax,x))
> >>    user  system elapsed
> >>   0.049   0.000   0.049
> >>
> >> > identical(r1,r2)
> >> [1] FALSE
> >> > system.time(r2 <- apply(x,1,max))
> >>    user  system elapsed
> >>   2.162   0.045   2.207
> >>
> >> ## 150 times slower!
> >>
> >> > identical(r1,r2)
> >> [1] TRUE
> >>
> >> pmax() is there for a reason.
> >> Or is there something I am missing?
> >>
> >
> >
> > Personal preference I think. I prefer the consistency of apply. If speed
> > is an issue matrixStats is both consistent and fast:
> >
> > library(matrixStats)
> > x <- matrix(runif(12e6), ncol=12)
> >
> > system.time(r1 <- do.call(pmax,as.data.frame(x)))
> >   ##  user  system elapsed
> >   ## 0.109   0.000   0.109
> > system.time(r2 <- apply(x,1,max))
> >   ##  user  system elapsed
> >   ## 1.292   0.024   1.321
> > system.time(r3 <- rowMaxs(x))
> >   ##  user  system elapsed
> >   ## 0.044   0.000   0.044
> >
> > pmax is a fine alternative for max special case.
> >
> > Best,
> > Ista
> >
> >
> >
> >>
> >> Cheers,
> >> Bert
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >> On Tue, Feb 20, 2018 at 8:16 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >>
> >>> This is what I was looking for. Thank you everyone!
> >>>
> >>> Sincerely,
> >>>
> >>> Milu
> >>>
> >>>
> >>> <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail> Mail
> >>> priva di virus. www.avast.com
> >>> <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> >>> <#m_4297398466082743447_m_6071581590498622123_DAB4FAD8-
> 2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >>>
> >>> On Tue, Feb 20, 2018 at 5:10 PM, Ista Zahn <istazahn at gmail.com> wrote:
> >>>
> >>>> Hi Milu,
> >>>>
> >>>> byapply(df, 12, function(x) apply(x, 1, max))
> >>>>
> >>>> You might also be interested in the matrixStats package.
> >>>>
> >>>> Best,
> >>>> Ista
> >>>>
> >>>> On Tue, Feb 20, 2018 at 9:55 AM, Miluji Sb <milujisb at gmail.com>
> wrote:
> >>>> >  Dear all,
> >>>> >
> >>>> > I have monthly data in wide format, I am only providing data (at the
> >>>> bottom
> >>>> > of the email) for the first 24 columns but I have 2880 columns in
> >>>> total.
> >>>> >
> >>>> > I would like to take max of every 12 columns. I have taken the mean
> of
> >>>> > every 12 columns with the following code:
> >>>> >
> >>>> > byapply <- function(x, by, fun, ...)
> >>>> > {
> >>>> >   # Create index list
> >>>> >   if (length(by) == 1)
> >>>> >   {
> >>>> >     nc <- ncol(x)
> >>>> >     split.index <- rep(1:ceiling(nc / by), each = by, length.out =
> nc)
> >>>> >   } else # 'by' is a vector of groups
> >>>> >   {
> >>>> >     nc <- length(by)
> >>>> >     split.index <- by
> >>>> >   }
> >>>> >   index.list <- split(seq(from = 1, to = nc), split.index)
> >>>> >
> >>>> >   # Pass index list to fun using sapply() and return object
> >>>> >   sapply(index.list, function(i)
> >>>> >   {
> >>>> >     do.call(fun, list(x[, i], ...))
> >>>> >   })
> >>>> > }
> >>>> >
> >>>> > ## Compute annual means
> >>>> > y <- byapply(df, 12, rowMeans)
> >>>> >
> >>>> > How can I switch rowMeans with a command that takes the maximum? I
> am
> >>>> a bit
> >>>> > baffled. Any help will be appreciated. Thank you.
> >>>> >
> >>>> > Sincerely,
> >>>> >
> >>>> > Milu
> >>>> >
> >>>> > ###
> >>>> > dput(droplevels(head(x, 5)))
> >>>> > structure(list(X0 = c(295.812103271484, 297.672424316406,
> >>>> 299.006805419922,
> >>>> > 297.631500244141, 298.372741699219), X1 = c(295.361328125,
> >>>> > 297.345092773438,
> >>>> > 298.067504882812, 297.285339355469, 298.275268554688), X2 =
> >>>> > c(294.279602050781,
> >>>> > 296.401550292969, 296.777984619141, 296.089111328125,
> 297.540374755859
> >>>> > ), X3 = c(292.103118896484, 294.253601074219, 293.773803710938,
> >>>> > 293.916229248047, 296.129943847656), X4 = c(288.525024414062,
> >>>> > 291.274505615234, 289.502777099609, 290.723388671875,
> 293.615112304688
> >>>> > ), X5 = c(286.018371582031, 288.748565673828, 286.463134765625,
> >>>> > 288.393951416016, 291.710266113281), X6 = c(285.550537109375,
> >>>> > 288.159149169922, 285.976501464844, 287.999816894531,
> 291.228271484375
> >>>> > ), X7 = c(289.136962890625, 290.751159667969, 290.170257568359,
> >>>> > 291.796203613281, 293.423248291016), X8 = c(292.410003662109,
> >>>> > 292.701263427734, 294.25244140625, 295.320404052734,
> 295.248199462891
> >>>> > ), X9 = c(293.821655273438, 294.139068603516, 296.630157470703,
> >>>> > 296.963531494141, 296.036224365234), X10 = c(294.532531738281,
> >>>> > 295.366607666016, 297.677551269531, 296.715911865234,
> 296.564178466797
> >>>> > ), X11 = c(295.869476318359, 297.010070800781, 299.330169677734,
> >>>> > 297.627593994141, 297.964935302734), X12 = c(295.986236572266,
> >>>> > 297.675567626953, 299.056671142578, 297.598907470703,
> 298.481842041016
> >>>> > ), X13 = c(295.947601318359, 297.934448242188, 298.745391845703,
> >>>> > 297.704925537109, 298.819091796875), X14 = c(294.654327392578,
> >>>> > 296.722717285156, 297.0986328125, 296.508239746094, 297.822021484375
> >>>> > ), X15 = c(292.176361083984, 294.49658203125, 293.888305664062,
> >>>> > 294.172149658203, 296.117095947266 <(709)%20594-7266>), X16 =
> >>>> c(288.400726318359,
> >>>> > 291.029113769531, 289.361907958984, 290.566772460938,
> 293.554016113281
> >>>> > ), X17 = c(285.665222167969, 288.293029785156, 286.118957519531,
> >>>> > 288.105285644531, 291.429382324219), X18 = c(285.971252441406,
> >>>> > 288.3798828125, 286.444580078125, 288.495880126953, 291.447326660156
> >>>> > ), X19 = c(288.79296875, 290.357543945312, 289.657928466797,
> >>>> > 291.449066162109, 293.095275878906), X20 = c(291.999877929688,
> >>>> > 292.838348388672, 293.840362548828, 294.412322998047,
> 294.941253662109
> >>>> > ), X21 = c(293.615447998047, 294.028106689453, 296.072296142578,
> >>>> > 296.447387695312, 295.824615478516), X22 = c(294.719848632812,
> >>>> > 295.392028808594, 297.453216552734, 297.114288330078,
> 296.883209228516
> >>>> > ), X23 = c(295.634429931641, 296.783294677734, 298.592346191406,
> >>>> > 297.469512939453, 297.832122802734)), .Names = c("X0", "X1",
> >>>> > "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11",
> >>>> > "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20",
> >>>> > "X21", "X22", "X23"), row.names = c(NA, 5L), class = "data.frame")
> >>>> >
> >>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
> >>>> =link&utm_campaign=sig-email&utm_content=webmail>
> >>>> > Mail
> >>>> > priva di virus. www.avast.com
> >>>> > <https://www.avast.com/sig-email?utm_medium=email&utm_source
> >>>> =link&utm_campaign=sig-email&utm_content=webmail>
> >>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >>>> >
> >>>> >         [[alternative HTML version deleted]]
> >>>> >
> >>>> > ______________________________________________
> >>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> > PLEASE do read the posting guide http://www.R-project.org/posti
> >>>> ng-guide.html
> >>>> > and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb 21 12:36:33 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Feb 2018 03:36:33 -0800
Subject: [R] Specify multiple nested random effects in lme with
 heteroskedastic variance across group
In-Reply-To: <CABkv+1f4WuqcsQi6d-Gta6W-Em0yZzdPBYBMh-JT4HymD_c_Lg@mail.gmail.com>
References: <CABkv+1f4WuqcsQi6d-Gta6W-Em0yZzdPBYBMh-JT4HymD_c_Lg@mail.gmail.com>
Message-ID: <CAGxFJbSyjiLBhFfb_xQDR1vqmdCzvZENpdzbbW6gn8MFBaqXyw@mail.gmail.com>

You should post this on the r-sig-mixed-models  list. You are more likely
to get a helpful response there.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 20, 2018 at 8:06 PM, suraj keshri <surajkeshri at gmail.com> wrote:

> I want to fit a random effects model with two separate nested random
> effects. I can easily do this using the `lmer` package in R. Here's how:
>
>     model<-lmer(y ~ 1 + x + (1 | oid/gid) + (1 | did/gid), data=data)
>
> Here, I'm fitting a random intercept for `oid` nested within `gid` and
> `did` nested within `gid`. This works well. However, I want to fit a model
> where the variance of the intercept changes with the `gid` for both the
> random effects. `nlme` package is capable of doing that. However, it's not
> clear how. The best I could do is like so:
>
>     model <- lme(y ~ 1 + x, random=list(gid=~1, oid=~1, did=~1),
> weights=varIdent(form=~1|gid), data = data)
>
> but this nests the `did` within `oid` and `gid` nested together. I tried to
> use the idea from a similar [question][1], which seems like a close problem
> but the answer has not been explained well in that question. I hope someone
> can figure this out.
>
>
>   [1]:
> https://stats.stackexchange.com/questions/58669/
> specifying-multiple-separate-random-effects-in-lme
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From MaxHennig13 at gmx.de  Wed Feb 21 15:35:50 2018
From: MaxHennig13 at gmx.de (Max Hennig)
Date: Wed, 21 Feb 2018 15:35:50 +0100
Subject: [R] TreeBUGS - subscript out of bounds
Message-ID: <trinity-db27178b-88d1-4013-afc9-f93e596ec59e-1519223750646@3c-app-gmx-bs31>

Dear all,
?
I've only (very) recently started to use R (so please be easy on me if I may omit to mention relevant information or have overlooked fairly basic steps to solving the problem, since I do not have a lot of experience) because I'm interested in multinomial processing tree modeling with the TreeBUGS package (Heck, Arnold & Arnold 2017 - TreeBUGS: An R package for hierarchical multinomial-processing-tree modeling).
I have attempted to conduct a permutation test with my dataset, as described on pages 5-6 of the paper. I've brought the data in the necessary long format (participant case in column 1, stimulus index in column 2, observed response in column 3) and specified the tree structure as described in the paper, in my case four trees with two possible responses each.
When specifying the test, I am given the message:
?
Error in M[, tree] : subscript out of bounds
?
Though I've found some information on this general error online, all of it applies to different tests and didn't help me to solve the problem.
Has anyone of you encountered this error before, or has a suggestion for me?
?
Best,
Max


From ericjberger at gmail.com  Wed Feb 21 15:45:03 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 21 Feb 2018 16:45:03 +0200
Subject: [R] TreeBUGS - subscript out of bounds
In-Reply-To: <trinity-db27178b-88d1-4013-afc9-f93e596ec59e-1519223750646@3c-app-gmx-bs31>
References: <trinity-db27178b-88d1-4013-afc9-f93e596ec59e-1519223750646@3c-app-gmx-bs31>
Message-ID: <CAGgJW76r-916b_DSF8zOnHH3D6MP-srz_fVEmU_yhWUe-+-cjw@mail.gmail.com>

Hi Max,
Here's an example that will generate that error. Maybe it will point you to
your problem.

# create a 2x2 matrix
>  m <- matrix(1:4,nrow=2)

# refer to column 3 - which does not exist
> m[,3]
# Error in m[, 3] : subscript out of bounds

HTH,
Eric




On Wed, Feb 21, 2018 at 4:35 PM, Max Hennig <MaxHennig13 at gmx.de> wrote:

> Dear all,
>
> I've only (very) recently started to use R (so please be easy on me if I
> may omit to mention relevant information or have overlooked fairly basic
> steps to solving the problem, since I do not have a lot of experience)
> because I'm interested in multinomial processing tree modeling with the
> TreeBUGS package (Heck, Arnold & Arnold 2017 - TreeBUGS: An R package for
> hierarchical multinomial-processing-tree modeling).
> I have attempted to conduct a permutation test with my dataset, as
> described on pages 5-6 of the paper. I've brought the data in the necessary
> long format (participant case in column 1, stimulus index in column 2,
> observed response in column 3) and specified the tree structure as
> described in the paper, in my case four trees with two possible responses
> each.
> When specifying the test, I am given the message:
>
> Error in M[, tree] : subscript out of bounds
>
> Though I've found some information on this general error online, all of it
> applies to different tests and didn't help me to solve the problem.
> Has anyone of you encountered this error before, or has a suggestion for
> me?
>
> Best,
> Max
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From joymae.gabion at g.msuiit.edu.ph  Wed Feb 21 15:37:53 2018
From: joymae.gabion at g.msuiit.edu.ph (JoyMae Gabion)
Date: Wed, 21 Feb 2018 22:37:53 +0800
Subject: [R] Modified Band Depth
Message-ID: <CAH5op1Z531iZC7tr2s6GALft-V-7KU5Zsb+JBmMJLw3kD8CUdw@mail.gmail.com>

 Dear Ma'am/Sir,

This is Joy Mae C. Gabion taking up Masters of Science in Statistics at
Mindanao State University ? Iligan Institute of Technology (MSU-IIT),
Philippines. I?m currently working on my master?s thesis and chose to base
it on the paper of Sun et.al (2012) which discussed the exact fast
computation of band depth for large functional datasets. There are codes in
Mathlab available in the appendix of the paper for the computation of band
depth and modified band depth. I just want to ask for help if there are
also codes available for that in R software. I highly appreciate your
response regarding this matter. Thank you so much.



Best regards,

Joy Mae

-- 
---
*DISCLAIMER AND CONFIDENTIALITY NOTICE* The Mindanao Sta...{{dropped:30}}


From boris.steipe at utoronto.ca  Wed Feb 21 21:08:28 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 21 Feb 2018 15:08:28 -0500
Subject: [R] Modified Band Depth
In-Reply-To: <CAH5op1Z531iZC7tr2s6GALft-V-7KU5Zsb+JBmMJLw3kD8CUdw@mail.gmail.com>
References: <CAH5op1Z531iZC7tr2s6GALft-V-7KU5Zsb+JBmMJLw3kD8CUdw@mail.gmail.com>
Message-ID: <D2A57608-18E6-463C-8921-A7E28D94AC66@utoronto.ca>

If you are talking about the "Supporting Information" - that contains only one small piece of matlab code that looks pretty trivial to translate if necessary. The rest are R scripts.

What then is the problem you need to solve?

B.



> On Feb 21, 2018, at 9:37 AM, JoyMae Gabion <joymae.gabion at g.msuiit.edu.ph> wrote:
> 
> Dear Ma'am/Sir,
> 
> This is Joy Mae C. Gabion taking up Masters of Science in Statistics at
> Mindanao State University ? Iligan Institute of Technology (MSU-IIT),
> Philippines. I?m currently working on my master?s thesis and chose to base
> it on the paper of Sun et.al (2012) which discussed the exact fast
> computation of band depth for large functional datasets. There are codes in
> Mathlab available in the appendix of the paper for the computation of band
> depth and modified band depth. I just want to ask for help if there are
> also codes available for that in R software. I highly appreciate your
> response regarding this matter. Thank you so much.
> 
> 
> 
> Best regards,
> 
> Joy Mae
> 
> -- 
> ---
> *DISCLAIMER AND CONFIDENTIALITY NOTICE* The Mindanao Sta...{{dropped:30}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From KWamae at kemri-wellcome.org  Wed Feb 21 21:33:57 2018
From: KWamae at kemri-wellcome.org (Kevin Wamae)
Date: Wed, 21 Feb 2018 20:33:57 +0000
Subject: [R] alternative for multiple if_else statements
Message-ID: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>

Hi, I am having trouble trying to figure out why if_else is behaving the way it is, it may be my code or the way the data is structured.

Below is a snapshot of a database am working on and it represents a longitudinal survey of study participants in a trial with weekly follow up.

The variable "survey_start" represents the start of the study-defined one year follow up (which we called "survey_year").

I am trying to populate all subsequent entries for each participant, per survey year, with the entry "survey" followed by an underscore and the respective year, eg. survey_2014.

There are missing entries such as the participant represented here, wasn't available at the start of the 2015 survey. Also, some participants don?t have complete one-year follow ups but I still need to include them.

I have written two codes, first one fails while the second works, the only difference being I have reversed the order in which the entries are populated in the second code (from 2007-2016 to 2016-2007) and removed the if_else statement for 2015. Also noticed, that for the second code, which spans the years 2007-2016 (less 2015), if a participants entries start from 2010-2016, the code fails.

Kindly assist in figuring this out...or better yet, an alternative.

    trialData <- structure(list(study = c("site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1"), studyno = c("child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1"), date = structure(c(16078, 16085, 16092,
16098, 16104, 16115, 16121, 16129, 16135, 16140, 16146, 16156,
16162, 16168, 16177, 16185, 16191, 16195, 16203, 16210, 16217,
16225, 16234, 16237, 16246, 16253, 16262, 16269, 16278, 16283,
16288, 16297, 16304, 16311, 16319, 16326, 16332, 16337, 16346,
16353, 16360, 16366, 16370, 16381, 16384, 16395, 16399, 16407,
16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477, 16484,
16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613,
16620, 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681,
16688, 16693, 16702, 16706, 16714, 16721, 16728, 16734, 16745,
16749, 16757, 16764, 16769, 16778, 16785, 16792, 16805, 16812,
16819, 16830, 16832, 16839, 16846, 16856, 16862, 16867, 16877,
16884, 16890, 16898, 16904, 16912, 16917, 16923, 16936, 16938,
16953, 16960, 16966, 16973, 16980), class = "Date"), year = c(2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L,
12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L,
11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 6L), survey_start = c("", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "",
"", "", "", "", "", "")), class = "data.frame", row.names = c(NA,
-125L), .Names = c("study", "studyno", "date", "year", "month",
"survey_start"))


code 1 fails:

trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",
                     if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
                     if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
                     if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
                     if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
                     if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
                     if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
                     if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
                     if_else(date >= date[survey_start == "Y" & year == 2015 & study == "site_1"][1] & date < date[month == 3 & year == 2016 & study == "site_1"][1], "survey_2015",
                     if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1], "survey_2016","")))))))))))

code 2 works:

    trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
  mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1]                                                               , "survey_2016",
                           if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
                           if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
                           if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
                           if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
                           if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
                           if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
                           if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
                           if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",""))))))))))

______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________

	[[alternative HTML version deleted]]


From jgreenberg at unr.edu  Wed Feb 21 22:28:30 2018
From: jgreenberg at unr.edu (Jonathan Greenberg)
Date: Wed, 21 Feb 2018 21:28:30 +0000
Subject: [R] Checking for a proper "stop" statement...
Message-ID: <CABG0rftisa_4zNkenu9zhWAS-kQLvYj-HoeA2epur7TK-qxuvA@mail.gmail.com>

Folks:

Consider the following two use cases:

goodfunction <- function()
{
stop("Something went wrong..."
}

# vs.

badfunction <- function()
{
notgood()
}

Is there a way for me to test if the functions make use of a stop()
statement WITHOUT modifying the stop() output (assume I can't mod the
function containing the stop() statement itself)?  For "goodfunction" the
answer is TRUE, for "badfunction" the answer is FALSE.  Both return an
error, but only one does it "safely".

I thought the answer might lie in a tryCatch statement but I'm having a
hard time figuring out how to do this test.

--j
-- 
-- 
Jonathan A. Greenberg, PhD
Randall Endowed Professor and Associate Professor of Remote Sensing
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Natural Resources & Environmental Science
University of Nevada, Reno
1664 N Virginia St MS/0186
Reno, NV 89557
Phone: 415-763-5476
http://www.unr.edu/nres
Gchat: jgrn307 at gmail.com, Skype: jgrn3007

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Feb 21 22:51:49 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 21 Feb 2018 16:51:49 -0500
Subject: [R] Checking for a proper "stop" statement...
In-Reply-To: <CABG0rftisa_4zNkenu9zhWAS-kQLvYj-HoeA2epur7TK-qxuvA@mail.gmail.com>
References: <CABG0rftisa_4zNkenu9zhWAS-kQLvYj-HoeA2epur7TK-qxuvA@mail.gmail.com>
Message-ID: <f349fed1-1d42-d18b-6443-2c05997ef8ec@gmail.com>

On 21/02/2018 4:28 PM, Jonathan Greenberg wrote:
> Folks:
> 
> Consider the following two use cases:
> 
> goodfunction <- function()
> {
> stop("Something went wrong..."
> }
> 
> # vs.
> 
> badfunction <- function()
> {
> notgood()
> }
> 
> Is there a way for me to test if the functions make use of a stop()
> statement WITHOUT modifying the stop() output (assume I can't mod the
> function containing the stop() statement itself)?  For "goodfunction" the
> answer is TRUE, for "badfunction" the answer is FALSE.  Both return an
> error, but only one does it "safely".
> 
> I thought the answer might lie in a tryCatch statement but I'm having a
> hard time figuring out how to do this test.
> 

I think tryCatch() is what you want.  To see the difference between 
those two errors, run

tryCatch(goodfunction(), error = function(e) browser())

and similarly with badfunction().  When you land in the browser, you'll see

Browse[1]> str(e)
List of 2
  $ message: chr "Something went wrong..."
  $ call   : language goodfunction()
  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"

and

Browse[1]> str(e)
List of 2
  $ message: chr "could not find function \"notgood\""
  $ call   : language notgood()
  - attr(*, "class")= chr [1:3] "simpleError" "error" "condition"


so you could write a test based on the message, or based on the call to 
see where the stop() happened.

Duncan Murdoch


From macqueen1 at llnl.gov  Wed Feb 21 23:21:09 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 21 Feb 2018 22:21:09 +0000
Subject: [R] Adding a table of contents to html output using the bookdown
 package
Message-ID: <40365FE1-560C-454E-BAB3-1B431D846AC1@llnl.gov>

I am trying to get rmarkdown with bookdown to include a table of contents in html output, and having trouble.

Here is an example that I think illustrates the trouble.
I have a file "test.Rmd" as follows:

[127]% cat test.Rmd
---
title: Test Document
output: 
  html_document: 
    toc: true
---

# Introduction

some text

# A section

some more text
[128]%

If I run:

library(rmarkdown)
render('test.Rmd')

I get a table of contents in the html file (test.html). Nice.

However, for more flexibility in switching back and forth between html, pdf, and Word output, and to get section numbering and the ability to cross reference tables and figures by number, I am rendering my .Rmd files using a command like

library(bookdown)  
render('test.Rmd',  output_dir='.',  output_format=html_document2(number_sections=TRUE)  )

Then there is no table of contents.

Are there an additional argument I could add to this render() command to get a TOC? I've looked, and haven't been able to find one.

Thanks
-Don

p.s.
On the other hand, with
    render('test.Rmd', output_dir='.', output_format=pdf_document2(number_sections=TRUE)  )
I do get a TOC in the pdf document.


> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] bookdown_0.5  rmarkdown_1.6

loaded via a namespace (and not attached):
 [1] compiler_3.4.2  backports_1.1.1 magrittr_1.5    rprojroot_1.2  
 [5] htmltools_0.3.6 tools_3.4.2     yaml_2.1.14     Rcpp_0.12.14   
 [9] stringi_1.1.5   knitr_1.17      stringr_1.2.0   digest_0.6.13  
[13] openxlsx_4.0.17 evaluate_0.10.1



--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 


From stefano.iacus at unimi.it  Thu Feb 22 04:29:02 2018
From: stefano.iacus at unimi.it (stefano iacus)
Date: Thu, 22 Feb 2018 04:29:02 +0100
Subject: [R] [WORKSHOP] Computational Aspects of Simulation and Inference
 for Stochastic Processes and the YUIMA Project
Message-ID: <5395601A-21F3-4D02-BEB4-BE50E7B44FD2@unimi.it>

Computational Aspects of Simulation and Inference for Stochastic Processes and the YUIMA Project

This two-day workshop is aimed at presenting the latest results on simulation and inference for stochastic processes and their current and prospect implementation within the YUIMA R package.
 
Dates: 
March 27 (Tue)   9:15-12:15, 14:45-17:45
March 28 (Wed)  9:15-12:15, 14:45-17:45

Location:
Department of Economics, Business and Statistics
Via Conservatorio 7, 20122 Milan (ITALY)
2 Floor, Departmental Seminar Room

Invited speakers:

* Alessandro De Gregorio (University of Rome)
* Alexande Brouste (University of Le Mans, France)
* Yuta Koike (University of Tokyo, JST CREST)
* Emanuele Guidotti (University of Milan)
* Stefano M. Iacus (University of Milan)
* Lorenzo Mercuri (University of Milan)
* Hiroki Masuda (Kyushu University)
* Yuma Uehara (Institute of Statistical Mathematics)
* Nakahiro Yoshida (University of Tokyo, Institute of Statistical Mathematics, JST CREST)

The attendance to the workshop is open to ?eveRyone" interested in the YUIMA Project. A considerable part of the workshop is dedicated to discussion on further development of the YUIMA package.

This workshop is supported by:
- Department of Economics, Business and Statistics, University of Milan
- CREST Japan Science and Technology Agency
- JSPS Grant-in-Aid for Scientific Research




-----------------------------------
Prof. Stefano M. Iacus, Ph.D.
Director of MEF - Master in Finance & Economics
http://www.mef.unimi.it
CEO/CTO/Co-Founder VOICES from the Blogs
http://www.voices-int.com

Department of Economics,
Management and Quantitative Methods
University of Milan
Via Conservatorio, 7
I-20123 Milan - Italy
Ph.: +39 02 50321 461
Fax: +39 02 50321 505
Twitter: @iacus
http://scholar.google.com/citations?user=JBs9tJ4AAAAJ&hl=en
http://orcid.org/0000-0002-4884-0047

Master in Finance & Economics
http://www.mef.unimi.it
Twitter: @mefunimi
Facebook: http://www.facebook.com/mefunimi
Email and further information at: mef at unimi.it


------------------------------------------------------------------------------------
Please don't send me Word or PowerPoint attachments if not 
absolutely necessary. See:
http://www.gnu.org/philosophy/no-word-attachments.html






	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From abouelmakarim1962 at gmail.com  Thu Feb 22 08:20:38 2018
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Thu, 22 Feb 2018 02:20:38 -0500
Subject: [R] Calculate LC50
Message-ID: <CAE9stmdij8m=vov-0jszQYwSh2HpFEYeFvY54VvD5k8jZZ_fDQ@mail.gmail.com>

Dear All: good morning


I need helps with the calculation of the *LC50*  from the data below


x<-c(0,0.3,0.7,1,4,10)
y<-c(100,86,65,51.3,19.2,7.4)

yxreg<-lm(y~x)


any help will be highly appreciated.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Thu Feb 22 11:04:16 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 22 Feb 2018 12:04:16 +0200
Subject: [R] alternative for multiple if_else statements
In-Reply-To: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
References: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
Message-ID: <CAGgJW76-LhVv-jR6ZJbdfCrWEKUameR4eXX=Q=WDokW+_1LaEA@mail.gmail.com>

Hi,
1. I think the reason that the different ordering leads to different
results is because of the following:
    date[ some condition is true ][1]
    will give you an NA if there are no rows where 'some condition holds'.
    In the code that 'works' you don't have such a situation, but in the
code that 'does not work' you presumably hit an NA before you get to the
result that you really want.
2. I am not a big fan of your "nested if" layout. I think you could rewrite
it more clearly - and without nesting - with something like

     > trialData$survey_year <- rep(NA_character_, nrow(trialData))
     > trialData$survey_year[ condition for survey_2007 ] <- "survey_2007"
     > trialData$survey_year[ condition for survey_2008 ] <- "survey_2008"
     > etc

HTH,
Eric

On Wed, Feb 21, 2018 at 10:33 PM, Kevin Wamae <KWamae at kemri-wellcome.org>
wrote:

> Hi, I am having trouble trying to figure out why if_else is behaving the
> way it is, it may be my code or the way the data is structured.
>
> Below is a snapshot of a database am working on and it represents a
> longitudinal survey of study participants in a trial with weekly follow up.
>
> The variable "survey_start" represents the start of the study-defined one
> year follow up (which we called "survey_year").
>
> I am trying to populate all subsequent entries for each participant, per
> survey year, with the entry "survey" followed by an underscore and the
> respective year, eg. survey_2014.
>
> There are missing entries such as the participant represented here, wasn't
> available at the start of the 2015 survey. Also, some participants don?t
> have complete one-year follow ups but I still need to include them.
>
> I have written two codes, first one fails while the second works, the only
> difference being I have reversed the order in which the entries are
> populated in the second code (from 2007-2016 to 2016-2007) and removed the
> if_else statement for 2015. Also noticed, that for the second code, which
> spans the years 2007-2016 (less 2015), if a participants entries start from
> 2010-2016, the code fails.
>
> Kindly assist in figuring this out...or better yet, an alternative.
>
>     trialData <- structure(list(study = c("site_1", "site_1", "site_1",
> "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1"), studyno = c("child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1"), date = structure(c(16078, 16085, 16092,
> 16098, 16104, 16115, 16121, 16129, 16135, 16140, 16146, 16156,
> 16162, 16168, 16177, 16185, 16191, 16195, 16203, 16210, 16217,
> 16225, 16234, 16237, 16246, 16253, 16262, 16269, 16278, 16283,
> 16288, 16297, 16304, 16311, 16319, 16326, 16332, 16337, 16346,
> 16353, 16360, 16366, 16370, 16381, 16384, 16395, 16399, 16407,
> 16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477, 16484,
> 16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
> 16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613,
> 16620, 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681,
> 16688, 16693, 16702, 16706, 16714, 16721, 16728, 16734, 16745,
> 16749, 16757, 16764, 16769, 16778, 16785, 16792, 16805, 16812,
> 16819, 16830, 16832, 16839, 16846, 16856, 16862, 16867, 16877,
> 16884, 16890, 16898, 16904, 16912, 16917, 16923, 16936, 16938,
> 16953, 16960, 16966, 16973, 16980), class = "Date"), year = c(2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L,
> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L,
> 12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
> 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L,
> 11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L,
> 6L, 6L), survey_start = c("", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "")), class = "data.frame", row.names = c(NA,
> -125L), .Names = c("study", "studyno", "date", "year", "month",
> "survey_start"))
>
>
> code 1 fails:
>
> trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
> mutate(survey_year = if_else(date >= date[survey_start == "Y" & year ==
> 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 &
> study == "site_1"][1], "survey_2007",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 &
> study == "site_1"][1], "survey_2008",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 &
> study == "site_1"][1], "survey_2009",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 &
> study == "site_1"][1], "survey_2010",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 &
> study == "site_1"][1], "survey_2011",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 &
> study == "site_1"][1], "survey_2012",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 &
> study == "site_1"][1], "survey_2013",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 &
> study == "site_1"][1], "survey_2014",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2015 & study == "site_1"][1] & date < date[month == 3 & year == 2016 &
> study == "site_1"][1], "survey_2015",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2016 & study == "site_1"][1], "survey_2016","")))))))))))
>
> code 2 works:
>
>     trialData <- trialData %>% arrange(studyno, date) %>%
> group_by(studyno) %>%
>   mutate(survey_year = if_else(date >= date[survey_start == "Y" & year ==
> 2016 & study == "site_1"][1]
>                , "survey_2016",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 &
> study == "site_1"][1], "survey_2014",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 &
> study == "site_1"][1], "survey_2013",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 &
> study == "site_1"][1], "survey_2012",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 &
> study == "site_1"][1], "survey_2011",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 &
> study == "site_1"][1], "survey_2010",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 &
> study == "site_1"][1], "survey_2009",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 &
> study == "site_1"][1], "survey_2008",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 &
> study == "site_1"][1], "survey_2007",""))))))))))
>
> ______________________________________________________________________
>
> This e-mail contains information which is confidential. It is intended
> only for the use of the named recipient. If you have received this e-mail
> in error, please let us know by replying to the sender, and immediately
> delete it from your system.  Please note, that in these circumstances, the
> use, disclosure, distribution or copying of this information is strictly
> prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility
> for the  accuracy or completeness of this message as it has been
> transmitted over a public network. Although the Programme has taken
> reasonable precautions to ensure no viruses are present in emails, it
> cannot accept responsibility for any loss or damage arising from the use of
> the email or attachments. Any views expressed in this message are those of
> the individual sender, except where the sender specifically states them to
> be the views of KEMRI-Wellcome Trust Programme.
> ______________________________________________________________________
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From E.Vettorazzi at uke.de  Thu Feb 22 12:19:19 2018
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Thu, 22 Feb 2018 12:19:19 +0100
Subject: [R] Calculate LC50
In-Reply-To: <CAE9stmdij8m=vov-0jszQYwSh2HpFEYeFvY54VvD5k8jZZ_fDQ@mail.gmail.com>
References: <CAE9stmdij8m=vov-0jszQYwSh2HpFEYeFvY54VvD5k8jZZ_fDQ@mail.gmail.com>
Message-ID: <c50f67d3-4ab9-98c1-a4f7-a80b70c40852@uke.de>

Have a look at the drc-package.

btw. a linear model does not fit your data very well.

Cheers.


Am 22.02.2018 um 08:20 schrieb AbouEl-Makarim Aboueissa:
> Dear All: good morning
> 
> 
> I need helps with the calculation of the *LC50*  from the data below
> 
> 
> x<-c(0,0.3,0.7,1,4,10)
> y<-c(100,86,65,51.3,19.2,7.4)
> 
> yxreg<-lm(y~x)
> 
> 
> any help will be highly appreciated.
> 
> 
> with many thanks
> abou
> ______________________
> 
> 
> *AbouEl-Makarim Aboueissa, PhD*
> 
> *Professor of Statistics*
> 
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistrasse 52
building W 34
20246 Hamburg

Phone: +49 (0) 40 7410 - 58243
Fax:   +49 (0) 40 7410 - 57790
Web: www.uke.de/imbe
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From ericjberger at gmail.com  Thu Feb 22 13:15:37 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 22 Feb 2018 14:15:37 +0200
Subject: [R] alternative for multiple if_else statements
In-Reply-To: <AB833505-631B-4A06-BE05-148494A71AF1@kemri-wellcome.org>
References: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
 <CAGgJW76-LhVv-jR6ZJbdfCrWEKUameR4eXX=Q=WDokW+_1LaEA@mail.gmail.com>
 <AB833505-631B-4A06-BE05-148494A71AF1@kemri-wellcome.org>
Message-ID: <CAGgJW77qxL41ycXtJQr67Sm1zG5KfLK5ZGpMFn6f7gVm9A7wPQ@mail.gmail.com>

Hi Kevin,
I ran the code on the full data set and was able to reproduce the problem
that you are facing.
My guess is that you have an error in your intuition and/or logic, and that
this relates to the use of the subscript [1].
Specifically, on the full dataset, the condition
trialData$date[trialData$survey_start == "Y" & trialData$year == 2013 &
trialData$site == "site_1"]

yields 412 matches, of which there are 9 unique ones, specifically

April 2,3,4,5,8,10,11,16,17

In the full data set the first element that appears, i.e. subscript[1], is
"2013-04-04".

In the filtered data set the first element that appears is "2013-04-05".

I hope that is enough information for you to make further progress from
here.

Best,
Eric



On Thu, Feb 22, 2018 at 1:28 PM, Kevin Wamae <KWamae at kemri-wellcome.org>
wrote:

> Dear Eric, wow, this seems to do the trick. But I have encountered a
> problem.
>
>
>
> I have tested it on the larger dataset and it seems to work on a filtered
> dataset but not on the whole dataset (attached). See below script..
>
>
>
> #load packages
>
> Library(dplyr)
>
>
>
> #load data
>
> trialData <- fread("trialData.txt") %>% mutate(date =
> as.Date(date,"%d/%m/%Y"))
>
>
>
> #create blank variable
>
> trialData$survey_year <- rep(NA_character_, nrow(trialData))
>
>
>
> *#attempt 1 fails: code for survey*
>
> trialData$survey_year[trialData$date >= trialData$date[trialData$survey_start
> == "Y" & trialData$year == 2013 & trialData$site == "site_1"][1] &
> trialData$date < trialData$date[trialData$month == 4 & trialData$year ==
> 2014 & trialData$site == "site_1"][1]] <- "survey_2013"
>
>
>
> #filter trialData
>
> trialData <- trialData %>% filter(id == "id_786/3")
>
>
>
> *#attempt 2 works: code for survey*
>
> trialData$survey_year[trialData$date >= trialData$date[trialData$survey_start
> == "Y" & trialData$year == 2013 & trialData$site == "site_1"][1] &
> trialData$date < trialData$date[trialData$month == 4 & trialData$year ==
> 2014 & trialData$site == "site_1"][1]] <- "survey_2013"
>
>
>
>
>
>
>
> *From: *Eric Berger <ericjberger at gmail.com>
> *Date: *Thursday, 22 February 2018 at 13:05
> *To: *Kevin Wamae <KWamae at kemri-wellcome.org>
> *Cc: *"R-help at r-project.org" <R-help at r-project.org>
> *Subject: *Re: [R] alternative for multiple if_else statements
>
>
>
> Hi,
>
> 1. I think the reason that the different ordering leads to different
> results is because of the following:
>
>     date[ some condition is true ][1]
>
>     will give you an NA if there are no rows where 'some condition holds'.
>
>     In the code that 'works' you don't have such a situation, but in the
> code that 'does not work' you presumably hit an NA before you get to the
> result that you really want.
>
> 2. I am not a big fan of your "nested if" layout. I think you could
> rewrite it more clearly - and without nesting - with something like
>
>
>
>      > trialData$survey_year <- rep(NA_character_, nrow(trialData))
>
>      > trialData$survey_year[ condition for survey_2007 ] <- "survey_2007"
>
>      > trialData$survey_year[ condition for survey_2008 ] <- "survey_2008"
>
>      > etc
>
>
>
> HTH,
>
> Eric
>
>
>
> On Wed, Feb 21, 2018 at 10:33 PM, Kevin Wamae <KWamae at kemri-wellcome.org>
> wrote:
>
> Hi, I am having trouble trying to figure out why if_else is behaving the
> way it is, it may be my code or the way the data is structured.
>
> Below is a snapshot of a database am working on and it represents a
> longitudinal survey of study participants in a trial with weekly follow up.
>
> The variable "survey_start" represents the start of the study-defined one
> year follow up (which we called "survey_year").
>
> I am trying to populate all subsequent entries for each participant, per
> survey year, with the entry "survey" followed by an underscore and the
> respective year, eg. survey_2014.
>
> There are missing entries such as the participant represented here, wasn't
> available at the start of the 2015 survey. Also, some participants don?t
> have complete one-year follow ups but I still need to include them.
>
> I have written two codes, first one fails while the second works, the only
> difference being I have reversed the order in which the entries are
> populated in the second code (from 2007-2016 to 2016-2007) and removed the
> if_else statement for 2015. Also noticed, that for the second code, which
> spans the years 2007-2016 (less 2015), if a participants entries start from
> 2010-2016, the code fails.
>
> Kindly assist in figuring this out...or better yet, an alternative.
>
>     trialData <- structure(list(study = c("site_1", "site_1", "site_1",
> "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1"), studyno = c("child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1"), date = structure(c(16078, 16085, 16092,
> 16098, 16104, 16115, 16121, 16129, 16135, 16140, 16146, 16156,
> 16162, 16168, 16177, 16185, 16191, 16195, 16203, 16210, 16217,
> 16225, 16234, 16237, 16246, 16253, 16262, 16269, 16278, 16283,
> 16288, 16297, 16304, 16311, 16319, 16326, 16332, 16337, 16346,
> 16353, 16360, 16366, 16370, 16381, 16384, 16395, 16399, 16407,
> 16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477, 16484,
> 16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
> 16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613,
> 16620, 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681,
> 16688, 16693, 16702, 16706, 16714, 16721, 16728, 16734, 16745,
> 16749, 16757, 16764, 16769, 16778, 16785, 16792, 16805, 16812,
> 16819, 16830, 16832, 16839, 16846, 16856, 16862, 16867, 16877,
> 16884, 16890, 16898, 16904, 16912, 16917, 16923, 16936, 16938,
> 16953, 16960, 16966, 16973, 16980), class = "Date"), year = c(2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L,
> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L,
> 12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
> 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L,
> 11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L,
> 6L, 6L), survey_start = c("", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "")), class = "data.frame", row.names = c(NA,
> -125L), .Names = c("study", "studyno", "date", "year", "month",
> "survey_start"))
>
>
> code 1 fails:
>
> trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
> mutate(survey_year = if_else(date >= date[survey_start == "Y" & year ==
> 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 &
> study == "site_1"][1], "survey_2007",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 &
> study == "site_1"][1], "survey_2008",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 &
> study == "site_1"][1], "survey_2009",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 &
> study == "site_1"][1], "survey_2010",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 &
> study == "site_1"][1], "survey_2011",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 &
> study == "site_1"][1], "survey_2012",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 &
> study == "site_1"][1], "survey_2013",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 &
> study == "site_1"][1], "survey_2014",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2015 & study == "site_1"][1] & date < date[month == 3 & year == 2016 &
> study == "site_1"][1], "survey_2015",
>                      if_else(date >= date[survey_start == "Y" & year ==
> 2016 & study == "site_1"][1], "survey_2016","")))))))))))
>
> code 2 works:
>
>     trialData <- trialData %>% arrange(studyno, date) %>%
> group_by(studyno) %>%
>   mutate(survey_year = if_else(date >= date[survey_start == "Y" & year ==
> 2016 & study == "site_1"][1]
>                , "survey_2016",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 &
> study == "site_1"][1], "survey_2014",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 &
> study == "site_1"][1], "survey_2013",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 &
> study == "site_1"][1], "survey_2012",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 &
> study == "site_1"][1], "survey_2011",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 &
> study == "site_1"][1], "survey_2010",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 &
> study == "site_1"][1], "survey_2009",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 &
> study == "site_1"][1], "survey_2008",
>                            if_else(date >= date[survey_start == "Y" & year
> == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 &
> study == "site_1"][1], "survey_2007",""))))))))))
>
> ______________________________________________________________________
>
> This e-mail contains information which is confidential. It is intended
> only for the use of the named recipient. If you have received this e-mail
> in error, please let us know by replying to the sender, and immediately
> delete it from your system.  Please note, that in these circumstances, the
> use, disclosure, distribution or copying of this information is strictly
> prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility
> for the  accuracy or completeness of this message as it has been
> transmitted over a public network. Although the Programme has taken
> reasonable precautions to ensure no viruses are present in emails, it
> cannot accept responsibility for any loss or damage arising from the use of
> the email or attachments. Any views expressed in this message are those of
> the individual sender, except where the sender specifically states them to
> be the views of KEMRI-Wellcome Trust Programme.
> ______________________________________________________________________
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________________________________
>
> This e-mail contains information which is confidential. It is intended
> only for the use of the named recipient. If you have received this e-mail
> in error, please let us know by replying to the sender, and immediately
> delete it from your system. Please note, that in these circumstances, the
> use, disclosure, distribution or copying of this information is strictly
> prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility
> for the accuracy or completeness of this message as it has been transmitted
> over a public network. Although the Programme has taken reasonable
> precautions to ensure no viruses are present in emails, it cannot accept
> responsibility for any loss or damage arising from the use of the email or
> attachments. Any views expressed in this message are those of the
> individual sender, except where the sender specifically states them to be
> the views of KEMRI-Wellcome Trust Programme.
> ______________________________________________________________________
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Thu Feb 22 14:57:37 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 22 Feb 2018 08:57:37 -0500
Subject: [R] alternative for multiple if_else statements
In-Reply-To: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
References: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
Message-ID: <CA+vqiLHPzbZ1nPtg9H2DaMCsg7ac7zp2NOe3gNwjK6L3kg=Beg@mail.gmail.com>

I don't fully understand the logic you are trying to implement, but
something along the lines of

foo <- cut(trialData$date,
           breaks = as.Date(c("2007-01-01",
                              "2008-05-01",
                              "2009-04-01",
                              "2010-05-01",
                              "2011-05-01",
                              "2012-04-01",
                              "2013-04-01",
                              "2014-04-01",
                              "2015-04-01",
                              "2016-03-01",
                              "2017-01-01")))

might work.

Best,
Ista

On Wed, Feb 21, 2018 at 3:33 PM, Kevin Wamae <KWamae at kemri-wellcome.org> wrote:
> Hi, I am having trouble trying to figure out why if_else is behaving the way it is, it may be my code or the way the data is structured.
>
> Below is a snapshot of a database am working on and it represents a longitudinal survey of study participants in a trial with weekly follow up.
>
> The variable "survey_start" represents the start of the study-defined one year follow up (which we called "survey_year").
>
> I am trying to populate all subsequent entries for each participant, per survey year, with the entry "survey" followed by an underscore and the respective year, eg. survey_2014.
>
> There are missing entries such as the participant represented here, wasn't available at the start of the 2015 survey. Also, some participants don?t have complete one-year follow ups but I still need to include them.
>
> I have written two codes, first one fails while the second works, the only difference being I have reversed the order in which the entries are populated in the second code (from 2007-2016 to 2016-2007) and removed the if_else statement for 2015. Also noticed, that for the second code, which spans the years 2007-2016 (less 2015), if a participants entries start from 2010-2016, the code fails.
>
> Kindly assist in figuring this out...or better yet, an alternative.
>
>     trialData <- structure(list(study = c("site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1"), studyno = c("child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1"), date = structure(c(16078, 16085, 16092,
> 16098, 16104, 16115, 16121, 16129, 16135, 16140, 16146, 16156,
> 16162, 16168, 16177, 16185, 16191, 16195, 16203, 16210, 16217,
> 16225, 16234, 16237, 16246, 16253, 16262, 16269, 16278, 16283,
> 16288, 16297, 16304, 16311, 16319, 16326, 16332, 16337, 16346,
> 16353, 16360, 16366, 16370, 16381, 16384, 16395, 16399, 16407,
> 16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477, 16484,
> 16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
> 16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613,
> 16620, 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681,
> 16688, 16693, 16702, 16706, 16714, 16721, 16728, 16734, 16745,
> 16749, 16757, 16764, 16769, 16778, 16785, 16792, 16805, 16812,
> 16819, 16830, 16832, 16839, 16846, 16856, 16862, 16867, 16877,
> 16884, 16890, 16898, 16904, 16912, 16917, 16923, 16936, 16938,
> 16953, 16960, 16966, 16973, 16980), class = "Date"), year = c(2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L,
> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L,
> 12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
> 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L,
> 11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L,
> 6L, 6L), survey_start = c("", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "")), class = "data.frame", row.names = c(NA,
> -125L), .Names = c("study", "studyno", "date", "year", "month",
> "survey_start"))
>
>
> code 1 fails:
>
> trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
> mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",
>                      if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
>                      if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
>                      if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
>                      if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
>                      if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
>                      if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
>                      if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
>                      if_else(date >= date[survey_start == "Y" & year == 2015 & study == "site_1"][1] & date < date[month == 3 & year == 2016 & study == "site_1"][1], "survey_2015",
>                      if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1], "survey_2016","")))))))))))
>
> code 2 works:
>
>     trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
>   mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1]                                                               , "survey_2016",
>                            if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
>                            if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
>                            if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
>                            if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
>                            if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
>                            if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
>                            if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
>                            if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",""))))))))))
>
> ______________________________________________________________________
>
> This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
> ______________________________________________________________________
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fisher at plessthan.com  Thu Feb 22 21:35:07 2018
From: fisher at plessthan.com (Dennis Fisher)
Date: Thu, 22 Feb 2018 12:35:07 -0800
Subject: [R] Problem with geterrmessage()
Message-ID: <8F658880-1E79-4E81-BC8D-932ADE4A0521@plessthan.com>

R 3.4.3
OS X

Colleagues

I have a 20K line script in which I encounter an unexpected problem.

If the script detects presence of a particular file USERCODE.txt, it executes:
	source(?USERCODE.txt?)
If that file is not present, the script executes without a problem.

There might be syntax errors in USERCODE.txt; therefore, the code above is embedded in a try command:
	try(source(?USERCODE.txt", local=T), silent=T)
followed by:
	ERRORMESSAGE <- geterrmessage()

For unclear reasons, an earlier command is yielding an error message:
	unused argument (\"\\n\")
Despite identifying the exact source of that error, I can?t fix it (and it is of no consequence).

Ideally, I would like to clear out the pre-existing error message immediately before the ?try? command (or perhaps at that particular location where it is being created) ? but I can?t figure out how to do so.

Any suggestions would be welcome.

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From luke-tierney at uiowa.edu  Thu Feb 22 21:45:16 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 22 Feb 2018 14:45:16 -0600 (CST)
Subject: [R] Problem with geterrmessage()
In-Reply-To: <8F658880-1E79-4E81-BC8D-932ADE4A0521@plessthan.com>
References: <8F658880-1E79-4E81-BC8D-932ADE4A0521@plessthan.com>
Message-ID: <alpine.DEB.2.20.1802221441470.26971@luke-Latitude>

Only the default error handler puts the error message in a buffer
where it can be retrieved with geterrmessage. try() replaces the
default error handler. Either look at the value returned by try() or
use tryCatch with conditionMessage.

Best,

luke

On Thu, 22 Feb 2018, Dennis Fisher wrote:

> R 3.4.3
> OS X
>
> Colleagues
>
> I have a 20K line script in which I encounter an unexpected problem.
>
> If the script detects presence of a particular file USERCODE.txt, it executes:
> 	source(?USERCODE.txt?)
> If that file is not present, the script executes without a problem.
>
> There might be syntax errors in USERCODE.txt; therefore, the code above is embedded in a try command:
> 	try(source(?USERCODE.txt", local=T), silent=T)
> followed by:
> 	ERRORMESSAGE <- geterrmessage()
>
> For unclear reasons, an earlier command is yielding an error message:
> 	unused argument (\"\\n\")
> Despite identifying the exact source of that error, I can?t fix it (and it is of no consequence).
>
> Ideally, I would like to clear out the pre-existing error message immediately before the ?try? command (or perhaps at that particular location where it is being created) ? but I can?t figure out how to do so.
>
> Any suggestions would be welcome.
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From fisher at plessthan.com  Thu Feb 22 22:01:37 2018
From: fisher at plessthan.com (Dennis Fisher)
Date: Thu, 22 Feb 2018 13:01:37 -0800
Subject: [R] Problem with geterrmessage()
In-Reply-To: <alpine.DEB.2.20.1802221441470.26971@luke-Latitude>
References: <8F658880-1E79-4E81-BC8D-932ADE4A0521@plessthan.com>
 <alpine.DEB.2.20.1802221441470.26971@luke-Latitude>
Message-ID: <6624DE93-1BE5-426A-90A5-0B8747DEF6C2@plessthan.com>

Luke

Thanks ? I revised the code to:
	ERRORMESSAGE <- try(source(USERSCRIPTFILE, local=T), silent=T) 

print(ERRORMESSAGE) now returns:
$value
[1] 0

$visible
[1] FALSE

Not clear what to make of that.

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com




> On Feb 22, 2018, at 12:45 PM, luke-tierney at uiowa.edu wrote:
> 
> Only the default error handler puts the error message in a buffer
> where it can be retrieved with geterrmessage. try() replaces the
> default error handler. Either look at the value returned by try() or
> use tryCatch with conditionMessage.
> 
> Best,
> 
> luke
> 
> On Thu, 22 Feb 2018, Dennis Fisher wrote:
> 
>> R 3.4.3
>> OS X
>> 
>> Colleagues
>> 
>> I have a 20K line script in which I encounter an unexpected problem.
>> 
>> If the script detects presence of a particular file USERCODE.txt, it executes:
>> 	source(?USERCODE.txt?)
>> If that file is not present, the script executes without a problem.
>> 
>> There might be syntax errors in USERCODE.txt; therefore, the code above is embedded in a try command:
>> 	try(source(?USERCODE.txt", local=T), silent=T)
>> followed by:
>> 	ERRORMESSAGE <- geterrmessage()
>> 
>> For unclear reasons, an earlier command is yielding an error message:
>> 	unused argument (\"\\n\")
>> Despite identifying the exact source of that error, I can?t fix it (and it is of no consequence).
>> 
>> Ideally, I would like to clear out the pre-existing error message immediately before the ?try? command (or perhaps at that particular location where it is being created) ? but I can?t figure out how to do so.
>> 
>> Any suggestions would be welcome.
>> 
>> Dennis
>> 
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>   Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From bgunter.4567 at gmail.com  Thu Feb 22 22:10:07 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 22 Feb 2018 13:10:07 -0800
Subject: [R] Problem with geterrmessage()
In-Reply-To: <6624DE93-1BE5-426A-90A5-0B8747DEF6C2@plessthan.com>
References: <8F658880-1E79-4E81-BC8D-932ADE4A0521@plessthan.com>
 <alpine.DEB.2.20.1802221441470.26971@luke-Latitude>
 <6624DE93-1BE5-426A-90A5-0B8747DEF6C2@plessthan.com>
Message-ID: <CAGxFJbT3S3+Z8TG2nwvGXDzZRCeUZCkm6fS_B7+vb0g1EqZ16Q@mail.gmail.com>

Please read ?try (again) carefully.In paticular note (under Value):

"The value of the expression if expr is evaluated without error, but an
invisible object of class "try-error"containing the error message, and the
error condition as the "condition" attribute, if it fails."

so:

attr(ERRORMESSAGE, "conditon") will give you the error conditon.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Feb 22, 2018 at 1:01 PM, Dennis Fisher <fisher at plessthan.com> wrote:

> Luke
>
> Thanks ? I revised the code to:
>         ERRORMESSAGE <- try(source(USERSCRIPTFILE, local=T), silent=T)
>
> print(ERRORMESSAGE) now returns:
> $value
> [1] 0
>
> $visible
> [1] FALSE
>
> Not clear what to make of that.
>
> Dennis
>
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
>
>
>
> > On Feb 22, 2018, at 12:45 PM, luke-tierney at uiowa.edu wrote:
> >
> > Only the default error handler puts the error message in a buffer
> > where it can be retrieved with geterrmessage. try() replaces the
> > default error handler. Either look at the value returned by try() or
> > use tryCatch with conditionMessage.
> >
> > Best,
> >
> > luke
> >
> > On Thu, 22 Feb 2018, Dennis Fisher wrote:
> >
> >> R 3.4.3
> >> OS X
> >>
> >> Colleagues
> >>
> >> I have a 20K line script in which I encounter an unexpected problem.
> >>
> >> If the script detects presence of a particular file USERCODE.txt, it
> executes:
> >>      source(?USERCODE.txt?)
> >> If that file is not present, the script executes without a problem.
> >>
> >> There might be syntax errors in USERCODE.txt; therefore, the code above
> is embedded in a try command:
> >>      try(source(?USERCODE.txt", local=T), silent=T)
> >> followed by:
> >>      ERRORMESSAGE <- geterrmessage()
> >>
> >> For unclear reasons, an earlier command is yielding an error message:
> >>      unused argument (\"\\n\")
> >> Despite identifying the exact source of that error, I can?t fix it (and
> it is of no consequence).
> >>
> >> Ideally, I would like to clear out the pre-existing error message
> immediately before the ?try? command (or perhaps at that particular
> location where it is being created) ? but I can?t figure out how to do so.
> >>
> >> Any suggestions would be welcome.
> >>
> >> Dennis
> >>
> >> Dennis Fisher MD
> >> P < (The "P Less Than" Company)
> >> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> >> www.PLessThan.com
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > --
> > Luke Tierney
> > Ralph E. Wareham Professor of Mathematical Sciences
> > University of Iowa                  Phone:             319-335-3386
> > Department of Statistics and        Fax:               319-335-3017
> >   Actuarial Science
> > 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> > Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From faiz7r at gmail.com  Fri Feb 23 05:09:49 2018
From: faiz7r at gmail.com (faiz rasool)
Date: Fri, 23 Feb 2018 09:09:49 +0500
Subject: [R] How to Save the residuals of an LM object greater or less than
 a certin value to an R object?
Message-ID: <CAFhDWBUsFJGmM6Hv7c89ec7Hdf=r6bDKekdSyuxazf=-SDNmkQ@mail.gmail.com>

Dear list members,

I want to  save residuals above or less than a certain value to an R
object. I have performed a multiple linear regression, and now I want
to find out which cases have a residual of above + 2.5 and ? 2.5.

Below I provide the R  commands I have used.

Reg<-lm(a~b+c+d+e+f) # perform multiple regression with a as the
dependent variable.

Residuals<-residuals(reg) # store residuals to an R object.
stdresiduals<-rstandard(reg) #save the standardized residuals.
#now I want to type a  command that will save the residuals  of
certain range to an object.

I realize that by plotting  the data I can quickly  see the  residuals
outside a certain boundtry, however, I am totally blind, so visually
inspecting the plot is not possible for me.

Thank you for any help.

Regards,
Faiz.


From boris.steipe at utoronto.ca  Fri Feb 23 05:31:44 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 22 Feb 2018 23:31:44 -0500
Subject: [R] Modified Band Depth
In-Reply-To: <CAH5op1beN95nRT6Y8h_0ooEoFNfv0rqmHYLms6DMX6P_pDz5FQ@mail.gmail.com>
References: <CAH5op1Z531iZC7tr2s6GALft-V-7KU5Zsb+JBmMJLw3kD8CUdw@mail.gmail.com>
 <D2A57608-18E6-463C-8921-A7E28D94AC66@utoronto.ca>
 <CAH5op1beN95nRT6Y8h_0ooEoFNfv0rqmHYLms6DMX6P_pDz5FQ@mail.gmail.com>
Message-ID: <C1E91241-D3B7-4091-BE4F-EA9BB5A97799@utoronto.ca>

Please keep the list CC'd.

In order to use the algorithms, I would assume you need to understand them. I hope you find it a productive challenge to express your understanding in code. Note that the article apparently spells out  what you need very explicitly in pseudocode. If you really need to work from the Matlab example, there are many resources online that explain Matlab syntax and how to translate code to R.

B.




> On Feb 22, 2018, at 2:21 AM, JoyMae Gabion <joymae.gabion at g.msuiit.edu.ph> wrote:
> 
> Thank you for the response. Honestly, I am not familiar with Matlab and not that good with R software. 
> Since I will be using R in my thesis, it will be helpful if there are R codes available for that computation. 
> Can I get your help for this, Sir?
> 
> 
> Joy Mae
> 
> On Thu, Feb 22, 2018 at 4:08 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> If you are talking about the "Supporting Information" - that contains only one small piece of matlab code that looks pretty trivial to translate if necessary. The rest are R scripts.
> 
> What then is the problem you need to solve?
> 
> B.
> 
> 
> 
>> On Feb 21, 2018, at 9:37 AM, JoyMae Gabion <joymae.gabion at g.msuiit.edu.ph> wrote:
>> 
>> Dear Ma'am/Sir,
>> 
>> This is Joy Mae C. Gabion taking up Masters of Science in Statistics at
>> Mindanao State University ? Iligan Institute of Technology (MSU-IIT),
>> Philippines. I?m currently working on my master?s thesis and chose to base
>> it on the paper of Sun et.al (2012) which discussed the exact fast
>> computation of band depth for large functional datasets. There are codes in
>> Mathlab available in the appendix of the paper for the computation of band
>> depth and modified band depth. I just want to ask for help if there are
>> also codes available for that in R software. I highly appreciate your
>> response regarding this matter. Thank you so much.
>> 
>> 
>> 
>> Best regards,
>> 
>> Joy Mae
>> 
>> --
>> ---
>> *DISCLAIMER AND CONFIDENTIALITY NOTICE* The Mindanao Sta...{{dropped:30}}
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> ---
> DISCLAIMER AND CONFIDENTIALITY NOTICE The Mindanao State University-Iligan Institute of Technology (MSU-IIT) makes no warranties of any kind, whether expressed or implied, with respect to the MSU-IIT e-mail resources it provides. MSU-IIT will not be responsible for damages resulting from the use of MSU-IIT e-mail resources, including, but not limited to, loss of data resulting from delays, non-deliveries, missed deliveries, service interruptions caused by the negligence of a MSU-IIT employee, or by the User's error or omissions. MSU-IIT specifically denies any responsibility for the accuracy or quality of information obtained through MSU-IIT e-mail resources, except material represented as an official MSU-IIT record. Any views expressed in this e-mail are those of the individual sender and may not necessarily reflect the views of MSU-IIT, except where the message states otherwise and the sender is authorized to state them to be the views of MSU-IIT. The information contained in this e-mail, including those in its attachments, is confidential and intended only for the person(s) or entity(ies) to which it is addressed. If you are not an intended recipient, you must not read, copy, store, disclose, distribute this message, or act in reliance upon the information contained in it. If you received this e-mail in error, please contact the sender and delete the material from any computer or system.


From jdnewmil at dcn.davis.ca.us  Fri Feb 23 05:56:40 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 22 Feb 2018 20:56:40 -0800
Subject: [R] 
 How to Save the residuals of an LM object greater or less than
 a certin value to an R object?
In-Reply-To: <CAFhDWBUsFJGmM6Hv7c89ec7Hdf=r6bDKekdSyuxazf=-SDNmkQ@mail.gmail.com>
References: <CAFhDWBUsFJGmM6Hv7c89ec7Hdf=r6bDKekdSyuxazf=-SDNmkQ@mail.gmail.com>
Message-ID: <46DCF4CC-D4BB-45F3-AEE4-73124D461AA5@dcn.davis.ca.us>

Residuals are stored as a numeric vector. The R software comes with a document "Introduction to R" that discusses basic math functions and logical operators that can create logical vectors:

abs( stdresiduals ) > 2.5

It also discusses indexing using logical vectors:

stdresiduals[ abs( stdresiduals ) > 2.5 ]

Note that in most cases it is worth going  the extra step of making your example reproducible [1][2][3] because many problems arise from issues in the data or in code that you don't think is broken. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On February 22, 2018 8:09:49 PM PST, faiz rasool <faiz7r at gmail.com> wrote:
>Dear list members,
>
>I want to  save residuals above or less than a certain value to an R
>object. I have performed a multiple linear regression, and now I want
>to find out which cases have a residual of above + 2.5 and ? 2.5.
>
>Below I provide the R  commands I have used.
>
>Reg<-lm(a~b+c+d+e+f) # perform multiple regression with a as the
>dependent variable.
>
>Residuals<-residuals(reg) # store residuals to an R object.
>stdresiduals<-rstandard(reg) #save the standardized residuals.
>#now I want to type a  command that will save the residuals  of
>certain range to an object.
>
>I realize that by plotting  the data I can quickly  see the  residuals
>outside a certain boundtry, however, I am totally blind, so visually
>inspecting the plot is not possible for me.
>
>Thank you for any help.
>
>Regards,
>Faiz.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From KWamae at kemri-wellcome.org  Fri Feb 23 06:11:20 2018
From: KWamae at kemri-wellcome.org (Kevin Wamae)
Date: Fri, 23 Feb 2018 05:11:20 +0000
Subject: [R] alternative for multiple if_else statements
In-Reply-To: <CA+vqiLHPzbZ1nPtg9H2DaMCsg7ac7zp2NOe3gNwjK6L3kg=Beg@mail.gmail.com>
References: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
 <CA+vqiLHPzbZ1nPtg9H2DaMCsg7ac7zp2NOe3gNwjK6L3kg=Beg@mail.gmail.com>
Message-ID: <81A4622F-D619-4C6E-B11E-7F8630F7E0DC@kemri-wellcome.org>

Dear Ista, thank you. Let me see how best I can implement this.

Regards
------------------
Kevin Wamae

?On 22/02/2018, 16:58, "Ista Zahn" <istazahn at gmail.com> wrote:

    I don't fully understand the logic you are trying to implement, but
    something along the lines of
    
    foo <- cut(trialData$date,
               breaks = as.Date(c("2007-01-01",
                                  "2008-05-01",
                                  "2009-04-01",
                                  "2010-05-01",
                                  "2011-05-01",
                                  "2012-04-01",
                                  "2013-04-01",
                                  "2014-04-01",
                                  "2015-04-01",
                                  "2016-03-01",
                                  "2017-01-01")))
    
    might work.
    
    Best,
    Ista
    
    On Wed, Feb 21, 2018 at 3:33 PM, Kevin Wamae <KWamae at kemri-wellcome.org> wrote:
    > Hi, I am having trouble trying to figure out why if_else is behaving the way it is, it may be my code or the way the data is structured.
    >
    > Below is a snapshot of a database am working on and it represents a longitudinal survey of study participants in a trial with weekly follow up.
    >
    > The variable "survey_start" represents the start of the study-defined one year follow up (which we called "survey_year").
    >
    > I am trying to populate all subsequent entries for each participant, per survey year, with the entry "survey" followed by an underscore and the respective year, eg. survey_2014.
    >
    > There are missing entries such as the participant represented here, wasn't available at the start of the 2015 survey. Also, some participants don?t have complete one-year follow ups but I still need to include them.
    >
    > I have written two codes, first one fails while the second works, the only difference being I have reversed the order in which the entries are populated in the second code (from 2007-2016 to 2016-2007) and removed the if_else statement for 2015. Also noticed, that for the second code, which spans the years 2007-2016 (less 2015), if a participants entries start from 2010-2016, the code fails.
    >
    > Kindly assist in figuring this out...or better yet, an alternative.
    >
    >     trialData <- structure(list(study = c("site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1"), studyno = c("child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1"), date = structure(c(16078, 16085, 16092,
    > 16098, 16104, 16115, 16121, 16129, 16135, 16140, 16146, 16156,
    > 16162, 16168, 16177, 16185, 16191, 16195, 16203, 16210, 16217,
    > 16225, 16234, 16237, 16246, 16253, 16262, 16269, 16278, 16283,
    > 16288, 16297, 16304, 16311, 16319, 16326, 16332, 16337, 16346,
    > 16353, 16360, 16366, 16370, 16381, 16384, 16395, 16399, 16407,
    > 16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477, 16484,
    > 16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
    > 16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613,
    > 16620, 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681,
    > 16688, 16693, 16702, 16706, 16714, 16721, 16728, 16734, 16745,
    > 16749, 16757, 16764, 16769, 16778, 16785, 16792, 16805, 16812,
    > 16819, 16830, 16832, 16839, 16846, 16856, 16862, 16867, 16877,
    > 16884, 16890, 16898, 16904, 16912, 16917, 16923, 16936, 16938,
    > 16953, 16960, 16966, 16973, 16980), class = "Date"), year = c(2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
    > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
    > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L,
    > 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
    > 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
    > 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L,
    > 12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
    > 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
    > 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L,
    > 11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
    > 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L,
    > 6L, 6L), survey_start = c("", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "")), class = "data.frame", row.names = c(NA,
    > -125L), .Names = c("study", "studyno", "date", "year", "month",
    > "survey_start"))
    >
    >
    > code 1 fails:
    >
    > trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
    > mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",
    >                      if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
    >                      if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
    >                      if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
    >                      if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
    >                      if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
    >                      if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
    >                      if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
    >                      if_else(date >= date[survey_start == "Y" & year == 2015 & study == "site_1"][1] & date < date[month == 3 & year == 2016 & study == "site_1"][1], "survey_2015",
    >                      if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1], "survey_2016","")))))))))))
    >
    > code 2 works:
    >
    >     trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
    >   mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1]                                                               , "survey_2016",
    >                            if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
    >                            if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
    >                            if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
    >                            if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
    >                            if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
    >                            if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
    >                            if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
    >                            if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",""))))))))))
    >
    > ______________________________________________________________________
    >
    > This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
    > ______________________________________________________________________
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    


______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________

From KWamae at kemri-wellcome.org  Fri Feb 23 06:13:13 2018
From: KWamae at kemri-wellcome.org (Kevin Wamae)
Date: Fri, 23 Feb 2018 05:13:13 +0000
Subject: [R] alternative for multiple if_else statements
In-Reply-To: <CAGgJW77qxL41ycXtJQr67Sm1zG5KfLK5ZGpMFn6f7gVm9A7wPQ@mail.gmail.com>
References: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
 <CAGgJW76-LhVv-jR6ZJbdfCrWEKUameR4eXX=Q=WDokW+_1LaEA@mail.gmail.com>
 <AB833505-631B-4A06-BE05-148494A71AF1@kemri-wellcome.org>
 <CAGgJW77qxL41ycXtJQr67Sm1zG5KfLK5ZGpMFn6f7gVm9A7wPQ@mail.gmail.com>
Message-ID: <13BCA034-469F-4865-93FE-0DA746CF6835@kemri-wellcome.org>

Dear Eric, thank you for that observation.

I realised that some of the participants have duplicated ?survey_start? dates and when I corrected this, the code works.

Regards
------------------
Kevin Wamae
From: Eric Berger <ericjberger at gmail.com>
Date: Thursday, 22 February 2018 at 15:16
To: Kevin Wamae <KWamae at kemri-wellcome.org>
Cc: "R-help at r-project.org" <R-help at r-project.org>
Subject: Re: [R] alternative for multiple if_else statements

Hi Kevin,
I ran the code on the full data set and was able to reproduce the problem that you are facing.
My guess is that you have an error in your intuition and/or logic, and that this relates to the use of the subscript [1].
Specifically, on the full dataset, the condition
trialData$date[trialData$survey_start == "Y" & trialData$year == 2013 & trialData$site == "site_1"]

yields 412 matches, of which there are 9 unique ones, specifically

April 2,3,4,5,8,10,11,16,17

In the full data set the first element that appears, i.e. subscript[1], is "2013-04-04".

In the filtered data set the first element that appears is "2013-04-05".

I hope that is enough information for you to make further progress from here.

Best,
Eric



On Thu, Feb 22, 2018 at 1:28 PM, Kevin Wamae <KWamae at kemri-wellcome.org<mailto:KWamae at kemri-wellcome.org>> wrote:
Dear Eric, wow, this seems to do the trick. But I have encountered a problem.

I have tested it on the larger dataset and it seems to work on a filtered dataset but not on the whole dataset (attached). See below script..

#load packages
Library(dplyr)

#load data
trialData <- fread("trialData.txt") %>% mutate(date = as.Date(date,"%d/%m/%Y"))

#create blank variable
trialData$survey_year <- rep(NA_character_, nrow(trialData))

#attempt 1 fails: code for survey
trialData$survey_year[trialData$date >= trialData$date[trialData$survey_start == "Y" & trialData$year == 2013 & trialData$site == "site_1"][1] & trialData$date < trialData$date[trialData$month == 4 & trialData$year == 2014 & trialData$site == "site_1"][1]] <- "survey_2013"

#filter trialData
trialData <- trialData %>% filter(id == "id_786/3")

#attempt 2 works: code for survey
trialData$survey_year[trialData$date >= trialData$date[trialData$survey_start == "Y" & trialData$year == 2013 & trialData$site == "site_1"][1] & trialData$date < trialData$date[trialData$month == 4 & trialData$year == 2014 & trialData$site == "site_1"][1]] <- "survey_2013"



From: Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>>
Date: Thursday, 22 February 2018 at 13:05
To: Kevin Wamae <KWamae at kemri-wellcome.org<mailto:KWamae at kemri-wellcome.org>>
Cc: "R-help at r-project.org<mailto:R-help at r-project.org>" <R-help at r-project.org<mailto:R-help at r-project.org>>
Subject: Re: [R] alternative for multiple if_else statements

Hi,
1. I think the reason that the different ordering leads to different results is because of the following:
    date[ some condition is true ][1]
    will give you an NA if there are no rows where 'some condition holds'.
    In the code that 'works' you don't have such a situation, but in the code that 'does not work' you presumably hit an NA before you get to the result that you really want.
2. I am not a big fan of your "nested if" layout. I think you could rewrite it more clearly - and without nesting - with something like

     > trialData$survey_year <- rep(NA_character_, nrow(trialData))
     > trialData$survey_year[ condition for survey_2007 ] <- "survey_2007"
     > trialData$survey_year[ condition for survey_2008 ] <- "survey_2008"
     > etc

HTH,
Eric

On Wed, Feb 21, 2018 at 10:33 PM, Kevin Wamae <KWamae at kemri-wellcome.org<mailto:KWamae at kemri-wellcome.org>> wrote:
Hi, I am having trouble trying to figure out why if_else is behaving the way it is, it may be my code or the way the data is structured.

Below is a snapshot of a database am working on and it represents a longitudinal survey of study participants in a trial with weekly follow up.

The variable "survey_start" represents the start of the study-defined one year follow up (which we called "survey_year").

I am trying to populate all subsequent entries for each participant, per survey year, with the entry "survey" followed by an underscore and the respective year, eg. survey_2014.

There are missing entries such as the participant represented here, wasn't available at the start of the 2015 survey. Also, some participants don?t have complete one-year follow ups but I still need to include them.

I have written two codes, first one fails while the second works, the only difference being I have reversed the order in which the entries are populated in the second code (from 2007-2016 to 2016-2007) and removed the if_else statement for 2015. Also noticed, that for the second code, which spans the years 2007-2016 (less 2015), if a participants entries start from 2010-2016, the code fails.

Kindly assist in figuring this out...or better yet, an alternative.

    trialData <- structure(list(study = c("site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
"site_1", "site_1"), studyno = c("child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
"child_1", "child_1"), date = structure(c(16078, 16085, 16092,
16098, 16104, 16115, 16121, 16129, 16135, 16140, 16146, 16156,
16162, 16168, 16177, 16185, 16191, 16195, 16203, 16210, 16217,
16225, 16234, 16237, 16246, 16253, 16262, 16269, 16278, 16283,
16288, 16297, 16304, 16311, 16319, 16326, 16332, 16337, 16346,
16353, 16360, 16366, 16370, 16381, 16384, 16395, 16399, 16407,
16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477, 16484,
16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613,
16620, 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681,
16688, 16693, 16702, 16706, 16714, 16721, 16728, 16734, 16745,
16749, 16757, 16764, 16769, 16778, 16785, 16792, 16805, 16812,
16819, 16830, 16832, 16839, 16846, 16856, 16862, 16867, 16877,
16884, 16890, 16898, 16904, 16912, 16917, 16923, 16936, 16938,
16953, 16960, 16966, 16973, 16980), class = "Date"), year = c(2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
2014L, 2014L, 2014L, 2014L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L,
12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 11L,
11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L,
6L, 6L), survey_start = c("", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
"", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "",
"", "", "", "", "", "")), class = "data.frame", row.names = c(NA,
-125L), .Names = c("study", "studyno", "date", "year", "month",
"survey_start"))


code 1 fails:

trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",
                     if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
                     if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
                     if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
                     if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
                     if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
                     if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
                     if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
                     if_else(date >= date[survey_start == "Y" & year == 2015 & study == "site_1"][1] & date < date[month == 3 & year == 2016 & study == "site_1"][1], "survey_2015",
                     if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1], "survey_2016","")))))))))))

code 2 works:

    trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
  mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2016 & study == "site_1"][1]                                                               , "survey_2016",
                           if_else(date >= date[survey_start == "Y" & year == 2014 & study == "site_1"][1] & date < date[month == 4 & year == 2015 & study == "site_1"][1], "survey_2014",
                           if_else(date >= date[survey_start == "Y" & year == 2013 & study == "site_1"][1] & date < date[month == 4 & year == 2014 & study == "site_1"][1], "survey_2013",
                           if_else(date >= date[survey_start == "Y" & year == 2012 & study == "site_1"][1] & date < date[month == 4 & year == 2013 & study == "site_1"][1], "survey_2012",
                           if_else(date >= date[survey_start == "Y" & year == 2011 & study == "site_1"][1] & date < date[month == 4 & year == 2012 & study == "site_1"][1], "survey_2011",
                           if_else(date >= date[survey_start == "Y" & year == 2010 & study == "site_1"][1] & date < date[month == 5 & year == 2011 & study == "site_1"][1], "survey_2010",
                           if_else(date >= date[survey_start == "Y" & year == 2009 & study == "site_1"][1] & date < date[month == 5 & year == 2010 & study == "site_1"][1], "survey_2009",
                           if_else(date >= date[survey_start == "Y" & year == 2008 & study == "site_1"][1] & date < date[month == 4 & year == 2009 & study == "site_1"][1], "survey_2008",
                           if_else(date >= date[survey_start == "Y" & year == 2007 & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study == "site_1"][1], "survey_2007",""))))))))))

______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system. Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________


______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________

	[[alternative HTML version deleted]]


From nevil.amos at gmail.com  Fri Feb 23 07:00:04 2018
From: nevil.amos at gmail.com (nevil amos)
Date: Fri, 23 Feb 2018 17:00:04 +1100
Subject: [R] Mapedit::selectMap in shiny map.
Message-ID: <CAN9eD7nJPiT54H=vP7ithv9GFyOC7wQ2STiyG=82LAjj=CoKyw@mail.gmail.com>

I would like to select polygons from an existing spatial polygon data set
interactively in a shiny leaflet map.
The process is straightforward in leaflet/ mapedit, however I need to
include the procedure in a shiny app map interface. I cannot work out how
to incorporate the selectMap() in the shiny app. An error is returned:

Here is some toy code showing the code in using leaflet locally:

library(mapedit)
library(leaflet)
options(stringsAsFactors = F)
bounds <- c(5.956063, 10.49511, 45.81706, 47.80848 )

lf <- leaflet() %>%
addTiles()%>%
addPolygons(data =gadmCHE,
label = ~NAME_1,
layerId = ~NAME_1)

selected <-selectMap(lf)

##the above works fine and returns a dataframe giving the ids of the
selected polygons.

##however the code below - trying to implement in shiny fails with "Can?t
call runApp() from within runApp(). If your application code contains
runApp(), please remove it.

library(shiny)
library(leaflet)
library(mapedit)

ui <- fluidPage(
leafletOutput(?mymap?)
)

server <- function(input, output, session) {

lf<-leaflet() %>%
addTiles()%>%
addPolygons(data =gadmCHE,
label = ~NAME_1,
layerId = ~NAME_1)
output$mymap <- renderLeaflet({selectMap(lf)
})
}
shinyApp(ui, server)

##How do I achieve the same in a shiny map?

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Feb 23 10:43:23 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Feb 2018 10:43:23 +0100
Subject: [R] Problem with geterrmessage()
In-Reply-To: <6624DE93-1BE5-426A-90A5-0B8747DEF6C2@plessthan.com>
References: <8F658880-1E79-4E81-BC8D-932ADE4A0521@plessthan.com>
 <alpine.DEB.2.20.1802221441470.26971@luke-Latitude>
 <6624DE93-1BE5-426A-90A5-0B8747DEF6C2@plessthan.com>
Message-ID: <23183.57915.418200.40730@stat.math.ethz.ch>

>>>>> Dennis Fisher <fisher at plessthan.com>
>>>>>     on Thu, 22 Feb 2018 13:01:37 -0800 writes:

    > Luke
    > Thanks ? I revised the code to:
    > ERRORMESSAGE <- try(source(USERSCRIPTFILE, local=T), silent=T) 

    > print(ERRORMESSAGE) now returns:
    > $value
    > [1] 0

    > $visible
    > [1] FALSE

    > Not clear what to make of that.
    > Dennis

The help page   ?try   has

contained for a long time

     ?try? is implemented using ?tryCatch?; for programming, instead of
     ?try(expr, silent = TRUE)?, something like ?tryCatch(expr, error =
     function(e) e)? (or other simple error handler functions) may be
     more efficient and flexible.

and you do use 'silent=T' (which is "unsafe" (*) !)

I'd strongly advocate you use the 2nd proposition by given by
Luke Tierney (cited below):
 Learn to use tryCatch() instead of try() and then such things
 can be done considerably less obscurely. 

Best,
Martin Maechler, ETH Zurich

--
*) Using 'T' instead of 'TRUE'  (of 'F' instead of 'FALSE' *is* unsafe):
   a previous  'T <- 0'  will change what you really wanted.
   TRUE and FALSE are  "constants" in R, whereas  T and F are variables


    > Dennis Fisher MD
    > P < (The "P Less Than" Company)
    > Phone / Fax: 1-866-PLessThan (1-866-753-7784)
    > www.PLessThan.com




    >> On Feb 22, 2018, at 12:45 PM, luke-tierney at uiowa.edu wrote:
    >> 
    >> Only the default error handler puts the error message in a buffer
    >> where it can be retrieved with geterrmessage. try() replaces the
    >> default error handler. Either look at the value returned by try() or
    >> use tryCatch with conditionMessage.
    >> 
    >> Best,
    >> 
    >> luke
    >> 
    >> On Thu, 22 Feb 2018, Dennis Fisher wrote:
    >> 
    >>> R 3.4.3
    >>> OS X
    >>> 
    >>> Colleagues
    >>> 
    >>> I have a 20K line script in which I encounter an unexpected problem.
    >>> 
    >>> If the script detects presence of a particular file USERCODE.txt, it executes:
    >>> source(?USERCODE.txt?)
    >>> If that file is not present, the script executes without a problem.
    >>> 
    >>> There might be syntax errors in USERCODE.txt; therefore, the code above is embedded in a try command:
    >>> try(source(?USERCODE.txt", local=T), silent=T)
    >>> followed by:
    >>> ERRORMESSAGE <- geterrmessage()
    >>> 
    >>> For unclear reasons, an earlier command is yielding an error message:
    >>> unused argument (\"\\n\")
    >>> Despite identifying the exact source of that error, I can?t fix it (and it is of no consequence).
    >>> 
    >>> Ideally, I would like to clear out the pre-existing error message immediately before the ?try? command (or perhaps at that particular location where it is being created) ? but I can?t figure out how to do so.
    >>> 
    >>> Any suggestions would be welcome.
    >>> 
    >>> Dennis
    >>> 
    >>> Dennis Fisher MD
    >>> P < (The "P Less Than" Company)
    >>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
    >>> www.PLessThan.com
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.
    >>> 
    >> 
    >> -- 
    >> Luke Tierney
    >> Ralph E. Wareham Professor of Mathematical Sciences
    >> University of Iowa                  Phone:             319-335-3386
    >> Department of Statistics and        Fax:               319-335-3017
    >> Actuarial Science
    >> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
    >> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Feb 23 12:40:54 2018
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Fri, 23 Feb 2018 12:40:54 +0100
Subject: [R] 
 How to Save the residuals of an LM object greater or less than
 a certin value to an R object?
In-Reply-To: <46DCF4CC-D4BB-45F3-AEE4-73124D461AA5@dcn.davis.ca.us>
References: <CAFhDWBUsFJGmM6Hv7c89ec7Hdf=r6bDKekdSyuxazf=-SDNmkQ@mail.gmail.com>
 <46DCF4CC-D4BB-45F3-AEE4-73124D461AA5@dcn.davis.ca.us>
Message-ID: <3EE887F8-D727-42C0-8BAC-42647CC0998C@gmail.com>

Also,

which( abs( stdresiduals ) > 2.5 )

will tell you which of the standardized residuals are bigger than 2.5 in absolute value. It returns a vector of indices, as in

> set.seed(1234)
> x <- rnorm(100)
> which (abs(x) > 2.5)
[1] 62
> x[62]
[1] 2.548991


-pd

> On 23 Feb 2018, at 05:56 , Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
> 
> Residuals are stored as a numeric vector. The R software comes with a document "Introduction to R" that discusses basic math functions and logical operators that can create logical vectors:
> 
> abs( stdresiduals ) > 2.5
> 
> It also discusses indexing using logical vectors:
> 
> stdresiduals[ abs( stdresiduals ) > 2.5 ]
> 
> Note that in most cases it is worth going  the extra step of making your example reproducible [1][2][3] because many problems arise from issues in the data or in code that you don't think is broken. 
> 
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> 
> [2] http://adv-r.had.co.nz/Reproducibility.html
> 
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 22, 2018 8:09:49 PM PST, faiz rasool <faiz7r at gmail.com> wrote:
>> Dear list members,
>> 
>> I want to  save residuals above or less than a certain value to an R
>> object. I have performed a multiple linear regression, and now I want
>> to find out which cases have a residual of above + 2.5 and ? 2.5.
>> 
>> Below I provide the R  commands I have used.
>> 
>> Reg<-lm(a~b+c+d+e+f) # perform multiple regression with a as the
>> dependent variable.
>> 
>> Residuals<-residuals(reg) # store residuals to an R object.
>> stdresiduals<-rstandard(reg) #save the standardized residuals.
>> #now I want to type a  command that will save the residuals  of
>> certain range to an object.
>> 
>> I realize that by plotting  the data I can quickly  see the  residuals
>> outside a certain boundtry, however, I am totally blind, so visually
>> inspecting the plot is not possible for me.
>> 
>> Thank you for any help.
>> 
>> Regards,
>> Faiz.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From markpayneatwork at gmail.com  Fri Feb 23 12:47:08 2018
From: markpayneatwork at gmail.com (Mark R Payne)
Date: Fri, 23 Feb 2018 12:47:08 +0100
Subject: [R] Quantile regression with some parameters fixed across tau..
Message-ID: <CAGBzUO8gorPJGz8T2sTijEx12YxqmsJ8VnFMs+3bhfirw2wCdw@mail.gmail.com>

Hi,

I would like to fit the following model with quantile regression:

y ~ alpha + beta

where both alpha and beta are factors. The conceptual model I have in my
head is that alpha is a constant set of values, that should be independent
of the quantile, tau and that all of the variability arises due to beta. If
I just fit the model using the quantreg package like so:

mdl <- rq( y ~ alpha +beta, data, tau=c(0.25,0.5,0.75))

..the values of alpha that I get vary according to the tau. Is there anyway
to force alpha to be the same across all taus?

Best wishes,

Mark

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Feb 23 13:45:13 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 23 Feb 2018 12:45:13 +0000
Subject: [R] 
 Aggregate over multiple and unequal column length data frames
In-Reply-To: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
References: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
Message-ID: <4dc6702440764e7c9c826d0b603e3a6f@SRVEXCHCM1301.precheza.cz>

Hi

Your example is rather confusing - partly because HTML formating, partly because weird coding.

You probably could concatenate your data frames e.g. by rbind or merge and after that you could try to aggregate them somehow.

I could construct example data.frames myself but most probably they would be different from yours and also the result would not be necessary the same as you expect.

You should post those data frames as output from dput(data) and show us real desired result from those example data frames.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek Esawi
> Sent: Wednesday, February 21, 2018 3:34 AM
> To: r-help at r-project.org
> Subject: [R] Aggregate over multiple and unequal column length data frames
>
>  Hi All--
>
> I have generated several 2 column data frames with variable length. The data
> frames have the same column names and variable types. I was trying to
> aggregate over the 2nd column for all the date frames, but could not figure out
> how.
>
> I thought i could make them all of equal length then combine them in 1 data
> frame where i can use aggregate, the formula version Or to put them in a list
> and loop use lapply but did not know how to do that and thought there might
> be a simpler way.
>
> Below is an example of 3 data frames and the desired result; note that some
> levels don't appear in all and may be null over all variable, like the case of dd
> on the desired result which i would like to list all levels even if some are all null.
>
> Thanks in advance,
>
> EK
>
>    df1           df2          df3
>
> c1 c2 c1 c2 c1 c2
> 1 aa 1 bb 1 aa
> 2 aa 2 bb 2 aa
> 3 bb 3 cc
> 4 cc 4 bb
> 5 bb
>
> desired result
>
> c1 c2 c2 c2
> aa 2 2
> bb 1 2 2
> cc 1 1
> dd
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From kpmainali at gmail.com  Fri Feb 23 19:52:33 2018
From: kpmainali at gmail.com (Kumar Mainali)
Date: Fri, 23 Feb 2018 13:52:33 -0500
Subject: [R] change location of temporary files
Message-ID: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>

I would like to change where R stores the temporary files to my external
hard drive in my iMac. This is important because the temporary files R
creates are huge and I do not have enough available space in my internal
HD. Again, this is for macOS.

This change has to be temporary. Later I need to use the usual location for
temp files in the internal HD.

Thanks in advance,
Kumar Mainali

-- 
Postdoctoral Associate
Department of Biology
University of Maryland, College Park
?

	[[alternative HTML version deleted]]


From hasan.diwan at gmail.com  Fri Feb 23 22:02:14 2018
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Fri, 23 Feb 2018 13:02:14 -0800
Subject: [R] change location of temporary files
In-Reply-To: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>
References: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>
Message-ID: <CAP+bYWDmYc-4eyAERaPt21mJGt0LNmiqhskPB89QxZSaNqF=JQ@mail.gmail.com>

Kumar,
tempfile has a dir parameter that you can use to designate the directory
the file will be created in.-- H

On 23 February 2018 at 10:52, Kumar Mainali <kpmainali at gmail.com> wrote:

> I would like to change where R stores the temporary files to my external
> hard drive in my iMac. This is important because the temporary files R
> creates are huge and I do not have enough available space in my internal
> HD. Again, this is for macOS.
>
> This change has to be temporary. Later I need to use the usual location for
> temp files in the internal HD.
>
> Thanks in advance,
> Kumar Mainali
>
> --
> Postdoctoral Associate
> Department of Biology
> University of Maryland, College Park
> ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
OpenPGP:
https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using
http://bit.ly/hd1ScheduleRequest.
Si vous voudrais faire connnaisance, allez a
http://bit.ly/hd1ScheduleRequest.

<https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1>Sent
from my mobile device
Envoye de mon portable

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Feb 23 22:55:43 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 23 Feb 2018 13:55:43 -0800
Subject: [R] change location of temporary files
In-Reply-To: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>
References: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>
Message-ID: <CAF8bMcZja4+TFZQnketO+=6u37-U6q4gKRmGoCx3vW7dK28n8A@mail.gmail.com>

Does setting the environment variable TMPDIR, before starting R,
to a directory on a bigger file system help?  On Linux I get

  % mkdir /tmp/RTMP-BILL
  % env TMPDIR=/tmp/RTMP-BILL R --quiet --vanilla
  > tempdir()
  [1] "/tmp/RTMP-BILL/Rtmppgowz4"
  > tempfile()
  [1] "/tmp/RTMP-BILL/Rtmppgowz4/file7ce36ec5cb1e"

I don't know if there is an R-specific environment variable or startup
flag for this.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Feb 23, 2018 at 10:52 AM, Kumar Mainali <kpmainali at gmail.com> wrote:

> I would like to change where R stores the temporary files to my external
> hard drive in my iMac. This is important because the temporary files R
> creates are huge and I do not have enough available space in my internal
> HD. Again, this is for macOS.
>
> This change has to be temporary. Later I need to use the usual location for
> temp files in the internal HD.
>
> Thanks in advance,
> Kumar Mainali
>
> --
> Postdoctoral Associate
> Department of Biology
> University of Maryland, College Park
> ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Fri Feb 23 23:29:51 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 23 Feb 2018 14:29:51 -0800
Subject: [R] change location of temporary files
In-Reply-To: <CAF8bMcZja4+TFZQnketO+=6u37-U6q4gKRmGoCx3vW7dK28n8A@mail.gmail.com>
References: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>
 <CAF8bMcZja4+TFZQnketO+=6u37-U6q4gKRmGoCx3vW7dK28n8A@mail.gmail.com>
Message-ID: <CAFDcVCSDoOn4zBkUR=DeZ_iP-F3MZn4mkO2UbLKbaHcZY4kybA@mail.gmail.com>

On Fri, Feb 23, 2018 at 1:55 PM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> Does setting the environment variable TMPDIR, before starting R,
> to a directory on a bigger file system help?  On Linux I get
>
>   % mkdir /tmp/RTMP-BILL
>   % env TMPDIR=/tmp/RTMP-BILL R --quiet --vanilla
>   > tempdir()
>   [1] "/tmp/RTMP-BILL/Rtmppgowz4"
>   > tempfile()
>   [1] "/tmp/RTMP-BILL/Rtmppgowz4/file7ce36ec5cb1e"
>
> I don't know if there is an R-specific environment variable or startup
> flag for this.

Yes, TMPDIR needs to be set *prior* to launching R in order for R to
acknowledge it.  Although most environment variables can be set in
platform-independent Renviron files which are processed early during
the R startup, TMPDIR is one of the exception - it is simply too late
to set it there because R =needs it very very early on.  So, it needs
to be set as in Bill's example above, or similarly:

export TMPDIR=/tmp/RTMP-BILL

/Henrik

>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Feb 23, 2018 at 10:52 AM, Kumar Mainali <kpmainali at gmail.com> wrote:
>
>> I would like to change where R stores the temporary files to my external
>> hard drive in my iMac. This is important because the temporary files R
>> creates are huge and I do not have enough available space in my internal
>> HD. Again, this is for macOS.
>>
>> This change has to be temporary. Later I need to use the usual location for
>> temp files in the internal HD.
>>
>> Thanks in advance,
>> Kumar Mainali
>>
>> --
>> Postdoctoral Associate
>> Department of Biology
>> University of Maryland, College Park
>> ?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ss5505 at cumc.columbia.edu  Fri Feb 23 23:33:44 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Fri, 23 Feb 2018 22:33:44 +0000
Subject: [R] change location of temporary files
In-Reply-To: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>
References: <CABK368hR8xa6T4BZoT6wsh-N9ByR6CFR08b7NWzDSaQXzs7tzQ@mail.gmail.com>
Message-ID: <CY1PR02MB16904480D312E23D788A07F881CC0@CY1PR02MB1690.namprd02.prod.outlook.com>

You can set this in script as:

library("unixtools ")
set.tempdir("/home/path_to_dir/temp_dir/")

--
Sanjeev 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kumar Mainali
Sent: Friday, February 23, 2018 1:53 PM
To: R Help <r-help at r-project.org>
Subject: [R] change location of temporary files

I would like to change where R stores the temporary files to my external hard drive in my iMac. This is important because the temporary files R creates are huge and I do not have enough available space in my internal HD. Again, this is for macOS.

This change has to be temporary. Later I need to use the usual location for temp files in the internal HD.

Thanks in advance,
Kumar Mainali

--
Postdoctoral Associate
Department of Biology
University of Maryland, College Park
?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From valkremk at gmail.com  Sat Feb 24 05:34:07 2018
From: valkremk at gmail.com (Val)
Date: Fri, 23 Feb 2018 22:34:07 -0600
Subject: [R] include
Message-ID: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>

Hi All,

I am reading a file as follow,

mydat <- read.table(textConnection("Col1 Col2 col3
Z2 NA NA
Z3 X1 NA
Z4 Y1 W1"),header = TRUE)

1. "NA" are   missing  should be replace by 0
2.  value that are in COl2 and Col3  should be included  in col1 before
they appear
in col2 and col3. So the output data looks like as follow,

X1  0  0
Y1  0  0
W1  0  0
Z2  0  0
Z3 X1  0
Z4 Y1 W1

Thank you in advance

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Feb 24 07:17:20 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 24 Feb 2018 17:17:20 +1100
Subject: [R] include
In-Reply-To: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
Message-ID: <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>

Hi Val,
Try this:

preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
 Col2=NA,col3=NA)
rbind(preval,mydat)

Jim

On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
> Hi All,
>
> I am reading a file as follow,
>
> mydat <- read.table(textConnection("Col1 Col2 col3
> Z2 NA NA
> Z3 X1 NA
> Z4 Y1 W1"),header = TRUE)
>
> 1. "NA" are   missing  should be replace by 0
> 2.  value that are in COl2 and Col3  should be included  in col1 before
> they appear
> in col2 and col3. So the output data looks like as follow,
>
> X1  0  0
> Y1  0  0
> W1  0  0
> Z2  0  0
> Z3 X1  0
> Z4 Y1 W1
>
> Thank you in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Sat Feb 24 18:59:02 2018
From: valkremk at gmail.com (Val)
Date: Sat, 24 Feb 2018 11:59:02 -0600
Subject: [R] include
In-Reply-To: <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
Message-ID: <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>

Thank you Jim

I wanted a final data frame  after replacing the NA's to "0"

x1 =  rbind(unique(preval),mydat)
x2 <- x1[is.na(x1)] <- 0
x2
 but I got this,

[1] 0

why I am getting this?


On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Val,
> Try this:
>
> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>  Col2=NA,col3=NA)
> rbind(preval,mydat)
>
> Jim
>
> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
> > Hi All,
> >
> > I am reading a file as follow,
> >
> > mydat <- read.table(textConnection("Col1 Col2 col3
> > Z2 NA NA
> > Z3 X1 NA
> > Z4 Y1 W1"),header = TRUE)
> >
> > 1. "NA" are   missing  should be replace by 0
> > 2.  value that are in COl2 and Col3  should be included  in col1 before
> > they appear
> > in col2 and col3. So the output data looks like as follow,
> >
> > X1  0  0
> > Y1  0  0
> > W1  0  0
> > Z2  0  0
> > Z3 X1  0
> > Z4 Y1 W1
> >
> > Thank you in advance
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Feb 24 19:53:16 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 24 Feb 2018 10:53:16 -0800
Subject: [R] include
In-Reply-To: <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
Message-ID: <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>

   x1 =  rbind(unique(preval),mydat)
  x2 <- x1[is.na(x1)] <- 0
  x2  # gives 0

Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think that
altered x1 is what you want.

You asked why x2 was zero.  The value of the expression
   f(a) <- b
and assignments are processed right to left so
   x2 <- x[!is.na(x1)] <- 0
is equivalent to
   x[!is.na(x1)] <- 0
   x2 <- 0


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:

> Thank you Jim
>
> I wanted a final data frame  after replacing the NA's to "0"
>
> x1 =  rbind(unique(preval),mydat)
> x2 <- x1[is.na(x1)] <- 0
> x2
>  but I got this,
>
> [1] 0
>
> why I am getting this?
>
>
> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Val,
> > Try this:
> >
> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >  Col2=NA,col3=NA)
> > rbind(preval,mydat)
> >
> > Jim
> >
> > On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
> > > Hi All,
> > >
> > > I am reading a file as follow,
> > >
> > > mydat <- read.table(textConnection("Col1 Col2 col3
> > > Z2 NA NA
> > > Z3 X1 NA
> > > Z4 Y1 W1"),header = TRUE)
> > >
> > > 1. "NA" are   missing  should be replace by 0
> > > 2.  value that are in COl2 and Col3  should be included  in col1 before
> > > they appear
> > > in col2 and col3. So the output data looks like as follow,
> > >
> > > X1  0  0
> > > Y1  0  0
> > > W1  0  0
> > > Z2  0  0
> > > Z3 X1  0
> > > Z4 Y1 W1
> > >
> > > Thank you in advance
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gwblack001 at sbcglobal.net  Sat Feb 24 20:16:27 2018
From: gwblack001 at sbcglobal.net (Gary Black)
Date: Sat, 24 Feb 2018 13:16:27 -0600
Subject: [R] Regression Tree Questions
Message-ID: <001d01d3ada3$f8e6b4e0$eab41ea0$@sbcglobal.net>

Hi All,

I'm a newbie and have two questions.  Please pardon me if they are very basic.


1.  I'm using a regression tree to predict the selling prices of 10 new records (homes).  The following code is resulting in an error message:  pred <- predict(model, newdata = outOfSample[, -6]) 

The error message is:

Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = attr(object,  : 
factor Sq. Feet has new levels 1375, 1421, 1547, 1621, 1868, 2211, 2265, 2530, 2672, 3365


Does anybody know what is causing this?  I've pasted a snippet of my original dataset (Crankshaw) and my out-of-sample dataset below.  Below it appears all code which I entered leading up to that point.  The error message appears at the end of that code.


2.  How can I get the regression tree to display in a more "friendly" way?  Unfortunately I cannot paste a picture of it in this email, but it displays the values of individual records at each node instead of the decision rule logic (e.g., Age >= 28).  I'm using the command > fancyRpartPlot(model) to display the tree.


Thank you!
Gary

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Original Data (Crankshaw):

Sq. Feet		Age	Bedrm	Bathrm	Garage	Sell Price ($)
1620		17	3	2	2	185500
1864		28	3	2	2	195250
1628		15	3	2	2	190750
1670		1	4	3	2	195750
1762		23	3	4	2	197250
1520		1	3	3	2	192900


Out-of-Sample Data:

NEW RECORDS:					
Sq. Feet		Age	Bedrm	Bathrm	Garage	Sell Price ($)
3365		8	4	4	3	
1547		28	3	2	2	
1375		36	2	1	1	
1621		53	3	1	2	
2530		23	4	3	2	
1868		42	3	2	2	
2211		23	3	2	2	
1421		39	2	1	1	
2672		3	4	2	3	
2265		7	3	2	2	


All Code Entered:

> Crankshaw <- read_excel("C:/Data/Excel/Crankshaw.xlsx")
> View(Crankshaw)
> outOfSample <- Crankshaw[305:nrow(Crankshaw), ]
> Crankshaw <- Crankshaw[1:300, ]
> install.packages("caret")
Installing package into ?C:/Users/Jason/Documents/R/win-library/3.4?
(as ?lib? is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/caret_6.0-78.zip'
Content type 'application/zip' length 5155836 bytes (4.9 MB)
downloaded 4.9 MB

package ?caret? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Jason\AppData\Local\Temp\RtmpmAxrJR\downloaded_packages
> install.packages("rattle")
Installing package into ?C:/Users/Jason/Documents/R/win-library/3.4?
(as ?lib? is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/rattle_5.1.0.zip'
Content type 'application/zip' length 1287407 bytes (1.2 MB)
downloaded 1.2 MB

package ?rattle? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\Jason\AppData\Local\Temp\RtmpmAxrJR\downloaded_packages
> library(rpart)
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
Warning messages:
1: package ?caret? was built under R version 3.4.3 
2: package ?ggplot2? was built under R version 3.4.3 
> library(rattle)
> n <- nrow(Crankshaw)
> train <- sample(1:n, size = 0.5 * n, replace = FALSE)
> CrankshawTrain <- Crankshaw[train, ]
> temp <- (1:n)[-train]
> val <- sample(temp, size = (0.3 / 0.5) * length(temp), replace = FALSE)
> CrankshawVal <- Crankshaw[val, ]
> test <- (1:n)[-c(train, val)]
> CrankshawTest <- Crankshaw[test, ]
> model <- rpart(`Selling Price ($)` ~ ., method = "anova", data = CrankshawTrain)
> fancyRpartPlot(model)
> pred <- predict(model, newdata = outOfSample[, -6])
Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = attr(object,  : 
  factor Sq. Feet has new levels 1375, 1421, 1547, 1621, 1868, 2211, 2265, 2530, 2672, 3365


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From chema at rinzewind.org  Sat Feb 24 20:21:36 2018
From: chema at rinzewind.org (=?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos)
Date: Sat, 24 Feb 2018 14:21:36 -0500
Subject: [R] Regression Tree Questions
In-Reply-To: <001d01d3ada3$f8e6b4e0$eab41ea0$@sbcglobal.net>
References: <001d01d3ada3$f8e6b4e0$eab41ea0$@sbcglobal.net>
Message-ID: <20180224192136.GA20249@equipaje>

On Sat, Feb 24, 2018 at 01:16:27PM -0600, Gary Black wrote:
> Hi All,
> 
> I'm a newbie and have two questions.  Please pardon me if they are very basic.
> 
> 
> 1.  I'm using a regression tree to predict the selling prices of 10 new records (homes).  The following code is resulting in an error message:  pred <- predict(model, newdata = outOfSample[, -6]) 
> 
> The error message is:
> 
> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = attr(object,  : 
> factor Sq. Feet has new levels 1375, 1421, 1547, 1621, 1868, 2211, 2265, 2530, 2672, 3365
> 

Seems to me that variable 'Sq. Feet' is being encoded as a factor 
instead of having numerical values. When you train, the model sees a 
series of values that understands as categorical, and when you try to 
predict it is encountering some different categories and it doesn't know 
what to do with them.

As that variable is most probably numeric, it should be read as such. 
You can try converting it on both your train and test datasets.

Cheers,

JMM.

-- Jos? Mar?a Mateos
https://rinzewind.org/blog-es || https://rinzewind.org/blog-en


From bgunter.4567 at gmail.com  Sat Feb 24 20:33:43 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 24 Feb 2018 11:33:43 -0800
Subject: [R] Regression Tree Questions
In-Reply-To: <20180224192136.GA20249@equipaje>
References: <001d01d3ada3$f8e6b4e0$eab41ea0$@sbcglobal.net>
 <20180224192136.GA20249@equipaje>
Message-ID: <CAGxFJbTjvi=TK=e96=RZ-5WP-_SCY1Rm_NkAVeALE2Pk01XW_w@mail.gmail.com>

But note that converting it e.g. via as.numeric() would be disastrous:

> as.numeric(factor(c(3,5,7)))
[1] 1 2 3

The OP may need to do some homework with R tutorials to learn about basic R
data structures; or if he has already done this, he may need to be more
explicit about how the data were created/entered.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Feb 24, 2018 at 11:21 AM, Jos? Mar?a Mateos <chema at rinzewind.org>
wrote:

> On Sat, Feb 24, 2018 at 01:16:27PM -0600, Gary Black wrote:
> > Hi All,
> >
> > I'm a newbie and have two questions.  Please pardon me if they are very
> basic.
> >
> >
> > 1.  I'm using a regression tree to predict the selling prices of 10 new
> records (homes).  The following code is resulting in an error message:
> pred <- predict(model, newdata = outOfSample[, -6])
> >
> > The error message is:
> >
> > Error in model.frame.default(Terms, newdata, na.action = na.action, xlev
> = attr(object,  :
> > factor Sq. Feet has new levels 1375, 1421, 1547, 1621, 1868, 2211, 2265,
> 2530, 2672, 3365
> >
>
> Seems to me that variable 'Sq. Feet' is being encoded as a factor
> instead of having numerical values. When you train, the model sees a
> series of values that understands as categorical, and when you try to
> predict it is encountering some different categories and it doesn't know
> what to do with them.
>
> As that variable is most probably numeric, it should be read as such.
> You can try converting it on both your train and test datasets.
>
> Cheers,
>
> JMM.
>
> -- Jos? Mar?a Mateos
> https://rinzewind.org/blog-es || https://rinzewind.org/blog-en
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Feb 24 21:09:13 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 24 Feb 2018 12:09:13 -0800
Subject: [R] Regression Tree Questions
In-Reply-To: <001d01d3ada3$f8e6b4e0$eab41ea0$@sbcglobal.net>
References: <001d01d3ada3$f8e6b4e0$eab41ea0$@sbcglobal.net>
Message-ID: <A25CF540-9223-4E48-BE5C-AE1657C5DF49@dcn.davis.ca.us>

As Bert implies, you may be getting ahead of yourself. An 8 may be a number, or it may be the character 8, or it could be a factor, and you don't seem to know the difference yet (thus suggesting tutorials). If you go to the trouble of making a reproducible example [1][2][3] then you may find the problem yourself or we will be able to check things using the example that you would not think to try. The str function can be helpful to find problems like the above. 

One surprisingly valuable step mentioned in the reprex references below is giving us the data for your example using the dput function. Another surprisingly useful technique is sending your question using plain text email format as the Posting Guide indicates (details of how to do that depends on your email client, which is off topic here).

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
-- 
Sent from my phone. Please excuse my brevity.

On February 24, 2018 11:16:27 AM PST, Gary Black <gwblack001 at sbcglobal.net> wrote:
>Hi All,
>
>I'm a newbie and have two questions.  Please pardon me if they are very
>basic.
>
>
>1.  I'm using a regression tree to predict the selling prices of 10 new
>records (homes).  The following code is resulting in an error message: 
>pred <- predict(model, newdata = outOfSample[, -6]) 
>
>The error message is:
>
>Error in model.frame.default(Terms, newdata, na.action = na.action,
>xlev = attr(object,  : 
>factor Sq. Feet has new levels 1375, 1421, 1547, 1621, 1868, 2211,
>2265, 2530, 2672, 3365
>
>
>Does anybody know what is causing this?  I've pasted a snippet of my
>original dataset (Crankshaw) and my out-of-sample dataset below.  Below
>it appears all code which I entered leading up to that point.  The
>error message appears at the end of that code.
>
>
>2.  How can I get the regression tree to display in a more "friendly"
>way?  Unfortunately I cannot paste a picture of it in this email, but
>it displays the values of individual records at each node instead of
>the decision rule logic (e.g., Age >= 28).  I'm using the command >
>fancyRpartPlot(model) to display the tree.
>
>
>Thank you!
>Gary
>
>-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>
>
>Original Data (Crankshaw):
>
>Sq. Feet		Age	Bedrm	Bathrm	Garage	Sell Price ($)
>1620		17	3	2	2	185500
>1864		28	3	2	2	195250
>1628		15	3	2	2	190750
>1670		1	4	3	2	195750
>1762		23	3	4	2	197250
>1520		1	3	3	2	192900
>
>
>Out-of-Sample Data:
>
>NEW RECORDS:					
>Sq. Feet		Age	Bedrm	Bathrm	Garage	Sell Price ($)
>3365		8	4	4	3	
>1547		28	3	2	2	
>1375		36	2	1	1	
>1621		53	3	1	2	
>2530		23	4	3	2	
>1868		42	3	2	2	
>2211		23	3	2	2	
>1421		39	2	1	1	
>2672		3	4	2	3	
>2265		7	3	2	2	
>
>
>All Code Entered:
>
>> Crankshaw <- read_excel("C:/Data/Excel/Crankshaw.xlsx")
>> View(Crankshaw)
>> outOfSample <- Crankshaw[305:nrow(Crankshaw), ]
>> Crankshaw <- Crankshaw[1:300, ]
>> install.packages("caret")
>Installing package into ?C:/Users/Jason/Documents/R/win-library/3.4?
>(as ?lib? is unspecified)
>trying URL
>'https://cran.rstudio.com/bin/windows/contrib/3.4/caret_6.0-78.zip'
>Content type 'application/zip' length 5155836 bytes (4.9 MB)
>downloaded 4.9 MB
>
>package ?caret? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>	C:\Users\Jason\AppData\Local\Temp\RtmpmAxrJR\downloaded_packages
>> install.packages("rattle")
>Installing package into ?C:/Users/Jason/Documents/R/win-library/3.4?
>(as ?lib? is unspecified)
>trying URL
>'https://cran.rstudio.com/bin/windows/contrib/3.4/rattle_5.1.0.zip'
>Content type 'application/zip' length 1287407 bytes (1.2 MB)
>downloaded 1.2 MB
>
>package ?rattle? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>	C:\Users\Jason\AppData\Local\Temp\RtmpmAxrJR\downloaded_packages
>> library(rpart)
>> library(caret)
>Loading required package: lattice
>Loading required package: ggplot2
>Warning messages:
>1: package ?caret? was built under R version 3.4.3 
>2: package ?ggplot2? was built under R version 3.4.3
>> library(rattle)
>> n <- nrow(Crankshaw)
>> train <- sample(1:n, size = 0.5 * n, replace = FALSE)
>> CrankshawTrain <- Crankshaw[train, ]
>> temp <- (1:n)[-train]
>> val <- sample(temp, size = (0.3 / 0.5) * length(temp), replace =
>FALSE)
>> CrankshawVal <- Crankshaw[val, ]
>> test <- (1:n)[-c(train, val)]
>> CrankshawTest <- Crankshaw[test, ]
>> model <- rpart(`Selling Price ($)` ~ ., method = "anova", data =
>CrankshawTrain)
>> fancyRpartPlot(model)
>> pred <- predict(model, newdata = outOfSample[, -6])
>Error in model.frame.default(Terms, newdata, na.action = na.action,
>xlev = attr(object,  : 
>factor Sq. Feet has new levels 1375, 1421, 1547, 1621, 1868, 2211,
>2265, 2530, 2672, 3365
>
>
>---
>This email has been checked for viruses by Avast antivirus software.
>https://www.avast.com/antivirus
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Feb 25 00:04:38 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 24 Feb 2018 18:04:38 -0500
Subject: [R] include
In-Reply-To: <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
Message-ID: <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>

On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
>     x1 =  rbind(unique(preval),mydat)
>    x2 <- x1[is.na(x1)] <- 0
>    x2  # gives 0
> 
> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think that
> altered x1 is what you want.
> 
> You asked why x2 was zero.  The value of the expression
>     f(a) <- b
> and assignments are processed right to left so
>     x2 <- x[!is.na(x1)] <- 0
> is equivalent to
>     x[!is.na(x1)] <- 0
>     x2 <- 0

That's not right in general, is it?  I'd think that should be

     x[!is.na(x1)] <- 0
     x2 <- x1

Of course, in this example, x1 is 0, so it gives the same answer.

Duncan Murdoch

> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
> 
>> Thank you Jim
>>
>> I wanted a final data frame  after replacing the NA's to "0"
>>
>> x1 =  rbind(unique(preval),mydat)
>> x2 <- x1[is.na(x1)] <- 0
>> x2
>>   but I got this,
>>
>> [1] 0
>>
>> why I am getting this?
>>
>>
>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>>> Hi Val,
>>> Try this:
>>>
>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>>   Col2=NA,col3=NA)
>>> rbind(preval,mydat)
>>>
>>> Jim
>>>
>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
>>>> Hi All,
>>>>
>>>> I am reading a file as follow,
>>>>
>>>> mydat <- read.table(textConnection("Col1 Col2 col3
>>>> Z2 NA NA
>>>> Z3 X1 NA
>>>> Z4 Y1 W1"),header = TRUE)
>>>>
>>>> 1. "NA" are   missing  should be replace by 0
>>>> 2.  value that are in COl2 and Col3  should be included  in col1 before
>>>> they appear
>>>> in col2 and col3. So the output data looks like as follow,
>>>>
>>>> X1  0  0
>>>> Y1  0  0
>>>> W1  0  0
>>>> Z2  0  0
>>>> Z3 X1  0
>>>> Z4 Y1 W1
>>>>
>>>> Thank you in advance
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From valkremk at gmail.com  Sun Feb 25 00:59:14 2018
From: valkremk at gmail.com (Val)
Date: Sat, 24 Feb 2018 17:59:14 -0600
Subject: [R] include
In-Reply-To: <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
Message-ID: <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>

Thank you Jim   and all, I got it.

I have one more question on the original question

 What does this  "[-1] "  do?
preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
                   Col2=NA,col3=NA)


mydat <- read.table(textConnection("Col1 Col2 col3
Z1 K1 K2
Z2 NA NA
Z3 X1 NA
Z4 Y1 W1"),header = TRUE)

preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
                   Col2=NA,col3=NA)
rbind(unique(preval),mydat)


 Col1 Col2 col3
1 <NA> <NA> <NA>
2   X1 <NA> <NA>
3   Y1 <NA> <NA>
4   K2 <NA> <NA>
5   W1 <NA> <NA>
6   Z1   K1   K2
7   Z2 <NA> <NA>
8   Z3   X1 <NA>
9   Z4   Y1   W1















On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
>
>>     x1 =  rbind(unique(preval),mydat)
>>    x2 <- x1[is.na(x1)] <- 0
>>    x2  # gives 0
>>
>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think that
>> altered x1 is what you want.
>>
>> You asked why x2 was zero.  The value of the expression
>>     f(a) <- b
>> and assignments are processed right to left so
>>     x2 <- x[!is.na(x1)] <- 0
>> is equivalent to
>>     x[!is.na(x1)] <- 0
>>     x2 <- 0
>>
>
> That's not right in general, is it?  I'd think that should be
>
>     x[!is.na(x1)] <- 0
>     x2 <- x1
>
> Of course, in this example, x1 is 0, so it gives the same answer.
>
> Duncan Murdoch
>
>
>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
>>
>> Thank you Jim
>>>
>>> I wanted a final data frame  after replacing the NA's to "0"
>>>
>>> x1 =  rbind(unique(preval),mydat)
>>> x2 <- x1[is.na(x1)] <- 0
>>> x2
>>>   but I got this,
>>>
>>> [1] 0
>>>
>>> why I am getting this?
>>>
>>>
>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>>
>>> Hi Val,
>>>> Try this:
>>>>
>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>>>   Col2=NA,col3=NA)
>>>> rbind(preval,mydat)
>>>>
>>>> Jim
>>>>
>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
>>>>
>>>>> Hi All,
>>>>>
>>>>> I am reading a file as follow,
>>>>>
>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
>>>>> Z2 NA NA
>>>>> Z3 X1 NA
>>>>> Z4 Y1 W1"),header = TRUE)
>>>>>
>>>>> 1. "NA" are   missing  should be replace by 0
>>>>> 2.  value that are in COl2 and Col3  should be included  in col1 before
>>>>> they appear
>>>>> in col2 and col3. So the output data looks like as follow,
>>>>>
>>>>> X1  0  0
>>>>> Y1  0  0
>>>>> W1  0  0
>>>>> Z2  0  0
>>>>> Z3 X1  0
>>>>> Z4 Y1 W1
>>>>>
>>>>> Thank you in advance
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>
>>>> posting-guide.html
>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Sun Feb 25 01:05:26 2018
From: valkremk at gmail.com (Val)
Date: Sat, 24 Feb 2018 18:05:26 -0600
Subject: [R] include
In-Reply-To: <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
Message-ID: <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>

Sorry , I hit the send key accidentally  here is my complete message.

Thank you Jim   and all, I got it.

I have one more question on the original question

 What does this  "[-1] "  do?
preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
                   Col2=NA,col3=NA)


mydat <- read.table(textConnection("Col1 Col2 col3
Z1 K1 K2
Z2 NA NA
Z3 X1 NA
Z4 Y1 W1"),header = TRUE)

preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
                   Col2=NA,col3=NA)
rbind(unique(preval),mydat)


 Col1 Col2 col3
1 <NA> <NA> <NA>
2   X1 <NA> <NA>
3   Y1 <NA> <NA>
4   K2 <NA> <NA>
5   W1 <NA> <NA>
6   Z1   K1   K2
7   Z2 <NA> <NA>
8   Z3   X1 <NA>
9   Z4   Y1   W1

I could not find K1 in the first   col1. Is that possible to fix this?

On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:

> Thank you Jim   and all, I got it.
>
> I have one more question on the original question
>
>  What does this  "[-1] "  do?
> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>                    Col2=NA,col3=NA)
>
>
> mydat <- read.table(textConnection("Col1 Col2 col3
> Z1 K1 K2
> Z2 NA NA
> Z3 X1 NA
> Z4 Y1 W1"),header = TRUE)
>
> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>                    Col2=NA,col3=NA)
> rbind(unique(preval),mydat)
>
>
>  Col1 Col2 col3
> 1 <NA> <NA> <NA>
> 2   X1 <NA> <NA>
> 3   Y1 <NA> <NA>
> 4   K2 <NA> <NA>
> 5   W1 <NA> <NA>
> 6   Z1   K1   K2
> 7   Z2 <NA> <NA>
> 8   Z3   X1 <NA>
> 9   Z4   Y1   W1
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
>>
>>>     x1 =  rbind(unique(preval),mydat)
>>>    x2 <- x1[is.na(x1)] <- 0
>>>    x2  # gives 0
>>>
>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think
>>> that
>>> altered x1 is what you want.
>>>
>>> You asked why x2 was zero.  The value of the expression
>>>     f(a) <- b
>>> and assignments are processed right to left so
>>>     x2 <- x[!is.na(x1)] <- 0
>>> is equivalent to
>>>     x[!is.na(x1)] <- 0
>>>     x2 <- 0
>>>
>>
>> That's not right in general, is it?  I'd think that should be
>>
>>     x[!is.na(x1)] <- 0
>>     x2 <- x1
>>
>> Of course, in this example, x1 is 0, so it gives the same answer.
>>
>> Duncan Murdoch
>>
>>
>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
>>>
>>> Thank you Jim
>>>>
>>>> I wanted a final data frame  after replacing the NA's to "0"
>>>>
>>>> x1 =  rbind(unique(preval),mydat)
>>>> x2 <- x1[is.na(x1)] <- 0
>>>> x2
>>>>   but I got this,
>>>>
>>>> [1] 0
>>>>
>>>> why I am getting this?
>>>>
>>>>
>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com>
>>>> wrote:
>>>>
>>>> Hi Val,
>>>>> Try this:
>>>>>
>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>>>>   Col2=NA,col3=NA)
>>>>> rbind(preval,mydat)
>>>>>
>>>>> Jim
>>>>>
>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
>>>>>
>>>>>> Hi All,
>>>>>>
>>>>>> I am reading a file as follow,
>>>>>>
>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
>>>>>> Z2 NA NA
>>>>>> Z3 X1 NA
>>>>>> Z4 Y1 W1"),header = TRUE)
>>>>>>
>>>>>> 1. "NA" are   missing  should be replace by 0
>>>>>> 2.  value that are in COl2 and Col3  should be included  in col1
>>>>>> before
>>>>>> they appear
>>>>>> in col2 and col3. So the output data looks like as follow,
>>>>>>
>>>>>> X1  0  0
>>>>>> Y1  0  0
>>>>>> W1  0  0
>>>>>> Z2  0  0
>>>>>> Z3 X1  0
>>>>>> Z4 Y1 W1
>>>>>>
>>>>>> Thank you in advance
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>
>>>>> posting-guide.html
>>>>>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Feb 25 01:18:05 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 25 Feb 2018 11:18:05 +1100
Subject: [R] include
In-Reply-To: <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
 <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
Message-ID: <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>

hi Val,
Your problem seems to be that the data are read in as a factor. The
simplest way I can think of to get around this is:

mydat <- read.table(textConnection("Col1 Col2 col3
Z1 K1 K2
Z2 NA NA
Z3 X1 NA
Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
 Col2=NA,col3=NA)
rbind(preval,mydat)
mydat[is.na(mydat)]<-"0"

Jiim


On Sun, Feb 25, 2018 at 11:05 AM, Val <valkremk at gmail.com> wrote:
> Sorry , I hit the send key accidentally  here is my complete message.
>
> Thank you Jim   and all, I got it.
>
> I have one more question on the original question
>
>  What does this  "[-1] "  do?
> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>                    Col2=NA,col3=NA)
>
>
> mydat <- read.table(textConnection("Col1 Col2 col3
> Z1 K1 K2
> Z2 NA NA
> Z3 X1 NA
> Z4 Y1 W1"),header = TRUE)
>
> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>                    Col2=NA,col3=NA)
> rbind(unique(preval),mydat)
>
>
>  Col1 Col2 col3
> 1 <NA> <NA> <NA>
> 2   X1 <NA> <NA>
> 3   Y1 <NA> <NA>
> 4   K2 <NA> <NA>
> 5   W1 <NA> <NA>
> 6   Z1   K1   K2
> 7   Z2 <NA> <NA>
> 8   Z3   X1 <NA>
> 9   Z4   Y1   W1
>
> I could not find K1 in the first   col1. Is that possible to fix this?
>
> On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:
>
>> Thank you Jim   and all, I got it.
>>
>> I have one more question on the original question
>>
>>  What does this  "[-1] "  do?
>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>                    Col2=NA,col3=NA)
>>
>>
>> mydat <- read.table(textConnection("Col1 Col2 col3
>> Z1 K1 K2
>> Z2 NA NA
>> Z3 X1 NA
>> Z4 Y1 W1"),header = TRUE)
>>
>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>                    Col2=NA,col3=NA)
>> rbind(unique(preval),mydat)
>>
>>
>>  Col1 Col2 col3
>> 1 <NA> <NA> <NA>
>> 2   X1 <NA> <NA>
>> 3   Y1 <NA> <NA>
>> 4   K2 <NA> <NA>
>> 5   W1 <NA> <NA>
>> 6   Z1   K1   K2
>> 7   Z2 <NA> <NA>
>> 8   Z3   X1 <NA>
>> 9   Z4   Y1   W1
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
>>>
>>>>     x1 =  rbind(unique(preval),mydat)
>>>>    x2 <- x1[is.na(x1)] <- 0
>>>>    x2  # gives 0
>>>>
>>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think
>>>> that
>>>> altered x1 is what you want.
>>>>
>>>> You asked why x2 was zero.  The value of the expression
>>>>     f(a) <- b
>>>> and assignments are processed right to left so
>>>>     x2 <- x[!is.na(x1)] <- 0
>>>> is equivalent to
>>>>     x[!is.na(x1)] <- 0
>>>>     x2 <- 0
>>>>
>>>
>>> That's not right in general, is it?  I'd think that should be
>>>
>>>     x[!is.na(x1)] <- 0
>>>     x2 <- x1
>>>
>>> Of course, in this example, x1 is 0, so it gives the same answer.
>>>
>>> Duncan Murdoch
>>>
>>>
>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
>>>>
>>>> Thank you Jim
>>>>>
>>>>> I wanted a final data frame  after replacing the NA's to "0"
>>>>>
>>>>> x1 =  rbind(unique(preval),mydat)
>>>>> x2 <- x1[is.na(x1)] <- 0
>>>>> x2
>>>>>   but I got this,
>>>>>
>>>>> [1] 0
>>>>>
>>>>> why I am getting this?
>>>>>
>>>>>
>>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com>
>>>>> wrote:
>>>>>
>>>>> Hi Val,
>>>>>> Try this:
>>>>>>
>>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>>>>>   Col2=NA,col3=NA)
>>>>>> rbind(preval,mydat)
>>>>>>
>>>>>> Jim
>>>>>>
>>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
>>>>>>
>>>>>>> Hi All,
>>>>>>>
>>>>>>> I am reading a file as follow,
>>>>>>>
>>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
>>>>>>> Z2 NA NA
>>>>>>> Z3 X1 NA
>>>>>>> Z4 Y1 W1"),header = TRUE)
>>>>>>>
>>>>>>> 1. "NA" are   missing  should be replace by 0
>>>>>>> 2.  value that are in COl2 and Col3  should be included  in col1
>>>>>>> before
>>>>>>> they appear
>>>>>>> in col2 and col3. So the output data looks like as follow,
>>>>>>>
>>>>>>> X1  0  0
>>>>>>> Y1  0  0
>>>>>>> W1  0  0
>>>>>>> Z2  0  0
>>>>>>> Z3 X1  0
>>>>>>> Z4 Y1 W1
>>>>>>>
>>>>>>> Thank you in advance
>>>>>>>
>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>>>
>>>>>> posting-guide.html
>>>>>>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Sun Feb 25 01:27:33 2018
From: valkremk at gmail.com (Val)
Date: Sat, 24 Feb 2018 18:27:33 -0600
Subject: [R] include
In-Reply-To: <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
 <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
 <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>
Message-ID: <CAJOiR6aJ-idxVQLx2hrUxmNC3Z81VAxJSSsF6ZtSbreTVgsbyw@mail.gmail.com>

Thank you Jim,

I read the data as you suggested but I could not find K1 in   col1.

rbind(preval,mydat)  Col1 Col2 col3
1 <NA> <NA> <NA>
2   X1 <NA> <NA>
3   Y1 <NA> <NA>
4   K2 <NA> <NA>
5   W1 <NA> <NA>
6   Z1   K1   K2
7   Z2 <NA> <NA>
8   Z3   X1 <NA>
9   Z4   Y1   W1



On Sat, Feb 24, 2018 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> hi Val,
> Your problem seems to be that the data are read in as a factor. The
> simplest way I can think of to get around this is:
>
> mydat <- read.table(textConnection("Col1 Col2 col3
> Z1 K1 K2
> Z2 NA NA
> Z3 X1 NA
> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>  Col2=NA,col3=NA)
> rbind(preval,mydat)
> mydat[is.na(mydat)]<-"0"
>
> Jiim
>
>
> On Sun, Feb 25, 2018 at 11:05 AM, Val <valkremk at gmail.com> wrote:
> > Sorry , I hit the send key accidentally  here is my complete message.
> >
> > Thank you Jim   and all, I got it.
> >
> > I have one more question on the original question
> >
> >  What does this  "[-1] "  do?
> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >                    Col2=NA,col3=NA)
> >
> >
> > mydat <- read.table(textConnection("Col1 Col2 col3
> > Z1 K1 K2
> > Z2 NA NA
> > Z3 X1 NA
> > Z4 Y1 W1"),header = TRUE)
> >
> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >                    Col2=NA,col3=NA)
> > rbind(unique(preval),mydat)
> >
> >
> >  Col1 Col2 col3
> > 1 <NA> <NA> <NA>
> > 2   X1 <NA> <NA>
> > 3   Y1 <NA> <NA>
> > 4   K2 <NA> <NA>
> > 5   W1 <NA> <NA>
> > 6   Z1   K1   K2
> > 7   Z2 <NA> <NA>
> > 8   Z3   X1 <NA>
> > 9   Z4   Y1   W1
> >
> > I could not find K1 in the first   col1. Is that possible to fix this?
> >
> > On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:
> >
> >> Thank you Jim   and all, I got it.
> >>
> >> I have one more question on the original question
> >>
> >>  What does this  "[-1] "  do?
> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >>                    Col2=NA,col3=NA)
> >>
> >>
> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> Z1 K1 K2
> >> Z2 NA NA
> >> Z3 X1 NA
> >> Z4 Y1 W1"),header = TRUE)
> >>
> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >>                    Col2=NA,col3=NA)
> >> rbind(unique(preval),mydat)
> >>
> >>
> >>  Col1 Col2 col3
> >> 1 <NA> <NA> <NA>
> >> 2   X1 <NA> <NA>
> >> 3   Y1 <NA> <NA>
> >> 4   K2 <NA> <NA>
> >> 5   W1 <NA> <NA>
> >> 6   Z1   K1   K2
> >> 7   Z2 <NA> <NA>
> >> 8   Z3   X1 <NA>
> >> 9   Z4   Y1   W1
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com>
> >> wrote:
> >>
> >>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
> >>>
> >>>>     x1 =  rbind(unique(preval),mydat)
> >>>>    x2 <- x1[is.na(x1)] <- 0
> >>>>    x2  # gives 0
> >>>>
> >>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think
> >>>> that
> >>>> altered x1 is what you want.
> >>>>
> >>>> You asked why x2 was zero.  The value of the expression
> >>>>     f(a) <- b
> >>>> and assignments are processed right to left so
> >>>>     x2 <- x[!is.na(x1)] <- 0
> >>>> is equivalent to
> >>>>     x[!is.na(x1)] <- 0
> >>>>     x2 <- 0
> >>>>
> >>>
> >>> That's not right in general, is it?  I'd think that should be
> >>>
> >>>     x[!is.na(x1)] <- 0
> >>>     x2 <- x1
> >>>
> >>> Of course, in this example, x1 is 0, so it gives the same answer.
> >>>
> >>> Duncan Murdoch
> >>>
> >>>
> >>>
> >>>>
> >>>> Bill Dunlap
> >>>> TIBCO Software
> >>>> wdunlap tibco.com
> >>>>
> >>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
> >>>>
> >>>> Thank you Jim
> >>>>>
> >>>>> I wanted a final data frame  after replacing the NA's to "0"
> >>>>>
> >>>>> x1 =  rbind(unique(preval),mydat)
> >>>>> x2 <- x1[is.na(x1)] <- 0
> >>>>> x2
> >>>>>   but I got this,
> >>>>>
> >>>>> [1] 0
> >>>>>
> >>>>> why I am getting this?
> >>>>>
> >>>>>
> >>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>> Hi Val,
> >>>>>> Try this:
> >>>>>>
> >>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> "col3")]))[-1],
> >>>>>>   Col2=NA,col3=NA)
> >>>>>> rbind(preval,mydat)
> >>>>>>
> >>>>>> Jim
> >>>>>>
> >>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
> >>>>>>
> >>>>>>> Hi All,
> >>>>>>>
> >>>>>>> I am reading a file as follow,
> >>>>>>>
> >>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
> >>>>>>> Z2 NA NA
> >>>>>>> Z3 X1 NA
> >>>>>>> Z4 Y1 W1"),header = TRUE)
> >>>>>>>
> >>>>>>> 1. "NA" are   missing  should be replace by 0
> >>>>>>> 2.  value that are in COl2 and Col3  should be included  in col1
> >>>>>>> before
> >>>>>>> they appear
> >>>>>>> in col2 and col3. So the output data looks like as follow,
> >>>>>>>
> >>>>>>> X1  0  0
> >>>>>>> Y1  0  0
> >>>>>>> W1  0  0
> >>>>>>> Z2  0  0
> >>>>>>> Z3 X1  0
> >>>>>>> Z4 Y1 W1
> >>>>>>>
> >>>>>>> Thank you in advance
> >>>>>>>
> >>>>>>>          [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
> >>>>>>>
> >>>>>> posting-guide.html
> >>>>>>
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>
> >>>>>>
> >>>>>>
> >>>>>          [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> >>>>> posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>>> ng-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Feb 25 01:38:32 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 25 Feb 2018 11:38:32 +1100
Subject: [R] include
In-Reply-To: <CAJOiR6aJ-idxVQLx2hrUxmNC3Z81VAxJSSsF6ZtSbreTVgsbyw@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
 <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
 <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>
 <CAJOiR6aJ-idxVQLx2hrUxmNC3Z81VAxJSSsF6ZtSbreTVgsbyw@mail.gmail.com>
Message-ID: <CA+8X3fV_oAr-1xTzBxZqXd830dsw6Qe3JSmFTeyUmaZge1ciZQ@mail.gmail.com>

Hi Val,
My fault - I assumed that the NA would be first in the result produced
by "unique":

mydat <- read.table(textConnection("Col1 Col2 col3
Z1 K1 K2
Z2 NA NA
Z3 X1 NA
Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
val23<-unique(unlist(mydat[,c("Col2","col3")]))
napos<-which(is.na(val23))
preval<-data.frame(Col1=val23[-napos],
 Col2=NA,col3=NA)
mydat<-rbind(preval,mydat)
mydat[is.na(mydat)]<-"0"
mydat

Jim

On Sun, Feb 25, 2018 at 11:27 AM, Val <valkremk at gmail.com> wrote:
> Thank you Jim,
>
> I read the data as you suggested but I could not find K1 in   col1.
>
> rbind(preval,mydat)
>   Col1 Col2 col3
> 1 <NA> <NA> <NA>
> 2   X1 <NA> <NA>
> 3   Y1 <NA> <NA>
> 4   K2 <NA> <NA>
> 5   W1 <NA> <NA>
> 6   Z1   K1   K2
> 7   Z2 <NA> <NA>
> 8   Z3   X1 <NA>
> 9   Z4   Y1   W1
>
>
>
> On Sat, Feb 24, 2018 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> hi Val,
>> Your problem seems to be that the data are read in as a factor. The
>> simplest way I can think of to get around this is:
>>
>> mydat <- read.table(textConnection("Col1 Col2 col3
>> Z1 K1 K2
>> Z2 NA NA
>> Z3 X1 NA
>> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>  Col2=NA,col3=NA)
>> rbind(preval,mydat)
>> mydat[is.na(mydat)]<-"0"
>>
>> Jiim
>>
>>
>> On Sun, Feb 25, 2018 at 11:05 AM, Val <valkremk at gmail.com> wrote:
>> > Sorry , I hit the send key accidentally  here is my complete message.
>> >
>> > Thank you Jim   and all, I got it.
>> >
>> > I have one more question on the original question
>> >
>> >  What does this  "[-1] "  do?
>> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >                    Col2=NA,col3=NA)
>> >
>> >
>> > mydat <- read.table(textConnection("Col1 Col2 col3
>> > Z1 K1 K2
>> > Z2 NA NA
>> > Z3 X1 NA
>> > Z4 Y1 W1"),header = TRUE)
>> >
>> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >                    Col2=NA,col3=NA)
>> > rbind(unique(preval),mydat)
>> >
>> >
>> >  Col1 Col2 col3
>> > 1 <NA> <NA> <NA>
>> > 2   X1 <NA> <NA>
>> > 3   Y1 <NA> <NA>
>> > 4   K2 <NA> <NA>
>> > 5   W1 <NA> <NA>
>> > 6   Z1   K1   K2
>> > 7   Z2 <NA> <NA>
>> > 8   Z3   X1 <NA>
>> > 9   Z4   Y1   W1
>> >
>> > I could not find K1 in the first   col1. Is that possible to fix this?
>> >
>> > On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:
>> >
>> >> Thank you Jim   and all, I got it.
>> >>
>> >> I have one more question on the original question
>> >>
>> >>  What does this  "[-1] "  do?
>> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >>                    Col2=NA,col3=NA)
>> >>
>> >>
>> >> mydat <- read.table(textConnection("Col1 Col2 col3
>> >> Z1 K1 K2
>> >> Z2 NA NA
>> >> Z3 X1 NA
>> >> Z4 Y1 W1"),header = TRUE)
>> >>
>> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >>                    Col2=NA,col3=NA)
>> >> rbind(unique(preval),mydat)
>> >>
>> >>
>> >>  Col1 Col2 col3
>> >> 1 <NA> <NA> <NA>
>> >> 2   X1 <NA> <NA>
>> >> 3   Y1 <NA> <NA>
>> >> 4   K2 <NA> <NA>
>> >> 5   W1 <NA> <NA>
>> >> 6   Z1   K1   K2
>> >> 7   Z2 <NA> <NA>
>> >> 8   Z3   X1 <NA>
>> >> 9   Z4   Y1   W1
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch
>> >> <murdoch.duncan at gmail.com>
>> >> wrote:
>> >>
>> >>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
>> >>>
>> >>>>     x1 =  rbind(unique(preval),mydat)
>> >>>>    x2 <- x1[is.na(x1)] <- 0
>> >>>>    x2  # gives 0
>> >>>>
>> >>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think
>> >>>> that
>> >>>> altered x1 is what you want.
>> >>>>
>> >>>> You asked why x2 was zero.  The value of the expression
>> >>>>     f(a) <- b
>> >>>> and assignments are processed right to left so
>> >>>>     x2 <- x[!is.na(x1)] <- 0
>> >>>> is equivalent to
>> >>>>     x[!is.na(x1)] <- 0
>> >>>>     x2 <- 0
>> >>>>
>> >>>
>> >>> That's not right in general, is it?  I'd think that should be
>> >>>
>> >>>     x[!is.na(x1)] <- 0
>> >>>     x2 <- x1
>> >>>
>> >>> Of course, in this example, x1 is 0, so it gives the same answer.
>> >>>
>> >>> Duncan Murdoch
>> >>>
>> >>>
>> >>>
>> >>>>
>> >>>> Bill Dunlap
>> >>>> TIBCO Software
>> >>>> wdunlap tibco.com
>> >>>>
>> >>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
>> >>>>
>> >>>> Thank you Jim
>> >>>>>
>> >>>>> I wanted a final data frame  after replacing the NA's to "0"
>> >>>>>
>> >>>>> x1 =  rbind(unique(preval),mydat)
>> >>>>> x2 <- x1[is.na(x1)] <- 0
>> >>>>> x2
>> >>>>>   but I got this,
>> >>>>>
>> >>>>> [1] 0
>> >>>>>
>> >>>>> why I am getting this?
>> >>>>>
>> >>>>>
>> >>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com>
>> >>>>> wrote:
>> >>>>>
>> >>>>> Hi Val,
>> >>>>>> Try this:
>> >>>>>>
>> >>>>>>
>> >>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >>>>>>   Col2=NA,col3=NA)
>> >>>>>> rbind(preval,mydat)
>> >>>>>>
>> >>>>>> Jim
>> >>>>>>
>> >>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
>> >>>>>>
>> >>>>>>> Hi All,
>> >>>>>>>
>> >>>>>>> I am reading a file as follow,
>> >>>>>>>
>> >>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
>> >>>>>>> Z2 NA NA
>> >>>>>>> Z3 X1 NA
>> >>>>>>> Z4 Y1 W1"),header = TRUE)
>> >>>>>>>
>> >>>>>>> 1. "NA" are   missing  should be replace by 0
>> >>>>>>> 2.  value that are in COl2 and Col3  should be included  in col1
>> >>>>>>> before
>> >>>>>>> they appear
>> >>>>>>> in col2 and col3. So the output data looks like as follow,
>> >>>>>>>
>> >>>>>>> X1  0  0
>> >>>>>>> Y1  0  0
>> >>>>>>> W1  0  0
>> >>>>>>> Z2  0  0
>> >>>>>>> Z3 X1  0
>> >>>>>>> Z4 Y1 W1
>> >>>>>>>
>> >>>>>>> Thank you in advance
>> >>>>>>>
>> >>>>>>>          [[alternative HTML version deleted]]
>> >>>>>>>
>> >>>>>>> ______________________________________________
>> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>> >>>>>>>
>> >>>>>> posting-guide.html
>> >>>>>>
>> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>>>
>> >>>>>>
>> >>>>>>
>> >>>>>          [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide http://www.R-project.org/
>> >>>>> posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>
>> >>>>>
>> >>>>         [[alternative HTML version deleted]]
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide http://www.R-project.org/posti
>> >>>> ng-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>>
>> >>>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From valkremk at gmail.com  Sun Feb 25 01:41:15 2018
From: valkremk at gmail.com (Val)
Date: Sat, 24 Feb 2018 18:41:15 -0600
Subject: [R] include
In-Reply-To: <CA+8X3fV_oAr-1xTzBxZqXd830dsw6Qe3JSmFTeyUmaZge1ciZQ@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
 <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
 <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>
 <CAJOiR6aJ-idxVQLx2hrUxmNC3Z81VAxJSSsF6ZtSbreTVgsbyw@mail.gmail.com>
 <CA+8X3fV_oAr-1xTzBxZqXd830dsw6Qe3JSmFTeyUmaZge1ciZQ@mail.gmail.com>
Message-ID: <CAJOiR6ZQXVrK+pxdc=Mqjj9mxUujit8kFHNN1yYU6N_vVWgiOg@mail.gmail.com>

Thank you so much Jim!

On Sat, Feb 24, 2018 at 6:38 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Val,
> My fault - I assumed that the NA would be first in the result produced
> by "unique":
>
> mydat <- read.table(textConnection("Col1 Col2 col3
> Z1 K1 K2
> Z2 NA NA
> Z3 X1 NA
> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> val23<-unique(unlist(mydat[,c("Col2","col3")]))
> napos<-which(is.na(val23))
> preval<-data.frame(Col1=val23[-napos],
>  Col2=NA,col3=NA)
> mydat<-rbind(preval,mydat)
> mydat[is.na(mydat)]<-"0"
> mydat
>
> Jim
>
> On Sun, Feb 25, 2018 at 11:27 AM, Val <valkremk at gmail.com> wrote:
> > Thank you Jim,
> >
> > I read the data as you suggested but I could not find K1 in   col1.
> >
> > rbind(preval,mydat)
> >   Col1 Col2 col3
> > 1 <NA> <NA> <NA>
> > 2   X1 <NA> <NA>
> > 3   Y1 <NA> <NA>
> > 4   K2 <NA> <NA>
> > 5   W1 <NA> <NA>
> > 6   Z1   K1   K2
> > 7   Z2 <NA> <NA>
> > 8   Z3   X1 <NA>
> > 9   Z4   Y1   W1
> >
> >
> >
> > On Sat, Feb 24, 2018 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> hi Val,
> >> Your problem seems to be that the data are read in as a factor. The
> >> simplest way I can think of to get around this is:
> >>
> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> Z1 K1 K2
> >> Z2 NA NA
> >> Z3 X1 NA
> >> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >>  Col2=NA,col3=NA)
> >> rbind(preval,mydat)
> >> mydat[is.na(mydat)]<-"0"
> >>
> >> Jiim
> >>
> >>
> >> On Sun, Feb 25, 2018 at 11:05 AM, Val <valkremk at gmail.com> wrote:
> >> > Sorry , I hit the send key accidentally  here is my complete message.
> >> >
> >> > Thank you Jim   and all, I got it.
> >> >
> >> > I have one more question on the original question
> >> >
> >> >  What does this  "[-1] "  do?
> >> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >> >                    Col2=NA,col3=NA)
> >> >
> >> >
> >> > mydat <- read.table(textConnection("Col1 Col2 col3
> >> > Z1 K1 K2
> >> > Z2 NA NA
> >> > Z3 X1 NA
> >> > Z4 Y1 W1"),header = TRUE)
> >> >
> >> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >> >                    Col2=NA,col3=NA)
> >> > rbind(unique(preval),mydat)
> >> >
> >> >
> >> >  Col1 Col2 col3
> >> > 1 <NA> <NA> <NA>
> >> > 2   X1 <NA> <NA>
> >> > 3   Y1 <NA> <NA>
> >> > 4   K2 <NA> <NA>
> >> > 5   W1 <NA> <NA>
> >> > 6   Z1   K1   K2
> >> > 7   Z2 <NA> <NA>
> >> > 8   Z3   X1 <NA>
> >> > 9   Z4   Y1   W1
> >> >
> >> > I could not find K1 in the first   col1. Is that possible to fix this?
> >> >
> >> > On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:
> >> >
> >> >> Thank you Jim   and all, I got it.
> >> >>
> >> >> I have one more question on the original question
> >> >>
> >> >>  What does this  "[-1] "  do?
> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> "col3")]))[-1],
> >> >>                    Col2=NA,col3=NA)
> >> >>
> >> >>
> >> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> >> Z1 K1 K2
> >> >> Z2 NA NA
> >> >> Z3 X1 NA
> >> >> Z4 Y1 W1"),header = TRUE)
> >> >>
> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> "col3")]))[-1],
> >> >>                    Col2=NA,col3=NA)
> >> >> rbind(unique(preval),mydat)
> >> >>
> >> >>
> >> >>  Col1 Col2 col3
> >> >> 1 <NA> <NA> <NA>
> >> >> 2   X1 <NA> <NA>
> >> >> 3   Y1 <NA> <NA>
> >> >> 4   K2 <NA> <NA>
> >> >> 5   W1 <NA> <NA>
> >> >> 6   Z1   K1   K2
> >> >> 7   Z2 <NA> <NA>
> >> >> 8   Z3   X1 <NA>
> >> >> 9   Z4   Y1   W1
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch
> >> >> <murdoch.duncan at gmail.com>
> >> >> wrote:
> >> >>
> >> >>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
> >> >>>
> >> >>>>     x1 =  rbind(unique(preval),mydat)
> >> >>>>    x2 <- x1[is.na(x1)] <- 0
> >> >>>>    x2  # gives 0
> >> >>>>
> >> >>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I
> think
> >> >>>> that
> >> >>>> altered x1 is what you want.
> >> >>>>
> >> >>>> You asked why x2 was zero.  The value of the expression
> >> >>>>     f(a) <- b
> >> >>>> and assignments are processed right to left so
> >> >>>>     x2 <- x[!is.na(x1)] <- 0
> >> >>>> is equivalent to
> >> >>>>     x[!is.na(x1)] <- 0
> >> >>>>     x2 <- 0
> >> >>>>
> >> >>>
> >> >>> That's not right in general, is it?  I'd think that should be
> >> >>>
> >> >>>     x[!is.na(x1)] <- 0
> >> >>>     x2 <- x1
> >> >>>
> >> >>> Of course, in this example, x1 is 0, so it gives the same answer.
> >> >>>
> >> >>> Duncan Murdoch
> >> >>>
> >> >>>
> >> >>>
> >> >>>>
> >> >>>> Bill Dunlap
> >> >>>> TIBCO Software
> >> >>>> wdunlap tibco.com
> >> >>>>
> >> >>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
> >> >>>>
> >> >>>> Thank you Jim
> >> >>>>>
> >> >>>>> I wanted a final data frame  after replacing the NA's to "0"
> >> >>>>>
> >> >>>>> x1 =  rbind(unique(preval),mydat)
> >> >>>>> x2 <- x1[is.na(x1)] <- 0
> >> >>>>> x2
> >> >>>>>   but I got this,
> >> >>>>>
> >> >>>>> [1] 0
> >> >>>>>
> >> >>>>> why I am getting this?
> >> >>>>>
> >> >>>>>
> >> >>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com
> >
> >> >>>>> wrote:
> >> >>>>>
> >> >>>>> Hi Val,
> >> >>>>>> Try this:
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> "col3")]))[-1],
> >> >>>>>>   Col2=NA,col3=NA)
> >> >>>>>> rbind(preval,mydat)
> >> >>>>>>
> >> >>>>>> Jim
> >> >>>>>>
> >> >>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
> >> >>>>>>
> >> >>>>>>> Hi All,
> >> >>>>>>>
> >> >>>>>>> I am reading a file as follow,
> >> >>>>>>>
> >> >>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
> >> >>>>>>> Z2 NA NA
> >> >>>>>>> Z3 X1 NA
> >> >>>>>>> Z4 Y1 W1"),header = TRUE)
> >> >>>>>>>
> >> >>>>>>> 1. "NA" are   missing  should be replace by 0
> >> >>>>>>> 2.  value that are in COl2 and Col3  should be included  in col1
> >> >>>>>>> before
> >> >>>>>>> they appear
> >> >>>>>>> in col2 and col3. So the output data looks like as follow,
> >> >>>>>>>
> >> >>>>>>> X1  0  0
> >> >>>>>>> Y1  0  0
> >> >>>>>>> W1  0  0
> >> >>>>>>> Z2  0  0
> >> >>>>>>> Z3 X1  0
> >> >>>>>>> Z4 Y1 W1
> >> >>>>>>>
> >> >>>>>>> Thank you in advance
> >> >>>>>>>
> >> >>>>>>>          [[alternative HTML version deleted]]
> >> >>>>>>>
> >> >>>>>>> ______________________________________________
> >> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >>>>>>>
> >> >>>>>> posting-guide.html
> >> >>>>>>
> >> >>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >> >>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>          [[alternative HTML version deleted]]
> >> >>>>>
> >> >>>>> ______________________________________________
> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >>>>> posting-guide.html
> >> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>>>>
> >> >>>>>
> >> >>>>         [[alternative HTML version deleted]]
> >> >>>>
> >> >>>> ______________________________________________
> >> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>> PLEASE do read the posting guide http://www.R-project.org/posti
> >> >>>> ng-guide.html
> >> >>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>>>
> >> >>>>
> >> >>>
> >> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Feb 25 02:00:23 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 24 Feb 2018 17:00:23 -0800
Subject: [R] include
In-Reply-To: <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
Message-ID: <CAF8bMcYo3QksuTaK0knVzoE=E90QVg74jusEFaZo_BB6HB=6-w@mail.gmail.com>

    That's not right in general, is it?  I'd think that should be

       x[!is.na(x1)] <- 0
       x2 <- x1

I left out a '1' on the first line - it should have been
   x1[!is.na(x1)] <- 0

In the following examples the value of the assignment
expression is the right hand side of the assignment.

> x1 <- factor(c("A","B","C","D","E"))
> x2 <- x1[2:5] <- c("C","E")
> str(x1)
 Factor w/ 5 levels "A","B","C","D",..: 1 3 5 3 5
> str(x2)
 chr [1:2] "C" "E"
'

> x1 <- (2:5) + 1i * (5:2)
> x2 <- x1[ Mod(x1) == 5 ] <- c(17L, 19L)
> str(x1)
 cplx [1:4] 2+5i 17+0i 19+0i ...
> str(x2)
 int [1:2] 17 19







Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Feb 24, 2018 at 3:04 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
>
>>     x1 =  rbind(unique(preval),mydat)
>>    x2 <- x1[is.na(x1)] <- 0
>>    x2  # gives 0
>>
>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I think that
>> altered x1 is what you want.
>>
>> You asked why x2 was zero.  The value of the expression
>>     f(a) <- b
>> and assignments are processed right to left so
>>     x2 <- x[!is.na(x1)] <- 0
>> is equivalent to
>>     x[!is.na(x1)] <- 0
>>     x2 <- 0
>>
>
> That's not right in general, is it?  I'd think that should be
>
>     x[!is.na(x1)] <- 0
>     x2 <- x1
>
> Of course, in this example, x1 is 0, so it gives the same answer.
>
> Duncan Murdoch
>
>
>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
>>
>> Thank you Jim
>>>
>>> I wanted a final data frame  after replacing the NA's to "0"
>>>
>>> x1 =  rbind(unique(preval),mydat)
>>> x2 <- x1[is.na(x1)] <- 0
>>> x2
>>>   but I got this,
>>>
>>> [1] 0
>>>
>>> why I am getting this?
>>>
>>>
>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>>
>>> Hi Val,
>>>> Try this:
>>>>
>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>>>>   Col2=NA,col3=NA)
>>>> rbind(preval,mydat)
>>>>
>>>> Jim
>>>>
>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
>>>>
>>>>> Hi All,
>>>>>
>>>>> I am reading a file as follow,
>>>>>
>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
>>>>> Z2 NA NA
>>>>> Z3 X1 NA
>>>>> Z4 Y1 W1"),header = TRUE)
>>>>>
>>>>> 1. "NA" are   missing  should be replace by 0
>>>>> 2.  value that are in COl2 and Col3  should be included  in col1 before
>>>>> they appear
>>>>> in col2 and col3. So the output data looks like as follow,
>>>>>
>>>>> X1  0  0
>>>>> Y1  0  0
>>>>> W1  0  0
>>>>> Z2  0  0
>>>>> Z3 X1  0
>>>>> Z4 Y1 W1
>>>>>
>>>>> Thank you in advance
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>
>>>> posting-guide.html
>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Sun Feb 25 16:55:55 2018
From: valkremk at gmail.com (Val)
Date: Sun, 25 Feb 2018 09:55:55 -0600
Subject: [R] include
In-Reply-To: <CA+8X3fV_oAr-1xTzBxZqXd830dsw6Qe3JSmFTeyUmaZge1ciZQ@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
 <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
 <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>
 <CAJOiR6aJ-idxVQLx2hrUxmNC3Z81VAxJSSsF6ZtSbreTVgsbyw@mail.gmail.com>
 <CA+8X3fV_oAr-1xTzBxZqXd830dsw6Qe3JSmFTeyUmaZge1ciZQ@mail.gmail.com>
Message-ID: <CAJOiR6Z_DofV1ugP88gHqQyrN2Ah2Tg+fT4eyFJ0Mmxr_tphog@mail.gmail.com>

HI Jim and all,

I want to put one more condition.   Include col2 and col3 if they are not
in col1.

Here is the data
mydat <- read.table(textConnection("Col1 Col2 col3
K2 X1 NA
Z1 K1 K2
Z2 NA NA
Z3 X1 NA
Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)

The desired out put would be

  Col1 Col2 col3
1    X1    0    0
2    K1    0    0
3    Y1    0    0
4    W1    0    0
6    K2   X1    0
7    Z1   K1   K2
8    Z2    0    0
9    Z3   X1    0
10   Z4   Y1   W1

K2 is already is already in col1 and should not be added.

Thank you in advance







On Sat, Feb 24, 2018 at 6:38 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Val,
> My fault - I assumed that the NA would be first in the result produced
> by "unique":
>
> mydat <- read.table(textConnection("Col1 Col2 col3
> Z1 K1 K2
> Z2 NA NA
> Z3 X1 NA
> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> val23<-unique(unlist(mydat[,c("Col2","col3")]))
> napos<-which(is.na(val23))
> preval<-data.frame(Col1=val23[-napos],
>  Col2=NA,col3=NA)
> mydat<-rbind(preval,mydat)
> mydat[is.na(mydat)]<-"0"
> mydat
>
> Jim
>
> On Sun, Feb 25, 2018 at 11:27 AM, Val <valkremk at gmail.com> wrote:
> > Thank you Jim,
> >
> > I read the data as you suggested but I could not find K1 in   col1.
> >
> > rbind(preval,mydat)
> >   Col1 Col2 col3
> > 1 <NA> <NA> <NA>
> > 2   X1 <NA> <NA>
> > 3   Y1 <NA> <NA>
> > 4   K2 <NA> <NA>
> > 5   W1 <NA> <NA>
> > 6   Z1   K1   K2
> > 7   Z2 <NA> <NA>
> > 8   Z3   X1 <NA>
> > 9   Z4   Y1   W1
> >
> >
> >
> > On Sat, Feb 24, 2018 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> hi Val,
> >> Your problem seems to be that the data are read in as a factor. The
> >> simplest way I can think of to get around this is:
> >>
> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> Z1 K1 K2
> >> Z2 NA NA
> >> Z3 X1 NA
> >> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >>  Col2=NA,col3=NA)
> >> rbind(preval,mydat)
> >> mydat[is.na(mydat)]<-"0"
> >>
> >> Jiim
> >>
> >>
> >> On Sun, Feb 25, 2018 at 11:05 AM, Val <valkremk at gmail.com> wrote:
> >> > Sorry , I hit the send key accidentally  here is my complete message.
> >> >
> >> > Thank you Jim   and all, I got it.
> >> >
> >> > I have one more question on the original question
> >> >
> >> >  What does this  "[-1] "  do?
> >> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >> >                    Col2=NA,col3=NA)
> >> >
> >> >
> >> > mydat <- read.table(textConnection("Col1 Col2 col3
> >> > Z1 K1 K2
> >> > Z2 NA NA
> >> > Z3 X1 NA
> >> > Z4 Y1 W1"),header = TRUE)
> >> >
> >> > preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >> >                    Col2=NA,col3=NA)
> >> > rbind(unique(preval),mydat)
> >> >
> >> >
> >> >  Col1 Col2 col3
> >> > 1 <NA> <NA> <NA>
> >> > 2   X1 <NA> <NA>
> >> > 3   Y1 <NA> <NA>
> >> > 4   K2 <NA> <NA>
> >> > 5   W1 <NA> <NA>
> >> > 6   Z1   K1   K2
> >> > 7   Z2 <NA> <NA>
> >> > 8   Z3   X1 <NA>
> >> > 9   Z4   Y1   W1
> >> >
> >> > I could not find K1 in the first   col1. Is that possible to fix this?
> >> >
> >> > On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:
> >> >
> >> >> Thank you Jim   and all, I got it.
> >> >>
> >> >> I have one more question on the original question
> >> >>
> >> >>  What does this  "[-1] "  do?
> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> "col3")]))[-1],
> >> >>                    Col2=NA,col3=NA)
> >> >>
> >> >>
> >> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> >> Z1 K1 K2
> >> >> Z2 NA NA
> >> >> Z3 X1 NA
> >> >> Z4 Y1 W1"),header = TRUE)
> >> >>
> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> "col3")]))[-1],
> >> >>                    Col2=NA,col3=NA)
> >> >> rbind(unique(preval),mydat)
> >> >>
> >> >>
> >> >>  Col1 Col2 col3
> >> >> 1 <NA> <NA> <NA>
> >> >> 2   X1 <NA> <NA>
> >> >> 3   Y1 <NA> <NA>
> >> >> 4   K2 <NA> <NA>
> >> >> 5   W1 <NA> <NA>
> >> >> 6   Z1   K1   K2
> >> >> 7   Z2 <NA> <NA>
> >> >> 8   Z3   X1 <NA>
> >> >> 9   Z4   Y1   W1
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch
> >> >> <murdoch.duncan at gmail.com>
> >> >> wrote:
> >> >>
> >> >>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
> >> >>>
> >> >>>>     x1 =  rbind(unique(preval),mydat)
> >> >>>>    x2 <- x1[is.na(x1)] <- 0
> >> >>>>    x2  # gives 0
> >> >>>>
> >> >>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and I
> think
> >> >>>> that
> >> >>>> altered x1 is what you want.
> >> >>>>
> >> >>>> You asked why x2 was zero.  The value of the expression
> >> >>>>     f(a) <- b
> >> >>>> and assignments are processed right to left so
> >> >>>>     x2 <- x[!is.na(x1)] <- 0
> >> >>>> is equivalent to
> >> >>>>     x[!is.na(x1)] <- 0
> >> >>>>     x2 <- 0
> >> >>>>
> >> >>>
> >> >>> That's not right in general, is it?  I'd think that should be
> >> >>>
> >> >>>     x[!is.na(x1)] <- 0
> >> >>>     x2 <- x1
> >> >>>
> >> >>> Of course, in this example, x1 is 0, so it gives the same answer.
> >> >>>
> >> >>> Duncan Murdoch
> >> >>>
> >> >>>
> >> >>>
> >> >>>>
> >> >>>> Bill Dunlap
> >> >>>> TIBCO Software
> >> >>>> wdunlap tibco.com
> >> >>>>
> >> >>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com> wrote:
> >> >>>>
> >> >>>> Thank you Jim
> >> >>>>>
> >> >>>>> I wanted a final data frame  after replacing the NA's to "0"
> >> >>>>>
> >> >>>>> x1 =  rbind(unique(preval),mydat)
> >> >>>>> x2 <- x1[is.na(x1)] <- 0
> >> >>>>> x2
> >> >>>>>   but I got this,
> >> >>>>>
> >> >>>>> [1] 0
> >> >>>>>
> >> >>>>> why I am getting this?
> >> >>>>>
> >> >>>>>
> >> >>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon <drjimlemon at gmail.com
> >
> >> >>>>> wrote:
> >> >>>>>
> >> >>>>> Hi Val,
> >> >>>>>> Try this:
> >> >>>>>>
> >> >>>>>>
> >> >>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> "col3")]))[-1],
> >> >>>>>>   Col2=NA,col3=NA)
> >> >>>>>> rbind(preval,mydat)
> >> >>>>>>
> >> >>>>>> Jim
> >> >>>>>>
> >> >>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com> wrote:
> >> >>>>>>
> >> >>>>>>> Hi All,
> >> >>>>>>>
> >> >>>>>>> I am reading a file as follow,
> >> >>>>>>>
> >> >>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
> >> >>>>>>> Z2 NA NA
> >> >>>>>>> Z3 X1 NA
> >> >>>>>>> Z4 Y1 W1"),header = TRUE)
> >> >>>>>>>
> >> >>>>>>> 1. "NA" are   missing  should be replace by 0
> >> >>>>>>> 2.  value that are in COl2 and Col3  should be included  in col1
> >> >>>>>>> before
> >> >>>>>>> they appear
> >> >>>>>>> in col2 and col3. So the output data looks like as follow,
> >> >>>>>>>
> >> >>>>>>> X1  0  0
> >> >>>>>>> Y1  0  0
> >> >>>>>>> W1  0  0
> >> >>>>>>> Z2  0  0
> >> >>>>>>> Z3 X1  0
> >> >>>>>>> Z4 Y1 W1
> >> >>>>>>>
> >> >>>>>>> Thank you in advance
> >> >>>>>>>
> >> >>>>>>>          [[alternative HTML version deleted]]
> >> >>>>>>>
> >> >>>>>>> ______________________________________________
> >> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >>>>>>>
> >> >>>>>> posting-guide.html
> >> >>>>>>
> >> >>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> >> >>>>>>>
> >> >>>>>>
> >> >>>>>>
> >> >>>>>          [[alternative HTML version deleted]]
> >> >>>>>
> >> >>>>> ______________________________________________
> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >>>>> posting-guide.html
> >> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>>>>
> >> >>>>>
> >> >>>>         [[alternative HTML version deleted]]
> >> >>>>
> >> >>>> ______________________________________________
> >> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>> PLEASE do read the posting guide http://www.R-project.org/posti
> >> >>>> ng-guide.html
> >> >>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>>>
> >> >>>>
> >> >>>
> >> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From garre.alberto at gmail.com  Sun Feb 25 12:17:06 2018
From: garre.alberto at gmail.com (Alberto Garre)
Date: Sun, 25 Feb 2018 12:17:06 +0100
Subject: [R] 
 How to Save the residuals of an LM object greater or less than
 a certin value to an R object?
Message-ID: <CAMo5YQZqwc8hmeeJu7r2MhbWSx5CLVg923nvEsiVOyUU933Gfw@mail.gmail.com>

Hi Peter,

the "residuals()" function returns the residuals of a model fitted using
the "lm" function. For instances, using the example included in the help of
lm:


ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2, 10, 20, labels = c("Ctl","Trt"))
weight <- c(ctl, trt)
lm.D9 <- lm(weight ~ group)

my_res <- residuals(lm.D9)
print(my_res)

The object returned by "residuals()" is a vector, so you can make any
operation with it. For instance:

my_res[my_res >= 0.1]

About your second question, I don't entirely understand what you want. The
"which()" function returns the indexes for which the condition is TRUE. In
this case, that the absolute value is greater than 2.5.

Alberto Garre


> Also,
>
> which( abs( stdresiduals ) > 2.5 )
>
> will tell you which of the standardized residuals are bigger than 2.5 in
absolute value. It returns a vector of indices, as in
>
> > set.seed(1234)
> > x <- rnorm(100)
> > which (abs(x) > 2.5)
> [1] 62
> > x[62]
> [1] 2.548991
>
>
> -pd

	[[alternative HTML version deleted]]


From allaisone1 at hotmail.com  Sun Feb 25 13:59:46 2018
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Sun, 25 Feb 2018 12:59:46 +0000
Subject: [R] reshaping column items into rows per unique ID
Message-ID: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>

Hi All

I have a datafram which looks like this :

CustomerID    DietType
1                           a
1                            c
1                            b
2                            f
2                             a
3                             j
4                             c
4                             c
4                              f

And I would like to reshape this so I can see the list of DietTypes per customer in rows instead of columns like this :

> MyDf
CustomerID      DietType   DietType  DietType
1                                a            c               b
2                                 f             a
3                                 j
4                                 c              c             f

I tried many times using melt(),spread (),and dcast () functions but was not able to produce the desired table. The best attempt was by typing :

# 1) Adding new column with unique values:
MyDf $newcol <- c (1:9)
#2) then :
NewDf <- dcast (MyDf,CustomerID~newcol,value.var=DietType)

This produces the desired table but with many NA values like this :

CustomerID    1   2   3    4     5    6     7   8   9
1                    a  c    b   NA NA NA NA NA NA
2                  NA NA NA  f     a  NA NA NA NA
3                  NA NA NA NA NA  j   NA NA NA
4                  NA NA NA NA NA NA c     c     f

  As you see, the lette/s indicating DietType move to the right side each time we move down leaving many NA values and as my original files is very large, I expect that the final output would contain around 800,000 columns and 70,000 rows. This is why my code works with small data but does not work with my large file because of memory issue even though I'm using large PC.

What changes I need to do with my code to produce the desired table where the list of DietTypes are grouped in rows exactly like the second table shown abover?

Regards
Allaisnoe

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Feb 25 18:08:13 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Feb 2018 09:08:13 -0800
Subject: [R] reshaping column items into rows per unique ID
In-Reply-To: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>
References: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbRV5nz4AhL+z3WvM9+OM2LG8xoMRcBM9efrXoG5QvAbRw@mail.gmail.com>

I believe you need to spend time with an R tutorial or two: a data frame
(presumably the "table" data structure you describe) can *not* contain
"blanks" -- all columns must be the same length, which means NA's are
filled in as needed.

Also, 8e^5 * 7e^4 = 5.6e^10, which almost certainly will not fit into any
local version of R (maybe it would in some server version -- others more
knowledgeable should comment on this).

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Feb 25, 2018 at 4:59 AM, Allaisone 1 <allaisone1 at hotmail.com> wrote:

> Hi All
>
> I have a datafram which looks like this :
>
> CustomerID    DietType
> 1                           a
> 1                            c
> 1                            b
> 2                            f
> 2                             a
> 3                             j
> 4                             c
> 4                             c
> 4                              f
>
> And I would like to reshape this so I can see the list of DietTypes per
> customer in rows instead of columns like this :
>
> > MyDf
> CustomerID      DietType   DietType  DietType
> 1                                a            c               b
> 2                                 f             a
> 3                                 j
> 4                                 c              c             f
>
> I tried many times using melt(),spread (),and dcast () functions but was
> not able to produce the desired table. The best attempt was by typing :
>
> # 1) Adding new column with unique values:
> MyDf $newcol <- c (1:9)
> #2) then :
> NewDf <- dcast (MyDf,CustomerID~newcol,value.var=DietType)
>
> This produces the desired table but with many NA values like this :
>
> CustomerID    1   2   3    4     5    6     7   8   9
> 1                    a  c    b   NA NA NA NA NA NA
> 2                  NA NA NA  f     a  NA NA NA NA
> 3                  NA NA NA NA NA  j   NA NA NA
> 4                  NA NA NA NA NA NA c     c     f
>
>   As you see, the lette/s indicating DietType move to the right side each
> time we move down leaving many NA values and as my original files is very
> large, I expect that the final output would contain around 800,000 columns
> and 70,000 rows. This is why my code works with small data but does not
> work with my large file because of memory issue even though I'm using large
> PC.
>
> What changes I need to do with my code to produce the desired table where
> the list of DietTypes are grouped in rows exactly like the second table
> shown abover?
>
> Regards
> Allaisnoe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Sun Feb 25 18:56:37 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 25 Feb 2018 19:56:37 +0200
Subject: [R] reshaping column items into rows per unique ID
In-Reply-To: <CAGxFJbRV5nz4AhL+z3WvM9+OM2LG8xoMRcBM9efrXoG5QvAbRw@mail.gmail.com>
References: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbRV5nz4AhL+z3WvM9+OM2LG8xoMRcBM9efrXoG5QvAbRw@mail.gmail.com>
Message-ID: <CAGgJW74QTJ_So_sBSOpWXVBJdr0SuwN4YUyus1DngKGwkPuRHw@mail.gmail.com>

Hi Allaisone,
I took a slightly different approach but you might find this either as or
more useful than your approach, or at least a start on the path to a
solution you need.

df1   <-
data.frame(CustId=c(1,1,1,2,3,3,4,4,4),DietType=c("a","c","b","f","a","j","c","c","f"),
                    stringsAsFactors=FALSE)
custs <- unique(df1$CustId)
dtype <- unique(df1$DietType)
nc    <- length(custs)
nd    <- length(dtype)
df2   <- as.data.frame( matrix(rep(0,nc*(nd+1)),nrow=nc),
stringsAsFactors=FALSE)
colnames(df2) <- c("CustId",dtype[order(dtype)])
df2$CustId <- custs[ order(custs) ]

for ( i in 1:nrow(df1) ) {
  iRow <- match(df1$CustId[i],df2$CustId)
  iCol <- match(df1$DietType[i],colnames(df2))
  df2[ iRow, iCol ] <- df2[ iRow, iCol] + 1
}

> df2
#       CustId   a  b  c  f   j
# 1             1  1  1  1  0  0
# 2              2  0 0  0  0  0
# 3              3  1 0  0  0  1
# 4              4  0 0  2  1  0

The dataframe df2 will have a column for the CustId and one column for each
unique diet type.
Each row is a unique customerId, and each entry contains the number of
times the given diet type occurred for that customer.

I hope that helps,
Eric



On Sun, Feb 25, 2018 at 7:08 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I believe you need to spend time with an R tutorial or two: a data frame
> (presumably the "table" data structure you describe) can *not* contain
> "blanks" -- all columns must be the same length, which means NA's are
> filled in as needed.
>
> Also, 8e^5 * 7e^4 = 5.6e^10, which almost certainly will not fit into any
> local version of R (maybe it would in some server version -- others more
> knowledgeable should comment on this).
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Feb 25, 2018 at 4:59 AM, Allaisone 1 <allaisone1 at hotmail.com>
> wrote:
>
> > Hi All
> >
> > I have a datafram which looks like this :
> >
> > CustomerID    DietType
> > 1                           a
> > 1                            c
> > 1                            b
> > 2                            f
> > 2                             a
> > 3                             j
> > 4                             c
> > 4                             c
> > 4                              f
> >
> > And I would like to reshape this so I can see the list of DietTypes per
> > customer in rows instead of columns like this :
> >
> > > MyDf
> > CustomerID      DietType   DietType  DietType
> > 1                                a            c               b
> > 2                                 f             a
> > 3                                 j
> > 4                                 c              c             f
> >
> > I tried many times using melt(),spread (),and dcast () functions but was
> > not able to produce the desired table. The best attempt was by typing :
> >
> > # 1) Adding new column with unique values:
> > MyDf $newcol <- c (1:9)
> > #2) then :
> > NewDf <- dcast (MyDf,CustomerID~newcol,value.var=DietType)
> >
> > This produces the desired table but with many NA values like this :
> >
> > CustomerID    1   2   3    4     5    6     7   8   9
> > 1                    a  c    b   NA NA NA NA NA NA
> > 2                  NA NA NA  f     a  NA NA NA NA
> > 3                  NA NA NA NA NA  j   NA NA NA
> > 4                  NA NA NA NA NA NA c     c     f
> >
> >   As you see, the lette/s indicating DietType move to the right side each
> > time we move down leaving many NA values and as my original files is very
> > large, I expect that the final output would contain around 800,000
> columns
> > and 70,000 rows. This is why my code works with small data but does not
> > work with my large file because of memory issue even though I'm using
> large
> > PC.
> >
> > What changes I need to do with my code to produce the desired table where
> > the list of DietTypes are grouped in rows exactly like the second table
> > shown abover?
> >
> > Regards
> > Allaisnoe
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Feb 25 19:18:43 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Feb 2018 10:18:43 -0800
Subject: [R] include
In-Reply-To: <CAJOiR6Z_DofV1ugP88gHqQyrN2Ah2Tg+fT4eyFJ0Mmxr_tphog@mail.gmail.com>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
 <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
 <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>
 <CAJOiR6aJ-idxVQLx2hrUxmNC3Z81VAxJSSsF6ZtSbreTVgsbyw@mail.gmail.com>
 <CA+8X3fV_oAr-1xTzBxZqXd830dsw6Qe3JSmFTeyUmaZge1ciZQ@mail.gmail.com>
 <CAJOiR6Z_DofV1ugP88gHqQyrN2Ah2Tg+fT4eyFJ0Mmxr_tphog@mail.gmail.com>
Message-ID: <99F8E30F-F9DA-4C3B-AF25-0718D445D8FE@dcn.davis.ca.us>

Jim has been exceedingly patient (and may well continue to be so), but this smells like "failure to launch". At what point will you start showing your (failed) attempts at solving your own problems so we can help you work on your specific weaknesses and become self-sufficient?
-- 
Sent from my phone. Please excuse my brevity.

On February 25, 2018 7:55:55 AM PST, Val <valkremk at gmail.com> wrote:
>HI Jim and all,
>
>I want to put one more condition.   Include col2 and col3 if they are
>not
>in col1.
>
>Here is the data
>mydat <- read.table(textConnection("Col1 Col2 col3
>K2 X1 NA
>Z1 K1 K2
>Z2 NA NA
>Z3 X1 NA
>Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
>
>The desired out put would be
>
>  Col1 Col2 col3
>1    X1    0    0
>2    K1    0    0
>3    Y1    0    0
>4    W1    0    0
>6    K2   X1    0
>7    Z1   K1   K2
>8    Z2    0    0
>9    Z3   X1    0
>10   Z4   Y1   W1
>
>K2 is already is already in col1 and should not be added.
>
>Thank you in advance
>
>
>
>
>
>
>
>On Sat, Feb 24, 2018 at 6:38 PM, Jim Lemon <drjimlemon at gmail.com>
>wrote:
>
>> Hi Val,
>> My fault - I assumed that the NA would be first in the result
>produced
>> by "unique":
>>
>> mydat <- read.table(textConnection("Col1 Col2 col3
>> Z1 K1 K2
>> Z2 NA NA
>> Z3 X1 NA
>> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
>> val23<-unique(unlist(mydat[,c("Col2","col3")]))
>> napos<-which(is.na(val23))
>> preval<-data.frame(Col1=val23[-napos],
>>  Col2=NA,col3=NA)
>> mydat<-rbind(preval,mydat)
>> mydat[is.na(mydat)]<-"0"
>> mydat
>>
>> Jim
>>
>> On Sun, Feb 25, 2018 at 11:27 AM, Val <valkremk at gmail.com> wrote:
>> > Thank you Jim,
>> >
>> > I read the data as you suggested but I could not find K1 in   col1.
>> >
>> > rbind(preval,mydat)
>> >   Col1 Col2 col3
>> > 1 <NA> <NA> <NA>
>> > 2   X1 <NA> <NA>
>> > 3   Y1 <NA> <NA>
>> > 4   K2 <NA> <NA>
>> > 5   W1 <NA> <NA>
>> > 6   Z1   K1   K2
>> > 7   Z2 <NA> <NA>
>> > 8   Z3   X1 <NA>
>> > 9   Z4   Y1   W1
>> >
>> >
>> >
>> > On Sat, Feb 24, 2018 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com>
>wrote:
>> >>
>> >> hi Val,
>> >> Your problem seems to be that the data are read in as a factor.
>The
>> >> simplest way I can think of to get around this is:
>> >>
>> >> mydat <- read.table(textConnection("Col1 Col2 col3
>> >> Z1 K1 K2
>> >> Z2 NA NA
>> >> Z3 X1 NA
>> >> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
>> >>
>preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >>  Col2=NA,col3=NA)
>> >> rbind(preval,mydat)
>> >> mydat[is.na(mydat)]<-"0"
>> >>
>> >> Jiim
>> >>
>> >>
>> >> On Sun, Feb 25, 2018 at 11:05 AM, Val <valkremk at gmail.com> wrote:
>> >> > Sorry , I hit the send key accidentally  here is my complete
>message.
>> >> >
>> >> > Thank you Jim   and all, I got it.
>> >> >
>> >> > I have one more question on the original question
>> >> >
>> >> >  What does this  "[-1] "  do?
>> >> >
>preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >> >                    Col2=NA,col3=NA)
>> >> >
>> >> >
>> >> > mydat <- read.table(textConnection("Col1 Col2 col3
>> >> > Z1 K1 K2
>> >> > Z2 NA NA
>> >> > Z3 X1 NA
>> >> > Z4 Y1 W1"),header = TRUE)
>> >> >
>> >> >
>preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
>> >> >                    Col2=NA,col3=NA)
>> >> > rbind(unique(preval),mydat)
>> >> >
>> >> >
>> >> >  Col1 Col2 col3
>> >> > 1 <NA> <NA> <NA>
>> >> > 2   X1 <NA> <NA>
>> >> > 3   Y1 <NA> <NA>
>> >> > 4   K2 <NA> <NA>
>> >> > 5   W1 <NA> <NA>
>> >> > 6   Z1   K1   K2
>> >> > 7   Z2 <NA> <NA>
>> >> > 8   Z3   X1 <NA>
>> >> > 9   Z4   Y1   W1
>> >> >
>> >> > I could not find K1 in the first   col1. Is that possible to fix
>this?
>> >> >
>> >> > On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:
>> >> >
>> >> >> Thank you Jim   and all, I got it.
>> >> >>
>> >> >> I have one more question on the original question
>> >> >>
>> >> >>  What does this  "[-1] "  do?
>> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
>> "col3")]))[-1],
>> >> >>                    Col2=NA,col3=NA)
>> >> >>
>> >> >>
>> >> >> mydat <- read.table(textConnection("Col1 Col2 col3
>> >> >> Z1 K1 K2
>> >> >> Z2 NA NA
>> >> >> Z3 X1 NA
>> >> >> Z4 Y1 W1"),header = TRUE)
>> >> >>
>> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
>> "col3")]))[-1],
>> >> >>                    Col2=NA,col3=NA)
>> >> >> rbind(unique(preval),mydat)
>> >> >>
>> >> >>
>> >> >>  Col1 Col2 col3
>> >> >> 1 <NA> <NA> <NA>
>> >> >> 2   X1 <NA> <NA>
>> >> >> 3   Y1 <NA> <NA>
>> >> >> 4   K2 <NA> <NA>
>> >> >> 5   W1 <NA> <NA>
>> >> >> 6   Z1   K1   K2
>> >> >> 7   Z2 <NA> <NA>
>> >> >> 8   Z3   X1 <NA>
>> >> >> 9   Z4   Y1   W1
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch
>> >> >> <murdoch.duncan at gmail.com>
>> >> >> wrote:
>> >> >>
>> >> >>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
>> >> >>>
>> >> >>>>     x1 =  rbind(unique(preval),mydat)
>> >> >>>>    x2 <- x1[is.na(x1)] <- 0
>> >> >>>>    x2  # gives 0
>> >> >>>>
>> >> >>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and
>I
>> think
>> >> >>>> that
>> >> >>>> altered x1 is what you want.
>> >> >>>>
>> >> >>>> You asked why x2 was zero.  The value of the expression
>> >> >>>>     f(a) <- b
>> >> >>>> and assignments are processed right to left so
>> >> >>>>     x2 <- x[!is.na(x1)] <- 0
>> >> >>>> is equivalent to
>> >> >>>>     x[!is.na(x1)] <- 0
>> >> >>>>     x2 <- 0
>> >> >>>>
>> >> >>>
>> >> >>> That's not right in general, is it?  I'd think that should be
>> >> >>>
>> >> >>>     x[!is.na(x1)] <- 0
>> >> >>>     x2 <- x1
>> >> >>>
>> >> >>> Of course, in this example, x1 is 0, so it gives the same
>answer.
>> >> >>>
>> >> >>> Duncan Murdoch
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>>>
>> >> >>>> Bill Dunlap
>> >> >>>> TIBCO Software
>> >> >>>> wdunlap tibco.com
>> >> >>>>
>> >> >>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com>
>wrote:
>> >> >>>>
>> >> >>>> Thank you Jim
>> >> >>>>>
>> >> >>>>> I wanted a final data frame  after replacing the NA's to "0"
>> >> >>>>>
>> >> >>>>> x1 =  rbind(unique(preval),mydat)
>> >> >>>>> x2 <- x1[is.na(x1)] <- 0
>> >> >>>>> x2
>> >> >>>>>   but I got this,
>> >> >>>>>
>> >> >>>>> [1] 0
>> >> >>>>>
>> >> >>>>> why I am getting this?
>> >> >>>>>
>> >> >>>>>
>> >> >>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon
><drjimlemon at gmail.com
>> >
>> >> >>>>> wrote:
>> >> >>>>>
>> >> >>>>> Hi Val,
>> >> >>>>>> Try this:
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
>> "col3")]))[-1],
>> >> >>>>>>   Col2=NA,col3=NA)
>> >> >>>>>> rbind(preval,mydat)
>> >> >>>>>>
>> >> >>>>>> Jim
>> >> >>>>>>
>> >> >>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com>
>wrote:
>> >> >>>>>>
>> >> >>>>>>> Hi All,
>> >> >>>>>>>
>> >> >>>>>>> I am reading a file as follow,
>> >> >>>>>>>
>> >> >>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
>> >> >>>>>>> Z2 NA NA
>> >> >>>>>>> Z3 X1 NA
>> >> >>>>>>> Z4 Y1 W1"),header = TRUE)
>> >> >>>>>>>
>> >> >>>>>>> 1. "NA" are   missing  should be replace by 0
>> >> >>>>>>> 2.  value that are in COl2 and Col3  should be included 
>in col1
>> >> >>>>>>> before
>> >> >>>>>>> they appear
>> >> >>>>>>> in col2 and col3. So the output data looks like as follow,
>> >> >>>>>>>
>> >> >>>>>>> X1  0  0
>> >> >>>>>>> Y1  0  0
>> >> >>>>>>> W1  0  0
>> >> >>>>>>> Z2  0  0
>> >> >>>>>>> Z3 X1  0
>> >> >>>>>>> Z4 Y1 W1
>> >> >>>>>>>
>> >> >>>>>>> Thank you in advance
>> >> >>>>>>>
>> >> >>>>>>>          [[alternative HTML version deleted]]
>> >> >>>>>>>
>> >> >>>>>>> ______________________________________________
>> >> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more,
>> see
>> >> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>> >> >>>>>>>
>> >> >>>>>> posting-guide.html
>> >> >>>>>>
>> >> >>>>>>> and provide commented, minimal, self-contained,
>reproducible
>> code.
>> >> >>>>>>>
>> >> >>>>>>
>> >> >>>>>>
>> >> >>>>>          [[alternative HTML version deleted]]
>> >> >>>>>
>> >> >>>>> ______________________________________________
>> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more, see
>> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>>> PLEASE do read the posting guide http://www.R-project.org/
>> >> >>>>> posting-guide.html
>> >> >>>>> and provide commented, minimal, self-contained, reproducible
>code.
>> >> >>>>>
>> >> >>>>>
>> >> >>>>         [[alternative HTML version deleted]]
>> >> >>>>
>> >> >>>> ______________________________________________
>> >> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>> PLEASE do read the posting guide
>http://www.R-project.org/posti
>> >> >>>> ng-guide.html
>> >> >>>> and provide commented, minimal, self-contained, reproducible
>code.
>> >> >>>>
>> >> >>>>
>> >> >>>
>> >> >>
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >
>> >
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Feb 25 20:20:24 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 25 Feb 2018 20:20:24 +0100
Subject: [R] reshaping column items into rows per unique ID
In-Reply-To: <CAGgJW74QTJ_So_sBSOpWXVBJdr0SuwN4YUyus1DngKGwkPuRHw@mail.gmail.com>
References: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>
 <CAGxFJbRV5nz4AhL+z3WvM9+OM2LG8xoMRcBM9efrXoG5QvAbRw@mail.gmail.com>
 <CAGgJW74QTJ_So_sBSOpWXVBJdr0SuwN4YUyus1DngKGwkPuRHw@mail.gmail.com>
Message-ID: <36EF594D-EE8F-485C-8187-6706711F9615@gmail.com>

It depends quite strongly on what you want to do with the result, but I wonder if what is really needed might be a list of diettypes per person, i.e. continuing from Eric's code

> On 25 Feb 2018, at 18:56 , Eric Berger <ericjberger at gmail.com> wrote:
> 
> Hi Allaisone,
> I took a slightly different approach but you might find this either as or
> more useful than your approach, or at least a start on the path to a
> solution you need.
> 
> df1   <-
> data.frame(CustId=c(1,1,1,2,3,3,4,4,4),DietType=c("a","c","b","f","a","j","c","c","f"),
>                    stringsAsFactors=FALSE)

> with(df1, tapply(DietType, CustId, list))
$`1`
[1] "a" "c" "b"

$`2`
[1] "f"

$`3`
[1] "a" "j"

$`4`
[1] "c" "c" "f"

or maybe get rid of duplicates with

> with(df1, tapply(DietType, CustId, unique))
$`1`
[1] "a" "c" "b"

$`2`
[1] "f"

$`3`
[1] "a" "j"

$`4`
[1] "c" "f"



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From valkremk at gmail.com  Sun Feb 25 20:36:55 2018
From: valkremk at gmail.com (Val)
Date: Sun, 25 Feb 2018 13:36:55 -0600
Subject: [R] include
In-Reply-To: <99F8E30F-F9DA-4C3B-AF25-0718D445D8FE@dcn.davis.ca.us>
References: <CAJOiR6ZZkZssZr-MJ2U8=jPgg0dogZ3S-5ify4rVAaUfYpMsyQ@mail.gmail.com>
 <CA+8X3fU7jAwrXsfgEhhQjw72vA5jYNaLBUqkR1zLc1ohS2=RLQ@mail.gmail.com>
 <CAJOiR6ZVoQVDaxmP5RYrY8N3B6s7nCoYXeP5ZZeM+wu_3_2SPg@mail.gmail.com>
 <CAF8bMcY_nKBFeg28Qb-s-0dRvb2zT--n98BWcV0azNsZN7pQMg@mail.gmail.com>
 <b94d2344-eab1-61b5-9808-2d3fc2b14a0a@gmail.com>
 <CAJOiR6am6s_tS=0M6WmzJv=gaF2Om+P23QFnvZCRcTCWu_k=XA@mail.gmail.com>
 <CAJOiR6YRU+W+g+hDEXZK1G1eYCYhWnO8CObJitcTehyit7fcKQ@mail.gmail.com>
 <CA+8X3fV7ppkrKeCmf7rRBDg8fQZ5ZU3KPSeExeKj9z1fkCSoLg@mail.gmail.com>
 <CAJOiR6aJ-idxVQLx2hrUxmNC3Z81VAxJSSsF6ZtSbreTVgsbyw@mail.gmail.com>
 <CA+8X3fV_oAr-1xTzBxZqXd830dsw6Qe3JSmFTeyUmaZge1ciZQ@mail.gmail.com>
 <CAJOiR6Z_DofV1ugP88gHqQyrN2Ah2Tg+fT4eyFJ0Mmxr_tphog@mail.gmail.com>
 <99F8E30F-F9DA-4C3B-AF25-0718D445D8FE@dcn.davis.ca.us>
Message-ID: <CAJOiR6bFin_dzwGHMoy4D5-v3bX5mig1Arx_=JeUmVrrSq9-XQ@mail.gmail.com>

Thank you all for your help and sorry for that.

On Sun, Feb 25, 2018 at 12:18 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Jim has been exceedingly patient (and may well continue to be so), but
> this smells like "failure to launch". At what point will you start showing
> your (failed) attempts at solving your own problems so we can help you work
> on your specific weaknesses and become self-sufficient?
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 25, 2018 7:55:55 AM PST, Val <valkremk at gmail.com> wrote:
> >HI Jim and all,
> >
> >I want to put one more condition.   Include col2 and col3 if they are
> >not
> >in col1.
> >
> >Here is the data
> >mydat <- read.table(textConnection("Col1 Col2 col3
> >K2 X1 NA
> >Z1 K1 K2
> >Z2 NA NA
> >Z3 X1 NA
> >Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> >
> >The desired out put would be
> >
> >  Col1 Col2 col3
> >1    X1    0    0
> >2    K1    0    0
> >3    Y1    0    0
> >4    W1    0    0
> >6    K2   X1    0
> >7    Z1   K1   K2
> >8    Z2    0    0
> >9    Z3   X1    0
> >10   Z4   Y1   W1
> >
> >K2 is already is already in col1 and should not be added.
> >
> >Thank you in advance
> >
> >
> >
> >
> >
> >
> >
> >On Sat, Feb 24, 2018 at 6:38 PM, Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >
> >> Hi Val,
> >> My fault - I assumed that the NA would be first in the result
> >produced
> >> by "unique":
> >>
> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> Z1 K1 K2
> >> Z2 NA NA
> >> Z3 X1 NA
> >> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> >> val23<-unique(unlist(mydat[,c("Col2","col3")]))
> >> napos<-which(is.na(val23))
> >> preval<-data.frame(Col1=val23[-napos],
> >>  Col2=NA,col3=NA)
> >> mydat<-rbind(preval,mydat)
> >> mydat[is.na(mydat)]<-"0"
> >> mydat
> >>
> >> Jim
> >>
> >> On Sun, Feb 25, 2018 at 11:27 AM, Val <valkremk at gmail.com> wrote:
> >> > Thank you Jim,
> >> >
> >> > I read the data as you suggested but I could not find K1 in   col1.
> >> >
> >> > rbind(preval,mydat)
> >> >   Col1 Col2 col3
> >> > 1 <NA> <NA> <NA>
> >> > 2   X1 <NA> <NA>
> >> > 3   Y1 <NA> <NA>
> >> > 4   K2 <NA> <NA>
> >> > 5   W1 <NA> <NA>
> >> > 6   Z1   K1   K2
> >> > 7   Z2 <NA> <NA>
> >> > 8   Z3   X1 <NA>
> >> > 9   Z4   Y1   W1
> >> >
> >> >
> >> >
> >> > On Sat, Feb 24, 2018 at 6:18 PM, Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >> >>
> >> >> hi Val,
> >> >> Your problem seems to be that the data are read in as a factor.
> >The
> >> >> simplest way I can think of to get around this is:
> >> >>
> >> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> >> Z1 K1 K2
> >> >> Z2 NA NA
> >> >> Z3 X1 NA
> >> >> Z4 Y1 W1"),header = TRUE,stringsAsFactors=FALSE)
> >> >>
> >preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >> >>  Col2=NA,col3=NA)
> >> >> rbind(preval,mydat)
> >> >> mydat[is.na(mydat)]<-"0"
> >> >>
> >> >> Jiim
> >> >>
> >> >>
> >> >> On Sun, Feb 25, 2018 at 11:05 AM, Val <valkremk at gmail.com> wrote:
> >> >> > Sorry , I hit the send key accidentally  here is my complete
> >message.
> >> >> >
> >> >> > Thank you Jim   and all, I got it.
> >> >> >
> >> >> > I have one more question on the original question
> >> >> >
> >> >> >  What does this  "[-1] "  do?
> >> >> >
> >preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >> >> >                    Col2=NA,col3=NA)
> >> >> >
> >> >> >
> >> >> > mydat <- read.table(textConnection("Col1 Col2 col3
> >> >> > Z1 K1 K2
> >> >> > Z2 NA NA
> >> >> > Z3 X1 NA
> >> >> > Z4 Y1 W1"),header = TRUE)
> >> >> >
> >> >> >
> >preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2","col3")]))[-1],
> >> >> >                    Col2=NA,col3=NA)
> >> >> > rbind(unique(preval),mydat)
> >> >> >
> >> >> >
> >> >> >  Col1 Col2 col3
> >> >> > 1 <NA> <NA> <NA>
> >> >> > 2   X1 <NA> <NA>
> >> >> > 3   Y1 <NA> <NA>
> >> >> > 4   K2 <NA> <NA>
> >> >> > 5   W1 <NA> <NA>
> >> >> > 6   Z1   K1   K2
> >> >> > 7   Z2 <NA> <NA>
> >> >> > 8   Z3   X1 <NA>
> >> >> > 9   Z4   Y1   W1
> >> >> >
> >> >> > I could not find K1 in the first   col1. Is that possible to fix
> >this?
> >> >> >
> >> >> > On Sat, Feb 24, 2018 at 5:59 PM, Val <valkremk at gmail.com> wrote:
> >> >> >
> >> >> >> Thank you Jim   and all, I got it.
> >> >> >>
> >> >> >> I have one more question on the original question
> >> >> >>
> >> >> >>  What does this  "[-1] "  do?
> >> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> >> "col3")]))[-1],
> >> >> >>                    Col2=NA,col3=NA)
> >> >> >>
> >> >> >>
> >> >> >> mydat <- read.table(textConnection("Col1 Col2 col3
> >> >> >> Z1 K1 K2
> >> >> >> Z2 NA NA
> >> >> >> Z3 X1 NA
> >> >> >> Z4 Y1 W1"),header = TRUE)
> >> >> >>
> >> >> >> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> >> "col3")]))[-1],
> >> >> >>                    Col2=NA,col3=NA)
> >> >> >> rbind(unique(preval),mydat)
> >> >> >>
> >> >> >>
> >> >> >>  Col1 Col2 col3
> >> >> >> 1 <NA> <NA> <NA>
> >> >> >> 2   X1 <NA> <NA>
> >> >> >> 3   Y1 <NA> <NA>
> >> >> >> 4   K2 <NA> <NA>
> >> >> >> 5   W1 <NA> <NA>
> >> >> >> 6   Z1   K1   K2
> >> >> >> 7   Z2 <NA> <NA>
> >> >> >> 8   Z3   X1 <NA>
> >> >> >> 9   Z4   Y1   W1
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >>
> >> >> >> On Sat, Feb 24, 2018 at 5:04 PM, Duncan Murdoch
> >> >> >> <murdoch.duncan at gmail.com>
> >> >> >> wrote:
> >> >> >>
> >> >> >>> On 24/02/2018 1:53 PM, William Dunlap via R-help wrote:
> >> >> >>>
> >> >> >>>>     x1 =  rbind(unique(preval),mydat)
> >> >> >>>>    x2 <- x1[is.na(x1)] <- 0
> >> >> >>>>    x2  # gives 0
> >> >> >>>>
> >> >> >>>> Why introduce the 'x2'?   x1[...] <- 0 alters x1 in place and
> >I
> >> think
> >> >> >>>> that
> >> >> >>>> altered x1 is what you want.
> >> >> >>>>
> >> >> >>>> You asked why x2 was zero.  The value of the expression
> >> >> >>>>     f(a) <- b
> >> >> >>>> and assignments are processed right to left so
> >> >> >>>>     x2 <- x[!is.na(x1)] <- 0
> >> >> >>>> is equivalent to
> >> >> >>>>     x[!is.na(x1)] <- 0
> >> >> >>>>     x2 <- 0
> >> >> >>>>
> >> >> >>>
> >> >> >>> That's not right in general, is it?  I'd think that should be
> >> >> >>>
> >> >> >>>     x[!is.na(x1)] <- 0
> >> >> >>>     x2 <- x1
> >> >> >>>
> >> >> >>> Of course, in this example, x1 is 0, so it gives the same
> >answer.
> >> >> >>>
> >> >> >>> Duncan Murdoch
> >> >> >>>
> >> >> >>>
> >> >> >>>
> >> >> >>>>
> >> >> >>>> Bill Dunlap
> >> >> >>>> TIBCO Software
> >> >> >>>> wdunlap tibco.com
> >> >> >>>>
> >> >> >>>> On Sat, Feb 24, 2018 at 9:59 AM, Val <valkremk at gmail.com>
> >wrote:
> >> >> >>>>
> >> >> >>>> Thank you Jim
> >> >> >>>>>
> >> >> >>>>> I wanted a final data frame  after replacing the NA's to "0"
> >> >> >>>>>
> >> >> >>>>> x1 =  rbind(unique(preval),mydat)
> >> >> >>>>> x2 <- x1[is.na(x1)] <- 0
> >> >> >>>>> x2
> >> >> >>>>>   but I got this,
> >> >> >>>>>
> >> >> >>>>> [1] 0
> >> >> >>>>>
> >> >> >>>>> why I am getting this?
> >> >> >>>>>
> >> >> >>>>>
> >> >> >>>>> On Sat, Feb 24, 2018 at 12:17 AM, Jim Lemon
> ><drjimlemon at gmail.com
> >> >
> >> >> >>>>> wrote:
> >> >> >>>>>
> >> >> >>>>> Hi Val,
> >> >> >>>>>> Try this:
> >> >> >>>>>>
> >> >> >>>>>>
> >> >> >>>>>> preval<-data.frame(Col1=unique(unlist(mydat[,c("Col2",
> >> "col3")]))[-1],
> >> >> >>>>>>   Col2=NA,col3=NA)
> >> >> >>>>>> rbind(preval,mydat)
> >> >> >>>>>>
> >> >> >>>>>> Jim
> >> >> >>>>>>
> >> >> >>>>>> On Sat, Feb 24, 2018 at 3:34 PM, Val <valkremk at gmail.com>
> >wrote:
> >> >> >>>>>>
> >> >> >>>>>>> Hi All,
> >> >> >>>>>>>
> >> >> >>>>>>> I am reading a file as follow,
> >> >> >>>>>>>
> >> >> >>>>>>> mydat <- read.table(textConnection("Col1 Col2 col3
> >> >> >>>>>>> Z2 NA NA
> >> >> >>>>>>> Z3 X1 NA
> >> >> >>>>>>> Z4 Y1 W1"),header = TRUE)
> >> >> >>>>>>>
> >> >> >>>>>>> 1. "NA" are   missing  should be replace by 0
> >> >> >>>>>>> 2.  value that are in COl2 and Col3  should be included
> >in col1
> >> >> >>>>>>> before
> >> >> >>>>>>> they appear
> >> >> >>>>>>> in col2 and col3. So the output data looks like as follow,
> >> >> >>>>>>>
> >> >> >>>>>>> X1  0  0
> >> >> >>>>>>> Y1  0  0
> >> >> >>>>>>> W1  0  0
> >> >> >>>>>>> Z2  0  0
> >> >> >>>>>>> Z3 X1  0
> >> >> >>>>>>> Z4 Y1 W1
> >> >> >>>>>>>
> >> >> >>>>>>> Thank you in advance
> >> >> >>>>>>>
> >> >> >>>>>>>          [[alternative HTML version deleted]]
> >> >> >>>>>>>
> >> >> >>>>>>> ______________________________________________
> >> >> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more,
> >> see
> >> >> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >> >>>>>>>
> >> >> >>>>>> posting-guide.html
> >> >> >>>>>>
> >> >> >>>>>>> and provide commented, minimal, self-contained,
> >reproducible
> >> code.
> >> >> >>>>>>>
> >> >> >>>>>>
> >> >> >>>>>>
> >> >> >>>>>          [[alternative HTML version deleted]]
> >> >> >>>>>
> >> >> >>>>> ______________________________________________
> >> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more, see
> >> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >> >>>>> posting-guide.html
> >> >> >>>>> and provide commented, minimal, self-contained, reproducible
> >code.
> >> >> >>>>>
> >> >> >>>>>
> >> >> >>>>         [[alternative HTML version deleted]]
> >> >> >>>>
> >> >> >>>> ______________________________________________
> >> >> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >> >> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >>>> PLEASE do read the posting guide
> >http://www.R-project.org/posti
> >> >> >>>> ng-guide.html
> >> >> >>>> and provide commented, minimal, self-contained, reproducible
> >code.
> >> >> >>>>
> >> >> >>>>
> >> >> >>>
> >> >> >>
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible
> >code.
> >> >
> >> >
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Feb 25 22:48:51 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Feb 2018 08:48:51 +1100
Subject: [R] reshaping column items into rows per unique ID
In-Reply-To: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>
References: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fU1fRn2x9p4S9=5MdyBZqRDJKEJ6woC1uvyNccJUPYGWA@mail.gmail.com>

Hi Allaisone,
If you want a data frame as the output you will have to put up with a
few NA values unless each Customer has the same number of diet types:

a1df<-read.table(text="CustomerID    DietType
1                           a
1                            c
1                            b
2                            f
2                             a
3                             j
4                             c
4                             c
4                              f",
header=TRUE,stringsAsFactors=FALSE)
library(prettyR)
stretch_df(a1df,"CustomerID","DietType")
  CustomerID DietType_1 DietType_2 DietType_3
1          1          a          c          b
2          2          f          a       <NA>
3          3          j       <NA>       <NA>
4          4          c          c          f

Jim


On Sun, Feb 25, 2018 at 11:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> Hi All
>
> I have a datafram which looks like this :
>
> CustomerID    DietType
> 1                           a
> 1                            c
> 1                            b
> 2                            f
> 2                             a
> 3                             j
> 4                             c
> 4                             c
> 4                              f
>
> And I would like to reshape this so I can see the list of DietTypes per customer in rows instead of columns like this :
>
>> MyDf
> CustomerID      DietType   DietType  DietType
> 1                                a            c               b
> 2                                 f             a
> 3                                 j
> 4                                 c              c             f
>
> I tried many times using melt(),spread (),and dcast () functions but was not able to produce the desired table. The best attempt was by typing :
>
> # 1) Adding new column with unique values:
> MyDf $newcol <- c (1:9)
> #2) then :
> NewDf <- dcast (MyDf,CustomerID~newcol,value.var=DietType)
>
> This produces the desired table but with many NA values like this :
>
> CustomerID    1   2   3    4     5    6     7   8   9
> 1                    a  c    b   NA NA NA NA NA NA
> 2                  NA NA NA  f     a  NA NA NA NA
> 3                  NA NA NA NA NA  j   NA NA NA
> 4                  NA NA NA NA NA NA c     c     f
>
>   As you see, the lette/s indicating DietType move to the right side each time we move down leaving many NA values and as my original files is very large, I expect that the final output would contain around 800,000 columns and 70,000 rows. This is why my code works with small data but does not work with my large file because of memory issue even though I'm using large PC.
>
> What changes I need to do with my code to produce the desired table where the list of DietTypes are grouped in rows exactly like the second table shown abover?
>
> Regards
> Allaisnoe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulaveronica at gmail.com  Mon Feb 26 02:07:24 2018
From: paulaveronica at gmail.com (Paula Couto)
Date: Sun, 25 Feb 2018 20:07:24 -0500
Subject: [R] glm package - Negative binomial regression model - Error
Message-ID: <CAJqhdO7CN0pue=pb=k+ChDds9-wX1F5eMewr8sor9rMU7m=BsA@mail.gmail.com>

HI there

I am running this model in negative binomial regression, using glm.
I had no problems with running the model with a set of data, but now that
i'm trying to run if for new one.  I always have this same error when
running the regression:

>
> #Run Regression
>     x=cbind(factor2ind(d$year),factor2ind(d$month_week))
>
>     out<- glm(cbind(influenza, n_sample) ~ x, family=quasibinomial,
> data=d)
>
>     d$prop<-out$fitted.values

Error in `$<-.data.frame`(`*tmp*`, prop, value = c(0.0486530542835839,  :
  replacement has 208 rows, data has 365

>     d$n_p1<-d$prop*d$factor*10
>
>     obs<-aggregate(d$prop, by = list(d$month_week), FUN=summary)
>     pred<-aggregate(d$n_p1, by = list(d$month_week), FUN=summary)
>

By the way, I previously prepared the data set  and defined that:
       d$factor<-sapply(d$year,f)
>         d$n_sample<-(d$n_muestras*d$factor*10)
>         d$prop<-(d$influenza/d$n_sample)

But I still don't understand why it keeps saying that dataframe has less
replacements than rows.
Could anybody help me with this?
 Many thankss!!!
P

	[[alternative HTML version deleted]]


From iuri at proxima.adm.br  Mon Feb 26 02:34:23 2018
From: iuri at proxima.adm.br (Iuri Gavronski)
Date: Sun, 25 Feb 2018 20:34:23 -0500
Subject: [R] Precision in R
Message-ID: <CA+YqJQDLoT3Knb1F9GCCPe5Vg-xkb3+jFVSGYUYOPUbbAY4hHQ@mail.gmail.com>

Hi,

Why sum() on a 10-item vector produces a different value than its
counterpart on a 2-item vector? I understand the problems related to
the arithmetic precision in storing decimal numbers in binary format,
but shouldn't the errors be equal regardless of the method used?

See my example:

> options(digits=22)
> x=rep(.1,10)
> x
 [1] 0.10000000000000001 0.10000000000000001 0.10000000000000001
 [4] 0.10000000000000001 0.10000000000000001 0.10000000000000001
 [7] 0.10000000000000001 0.10000000000000001 0.10000000000000001
[10] 0.10000000000000001
> sum(x)
[1] 1
> y=0
> for (i in 1:10) {y=sum(y+x[i])}
> y
[1] 0.99999999999999989
> y*10^6
[1] 999999.99999999988
> sum(x)*10^6
[1] 1e+06
> z=.1+.1+.1+.1+.1+.1+.1+.1+.1+.1
> z
[1] 0.99999999999999989
>


From jdnewmil at dcn.davis.ca.us  Mon Feb 26 09:21:12 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 26 Feb 2018 00:21:12 -0800 (PST)
Subject: [R] Precision in R
In-Reply-To: <CA+YqJQDLoT3Knb1F9GCCPe5Vg-xkb3+jFVSGYUYOPUbbAY4hHQ@mail.gmail.com>
References: <CA+YqJQDLoT3Knb1F9GCCPe5Vg-xkb3+jFVSGYUYOPUbbAY4hHQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1802252320250.59281@pedal.dcn.davis.ca.us>

On Sun, 25 Feb 2018, Iuri Gavronski wrote:

> Hi,
>
> Why sum() on a 10-item vector produces a different value than its
> counterpart on a 2-item vector? I understand the problems related to
> the arithmetic precision in storing decimal numbers in binary format,
> but shouldn't the errors be equal regardless of the method used?

Since you understand the problems, why are you asking? More to the point, 
why are you asking as if this was a property of R rather than a property 
of all typical IEEE754 floating point implementations?

For others Googling this: short answer is don't make your program behavior 
depend on the least significant digits... they are not reliable. Read 
about the difference between double precision (53 bits or about 15 digits 
[1]) and extended precision (63 bits or about 18 digits for Intel math 
coprocessors [2]) and ask questions about this topic in an appropriate 
forum (e.g. [3]) since this issue can crop up in practically any 
programming language.

> See my example:

Examples are good. Diving into numerical analysis theory not so much.

>> options(digits=22)

Don't be misleading... you are not going to get 22digits with standard 
numeric types. Note that you get 17 digits below, and two of those are 
artifacts pulled from the artificially-expanded extended-precision values 
in the coprocessor... the numbers in memory are not that precise. The best 
that can be said for using 17digit printed values is that you have the 
best shot at being able to reproduce the actual 15 digits of double 
precision in a different program or instance of R if you keep them.

>> x=rep(.1,10)
>> x
> [1] 0.10000000000000001 0.10000000000000001 0.10000000000000001
> [4] 0.10000000000000001 0.10000000000000001 0.10000000000000001
> [7] 0.10000000000000001 0.10000000000000001 0.10000000000000001
> [10] 0.10000000000000001

Sitting in memory (not extended precision!)

>> sum(x)
> [1] 1

sum() is vectorized (compact compiled C code)... the intermediate values 
can stay in the coprocessor at extended precision. Only the result is 
trimmed back to double precision.

>> y=0
>> for (i in 1:10) {y=sum(y+x[i])}

Why are you calling the sum function on a scalar value? The addition has 
already taken place...

The actual intermediate values in this for loop get stored in RAM at 
double precision and get re-expanded to extended precision each time 
an addition occurs and then rounded again when the addition is done.
That is a lot of rounding compared to the sum function.

>> y
> [1] 0.99999999999999989
>> y*10^6
> [1] 999999.99999999988

Note that 10 = 2*5 = b'0010' * b'0101' is not just a power of 2 so both 
the binary mantissa and binary exponent are getting modified when you 
multiply by powers of 10, so the rounding may be different for various 
powers of 10.

>> sum(x)*10^6
> [1] 1e+06
>> z=.1+.1+.1+.1+.1+.1+.1+.1+.1+.1

More double precision.

>> z
> [1] 0.99999999999999989

Similar to for loop.

Don't rely on the last few digits to be stable. Take a course in numerical 
analysis if you just cannot take my word for it that those last few digits 
are going wander off a bit no matter what you do.

[1] https://en.wikipedia.org/wiki/IEEE_754
[2] https://en.wikipedia.org/wiki/Extended_precision
[3] https://cs.stackexchange.com/search?q=ieee+754

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From thierry.onkelinx at inbo.be  Mon Feb 26 09:02:18 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 26 Feb 2018 09:02:18 +0100
Subject: [R] glm package - Negative binomial regression model - Error
In-Reply-To: <CAJqhdO7CN0pue=pb=k+ChDds9-wX1F5eMewr8sor9rMU7m=BsA@mail.gmail.com>
References: <CAJqhdO7CN0pue=pb=k+ChDds9-wX1F5eMewr8sor9rMU7m=BsA@mail.gmail.com>
Message-ID: <CAJuCY5xg8ryw6FhXvvogLOTu259mP0UsUze-Df=gF6=HEnz3hw@mail.gmail.com>

Dear Paula,

There are probably missing observations in your data set. Read the
na.action part of the glm help file. na.exclude is most likely what you are
looking for.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-02-26 2:07 GMT+01:00 Paula Couto <paulaveronica at gmail.com>:

> HI there
>
> I am running this model in negative binomial regression, using glm.
> I had no problems with running the model with a set of data, but now that
> i'm trying to run if for new one.  I always have this same error when
> running the regression:
>
> >
> > #Run Regression
> >     x=cbind(factor2ind(d$year),factor2ind(d$month_week))
> >
> >     out<- glm(cbind(influenza, n_sample) ~ x, family=quasibinomial,
> > data=d)
> >
> >     d$prop<-out$fitted.values
>
> Error in `$<-.data.frame`(`*tmp*`, prop, value = c(0.0486530542835839,  :
>   replacement has 208 rows, data has 365
>
> >     d$n_p1<-d$prop*d$factor*10
> >
> >     obs<-aggregate(d$prop, by = list(d$month_week), FUN=summary)
> >     pred<-aggregate(d$n_p1, by = list(d$month_week), FUN=summary)
> >
>
> By the way, I previously prepared the data set  and defined that:
>        d$factor<-sapply(d$year,f)
> >         d$n_sample<-(d$n_muestras*d$factor*10)
> >         d$prop<-(d$influenza/d$n_sample)
>
> But I still don't understand why it keeps saying that dataframe has less
> replacements than rows.
> Could anybody help me with this?
>  Many thankss!!!
> P
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Feb 26 09:06:00 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 26 Feb 2018 09:06:00 +0100
Subject: [R] Precision in R
In-Reply-To: <CA+YqJQDLoT3Knb1F9GCCPe5Vg-xkb3+jFVSGYUYOPUbbAY4hHQ@mail.gmail.com>
References: <CA+YqJQDLoT3Knb1F9GCCPe5Vg-xkb3+jFVSGYUYOPUbbAY4hHQ@mail.gmail.com>
Message-ID: <CAJuCY5wRoMrnS8Dk7shdGtfqt_1FQTPVh8teDJJiyR5_S7HL7w@mail.gmail.com>

This is described in R FAQ 7.31


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-02-26 2:34 GMT+01:00 Iuri Gavronski <iuri at proxima.adm.br>:

> Hi,
>
> Why sum() on a 10-item vector produces a different value than its
> counterpart on a 2-item vector? I understand the problems related to
> the arithmetic precision in storing decimal numbers in binary format,
> but shouldn't the errors be equal regardless of the method used?
>
> See my example:
>
> > options(digits=22)
> > x=rep(.1,10)
> > x
>  [1] 0.10000000000000001 0.10000000000000001 0.10000000000000001
>  [4] 0.10000000000000001 0.10000000000000001 0.10000000000000001
>  [7] 0.10000000000000001 0.10000000000000001 0.10000000000000001
> [10] 0.10000000000000001
> > sum(x)
> [1] 1
> > y=0
> > for (i in 1:10) {y=sum(y+x[i])}
> > y
> [1] 0.99999999999999989
> > y*10^6
> [1] 999999.99999999988
> > sum(x)*10^6
> [1] 1e+06
> > z=.1+.1+.1+.1+.1+.1+.1+.1+.1+.1
> > z
> [1] 0.99999999999999989
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From faiz7r at gmail.com  Mon Feb 26 12:30:22 2018
From: faiz7r at gmail.com (faiz rasool)
Date: Mon, 26 Feb 2018 16:30:22 +0500
Subject: [R] questions about performing Robust multiple regression using
 bootstrap
Message-ID: <CAFhDWBVSzM+NTvkrk9FFvNjmxqFMT3bp-GKLw0e=B1qnh3g6wA@mail.gmail.com>

Dear list,

I am slightly confused about how I  can do the following in R.

I want to  perform   robust multiple regression. I?ve used the Boot
function in CAR package to find confidence intervals and standard
errors. Inadition to these, I want to find the  robust estimates  for
the F test and  r-square. Finally, I  would like to know the
significance levels of bootstrap results.

Below I  explain my question  using commented R code.

[1] reg=lm(a~b+c+d+e) # perform multiple regression.
[2] library(car) #load the car package.
[3] bootstrap=Boot(reg) #perform bootstrap using the Boot function in
car package.
[4] summary(bootstrap) #show the results of bootstrap.
[5]now  I would like to type a code that can give me robust
estimates  of R-square, F tests, and  significance  levels for
coefficients and f.


Thanks for any help.

Regards,
Faiz.


From S.Ellison at LGCGroup.com  Mon Feb 26 12:56:39 2018
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 26 Feb 2018 11:56:39 +0000
Subject: [R] alternative for multiple if_else statements
In-Reply-To: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
References: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
Message-ID: <1A8C1289955EF649A09086A153E267240C428838B2@GBTEDVPEXCMB04.corp.lgc-group.com>

That many ifelse statements is obviously rather a pain.

Would you not have got what you want with 

... paste("survey", year, sep="_") 
?

If that is not what you're looking for (eg because 'year' is the observation year and not the study start year), perhaps something that picks the minimum year for a subject or other relevant group might work? For example
paste("survey", ave(year, studyno, FUN=min), sep="_")


S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kevin
> Wamae
> Sent: 21 February 2018 20:34
> To: R-help at r-project.org
> Subject: [R] alternative for multiple if_else statements
> 
> Hi, I am having trouble trying to figure out why if_else is behaving the way it is,
> it may be my code or the way the data is structured.
> 
> Below is a snapshot of a database am working on and it represents a
> longitudinal survey of study participants in a trial with weekly follow up.
> 
> The variable "survey_start" represents the start of the study-defined one year
> follow up (which we called "survey_year").
> 
> I am trying to populate all subsequent entries for each participant, per survey
> year, with the entry "survey" followed by an underscore and the respective
> year, eg. survey_2014.
> 
> There are missing entries such as the participant represented here, wasn't
> available at the start of the 2015 survey. Also, some participants don?t have
> complete one-year follow ups but I still need to include them.
> 
> I have written two codes, first one fails while the second works, the only
> difference being I have reversed the order in which the entries are populated in
> the second code (from 2007-2016 to 2016-2007) and removed the if_else
> statement for 2015. Also noticed, that for the second code, which spans the
> years 2007-2016 (less 2015), if a participants entries start from 2010-2016, the
> code fails.
> 
> Kindly assist in figuring this out...or better yet, an alternative.
> 
>     trialData <- structure(list(study = c("site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
> "site_1"), studyno = c("child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
> "child_1"), date = structure(c(16078, 16085, 16092, 16098, 16104, 16115,
> 16121, 16129, 16135, 16140, 16146, 16156, 16162, 16168, 16177, 16185,
> 16191, 16195, 16203, 16210, 16217, 16225, 16234, 16237, 16246, 16253,
> 16262, 16269, 16278, 16283, 16288, 16297, 16304, 16311, 16319, 16326,
> 16332, 16337, 16346, 16353, 16360, 16366, 16370, 16381, 16384, 16395,
> 16399, 16407, 16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477,
> 16484, 16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
> 16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613, 16620,
> 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681, 16688, 16693,
> 16702, 16706, 16714, 16721, 16728, 16734, 16745, 16749, 16757, 16764,
> 16769, 16778, 16785, 16792, 16805, 16812, 16819, 16830, 16832, 16839,
> 16846, 16856, 16862, 16867, 16877, 16884, 16890, 16898, 16904, 16912,
> 16917, 16923, 16936, 16938, 16953, 16960, 16966, 16973, 16980), class =
> "Date"), year = c(2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
> 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L, 1L, 1L, 1L, 2L,
> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L,
> 7L, 7L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L,
> 11L, 12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L,
> 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L), survey_start =
> c("", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
> "", "", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "", "", "", "", "", "", "")), class =
> "data.frame", row.names = c(NA, -125L), .Names = c("study", "studyno", "date",
> "year", "month",
> "survey_start"))
> 
> 
> code 1 fails:
> 
> trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
> mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2007
> & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study ==
> "site_1"][1], "survey_2007",
>                      if_else(date >= date[survey_start == "Y" & year == 2008 & study
> == "site_1"][1] & date < date[month == 4 & year == 2009 & study ==
> "site_1"][1], "survey_2008",
>                      if_else(date >= date[survey_start == "Y" & year == 2009 & study
> == "site_1"][1] & date < date[month == 5 & year == 2010 & study ==
> "site_1"][1], "survey_2009",
>                      if_else(date >= date[survey_start == "Y" & year == 2010 & study
> == "site_1"][1] & date < date[month == 5 & year == 2011 & study ==
> "site_1"][1], "survey_2010",
>                      if_else(date >= date[survey_start == "Y" & year == 2011 & study
> == "site_1"][1] & date < date[month == 4 & year == 2012 & study ==
> "site_1"][1], "survey_2011",
>                      if_else(date >= date[survey_start == "Y" & year == 2012 & study
> == "site_1"][1] & date < date[month == 4 & year == 2013 & study ==
> "site_1"][1], "survey_2012",
>                      if_else(date >= date[survey_start == "Y" & year == 2013 & study
> == "site_1"][1] & date < date[month == 4 & year == 2014 & study ==
> "site_1"][1], "survey_2013",
>                      if_else(date >= date[survey_start == "Y" & year == 2014 & study
> == "site_1"][1] & date < date[month == 4 & year == 2015 & study ==
> "site_1"][1], "survey_2014",
>                      if_else(date >= date[survey_start == "Y" & year == 2015 & study
> == "site_1"][1] & date < date[month == 3 & year == 2016 & study ==
> "site_1"][1], "survey_2015",
>                      if_else(date >= date[survey_start == "Y" & year == 2016 & study
> == "site_1"][1], "survey_2016","")))))))))))
> 
> code 2 works:
> 
>     trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno)
> %>%
>   mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2016
> & study == "site_1"][1]                                                               , "survey_2016",
>                            if_else(date >= date[survey_start == "Y" & year == 2014 &
> study == "site_1"][1] & date < date[month == 4 & year == 2015 & study ==
> "site_1"][1], "survey_2014",
>                            if_else(date >= date[survey_start == "Y" & year == 2013 &
> study == "site_1"][1] & date < date[month == 4 & year == 2014 & study ==
> "site_1"][1], "survey_2013",
>                            if_else(date >= date[survey_start == "Y" & year == 2012 &
> study == "site_1"][1] & date < date[month == 4 & year == 2013 & study ==
> "site_1"][1], "survey_2012",
>                            if_else(date >= date[survey_start == "Y" & year == 2011 &
> study == "site_1"][1] & date < date[month == 4 & year == 2012 & study ==
> "site_1"][1], "survey_2011",
>                            if_else(date >= date[survey_start == "Y" & year == 2010 &
> study == "site_1"][1] & date < date[month == 5 & year == 2011 & study ==
> "site_1"][1], "survey_2010",
>                            if_else(date >= date[survey_start == "Y" & year == 2009 &
> study == "site_1"][1] & date < date[month == 5 & year == 2010 & study ==
> "site_1"][1], "survey_2009",
>                            if_else(date >= date[survey_start == "Y" & year == 2008 &
> study == "site_1"][1] & date < date[month == 4 & year == 2009 & study ==
> "site_1"][1], "survey_2008",
>                            if_else(date >= date[survey_start == "Y" & year == 2007 &
> study == "site_1"][1] & date < date[month == 5 & year == 2008 & study ==
> "site_1"][1], "survey_2007",""))))))))))
> 
> ________________________________________________________________
> ______
> 
> This e-mail contains information which is confidential. It is intended only for the
> use of the named recipient. If you have received this e-mail in error, please let
> us know by replying to the sender, and immediately delete it from your system.
> Please note, that in these circumstances, the use, disclosure, distribution or
> copying of this information is strictly prohibited. KEMRI-Wellcome Trust
> Programme cannot accept any responsibility for the  accuracy or completeness
> of this message as it has been transmitted over a public network. Although the
> Programme has taken reasonable precautions to ensure no viruses are present
> in emails, it cannot accept responsibility for any loss or damage arising from
> the use of the email or attachments. Any views expressed in this message are
> those of the individual sender, except where the sender specifically states them
> to be the views of KEMRI-Wellcome Trust Programme.
> ________________________________________________________________
> ______
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From audun at symplur.com  Fri Feb 23 00:21:03 2018
From: audun at symplur.com (Audun Utengen)
Date: Thu, 22 Feb 2018 15:21:03 -0800
Subject: [R] [R-pkgs] SympluR - Analyze Healthcare Social Media Data from
 the Symplur API
Message-ID: <43F57463-A7D2-43F0-8868-FB238911E01F@symplur.com>

Hi all, 

Just launched a new R package - SympluR! 

It allows you to analyze data from the Healthcare Social Graph via access to the Symplur API.

- The Healthcare Social Graph contains billions of healthcare social media data points. Hundreds of published journal articles have leveraged data from the Healthcare Social Graph. More about Symplur research: https://www.symplur.com/healthcare-social-media-research <https://www.symplur.com/healthcare-social-media-research>
- Credit to Professor Larry Chu, MD at Stanford University School of Medicine for the idea of the 'SympluR' package.

CRAN: https://cran.r-project.org/package=SympluR <https://cran.r-project.org/package=SympluR>
GitHub: https://github.com/symplur/SympluR <https://github.com/symplur/SympluR>


Best,

Audun Utengen
@audvin
https://www.symplur.com


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From KWamae at kemri-wellcome.org  Mon Feb 26 14:12:46 2018
From: KWamae at kemri-wellcome.org (Kevin Wamae)
Date: Mon, 26 Feb 2018 13:12:46 +0000
Subject: [R] alternative for multiple if_else statements
In-Reply-To: <1A8C1289955EF649A09086A153E267240C428838B2@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <C894EDB6-954E-4887-8FB7-3FEDE86FBF81@contoso.com>
 <1A8C1289955EF649A09086A153E267240C428838B2@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <472AF7BA-382C-49C6-9EED-D5014166C473@kemri-wellcome.org>

Dear Ellison, thank you for the feedback, we replaced dplyr::if_else with dplyr::case_when and it seems to do the trick.

Still, we have to write several statements to match all the respective years but it's working.

Let me see how we can implement your suggestion.

Regards
------------------
Kevin Wamae
?On 26/02/2018, 14:57, "S Ellison" <S.Ellison at LGCGroup.com> wrote:

    That many ifelse statements is obviously rather a pain.
    
    Would you not have got what you want with 
    
    ... paste("survey", year, sep="_") 
    ?
    
    If that is not what you're looking for (eg because 'year' is the observation year and not the study start year), perhaps something that picks the minimum year for a subject or other relevant group might work? For example
    paste("survey", ave(year, studyno, FUN=min), sep="_")
    
    
    S Ellison
    
    > -----Original Message-----
    > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kevin
    > Wamae
    > Sent: 21 February 2018 20:34
    > To: R-help at r-project.org
    > Subject: [R] alternative for multiple if_else statements
    > 
    > Hi, I am having trouble trying to figure out why if_else is behaving the way it is,
    > it may be my code or the way the data is structured.
    > 
    > Below is a snapshot of a database am working on and it represents a
    > longitudinal survey of study participants in a trial with weekly follow up.
    > 
    > The variable "survey_start" represents the start of the study-defined one year
    > follow up (which we called "survey_year").
    > 
    > I am trying to populate all subsequent entries for each participant, per survey
    > year, with the entry "survey" followed by an underscore and the respective
    > year, eg. survey_2014.
    > 
    > There are missing entries such as the participant represented here, wasn't
    > available at the start of the 2015 survey. Also, some participants don?t have
    > complete one-year follow ups but I still need to include them.
    > 
    > I have written two codes, first one fails while the second works, the only
    > difference being I have reversed the order in which the entries are populated in
    > the second code (from 2007-2016 to 2016-2007) and removed the if_else
    > statement for 2015. Also noticed, that for the second code, which spans the
    > years 2007-2016 (less 2015), if a participants entries start from 2010-2016, the
    > code fails.
    > 
    > Kindly assist in figuring this out...or better yet, an alternative.
    > 
    >     trialData <- structure(list(study = c("site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1", "site_1",
    > "site_1"), studyno = c("child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1", "child_1", "child_1", "child_1", "child_1", "child_1", "child_1",
    > "child_1"), date = structure(c(16078, 16085, 16092, 16098, 16104, 16115,
    > 16121, 16129, 16135, 16140, 16146, 16156, 16162, 16168, 16177, 16185,
    > 16191, 16195, 16203, 16210, 16217, 16225, 16234, 16237, 16246, 16253,
    > 16262, 16269, 16278, 16283, 16288, 16297, 16304, 16311, 16319, 16326,
    > 16332, 16337, 16346, 16353, 16360, 16366, 16370, 16381, 16384, 16395,
    > 16399, 16407, 16415, 16422, 16444, 16452, 16454, 16467, 16474, 16477,
    > 16484, 16490, 16501, 16508, 16514, 16520, 16529, 16533, 16539, 16550,
    > 16556, 16564, 16566, 16578, 16582, 16593, 16599, 16604, 16613, 16620,
    > 16623, 16635, 16636, 16654, 16660, 16666, 16673, 16681, 16688, 16693,
    > 16702, 16706, 16714, 16721, 16728, 16734, 16745, 16749, 16757, 16764,
    > 16769, 16778, 16785, 16792, 16805, 16812, 16819, 16830, 16832, 16839,
    > 16846, 16856, 16862, 16867, 16877, 16884, 16890, 16898, 16904, 16912,
    > 16917, 16923, 16936, 16938, 16953, 16960, 16966, 16973, 16980), class =
    > "Date"), year = c(2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L,
    > 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2014L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
    > 2015L, 2015L, 2015L, 2015L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
    > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
    > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L), month = c(1L, 1L, 1L, 1L, 2L,
    > 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L,
    > 7L, 7L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L,
    > 11L, 12L, 12L, 12L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L,
    > 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 10L,
    > 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
    > 2L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L), survey_start =
    > c("", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "Y", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
    > "", "", "", "", "", "", "", "Y", "", "", "", "", "", "", "", "", "", "", "", "", "", "")), class =
    > "data.frame", row.names = c(NA, -125L), .Names = c("study", "studyno", "date",
    > "year", "month",
    > "survey_start"))
    > 
    > 
    > code 1 fails:
    > 
    > trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno) %>%
    > mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2007
    > & study == "site_1"][1] & date < date[month == 5 & year == 2008 & study ==
    > "site_1"][1], "survey_2007",
    >                      if_else(date >= date[survey_start == "Y" & year == 2008 & study
    > == "site_1"][1] & date < date[month == 4 & year == 2009 & study ==
    > "site_1"][1], "survey_2008",
    >                      if_else(date >= date[survey_start == "Y" & year == 2009 & study
    > == "site_1"][1] & date < date[month == 5 & year == 2010 & study ==
    > "site_1"][1], "survey_2009",
    >                      if_else(date >= date[survey_start == "Y" & year == 2010 & study
    > == "site_1"][1] & date < date[month == 5 & year == 2011 & study ==
    > "site_1"][1], "survey_2010",
    >                      if_else(date >= date[survey_start == "Y" & year == 2011 & study
    > == "site_1"][1] & date < date[month == 4 & year == 2012 & study ==
    > "site_1"][1], "survey_2011",
    >                      if_else(date >= date[survey_start == "Y" & year == 2012 & study
    > == "site_1"][1] & date < date[month == 4 & year == 2013 & study ==
    > "site_1"][1], "survey_2012",
    >                      if_else(date >= date[survey_start == "Y" & year == 2013 & study
    > == "site_1"][1] & date < date[month == 4 & year == 2014 & study ==
    > "site_1"][1], "survey_2013",
    >                      if_else(date >= date[survey_start == "Y" & year == 2014 & study
    > == "site_1"][1] & date < date[month == 4 & year == 2015 & study ==
    > "site_1"][1], "survey_2014",
    >                      if_else(date >= date[survey_start == "Y" & year == 2015 & study
    > == "site_1"][1] & date < date[month == 3 & year == 2016 & study ==
    > "site_1"][1], "survey_2015",
    >                      if_else(date >= date[survey_start == "Y" & year == 2016 & study
    > == "site_1"][1], "survey_2016","")))))))))))
    > 
    > code 2 works:
    > 
    >     trialData <- trialData %>% arrange(studyno, date) %>% group_by(studyno)
    > %>%
    >   mutate(survey_year = if_else(date >= date[survey_start == "Y" & year == 2016
    > & study == "site_1"][1]                                                               , "survey_2016",
    >                            if_else(date >= date[survey_start == "Y" & year == 2014 &
    > study == "site_1"][1] & date < date[month == 4 & year == 2015 & study ==
    > "site_1"][1], "survey_2014",
    >                            if_else(date >= date[survey_start == "Y" & year == 2013 &
    > study == "site_1"][1] & date < date[month == 4 & year == 2014 & study ==
    > "site_1"][1], "survey_2013",
    >                            if_else(date >= date[survey_start == "Y" & year == 2012 &
    > study == "site_1"][1] & date < date[month == 4 & year == 2013 & study ==
    > "site_1"][1], "survey_2012",
    >                            if_else(date >= date[survey_start == "Y" & year == 2011 &
    > study == "site_1"][1] & date < date[month == 4 & year == 2012 & study ==
    > "site_1"][1], "survey_2011",
    >                            if_else(date >= date[survey_start == "Y" & year == 2010 &
    > study == "site_1"][1] & date < date[month == 5 & year == 2011 & study ==
    > "site_1"][1], "survey_2010",
    >                            if_else(date >= date[survey_start == "Y" & year == 2009 &
    > study == "site_1"][1] & date < date[month == 5 & year == 2010 & study ==
    > "site_1"][1], "survey_2009",
    >                            if_else(date >= date[survey_start == "Y" & year == 2008 &
    > study == "site_1"][1] & date < date[month == 4 & year == 2009 & study ==
    > "site_1"][1], "survey_2008",
    >                            if_else(date >= date[survey_start == "Y" & year == 2007 &
    > study == "site_1"][1] & date < date[month == 5 & year == 2008 & study ==
    > "site_1"][1], "survey_2007",""))))))))))
    > 
    > ________________________________________________________________
    > ______
    > 
    > This e-mail contains information which is confidential. It is intended only for the
    > use of the named recipient. If you have received this e-mail in error, please let
    > us know by replying to the sender, and immediately delete it from your system.
    > Please note, that in these circumstances, the use, disclosure, distribution or
    > copying of this information is strictly prohibited. KEMRI-Wellcome Trust
    > Programme cannot accept any responsibility for the  accuracy or completeness
    > of this message as it has been transmitted over a public network. Although the
    > Programme has taken reasonable precautions to ensure no viruses are present
    > in emails, it cannot accept responsibility for any loss or damage arising from
    > the use of the email or attachments. Any views expressed in this message are
    > those of the individual sender, except where the sender specifically states them
    > to be the views of KEMRI-Wellcome Trust Programme.
    > ________________________________________________________________
    > ______
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    
    *******************************************************************
    This email and any attachments are confidential. Any use, copying or
    disclosure other than by the intended recipient is unauthorised. If 
    you have received this message in error, please notify the sender 
    immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
    and delete this message and any copies from your computer and network. 
    LGC Limited. Registered in England 2991879. 
    Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
    


______________________________________________________________________

This e-mail contains information which is confidential. It is intended only for the use of the named recipient. If you have received this e-mail in error, please let us know by replying to the sender, and immediately delete it from your system.  Please note, that in these circumstances, the use, disclosure, distribution or copying of this information is strictly prohibited. KEMRI-Wellcome Trust Programme cannot accept any responsibility for the  accuracy or completeness of this message as it has been transmitted over a public network. Although the Programme has taken reasonable precautions to ensure no viruses are present in emails, it cannot accept responsibility for any loss or damage arising from the use of the email or attachments. Any views expressed in this message are those of the individual sender, except where the sender specifically states them to be the views of KEMRI-Wellcome Trust Programme.
______________________________________________________________________

From pd.mes at cbs.dk  Mon Feb 26 15:47:23 2018
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Mon, 26 Feb 2018 14:47:23 +0000
Subject: [R] R 3.4.4 scheduled for March 15
Message-ID: <63401A34-70F6-4170-BA99-7D9C57A8C669@cbs.dk>

Full schedule available on developer.r-project.org (pending auto-update from SVN)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From paulaveronica at gmail.com  Mon Feb 26 15:55:47 2018
From: paulaveronica at gmail.com (Paula Couto)
Date: Mon, 26 Feb 2018 09:55:47 -0500
Subject: [R] glm package - Negative binomial regression model - Error
In-Reply-To: <CAJuCY5xg8ryw6FhXvvogLOTu259mP0UsUze-Df=gF6=HEnz3hw@mail.gmail.com>
References: <CAJqhdO7CN0pue=pb=k+ChDds9-wX1F5eMewr8sor9rMU7m=BsA@mail.gmail.com>
 <CAJuCY5xg8ryw6FhXvvogLOTu259mP0UsUze-Df=gF6=HEnz3hw@mail.gmail.com>
Message-ID: <CAJqhdO6t2Tv5YeSTM+eROOQFnoFTsUJmsFsXVd=zuQp8-BwkzQ@mail.gmail.com>

Thank  you so much, Thierry!!
I will try that now and see if that solves the issue
Bests,
Paula


On Feb 26, 2018 03:02, "Thierry Onkelinx" <thierry.onkelinx at inbo.be> wrote:

Dear Paula,

There are probably missing observations in your data set. Read the
na.action part of the glm help file. na.exclude is most likely what you are
looking for.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g>
bus 73, 1000 Brussel
www.inbo.be

////////////////////////////////////////////////////////////
///////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
////////////////////////////////////////////////////////////
///////////////////////////////

<https://www.inbo.be>

2018-02-26 2:07 GMT+01:00 Paula Couto <paulaveronica at gmail.com>:

> HI there
>
> I am running this model in negative binomial regression, using glm.
> I had no problems with running the model with a set of data, but now that
> i'm trying to run if for new one.  I always have this same error when
> running the regression:
>
> >
> > #Run Regression
> >     x=cbind(factor2ind(d$year),factor2ind(d$month_week))
> >
> >     out<- glm(cbind(influenza, n_sample) ~ x, family=quasibinomial,
> > data=d)
> >
> >     d$prop<-out$fitted.values
>
> Error in `$<-.data.frame`(`*tmp*`, prop, value = c(0.0486530542835839,  :
>   replacement has 208 rows, data has 365
>
> >     d$n_p1<-d$prop*d$factor*10
> >
> >     obs<-aggregate(d$prop, by = list(d$month_week), FUN=summary)
> >     pred<-aggregate(d$n_p1, by = list(d$month_week), FUN=summary)
> >
>
> By the way, I previously prepared the data set  and defined that:
>        d$factor<-sapply(d$year,f)
> >         d$n_sample<-(d$n_muestras*d$factor*10)
> >         d$prop<-(d$influenza/d$n_sample)
>
> But I still don't understand why it keeps saying that dataframe has less
> replacements than rows.
> Could anybody help me with this?
>  Many thankss!!!
> P
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb 26 16:28:42 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Feb 2018 07:28:42 -0800
Subject: [R] questions about performing Robust multiple regression using
 bootstrap
In-Reply-To: <CAFhDWBVSzM+NTvkrk9FFvNjmxqFMT3bp-GKLw0e=B1qnh3g6wA@mail.gmail.com>
References: <CAFhDWBVSzM+NTvkrk9FFvNjmxqFMT3bp-GKLw0e=B1qnh3g6wA@mail.gmail.com>
Message-ID: <CAGxFJbTB==oXiQa6OpK1CTsvMrHgM7LFBvSucx7ffP3KhJ_-6A@mail.gmail.com>

Although this is superficially a question about R code, it heavily depends
on exactly what you mean by "robust" and "robust tests," which are
statistical issues, not R coding issues. As such, it is off topic here. So
I would suggest that you post on a statistical site like
stats.stackexchange.com instead. While there, I suggest you also ask
whether what you want to do makes any sense (I don't think it does).

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Feb 26, 2018 at 3:30 AM, faiz rasool <faiz7r at gmail.com> wrote:

> Dear list,
>
> I am slightly confused about how I  can do the following in R.
>
> I want to  perform   robust multiple regression. I?ve used the Boot
> function in CAR package to find confidence intervals and standard
> errors. Inadition to these, I want to find the  robust estimates  for
> the F test and  r-square. Finally, I  would like to know the
> significance levels of bootstrap results.
>
> Below I  explain my question  using commented R code.
>
> [1] reg=lm(a~b+c+d+e) # perform multiple regression.
> [2] library(car) #load the car package.
> [3] bootstrap=Boot(reg) #perform bootstrap using the Boot function in
> car package.
> [4] summary(bootstrap) #show the results of bootstrap.
> [5]now  I would like to type a code that can give me robust
> estimates  of R-square, F tests, and  significance  levels for
> coefficients and f.
>
>
> Thanks for any help.
>
> Regards,
> Faiz.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Feb 26 16:47:23 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 26 Feb 2018 15:47:23 +0000
Subject: [R] questions about performing Robust multiple regression using
 bootstrap
In-Reply-To: <11108_1519644632_w1QBUVpM017023_CAFhDWBVSzM+NTvkrk9FFvNjmxqFMT3bp-GKLw0e=B1qnh3g6wA@mail.gmail.com>
References: <11108_1519644632_w1QBUVpM017023_CAFhDWBVSzM+NTvkrk9FFvNjmxqFMT3bp-GKLw0e=B1qnh3g6wA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836786084@FHSDB2D11-2.csu.mcmaster.ca>

Dear Faiz,

Bootstrapping R^2 using Boot() is straightforward: Simply write a function that returns R^2, possibly in a vector with the regression coefficients, and use it as the f argument to Boot(). That will get you, e.g., bootstrapped confidence intervals for R^2. (Why you want that is another question.) See the example in ?Boot that shows how to bootstrap the estimated error variance (without the regression coefficients).

On the other hand, bootstrap hypothesis tests aren't entirely straightforward (and you might ask yourself why you need them when you have bootstrap confidence intervals). If memory serves, there's a discussion in the Davison  and Hinkley reference in ?Boot (I don't have a copy of the book at my current location, so I can't check). There's also a brief discussion in Sec. 21.4 of my Applied Regression Analysis and Generalized Linear Models, 3rd ed. 

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of faiz rasool
> Sent: Monday, February 26, 2018 6:30 AM
> To: R-help at r-project.org
> Subject: [R] questions about performing Robust multiple regression using
> bootstrap
> 
> Dear list,
> 
> I am slightly confused about how I  can do the following in R.
> 
> I want to  perform   robust multiple regression. I?ve used the Boot
> function in CAR package to find confidence intervals and standard errors.
> Inadition to these, I want to find the  robust estimates  for the F test and  r-
> square. Finally, I  would like to know the significance levels of bootstrap results.
> 
> Below I  explain my question  using commented R code.
> 
> [1] reg=lm(a~b+c+d+e) # perform multiple regression.
> [2] library(car) #load the car package.
> [3] bootstrap=Boot(reg) #perform bootstrap using the Boot function in car
> package.
> [4] summary(bootstrap) #show the results of bootstrap.
> [5]now  I would like to type a code that can give me robust estimates  of R-
> square, F tests, and  significance  levels for coefficients and f.
> 
> 
> Thanks for any help.
> 
> Regards,
> Faiz.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From wdunlap at tibco.com  Mon Feb 26 16:54:40 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 26 Feb 2018 07:54:40 -0800
Subject: [R] Precision in R
In-Reply-To: <CA+YqJQDLoT3Knb1F9GCCPe5Vg-xkb3+jFVSGYUYOPUbbAY4hHQ@mail.gmail.com>
References: <CA+YqJQDLoT3Knb1F9GCCPe5Vg-xkb3+jFVSGYUYOPUbbAY4hHQ@mail.gmail.com>
Message-ID: <CAF8bMcYG9qUqVacjyVggtpaYrNsrDmbYETN2gb_gVaz9_7c2og@mail.gmail.com>

In the R expression
   x[1] + x[2]
the result must be stored as a double precision number,
because that is what R "numerics" are.  sum() does not
have to keep its intermediate results as doubles, but
can use quad precision or Kahan's summation algorithm
(both methods involve more than a simple double to
keep track of the running sum) to give more accurate results
for summing vectors.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Feb 25, 2018 at 5:34 PM, Iuri Gavronski <iuri at proxima.adm.br> wrote:

> Hi,
>
> Why sum() on a 10-item vector produces a different value than its
> counterpart on a 2-item vector? I understand the problems related to
> the arithmetic precision in storing decimal numbers in binary format,
> but shouldn't the errors be equal regardless of the method used?
>
> See my example:
>
> > options(digits=22)
> > x=rep(.1,10)
> > x
>  [1] 0.10000000000000001 0.10000000000000001 0.10000000000000001
>  [4] 0.10000000000000001 0.10000000000000001 0.10000000000000001
>  [7] 0.10000000000000001 0.10000000000000001 0.10000000000000001
> [10] 0.10000000000000001
> > sum(x)
> [1] 1
> > y=0
> > for (i in 1:10) {y=sum(y+x[i])}
> > y
> [1] 0.99999999999999989
> > y*10^6
> [1] 999999.99999999988
> > sum(x)*10^6
> [1] 1e+06
> > z=.1+.1+.1+.1+.1+.1+.1+.1+.1+.1
> > z
> [1] 0.99999999999999989
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Giulia.Carella at lsce.ipsl.fr  Mon Feb 26 15:06:28 2018
From: Giulia.Carella at lsce.ipsl.fr (Giulia Carella)
Date: Mon, 26 Feb 2018 15:06:28 +0100
Subject: [R] Gam with mrf smoother (mgcv)
Message-ID: <44e87bc6-9d0a-860f-7055-9d1cf39e01f8@lsce.ipsl.fr>

Hallo,

I want to use gam from the mgcv package with a mrf smoother.

This is my data set (`x`)

 ?????? y????????? id
 ??? 1? 0.6684496? 1
 ??? 2? 0.6684496? 2
 ??? 3? 0.6684496? 3
 ??? 4? 0.6684496? 4
 ??? 5? 0.6684496? 5
 ??? 6? 0.6684496? 6
 ??? 7? 0.6684496? 7
 ??? 8? 0.5879492? 8
 ??? 9? 0.5879492? 9
 ??? 10 0.5879492 10
 ??? 11 0.5879492 11
 ??? 12 0.5879492 12
 ??? 13 0.5879492 13
 ??? 14 0.5879492 14
 ??? 15 0.6445448 15
 ??? 16 0.6445448 16
 ??? 17 0.6445448 17
 ??? 18 0.6445448 18
 ??? 19 0.6445448 19
 ??? 20 0.6445448 20
 ??? 21 0.6445448 21
 ??? 22 0.5815767 22
 ??? 23 0.5815767 23
 ??? 24 0.5815767 24
 ??? 25 0.5815767 25
 ??? 26 0.5815767 26
 ??? 27 0.5815767 27
 ??? 28 0.5815767 28
 ??? 29 0.6636673 29
 ??? 30 0.6636673 30
 ??? 31 0.6636673 31
 ??? 32 0.6636673 32
 ??? 33 0.6636673 33
 ??? 34 0.6636673 34
 ??? 35 0.6636673 35
 ??? 36 0.4249320 36
 ??? 37 0.4249320 37
 ??? 38 0.4249320 38
 ??? 39 0.4249320 39
 ??? 40 0.4249320 40
 ??? 41 0.4249320 41
 ??? 42 0.4249320 42

and this is my neighbouring structure (nb)

 ??? $`1`
 ??? [1] 1 2 3 4 5 6 7

 ??? $`2`
 ??? [1] 1 2 3 4 5 6 7

 ??? $`3`
 ??? [1] 1 2 3 4 5 6 7

 ??? $`4`
 ??? [1] 1 2 3 4 5 6 7

 ??? $`5`
 ??? [1] 1 2 3 4 5 6 7

 ??? $`6`
 ??? [1] 1 2 3 4 5 6 7

 ??? $`7`
 ??? [1] 1 2 3 4 5 6 7

 ??? $`8`
 ??? [1]? 8? 9 10 11 12 13 14

 ??? $`9`
 ??? [1]? 8? 9 10 11 12 13 14

 ??? $`10`
 ??? [1]? 8? 9 10 11 12 13 14

 ??? $`11`
 ??? [1]? 8? 9 10 11 12 13 14

 ??? $`12`
 ??? [1]? 8? 9 10 11 12 13 14

 ??? $`13`
 ??? [1]? 8? 9 10 11 12 13 14

 ??? $`14`
 ??? [1]? 8? 9 10 11 12 13 14

 ??? $`15`
 ??? [1] 15 16 17 18 19 20 21

 ??? $`16`
 ??? [1] 15 16 17 18 19 20 21

 ??? $`17`
 ??? [1] 15 16 17 18 19 20 21

 ??? $`18`
 ??? [1] 15 16 17 18 19 20 21

 ??? $`19`
 ??? [1] 15 16 17 18 19 20 21

 ??? $`20`
 ??? [1] 15 16 17 18 19 20 21

 ??? $`21`
 ??? [1] 15 16 17 18 19 20 21

 ??? $`22`
 ??? [1] 22 23 24 25 26 27 28

 ??? $`23`
 ??? [1] 22 23 24 25 26 27 28

 ??? $`24`
 ??? [1] 22 23 24 25 26 27 28

 ??? $`25`
 ??? [1] 22 23 24 25 26 27 28

 ??? $`26`
 ??? [1] 22 23 24 25 26 27 28

 ??? $`27`
 ??? [1] 22 23 24 25 26 27 28

 ??? $`28`
 ??? [1] 22 23 24 25 26 27 28

 ??? $`29`
 ??? [1] 29 30 31 32 33 34 35

 ??? $`30`
 ??? [1] 29 30 31 32 33 34 35

 ??? $`31`
 ??? [1] 29 30 31 32 33 34 35

 ??? $`32`
 ??? [1] 29 30 31 32 33 34 35

 ??? $`33`
 ??? [1] 29 30 31 32 33 34 35

 ??? $`34`
 ??? [1] 29 30 31 32 33 34 35

 ??? $`35`
 ??? [1] 29 30 31 32 33 34 35

 ??? $`36`
 ??? [1] 36 37 38 39 40 41 42

 ??? $`37`
 ??? [1] 36 37 38 39 40 41 42

 ??? $`38`
 ??? [1] 36 37 38 39 40 41 42

 ??? $`39`
 ??? [1] 36 37 38 39 40 41 42

 ??? $`40`
 ??? [1] 36 37 38 39 40 41 42

 ??? $`41`
 ??? [1] 36 37 38 39 40 41 42

 ??? $`42`
 ??? [1] 36 37 38 39 40 41 42

However, when I run

 ??? b <- gam(y ~ s(id,bs="mrf",xt=list(nb=nb)),data=x,method="REML")

I get the following error:

Error in initial.sp(w * x, S, off) : S[[1]] matrix is not +ve definite.

Why is the penalty matrix non semi-positive definite? Am I defining 
something wrong?

Many thanks in advance


From bethanykaye4 at gmail.com  Mon Feb 26 17:28:37 2018
From: bethanykaye4 at gmail.com (B Hansen)
Date: Mon, 26 Feb 2018 10:28:37 -0600
Subject: [R] How to model repeated measures negative binomial data with GEE
 or GLMM
Message-ID: <CAFxyLhwL0NoDZOOS--_SMKWW9W9F_-Y6OFAcAzJnsB-1Uh_cRQ@mail.gmail.com>

Goal: use GEE or GLMM to analyze repeated measures data in R

GEE problem: can?t find a way to do GEE with negative binomial family in R

GLMM problem: not sure if I?m specifying random effect correctly


Study question: Does the interaction of director and recipient group affect
rates of a behavior?

Data:

Animals (n = 38) in one of 3 groups (life stages): B or C.

Some individuals (~5) transitioned between groups between observation
periods (2010, 2011, 2012), e.g., transitioning from B -> C.

I gathered data on individuals in groups B and C, recording how often they
directed a behavior to individuals in groups A, B, or C.


I have multiple measures for each director (both within and between years).
For example, for an individual who was alive for the entire study, I have
one count of the behavior directed toward groups A, B, and C for each of
the three years of study (total = 9 counts). Some individuals were observed
all three years, others were only observed one or two years.


Approach 1:

Initially I used GEE in SPSS, the software I initially learned on (but no
longer have access to)


Outcome variable: counts of directed behaviors (?Diract?) from directors
(?Dir? in group B or C) to members of groups A, B, C (?Rec"). Values range
from 0-4, with overdispersion.

Offset: the amount of time the focal individual was observed with
individuals from the recipient group (natural log transformation applied,
?LnScan?)

Explanatory variable: the interaction of director and recipient group
(?Dir*Rec?)

Fixed effect: ?Year?

Family: Negative binomial with log link function

Exchangeable working correlation matrix


I hoped to rerun the analyses in R, which I am now learning to use.
However, I cannot find a straightforward way to run a GEE in R with a
negative binomial family. I am able to code what I want using a Poisson
distribution using package geeglm:


library("geeglm")

m1 <- geeglm(Diract ~ Dir*Rec + Year + offset(LnScan), family =
poisson("log"), data=Direct, id=ID, corstr="exchangeable")


The lack of a negative binomial option for GEE in R has been addressed in
the past few years here:

https://www.researchgate.net/post/Does_anyone_know_how_to_undertake_Generalized_Estimating_Equation_GEE_modelling_using_the_negative_binomial_distribution_in_R


and here:


http://r.789695.n4.nabble.com/Negative-Binomial-Regression-td861977.html


A similar question here is unanswered:


https://stats.stackexchange.com/questions/83957/fit-negbin-glm-model-with-autoregressive-correlation-structure


I wonder if there are any newer developments, since the posts are a few
years old. I?m not very advanced in R, so if the solution involves a lot of
creative coding, I won?t likely be able to figure it out. I have already
tried using:


library("sos")

findFn("{generalized estimating equation}")


and researching every package listed. Most seem to leverage gee (JGEE) or
geepack (wgeesel), or lack a negative binomial family (PGEE, spind).


Approach 2: GLMM

I have become more familiar with GLMMs in R, so perhaps that is a better
approach. I tried running GLMMs with package glmmTMB, but I am not sure I
specified the random effect correctly (am I properly accounting for the
repeated measures within AND between years?):


m2 <- glmmTMB(Diract ~ DirPar*RecPar + offset(LnScan) + Year + (1|ID),
data=Direct, family=list(family="nbinom1",link="log"))


I further tried to specify a compound symmetry covariance structure with
glmmTMB, but this failed:


m2a <- glmmTMB(Diract ~ DirPar*RecPar + offset(LnScan) + Year + cs(1|ID),
data=Direct,family=list(family="nbinom1",link="log"))

Warning message:

In fitTMB(TMBStruc) :

Model convergence problem; non-positive-definite Hessian matrix. See
vignette('troubleshooting')


I also tried Ben Bolker?s suggestion (posted on Nabble; see link above) to
use glmmPQL, but I got an error message:


m3 <- glmmPQL(Diract ~ Dir*Rec + offset(LnScan) + Year, random = ~ 1 | ID,
family = negative.binomial(1), data = Direct,
correlation=corCompSymm(form=~1|ID))


Error in glmmPQL(Diract ~ DirPar * RecPar + offset(LnScan) + Year, random =
~1 |  : could not find function "corCompSymm"


If anyone has tips for a) a GEE with a negative binomial family and/or b)
making sure I am specifying the random effect in a GLMM correctly to
account for multiple measures within and across years, that would be
greatly appreciated. Thank you from a self-taught but passionate R user!


Bethany K. Hansen, PhD

Chimp Haven sanctuary

	[[alternative HTML version deleted]]


From thomas.mailund at gmail.com  Mon Feb 26 20:59:54 2018
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Mon, 26 Feb 2018 20:59:54 +0100
Subject: [R] Parallel assignments and goto
In-Reply-To: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
References: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
Message-ID: <160a872a-7d87-449b-b4c7-91590879ca69@Spark>

Following up on this attempt of implementing the tail-recursion optimisation ? now that I?ve finally had the chance to look at it again ? I find that non-local return implemented with callCC doesn?t actually incur much overhead once I do it more sensibly. I haven?t found a good way to handle parallel assignments that isn?t vastly slower than simply introducing extra variables, so I am going with that solution. However, I have now run into another problem involving those local variables ? and assigning to local variables in general.

Consider again the factorial function and three different ways of implementing it using the tail recursion optimisation:

factorial <- function(n, acc = 1) {
? ? if (n == 1) acc
? ? else factorial(n - 1, n * acc)
}

factorial_tr_manual <- function (n, acc = 1)
{
? ? repeat {
? ? ? ? if (n <= 1)
? ? ? ? ? ? return(acc)
? ? ? ? else {
? ? ? ? ? ? .tailr_n <- n - 1
? ? ? ? ? ? .tailr_acc <- acc * n
? ? ? ? ? ? n <- .tailr_n
? ? ? ? ? ? acc <- .tailr_acc
? ? ? ? ? ? next
? ? ? ? }
? ? }
}

factorial_tr_automatic_1 <- function(n, acc = 1) {
? ? callCC(function(escape) {
? ? ? ? repeat {
? ? ? ? ? ? if (n <= 1) {
? ? ? ? ? ? ? ? escape(acc)
? ? ? ? ? ? } else {
? ? ? ? ? ? ? ? .tailr_n <- n - 1
? ? ? ? ? ? ? ? .tailr_acc <- n * acc
? ? ? ? ? ? ? ? n <- .tailr_n
? ? ? ? ? ? ? ? acc <- .tailr_acc
? ? ? ? ? ? }
? ? ? ? }
? ? })
}

factorial_tr_automatic_2 <- function(n, acc = 1) {
? ? .tailr_env <- rlang::get_env()
? ? callCC(function(escape) {
? ? ? ? repeat {
? ? ? ? ? ? if (n <= 1) {
? ? ? ? ? ? ? ? escape(acc)
? ? ? ? ? ? } else {
? ? ? ? ? ? ? ? .tailr_env$.tailr_n <- n - 1
? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- n * acc
? ? ? ? ? ? ? ? .tailr_env$n <- .tailr_env$.tailr_n
? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
? ? ? ? ? ? }
? ? ? ? }
? ? })
}

The?factorial_tr_manual function is how I would implement the function manually while?factorial_tr_automatic_1 is what my package used to come up with. It handles non-local returns, because this is something I need in general. Finally,?factorial_tr_automatic_2 accesses the local variables explicitly through the environment, which is what my package currently produces.

The difference between supporting non-local returns and not is tiny, but explicitly accessing variables through their environment costs me about a factor of five ? something that surprised me.

> microbenchmark::microbenchmark(factorial(1000),
+ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_manual(1000),
+ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_1(1000),
+ ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_2(1000))
Unit: microseconds
? ? ? ? ? ? ? ? ? ? ? ? ? ?expr ? ? min ? ? ? lq ? ? mean ? median
? ? ? ? ? ? ? ? factorial(1000) 756.357 810.4135 963.1040 856.3315
? ? ? factorial_tr_manual(1000) 104.838 119.7595 198.7347 129.0870
?factorial_tr_automatic_1(1000) 112.354 125.5145 211.6148 135.5255
?factorial_tr_automatic_2(1000) 461.015 544.7035 688.5988 565.3240
? ? ? ?uq ? ? ?max neval
?945.3110 4149.099 ? 100
?136.8200 4190.331 ? 100
?152.9625 5944.312 ? 100
?600.5235 7798.622 ? 100

The simple solution, of course, is to not do that, but then I can?t handle expressions inside calls to ?with?. And I would really like to, because then I can combine tail recursion with pattern matching.

I can define linked lists and a length function on them like this:

library(pmatch)
llist := NIL | CONS(car, cdr : llist)

llength <- function(llist, acc = 0) {
? ? cases(llist,
? ? ? ? ? NIL -> acc,
? ? ? ? ? CONS(car, cdr) -> llength(cdr, acc + 1))
}

The tail-recursion I get out of transforming this function looks like this:

llength_tr <- function (llist, acc = 0) {
? ? .tailr_env <- rlang::get_env()
? ? callCC(function(escape) {
? ? ? ? repeat {
? ? ? ? ? ? if (!rlang::is_null(..match_env <- test_pattern(llist,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NIL)))
? ? ? ? ? ? ? ? with(..match_env, escape(acc))

? ? ? ? ? ? else if (!rlang::is_null(..match_env <-
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?test_pattern(llist, CONS(car, cdr))))
? ? ? ? ? ? ? ? with(..match_env, {
? ? ? ? ? ? ? ? ? ? .tailr_env$.tailr_llist <- cdr
? ? ? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- acc + 1
? ? ? ? ? ? ? ? ? ? .tailr_env$llist <- .tailr_env$.tailr_llist
? ? ? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
? ? ? ? ? ? ? ? })
? ? ? ? }
? ? })
}

Maybe not the prettiest code, but you are not supposed to actually see it, of course.

There is not much gain in speed

Unit: milliseconds
? ? ? ? ? ? ? ? ? ?expr ? ? ?min ? ? ? lq ? ? mean ? median ? ? ? uq
? ? llength(test_llist) 70.74605 76.08734 87.78418 85.81193 94.66378
?llength_tr(test_llist) 45.16946 51.56856 59.09306 57.00101 63.07044
? ? ? max neval
?182.4894 ? 100
?166.6990 ? 100

but you don?t run out of stack space

> llength(make_llist(1000))
Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
Error during wrapup: C stack usage ?7990648 is too close to the limit
> llength_tr(make_llist(1000))
[1] 1000

I should be able to make the function go faster if I had a faster way of handling the variable assignments, but inside ?with?, I?m not sure how to do that?

Any suggestions?

Cheers

On 11 Feb 2018, 16.48 +0100, Thomas Mailund <thomas.mailund at gmail.com>, wrote:
> Hi guys,
>
> I am working on some code for automatically translating recursive functions into looping functions to implemented tail-recursion optimisations. See https://github.com/mailund/tailr
>
> As a toy-example, consider the factorial function
>
> factorial <- function(n, acc = 1) {
> if (n <= 1) acc
> else factorial(n - 1, acc * n)
> }
>
> I can automatically translate this into the loop-version
>
> factorial_tr_1 <- function (n, acc = 1)
> {
> repeat {
> if (n <= 1)
> return(acc)
> else {
> .tailr_n <- n - 1
> .tailr_acc <- acc * acc
> n <- .tailr_n
> acc <- .tailr_acc
> next
> }
> }
> }
>
> which will run faster and not have problems with recursion depths. However, I?m not entirely happy with this version for two reasons: I am not happy with introducing the temporary variables and this rewrite will not work if I try to over-scope an evaluation context.
>
> I have two related questions, one related to parallel assignments ? i.e. expressions to variables so the expression uses the old variable values and not the new values until the assignments are all done ? and one related to restarting a loop from nested loops or from nested expressions in `with` expressions or similar.
>
> I can implement parallel assignment using something like rlang::env_bind:
>
> factorial_tr_2 <- function (n, acc = 1)
> {
> .tailr_env <- rlang::get_env()
> repeat {
> if (n <= 1)
> return(acc)
> else {
> rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> next
> }
> }
> }
>
> This reduces the number of additional variables I need to one, but is a couple of orders of magnitude slower than the first version.
>
> > microbenchmark::microbenchmark(factorial(100),
> + factorial_tr_1(100),
> + factorial_tr_2(100))
> Unit: microseconds
> expr min lq mean median uq max neval
> factorial(100) 53.978 60.543 77.76203 71.0635 85.947 180.251 100
> factorial_tr_1(100) 9.022 9.903 11.52563 11.0430 11.984 28.464 100
> factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463 8177.635 100
>
>
> Is there another way to do parallel assignments that doesn?t cost this much in running time?
>
> My other problem is the use of `next`. I would like to combine tail-recursion optimisation with pattern matching as in https://github.com/mailund/pmatch where I can, for example, define a linked list like this:
>
> devtools::install_github("mailund/pmatch?)
> library(pmatch)
> llist := NIL | CONS(car, cdr : llist)
>
> and define a function for computing the length of a list like this:
>
> list_length <- function(lst, acc = 0) {
> force(acc)
> cases(lst,
> NIL -> acc,
> CONS(car, cdr) -> list_length(cdr, acc + 1))
> }
>
> The `cases` function creates an environment that binds variables in a pattern-description that over-scopes the expression to the right of `->`, so the recursive call in this example have access to the variables `cdr` and `car`.
>
> I can transform a `cases` call to one that creates the environment containing the bound variables and then evaluate this using `eval` or `with`, but in either case, a call to `next` will not work in such a context. The expression will be evaluated inside `bind` or `with`, and not in the `list_lenght` function.
>
> A version that *will* work, is something like this
>
> factorial_tr_3 <- function (n, acc = 1)
> {
> .tailr_env <- rlang::get_env()
> .tailr_frame <- rlang::current_frame()
> repeat {
> if (n <= 1)
> rlang::return_from(.tailr_frame, acc)
> else {
> rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> rlang::return_to(.tailr_frame)
> }
> }
> }
>
> Here, again, for the factorial function since this is easier to follow than the list-length function.
>
> This solution will also work if you return values from inside loops, where `next` wouldn?t work either.
>
> Using `rlang::return_from` and `rlang::return_to` implements the right semantics, but costs me another order of magnitude in running time.
>
> microbenchmark::microbenchmark(factorial(100),
> factorial_tr_1(100),
> factorial_tr_2(100),
> factorial_tr_3(100))
> Unit: microseconds
> expr min lq mean median uq max neval
> factorial(100) 52.479 60.2640 93.43069 67.5130 83.925 2062.481 100
> factorial_tr_1(100) 8.875 9.6525 49.19595 10.6945 11.217 3818.823 100
> factorial_tr_2(100) 5296.350 5525.0745 5973.77664 5737.8730 6260.128 8471.301 100
> factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725 89859.169 171039.228 100
>
> I can live with the ?introducing extra variables? solution to parallel assignment, and I could hack my way out of using `with` or `bind` in rewriting `cases`, but restarting a `repeat` loop would really make for a nicer solution. I know that `goto` is considered harmful, but really, in this case, it is what I want.
>
> A `callCC` version also solves the problem
>
> factorial_tr_4 <- function(n, acc = 1) {
> function_body <- function(continuation) {
> if (n <= 1) {
> continuation(acc)
> } else {
> continuation(list("continue", n = n - 1, acc = acc * n))
> }
> }
> repeat {
> result <- callCC(function_body)
> if (is.list(result) && result[[1]] == "continue") {
> n <- result$n
> acc <- result$acc
> next
> } else {
> return(result)
> }
> }
> }
>
> But this requires that I know how to distinguish between a valid return value and a tag for ?next? and is still a lot slower than the `next` solution
>
> microbenchmark::microbenchmark(factorial(100),
> factorial_tr_1(100),
> factorial_tr_2(100),
> factorial_tr_3(100),
> factorial_tr_4(100))
> Unit: microseconds
> expr min lq mean median uq max neval
> factorial(100) 54.109 61.8095 81.33167 81.8785 89.748 243.554 100
> factorial_tr_1(100) 9.025 9.9035 11.38607 11.1990 12.008 22.375 100
> factorial_tr_2(100) 5272.524 5798.3965 6302.40467 6077.7180 6492.959 9967.237 100
> factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665 75405.054 203785.673 100
> factorial_tr_4(100) 270.978 302.7890 337.48763 313.9930 334.096 1425.702 100
>
> I don?t necessarily need the tail-recursion optimisation to be faster than the recursive version; just getting out of the problem of too deep recursions is a benefit, but I would rather not pay with an order of magnitude for it. I could, of course, try to handle cases that works with `next` in one way, and other cases using `callCC`, but I feel it should be possible with a version that handles all cases the same way.
>
> Is there any way to achieve this?
>
> Cheers
> Thomas
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From gwblack001 at sbcglobal.net  Tue Feb 27 00:25:56 2018
From: gwblack001 at sbcglobal.net (Gary Black)
Date: Mon, 26 Feb 2018 17:25:56 -0600
Subject: [R] Random Seed Location
Message-ID: <000701d3af59$28341b50$789c51f0$@sbcglobal.net>

Hi all,

For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
different results (e.g., error rates, classification probabilities) from run
to run even though I am using the same random seed. 

Nothing else (input-wise) is changing, but my results are somewhat different
from run to run.  The only randomness should be in the partitioning, and I
have set the seed before this point.  

My question simply is:  should the location of the set.seed command matter,
provided that it is applied before any commands which involve randomness
(such as partitioning)?  

If you need to see the code, it is below:

Thank you,
Gary


A.	Separate the original (in-sample) data from the new (out-of-sample)
data.  Set a random seed.

> InvestTech <- as.data.frame(InvestTechRevised)
> outOfSample <- InvestTech[5001:nrow(InvestTech), ]
> InvestTech <- InvestTech[1:5000, ]
> set.seed(654321)

B.	Install and load the caret, ggplot2 and e1071 packages.

> install.packages(?caret?)
> install.packages(?ggplot2?)
> install.packages(?e1071?)
> library(caret)
> library(ggplot2)
> library(e1071)

C.	Bin the predictor variables with approximately equal counts using
the cut_number function from the ggplot2 package.  We will use 20 bins. 

> InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
> InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
> outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
> outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)

D.	Partition the original (in-sample) data into 60% training and 40%
validation sets.

> n <- nrow(InvestTech)
> train <- sample(1:n, size = 0.6 * n, replace = FALSE)
> InvestTechTrain <- InvestTech[train, ]
> InvestTechVal <- InvestTech[-train, ]

E.	Use the naiveBayes function in the e1071 package to fit the model.

> model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data = InvestTechTrain)
> prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)

F.	Use the confusionMatrix function in the caret package to output the
confusion matrix.

> confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
?everything?, positive = ?1?)
> accuracy <- confMtr$overall[1]
> valError <- 1 ? accuracy
> confMtr

G.	Classify the 18 new (out-of-sample) readers using the following
code. 
> prob <- predict(model, newdata = outOfSample, type = ?raw?)
> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
> cbind(pred, prob, outOfSample[, -3])







---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From bgunter.4567 at gmail.com  Tue Feb 27 01:30:47 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Feb 2018 16:30:47 -0800
Subject: [R] Random Seed Location
In-Reply-To: <000701d3af59$28341b50$789c51f0$@sbcglobal.net>
References: <000701d3af59$28341b50$789c51f0$@sbcglobal.net>
Message-ID: <CAGxFJbQsHZXEE=m-XS_gpPUK-f82CFXmcJ_5x+V07ts0XFmEcA@mail.gmail.com>

In case you don't get an answer from someone more knowledgeable:

1. I don't know.
2.  But it is possible that other packages that are loaded after set.seed()
fool with the RNG.
3. So I would call set.seed just before you invoke each random number
generation to be safe.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
wrote:

> Hi all,
>
> For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
> different results (e.g., error rates, classification probabilities) from
> run
> to run even though I am using the same random seed.
>
> Nothing else (input-wise) is changing, but my results are somewhat
> different
> from run to run.  The only randomness should be in the partitioning, and I
> have set the seed before this point.
>
> My question simply is:  should the location of the set.seed command matter,
> provided that it is applied before any commands which involve randomness
> (such as partitioning)?
>
> If you need to see the code, it is below:
>
> Thank you,
> Gary
>
>
> A.      Separate the original (in-sample) data from the new (out-of-sample)
> data.  Set a random seed.
>
> > InvestTech <- as.data.frame(InvestTechRevised)
> > outOfSample <- InvestTech[5001:nrow(InvestTech), ]
> > InvestTech <- InvestTech[1:5000, ]
> > set.seed(654321)
>
> B.      Install and load the caret, ggplot2 and e1071 packages.
>
> > install.packages(?caret?)
> > install.packages(?ggplot2?)
> > install.packages(?e1071?)
> > library(caret)
> > library(ggplot2)
> > library(e1071)
>
> C.      Bin the predictor variables with approximately equal counts using
> the cut_number function from the ggplot2 package.  We will use 20 bins.
>
> > InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
> > InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
> > outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
> > outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
>
> D.      Partition the original (in-sample) data into 60% training and 40%
> validation sets.
>
> > n <- nrow(InvestTech)
> > train <- sample(1:n, size = 0.6 * n, replace = FALSE)
> > InvestTechTrain <- InvestTech[train, ]
> > InvestTechVal <- InvestTech[-train, ]
>
> E.      Use the naiveBayes function in the e1071 package to fit the model.
>
> > model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data = InvestTechTrain)
> > prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
> > pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>
> F.      Use the confusionMatrix function in the caret package to output the
> confusion matrix.
>
> > confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
> ?everything?, positive = ?1?)
> > accuracy <- confMtr$overall[1]
> > valError <- 1 ? accuracy
> > confMtr
>
> G.      Classify the 18 new (out-of-sample) readers using the following
> code.
> > prob <- predict(model, newdata = outOfSample, type = ?raw?)
> > pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
> > cbind(pred, prob, outOfSample[, -3])
>
>
>
>
>
>
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Feb 27 02:51:54 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 26 Feb 2018 17:51:54 -0800
Subject: [R] Random Seed Location
In-Reply-To: <CAGxFJbQsHZXEE=m-XS_gpPUK-f82CFXmcJ_5x+V07ts0XFmEcA@mail.gmail.com>
References: <000701d3af59$28341b50$789c51f0$@sbcglobal.net>
 <CAGxFJbQsHZXEE=m-XS_gpPUK-f82CFXmcJ_5x+V07ts0XFmEcA@mail.gmail.com>
Message-ID: <CAF8bMcYBENwaqB1EaNC7dcfARSGyvw-jVOtGfP1_e4mVA_O76w@mail.gmail.com>

If your computations involve the parallel package then set.seed(seed)
may not produce repeatable results.  E.g.,

> cl <- parallel::makeCluster(3)  # Create cluster with 3 nodes on local
host
> set.seed(100); runif(2)
[1] 0.3077661 0.2576725
> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
         [,1]     [,2]     [,3]
[1,] 101.7779 102.5308 103.3459
[2,] 101.8128 102.6114 103.9102
>
> set.seed(100); runif(2)
[1] 0.3077661 0.2576725
> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
         [,1]     [,2]     [,3]
[1,] 101.1628 102.9643 103.2684
[2,] 101.9205 102.6937 103.7907


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Feb 26, 2018 at 4:30 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> In case you don't get an answer from someone more knowledgeable:
>
> 1. I don't know.
> 2.  But it is possible that other packages that are loaded after set.seed()
> fool with the RNG.
> 3. So I would call set.seed just before you invoke each random number
> generation to be safe.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
> wrote:
>
> > Hi all,
> >
> > For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
> > different results (e.g., error rates, classification probabilities) from
> > run
> > to run even though I am using the same random seed.
> >
> > Nothing else (input-wise) is changing, but my results are somewhat
> > different
> > from run to run.  The only randomness should be in the partitioning, and
> I
> > have set the seed before this point.
> >
> > My question simply is:  should the location of the set.seed command
> matter,
> > provided that it is applied before any commands which involve randomness
> > (such as partitioning)?
> >
> > If you need to see the code, it is below:
> >
> > Thank you,
> > Gary
> >
> >
> > A.      Separate the original (in-sample) data from the new
> (out-of-sample)
> > data.  Set a random seed.
> >
> > > InvestTech <- as.data.frame(InvestTechRevised)
> > > outOfSample <- InvestTech[5001:nrow(InvestTech), ]
> > > InvestTech <- InvestTech[1:5000, ]
> > > set.seed(654321)
> >
> > B.      Install and load the caret, ggplot2 and e1071 packages.
> >
> > > install.packages(?caret?)
> > > install.packages(?ggplot2?)
> > > install.packages(?e1071?)
> > > library(caret)
> > > library(ggplot2)
> > > library(e1071)
> >
> > C.      Bin the predictor variables with approximately equal counts using
> > the cut_number function from the ggplot2 package.  We will use 20 bins.
> >
> > > InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
> > > InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
> > > outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
> > > outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
> >
> > D.      Partition the original (in-sample) data into 60% training and 40%
> > validation sets.
> >
> > > n <- nrow(InvestTech)
> > > train <- sample(1:n, size = 0.6 * n, replace = FALSE)
> > > InvestTechTrain <- InvestTech[train, ]
> > > InvestTechVal <- InvestTech[-train, ]
> >
> > E.      Use the naiveBayes function in the e1071 package to fit the
> model.
> >
> > > model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data =
> InvestTechTrain)
> > > prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
> > > pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
> >
> > F.      Use the confusionMatrix function in the caret package to output
> the
> > confusion matrix.
> >
> > > confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
> > ?everything?, positive = ?1?)
> > > accuracy <- confMtr$overall[1]
> > > valError <- 1 ? accuracy
> > > confMtr
> >
> > G.      Classify the 18 new (out-of-sample) readers using the following
> > code.
> > > prob <- predict(model, newdata = outOfSample, type = ?raw?)
> > > pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
> > > cbind(pred, prob, outOfSample[, -3])
> >
> >
> >
> >
> >
> >
> >
> > ---
> > This email has been checked for viruses by Avast antivirus software.
> > https://www.avast.com/antivirus
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Feb 27 02:56:37 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 26 Feb 2018 17:56:37 -0800
Subject: [R] Random Seed Location
In-Reply-To: <CAGxFJbQsHZXEE=m-XS_gpPUK-f82CFXmcJ_5x+V07ts0XFmEcA@mail.gmail.com>
References: <000701d3af59$28341b50$789c51f0$@sbcglobal.net>
 <CAGxFJbQsHZXEE=m-XS_gpPUK-f82CFXmcJ_5x+V07ts0XFmEcA@mail.gmail.com>
Message-ID: <C0466E15-395D-4105-84E9-9585D2B10FB3@dcn.davis.ca.us>

 I am willing to go out on that limb and say the answer to the OP question is yes, the RN sequence in R should be reproducible. I agree though that it doesn't look like he is actually taking care not to run code that would disturb the generator.
-- 
Sent from my phone. Please excuse my brevity.

On February 26, 2018 4:30:47 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>In case you don't get an answer from someone more knowledgeable:
>
>1. I don't know.
>2.  But it is possible that other packages that are loaded after
>set.seed()
>fool with the RNG.
>3. So I would call set.seed just before you invoke each random number
>generation to be safe.
>
>Cheers,
>Bert
>
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
>wrote:
>
>> Hi all,
>>
>> For some odd reason when running na?ve bayes, k-NN, etc., I get
>slightly
>> different results (e.g., error rates, classification probabilities)
>from
>> run
>> to run even though I am using the same random seed.
>>
>> Nothing else (input-wise) is changing, but my results are somewhat
>> different
>> from run to run.  The only randomness should be in the partitioning,
>and I
>> have set the seed before this point.
>>
>> My question simply is:  should the location of the set.seed command
>matter,
>> provided that it is applied before any commands which involve
>randomness
>> (such as partitioning)?
>>
>> If you need to see the code, it is below:
>>
>> Thank you,
>> Gary
>>
>>
>> A.      Separate the original (in-sample) data from the new
>(out-of-sample)
>> data.  Set a random seed.
>>
>> > InvestTech <- as.data.frame(InvestTechRevised)
>> > outOfSample <- InvestTech[5001:nrow(InvestTech), ]
>> > InvestTech <- InvestTech[1:5000, ]
>> > set.seed(654321)
>>
>> B.      Install and load the caret, ggplot2 and e1071 packages.
>>
>> > install.packages(?caret?)
>> > install.packages(?ggplot2?)
>> > install.packages(?e1071?)
>> > library(caret)
>> > library(ggplot2)
>> > library(e1071)
>>
>> C.      Bin the predictor variables with approximately equal counts
>using
>> the cut_number function from the ggplot2 package.  We will use 20
>bins.
>>
>> > InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
>> > InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
>> > outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
>> > outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
>>
>> D.      Partition the original (in-sample) data into 60% training and
>40%
>> validation sets.
>>
>> > n <- nrow(InvestTech)
>> > train <- sample(1:n, size = 0.6 * n, replace = FALSE)
>> > InvestTechTrain <- InvestTech[train, ]
>> > InvestTechVal <- InvestTech[-train, ]
>>
>> E.      Use the naiveBayes function in the e1071 package to fit the
>model.
>>
>> > model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data =
>InvestTechTrain)
>> > prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
>> > pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>>
>> F.      Use the confusionMatrix function in the caret package to
>output the
>> confusion matrix.
>>
>> > confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
>> ?everything?, positive = ?1?)
>> > accuracy <- confMtr$overall[1]
>> > valError <- 1 ? accuracy
>> > confMtr
>>
>> G.      Classify the 18 new (out-of-sample) readers using the
>following
>> code.
>> > prob <- predict(model, newdata = outOfSample, type = ?raw?)
>> > pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>> > cbind(pred, prob, outOfSample[, -3])
>>
>>
>>
>>
>>
>>
>>
>> ---
>> This email has been checked for viruses by Avast antivirus software.
>> https://www.avast.com/antivirus
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From esawiek at gmail.com  Tue Feb 27 14:54:23 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Tue, 27 Feb 2018 08:54:23 -0500
Subject: [R] 
 Aggregate over multiple and unequal column length data frames
In-Reply-To: <4dc6702440764e7c9c826d0b603e3a6f@SRVEXCHCM1301.precheza.cz>
References: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
 <4dc6702440764e7c9c826d0b603e3a6f@SRVEXCHCM1301.precheza.cz>
Message-ID: <CA+ZkTxs09FzoCC=on-2x7LrPuUehFYxpttDt2x+qMqZkpQSDMg@mail.gmail.com>

Thank you Pikal and Bert. My apology for posting parts of my previous
email in HTML. Bert's suggestion will work but i am wondering if there
is an alternative
especially in the case where the data frames are big; that is the
difference in lengths among them is large. Below is a list of sample
date frames and desired result.

EK


dput(df1<-data.frame(col1=c(1,2,3,4,5),col2=c("aa","aa","bb","cc","dd")))
dput(df2<-data.frame(col1=c(1,2,4,5),col2=c("bb","bb","cc","bb")))
dput(df3<-data.frame(col1=c(1,3),col2=c("aa","aa")))
# desired result
dput(dfn<-data.frame(col1=c(2,2,1,1),col2=c(0,3,1,0),col3=c(2,0,0,0),row.names
= c("aa","bb","cc","dd")))

On Fri, Feb 23, 2018 at 7:45 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> Your example is rather confusing - partly because HTML formating, partly because weird coding.
>
> You probably could concatenate your data frames e.g. by rbind or merge and after that you could try to aggregate them somehow.
>
> I could construct example data.frames myself but most probably they would be different from yours and also the result would not be necessary the same as you expect.
>
> You should post those data frames as output from dput(data) and show us real desired result from those example data frames.
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek Esawi
>> Sent: Wednesday, February 21, 2018 3:34 AM
>> To: r-help at r-project.org
>> Subject: [R] Aggregate over multiple and unequal column length data frames
>>
>>  Hi All--
>>
>> I have generated several 2 column data frames with variable length. The data
>> frames have the same column names and variable types. I was trying to
>> aggregate over the 2nd column for all the date frames, but could not figure out
>> how.
>>
>> I thought i could make them all of equal length then combine them in 1 data
>> frame where i can use aggregate, the formula version Or to put them in a list
>> and loop use lapply but did not know how to do that and thought there might
>> be a simpler way.
>>
>> Below is an example of 3 data frames and the desired result; note that some
>> levels don't appear in all and may be null over all variable, like the case of dd
>> on the desired result which i would like to list all levels even if some are all null.
>>
>> Thanks in advance,
>>
>> EK
>>
>>    df1           df2          df3
>>
>> c1 c2 c1 c2 c1 c2
>> 1 aa 1 bb 1 aa
>> 2 aa 2 bb 2 aa
>> 3 bb 3 cc
>> 4 cc 4 bb
>> 5 bb
>>
>> desired result
>>
>> c1 c2 c2 c2
>> aa 2 2
>> bb 1 2 2
>> cc 1 1
>> dd
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From petr.pikal at precheza.cz  Tue Feb 27 15:31:58 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 27 Feb 2018 14:31:58 +0000
Subject: [R] 
 Aggregate over multiple and unequal column length data frames
In-Reply-To: <CA+ZkTxs09FzoCC=on-2x7LrPuUehFYxpttDt2x+qMqZkpQSDMg@mail.gmail.com>
References: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
 <4dc6702440764e7c9c826d0b603e3a6f@SRVEXCHCM1301.precheza.cz>
 <CA+ZkTxs09FzoCC=on-2x7LrPuUehFYxpttDt2x+qMqZkpQSDMg@mail.gmail.com>
Message-ID: <c3ce0b6fc9944bc2af85144e823e118c@SRVEXCHCM1301.precheza.cz>

Hi

you does not need this:
dput(df1<-data.frame(col1=c(1,2,3,4,5),col2=c("aa","aa","bb","cc","dd")))

this is enough to represent exactly any object to mail:
> dput(df1)
structure(list(col1 = c(1, 2, 3, 4, 5), col2 = structure(c(1L,
1L, 2L, 3L, 4L), .Label = c("aa", "bb", "cc", "dd"), class = "factor")), .Names = c("col1",
"col2"), row.names = c(NA, -5L), class = "data.frame")

Anyway (I am sure there is better way but)
# make list from your data frames
lll<-list(df1, df2, df3)

#add new column to each part
for (i in 1:3) lll[[i]]$n<-i

#concatenate data to one data frame
dat<-do.call(rbind, lll)

# make table (and data frame from it)
data.frame(unclass(table(dat$col2, dat$n)))
   X1 X2 X3
aa  2  0  2
bb  1  3  0
cc  1  1  0
dd  1  0  0

I believe that in your dfn is typo in second row and first column and that with your 3 data.frames the result should be 1.

Cheers
Petr

> -----Original Message-----
> From: Ek Esawi [mailto:esawiek at gmail.com]
> Sent: Tuesday, February 27, 2018 2:54 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help at r-project.org
> Subject: Re: [R] Aggregate over multiple and unequal column length data
> frames
>
> Thank you Pikal and Bert. My apology for posting parts of my previous email in
> HTML. Bert's suggestion will work but i am wondering if there is an alternative
> especially in the case where the data frames are big; that is the difference in
> lengths among them is large. Below is a list of sample date frames and desired
> result.
>
> EK
>
>
> dput(df1<-data.frame(col1=c(1,2,3,4,5),col2=c("aa","aa","bb","cc","dd")))
> dput(df2<-data.frame(col1=c(1,2,4,5),col2=c("bb","bb","cc","bb")))
> dput(df3<-data.frame(col1=c(1,3),col2=c("aa","aa")))
> # desired result
> dput(dfn<-data.frame(col1=c(2,2,1,1),col2=c(0,3,1,0),col3=c(2,0,0,0),row.names
> = c("aa","bb","cc","dd")))
>
> On Fri, Feb 23, 2018 at 7:45 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > Hi
> >
> > Your example is rather confusing - partly because HTML formating, partly
> because weird coding.
> >
> > You probably could concatenate your data frames e.g. by rbind or merge and
> after that you could try to aggregate them somehow.
> >
> > I could construct example data.frames myself but most probably they would
> be different from yours and also the result would not be necessary the same as
> you expect.
> >
> > You should post those data frames as output from dput(data) and show us
> real desired result from those example data frames.
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek
> >> Esawi
> >> Sent: Wednesday, February 21, 2018 3:34 AM
> >> To: r-help at r-project.org
> >> Subject: [R] Aggregate over multiple and unequal column length data
> >> frames
> >>
> >>  Hi All--
> >>
> >> I have generated several 2 column data frames with variable length.
> >> The data frames have the same column names and variable types. I was
> >> trying to aggregate over the 2nd column for all the date frames, but
> >> could not figure out how.
> >>
> >> I thought i could make them all of equal length then combine them in
> >> 1 data frame where i can use aggregate, the formula version Or to put
> >> them in a list and loop use lapply but did not know how to do that
> >> and thought there might be a simpler way.
> >>
> >> Below is an example of 3 data frames and the desired result; note
> >> that some levels don't appear in all and may be null over all
> >> variable, like the case of dd on the desired result which i would like to list all
> levels even if some are all null.
> >>
> >> Thanks in advance,
> >>
> >> EK
> >>
> >>    df1           df2          df3
> >>
> >> c1 c2 c1 c2 c1 c2
> >> 1 aa 1 bb 1 aa
> >> 2 aa 2 bb 2 aa
> >> 3 bb 3 cc
> >> 4 cc 4 bb
> >> 5 bb
> >>
> >> desired result
> >>
> >> c1 c2 c2 c2
> >> aa 2 2
> >> bb 1 2 2
> >> cc 1 1
> >> dd
> >>
> >> [[alternative HTML version deleted]]
> >>

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From thomas.mailund at gmail.com  Tue Feb 27 15:51:44 2018
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Tue, 27 Feb 2018 15:51:44 +0100
Subject: [R] Parallel assignments and goto
In-Reply-To: <160a872a-7d87-449b-b4c7-91590879ca69@Spark>
References: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
 <160a872a-7d87-449b-b4c7-91590879ca69@Spark>
Message-ID: <613f4787-8e86-4417-ba36-267c0599dc74@Spark>

Interestingly, the <<- operator is also a lot faster than using a namespace explicitly, and only slightly slower than using <- with local variables, see below. But, surely, both must at some point insert values in a given environment ? either the local one, for <-, or an enclosing one, for <<- ? so I guess I am asking if there is a more low-level assignment operation I can get my hands on without diving into C?


factorial <- function(n, acc = 1) {
? ? if (n == 1) acc
? ? else factorial(n - 1, n * acc)
}

factorial_tr_manual <- function (n, acc = 1)
{
? ? repeat {
? ? ? ? if (n <= 1)
? ? ? ? ? ? return(acc)
? ? ? ? else {
? ? ? ? ? ? .tailr_n <- n - 1
? ? ? ? ? ? .tailr_acc <- acc * n
? ? ? ? ? ? n <- .tailr_n
? ? ? ? ? ? acc <- .tailr_acc
? ? ? ? ? ? next
? ? ? ? }
? ? }
}

factorial_tr_automatic_1 <- function(n, acc = 1) {
? ? .tailr_n <- n
? ? .tailr_acc <- acc
? ? callCC(function(escape) {
? ? ? ? repeat {
? ? ? ? ? ? n <- .tailr_n
? ? ? ? ? ? acc <- .tailr_acc
? ? ? ? ? ? if (n <= 1) {
? ? ? ? ? ? ? ? escape(acc)
? ? ? ? ? ? } else {
? ? ? ? ? ? ? ? .tailr_n <<- n - 1
? ? ? ? ? ? ? ? .tailr_acc <<- n * acc
? ? ? ? ? ? }
? ? ? ? }
? ? })
}

factorial_tr_automatic_2 <- function(n, acc = 1) {
? ? .tailr_env <- rlang::get_env()
? ? callCC(function(escape) {
? ? ? ? repeat {
? ? ? ? ? ? if (n <= 1) {
? ? ? ? ? ? ? ? escape(acc)
? ? ? ? ? ? } else {
? ? ? ? ? ? ? ? .tailr_env$.tailr_n <- n - 1
? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- n * acc
? ? ? ? ? ? ? ? .tailr_env$n <- .tailr_env$.tailr_n
? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
? ? ? ? ? ? }
? ? ? ? }
? ? })
}

microbenchmark::microbenchmark(factorial(1000),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_manual(1000),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_1(1000),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_2(1000))
Unit: microseconds
? ? ? ? ? ? ? ? ? ? ? ? ? ?expr ? ? min ? ? ?lq ? ? ?mean ? median ? ? ? ?uq ? ? ?max neval
? ? ? ? ? ? ? ? factorial(1000) 884.137 942.060 1076.3949 977.6235 1042.5035 2889.779 ? 100
? ? ? factorial_tr_manual(1000) 110.215 116.919 ?130.2337 118.7350 ?122.7495 ?255.062 ? 100
?factorial_tr_automatic_1(1000) 179.897 183.437 ?212.8879 187.8250 ?195.7670 ?979.352 ? 100
?factorial_tr_automatic_2(1000) 508.353 534.328 ?601.9643 560.7830 ?587.8350 1424.260 ? 100

Cheers

On 26 Feb 2018, 21.12 +0100, Thomas Mailund <thomas.mailund at gmail.com>, wrote:
> Following up on this attempt of implementing the tail-recursion optimisation ? now that I?ve finally had the chance to look at it again ? I find that non-local return implemented with callCC doesn?t actually incur much overhead once I do it more sensibly. I haven?t found a good way to handle parallel assignments that isn?t vastly slower than simply introducing extra variables, so I am going with that solution. However, I have now run into another problem involving those local variables ? and assigning to local variables in general.
>
> Consider again the factorial function and three different ways of implementing it using the tail recursion optimisation:
>
> factorial <- function(n, acc = 1) {
> ? ? if (n == 1) acc
> ? ? else factorial(n - 1, n * acc)
> }
>
> factorial_tr_manual <- function (n, acc = 1)
> {
> ? ? repeat {
> ? ? ? ? if (n <= 1)
> ? ? ? ? ? ? return(acc)
> ? ? ? ? else {
> ? ? ? ? ? ? .tailr_n <- n - 1
> ? ? ? ? ? ? .tailr_acc <- acc * n
> ? ? ? ? ? ? n <- .tailr_n
> ? ? ? ? ? ? acc <- .tailr_acc
> ? ? ? ? ? ? next
> ? ? ? ? }
> ? ? }
> }
>
> factorial_tr_automatic_1 <- function(n, acc = 1) {
> ? ? callCC(function(escape) {
> ? ? ? ? repeat {
> ? ? ? ? ? ? if (n <= 1) {
> ? ? ? ? ? ? ? ? escape(acc)
> ? ? ? ? ? ? } else {
> ? ? ? ? ? ? ? ? .tailr_n <- n - 1
> ? ? ? ? ? ? ? ? .tailr_acc <- n * acc
> ? ? ? ? ? ? ? ? n <- .tailr_n
> ? ? ? ? ? ? ? ? acc <- .tailr_acc
> ? ? ? ? ? ? }
> ? ? ? ? }
> ? ? })
> }
>
> factorial_tr_automatic_2 <- function(n, acc = 1) {
> ? ? .tailr_env <- rlang::get_env()
> ? ? callCC(function(escape) {
> ? ? ? ? repeat {
> ? ? ? ? ? ? if (n <= 1) {
> ? ? ? ? ? ? ? ? escape(acc)
> ? ? ? ? ? ? } else {
> ? ? ? ? ? ? ? ? .tailr_env$.tailr_n <- n - 1
> ? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- n * acc
> ? ? ? ? ? ? ? ? .tailr_env$n <- .tailr_env$.tailr_n
> ? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
> ? ? ? ? ? ? }
> ? ? ? ? }
> ? ? })
> }
>
> The?factorial_tr_manual function is how I would implement the function manually while?factorial_tr_automatic_1 is what my package used to come up with. It handles non-local returns, because this is something I need in general. Finally,?factorial_tr_automatic_2 accesses the local variables explicitly through the environment, which is what my package currently produces.
>
> The difference between supporting non-local returns and not is tiny, but explicitly accessing variables through their environment costs me about a factor of five ? something that surprised me.
>
> > microbenchmark::microbenchmark(factorial(1000),
> + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_manual(1000),
> + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_1(1000),
> + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_2(1000))
> Unit: microseconds
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?expr ? ? min ? ? ? lq ? ? mean ? median
> ? ? ? ? ? ? ? ? factorial(1000) 756.357 810.4135 963.1040 856.3315
> ? ? ? factorial_tr_manual(1000) 104.838 119.7595 198.7347 129.0870
> ?factorial_tr_automatic_1(1000) 112.354 125.5145 211.6148 135.5255
> ?factorial_tr_automatic_2(1000) 461.015 544.7035 688.5988 565.3240
> ? ? ? ?uq ? ? ?max neval
> ?945.3110 4149.099 ? 100
> ?136.8200 4190.331 ? 100
> ?152.9625 5944.312 ? 100
> ?600.5235 7798.622 ? 100
>
> The simple solution, of course, is to not do that, but then I can?t handle expressions inside calls to ?with?. And I would really like to, because then I can combine tail recursion with pattern matching.
>
> I can define linked lists and a length function on them like this:
>
> library(pmatch)
> llist := NIL | CONS(car, cdr : llist)
>
> llength <- function(llist, acc = 0) {
> ? ? cases(llist,
> ? ? ? ? ? NIL -> acc,
> ? ? ? ? ? CONS(car, cdr) -> llength(cdr, acc + 1))
> }
>
> The tail-recursion I get out of transforming this function looks like this:
>
> llength_tr <- function (llist, acc = 0) {
> ? ? .tailr_env <- rlang::get_env()
> ? ? callCC(function(escape) {
> ? ? ? ? repeat {
> ? ? ? ? ? ? if (!rlang::is_null(..match_env <- test_pattern(llist,
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NIL)))
> ? ? ? ? ? ? ? ? with(..match_env, escape(acc))
>
> ? ? ? ? ? ? else if (!rlang::is_null(..match_env <-
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?test_pattern(llist, CONS(car, cdr))))
> ? ? ? ? ? ? ? ? with(..match_env, {
> ? ? ? ? ? ? ? ? ? ? .tailr_env$.tailr_llist <- cdr
> ? ? ? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- acc + 1
> ? ? ? ? ? ? ? ? ? ? .tailr_env$llist <- .tailr_env$.tailr_llist
> ? ? ? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
> ? ? ? ? ? ? ? ? })
> ? ? ? ? }
> ? ? })
> }
>
> Maybe not the prettiest code, but you are not supposed to actually see it, of course.
>
> There is not much gain in speed
>
> Unit: milliseconds
> ? ? ? ? ? ? ? ? ? ?expr ? ? ?min ? ? ? lq ? ? mean ? median ? ? ? uq
> ? ? llength(test_llist) 70.74605 76.08734 87.78418 85.81193 94.66378
> ?llength_tr(test_llist) 45.16946 51.56856 59.09306 57.00101 63.07044
> ? ? ? max neval
> ?182.4894 ? 100
> ?166.6990 ? 100
>
> but you don?t run out of stack space
>
> > llength(make_llist(1000))
> Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
> Error during wrapup: C stack usage ?7990648 is too close to the limit
> > llength_tr(make_llist(1000))
> [1] 1000
>
> I should be able to make the function go faster if I had a faster way of handling the variable assignments, but inside ?with?, I?m not sure how to do that?
>
> Any suggestions?
>
> Cheers
>
> On 11 Feb 2018, 16.48 +0100, Thomas Mailund <thomas.mailund at gmail.com>, wrote:
> > Hi guys,
> >
> > I am working on some code for automatically translating recursive functions into looping functions to implemented tail-recursion optimisations. See https://github.com/mailund/tailr
> >
> > As a toy-example, consider the factorial function
> >
> > factorial <- function(n, acc = 1) {
> > if (n <= 1) acc
> > else factorial(n - 1, acc * n)
> > }
> >
> > I can automatically translate this into the loop-version
> >
> > factorial_tr_1 <- function (n, acc = 1)
> > {
> > repeat {
> > if (n <= 1)
> > return(acc)
> > else {
> > .tailr_n <- n - 1
> > .tailr_acc <- acc * acc
> > n <- .tailr_n
> > acc <- .tailr_acc
> > next
> > }
> > }
> > }
> >
> > which will run faster and not have problems with recursion depths. However, I?m not entirely happy with this version for two reasons: I am not happy with introducing the temporary variables and this rewrite will not work if I try to over-scope an evaluation context.
> >
> > I have two related questions, one related to parallel assignments ? i.e. expressions to variables so the expression uses the old variable values and not the new values until the assignments are all done ? and one related to restarting a loop from nested loops or from nested expressions in `with` expressions or similar.
> >
> > I can implement parallel assignment using something like rlang::env_bind:
> >
> > factorial_tr_2 <- function (n, acc = 1)
> > {
> > .tailr_env <- rlang::get_env()
> > repeat {
> > if (n <= 1)
> > return(acc)
> > else {
> > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > next
> > }
> > }
> > }
> >
> > This reduces the number of additional variables I need to one, but is a couple of orders of magnitude slower than the first version.
> >
> > > microbenchmark::microbenchmark(factorial(100),
> > + factorial_tr_1(100),
> > + factorial_tr_2(100))
> > Unit: microseconds
> > expr min lq mean median uq max neval
> > factorial(100) 53.978 60.543 77.76203 71.0635 85.947 180.251 100
> > factorial_tr_1(100) 9.022 9.903 11.52563 11.0430 11.984 28.464 100
> > factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463 8177.635 100
> >
> >
> > Is there another way to do parallel assignments that doesn?t cost this much in running time?
> >
> > My other problem is the use of `next`. I would like to combine tail-recursion optimisation with pattern matching as in https://github.com/mailund/pmatch where I can, for example, define a linked list like this:
> >
> > devtools::install_github("mailund/pmatch?)
> > library(pmatch)
> > llist := NIL | CONS(car, cdr : llist)
> >
> > and define a function for computing the length of a list like this:
> >
> > list_length <- function(lst, acc = 0) {
> > force(acc)
> > cases(lst,
> > NIL -> acc,
> > CONS(car, cdr) -> list_length(cdr, acc + 1))
> > }
> >
> > The `cases` function creates an environment that binds variables in a pattern-description that over-scopes the expression to the right of `->`, so the recursive call in this example have access to the variables `cdr` and `car`.
> >
> > I can transform a `cases` call to one that creates the environment containing the bound variables and then evaluate this using `eval` or `with`, but in either case, a call to `next` will not work in such a context. The expression will be evaluated inside `bind` or `with`, and not in the `list_lenght` function.
> >
> > A version that *will* work, is something like this
> >
> > factorial_tr_3 <- function (n, acc = 1)
> > {
> > .tailr_env <- rlang::get_env()
> > .tailr_frame <- rlang::current_frame()
> > repeat {
> > if (n <= 1)
> > rlang::return_from(.tailr_frame, acc)
> > else {
> > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > rlang::return_to(.tailr_frame)
> > }
> > }
> > }
> >
> > Here, again, for the factorial function since this is easier to follow than the list-length function.
> >
> > This solution will also work if you return values from inside loops, where `next` wouldn?t work either.
> >
> > Using `rlang::return_from` and `rlang::return_to` implements the right semantics, but costs me another order of magnitude in running time.
> >
> > microbenchmark::microbenchmark(factorial(100),
> > factorial_tr_1(100),
> > factorial_tr_2(100),
> > factorial_tr_3(100))
> > Unit: microseconds
> > expr min lq mean median uq max neval
> > factorial(100) 52.479 60.2640 93.43069 67.5130 83.925 2062.481 100
> > factorial_tr_1(100) 8.875 9.6525 49.19595 10.6945 11.217 3818.823 100
> > factorial_tr_2(100) 5296.350 5525.0745 5973.77664 5737.8730 6260.128 8471.301 100
> > factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725 89859.169 171039.228 100
> >
> > I can live with the ?introducing extra variables? solution to parallel assignment, and I could hack my way out of using `with` or `bind` in rewriting `cases`, but restarting a `repeat` loop would really make for a nicer solution. I know that `goto` is considered harmful, but really, in this case, it is what I want.
> >
> > A `callCC` version also solves the problem
> >
> > factorial_tr_4 <- function(n, acc = 1) {
> > function_body <- function(continuation) {
> > if (n <= 1) {
> > continuation(acc)
> > } else {
> > continuation(list("continue", n = n - 1, acc = acc * n))
> > }
> > }
> > repeat {
> > result <- callCC(function_body)
> > if (is.list(result) && result[[1]] == "continue") {
> > n <- result$n
> > acc <- result$acc
> > next
> > } else {
> > return(result)
> > }
> > }
> > }
> >
> > But this requires that I know how to distinguish between a valid return value and a tag for ?next? and is still a lot slower than the `next` solution
> >
> > microbenchmark::microbenchmark(factorial(100),
> > factorial_tr_1(100),
> > factorial_tr_2(100),
> > factorial_tr_3(100),
> > factorial_tr_4(100))
> > Unit: microseconds
> > expr min lq mean median uq max neval
> > factorial(100) 54.109 61.8095 81.33167 81.8785 89.748 243.554 100
> > factorial_tr_1(100) 9.025 9.9035 11.38607 11.1990 12.008 22.375 100
> > factorial_tr_2(100) 5272.524 5798.3965 6302.40467 6077.7180 6492.959 9967.237 100
> > factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665 75405.054 203785.673 100
> > factorial_tr_4(100) 270.978 302.7890 337.48763 313.9930 334.096 1425.702 100
> >
> > I don?t necessarily need the tail-recursion optimisation to be faster than the recursive version; just getting out of the problem of too deep recursions is a benefit, but I would rather not pay with an order of magnitude for it. I could, of course, try to handle cases that works with `next` in one way, and other cases using `callCC`, but I feel it should be possible with a version that handles all cases the same way.
> >
> > Is there any way to achieve this?
> >
> > Cheers
> > Thomas
> >
> >
> >
> >
> >
> >
> >
> >

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 27 16:52:53 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Feb 2018 07:52:53 -0800
Subject: [R] 
 Aggregate over multiple and unequal column length data frames
In-Reply-To: <CA+ZkTxs09FzoCC=on-2x7LrPuUehFYxpttDt2x+qMqZkpQSDMg@mail.gmail.com>
References: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
 <4dc6702440764e7c9c826d0b603e3a6f@SRVEXCHCM1301.precheza.cz>
 <CA+ZkTxs09FzoCC=on-2x7LrPuUehFYxpttDt2x+qMqZkpQSDMg@mail.gmail.com>
Message-ID: <CAGxFJbQK5f6CcU9tB9F_u8xsf9-E+D3J2et6viOBLKb61ycb+Q@mail.gmail.com>

Then you need to rethink your data structure. Use a list instead of a data
frame. The components of a list can have different lengths, and the "apply"
family of functions (lapply(), etc.) can operate on them. Consult any good
R tutorial for details.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 27, 2018 at 5:54 AM, Ek Esawi <esawiek at gmail.com> wrote:

> Thank you Pikal and Bert. My apology for posting parts of my previous
> email in HTML. Bert's suggestion will work but i am wondering if there
> is an alternative
> especially in the case where the data frames are big; that is the
> difference in lengths among them is large. Below is a list of sample
> date frames and desired result.
>
> EK
>
>
> dput(df1<-data.frame(col1=c(1,2,3,4,5),col2=c("aa","aa","bb","cc","dd")))
> dput(df2<-data.frame(col1=c(1,2,4,5),col2=c("bb","bb","cc","bb")))
> dput(df3<-data.frame(col1=c(1,3),col2=c("aa","aa")))
> # desired result
> dput(dfn<-data.frame(col1=c(2,2,1,1),col2=c(0,3,1,0),col3=c(
> 2,0,0,0),row.names
> = c("aa","bb","cc","dd")))
>
> On Fri, Feb 23, 2018 at 7:45 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > Hi
> >
> > Your example is rather confusing - partly because HTML formating, partly
> because weird coding.
> >
> > You probably could concatenate your data frames e.g. by rbind or merge
> and after that you could try to aggregate them somehow.
> >
> > I could construct example data.frames myself but most probably they
> would be different from yours and also the result would not be necessary
> the same as you expect.
> >
> > You should post those data frames as output from dput(data) and show us
> real desired result from those example data frames.
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ek
> Esawi
> >> Sent: Wednesday, February 21, 2018 3:34 AM
> >> To: r-help at r-project.org
> >> Subject: [R] Aggregate over multiple and unequal column length data
> frames
> >>
> >>  Hi All--
> >>
> >> I have generated several 2 column data frames with variable length. The
> data
> >> frames have the same column names and variable types. I was trying to
> >> aggregate over the 2nd column for all the date frames, but could not
> figure out
> >> how.
> >>
> >> I thought i could make them all of equal length then combine them in 1
> data
> >> frame where i can use aggregate, the formula version Or to put them in
> a list
> >> and loop use lapply but did not know how to do that and thought there
> might
> >> be a simpler way.
> >>
> >> Below is an example of 3 data frames and the desired result; note that
> some
> >> levels don't appear in all and may be null over all variable, like the
> case of dd
> >> on the desired result which i would like to list all levels even if
> some are all null.
> >>
> >> Thanks in advance,
> >>
> >> EK
> >>
> >>    df1           df2          df3
> >>
> >> c1 c2 c1 c2 c1 c2
> >> 1 aa 1 bb 1 aa
> >> 2 aa 2 bb 2 aa
> >> 3 bb 3 cc
> >> 4 cc 4 bb
> >> 5 bb
> >>
> >> desired result
> >>
> >> c1 c2 c2 c2
> >> aa 2 2
> >> bb 1 2 2
> >> cc 1 1
> >> dd
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> > - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 27 17:16:23 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Feb 2018 08:16:23 -0800
Subject: [R] Parallel assignments and goto
In-Reply-To: <613f4787-8e86-4417-ba36-267c0599dc74@Spark>
References: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
 <160a872a-7d87-449b-b4c7-91590879ca69@Spark>
 <613f4787-8e86-4417-ba36-267c0599dc74@Spark>
Message-ID: <CAGxFJbSfjVLLv2rwBXR4wwWSz+Yq3eFuLSc4U758u6REE8HbHQ@mail.gmail.com>

No clue, but see ?assign perhaps if you have not done so already.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 27, 2018 at 6:51 AM, Thomas Mailund <thomas.mailund at gmail.com>
wrote:

> Interestingly, the <<- operator is also a lot faster than using a
> namespace explicitly, and only slightly slower than using <- with local
> variables, see below. But, surely, both must at some point insert values in
> a given environment ? either the local one, for <-, or an enclosing one,
> for <<- ? so I guess I am asking if there is a more low-level assignment
> operation I can get my hands on without diving into C?
>
>
> factorial <- function(n, acc = 1) {
>     if (n == 1) acc
>     else factorial(n - 1, n * acc)
> }
>
> factorial_tr_manual <- function (n, acc = 1)
> {
>     repeat {
>         if (n <= 1)
>             return(acc)
>         else {
>             .tailr_n <- n - 1
>             .tailr_acc <- acc * n
>             n <- .tailr_n
>             acc <- .tailr_acc
>             next
>         }
>     }
> }
>
> factorial_tr_automatic_1 <- function(n, acc = 1) {
>     .tailr_n <- n
>     .tailr_acc <- acc
>     callCC(function(escape) {
>         repeat {
>             n <- .tailr_n
>             acc <- .tailr_acc
>             if (n <= 1) {
>                 escape(acc)
>             } else {
>                 .tailr_n <<- n - 1
>                 .tailr_acc <<- n * acc
>             }
>         }
>     })
> }
>
> factorial_tr_automatic_2 <- function(n, acc = 1) {
>     .tailr_env <- rlang::get_env()
>     callCC(function(escape) {
>         repeat {
>             if (n <= 1) {
>                 escape(acc)
>             } else {
>                 .tailr_env$.tailr_n <- n - 1
>                 .tailr_env$.tailr_acc <- n * acc
>                 .tailr_env$n <- .tailr_env$.tailr_n
>                 .tailr_env$acc <- .tailr_env$.tailr_acc
>             }
>         }
>     })
> }
>
> microbenchmark::microbenchmark(factorial(1000),
>                                factorial_tr_manual(1000),
>                                factorial_tr_automatic_1(1000),
>                                factorial_tr_automatic_2(1000))
> Unit: microseconds
>                            expr     min      lq      mean   median
>  uq      max neval
>                 factorial(1000) 884.137 942.060 1076.3949 977.6235
> 1042.5035 2889.779   100
>       factorial_tr_manual(1000) 110.215 116.919  130.2337 118.7350
>  122.7495  255.062   100
>  factorial_tr_automatic_1(1000) 179.897 183.437  212.8879 187.8250
>  195.7670  979.352   100
>  factorial_tr_automatic_2(1000) 508.353 534.328  601.9643 560.7830
>  587.8350 1424.260   100
>
> Cheers
>
> On 26 Feb 2018, 21.12 +0100, Thomas Mailund <thomas.mailund at gmail.com>,
> wrote:
> > Following up on this attempt of implementing the tail-recursion
> optimisation ? now that I?ve finally had the chance to look at it again ? I
> find that non-local return implemented with callCC doesn?t actually incur
> much overhead once I do it more sensibly. I haven?t found a good way to
> handle parallel assignments that isn?t vastly slower than simply
> introducing extra variables, so I am going with that solution. However, I
> have now run into another problem involving those local variables ? and
> assigning to local variables in general.
> >
> > Consider again the factorial function and three different ways of
> implementing it using the tail recursion optimisation:
> >
> > factorial <- function(n, acc = 1) {
> >     if (n == 1) acc
> >     else factorial(n - 1, n * acc)
> > }
> >
> > factorial_tr_manual <- function (n, acc = 1)
> > {
> >     repeat {
> >         if (n <= 1)
> >             return(acc)
> >         else {
> >             .tailr_n <- n - 1
> >             .tailr_acc <- acc * n
> >             n <- .tailr_n
> >             acc <- .tailr_acc
> >             next
> >         }
> >     }
> > }
> >
> > factorial_tr_automatic_1 <- function(n, acc = 1) {
> >     callCC(function(escape) {
> >         repeat {
> >             if (n <= 1) {
> >                 escape(acc)
> >             } else {
> >                 .tailr_n <- n - 1
> >                 .tailr_acc <- n * acc
> >                 n <- .tailr_n
> >                 acc <- .tailr_acc
> >             }
> >         }
> >     })
> > }
> >
> > factorial_tr_automatic_2 <- function(n, acc = 1) {
> >     .tailr_env <- rlang::get_env()
> >     callCC(function(escape) {
> >         repeat {
> >             if (n <= 1) {
> >                 escape(acc)
> >             } else {
> >                 .tailr_env$.tailr_n <- n - 1
> >                 .tailr_env$.tailr_acc <- n * acc
> >                 .tailr_env$n <- .tailr_env$.tailr_n
> >                 .tailr_env$acc <- .tailr_env$.tailr_acc
> >             }
> >         }
> >     })
> > }
> >
> > The factorial_tr_manual function is how I would implement the function
> manually while factorial_tr_automatic_1 is what my package used to come up
> with. It handles non-local returns, because this is something I need in
> general. Finally, factorial_tr_automatic_2 accesses the local variables
> explicitly through the environment, which is what my package currently
> produces.
> >
> > The difference between supporting non-local returns and not is tiny, but
> explicitly accessing variables through their environment costs me about a
> factor of five ? something that surprised me.
> >
> > > microbenchmark::microbenchmark(factorial(1000),
> > +                                factorial_tr_manual(1000),
> > +                                factorial_tr_automatic_1(1000),
> > +                                factorial_tr_automatic_2(1000))
> > Unit: microseconds
> >                            expr     min       lq     mean   median
> >                 factorial(1000) 756.357 810.4135 963.1040 856.3315
> >       factorial_tr_manual(1000) 104.838 119.7595 198.7347 129.0870
> >  factorial_tr_automatic_1(1000) 112.354 125.5145 211.6148 135.5255
> >  factorial_tr_automatic_2(1000) 461.015 544.7035 688.5988 565.3240
> >        uq      max neval
> >  945.3110 4149.099   100
> >  136.8200 4190.331   100
> >  152.9625 5944.312   100
> >  600.5235 7798.622   100
> >
> > The simple solution, of course, is to not do that, but then I can?t
> handle expressions inside calls to ?with?. And I would really like to,
> because then I can combine tail recursion with pattern matching.
> >
> > I can define linked lists and a length function on them like this:
> >
> > library(pmatch)
> > llist := NIL | CONS(car, cdr : llist)
> >
> > llength <- function(llist, acc = 0) {
> >     cases(llist,
> >           NIL -> acc,
> >           CONS(car, cdr) -> llength(cdr, acc + 1))
> > }
> >
> > The tail-recursion I get out of transforming this function looks like
> this:
> >
> > llength_tr <- function (llist, acc = 0) {
> >     .tailr_env <- rlang::get_env()
> >     callCC(function(escape) {
> >         repeat {
> >             if (!rlang::is_null(..match_env <- test_pattern(llist,
> >                                                             NIL)))
> >                 with(..match_env, escape(acc))
> >
> >             else if (!rlang::is_null(..match_env <-
> >                                      test_pattern(llist, CONS(car,
> cdr))))
> >                 with(..match_env, {
> >                     .tailr_env$.tailr_llist <- cdr
> >                     .tailr_env$.tailr_acc <- acc + 1
> >                     .tailr_env$llist <- .tailr_env$.tailr_llist
> >                     .tailr_env$acc <- .tailr_env$.tailr_acc
> >                 })
> >         }
> >     })
> > }
> >
> > Maybe not the prettiest code, but you are not supposed to actually see
> it, of course.
> >
> > There is not much gain in speed
> >
> > Unit: milliseconds
> >                    expr      min       lq     mean   median       uq
> >     llength(test_llist) 70.74605 76.08734 87.78418 85.81193 94.66378
> >  llength_tr(test_llist) 45.16946 51.56856 59.09306 57.00101 63.07044
> >       max neval
> >  182.4894   100
> >  166.6990   100
> >
> > but you don?t run out of stack space
> >
> > > llength(make_llist(1000))
> > Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?
> > Error during wrapup: C stack usage  7990648 is too close to the limit
> > > llength_tr(make_llist(1000))
> > [1] 1000
> >
> > I should be able to make the function go faster if I had a faster way of
> handling the variable assignments, but inside ?with?, I?m not sure how to
> do that?
> >
> > Any suggestions?
> >
> > Cheers
> >
> > On 11 Feb 2018, 16.48 +0100, Thomas Mailund <thomas.mailund at gmail.com>,
> wrote:
> > > Hi guys,
> > >
> > > I am working on some code for automatically translating recursive
> functions into looping functions to implemented tail-recursion
> optimisations. See https://github.com/mailund/tailr
> > >
> > > As a toy-example, consider the factorial function
> > >
> > > factorial <- function(n, acc = 1) {
> > > if (n <= 1) acc
> > > else factorial(n - 1, acc * n)
> > > }
> > >
> > > I can automatically translate this into the loop-version
> > >
> > > factorial_tr_1 <- function (n, acc = 1)
> > > {
> > > repeat {
> > > if (n <= 1)
> > > return(acc)
> > > else {
> > > .tailr_n <- n - 1
> > > .tailr_acc <- acc * acc
> > > n <- .tailr_n
> > > acc <- .tailr_acc
> > > next
> > > }
> > > }
> > > }
> > >
> > > which will run faster and not have problems with recursion depths.
> However, I?m not entirely happy with this version for two reasons: I am not
> happy with introducing the temporary variables and this rewrite will not
> work if I try to over-scope an evaluation context.
> > >
> > > I have two related questions, one related to parallel assignments ?
> i.e. expressions to variables so the expression uses the old variable
> values and not the new values until the assignments are all done ? and one
> related to restarting a loop from nested loops or from nested expressions
> in `with` expressions or similar.
> > >
> > > I can implement parallel assignment using something like
> rlang::env_bind:
> > >
> > > factorial_tr_2 <- function (n, acc = 1)
> > > {
> > > .tailr_env <- rlang::get_env()
> > > repeat {
> > > if (n <= 1)
> > > return(acc)
> > > else {
> > > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > > next
> > > }
> > > }
> > > }
> > >
> > > This reduces the number of additional variables I need to one, but is
> a couple of orders of magnitude slower than the first version.
> > >
> > > > microbenchmark::microbenchmark(factorial(100),
> > > + factorial_tr_1(100),
> > > + factorial_tr_2(100))
> > > Unit: microseconds
> > > expr min lq mean median uq max neval
> > > factorial(100) 53.978 60.543 77.76203 71.0635 85.947 180.251 100
> > > factorial_tr_1(100) 9.022 9.903 11.52563 11.0430 11.984 28.464 100
> > > factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463
> 8177.635 100
> > >
> > >
> > > Is there another way to do parallel assignments that doesn?t cost this
> much in running time?
> > >
> > > My other problem is the use of `next`. I would like to combine
> tail-recursion optimisation with pattern matching as in
> https://github.com/mailund/pmatch where I can, for example, define a
> linked list like this:
> > >
> > > devtools::install_github("mailund/pmatch?)
> > > library(pmatch)
> > > llist := NIL | CONS(car, cdr : llist)
> > >
> > > and define a function for computing the length of a list like this:
> > >
> > > list_length <- function(lst, acc = 0) {
> > > force(acc)
> > > cases(lst,
> > > NIL -> acc,
> > > CONS(car, cdr) -> list_length(cdr, acc + 1))
> > > }
> > >
> > > The `cases` function creates an environment that binds variables in a
> pattern-description that over-scopes the expression to the right of `->`,
> so the recursive call in this example have access to the variables `cdr`
> and `car`.
> > >
> > > I can transform a `cases` call to one that creates the environment
> containing the bound variables and then evaluate this using `eval` or
> `with`, but in either case, a call to `next` will not work in such a
> context. The expression will be evaluated inside `bind` or `with`, and not
> in the `list_lenght` function.
> > >
> > > A version that *will* work, is something like this
> > >
> > > factorial_tr_3 <- function (n, acc = 1)
> > > {
> > > .tailr_env <- rlang::get_env()
> > > .tailr_frame <- rlang::current_frame()
> > > repeat {
> > > if (n <= 1)
> > > rlang::return_from(.tailr_frame, acc)
> > > else {
> > > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > > rlang::return_to(.tailr_frame)
> > > }
> > > }
> > > }
> > >
> > > Here, again, for the factorial function since this is easier to follow
> than the list-length function.
> > >
> > > This solution will also work if you return values from inside loops,
> where `next` wouldn?t work either.
> > >
> > > Using `rlang::return_from` and `rlang::return_to` implements the right
> semantics, but costs me another order of magnitude in running time.
> > >
> > > microbenchmark::microbenchmark(factorial(100),
> > > factorial_tr_1(100),
> > > factorial_tr_2(100),
> > > factorial_tr_3(100))
> > > Unit: microseconds
> > > expr min lq mean median uq max neval
> > > factorial(100) 52.479 60.2640 93.43069 67.5130 83.925 2062.481 100
> > > factorial_tr_1(100) 8.875 9.6525 49.19595 10.6945 11.217 3818.823 100
> > > factorial_tr_2(100) 5296.350 5525.0745 5973.77664 5737.8730 6260.128
> 8471.301 100
> > > factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725
> 89859.169 171039.228 100
> > >
> > > I can live with the ?introducing extra variables? solution to parallel
> assignment, and I could hack my way out of using `with` or `bind` in
> rewriting `cases`, but restarting a `repeat` loop would really make for a
> nicer solution. I know that `goto` is considered harmful, but really, in
> this case, it is what I want.
> > >
> > > A `callCC` version also solves the problem
> > >
> > > factorial_tr_4 <- function(n, acc = 1) {
> > > function_body <- function(continuation) {
> > > if (n <= 1) {
> > > continuation(acc)
> > > } else {
> > > continuation(list("continue", n = n - 1, acc = acc * n))
> > > }
> > > }
> > > repeat {
> > > result <- callCC(function_body)
> > > if (is.list(result) && result[[1]] == "continue") {
> > > n <- result$n
> > > acc <- result$acc
> > > next
> > > } else {
> > > return(result)
> > > }
> > > }
> > > }
> > >
> > > But this requires that I know how to distinguish between a valid
> return value and a tag for ?next? and is still a lot slower than the `next`
> solution
> > >
> > > microbenchmark::microbenchmark(factorial(100),
> > > factorial_tr_1(100),
> > > factorial_tr_2(100),
> > > factorial_tr_3(100),
> > > factorial_tr_4(100))
> > > Unit: microseconds
> > > expr min lq mean median uq max neval
> > > factorial(100) 54.109 61.8095 81.33167 81.8785 89.748 243.554 100
> > > factorial_tr_1(100) 9.025 9.9035 11.38607 11.1990 12.008 22.375 100
> > > factorial_tr_2(100) 5272.524 5798.3965 6302.40467 6077.7180 6492.959
> 9967.237 100
> > > factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665
> 75405.054 203785.673 100
> > > factorial_tr_4(100) 270.978 302.7890 337.48763 313.9930 334.096
> 1425.702 100
> > >
> > > I don?t necessarily need the tail-recursion optimisation to be faster
> than the recursive version; just getting out of the problem of too deep
> recursions is a benefit, but I would rather not pay with an order of
> magnitude for it. I could, of course, try to handle cases that works with
> `next` in one way, and other cases using `callCC`, but I feel it should be
> possible with a version that handles all cases the same way.
> > >
> > > Is there any way to achieve this?
> > >
> > > Cheers
> > > Thomas
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thomas.mailund at gmail.com  Tue Feb 27 17:46:37 2018
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Tue, 27 Feb 2018 17:46:37 +0100
Subject: [R] Parallel assignments and goto
In-Reply-To: <CAGxFJbSfjVLLv2rwBXR4wwWSz+Yq3eFuLSc4U758u6REE8HbHQ@mail.gmail.com>
References: <60E1EC42-4070-431D-9621-D1204B3C5FC7@gmail.com>
 <160a872a-7d87-449b-b4c7-91590879ca69@Spark>
 <613f4787-8e86-4417-ba36-267c0599dc74@Spark>
 <CAGxFJbSfjVLLv2rwBXR4wwWSz+Yq3eFuLSc4U758u6REE8HbHQ@mail.gmail.com>
Message-ID: <1ae639bf-a5d1-4cb1-84c6-0828139b32c8@Spark>

I did try assign. That was the slowest version from what my profiling could tell, as far as I recall, which really surprised me. I had expected it to be the fastest. The second slowest was using the [[ operator on environments. Or it might be the reverse for those two. They were both slower than the other versions I posted here.

Cheers

On 27 Feb 2018, 17.16 +0100, Bert Gunter <bgunter.4567 at gmail.com>, wrote:
> No clue, but see ?assign perhaps if you have not done so already.
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> > On Tue, Feb 27, 2018 at 6:51 AM, Thomas Mailund <thomas.mailund at gmail.com> wrote:
> > > Interestingly, the <<- operator is also a lot faster than using a namespace explicitly, and only slightly slower than using <- with local variables, see below. But, surely, both must at some point insert values in a given environment ? either the local one, for <-, or an enclosing one, for <<- ? so I guess I am asking if there is a more low-level assignment operation I can get my hands on without diving into C?
> > >
> > >
> > > factorial <- function(n, acc = 1) {
> > > ? ? if (n == 1) acc
> > > ? ? else factorial(n - 1, n * acc)
> > > }
> > >
> > > factorial_tr_manual <- function (n, acc = 1)
> > > {
> > > ? ? repeat {
> > > ? ? ? ? if (n <= 1)
> > > ? ? ? ? ? ? return(acc)
> > > ? ? ? ? else {
> > > ? ? ? ? ? ? .tailr_n <- n - 1
> > > ? ? ? ? ? ? .tailr_acc <- acc * n
> > > ? ? ? ? ? ? n <- .tailr_n
> > > ? ? ? ? ? ? acc <- .tailr_acc
> > > ? ? ? ? ? ? next
> > > ? ? ? ? }
> > > ? ? }
> > > }
> > >
> > > factorial_tr_automatic_1 <- function(n, acc = 1) {
> > > ? ? .tailr_n <- n
> > > ? ? .tailr_acc <- acc
> > > ? ? callCC(function(escape) {
> > > ? ? ? ? repeat {
> > > ? ? ? ? ? ? n <- .tailr_n
> > > ? ? ? ? ? ? acc <- .tailr_acc
> > > ? ? ? ? ? ? if (n <= 1) {
> > > ? ? ? ? ? ? ? ? escape(acc)
> > > ? ? ? ? ? ? } else {
> > > ? ? ? ? ? ? ? ? .tailr_n <<- n - 1
> > > ? ? ? ? ? ? ? ? .tailr_acc <<- n * acc
> > > ? ? ? ? ? ? }
> > > ? ? ? ? }
> > > ? ? })
> > > }
> > >
> > > factorial_tr_automatic_2 <- function(n, acc = 1) {
> > > ? ? .tailr_env <- rlang::get_env()
> > > ? ? callCC(function(escape) {
> > > ? ? ? ? repeat {
> > > ? ? ? ? ? ? if (n <= 1) {
> > > ? ? ? ? ? ? ? ? escape(acc)
> > > ? ? ? ? ? ? } else {
> > > ? ? ? ? ? ? ? ? .tailr_env$.tailr_n <- n - 1
> > > ? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- n * acc
> > > ? ? ? ? ? ? ? ? .tailr_env$n <- .tailr_env$.tailr_n
> > > ? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
> > > ? ? ? ? ? ? }
> > > ? ? ? ? }
> > > ? ? })
> > > }
> > >
> > > microbenchmark::microbenchmark(factorial(1000),
> > > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_manual(1000),
> > > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_1(1000),
> > > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_2(1000))
> > > Unit: microseconds
> > > ? ? ? ? ? ? ? ? ? ? ? ? ? ?expr ? ? min ? ? ?lq ? ? ?mean ? median ? ? ? ?uq ? ? ?max neval
> > > ? ? ? ? ? ? ? ? factorial(1000) 884.137 942.060 1076.3949 977.6235 1042.5035 2889.779 ? 100
> > > ? ? ? factorial_tr_manual(1000) 110.215 116.919 ?130.2337 118.7350 ?122.7495 ?255.062 ? 100
> > > ?factorial_tr_automatic_1(1000) 179.897 183.437 ?212.8879 187.8250 ?195.7670 ?979.352 ? 100
> > > ?factorial_tr_automatic_2(1000) 508.353 534.328 ?601.9643 560.7830 ?587.8350 1424.260 ? 100
> > >
> > > Cheers
> > >
> > > On 26 Feb 2018, 21.12 +0100, Thomas Mailund <thomas.mailund at gmail.com>, wrote:
> > > > Following up on this attempt of implementing the tail-recursion optimisation ? now that I?ve finally had the chance to look at it again ? I find that non-local return implemented with callCC doesn?t actually incur much overhead once I do it more sensibly. I haven?t found a good way to handle parallel assignments that isn?t vastly slower than simply introducing extra variables, so I am going with that solution. However, I have now run into another problem involving those local variables ? and assigning to local variables in general.
> > > >
> > > > Consider again the factorial function and three different ways of implementing it using the tail recursion optimisation:
> > > >
> > > > factorial <- function(n, acc = 1) {
> > > > ? ? if (n == 1) acc
> > > > ? ? else factorial(n - 1, n * acc)
> > > > }
> > > >
> > > > factorial_tr_manual <- function (n, acc = 1)
> > > > {
> > > > ? ? repeat {
> > > > ? ? ? ? if (n <= 1)
> > > > ? ? ? ? ? ? return(acc)
> > > > ? ? ? ? else {
> > > > ? ? ? ? ? ? .tailr_n <- n - 1
> > > > ? ? ? ? ? ? .tailr_acc <- acc * n
> > > > ? ? ? ? ? ? n <- .tailr_n
> > > > ? ? ? ? ? ? acc <- .tailr_acc
> > > > ? ? ? ? ? ? next
> > > > ? ? ? ? }
> > > > ? ? }
> > > > }
> > > >
> > > > factorial_tr_automatic_1 <- function(n, acc = 1) {
> > > > ? ? callCC(function(escape) {
> > > > ? ? ? ? repeat {
> > > > ? ? ? ? ? ? if (n <= 1) {
> > > > ? ? ? ? ? ? ? ? escape(acc)
> > > > ? ? ? ? ? ? } else {
> > > > ? ? ? ? ? ? ? ? .tailr_n <- n - 1
> > > > ? ? ? ? ? ? ? ? .tailr_acc <- n * acc
> > > > ? ? ? ? ? ? ? ? n <- .tailr_n
> > > > ? ? ? ? ? ? ? ? acc <- .tailr_acc
> > > > ? ? ? ? ? ? }
> > > > ? ? ? ? }
> > > > ? ? })
> > > > }
> > > >
> > > > factorial_tr_automatic_2 <- function(n, acc = 1) {
> > > > ? ? .tailr_env <- rlang::get_env()
> > > > ? ? callCC(function(escape) {
> > > > ? ? ? ? repeat {
> > > > ? ? ? ? ? ? if (n <= 1) {
> > > > ? ? ? ? ? ? ? ? escape(acc)
> > > > ? ? ? ? ? ? } else {
> > > > ? ? ? ? ? ? ? ? .tailr_env$.tailr_n <- n - 1
> > > > ? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- n * acc
> > > > ? ? ? ? ? ? ? ? .tailr_env$n <- .tailr_env$.tailr_n
> > > > ? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
> > > > ? ? ? ? ? ? }
> > > > ? ? ? ? }
> > > > ? ? })
> > > > }
> > > >
> > > > The?factorial_tr_manual function is how I would implement the function manually while?factorial_tr_automatic_1 is what my package used to come up with. It handles non-local returns, because this is something I need in general. Finally,?factorial_tr_automatic_2 accesses the local variables explicitly through the environment, which is what my package currently produces.
> > > >
> > > > The difference between supporting non-local returns and not is tiny, but explicitly accessing variables through their environment costs me about a factor of five ? something that surprised me.
> > > >
> > > > > microbenchmark::microbenchmark(factorial(1000),
> > > > + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_manual(1000),
> > > > + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_1(1000),
> > > > + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?factorial_tr_automatic_2(1000))
> > > > Unit: microseconds
> > > > ? ? ? ? ? ? ? ? ? ? ? ? ? ?expr ? ? min ? ? ? lq ? ? mean ? median
> > > > ? ? ? ? ? ? ? ? factorial(1000) 756.357 810.4135 963.1040 856.3315
> > > > ? ? ? factorial_tr_manual(1000) 104.838 119.7595 198.7347 129.0870
> > > > ?factorial_tr_automatic_1(1000) 112.354 125.5145 211.6148 135.5255
> > > > ?factorial_tr_automatic_2(1000) 461.015 544.7035 688.5988 565.3240
> > > > ? ? ? ?uq ? ? ?max neval
> > > > ?945.3110 4149.099 ? 100
> > > > ?136.8200 4190.331 ? 100
> > > > ?152.9625 5944.312 ? 100
> > > > ?600.5235 7798.622 ? 100
> > > >
> > > > The simple solution, of course, is to not do that, but then I can?t handle expressions inside calls to ?with?. And I would really like to, because then I can combine tail recursion with pattern matching.
> > > >
> > > > I can define linked lists and a length function on them like this:
> > > >
> > > > library(pmatch)
> > > > llist := NIL | CONS(car, cdr : llist)
> > > >
> > > > llength <- function(llist, acc = 0) {
> > > > ? ? cases(llist,
> > > > ? ? ? ? ? NIL -> acc,
> > > > ? ? ? ? ? CONS(car, cdr) -> llength(cdr, acc + 1))
> > > > }
> > > >
> > > > The tail-recursion I get out of transforming this function looks like this:
> > > >
> > > > llength_tr <- function (llist, acc = 0) {
> > > > ? ? .tailr_env <- rlang::get_env()
> > > > ? ? callCC(function(escape) {
> > > > ? ? ? ? repeat {
> > > > ? ? ? ? ? ? if (!rlang::is_null(..match_env <- test_pattern(llist,
> > > > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NIL)))
> > > > ? ? ? ? ? ? ? ? with(..match_env, escape(acc))
> > > >
> > > > ? ? ? ? ? ? else if (!rlang::is_null(..match_env <-
> > > > ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?test_pattern(llist, CONS(car, cdr))))
> > > > ? ? ? ? ? ? ? ? with(..match_env, {
> > > > ? ? ? ? ? ? ? ? ? ? .tailr_env$.tailr_llist <- cdr
> > > > ? ? ? ? ? ? ? ? ? ? .tailr_env$.tailr_acc <- acc + 1
> > > > ? ? ? ? ? ? ? ? ? ? .tailr_env$llist <- .tailr_env$.tailr_llist
> > > > ? ? ? ? ? ? ? ? ? ? .tailr_env$acc <- .tailr_env$.tailr_acc
> > > > ? ? ? ? ? ? ? ? })
> > > > ? ? ? ? }
> > > > ? ? })
> > > > }
> > > >
> > > > Maybe not the prettiest code, but you are not supposed to actually see it, of course.
> > > >
> > > > There is not much gain in speed
> > > >
> > > > Unit: milliseconds
> > > > ? ? ? ? ? ? ? ? ? ?expr ? ? ?min ? ? ? lq ? ? mean ? median ? ? ? uq
> > > > ? ? llength(test_llist) 70.74605 76.08734 87.78418 85.81193 94.66378
> > > > ?llength_tr(test_llist) 45.16946 51.56856 59.09306 57.00101 63.07044
> > > > ? ? ? max neval
> > > > ?182.4894 ? 100
> > > > ?166.6990 ? 100
> > > >
> > > > but you don?t run out of stack space
> > > >
> > > > > llength(make_llist(1000))
> > > > Error: evaluation nested too deeply: infinite recursion / options(expressions=)?
> > > > Error during wrapup: C stack usage ?7990648 is too close to the limit
> > > > > llength_tr(make_llist(1000))
> > > > [1] 1000
> > > >
> > > > I should be able to make the function go faster if I had a faster way of handling the variable assignments, but inside ?with?, I?m not sure how to do that?
> > > >
> > > > Any suggestions?
> > > >
> > > > Cheers
> > > >
> > > > On 11 Feb 2018, 16.48 +0100, Thomas Mailund <thomas.mailund at gmail.com>, wrote:
> > > > > Hi guys,
> > > > >
> > > > > I am working on some code for automatically translating recursive functions into looping functions to implemented tail-recursion optimisations. See https://github.com/mailund/tailr
> > > > >
> > > > > As a toy-example, consider the factorial function
> > > > >
> > > > > factorial <- function(n, acc = 1) {
> > > > > if (n <= 1) acc
> > > > > else factorial(n - 1, acc * n)
> > > > > }
> > > > >
> > > > > I can automatically translate this into the loop-version
> > > > >
> > > > > factorial_tr_1 <- function (n, acc = 1)
> > > > > {
> > > > > repeat {
> > > > > if (n <= 1)
> > > > > return(acc)
> > > > > else {
> > > > > .tailr_n <- n - 1
> > > > > .tailr_acc <- acc * acc
> > > > > n <- .tailr_n
> > > > > acc <- .tailr_acc
> > > > > next
> > > > > }
> > > > > }
> > > > > }
> > > > >
> > > > > which will run faster and not have problems with recursion depths. However, I?m not entirely happy with this version for two reasons: I am not happy with introducing the temporary variables and this rewrite will not work if I try to over-scope an evaluation context.
> > > > >
> > > > > I have two related questions, one related to parallel assignments ? i.e. expressions to variables so the expression uses the old variable values and not the new values until the assignments are all done ? and one related to restarting a loop from nested loops or from nested expressions in `with` expressions or similar.
> > > > >
> > > > > I can implement parallel assignment using something like rlang::env_bind:
> > > > >
> > > > > factorial_tr_2 <- function (n, acc = 1)
> > > > > {
> > > > > .tailr_env <- rlang::get_env()
> > > > > repeat {
> > > > > if (n <= 1)
> > > > > return(acc)
> > > > > else {
> > > > > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > > > > next
> > > > > }
> > > > > }
> > > > > }
> > > > >
> > > > > This reduces the number of additional variables I need to one, but is a couple of orders of magnitude slower than the first version.
> > > > >
> > > > > > microbenchmark::microbenchmark(factorial(100),
> > > > > + factorial_tr_1(100),
> > > > > + factorial_tr_2(100))
> > > > > Unit: microseconds
> > > > > expr min lq mean median uq max neval
> > > > > factorial(100) 53.978 60.543 77.76203 71.0635 85.947 180.251 100
> > > > > factorial_tr_1(100) 9.022 9.903 11.52563 11.0430 11.984 28.464 100
> > > > > factorial_tr_2(100) 5870.565 6109.905 6534.13607 6320.4830 6756.463 8177.635 100
> > > > >
> > > > >
> > > > > Is there another way to do parallel assignments that doesn?t cost this much in running time?
> > > > >
> > > > > My other problem is the use of `next`. I would like to combine tail-recursion optimisation with pattern matching as in https://github.com/mailund/pmatch where I can, for example, define a linked list like this:
> > > > >
> > > > > devtools::install_github("mailund/pmatch?)
> > > > > library(pmatch)
> > > > > llist := NIL | CONS(car, cdr : llist)
> > > > >
> > > > > and define a function for computing the length of a list like this:
> > > > >
> > > > > list_length <- function(lst, acc = 0) {
> > > > > force(acc)
> > > > > cases(lst,
> > > > > NIL -> acc,
> > > > > CONS(car, cdr) -> list_length(cdr, acc + 1))
> > > > > }
> > > > >
> > > > > The `cases` function creates an environment that binds variables in a pattern-description that over-scopes the expression to the right of `->`, so the recursive call in this example have access to the variables `cdr` and `car`.
> > > > >
> > > > > I can transform a `cases` call to one that creates the environment containing the bound variables and then evaluate this using `eval` or `with`, but in either case, a call to `next` will not work in such a context. The expression will be evaluated inside `bind` or `with`, and not in the `list_lenght` function.
> > > > >
> > > > > A version that *will* work, is something like this
> > > > >
> > > > > factorial_tr_3 <- function (n, acc = 1)
> > > > > {
> > > > > .tailr_env <- rlang::get_env()
> > > > > .tailr_frame <- rlang::current_frame()
> > > > > repeat {
> > > > > if (n <= 1)
> > > > > rlang::return_from(.tailr_frame, acc)
> > > > > else {
> > > > > rlang::env_bind(.tailr_env, n = n - 1, acc = acc * n)
> > > > > rlang::return_to(.tailr_frame)
> > > > > }
> > > > > }
> > > > > }
> > > > >
> > > > > Here, again, for the factorial function since this is easier to follow than the list-length function.
> > > > >
> > > > > This solution will also work if you return values from inside loops, where `next` wouldn?t work either.
> > > > >
> > > > > Using `rlang::return_from` and `rlang::return_to` implements the right semantics, but costs me another order of magnitude in running time.
> > > > >
> > > > > microbenchmark::microbenchmark(factorial(100),
> > > > > factorial_tr_1(100),
> > > > > factorial_tr_2(100),
> > > > > factorial_tr_3(100))
> > > > > Unit: microseconds
> > > > > expr min lq mean median uq max neval
> > > > > factorial(100) 52.479 60.2640 93.43069 67.5130 83.925 2062.481 100
> > > > > factorial_tr_1(100) 8.875 9.6525 49.19595 10.6945 11.217 3818.823 100
> > > > > factorial_tr_2(100) 5296.350 5525.0745 5973.77664 5737.8730 6260.128 8471.301 100
> > > > > factorial_tr_3(100) 77554.457 80757.0905 87307.28737 84004.0725 89859.169 171039.228 100
> > > > >
> > > > > I can live with the ?introducing extra variables? solution to parallel assignment, and I could hack my way out of using `with` or `bind` in rewriting `cases`, but restarting a `repeat` loop would really make for a nicer solution. I know that `goto` is considered harmful, but really, in this case, it is what I want.
> > > > >
> > > > > A `callCC` version also solves the problem
> > > > >
> > > > > factorial_tr_4 <- function(n, acc = 1) {
> > > > > function_body <- function(continuation) {
> > > > > if (n <= 1) {
> > > > > continuation(acc)
> > > > > } else {
> > > > > continuation(list("continue", n = n - 1, acc = acc * n))
> > > > > }
> > > > > }
> > > > > repeat {
> > > > > result <- callCC(function_body)
> > > > > if (is.list(result) && result[[1]] == "continue") {
> > > > > n <- result$n
> > > > > acc <- result$acc
> > > > > next
> > > > > } else {
> > > > > return(result)
> > > > > }
> > > > > }
> > > > > }
> > > > >
> > > > > But this requires that I know how to distinguish between a valid return value and a tag for ?next? and is still a lot slower than the `next` solution
> > > > >
> > > > > microbenchmark::microbenchmark(factorial(100),
> > > > > factorial_tr_1(100),
> > > > > factorial_tr_2(100),
> > > > > factorial_tr_3(100),
> > > > > factorial_tr_4(100))
> > > > > Unit: microseconds
> > > > > expr min lq mean median uq max neval
> > > > > factorial(100) 54.109 61.8095 81.33167 81.8785 89.748 243.554 100
> > > > > factorial_tr_1(100) 9.025 9.9035 11.38607 11.1990 12.008 22.375 100
> > > > > factorial_tr_2(100) 5272.524 5798.3965 6302.40467 6077.7180 6492.959 9967.237 100
> > > > > factorial_tr_3(100) 66186.080 72336.2810 76480.75172 73632.9665 75405.054 203785.673 100
> > > > > factorial_tr_4(100) 270.978 302.7890 337.48763 313.9930 334.096 1425.702 100
> > > > >
> > > > > I don?t necessarily need the tail-recursion optimisation to be faster than the recursive version; just getting out of the problem of too deep recursions is a benefit, but I would rather not pay with an order of magnitude for it. I could, of course, try to handle cases that works with `next` in one way, and other cases using `callCC`, but I feel it should be possible with a version that handles all cases the same way.
> > > > >
> > > > > Is there any way to achieve this?
> > > > >
> > > > > Cheers
> > > > > Thomas
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > >
> > > ? ? ? ? [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From reichmanj at sbcglobal.net  Tue Feb 27 18:07:28 2018
From: reichmanj at sbcglobal.net (JEFFERY REICHMAN)
Date: Tue, 27 Feb 2018 17:07:28 +0000 (UTC)
Subject: [R] OpenRTB Data
References: <279830930.6469389.1519751248308.ref@mail.yahoo.com>
Message-ID: <279830930.6469389.1519751248308@mail.yahoo.com>

R Forum

Are there any R libraries designed specifically for RTB (Real Time Bidding) data?

Jeff Reichman


From falshawy at gmail.com  Tue Feb 27 23:55:29 2018
From: falshawy at gmail.com (Firas ALSHAWY)
Date: Wed, 28 Feb 2018 00:55:29 +0200
Subject: [R] Help
Message-ID: <CAMfaEiH9hsCnD75uWOhRai6GON610q7WLWvV_FPYhTx4a0Z3eg@mail.gmail.com>

Dear
I hope you are wery well when read this e-mail.My name is Firas ALSHAWY and
I am a Phd student in the high Institute of marine research - tishreen
university- Syria
I would like to want some help my in my research, I have data ( length -
weight - gonad weight - fishing mortality - natural mortality - the number
of fish-temperature of water, maximum age ) , I would like to use the
package ( stock synthesis) in R program but I don't know how I can use it .
I would like to ask you to help my in this subject and if this package not
useful what I can do or use any other package.
thank you
Firas



?

	[[alternative HTML version deleted]]


From richard.a.student at gmail.com  Tue Feb 27 23:49:26 2018
From: richard.a.student at gmail.com (Richard Student)
Date: Tue, 27 Feb 2018 17:49:26 -0500
Subject: [R] File system issue since upgrading macOS to High Sierra
Message-ID: <CAJEoHig=peDoxWdRDeekZ5T5Z-kwVp-speRyoO=F46K9aCfDKg@mail.gmail.com>

Hi,

Since upgrading macOS High Sierra, R will stop responding, requiring me to
force R to quit, when I am trying to open a script using File -> Open
Document.

I don't have any problems opening files by double-clicking them in Finder.

Sometimes R gives me the message in the attached screenshot:


Any suggestions?

-Rich

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2018-02-27 at 5.25.45 PM.png
Type: image/png
Size: 67050 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180227/edcf49e5/attachment.png>

From yddg at yahoo.dk  Wed Feb 28 08:48:20 2018
From: yddg at yahoo.dk (mathias svane hansen)
Date: Wed, 28 Feb 2018 07:48:20 +0000 (UTC)
Subject: [R] Words near one another.
References: <287291262.10660072.1519804100088.ref@mail.yahoo.com>
Message-ID: <287291262.10660072.1519804100088@mail.yahoo.com>

Hi everyone. 

I'm very new to R, so please forgive me, if I ask the obvious. I am currently using R to fulltextsearches in PDF files, using the PDFsearch package and it is working quite well. My question is however if it is possible search for words near one another fx "house" & "Busstop". 

Thank you. 

M. S. Hansen


From petr.pikal at precheza.cz  Wed Feb 28 10:21:09 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 28 Feb 2018 09:21:09 +0000
Subject: [R] Help
In-Reply-To: <CAMfaEiH9hsCnD75uWOhRai6GON610q7WLWvV_FPYhTx4a0Z3eg@mail.gmail.com>
References: <CAMfaEiH9hsCnD75uWOhRai6GON610q7WLWvV_FPYhTx4a0Z3eg@mail.gmail.com>
Message-ID: <a134a44bc1274c369013ef452428d0c2@SRVEXCHCM1301.precheza.cz>

Hi Firas

I would strongly recommend if you go throuugh R intro, which shall be in doc folder where you installed R. R is not extremely complicated but you need to understand at least what are objects, something about how they behave and how you can operate with them and of course how to install and use packages and functions from packages.

Regarding your question about stock syntheses you prabably refer to package ss3sim. I am not familiar with it and on quick glance it seems to me it is quite complicated and requires good knowledge of the problem (which I do not have). But it comes with pretty extensive tutorial with examples so if you understand the topic you probably can smoothly use it.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Firas
> ALSHAWY
> Sent: Tuesday, February 27, 2018 11:55 PM
> To: r-help at r-project.org
> Subject: [R] Help
>
> Dear
> I hope you are wery well when read this e-mail.My name is Firas ALSHAWY and
> I am a Phd student in the high Institute of marine research - tishreen
> university- Syria
> I would like to want some help my in my research, I have data ( length - weight
> - gonad weight - fishing mortality - natural mortality - the number of fish-
> temperature of water, maximum age ) , I would like to use the package ( stock
> synthesis) in R program but I don't know how I can use it .
> I would like to ask you to help my in this subject and if this package not useful
> what I can do or use any other package.
> thank you
> Firas
>
>
>
> ?
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From esawiek at gmail.com  Wed Feb 28 15:36:40 2018
From: esawiek at gmail.com (Ek Esawi)
Date: Wed, 28 Feb 2018 09:36:40 -0500
Subject: [R] 
 Aggregate over multiple and unequal column length data frames
In-Reply-To: <CAGxFJbQK5f6CcU9tB9F_u8xsf9-E+D3J2et6viOBLKb61ycb+Q@mail.gmail.com>
References: <CA+ZkTxt3Wd=sMAh4R-rFCOJpaOer10Pj+1xi8_+cJY8ZDYZjEQ@mail.gmail.com>
 <4dc6702440764e7c9c826d0b603e3a6f@SRVEXCHCM1301.precheza.cz>
 <CA+ZkTxs09FzoCC=on-2x7LrPuUehFYxpttDt2x+qMqZkpQSDMg@mail.gmail.com>
 <CAGxFJbQK5f6CcU9tB9F_u8xsf9-E+D3J2et6viOBLKb61ycb+Q@mail.gmail.com>
Message-ID: <CA+ZkTxsgBTWGscuHs0vztyHW0S=qqtooMuBB60am=MHTU0RV5Q@mail.gmail.com>

Thank you again Pikal and Bert. Using lapply, as Bert suggested, was
the first thing that i thought of dealing with this question and  was
mentioned in my original posting. I just did not know how to implement
it to get the results/form i want. Below is what i did but could not
get it to give me the results as i want which was given on Pikal's
answer.

nlist <- list(df1$col2,df2$col2, df3$col2)

lapply(nlist, function(x) table(x))
[[1]]
x
aa bb cc dd
 2  1  1  1

[[2]]
x
bb cc
 3  1

[[3]]
x
aa
 2


From bgunter.4567 at gmail.com  Wed Feb 28 16:34:00 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Feb 2018 07:34:00 -0800
Subject: [R] File system issue since upgrading macOS to High Sierra
In-Reply-To: <CAJEoHig=peDoxWdRDeekZ5T5Z-kwVp-speRyoO=F46K9aCfDKg@mail.gmail.com>
References: <CAJEoHig=peDoxWdRDeekZ5T5Z-kwVp-speRyoO=F46K9aCfDKg@mail.gmail.com>
Message-ID: <CAGxFJbSAvg+=h3vvsuD3WM6fv0w4EMoq+e3FQw76wLYfdxQSBA@mail.gmail.com>

> Any suggestions?
>

Post on the r-sig-mac list if you do not get a satisfactory reply here.

-- Bert


>
> -Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


