From tr@xp|@yer @end|ng |rom gm@||@com  Sun Sep  1 21:06:01 2019
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Sun, 1 Sep 2019 21:06:01 +0200
Subject: [R] Reading large files with R
Message-ID: <CAGAA5behB7bzkxjr0JeRGYLWjfQYCDwju=PQ5h_zTRsC+qgyCg@mail.gmail.com>

Hi,

  I am trying to read yaml-file which is not so large (7 GB) and I have
plenty of memory.
However I get this error:

$  R --version
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

library(yaml)
keys <- read_yaml("/data/gpg/gpg-keys.yaml")

Error in paste(readLines(file), collapse = "\n") :
  result would exceed 2^31-1 bytes

2^31-1 is only 2GB.

Please advise,

Regards
Martin

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Sep  1 21:53:55 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 1 Sep 2019 15:53:55 -0400
Subject: [R] Reading large files with R
In-Reply-To: <CAGAA5behB7bzkxjr0JeRGYLWjfQYCDwju=PQ5h_zTRsC+qgyCg@mail.gmail.com>
References: <CAGAA5behB7bzkxjr0JeRGYLWjfQYCDwju=PQ5h_zTRsC+qgyCg@mail.gmail.com>
Message-ID: <e8e98374-6521-5e48-0ffd-c669f4cf4173@gmail.com>

On 01/09/2019 3:06 p.m., Martin M?ller Skarbiniks Pedersen wrote:
> Hi,
> 
>    I am trying to read yaml-file which is not so large (7 GB) and I have
> plenty of memory.
> However I get this error:
> 
> $  R --version
> R version 3.6.1 (2019-07-05) -- "Action of the Toes"
> Copyright (C) 2019 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> library(yaml)
> keys <- read_yaml("/data/gpg/gpg-keys.yaml")
> 
> Error in paste(readLines(file), collapse = "\n") :
>    result would exceed 2^31-1 bytes
> 
> 2^31-1 is only 2GB.
> 
> Please advise,
> 
> Regards
> Martin

Individual elements in character vectors have a size limit of 2^31-1. 
The read_yaml() function is putting the whole file into one element, and 
that's failing.

You probably have a couple of choices:

  - Rewrite read_yaml() so it doesn't try to do that.  This is likely 
hard, because most of the work is being done by a C routine, but it's 
conceivable you could use the stringi::stri_read_raw function to do the 
reading, and convince the C routine to handle the raw value instead of a 
character value.

  - Find a way to split up your file into smaller pieces.

Duncan Murdoch


From tr@xp|@yer @end|ng |rom gm@||@com  Sun Sep  1 23:53:47 2019
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Sun, 1 Sep 2019 23:53:47 +0200
Subject: [R] Reading large files with R
In-Reply-To: <e8e98374-6521-5e48-0ffd-c669f4cf4173@gmail.com>
References: <CAGAA5behB7bzkxjr0JeRGYLWjfQYCDwju=PQ5h_zTRsC+qgyCg@mail.gmail.com>
 <e8e98374-6521-5e48-0ffd-c669f4cf4173@gmail.com>
Message-ID: <CAGAA5bdGsxzSFHDmVbj7gv1p=rNNep-nojyUm+6J_zk-BT2vdQ@mail.gmail.com>

On Sun, 1 Sep 2019 at 21:53, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 01/09/2019 3:06 p.m., Martin M?ller Skarbiniks Pedersen wrote:
> > Hi,
> >
> >    I am trying to read yaml-file which is not so large (7 GB) and I have
> > plenty of memory.
>
>

> Individual elements in character vectors have a size limit of 2^31-1.
> The read_yaml() function is putting the whole file into one element, and
> that's failing.
>
>
Oh. I didn't know that. But ok, why would anyone create a
a single character vector so big ...

You probably have a couple of choices:
>
>   - Rewrite read_yaml() so it doesn't try to do that.  This is likely
> hard, because most of the work is being done by a C routine, but it's
> conceivable you could use the stringi::stri_read_raw function to do the
> reading, and convince the C routine to handle the raw value instead of a
> character value.
>

I actually might do that in the future.

  - Find a way to split up your file into smaller pieces.
>

Yes, that will be my first solution. Most YAML is easier to parse without
pasting all lines together (crazy!)


> Duncan Murdoch
>

Thanks for pointing me in the right direction.

/Martin

	[[alternative HTML version deleted]]


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Mon Sep  2 12:30:19 2019
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Mon, 2 Sep 2019 12:30:19 +0200
Subject: [R] Course: Introduction to regression models with spatial and
 temporal correlation using R-INLA
Message-ID: <3ef8e482-3209-88b0-cf84-da7e4144dee5@highstat.com>

We would like to announce the following 3 statistics courses.

Course: Introduction to regression models with spatial and temporal 
correlation using R-INLA

Location: Canada and The Netherlands


Where and when:

1. Introduction to regression models with spatial and temporal 
correlation using R-INLA. NIOZ, Texel, The Netherlands. 23-27 September 
2019

2. Introduction to regression models with spatial and spatial-temporal 
correlation using R-INLA. Burlington (close to Toronto), ON, Canada. 28 
October - 1 November 2019


Course website: http://highstat.com/index.php/courses-upcoming



Kind regards,


Alain Zuur


-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com


From m||uj|@b @end|ng |rom gm@||@com  Mon Sep  2 19:34:12 2019
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Mon, 2 Sep 2019 19:34:12 +0200
Subject: [R] Sequential date by group
Message-ID: <CAMLwc7N=PShY-OJwNXQ7_h=0OSULwv1wYBYvGChszKcY4Kw5TQ@mail.gmail.com>

Dear all,

I have a panel data with a large number of groups and the cumulative number
of months (1 - 372) for January 1995 to December 2005. My goal is to
extract the corresponding month and year for each observation.

I tried the following;

###
x %>%
  group_by(id) %>%
  do( data.frame(., Date= seq(.$startdate,
                              as.Date('1975-01-01'), by = '1 month')))

However, I get the following error;

###
Error in seq.default(.$startdate, as.Date("1975-01-01"), by = "1 month") :
  'from' must be of length 1

Essentially, I want to convert the month number (1-372) to January 1975 to
December 2005 by ID. Is that possible? Any help will be highly appreciated.

### Data ###
x <- structure(list(id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L), month =
c(1L,
2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), startdate = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1975-01-01", class = "factor"),
    enddate = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
"2005-12-31", class = "factor")), class = "data.frame", row.names = c(NA,
-9L))

Cross-posted in Statalist - however, Stata seems to have a very inflexible
date-time structure.

Best regards,

Milu

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Sep  2 20:28:23 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 2 Sep 2019 21:28:23 +0300
Subject: [R] Sequential date by group
In-Reply-To: <CAMLwc7N=PShY-OJwNXQ7_h=0OSULwv1wYBYvGChszKcY4Kw5TQ@mail.gmail.com>
References: <CAMLwc7N=PShY-OJwNXQ7_h=0OSULwv1wYBYvGChszKcY4Kw5TQ@mail.gmail.com>
Message-ID: <CAGgJW76dVOE17+g1zd1_SHxNmKtsjBw+wgh5EEVitq+UYhZSJg@mail.gmail.com>

dtV <- seq(from=as.Date("1975-01-01"),by='1 month',length=372)
x$dt <- dtV[x$id]

HTH,
Eric


On Mon, Sep 2, 2019 at 8:36 PM Miluji Sb <milujisb at gmail.com> wrote:

> Dear all,
>
> I have a panel data with a large number of groups and the cumulative number
> of months (1 - 372) for January 1995 to December 2005. My goal is to
> extract the corresponding month and year for each observation.
>
> I tried the following;
>
> ###
> x %>%
>   group_by(id) %>%
>   do( data.frame(., Date= seq(.$startdate,
>                               as.Date('1975-01-01'), by = '1 month')))
>
> However, I get the following error;
>
> ###
> Error in seq.default(.$startdate, as.Date("1975-01-01"), by = "1 month") :
>   'from' must be of length 1
>
> Essentially, I want to convert the month number (1-372) to January 1975 to
> December 2005 by ID. Is that possible? Any help will be highly appreciated.
>
> ### Data ###
> x <- structure(list(id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L), month =
> c(1L,
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), startdate = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1975-01-01", class = "factor"),
>     enddate = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
> "2005-12-31", class = "factor")), class = "data.frame", row.names = c(NA,
> -9L))
>
> Cross-posted in Statalist - however, Stata seems to have a very inflexible
> date-time structure.
>
> Best regards,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep  3 00:51:51 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 2 Sep 2019 15:51:51 -0700 (PDT)
Subject: [R] Sequential date by group
In-Reply-To: <CAMLwc7N=PShY-OJwNXQ7_h=0OSULwv1wYBYvGChszKcY4Kw5TQ@mail.gmail.com>
References: <CAMLwc7N=PShY-OJwNXQ7_h=0OSULwv1wYBYvGChszKcY4Kw5TQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1909021519390.78319@pedal.dcn.davis.ca.us>

Your sample data has startdate and enddate columns as though these values 
might vary throughout the data set, but your description suggests that 
those values are fixed for the whole dataset.

If those values are really constant, then

x$Year <- 1995L + 12 * ( ( x$month - 1L ) %/% 12L )
x$Month <- ( x$month - 1L ) %% 12L + 1

should be enough.

If in fact your startdate can be different for different IDs, then you 
would need to wrap this up a bit:

############ base R
x$startdate <- as.Date( as.character( x$startdate ) )
x$Y <- as.integer( format( DF$startdate, format = "%Y" ) )
xlist <- split( x, x$id )
xlist1 <- lapply( xlist
                 , FUN = function( DF ) {
                     DF$Year <- Y + 12 * ( ( DF$month - 1L ) %/% 12L )
                     DF$Month <- ( DF$month - 1L ) %% 12L + 1
                     DF
                   }
                 )
x1 <- unsplit( xlist1, x$id )

###### dplyr
library(dplyr)
x2 <- (   x
       %>% mutate( Y = as.integer( format( startdate, format = "%Y" ) ) )
       %>% group_by( id )
       %>% mutate( Year = Y + 12L * ( ( month - 1L ) %/% 12L )
                 , Month = ( month - 1L ) %% 12L + 1L
                 )
       %>% ungroup
       )
#########

On Mon, 2 Sep 2019, Miluji Sb wrote:

> Dear all,
>
> I have a panel data with a large number of groups and the cumulative number
> of months (1 - 372) for January 1995 to December 2005. My goal is to
> extract the corresponding month and year for each observation.
>
> I tried the following;
>
> ###
> x %>%
>  group_by(id) %>%
>  do( data.frame(., Date= seq(.$startdate,
>                              as.Date('1975-01-01'), by = '1 month')))
>
> However, I get the following error;
>
> ###
> Error in seq.default(.$startdate, as.Date("1975-01-01"), by = "1 month") :
>  'from' must be of length 1
>
> Essentially, I want to convert the month number (1-372) to January 1975 to
> December 2005 by ID. Is that possible? Any help will be highly appreciated.
>
> ### Data ###
> x <- structure(list(id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L), month =
> c(1L,
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), startdate = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1975-01-01", class = "factor"),
>    enddate = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
> "2005-12-31", class = "factor")), class = "data.frame", row.names = c(NA,
> -9L))
>
> Cross-posted in Statalist - however, Stata seems to have a very inflexible
> date-time structure.
>
> Best regards,
>
> Milu
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From chr|@@@ @end|ng |rom med@um|ch@edu  Tue Sep  3 14:14:41 2019
From: chr|@@@ @end|ng |rom med@um|ch@edu (Andrews, Chris)
Date: Tue, 3 Sep 2019 12:14:41 +0000
Subject: [R] Efficient way to update a survival model
In-Reply-To: <VI1PR04MB5726E7FFAB286C08FFEA7D86BABD0@VI1PR04MB5726.eurprd04.prod.outlook.com>
References: <VI1PR04MB5726D4BB6BF9B179B03F1FB1BAA30@VI1PR04MB5726.eurprd04.prod.outlook.com>,
 <20190829085410.Horde.cR3kDdYBZGYzoxbukl-m7xZ@webmail.unipa.it>,
 <VI1PR04MB57262BC7EFF56B29A668A88DBAA20@VI1PR04MB5726.eurprd04.prod.outlook.com>
 <VI1PR04MB5726B07EAE5864C32974CFAFBABD0@VI1PR04MB5726.eurprd04.prod.outlook.com>,
 <2e9ea8fb168f46a78bb704bc3ba65b81@med.umich.edu>,
 <VI1PR04MB5726E7FFAB286C08FFEA7D86BABD0@VI1PR04MB5726.eurprd04.prod.outlook.com>
Message-ID: <91c546469e9c48a085fe7aba297f8e95@med.umich.edu>

library("survival")
set.seed(1)
v <- runif(nrow(pbc), min = 0, max = 2)
Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)

Cox <- vector("list", 10)
for (k in 1:10) {
        form <- as.formula(sprintf(". ~ . + cos(%d * v)", k))
        Cox[[k]] <- update(if (k==1) Cox0 else Cox[[k-1]], form)
}
________________________________________
From: Frank S. <f_j_rod at hotmail.com>
Sent: Friday, August 30, 2019 6:36:39 PM
To: Andrews, Chris
Cc: r-help at r-project.org
Subject: RE: [R] Efficient way to update a survival model

External Email - Use Caution
Chris, thank you for your elegant solution!

Just one minor question:
I wonder how to include within the loop of your solution the 10 models, that is, writing
for (k in 1:10) so that you can get {Cox[[1]], ..., Cox[[10]]}. However, I'm aware that some
change has to be done due to the fact that, when computing Cox[[1]], the term Cox[[k -1]]
does not exist. Is it possible to perform some "trick" (e.g. re-indexing) in order to achieve this?

Best,

Frank
________________________________
De: Andrews, Chris <chrisaa at med.umich.edu>
Enviado: viernes, 30 de agosto de 2019 15:08
Para: Frank S. <f_j_rod at hotmail.com>; Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
Cc: r-help at r-project.org <r-help at r-project.org>
Asunto: RE: [R] Efficient way to update a survival model

The updated formula needs to have a different term rather than cos(k * v) every time.  Here is one way to explicitly change the formula.

library("survival")
set.seed(1)
v <- runif(nrow(pbc), min = 0, max = 2)
Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)

Cox <- vector("list", 10)
Cox[[1]] <- update(Cox0, . ~ . + cos(1 * v))
for (k in 2:10) {
        form <- as.formula(sprintf(". ~ . + cos(%d * v)", k))
        Cox[[k]] <- update(Cox[[k-1]], form)
}

Cox

-----Original Message-----
From: Frank S. [mailto:f_j_rod at hotmail.com]
Sent: Friday, August 30, 2019 5:54 AM
To: Vito Michele Rosario Muggeo
Cc: r-help at r-project.org
Subject: Re: [R] Efficient way to update a survival model

Hi everyone,

Vito, perhaps my previous mail was not clear.  It is true that I used a loop, but the key point is that such a loop
cannot compute the desired result. For example, for k = 3 the following loop

Cox <- list()
Cox[[1]] <- coxph(Surv(time,status == 2) ~ v + cos(v), data =  pbc)
for (k in 2:10) {
  Cox[[k]] <- update(Cox[[k-1]], . ~ . + cos(k * v), data =  pbc)
}

leads to a model Cox[[3]] which accounts for terms {v, cos(v), cos(3*v)}, but does not include the term cos(2*v).
I think that this could be one way to solve my question:

library("survival")
set.seed(1)
v <- runif(nrow(pbc), min = 0, max = 2)
Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
k.max <- 9
Z <- outer(v, 1:k.max, function (x, y) {sin(x * y)})  # Matrix with the outer product of the two arrays

Cox <- list()
for (k in 1:k.max){
 Cox[[k]] <-
   update(Cox0, substitute(. ~ . + Z[, 1:k]), data =  pbc)
   attr(Cox[[k]]$coefficients, "names")[2:(k+1)] <- paste0("sin(", 1:k, "* v)")
}
Cox

Best,

Frank

________________________________
De: Frank S. <f_j_rod at hotmail.com>
Enviado: jueves, 29 de agosto de 2019 12:38
Para: Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
Cc: r-help at r-project.org <r-help at r-project.org>
Asunto: RE: [R] Efficient way to update a survival model

Hi Vito,

Thanks for your reply! Following your suggestion, I have tried:

Cox[[3]] <- update(Cox[[2]], . ~ . + cos(3 * v), init=c(coef(Cox[[1]]), 0, 0), data =  pbc)
Cox[[3]] <- update(Cox[[2]], . ~ . + cos(3 * v), data =  pbc)

and both expressions lead to the same result. Is that OK?

Additionally, in my original question I wondered about the possibility of reducing the
10 lines of code to one general expression or some  loop. Is it possible?

Best,

Frank
________________________________
De: Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
Enviado: jueves, 29 de agosto de 2019 8:54
Para: Frank S. <f_j_rod at hotmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Asunto: Re: [R] Efficient way to update a survival model

dear Frank,

update() does not update actually.. It just builds a new call which is
evaluated. To speed up the procedure you could try to supply starting
values via argument 'init'. The first values come from the previous
fit, and the last one referring to new coefficients is set to zero (or
any other appropriate value).

Something like (untested), for instance

update(Cox[[2]], . ~ . + cos(3 * v), init=c(coef(Cox[[1]]),0), data =  pbc)

Hope this helps,
best,
vito



"Frank S." <f_j_rod at hotmail.com> ha scritto:

> Hello everybody, I come with a question which I do not know how to
> conduct in an efficient way. In order to
> provide a toy example, consider the dataset "pbc" from the package
> "survival". First, I fit the Cox model "Cox0":
>
> library("survival")
> set.seed(1)
> v <- runif(nrow(pbc), min = 0, max = 2)
> Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
>
> Then, from the above model, I can fit recursively 10 additional models as:
>
> Cox <- list()
>
> Cox[[1]] <- update(Cox0, . ~ . + cos(1 * v), data =  pbc)
> Cox[[2]] <- update(Cox[[1]], . ~ . + cos(2 * v), data =  pbc)
> Cox[[3]] <- update(Cox[[2]], . ~ . + cos(3 * v), data =  pbc)
> Cox[[4]] <- update(Cox[[3]], . ~ . + cos(4 * v), data =  pbc)
> ...
> Cox[[10]] <- update(Cox[[9]], . ~ . + cos(10* v), data =  pbc)
>
> Since in practice I have to repeat above step until Cox[[100]], say,
> do you know an efficient way to
> wrap this code chunk in a loop or similar?
>
> I had tried:
>
> set.seed(1)
> v <- runif(nrow(pbc), min = 0, max = 2)
> Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
>
> Cox <- list()
> Cox[[1]] <- update(Cox0, . ~ . + cos(1 * v), data =  pbc)
> for (k in 1:10) {
>   Cox[[k + 1]] <- update(Cox[[k]], . ~ . + cos((k + 1) * v), data =  pbc)
> }
>
> However, from Cox[[3]] onwards, the intermediate values of integer k
> are not included here (for
>  instance, the model Cox[[10]] would only include the cosinus terms
> for cos(1*v) and cos(10*v)).
>
[[elided Hotmail spam]]
>
> Frank
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



        [[alternative HTML version deleted]]


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues
**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From j@de@ @end|ng |rom uc@d@edu  Tue Sep  3 02:33:50 2019
From: j@de@ @end|ng |rom uc@d@edu (Ades, James)
Date: Tue, 3 Sep 2019 00:33:50 +0000
Subject: [R] Large mixed & crossed-effect model looking at educational
 spending on crime rates with error messages
Message-ID: <A683B57B-1FA5-4753-A520-BDCBF60DB94D@UCSD.edu>


I posted my question at Stack Overflow, where it didn?t get much of a response, and I was pointed in this direction by Ben Bolker. I?m happy to send the whole dataset to anyone who wants but thought that it would be presumptuous to include an enormous dput() here.

I?m looking at the effects of education spending per school district on crime rate (FBI crime data/UCR) within the cities and towns those school districts serve over a fifteen year period. The DV now has 203,410 observations of city/town crime data over those fifteen years. (I use that figure with some reticence, because there are so many moving parts and things to account for, but having employed over 100 datasets and hours passing through the code again, I think that figure is correct.)

Cities are technically crossed with school district, in that one city might attend multiple school districts. This means that one city could have multiple values for expenditure per student. School districts, however, also overlap with counties. As if things weren?t complicated enough, cities are mostly nested within county (though there are cities that exist in two counties, but it?s not often, and it?s usually by a small amount). Given that each city/town has a distinct PLACE_ID, my understanding is that this could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or (1|STATE/COUNTY_ID/PLACE_ID).

I?m pretty familiar with mixed-effect models, and I?ve looked through clear and informative posts such as this one: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified. I believe things would remain sane to include school district (full_district_id) as another crossed effect, as below:
glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) + (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, total.years, na.action = "na.omit")

Variables (not included in this model, to keep things null and simple) are centered and logged: pop per city, pop.dens per city, year, unemployment rate per county, proportion children living in poverty per school district, per capita income per county, difference in those who voted democrat in presidential elections per county, log enforcement per city/town, centered expenditure per student/ 1000 (per school district). PLACE_ID corresponds to cities and towns, COUNTY_ID to counties, full_district_id to school districts, and state.

First, if I try to run the full model, using UCSD?s supercomputer, I get the error that the job was killed, presumably because it got to a point where it consumed too much ram (I think 125mb).

I then tried to create a small subsection of data with arrange(STATE, COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through Delaware), so that I have 26,599 values. If I run this null model with the above code, I get the following error:

```
Error in getOptfun(optimizer) :
  optimizer function must use (at least) formal parameters ?fn?, ?par?, ?lower?, ?control?
```

Then I tried with the optimx, with these configurations: control = glmerControl(optimizer = "optimx?,
optCtrl = list(method = "nlminb?,
maxit=10000,
iter.max=10000,
eval.max=10000,
lower = c(0,0,0),
upper = c(Inf,10,1)))

and I received the following warning?since this is a null model, there aren?t any variables to really rescale.\

```
Warning messages:
1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,  :
  unrecognized control elements named ?lower?, ?upper? ignored
3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 0.00102386 (tol = 0.001, component 1)
4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?
```

I then tried more values (to 92,486, through Missouri). First, I tried the optimizer nloptr, and then I tried the optimix. I still received the same above errors.

I?ve checked and rechecked everything, so I wanted to solicit advice, either for where I might be going wrong, or for what I could do to resolve these error messages.

I?ve provided a brief snippet of the data below (randomly pulling a number of cities within counties of Arkansas, Arizona, and Alabama, as a dput.

Thanks!




231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
"0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
"0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
"0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
"0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
"0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
"0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
"0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
"0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
"0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
"0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
"0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
"0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
"0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
"0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
"0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
"0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
"0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
"0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
"0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
"0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
"0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
"0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
"0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
"0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
"0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
"0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
"0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
"0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
"0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
"0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
"0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
"0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
"0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
"0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
"0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
"0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
"0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
"0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
"0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
"0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
"0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
"0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
"0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
"0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
"0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
"0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
), COUNTY = c("autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"autauga county", "autauga county", "autauga county", "autauga county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "baldwin county",
"baldwin county", "baldwin county", "baldwin county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "apache county",
"apache county", "apache county", "apache county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"cochise county", "cochise county", "cochise county", "cochise county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "coconino county", "coconino county",
"coconino county", "coconino county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "gila county", "gila county", "gila county", "gila county",
"gila county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "graham county", "graham county", "graham county",
"graham county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "greenlee county", "greenlee county",
"greenlee county", "greenlee county", "la paz county", "la paz county",
"la paz county", "la paz county", "la paz county", "la paz county",
"la paz county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"pulaski county", "pulaski county", "pulaski county", "pulaski county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"randolph county", "randolph county", "randolph county", "randolph county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "st. francis county", "st. francis county",
"st. francis county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county", "saline county", "saline county", "saline county",
"saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01001",
"01001", "01001", "01001", "01001", "01001", "01001", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "01003", "01003", "01003", "01003", "01003", "01003",
"01003", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04001", "04001",
"04001", "04001", "04001", "04001", "04001", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04003", "04003",
"04003", "04003", "04003", "04003", "04003", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04005", "04005",
"04005", "04005", "04005", "04005", "04005", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04007", "04007", "04007",
"04007", "04007", "04007", "04007", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04009", "04009", "04009", "04009",
"04009", "04009", "04009", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04011",
"04011", "04011", "04011", "04011", "04011", "04011", "04012",
"04012", "04012", "04012", "04012", "04012", "04012", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05119",
"05119", "05119", "05119", "05119", "05119", "05119", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05121", "05121", "05121",
"05121", "05121", "05121", "05121", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05123",
"05123", "05123", "05123", "05123", "05123", "05123", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125", "05125", "05125",
"05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Autauga County School District", "Autauga County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Baldwin County School District",
"Baldwin County School District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "St. Johns Unified District",
"St. Johns Unified District", "St. Johns Unified District", "St. Johns Unified District",
"St. Johns Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Round Valley Unified District", "Round Valley Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Benson Unified School District", "St. David Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Douglas Unified District",
"Douglas Unified District", "Douglas Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Fort Huachuca Accommodation District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Fort Huachuca Accommodation District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Sierra Vista Unified District",
"Sierra Vista Unified District", "Tombstone Unified District",
"Tombstone Unified District", "Tombstone Unified District", "Tombstone Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Willcox Unified District", "Willcox Unified District",
"Willcox Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Fredonia-Moccasin Unified District", "Page Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff Unified District",
"Flagstaff Unified District", "Flagstaff Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Williams Unified District", "Williams Unified District",
"Williams Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Globe Unified District",
"Miami Unified District", "Globe Unified District", "Miami Unified District",
"Globe Unified District", "Miami Unified District", "Hayden-Winkelman Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Miami Unified District", "Miami Unified District",
"Miami Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Payson Unified District", "Payson Unified District",
"Payson Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Pima Unified District", "Pima Unified District",
"Pima Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Safford Unified District", "Thatcher Unified District",
"Safford Unified District", "Thatcher Unified District", "Safford Unified District",
"Thatcher Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Clifton Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Morenci Unified District", "Clifton Unified District",
"Morenci Unified District", "Clifton Unified District", "Morenci Unified District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Parker Unified School District",
"Parker Unified School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Little Rock School District",
"Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Little Rock School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"North Little Rock School District", "Pulaski County Special School District",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Corning Public Schools", "Corning Public Schools",
"Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring Schools",
"Mammoth Spring Schools", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Greene County Technical School District", "Greene County Technical School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Pocahontas School District", "Pocahontas School District",
"Pocahontas School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Sloan-Hendrix School District",
"Sloan-Hendrix School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "Forrest City School District",
"Forrest City School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "West Memphis School District",
"West Memphis School District", "Bryant Public Schools", "Bryant Public Schools",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bauxite School District", "Benton School District",
"Bryant Public Schools", "Harmony Grove School District", "Bauxite School District",
"Benton School District", "Bryant Public Schools", "Harmony Grove School District",
"Bauxite School District", "Benton School District", "Bryant Public Schools",
"Harmony Grove School District", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Fountain Lake School District",
"Fountain Lake School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Bryant Public Schools", "Pulaski County Special School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Sheridan School District", "Sheridan School District", "Sheridan School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District", "Pulaski County Special School District",
"Pulaski County Special School District"), EXPENDITURE_PER_STUDENT = c(5.2927293064877,
5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
-800L), class = c("tbl_df", "tbl", "data.frame"))

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep  3 16:32:19 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 3 Sep 2019 07:32:19 -0700
Subject: [R] Large mixed & crossed-effect model looking at educational
 spending on crime rates with error messages
In-Reply-To: <A683B57B-1FA5-4753-A520-BDCBF60DB94D@UCSD.edu>
References: <A683B57B-1FA5-4753-A520-BDCBF60DB94D@UCSD.edu>
Message-ID: <CAGxFJbSdTVcAg2HvaTF_8JhLVKWuhLDfx7ROJMTeCR+f8e1DEQ@mail.gmail.com>

You should post this on the R-sig-mixed-models list, not here. When you do
so, use ?dput to include data, not cut and paste.

Cheers,
Bert


On Tue, Sep 3, 2019 at 6:10 AM Ades, James <jades at ucsd.edu> wrote:

>
> I posted my question at Stack Overflow, where it didn?t get much of a
> response, and I was pointed in this direction by Ben Bolker. I?m happy to
> send the whole dataset to anyone who wants but thought that it would be
> presumptuous to include an enormous dput() here.
>
> I?m looking at the effects of education spending per school district on
> crime rate (FBI crime data/UCR) within the cities and towns those school
> districts serve over a fifteen year period. The DV now has 203,410
> observations of city/town crime data over those fifteen years. (I use that
> figure with some reticence, because there are so many moving parts and
> things to account for, but having employed over 100 datasets and hours
> passing through the code again, I think that figure is correct.)
>
> Cities are technically crossed with school district, in that one city
> might attend multiple school districts. This means that one city could have
> multiple values for expenditure per student. School districts, however,
> also overlap with counties. As if things weren?t complicated enough, cities
> are mostly nested within county (though there are cities that exist in two
> counties, but it?s not often, and it?s usually by a small amount). Given
> that each city/town has a distinct PLACE_ID, my understanding is that this
> could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or
> (1|STATE/COUNTY_ID/PLACE_ID).
>
> I?m pretty familiar with mixed-effect models, and I?ve looked through
> clear and informative posts such as this one:
> https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified.
> I believe things would remain sane to include school district
> (full_district_id) as another crossed effect, as below:
> glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) +
> (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control
> = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> total.years, na.action = "na.omit")
>
> Variables (not included in this model, to keep things null and simple) are
> centered and logged: pop per city, pop.dens per city, year, unemployment
> rate per county, proportion children living in poverty per school district,
> per capita income per county, difference in those who voted democrat in
> presidential elections per county, log enforcement per city/town, centered
> expenditure per student/ 1000 (per school district). PLACE_ID corresponds
> to cities and towns, COUNTY_ID to counties, full_district_id to school
> districts, and state.
>
> First, if I try to run the full model, using UCSD?s supercomputer, I get
> the error that the job was killed, presumably because it got to a point
> where it consumed too much ram (I think 125mb).
>
> I then tried to create a small subsection of data with arrange(STATE,
> COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through
> Delaware), so that I have 26,599 values. If I run this null model with the
> above code, I get the following error:
>
> ```
> Error in getOptfun(optimizer) :
>   optimizer function must use (at least) formal parameters ?fn?, ?par?,
> ?lower?, ?control?
> ```
>
> Then I tried with the optimx, with these configurations: control =
> glmerControl(optimizer = "optimx?,
> optCtrl = list(method = "nlminb?,
> maxit=10000,
> iter.max=10000,
> eval.max=10000,
> lower = c(0,0,0),
> upper = c(Inf,10,1)))
>
> and I received the following warning?since this is a null model, there
> aren?t any variables to really rescale.\
>
> ```
> Warning messages:
> 1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,
> :
>   unrecognized control elements named ?lower?, ?upper? ignored
> 2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,
> :
>   unrecognized control elements named ?lower?, ?upper? ignored
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge with max|grad| = 0.00102386 (tol = 0.001,
> component 1)
> 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
> ```
>
> I then tried more values (to 92,486, through Missouri). First, I tried the
> optimizer nloptr, and then I tried the optimix. I still received the same
> above errors.
>
> I?ve checked and rechecked everything, so I wanted to solicit advice,
> either for where I might be going wrong, or for what I could do to resolve
> these error messages.
>
> I?ve provided a brief snippet of the data below (randomly pulling a number
> of cities within counties of Arkansas, Arizona, and Alabama, as a dput.
>
> Thanks!
>
>
>
>
> 231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
> 1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> "0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> "0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
> "0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> "0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
> "0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
> "0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
> "0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
> "0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
> "0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
> "0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> "0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
> "0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
> "0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
> "0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
> "0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> "0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> "0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> "0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
> "0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
> "0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> "0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> "0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
> "0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
> "0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
> "0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
> "0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> "0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
> "0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
> "0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
> "0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
> "0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
> "0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
> "0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> "0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> "0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
> "0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
> "0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
> "0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
> "0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
> "0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
> "0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
> "0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
> "0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
> "0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> "0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
> "0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
> "0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
> "0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
> "0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
> "0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
> "0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> "0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
> ), COUNTY = c("autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "autauga county", "autauga county", "autauga county", "autauga county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> "baldwin county", "baldwin county", "baldwin county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "apache county",
> "apache county", "apache county", "apache county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "cochise county", "cochise county", "cochise county", "cochise county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "coconino county", "coconino county",
> "coconino county", "coconino county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "gila county", "gila county", "gila county", "gila county",
> "gila county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "graham county", "graham county", "graham county",
> "graham county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> "greenlee county", "greenlee county", "la paz county", "la paz county",
> "la paz county", "la paz county", "la paz county", "la paz county",
> "la paz county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "randolph county", "randolph county", "randolph county", "randolph county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "st. francis county", "st. francis county",
> "st. francis county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county", "saline county", "saline county", "saline county",
> "saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> "01001", "01001", "01001", "01001", "01001", "01001", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> "01003", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> "04001", "04001", "04001", "04001", "04001", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> "04003", "04003", "04003", "04003", "04003", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> "04005", "04005", "04005", "04005", "04005", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> "04007", "04007", "04007", "04007", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> "04009", "04009", "04009", "04011", "04011", "04011", "04011",
> "04011", "04011", "04011", "04011", "04011", "04011", "04011",
> "04011", "04011", "04011", "04011", "04011", "04011", "04012",
> "04012", "04012", "04012", "04012", "04012", "04012", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> "05119", "05119", "05119", "05119", "05119", "05119", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> "05121", "05121", "05121", "05121", "05123", "05123", "05123",
> "05123", "05123", "05123", "05123", "05123", "05123", "05123",
> "05123", "05123", "05123", "05123", "05123", "05123", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> "05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County
> School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Autauga County School District", "Autauga County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Baldwin County School District",
> "Baldwin County School District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "St. Johns Unified District",
> "St. Johns Unified District", "St. Johns Unified District", "St. Johns
> Unified District",
> "St. Johns Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Round Valley Unified District", "Round Valley Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Benson Unified School District", "St. David Unified District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> District",
> "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> District",
> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
> District",
> "Douglas Unified District", "Douglas Unified District", "Douglas Unified
> District",
> "Douglas Unified District", "Douglas Unified District", "Tombstone Unified
> District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca
> Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> "Sierra Vista Unified District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> "Sierra Vista Unified District", "Sierra Vista Unified District",
> "Sierra Vista Unified District", "Tombstone Unified District",
> "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> Unified District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> District",
> "Willcox Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Fredonia-Moccasin Unified District", "Page Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> Unified District",
> "Flagstaff Unified District", "Flagstaff Unified District", "Williams
> Unified District",
> "Williams Unified District", "Williams Unified District", "Williams
> Unified District",
> "Williams Unified District", "Williams Unified District", "Williams
> Unified District",
> "Williams Unified District", "Williams Unified District", "Williams
> Unified District",
> "Williams Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Globe Unified
> District",
> "Miami Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Globe Unified
> District",
> "Miami Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Globe Unified
> District",
> "Miami Unified District", "Globe Unified District", "Miami Unified
> District",
> "Globe Unified District", "Miami Unified District", "Hayden-Winkelman
> Unified District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Miami Unified District", "Miami Unified
> District",
> "Miami Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Payson Unified District", "Payson Unified
> District",
> "Payson Unified District", "Pima Unified District", "Pima Unified
> District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Pima Unified District", "Pima Unified District",
> "Pima Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> District",
> "Safford Unified District", "Thatcher Unified District", "Safford Unified
> District",
> "Thatcher Unified District", "Clifton Unified District", "Morenci Unified
> District",
> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
> District",
> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
> District",
> "Clifton Unified District", "Morenci Unified District", "Clifton Unified
> District",
> "Morenci Unified District", "Morenci Unified District", "Clifton Unified
> District",
> "Morenci Unified District", "Clifton Unified District", "Morenci Unified
> District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Parker Unified School District",
> "Parker Unified School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Little Rock School District",
> "Little Rock School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Little Rock School District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "North Little Rock School District", "Pulaski County Special School
> District",
> "Corning Public Schools", "Corning Public Schools", "Corning Public
> Schools",
> "Corning Public Schools", "Corning Public Schools", "Corning Public
> Schools",
> "Corning Public Schools", "Corning Public Schools", "Corning Public
> Schools",
> "Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring
> Schools",
> "Mammoth Spring Schools", "Greene County Technical School District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Greene County Technical School District", "Greene County Technical School
> District",
> "Pocahontas School District", "Pocahontas School District", "Pocahontas
> School District",
> "Pocahontas School District", "Pocahontas School District", "Pocahontas
> School District",
> "Pocahontas School District", "Pocahontas School District", "Pocahontas
> School District",
> "Pocahontas School District", "Sloan-Hendrix School District",
> "Sloan-Hendrix School District", "Sloan-Hendrix School District",
> "Sloan-Hendrix School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "Forrest City School District",
> "Forrest City School District", "West Memphis School District",
> "West Memphis School District", "West Memphis School District",
> "West Memphis School District", "West Memphis School District",
> "West Memphis School District", "Bryant Public Schools", "Bryant Public
> Schools",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bauxite School District", "Benton School
> District",
> "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> District",
> "Benton School District", "Bryant Public Schools", "Harmony Grove School
> District",
> "Bauxite School District", "Benton School District", "Bryant Public
> Schools",
> "Harmony Grove School District", "Bryant Public Schools", "Bryant Public
> Schools",
> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Fountain Lake School District",
> "Fountain Lake School District", "Pulaski County Special School District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Bryant Public Schools", "Pulaski County Special School District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Sheridan School District", "Sheridan School District", "Sheridan School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District", "Pulaski County Special School
> District",
> "Pulaski County Special School District"), EXPENDITURE_PER_STUDENT =
> c(5.2927293064877,
> 5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
> 7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
> 7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
> 7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
> 5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
> 7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
> 7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
> 7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
> 9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
> 8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
> 6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
> 9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
> 8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
> 8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> 8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
> 6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
> 9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> 6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
> 8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
> 8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
> 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> 9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
> 8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
> 8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
> 7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
> 8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
> 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> 8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
> 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
> 8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
> 9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
> 8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
> 8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
> 8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
> 7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
> 6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
> 9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
> 6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
> 7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
> 8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
> 9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
> 8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
> 7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
> 9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
> 6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
> 7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
> 7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
> 7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
> 4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
> 5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
> 6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
> 10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
> 6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
> 7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
> 8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
> 7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
> 7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
> 7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
> 6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
> 8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
> 7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
> 8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
> 7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
> 8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
> 9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
> 8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
> 8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
> 7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
> 9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
> 10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
> 7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
> 8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
> 7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
> 11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
> 9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
> 5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
> 6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
> 7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
> 5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
> 6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
> 7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
> 7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
> 7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
> 7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
> 5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
> 7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
> 7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
> 5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
> 7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
> 6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
> 4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
> 4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
> 5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
> 6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
> 6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
> 6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
> 6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
> 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
> 7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
> 10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
> 9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
> 6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
> 6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
> 8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
> 12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
> 10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
> 12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
> 9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
> 10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
> 10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
> 12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
> 12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
> 12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
> 12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> 10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
> 8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
> 8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
> 9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
> 10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
> 9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
> 10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
> 11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
> 11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
> 8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
> 9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
> 10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
> 10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
> 10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
> 10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
> 8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
> 9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
> 9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
> 6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
> 7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
> 8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
> 8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
> 7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
> 8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
> 7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
> 8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
> 10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
> 10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
> 9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
> 8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
> 7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
> 7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
> 7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
> 7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
> 7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
> 7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
> 7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
> 8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
> 8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
> 8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
> 8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
> 8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
> 8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
> 7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
> 7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
> 6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
> 8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
> 11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
> 8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> 10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
> 8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
> 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
> 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
> 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
> 9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
> 9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
> 11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
> 9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
> 10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
> 10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
> 7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
> 8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
> 6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
> 8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
> 7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
> 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
> 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> 10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
> -800L), class = c("tbl_df", "tbl", "data.frame"))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Tue Sep  3 18:25:47 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Tue, 3 Sep 2019 12:25:47 -0400
Subject: [R] Large mixed & crossed-effect model looking at educational
 spending on crime rates with error messages
In-Reply-To: <CAGxFJbSdTVcAg2HvaTF_8JhLVKWuhLDfx7ROJMTeCR+f8e1DEQ@mail.gmail.com>
References: <A683B57B-1FA5-4753-A520-BDCBF60DB94D@UCSD.edu>
 <CAGxFJbSdTVcAg2HvaTF_8JhLVKWuhLDfx7ROJMTeCR+f8e1DEQ@mail.gmail.com>
Message-ID: <CAJc=yOHBzR85-ekX=Dt3-fc79R8sxv0-b-7w3LR3yridy1xoSw@mail.gmail.com>

(And post in plain text)

On Tue, Sep 3, 2019 at 10:34 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You should post this on the R-sig-mixed-models list, not here. When you do
> so, use ?dput to include data, not cut and paste.
>
> Cheers,
> Bert
>
>
> On Tue, Sep 3, 2019 at 6:10 AM Ades, James <jades at ucsd.edu> wrote:
>
> >
> > I posted my question at Stack Overflow, where it didn?t get much of a
> > response, and I was pointed in this direction by Ben Bolker. I?m happy to
> > send the whole dataset to anyone who wants but thought that it would be
> > presumptuous to include an enormous dput() here.
> >
> > I?m looking at the effects of education spending per school district on
> > crime rate (FBI crime data/UCR) within the cities and towns those school
> > districts serve over a fifteen year period. The DV now has 203,410
> > observations of city/town crime data over those fifteen years. (I use that
> > figure with some reticence, because there are so many moving parts and
> > things to account for, but having employed over 100 datasets and hours
> > passing through the code again, I think that figure is correct.)
> >
> > Cities are technically crossed with school district, in that one city
> > might attend multiple school districts. This means that one city could have
> > multiple values for expenditure per student. School districts, however,
> > also overlap with counties. As if things weren?t complicated enough, cities
> > are mostly nested within county (though there are cities that exist in two
> > counties, but it?s not often, and it?s usually by a small amount). Given
> > that each city/town has a distinct PLACE_ID, my understanding is that this
> > could be represented as (1|PLACE_ID) + (1|STATE/COUNTY_ID) or
> > (1|STATE/COUNTY_ID/PLACE_ID).
> >
> > I?m pretty familiar with mixed-effect models, and I?ve looked through
> > clear and informative posts such as this one:
> > https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified.
> > I believe things would remain sane to include school district
> > (full_district_id) as another crossed effect, as below:
> > glmer.total <- glmer(CRIME_TOTAL ~ 1 + (year|PLACE_ID) +
> > (1|STATE/COUNTY_ID) + (year|full_district_id), family = "poisson", control
> > = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> > total.years, na.action = "na.omit")
> >
> > Variables (not included in this model, to keep things null and simple) are
> > centered and logged: pop per city, pop.dens per city, year, unemployment
> > rate per county, proportion children living in poverty per school district,
> > per capita income per county, difference in those who voted democrat in
> > presidential elections per county, log enforcement per city/town, centered
> > expenditure per student/ 1000 (per school district). PLACE_ID corresponds
> > to cities and towns, COUNTY_ID to counties, full_district_id to school
> > districts, and state.
> >
> > First, if I try to run the full model, using UCSD?s supercomputer, I get
> > the error that the job was killed, presumably because it got to a point
> > where it consumed too much ram (I think 125mb).
> >
> > I then tried to create a small subsection of data with arrange(STATE,
> > COUNTY_ID, PLACE_ID) and then slicing by the first ten states (up through
> > Delaware), so that I have 26,599 values. If I run this null model with the
> > above code, I get the following error:
> >
> > ```
> > Error in getOptfun(optimizer) :
> >   optimizer function must use (at least) formal parameters ?fn?, ?par?,
> > ?lower?, ?control?
> > ```
> >
> > Then I tried with the optimx, with these configurations: control =
> > glmerControl(optimizer = "optimx?,
> > optCtrl = list(method = "nlminb?,
> > maxit=10000,
> > iter.max=10000,
> > eval.max=10000,
> > lower = c(0,0,0),
> > upper = c(Inf,10,1)))
> >
> > and I received the following warning?since this is a null model, there
> > aren?t any variables to really rescale.\
> >
> > ```
> > Warning messages:
> > 1: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,
> > :
> >   unrecognized control elements named ?lower?, ?upper? ignored
> > 2: In nlminb(start = par, objective = ufn, gradient = ugr, lower = lower,
> > :
> >   unrecognized control elements named ?lower?, ?upper? ignored
> > 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >   Model failed to converge with max|grad| = 0.00102386 (tol = 0.001,
> > component 1)
> > 4: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
> >   Model is nearly unidentifiable: very large eigenvalue
> >  - Rescale variables?
> > ```
> >
> > I then tried more values (to 92,486, through Missouri). First, I tried the
> > optimizer nloptr, and then I tried the optimix. I still received the same
> > above errors.
> >
> > I?ve checked and rechecked everything, so I wanted to solicit advice,
> > either for where I might be going wrong, or for what I could do to resolve
> > these error messages.
> >
> > I?ve provided a brief snippet of the data below (randomly pulling a number
> > of cities within counties of Arkansas, Arizona, and Alabama, as a dput.
> >
> > Thanks!
> >
> >
> >
> >
> > 231, 206, 935, 1070, 974, 1108, 1244, 1095, 1131, 1151, 1420,
> > 1316, 1321, 1414, 1484), full_district_id = c("0100240", "0100240",
> > "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> > "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> > "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> > "0100240", "0100240", "0100240", "0100240", "0100240", "0100240",
> > "0100240", "0100240", "0100240", "0100240", "0100240", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0100270", "0100270", "0100270", "0100270",
> > "0100270", "0100270", "0407130", "0407130", "0407130", "0407130",
> > "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> > "0407130", "0407130", "0407130", "0407130", "0408080", "0408080",
> > "0408080", "0408080", "0408080", "0407130", "0407130", "0407130",
> > "0407130", "0407130", "0407130", "0407130", "0407130", "0407130",
> > "0407130", "0407130", "0407130", "0407130", "0400212", "0408020",
> > "0400212", "0408020", "0400212", "0408020", "0400212", "0408020",
> > "0400212", "0408020", "0400212", "0408020", "0401180", "0401180",
> > "0401180", "0401180", "0401180", "0401180", "0401180", "0401180",
> > "0401180", "0402530", "0402530", "0402530", "0402530", "0402530",
> > "0402530", "0402530", "0402530", "0408600", "0408600", "0408600",
> > "0408600", "0408600", "0408600", "0408600", "0408600", "0408600",
> > "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> > "0403150", "0401460", "0403150", "0401460", "0403150", "0401460",
> > "0401460", "0403150", "0401460", "0403150", "0401460", "0403150",
> > "0401460", "0401460", "0401460", "0401460", "0408600", "0408600",
> > "0408600", "0408600", "0409250", "0409250", "0409250", "0409250",
> > "0409250", "0409250", "0409250", "0409250", "0409250", "0409250",
> > "0409250", "0409250", "0409250", "0402860", "0402860", "0402860",
> > "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> > "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> > "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> > "0403080", "0403080", "0403080", "0403080", "0403080", "0403080",
> > "0403080", "0403080", "0405820", "0403080", "0405820", "0403080",
> > "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> > "0405820", "0403080", "0405820", "0403080", "0405820", "0403080",
> > "0405820", "0403080", "0405820", "0402860", "0402860", "0402860",
> > "0402860", "0402860", "0402860", "0402860", "0402860", "0402860",
> > "0402860", "0402860", "0409310", "0409310", "0409310", "0409310",
> > "0409310", "0409310", "0409310", "0409310", "0409310", "0409310",
> > "0409310", "0403500", "0405030", "0403500", "0405030", "0403500",
> > "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> > "0405030", "0403500", "0405030", "0403500", "0405030", "0403500",
> > "0405030", "0403500", "0405030", "0403500", "0405030", "0403730",
> > "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> > "0405030", "0405030", "0405030", "0405030", "0405030", "0405030",
> > "0405030", "0406070", "0406070", "0406070", "0406070", "0406070",
> > "0406070", "0406070", "0406070", "0406070", "0406070", "0406070",
> > "0406070", "0406440", "0406440", "0406440", "0406440", "0406440",
> > "0406440", "0406440", "0406440", "0406440", "0406440", "0406440",
> > "0406440", "0407240", "0408410", "0407240", "0408410", "0407240",
> > "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> > "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> > "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> > "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> > "0408410", "0407240", "0408410", "0407240", "0408410", "0407240",
> > "0408410", "0402110", "0405320", "0402110", "0405320", "0402110",
> > "0405320", "0402110", "0405320", "0402110", "0405320", "0402110",
> > "0405320", "0405320", "0402110", "0405320", "0402110", "0405320",
> > "0405980", "0405980", "0405980", "0405980", "0405980", "0405980",
> > "0405980", "0509000", "0509000", "0509000", "0509000", "0509000",
> > "0509000", "0509000", "0509000", "0509000", "0509000", "0509000",
> > "0509000", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> > "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> > "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> > "0511850", "0509000", "0511850", "0509000", "0511850", "0509000",
> > "0511850", "0509000", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0510680", "0511850", "0510680", "0511850", "0510680", "0511850",
> > "0500009", "0500009", "0500009", "0500009", "0500009", "0500009",
> > "0500009", "0500009", "0500009", "0500009", "0509270", "0509270",
> > "0509270", "0513080", "0513080", "0513080", "0513080", "0513080",
> > "0513080", "0513080", "0513080", "0513080", "0513080", "0513080",
> > "0513080", "0513080", "0511610", "0511610", "0511610", "0511610",
> > "0511610", "0511610", "0511610", "0511610", "0511610", "0511610",
> > "0512480", "0512480", "0512480", "0512480", "0506270", "0506270",
> > "0506270", "0506270", "0506270", "0506270", "0506270", "0506270",
> > "0506270", "0506270", "0508040", "0508040", "0508040", "0508040",
> > "0508040", "0508040", "0503690", "0503690", "0502790", "0502960",
> > "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> > "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> > "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> > "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> > "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> > "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> > "0503690", "0507320", "0502790", "0502960", "0503690", "0507320",
> > "0502790", "0502960", "0503690", "0507320", "0502790", "0502960",
> > "0503690", "0507320", "0503690", "0503690", "0503690", "0503690",
> > "0503690", "0503690", "0503690", "0503690", "0503690", "0503690",
> > "0503690", "0506420", "0506420", "0506420", "0506420", "0506420",
> > "0506420", "0506420", "0506420", "0506420", "0506420", "0506420",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0503690", "0511850", "0503690",
> > "0511850", "0503690", "0511850", "0503690", "0511850", "0500015",
> > "0500015", "0500015", "0500015", "0500015", "0500015", "0500015",
> > "0500015", "0500015", "0500015", "0500015", "0500015", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850",
> > "0511850", "0511850", "0511850", "0511850", "0511850", "0511850"
> > ), COUNTY = c("autauga county", "autauga county", "autauga county",
> > "autauga county", "autauga county", "autauga county", "autauga county",
> > "autauga county", "autauga county", "autauga county", "autauga county",
> > "autauga county", "autauga county", "autauga county", "autauga county",
> > "autauga county", "autauga county", "autauga county", "autauga county",
> > "autauga county", "autauga county", "autauga county", "autauga county",
> > "autauga county", "autauga county", "autauga county", "autauga county",
> > "autauga county", "autauga county", "autauga county", "autauga county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "baldwin county",
> > "baldwin county", "baldwin county", "baldwin county", "apache county",
> > "apache county", "apache county", "apache county", "apache county",
> > "apache county", "apache county", "apache county", "apache county",
> > "apache county", "apache county", "apache county", "apache county",
> > "apache county", "apache county", "apache county", "apache county",
> > "apache county", "apache county", "apache county", "apache county",
> > "apache county", "apache county", "apache county", "apache county",
> > "apache county", "apache county", "apache county", "apache county",
> > "apache county", "apache county", "apache county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "cochise county", "cochise county", "cochise county", "cochise county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "coconino county", "coconino county",
> > "coconino county", "coconino county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "gila county", "gila county", "gila county", "gila county",
> > "gila county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "graham county", "graham county", "graham county",
> > "graham county", "greenlee county", "greenlee county", "greenlee county",
> > "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> > "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> > "greenlee county", "greenlee county", "greenlee county", "greenlee county",
> > "greenlee county", "greenlee county", "la paz county", "la paz county",
> > "la paz county", "la paz county", "la paz county", "la paz county",
> > "la paz county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "pulaski county", "pulaski county", "pulaski county", "pulaski county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "randolph county", "randolph county", "randolph county", "randolph county",
> > "st. francis county", "st. francis county", "st. francis county",
> > "st. francis county", "st. francis county", "st. francis county",
> > "st. francis county", "st. francis county", "st. francis county",
> > "st. francis county", "st. francis county", "st. francis county",
> > "st. francis county", "st. francis county", "st. francis county",
> > "st. francis county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county", "saline county", "saline county", "saline county",
> > "saline county"), COUNTY_ID = c("01001", "01001", "01001", "01001",
> > "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> > "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> > "01001", "01001", "01001", "01001", "01001", "01001", "01001",
> > "01001", "01001", "01001", "01001", "01001", "01001", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "01003", "01003", "01003", "01003", "01003", "01003",
> > "01003", "04001", "04001", "04001", "04001", "04001", "04001",
> > "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> > "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> > "04001", "04001", "04001", "04001", "04001", "04001", "04001",
> > "04001", "04001", "04001", "04001", "04001", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04003", "04003",
> > "04003", "04003", "04003", "04003", "04003", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04005", "04005",
> > "04005", "04005", "04005", "04005", "04005", "04007", "04007",
> > "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> > "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> > "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> > "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> > "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> > "04007", "04007", "04007", "04007", "04007", "04007", "04007",
> > "04007", "04007", "04007", "04007", "04009", "04009", "04009",
> > "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> > "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> > "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> > "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> > "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> > "04009", "04009", "04009", "04009", "04009", "04009", "04009",
> > "04009", "04009", "04009", "04011", "04011", "04011", "04011",
> > "04011", "04011", "04011", "04011", "04011", "04011", "04011",
> > "04011", "04011", "04011", "04011", "04011", "04011", "04012",
> > "04012", "04012", "04012", "04012", "04012", "04012", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05119",
> > "05119", "05119", "05119", "05119", "05119", "05119", "05121",
> > "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> > "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> > "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> > "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> > "05121", "05121", "05121", "05121", "05121", "05121", "05121",
> > "05121", "05121", "05121", "05121", "05123", "05123", "05123",
> > "05123", "05123", "05123", "05123", "05123", "05123", "05123",
> > "05123", "05123", "05123", "05123", "05123", "05123", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125", "05125", "05125",
> > "05125", "05125", "05125", "05125", "05125"), DISTRICT = c("Autauga County
> > School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Autauga County School District", "Autauga County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Baldwin County School District",
> > "Baldwin County School District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "St. Johns Unified District",
> > "St. Johns Unified District", "St. Johns Unified District", "St. Johns
> > Unified District",
> > "St. Johns Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Round Valley Unified District", "Round Valley Unified District",
> > "Benson Unified School District", "St. David Unified District",
> > "Benson Unified School District", "St. David Unified District",
> > "Benson Unified School District", "St. David Unified District",
> > "Benson Unified School District", "St. David Unified District",
> > "Benson Unified School District", "St. David Unified District",
> > "Benson Unified School District", "St. David Unified District",
> > "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> > District",
> > "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> > District",
> > "Bisbee Unified District", "Bisbee Unified District", "Bisbee Unified
> > District",
> > "Douglas Unified District", "Douglas Unified District", "Douglas Unified
> > District",
> > "Douglas Unified District", "Douglas Unified District", "Douglas Unified
> > District",
> > "Douglas Unified District", "Douglas Unified District", "Tombstone Unified
> > District",
> > "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> > Unified District",
> > "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> > Unified District",
> > "Tombstone Unified District", "Tombstone Unified District", "Fort Huachuca
> > Accommodation District",
> > "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> > "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> > "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> > "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> > "Sierra Vista Unified District", "Fort Huachuca Accommodation District",
> > "Sierra Vista Unified District", "Sierra Vista Unified District",
> > "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> > "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> > "Fort Huachuca Accommodation District", "Sierra Vista Unified District",
> > "Sierra Vista Unified District", "Sierra Vista Unified District",
> > "Sierra Vista Unified District", "Tombstone Unified District",
> > "Tombstone Unified District", "Tombstone Unified District", "Tombstone
> > Unified District",
> > "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> > District",
> > "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> > District",
> > "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> > District",
> > "Willcox Unified District", "Willcox Unified District", "Willcox Unified
> > District",
> > "Willcox Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Fredonia-Moccasin Unified District",
> > "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> > "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> > "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> > "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> > "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> > "Fredonia-Moccasin Unified District", "Fredonia-Moccasin Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Fredonia-Moccasin Unified District", "Page Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Flagstaff
> > Unified District",
> > "Flagstaff Unified District", "Flagstaff Unified District", "Williams
> > Unified District",
> > "Williams Unified District", "Williams Unified District", "Williams
> > Unified District",
> > "Williams Unified District", "Williams Unified District", "Williams
> > Unified District",
> > "Williams Unified District", "Williams Unified District", "Williams
> > Unified District",
> > "Williams Unified District", "Globe Unified District", "Miami Unified
> > District",
> > "Globe Unified District", "Miami Unified District", "Globe Unified
> > District",
> > "Miami Unified District", "Globe Unified District", "Miami Unified
> > District",
> > "Globe Unified District", "Miami Unified District", "Globe Unified
> > District",
> > "Miami Unified District", "Globe Unified District", "Miami Unified
> > District",
> > "Globe Unified District", "Miami Unified District", "Globe Unified
> > District",
> > "Miami Unified District", "Globe Unified District", "Miami Unified
> > District",
> > "Globe Unified District", "Miami Unified District", "Hayden-Winkelman
> > Unified District",
> > "Miami Unified District", "Miami Unified District", "Miami Unified
> > District",
> > "Miami Unified District", "Miami Unified District", "Miami Unified
> > District",
> > "Miami Unified District", "Miami Unified District", "Miami Unified
> > District",
> > "Miami Unified District", "Miami Unified District", "Miami Unified
> > District",
> > "Miami Unified District", "Payson Unified District", "Payson Unified
> > District",
> > "Payson Unified District", "Payson Unified District", "Payson Unified
> > District",
> > "Payson Unified District", "Payson Unified District", "Payson Unified
> > District",
> > "Payson Unified District", "Payson Unified District", "Payson Unified
> > District",
> > "Payson Unified District", "Pima Unified District", "Pima Unified
> > District",
> > "Pima Unified District", "Pima Unified District", "Pima Unified District",
> > "Pima Unified District", "Pima Unified District", "Pima Unified District",
> > "Pima Unified District", "Pima Unified District", "Pima Unified District",
> > "Pima Unified District", "Safford Unified District", "Thatcher Unified
> > District",
> > "Safford Unified District", "Thatcher Unified District", "Safford Unified
> > District",
> > "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> > District",
> > "Safford Unified District", "Thatcher Unified District", "Safford Unified
> > District",
> > "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> > District",
> > "Safford Unified District", "Thatcher Unified District", "Safford Unified
> > District",
> > "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> > District",
> > "Safford Unified District", "Thatcher Unified District", "Safford Unified
> > District",
> > "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> > District",
> > "Safford Unified District", "Thatcher Unified District", "Safford Unified
> > District",
> > "Thatcher Unified District", "Safford Unified District", "Thatcher Unified
> > District",
> > "Safford Unified District", "Thatcher Unified District", "Safford Unified
> > District",
> > "Thatcher Unified District", "Clifton Unified District", "Morenci Unified
> > District",
> > "Clifton Unified District", "Morenci Unified District", "Clifton Unified
> > District",
> > "Morenci Unified District", "Clifton Unified District", "Morenci Unified
> > District",
> > "Clifton Unified District", "Morenci Unified District", "Clifton Unified
> > District",
> > "Morenci Unified District", "Morenci Unified District", "Clifton Unified
> > District",
> > "Morenci Unified District", "Clifton Unified District", "Morenci Unified
> > District",
> > "Parker Unified School District", "Parker Unified School District",
> > "Parker Unified School District", "Parker Unified School District",
> > "Parker Unified School District", "Parker Unified School District",
> > "Parker Unified School District", "Little Rock School District",
> > "Little Rock School District", "Little Rock School District",
> > "Little Rock School District", "Little Rock School District",
> > "Little Rock School District", "Little Rock School District",
> > "Little Rock School District", "Little Rock School District",
> > "Little Rock School District", "Little Rock School District",
> > "Little Rock School District", "Pulaski County Special School District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Little Rock School District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "North Little Rock School District", "Pulaski County Special School
> > District",
> > "Corning Public Schools", "Corning Public Schools", "Corning Public
> > Schools",
> > "Corning Public Schools", "Corning Public Schools", "Corning Public
> > Schools",
> > "Corning Public Schools", "Corning Public Schools", "Corning Public
> > Schools",
> > "Corning Public Schools", "Mammoth Spring Schools", "Mammoth Spring
> > Schools",
> > "Mammoth Spring Schools", "Greene County Technical School District",
> > "Greene County Technical School District", "Greene County Technical School
> > District",
> > "Greene County Technical School District", "Greene County Technical School
> > District",
> > "Greene County Technical School District", "Greene County Technical School
> > District",
> > "Greene County Technical School District", "Greene County Technical School
> > District",
> > "Greene County Technical School District", "Greene County Technical School
> > District",
> > "Greene County Technical School District", "Greene County Technical School
> > District",
> > "Pocahontas School District", "Pocahontas School District", "Pocahontas
> > School District",
> > "Pocahontas School District", "Pocahontas School District", "Pocahontas
> > School District",
> > "Pocahontas School District", "Pocahontas School District", "Pocahontas
> > School District",
> > "Pocahontas School District", "Sloan-Hendrix School District",
> > "Sloan-Hendrix School District", "Sloan-Hendrix School District",
> > "Sloan-Hendrix School District", "Forrest City School District",
> > "Forrest City School District", "Forrest City School District",
> > "Forrest City School District", "Forrest City School District",
> > "Forrest City School District", "Forrest City School District",
> > "Forrest City School District", "Forrest City School District",
> > "Forrest City School District", "West Memphis School District",
> > "West Memphis School District", "West Memphis School District",
> > "West Memphis School District", "West Memphis School District",
> > "West Memphis School District", "Bryant Public Schools", "Bryant Public
> > Schools",
> > "Bauxite School District", "Benton School District", "Bryant Public
> > Schools",
> > "Harmony Grove School District", "Bauxite School District", "Benton School
> > District",
> > "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> > District",
> > "Benton School District", "Bryant Public Schools", "Harmony Grove School
> > District",
> > "Bauxite School District", "Benton School District", "Bryant Public
> > Schools",
> > "Harmony Grove School District", "Bauxite School District", "Benton School
> > District",
> > "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> > District",
> > "Benton School District", "Bryant Public Schools", "Harmony Grove School
> > District",
> > "Bauxite School District", "Benton School District", "Bryant Public
> > Schools",
> > "Harmony Grove School District", "Bauxite School District", "Benton School
> > District",
> > "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> > District",
> > "Benton School District", "Bryant Public Schools", "Harmony Grove School
> > District",
> > "Bauxite School District", "Benton School District", "Bryant Public
> > Schools",
> > "Harmony Grove School District", "Bauxite School District", "Benton School
> > District",
> > "Bryant Public Schools", "Harmony Grove School District", "Bauxite School
> > District",
> > "Benton School District", "Bryant Public Schools", "Harmony Grove School
> > District",
> > "Bauxite School District", "Benton School District", "Bryant Public
> > Schools",
> > "Harmony Grove School District", "Bryant Public Schools", "Bryant Public
> > Schools",
> > "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> > "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> > "Bryant Public Schools", "Bryant Public Schools", "Bryant Public Schools",
> > "Fountain Lake School District", "Fountain Lake School District",
> > "Fountain Lake School District", "Fountain Lake School District",
> > "Fountain Lake School District", "Fountain Lake School District",
> > "Fountain Lake School District", "Fountain Lake School District",
> > "Fountain Lake School District", "Fountain Lake School District",
> > "Fountain Lake School District", "Pulaski County Special School District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Bryant Public Schools", "Pulaski County Special School District",
> > "Bryant Public Schools", "Pulaski County Special School District",
> > "Bryant Public Schools", "Pulaski County Special School District",
> > "Bryant Public Schools", "Pulaski County Special School District",
> > "Sheridan School District", "Sheridan School District", "Sheridan School
> > District",
> > "Sheridan School District", "Sheridan School District", "Sheridan School
> > District",
> > "Sheridan School District", "Sheridan School District", "Sheridan School
> > District",
> > "Sheridan School District", "Sheridan School District", "Sheridan School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District", "Pulaski County Special School
> > District",
> > "Pulaski County Special School District"), EXPENDITURE_PER_STUDENT =
> > c(5.2927293064877,
> > 5.83217391304348, 6.24197091745999, 7.00549108992955, 7.58262281770199,
> > 7.42023581578152, 5.2927293064877, 6.24197091745999, 7.58262281770199,
> > 7.42023581578152, 7.3847757046447, 7.53533925686591, 7.0917048346056,
> > 7.18122877431306, 7.4336542486396, 7.54056291390728, 8.11883528526915,
> > 5.2927293064877, 5.4061504667765, 5.83217391304348, 6.24197091745999,
> > 7.00549108992955, 7.58262281770199, 7.3847757046447, 7.53533925686591,
> > 7.0917048346056, 7.18122877431306, 7.4336542486396, 7.54056291390728,
> > 7.62202102195858, 8.11883528526915, 6.72722224595276, 7.55975125802888,
> > 9.08160237388724, 10.0624245624623, 8.34440937621902, 8.12038327526132,
> > 8.10149903123832, 8.8251378752353, 8.82232971630278, 9.07112703083024,
> > 6.72722224595276, 6.76353122269834, 7.55975125802888, 8.21461591802142,
> > 9.08160237388724, 9.40051622418879, 8.27094691535151, 8.34440937621902,
> > 8.12038327526132, 8.10149903123832, 8.8251378752353, 8.82232971630278,
> > 8.94384274675891, 9.07112703083024, 6.72722224595276, 7.55975125802888,
> > 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> > 8.34440937621902, 8.12038327526132, 8.8251378752353, 6.72722224595276,
> > 6.76353122269834, 7.55975125802888, 9.08160237388724, 10.0624245624623,
> > 9.40051622418879, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> > 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> > 6.72722224595276, 9.08160237388724, 9.40051622418879, 8.27094691535151,
> > 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
> > 8.82232971630278, 9.07112703083024, 6.72722224595276, 7.55975125802888,
> > 8.21461591802142, 9.08160237388724, 10.0624245624623, 9.40051622418879,
> > 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> > 8.8251378752353, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> > 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
> > 8.27094691535151, 8.34440937621902, 8.12038327526132, 8.10149903123832,
> > 9.07112703083024, 6.72722224595276, 7.55975125802888, 8.21461591802142,
> > 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.34440937621902,
> > 8.12038327526132, 8.94384274675891, 9.07112703083024, 6.72722224595276,
> > 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> > 8.34440937621902, 8.12038327526132, 8.10149903123832, 8.8251378752353,
> > 8.82232971630278, 8.94384274675891, 9.07112703083024, 6.72722224595276,
> > 7.55975125802888, 8.21461591802142, 9.08160237388724, 10.0624245624623,
> > 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
> > 8.10149903123832, 8.82232971630278, 8.94384274675891, 6.72722224595276,
> > 9.08160237388724, 10.0624245624623, 9.40051622418879, 8.27094691535151,
> > 8.12038327526132, 8.82232971630278, 8.94384274675891, 9.07112703083024,
> > 6.72722224595276, 7.55975125802888, 8.21461591802142, 9.08160237388724,
> > 9.40051622418879, 8.27094691535151, 8.34440937621902, 8.12038327526132,
> > 8.10149903123832, 8.8251378752353, 8.82232971630278, 8.94384274675891,
> > 9.07112703083024, 6.12082777036048, 7.13046495489244, 7.48205822613406,
> > 8.42205582028591, 8.80758807588076, 9.71007853403141, 8.90625,
> > 8.23277074542897, 8.28856088560886, 6.7035633055345, 8.31709145427286,
> > 8.39924812030075, 8.18996138996139, 7.76379176379176, 7.18944392082941,
> > 7.68155893536122, 8.99380421313507, 9.23019801980198, 9.44252163164401,
> > 6.12082777036048, 7.13046495489244, 7.48205822613406, 8.42205582028591,
> > 9.71007853403141, 8.90625, 8.23277074542897, 8.28856088560886,
> > 6.7035633055345, 8.31709145427286, 8.39924812030075, 8.18996138996139,
> > 7.76379176379176, 6.62690839694656, 6.32572614107884, 6.91001011122346,
> > 8.82959641255605, 7.57358870967742, 8.00948766603416, 7.39882121807466,
> > 9.23711340206185, 8.05449330783939, 8.3406374501992, 7.63463203463203,
> > 8.23214285714286, 5.51444547996272, 7.53790238836968, 7.63434343434343,
> > 7.92813765182186, 8.50155763239875, 9.61519302615193, 9.70428015564202,
> > 9.4328947368421, 8.59541984732824, 5.55893074119077, 5.86838837844549,
> > 6.35430694218714, 6.68793828892006, 6.59272979856448, 5.81831610044313,
> > 7.18246822033898, 7.32805676855895, 5.939, 6.85257731958763,
> > 7.48630887185104, 7.16906077348066, 9.00130890052356, 9.90243902439024,
> > 7.84958871915394, 8.19285714285714, 7.69109357384442, 7.87118084227911,
> > 4.83343091334895, 8.06544293695132, 5.55677928263134, 8.83374689826303,
> > 5.91642995963522, 8.51578947368421, 6.26183602771363, 10.4579349904398,
> > 6.92585083272991, 9.41557305336833, 7.19042740046838, 7.6807833147588,
> > 10.9243295019157, 7.87441627751835, 6.29256360078278, 7.52888022678951,
> > 6.18485742379548, 7.40448625180897, 7.00034734282737, 7.04250087811732,
> > 7.88884892086331, 5.939, 9.90243902439024, 7.84958871915394,
> > 8.19285714285714, 5.96870653685675, 6.76280701754386, 7.08764367816092,
> > 7.34377276037873, 8.15425531914894, 8.22409638554217, 7.60411899313501,
> > 7.58069498069498, 7.49270664505673, 6.86683630195081, 8.12709620476611,
> > 7.46073298429319, 7.82620087336245, 6.1090719318083, 6.19281131909658,
> > 6.62732809603672, 7.20896453395117, 7.57677270303892, 7.89167412712623,
> > 8.40861296516412, 8.17979855031535, 8.793385982231, 8.76992084432718,
> > 7.95928593798935, 7.74918133442489, 7.97295629820051, 8.09428950863214,
> > 8.44476683937824, 7.01617250673854, 8.24033149171271, 8.15584415584416,
> > 7.792, 8.92711370262391, 9.64838709677419, 10.7218045112782,
> > 8.49354838709677, 9.14084507042254, 7.74712643678161, 9.88702928870293,
> > 9.50579150579151, 10.108, 7.01617250673854, 7.27842377260982,
> > 8.24033149171271, 8.56187521544295, 10.7218045112782, 8.53533333333333,
> > 8.49354838709677, 8.62977099236641, 9.14084507042254, 8.14606741573034,
> > 7.74712643678161, 7.01046176046176, 9.88702928870293, 9.46165191740413,
> > 9.50579150579151, 9.23091110291405, 10.108, 9.37196261682243,
> > 10.6221198156682, 8.92933382407067, 6.1090719318083, 6.62732809603672,
> > 7.20896453395117, 7.57677270303892, 7.89167412712623, 8.40861296516412,
> > 8.17979855031535, 8.793385982231, 8.76992084432718, 7.95928593798935,
> > 7.97295629820051, 6.6392811296534, 7.89387755102041, 8.45956873315364,
> > 11.218523878437, 8.52815829528158, 8.36842105263158, 7.81199351701783,
> > 9.1421647819063, 8.63695299837925, 8.80372250423012, 8.40688575899843,
> > 5.38861047835991, 5.75704809286899, 5.67469310670444, 7.44364292155095,
> > 6.69357976653697, 7.11985688729875, 6.91486146095718, 7.21993127147766,
> > 7.25245732022763, 7.72690106295993, 6.78057939914163, 7.1227495908347,
> > 5.89532920652786, 7.14781172584641, 5.44613511868533, 6.3986543313709,
> > 6.55555555555556, 7.14873140857393, 6.97257268239166, 6.9459219858156,
> > 7.816553428042, 7.19015280135823, 8.65277777777778, 7.44364292155095,
> > 7.11985688729875, 7.21993127147766, 7.72690106295993, 7.53658536585366,
> > 7.1227495908347, 7.14781172584641, 7.14390842191333, 6.3986543313709,
> > 7.14873140857393, 6.9459219858156, 7.16031886625332, 7.19015280135823,
> > 5.12904347826087, 5.90447443181818, 6.26032315978456, 6.51832088224831,
> > 7.62146454862456, 7.76151980598222, 7.66235931638183, 7.14583333333333,
> > 7.40443329150983, 7.63142123287671, 7.54361567635904, 7.9720910261915,
> > 5.56259426847662, 6.42748091603053, 10.6981132075472, 7.92669432918396,
> > 7.15964240102171, 6.74368686868687, 6.8751677852349, 5.89911727616646,
> > 6.29238329238329, 6.35765550239234, 6.54787878787879, 6.6196682464455,
> > 4.97549019607843, 4.76815181518152, 6.92771464646465, 5.67053364269142,
> > 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
> > 4.97549019607843, 4.76815181518152, 5.77957177957178, 5.61423550087873,
> > 5.92077087794433, 5.71404399323181, 6.21070693205216, 5.85202863961814,
> > 6.83663527119195, 6.39923954372624, 6.7621359223301, 6.24686809137804,
> > 6.6576836701957, 5.94338235294118, 6.1901681759379, 5.3241330502477,
> > 6.27197452229299, 5.2630890052356, 6.00831467860569, 5.20410703173615,
> > 6.69428926132837, 5.35815602836879, 6.92771464646465, 5.67053364269142,
> > 7.18136769078295, 5.61715601611975, 7.3194626474443, 5.95308083663086,
> > 7.58947368421053, 6.12723449001052, 8.22988505747126, 6.13786008230453,
> > 10.7810218978102, 6.18452935694315, 9.57971014492754, 6.37686240140228,
> > 9.55633802816901, 6.40726124704025, 10.9912280701754, 7.50491510277033,
> > 6.6267902274642, 12.7692307692308, 6.54754358161648, 9.41666666666667,
> > 6.12397311426438, 6.33300923675255, 7.51452081316554, 8.43537759756716,
> > 8.91471658866355, 8.85417775412453, 9.22906267332224, 7.91540948275862,
> > 12.7830785982175, 12.4487962924989, 10.4415342832695, 10.6431472456063,
> > 10.9882582421785, 12.2438777496593, 12.0890472647531, 12.5818225285891,
> > 12.9612504978096, 12.9894630601534, 12.7830785982175, 12.4487962924989,
> > 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.64585063389249,
> > 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
> > 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
> > 9.5292768273717, 8.12304189928993, 9.9727155921699, 8.22741701189003,
> > 10.4415342832695, 8.67943833678023, 10.6431472456063, 9.44432726465364,
> > 10.9882582421785, 9.64585063389249, 11.2046290203971, 10.3339912033382,
> > 12.2438777496593, 10.8793211816468, 12.0890472647531, 10.9038385212905,
> > 12.5818225285891, 9.96331605062162, 12.9612504978096, 10.5577464788732,
> > 12.9894630601534, 10.6464283645212, 12.7830785982175, 10.9712915896488,
> > 12.4487962924989, 11.7409097942132, 8.12304189928993, 8.22741701189003,
> > 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
> > 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> > 10.6464283645212, 10.9712915896488, 11.7409097942132, 7.60162173546757,
> > 8.12304189928993, 8.12884556807798, 8.22741701189003, 8.50751879699248,
> > 8.67943833678023, 9.50669336987457, 9.44432726465364, 9.60444538080691,
> > 9.64585063389249, 10.3580374702412, 10.3339912033382, 10.623085106383,
> > 10.8793211816468, 10.652063841497, 10.9038385212905, 9.73269924565431,
> > 9.96331605062162, 9.73378689783825, 10.5577464788732, 9.40273672687466,
> > 10.6464283645212, 9.63958263958264, 10.9712915896488, 9.58136439267887,
> > 11.7409097942132, 10.5577464788732, 10.6464283645212, 10.9712915896488,
> > 11.7409097942132, 7.60162173546757, 8.12304189928993, 8.12884556807798,
> > 8.22741701189003, 8.50751879699248, 8.67943833678023, 9.50669336987457,
> > 9.44432726465364, 9.60444538080691, 9.64585063389249, 10.3580374702412,
> > 10.3339912033382, 10.623085106383, 10.8793211816468, 10.652063841497,
> > 10.9038385212905, 9.73269924565431, 9.96331605062162, 9.73378689783825,
> > 10.5577464788732, 9.40273672687466, 10.6464283645212, 9.63958263958264,
> > 10.9712915896488, 9.58136439267887, 11.7409097942132, 7.80456026058632,
> > 8.21162579473206, 7.90869939707149, 9.46188340807175, 9.84302862419206,
> > 9.28445747800587, 8.86706349206349, 9.19162303664922, 9.07971014492754,
> > 9.36363636363636, 8.9917695473251, 9.58350515463917, 9.92813141683778,
> > 6.91358743089904, 6.79414180125924, 7.10879001627781, 7.57619451512581,
> > 7.44309173272933, 7.84115827944897, 8.11397967591321, 8.60985797827903,
> > 8.50920411478073, 8.42636072572038, 8.62165740005295, 8.74824081313526,
> > 8.76567398119122, 6.7948984903696, 6.78862606945143, 7.73729266987694,
> > 7.95042643923241, 8.11260775862069, 7.98584163607761, 8.20189773326305,
> > 8.06330416881112, 8.26944585663447, 8.53329918032787, 7.45793103448276,
> > 7.74049803407602, 8.16645161290323, 8.04025974025974, 8.01747815230961,
> > 8.43163869693978, 8.95605518650996, 9.074016563147, 9.84807379272925,
> > 10.4413265306122, 10.0133412392529, 10.3694306930693, 11.3058269996381,
> > 10.5112277631963, 9.43511312217194, 10.0543611256773, 10.0988177166049,
> > 9.43511312217194, 10.0543611256773, 10.0988177166049, 7.95654087358345,
> > 8.30098346482222, 6.09793351302785, 6.63657733897508, 6.20885116702031,
> > 7.01203369434416, 6.72523686477175, 6.81696529825357, 6.60735659027879,
> > 7.2252358490566, 7.15823293172691, 6.95142670442169, 7.00189449140192,
> > 7.40715109573241, 7.14274691358025, 7.1871996505024, 7.08865000698032,
> > 7.20507399577167, 6.90175438596491, 7.26443243243243, 7.16230014778987,
> > 7.62271805273834, 7.19021364576154, 7.57658619953001, 7.5522002839076,
> > 7.9588785046729, 7.41418157720345, 7.72357894736842, 7.43353681325526,
> > 7.81007067137809, 7.65282284231019, 7.89898132427844, 7.58417971083762,
> > 8.20162748643761, 7.48300192431046, 7.57974891953077, 7.69333333333333,
> > 8.15555555555556, 7.56432566811684, 7.7354761429427, 7.81993065652612,
> > 8.25194805194805, 7.9640644361834, 7.7116781157998, 7.8797826328047,
> > 8.15601023017903, 8.30181818181818, 7.99027426570706, 7.95654087358345,
> > 8.79780960404381, 7.93843395098625, 7.840061514802, 8.30098346482222,
> > 8.58135860979463, 6.20885116702031, 7.00189449140192, 7.08865000698032,
> > 7.16230014778987, 7.5522002839076, 7.43353681325526, 7.58417971083762,
> > 7.69333333333333, 7.8797826328047, 7.95654087358345, 8.30098346482222,
> > 6.97558922558923, 7.56495726495726, 7.99651264167393, 9.85160202360877,
> > 8.94103194103194, 9.66104417670683, 10.6750814332248, 11.5657998423956,
> > 11.4848254931715, 10.4968242766408, 10.1266435986159, 8.12304189928993,
> > 8.22741701189003, 8.67943833678023, 9.64585063389249, 10.3339912033382,
> > 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> > 10.6464283645212, 10.9712915896488, 11.7409097942132, 8.12304189928993,
> > 8.22741701189003, 8.67943833678023, 9.44432726465364, 9.64585063389249,
> > 10.3339912033382, 10.8793211816468, 10.9038385212905, 9.96331605062162,
> > 10.5577464788732, 10.6464283645212, 10.9712915896488, 11.7409097942132,
> > 8.12304189928993, 8.22741701189003, 8.67943833678023, 9.44432726465364,
> > 9.64585063389249, 10.3339912033382, 10.8793211816468, 10.9038385212905,
> > 9.96331605062162, 10.5577464788732, 10.6464283645212, 10.9712915896488,
> > 11.7409097942132, 8.12304189928993, 8.22741701189003, 8.67943833678023,
> > 9.44432726465364, 9.64585063389249, 10.3339912033382, 10.8793211816468,
> > 10.9038385212905, 9.96331605062162, 10.5577464788732, 10.6464283645212,
> > 10.9712915896488, 11.7409097942132, 7.81993065652612, 10.5577464788732,
> > 7.8797826328047, 10.6464283645212, 7.95654087358345, 10.9712915896488,
> > 8.30098346482222, 11.7409097942132, 6.8108605614358, 6.88741567806467,
> > 6.98612074947953, 6.9482880755608, 7.5150142993327, 7.67364213496356,
> > 8.04991719895907, 8.06427398545625, 7.73682983682984, 7.91900905192949,
> > 7.91520190023753, 8.0556866446437, 8.12304189928993, 8.22741701189003,
> > 8.67943833678023, 9.44432726465364, 9.64585063389249, 10.3339912033382,
> > 10.8793211816468, 10.9038385212905, 9.96331605062162, 10.5577464788732,
> > 10.6464283645212, 10.9712915896488, 11.7409097942132)), row.names = c(NA,
> > -800L), class = c("tbl_df", "tbl", "data.frame"))
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m||uj|@b @end|ng |rom gm@||@com  Tue Sep  3 18:27:42 2019
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Tue, 3 Sep 2019 18:27:42 +0200
Subject: [R] Sequential date by group
In-Reply-To: <alpine.BSF.2.00.1909021519390.78319@pedal.dcn.davis.ca.us>
References: <CAMLwc7N=PShY-OJwNXQ7_h=0OSULwv1wYBYvGChszKcY4Kw5TQ@mail.gmail.com>
 <alpine.BSF.2.00.1909021519390.78319@pedal.dcn.davis.ca.us>
Message-ID: <CAMLwc7Oupa2MBv4VmsEnZOpO+ncOkGvHCpXbyLDnuFSNtbGs0Q@mail.gmail.com>

Thanks, Jeff. I am trying your solutions - appreciate your help!

Best,

Milu

On Tue, Sep 3, 2019 at 12:51 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Your sample data has startdate and enddate columns as though these values
> might vary throughout the data set, but your description suggests that
> those values are fixed for the whole dataset.
>
> If those values are really constant, then
>
> x$Year <- 1995L + 12 * ( ( x$month - 1L ) %/% 12L )
> x$Month <- ( x$month - 1L ) %% 12L + 1
>
> should be enough.
>
> If in fact your startdate can be different for different IDs, then you
> would need to wrap this up a bit:
>
> ############ base R
> x$startdate <- as.Date( as.character( x$startdate ) )
> x$Y <- as.integer( format( DF$startdate, format = "%Y" ) )
> xlist <- split( x, x$id )
> xlist1 <- lapply( xlist
>                  , FUN = function( DF ) {
>                      DF$Year <- Y + 12 * ( ( DF$month - 1L ) %/% 12L )
>                      DF$Month <- ( DF$month - 1L ) %% 12L + 1
>                      DF
>                    }
>                  )
> x1 <- unsplit( xlist1, x$id )
>
> ###### dplyr
> library(dplyr)
> x2 <- (   x
>        %>% mutate( Y = as.integer( format( startdate, format = "%Y" ) ) )
>        %>% group_by( id )
>        %>% mutate( Year = Y + 12L * ( ( month - 1L ) %/% 12L )
>                  , Month = ( month - 1L ) %% 12L + 1L
>                  )
>        %>% ungroup
>        )
> #########
>
> On Mon, 2 Sep 2019, Miluji Sb wrote:
>
> > Dear all,
> >
> > I have a panel data with a large number of groups and the cumulative
> number
> > of months (1 - 372) for January 1995 to December 2005. My goal is to
> > extract the corresponding month and year for each observation.
> >
> > I tried the following;
> >
> > ###
> > x %>%
> >  group_by(id) %>%
> >  do( data.frame(., Date= seq(.$startdate,
> >                              as.Date('1975-01-01'), by = '1 month')))
> >
> > However, I get the following error;
> >
> > ###
> > Error in seq.default(.$startdate, as.Date("1975-01-01"), by = "1 month")
> :
> >  'from' must be of length 1
> >
> > Essentially, I want to convert the month number (1-372) to January 1975
> to
> > December 2005 by ID. Is that possible? Any help will be highly
> appreciated.
> >
> > ### Data ###
> > x <- structure(list(id = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L), month =
> > c(1L,
> > 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L), startdate = structure(c(1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1975-01-01", class =
> "factor"),
> >    enddate = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
> > "2005-12-31", class = "factor")), class = "data.frame", row.names = c(NA,
> > -9L))
> >
> > Cross-posted in Statalist - however, Stata seems to have a very
> inflexible
> > date-time structure.
> >
> > Best regards,
> >
> > Milu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

	[[alternative HTML version deleted]]


From |_j_rod @end|ng |rom hotm@||@com  Wed Sep  4 11:55:47 2019
From: |_j_rod @end|ng |rom hotm@||@com (Frank S.)
Date: Wed, 4 Sep 2019 09:55:47 +0000
Subject: [R] Efficient way to update a survival model
In-Reply-To: <79B2FB80-0D6F-45C5-AB45-AC6814E43AB3@ucsd.edu>
References: <VI1PR04MB5726D4BB6BF9B179B03F1FB1BAA30@VI1PR04MB5726.eurprd04.prod.outlook.com>
 <20190829085410.Horde.cR3kDdYBZGYzoxbukl-m7xZ@webmail.unipa.it>
 <VI1PR04MB57262BC7EFF56B29A668A88DBAA20@VI1PR04MB5726.eurprd04.prod.outlook.com>
 <VI1PR04MB5726B07EAE5864C32974CFAFBABD0@VI1PR04MB5726.eurprd04.prod.outlook.com>
 <2e9ea8fb168f46a78bb704bc3ba65b81@med.umich.edu>
 <VI1PR04MB5726E7FFAB286C08FFEA7D86BABD0@VI1PR04MB5726.eurprd04.prod.outlook.com>,
 <79B2FB80-0D6F-45C5-AB45-AC6814E43AB3@ucsd.edu>
Message-ID: <VI1PR04MB5726C4C0471044C7217DD2CBBAB80@VI1PR04MB5726.eurprd04.prod.outlook.com>

Charles, thank you for your suggestion!

Frank S.
________________________________
De: Berry, Charles <ccberry at ucsd.edu>
Enviado: s?bado, 31 de agosto de 2019 19:21
Para: Frank S. <f_j_rod at hotmail.com>
Cc: Andrews, Chris <chrisaa at med.umich.edu>; r-help at r-project.org <r-help at r-project.org>
Asunto: Re: Efficient way to update a survival model

The i^th model is included in the Cox[[ i ]] object.

You can extract the formula objects with:

frms <- lapply(Cox, formula)

then if you want the existing and incremental terms:

indeps <- lapply(frms, function(x) as.list( x[[ 3 ]] ))

oldTerms <- lapply(indeps, "[[", 2)

newTerms <- lapply(indeps, "[[", 3)

> oldTerms[3:4]
[[1]]
v + cos(1 * v) + cos(2 * v)

[[2]]
v + cos(1 * v) + cos(2 * v) + cos(3 * v)

> newTerms[ 3:4 ]
[[1]]
cos(3 * v)

[[2]]
cos(4 * v)

>

HTH,

Chuck

> On Aug 30, 2019, at 3:36 PM, Frank S. <f_j_rod at hotmail.com> wrote:
>
[[elided Hotmail spam]]
>
> Just one minor question:
> I wonder how to include within the loop of your solution the 10 models, that is, writing
> for (k in 1:10) so that you can get {Cox[[1]], ..., Cox[[10]]}. However, I'm aware that some
> change has to be done due to the fact that, when computing Cox[[1]], the term Cox[[k -1]]
> does not exist. Is it possible to perform some "trick" (e.g. re-indexing) in order to achieve this?
>
> Best,
>
> Frank
> ________________________________
> De: Andrews, Chris <chrisaa at med.umich.edu>
> Enviado: viernes, 30 de agosto de 2019 15:08
> Para: Frank S. <f_j_rod at hotmail.com>; Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Asunto: RE: [R] Efficient way to update a survival model
>
> The updated formula needs to have a different term rather than cos(k * v) every time.  Here is one way to explicitly change the formula.
>
> library("survival")
> set.seed(1)
> v <- runif(nrow(pbc), min = 0, max = 2)
> Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
>
> Cox <- vector("list", 10)
> Cox[[1]] <- update(Cox0, . ~ . + cos(1 * v))
> for (k in 2:10) {
>        form <- as.formula(sprintf(". ~ . + cos(%d * v)", k))
>        Cox[[k]] <- update(Cox[[k-1]], form)
> }
>
> Cox
>
> -----Original Message-----
> From: Frank S. [mailto:f_j_rod at hotmail.com]
> Sent: Friday, August 30, 2019 5:54 AM
> To: Vito Michele Rosario Muggeo
> Cc: r-help at r-project.org
> Subject: Re: [R] Efficient way to update a survival model
>
> Hi everyone,
>
> Vito, perhaps my previous mail was not clear.  It is true that I used a loop, but the key point is that such a loop
> cannot compute the desired result. For example, for k = 3 the following loop
>
> Cox <- list()
> Cox[[1]] <- coxph(Surv(time,status == 2) ~ v + cos(v), data =  pbc)
> for (k in 2:10) {
>  Cox[[k]] <- update(Cox[[k-1]], . ~ . + cos(k * v), data =  pbc)
> }
>
> leads to a model Cox[[3]] which accounts for terms {v, cos(v), cos(3*v)}, but does not include the term cos(2*v).
> I think that this could be one way to solve my question:
>
> library("survival")
> set.seed(1)
> v <- runif(nrow(pbc), min = 0, max = 2)
> Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
> k.max <- 9
> Z <- outer(v, 1:k.max, function (x, y) {sin(x * y)})  # Matrix with the outer product of the two arrays
>
> Cox <- list()
> for (k in 1:k.max){
> Cox[[k]] <-
>   update(Cox0, substitute(. ~ . + Z[, 1:k]), data =  pbc)
>   attr(Cox[[k]]$coefficients, "names")[2:(k+1)] <- paste0("sin(", 1:k, "* v)")
> }
> Cox
>
> Best,
>
> Frank
>
> _____



	[[alternative HTML version deleted]]


From |_j_rod @end|ng |rom hotm@||@com  Wed Sep  4 11:57:00 2019
From: |_j_rod @end|ng |rom hotm@||@com (Frank S.)
Date: Wed, 4 Sep 2019 09:57:00 +0000
Subject: [R] Efficient way to update a survival model
In-Reply-To: <91c546469e9c48a085fe7aba297f8e95@med.umich.edu>
References: <VI1PR04MB5726D4BB6BF9B179B03F1FB1BAA30@VI1PR04MB5726.eurprd04.prod.outlook.com>,
 <20190829085410.Horde.cR3kDdYBZGYzoxbukl-m7xZ@webmail.unipa.it>,
 <VI1PR04MB57262BC7EFF56B29A668A88DBAA20@VI1PR04MB5726.eurprd04.prod.outlook.com>
 <VI1PR04MB5726B07EAE5864C32974CFAFBABD0@VI1PR04MB5726.eurprd04.prod.outlook.com>,
 <2e9ea8fb168f46a78bb704bc3ba65b81@med.umich.edu>,
 <VI1PR04MB5726E7FFAB286C08FFEA7D86BABD0@VI1PR04MB5726.eurprd04.prod.outlook.com>,
 <91c546469e9c48a085fe7aba297f8e95@med.umich.edu>
Message-ID: <VI1PR04MB5726D23D611CB85DCA5CD13CBAB80@VI1PR04MB5726.eurprd04.prod.outlook.com>

Chris, thank you so much for your answer!!

Best,

Frank S.
________________________________
De: Andrews, Chris <chrisaa at med.umich.edu>
Enviado: martes, 3 de septiembre de 2019 14:14
Para: Frank S. <f_j_rod at hotmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Asunto: Re: [R] Efficient way to update a survival model

library("survival")
set.seed(1)
v <- runif(nrow(pbc), min = 0, max = 2)
Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)

Cox <- vector("list", 10)
for (k in 1:10) {
        form <- as.formula(sprintf(". ~ . + cos(%d * v)", k))
        Cox[[k]] <- update(if (k==1) Cox0 else Cox[[k-1]], form)
}
________________________________________
From: Frank S. <f_j_rod at hotmail.com>
Sent: Friday, August 30, 2019 6:36:39 PM
To: Andrews, Chris
Cc: r-help at r-project.org
Subject: RE: [R] Efficient way to update a survival model

External Email - Use Caution
[[elided Hotmail spam]]

Just one minor question:
I wonder how to include within the loop of your solution the 10 models, that is, writing
for (k in 1:10) so that you can get {Cox[[1]], ..., Cox[[10]]}. However, I'm aware that some
change has to be done due to the fact that, when computing Cox[[1]], the term Cox[[k -1]]
does not exist. Is it possible to perform some "trick" (e.g. re-indexing) in order to achieve this?

Best,

Frank
________________________________
De: Andrews, Chris <chrisaa at med.umich.edu>
Enviado: viernes, 30 de agosto de 2019 15:08
Para: Frank S. <f_j_rod at hotmail.com>; Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
Cc: r-help at r-project.org <r-help at r-project.org>
Asunto: RE: [R] Efficient way to update a survival model

The updated formula needs to have a different term rather than cos(k * v) every time.  Here is one way to explicitly change the formula.

library("survival")
set.seed(1)
v <- runif(nrow(pbc), min = 0, max = 2)
Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)

Cox <- vector("list", 10)
Cox[[1]] <- update(Cox0, . ~ . + cos(1 * v))
for (k in 2:10) {
        form <- as.formula(sprintf(". ~ . + cos(%d * v)", k))
        Cox[[k]] <- update(Cox[[k-1]], form)
}

Cox

-----Original Message-----
From: Frank S. [mailto:f_j_rod at hotmail.com]
Sent: Friday, August 30, 2019 5:54 AM
To: Vito Michele Rosario Muggeo
Cc: r-help at r-project.org
Subject: Re: [R] Efficient way to update a survival model

Hi everyone,

Vito, perhaps my previous mail was not clear.  It is true that I used a loop, but the key point is that such a loop
cannot compute the desired result. For example, for k = 3 the following loop

Cox <- list()
Cox[[1]] <- coxph(Surv(time,status == 2) ~ v + cos(v), data =  pbc)
for (k in 2:10) {
  Cox[[k]] <- update(Cox[[k-1]], . ~ . + cos(k * v), data =  pbc)
}

leads to a model Cox[[3]] which accounts for terms {v, cos(v), cos(3*v)}, but does not include the term cos(2*v).
I think that this could be one way to solve my question:

library("survival")
set.seed(1)
v <- runif(nrow(pbc), min = 0, max = 2)
Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
k.max <- 9
Z <- outer(v, 1:k.max, function (x, y) {sin(x * y)})  # Matrix with the outer product of the two arrays

Cox <- list()
for (k in 1:k.max){
 Cox[[k]] <-
   update(Cox0, substitute(. ~ . + Z[, 1:k]), data =  pbc)
   attr(Cox[[k]]$coefficients, "names")[2:(k+1)] <- paste0("sin(", 1:k, "* v)")
}
Cox

Best,

Frank

________________________________
De: Frank S. <f_j_rod at hotmail.com>
Enviado: jueves, 29 de agosto de 2019 12:38
Para: Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
Cc: r-help at r-project.org <r-help at r-project.org>
Asunto: RE: [R] Efficient way to update a survival model

Hi Vito,

Thanks for your reply! Following your suggestion, I have tried:

Cox[[3]] <- update(Cox[[2]], . ~ . + cos(3 * v), init=c(coef(Cox[[1]]), 0, 0), data =  pbc)
Cox[[3]] <- update(Cox[[2]], . ~ . + cos(3 * v), data =  pbc)

and both expressions lead to the same result. Is that OK?

Additionally, in my original question I wondered about the possibility of reducing the
10 lines of code to one general expression or some  loop. Is it possible?

Best,

Frank
________________________________
De: Vito Michele Rosario Muggeo <vito.muggeo at unipa.it>
Enviado: jueves, 29 de agosto de 2019 8:54
Para: Frank S. <f_j_rod at hotmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Asunto: Re: [R] Efficient way to update a survival model

dear Frank,

update() does not update actually.. It just builds a new call which is
evaluated. To speed up the procedure you could try to supply starting
values via argument 'init'. The first values come from the previous
fit, and the last one referring to new coefficients is set to zero (or
any other appropriate value).

Something like (untested), for instance

update(Cox[[2]], . ~ . + cos(3 * v), init=c(coef(Cox[[1]]),0), data =  pbc)

Hope this helps,
best,
vito



"Frank S." <f_j_rod at hotmail.com> ha scritto:

> Hello everybody, I come with a question which I do not know how to
> conduct in an efficient way. In order to
> provide a toy example, consider the dataset "pbc" from the package
> "survival". First, I fit the Cox model "Cox0":
>
> library("survival")
> set.seed(1)
> v <- runif(nrow(pbc), min = 0, max = 2)
> Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
>
> Then, from the above model, I can fit recursively 10 additional models as:
>
> Cox <- list()
>
> Cox[[1]] <- update(Cox0, . ~ . + cos(1 * v), data =  pbc)
> Cox[[2]] <- update(Cox[[1]], . ~ . + cos(2 * v), data =  pbc)
> Cox[[3]] <- update(Cox[[2]], . ~ . + cos(3 * v), data =  pbc)
> Cox[[4]] <- update(Cox[[3]], . ~ . + cos(4 * v), data =  pbc)
> ...
> Cox[[10]] <- update(Cox[[9]], . ~ . + cos(10* v), data =  pbc)
>
> Since in practice I have to repeat above step until Cox[[100]], say,
> do you know an efficient way to
> wrap this code chunk in a loop or similar?
>
> I had tried:
>
> set.seed(1)
> v <- runif(nrow(pbc), min = 0, max = 2)
> Cox0 <- coxph(Surv(pbc$time,pbc$status == 2) ~ v, data =  pbc)
>
> Cox <- list()
> Cox[[1]] <- update(Cox0, . ~ . + cos(1 * v), data =  pbc)
> for (k in 1:10) {
>   Cox[[k + 1]] <- update(Cox[[k]], . ~ . + cos((k + 1) * v), data =  pbc)
> }
>
> However, from Cox[[3]] onwards, the intermediate values of integer k
> are not included here (for
>  instance, the model Cox[[10]] would only include the cosinus terms
> for cos(1*v) and cos(10*v)).
>
[[elided Hotmail spam]]
>
> Frank
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



        [[alternative HTML version deleted]]


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues
**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues


	[[alternative HTML version deleted]]


From |@heemj@n93 @end|ng |rom y@hoo@com  Wed Sep  4 12:28:59 2019
From: |@heemj@n93 @end|ng |rom y@hoo@com (Faheem Jan)
Date: Wed, 4 Sep 2019 10:28:59 +0000 (UTC)
Subject: [R] Durbin- Levinson algorithm
References: <2084007458.1398576.1567592939383.ref@mail.yahoo.com>
Message-ID: <2084007458.1398576.1567592939383@mail.yahoo.com>

hi, i have a problem that how i could use Durbin- levinson algorithm for prediction in case of multiple time series? how i could do this in R...

	[[alternative HTML version deleted]]


From |@heemj@n93 @end|ng |rom y@hoo@com  Wed Sep  4 12:25:54 2019
From: |@heemj@n93 @end|ng |rom y@hoo@com (Faheem Jan)
Date: Wed, 4 Sep 2019 10:25:54 +0000 (UTC)
Subject: [R] Functional final prediction error
References: <1718928525.1388973.1567592754015.ref@mail.yahoo.com>
Message-ID: <1718928525.1388973.1567592754015@mail.yahoo.com>

Hi, my question is related functional data analysis, what is functional final prediction error how we can use to transform vector autoregressive model to its functional form...need help in this regard i will be thanks ful..

	[[alternative HTML version deleted]]


From S@E|||@on @end|ng |rom LGCGroup@com  Wed Sep  4 13:49:51 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Wed, 4 Sep 2019 11:49:51 +0000
Subject: [R] Durbin- Levinson algorithm
In-Reply-To: <2084007458.1398576.1567592939383@mail.yahoo.com>
References: <2084007458.1398576.1567592939383.ref@mail.yahoo.com>
 <2084007458.1398576.1567592939383@mail.yahoo.com>
Message-ID: <6d2a3ad2de794f3c85f82699b6d79f39@GBDCVPEXC08.corp.lgc-group.com>

Google "levionson-Durbin in R

The first reference is the levinson function in the signal package.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Faheem
> Jan via R-help
> Sent: 04 September 2019 11:29
> To: R-help Mailing List
> Subject: [R] Durbin- Levinson algorithm
> 
> ===============
>  EXTERNAL EMAIL
> ===============
> 
> hi, i have a problem that how i could use Durbin- levinson algorithm for
> prediction in case of multiple time series? how i could do this in R...
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ==========================================================
> ====================================
> WARNING - EXTERNAL: This email originated from outside of LGC. Do not click
> any links or open any attachments
> unless you trust the sender and know that the content is safe
> ==========================================================
> ====================================


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Wed Sep  4 15:24:57 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Wed, 4 Sep 2019 15:24:57 +0200
Subject: [R] [effects] allEffects does not accept integer value for xlevels
Message-ID: <3bb9b027-c78c-f509-ee2f-8286723484ce@math.uni-giessen.de>

Dear list,

citing from allEffects' help page (of package effects 4.1-2):
"If xlevels=n is an integer, then each numeric predictor is
represented by n equally spaced values rounded to 'nice' numbers."
	

However, adapting the first example from allEffects' help
page throws an an error:

mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
                   data=Cowles, family=binomial)
allEffects(mod.cowles, xlevels=5)
Error in xlevels[[name]] : subscript out of bounds


It appears to me that the cause is buried in
effects:::Analyze.model

in or close to the the lines

if (is.numeric(xlevels) & length(xlevels) == 1L) {
   levs <- xlevels
   for (name in focal.predictors) xlevels[[name]] <- levs
  }



where xlevels -- while not being a list in this case -- is
subscripted by xlevels[[name]].

Is anyone aware of a workaround (without having to specify all
numeric predictors of the used model explicitly in a list and
giving it to xlevels when calling allEffects), and without
having to write my own Analyze.model function? ;-)


  Thx in advance and best regards  --  Gerrit



PS:  sessionInfo()

R version 3.6.1 (2019-07-05)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

Matrix products: default

Random number generation:
  RNG:     Mersenne-Twister
  Normal:  Inversion
  Sample:  Rounding

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] effects_4.1-2 carData_3.0-2

loaded via a namespace (and not attached):
  [1] Rcpp_1.0.2        lattice_0.20-38   MASS_7.3-51.4     grid_3.6.1 

  [5] DBI_1.0.0         nlme_3.1-141      survey_3.36 
estimability_1.3
  [9] minqa_1.2.4       nloptr_1.2.1      Matrix_1.2-17     boot_1.3-23 

[13] splines_3.6.1     lme4_1.1-21.9001  survival_2.44-1.1 compiler_3.6.1
[17] colorspace_1.4-1  mitools_2.4       nnet_7.3-12


---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner


From j|ox @end|ng |rom mcm@@ter@c@  Wed Sep  4 16:19:44 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 4 Sep 2019 14:19:44 +0000
Subject: [R] 
 [effects] allEffects does not accept integer value for xlevels
In-Reply-To: <1659_1567603516_x84DOvZp005404_3bb9b027-c78c-f509-ee2f-8286723484ce@math.uni-giessen.de>
References: <1659_1567603516_x84DOvZp005404_3bb9b027-c78c-f509-ee2f-8286723484ce@math.uni-giessen.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836D05421@FHSDB2D11-2.csu.mcmaster.ca>

Dear Gerrit,

Yes, that appears to be a bug in Effect() -- too bad that it wasn't discovered earlier because a new version of the package was submitted yesterday, but thank you for the bug report.

We'll fix the bug, but until then a work-around is to specify the number of levels for each numeric predictor, as in

	allEffects(mod.cowles, xlevels=list(neuroticism=4, extraversion=4))

I used 4 levels here to verify that this works correctly, since 5 is the default.

As well, although unrelated to this bug, you might take a look at predictorEffects(), which we recommend in preference to allEffects().

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gerrit
> Eichner
> Sent: Wednesday, September 4, 2019 9:25 AM
> To: r-help at r-project.org
> Subject: [R] [effects] allEffects does not accept integer value for
> xlevels
> 
> Dear list,
> 
> citing from allEffects' help page (of package effects 4.1-2):
> "If xlevels=n is an integer, then each numeric predictor is represented by
> n equally spaced values rounded to 'nice' numbers."
> 
> 
> However, adapting the first example from allEffects' help page throws an
> an error:
> 
> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
>                    data=Cowles, family=binomial) allEffects(mod.cowles,
> xlevels=5) Error in xlevels[[name]] : subscript out of bounds
> 
> 
> It appears to me that the cause is buried in effects:::Analyze.model
> 
> in or close to the the lines
> 
> if (is.numeric(xlevels) & length(xlevels) == 1L) {
>    levs <- xlevels
>    for (name in focal.predictors) xlevels[[name]] <- levs
>   }
> 
> 
> 
> where xlevels -- while not being a list in this case -- is subscripted by
> xlevels[[name]].
> 
> Is anyone aware of a workaround (without having to specify all numeric
> predictors of the used model explicitly in a list and giving it to xlevels
> when calling allEffects), and without having to write my own Analyze.model
> function? ;-)
> 
> 
>   Thx in advance and best regards  --  Gerrit
> 
> 
> 
> PS:  sessionInfo()
> 
> R version 3.6.1 (2019-07-05)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10 x64
> (build 18362)
> 
> Matrix products: default
> 
> Random number generation:
>   RNG:     Mersenne-Twister
>   Normal:  Inversion
>   Sample:  Rounding
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252 [3]
> LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5]
> LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] effects_4.1-2 carData_3.0-2
> 
> loaded via a namespace (and not attached):
>   [1] Rcpp_1.0.2        lattice_0.20-38   MASS_7.3-51.4     grid_3.6.1
> 
>   [5] DBI_1.0.0         nlme_3.1-141      survey_3.36
> estimability_1.3
>   [9] minqa_1.2.4       nloptr_1.2.1      Matrix_1.2-17     boot_1.3-23
> 
> [13] splines_3.6.1     lme4_1.1-21.9001  survival_2.44-1.1 compiler_3.6.1
> [17] colorspace_1.4-1  mitools_2.4       nnet_7.3-12
> 
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@|||P@dpo@t @end|ng |rom gm@||@com  Wed Sep  4 16:35:30 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Wed, 4 Sep 2019 17:35:30 +0300
Subject: [R] Change Y-axis labels
Message-ID: <CAH6117KOVTMOyV7A=RCVU1Q=3=FCnDg39UO7F+UXS_hjtH_Vsw@mail.gmail.com>

The Y scale is divided (by default) as:
0.0 ... 0.2 ... 0.4 ... 0.6 ... 0.8 ...1.0
But I would like so:
0 ... 20 ... 40 ... 60 ... 80... 100
(with rotating axis labels)
When I use par function (marked as comment here) it turns out
correctly for ONLY ONE picture?! Help me, please. (This is the code
for restricted mean survival time.)

install.packages("survival")
install.packages("survRM2")
library(survival)
library(survRM2)
#automatically creates a sample data
D=rmst2.sample.data()
time=D$time
status=D$status
arm=D$arm
tau=NULL
a=rmst2(time, status, arm, tau=10)
#par(yaxt="n")
plot(a, xlab="Years", ylab="Probability", density=60)
#par(yaxt="s")
#axis(side = 2, at = seq(0, 1, 0.2), labels = seq(0, 100, 20), las = 1)


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Wed Sep  4 22:37:17 2019
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Wed, 4 Sep 2019 13:37:17 -0700
Subject: [R] creating a line plot for time series data for several years
Message-ID: <CAMwU6B2RtjySsQ9AKbijDJa5vE2SZ21QQ6ieXrdmfSiAzFwRwQ@mail.gmail.com>

Hi R Users,
I have been getting a trouble to create a time series plot (line) as I was
trying to create a line graph for each year using month and date (in x
axis). I would like to put only one x axis (month and date) for three years
using the facet_grid, but it has not been creating a lineplot for me. I
wanted to compare (visually) whether  the date of observing of the
population vary by year.
I used the following code but did not plot for me any line. Is there any
possibility to create the lines for each year? A sample of the data is
given for your information.

daT$DATE<-format(as.Date(daT$date), format="%m/%d")
Ab<-ggplot(daT, aes(x= as.factor(DATE), y=abundance, colour=site)) +
    geom_line() +
    theme_bw()
Ab+facet_grid(year~.)+theme(axis.text.x = element_text(angle = 90, hjust =
1, size=4))
###

daT<-structure(list(year = c(2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
2018L, 2018L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
2017L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L), date = structure(c(231L, 232L, 233L, 234L, 235L, 236L,
237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L,
259L, 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L,
270L, 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L,
281L, 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L,
292L, 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L,
303L, 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L,
314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L,
325L, 326L, 327L, 328L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
125L, 126L, 127L, 128L, 129L, 130L, 131L, 131L, 132L, 132L, 133L,
133L, 134L, 135L, 135L, 136L, 136L, 137L, 138L, 138L, 139L, 140L,
141L, 142L, 143L, 144L, 145L, 146L, 146L, 147L, 148L, 149L, 150L,
151L, 152L, 153L, 154L, 155L, 156L, 157L, 157L, 158L, 158L, 159L,
159L, 160L, 160L, 161L, 162L, 163L, 164L, 164L, 165L, 165L, 166L,
166L, 167L, 167L, 168L, 168L, 169L, 170L, 170L, 171L, 171L, 172L,
172L, 173L, 173L, 174L, 174L, 175L, 175L, 176L, 176L, 177L, 178L,
178L, 179L, 179L, 180L, 180L, 181L, 182L, 183L, 183L, 184L, 184L,
185L, 186L, 187L, 188L, 188L, 189L, 190L, 190L, 191L, 191L, 192L,
193L, 194L, 195L, 195L, 196L, 196L, 197L, 197L, 198L, 198L, 199L,
199L, 200L, 201L, 201L, 202L, 203L, 203L, 204L, 205L, 206L, 207L,
208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L, 216L, 217L, 218L,
219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L, 227L, 228L, 229L,
230L, 230L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 9L, 10L, 11L,
12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 16L, 17L, 17L, 18L, 19L,
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 27L, 28L, 28L, 29L, 30L,
31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 38L, 39L, 40L, 40L, 41L,
41L, 42L, 43L, 44L, 45L, 46L, 47L, 47L, 48L, 49L, 50L, 51L, 52L,
52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 59L, 60L, 61L, 62L, 63L,
63L, 64L, 65L, 66L, 67L, 68L, 68L, 69L, 70L, 71L, 72L, 72L, 73L,
73L, 74L, 74L, 75L, 76L, 76L, 77L, 78L, 78L, 79L, 80L, 81L, 82L,
83L, 84L, 85L, 85L, 86L, 87L, 87L, 88L, 89L, 90L, 91L, 92L, 92L,
93L, 94L, 94L, 95L, 96L, 96L, 97L, 98L, 98L, 99L, 100L, 100L,
101L, 101L, 102L, 102L, 103L, 104L, 104L, 105L, 106L, 106L, 107L,
107L, 108L, 109L, 110L, 110L, 111L, 111L, 112L, 113L, 114L, 114L,
115L, 116L, 117L), .Label = c("2016-06-01", "2016-06-06", "2016-06-12",
"2016-06-14", "2016-06-16", "2016-06-17", "2016-06-18", "2016-06-19",
"2016-06-21", "2016-06-22", "2016-06-23", "2016-06-24", "2016-06-26",
"2016-06-27", "2016-06-28", "2016-06-30", "2016-07-01", "2016-07-03",
"2016-07-05", "2016-07-07", "2016-07-08", "2016-07-09", "2016-07-11",
"2016-07-12", "2016-07-14", "2016-07-16", "2016-07-17", "2016-07-18",
"2016-07-19", "2016-07-20", "2016-07-21", "2016-07-22", "2016-07-23",
"2016-07-25", "2016-07-26", "2016-07-27", "2016-07-28", "2016-07-29",
"2016-07-30", "2016-08-01", "2016-08-02", "2016-08-03", "2016-08-04",
"2016-08-05", "2016-08-06", "2016-08-07", "2016-08-08", "2016-08-09",
"2016-08-10", "2016-08-11", "2016-08-12", "2016-08-13", "2016-08-14",
"2016-08-15", "2016-08-16", "2016-08-18", "2016-08-19", "2016-08-20",
"2016-08-21", "2016-08-25", "2016-08-26", "2016-08-28", "2016-09-02",
"2016-09-04", "2016-09-05", "2016-09-06", "2016-09-07", "2016-09-08",
"2016-09-09", "2016-09-10", "2016-09-11", "2016-09-12", "2016-09-13",
"2016-09-14", "2016-09-17", "2016-09-18", "2016-09-19", "2016-09-20",
"2016-09-23", "2016-09-24", "2016-09-26", "2016-09-27", "2016-09-28",
"2016-09-29", "2016-09-30", "2016-10-02", "2016-10-03", "2016-10-04",
"2016-10-05", "2016-10-06", "2016-10-08", "2016-10-09", "2016-10-11",
"2016-10-12", "2016-10-13", "2016-10-14", "2016-10-15", "2016-10-16",
"2016-10-18", "2016-10-19", "2016-10-20", "2016-10-21", "2016-10-22",
"2016-10-23", "2016-10-24", "2016-10-25", "2016-10-27", "2016-10-28",
"2016-10-29", "2016-10-30", "2016-10-31", "2016-11-01", "2016-11-02",
"2016-11-07", "2016-11-17", "2016-11-25", "2016-11-27", "2017-06-19",
"2017-07-06", "2017-07-08", "2017-07-12", "2017-07-17", "2017-07-18",
"2017-07-20", "2017-07-21", "2017-07-22", "2017-07-23", "2017-07-24",
"2017-07-25", "2017-07-26", "2017-07-27", "2017-07-29", "2017-07-31",
"2017-08-01", "2017-08-02", "2017-08-03", "2017-08-04", "2017-08-05",
"2017-08-07", "2017-08-09", "2017-08-10", "2017-08-13", "2017-08-15",
"2017-08-16", "2017-08-17", "2017-08-18", "2017-08-20", "2017-08-24",
"2017-08-25", "2017-08-26", "2017-08-28", "2017-08-29", "2017-09-03",
"2017-09-04", "2017-09-06", "2017-09-08", "2017-09-10", "2017-09-11",
"2017-09-12", "2017-09-14", "2017-09-15", "2017-09-16", "2017-09-17",
"2017-09-18", "2017-09-19", "2017-09-21", "2017-09-22", "2017-09-23",
"2017-09-24", "2017-09-25", "2017-09-26", "2017-09-27", "2017-09-28",
"2017-09-29", "2017-09-30", "2017-10-01", "2017-10-02", "2017-10-03",
"2017-10-04", "2017-10-06", "2017-10-07", "2017-10-08", "2017-10-10",
"2017-10-11", "2017-10-12", "2017-10-14", "2017-10-15", "2017-10-16",
"2017-10-19", "2017-10-20", "2017-10-22", "2017-10-23", "2017-10-24",
"2017-10-25", "2017-10-26", "2017-10-27", "2017-10-28", "2017-10-29",
"2017-10-30", "2017-10-31", "2017-11-01", "2017-11-02", "2017-11-03",
"2017-11-04", "2017-11-05", "2017-11-06", "2017-11-07", "2017-11-09",
"2017-11-10", "2017-11-11", "2017-11-13", "2017-11-16", "2017-11-17",
"2017-11-21", "2017-11-22", "2017-11-23", "2017-11-27", "2017-11-28",
"2017-11-29", "2017-11-30", "2017-12-02", "2017-12-03", "2017-12-05",
"2017-12-09", "2017-12-10", "2017-12-11", "2017-12-13", "2017-12-14",
"2017-12-20", "2017-12-21", "2018-07-03", "2018-07-06", "2018-07-07",
"2018-07-08", "2018-07-09", "2018-07-10", "2018-07-11", "2018-07-12",
"2018-07-13", "2018-07-14", "2018-07-16", "2018-07-18", "2018-07-19",
"2018-07-20", "2018-07-21", "2018-07-22", "2018-07-24", "2018-07-25",
"2018-07-26", "2018-07-27", "2018-07-28", "2018-07-29", "2018-07-30",
"2018-07-31", "2018-08-01", "2018-08-02", "2018-08-03", "2018-08-04",
"2018-08-05", "2018-08-07", "2018-08-08", "2018-08-09", "2018-08-10",
"2018-08-11", "2018-08-12", "2018-08-13", "2018-08-14", "2018-08-15",
"2018-08-16", "2018-08-17", "2018-08-18", "2018-08-20", "2018-08-24",
"2018-08-26", "2018-08-27", "2018-08-28", "2018-08-29", "2018-08-30",
"2018-08-31", "2018-09-02", "2018-09-03", "2018-09-04", "2018-09-05",
"2018-09-06", "2018-09-07", "2018-09-08", "2018-09-09", "2018-09-10",
"2018-09-11", "2018-09-12", "2018-09-13", "2018-09-14", "2018-09-15",
"2018-09-17", "2018-09-18", "2018-09-19", "2018-09-20", "2018-09-21",
"2018-09-22", "2018-09-23", "2018-09-24", "2018-09-26", "2018-09-27",
"2018-09-28", "2018-09-29", "2018-09-30", "2018-10-01", "2018-10-02",
"2018-10-03", "2018-10-05", "2018-10-06", "2018-10-08", "2018-10-09",
"2018-10-10", "2018-10-12", "2018-10-13", "2018-10-14", "2018-10-17",
"2018-10-18", "2018-10-19", "2018-10-22", "2018-10-27", "2018-10-28",
"2018-10-29", "2018-11-01", "2018-11-03", "2018-11-04", "2018-11-05"
), class = "factor"), abundance = c(0, 2, 5, 6, 6, 7, 7, 7, 7,
9, 11, 13, 13, 13, 13, 14, 15, 15, 16, 17, 17, 18, 18, 19, 22,
23, 24, 25, 29, 31, 32, 34, 36, 36, 37, 37, 38, 39, 40, 40, 40,
40, 40, 41, 41, 41, 44, 44, 44, 47, 47, 47, 47, 47, 47, 47, 47,
47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,
48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,
48, 48, 48, 48, 48, 48, 48, 48, 48, 1, 2, 2, 2, 3, 4, 5, 6, 6,
6, 7, 9, 10, 11, 12, 14, 14, 15, 15, 16, 18, 19, 21, 22, 24,
25, 25, 26, 27, 28, 29, 30, 31, 31, 33, 33, 35, 36, 37, 38, 39,
40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,
41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,
42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,
42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43,
43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 0,
1, 2, 3, 4, 4, 5, 6, 6, 7, 7, 7, 8, 8, 8, 9, 10, 10, 10, 10,
11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 15, 16, 18, 19,
20, 21, 21, 21, 21, 21, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35,
35, 35, 36, 36, 37, 39, 41, 42, 42, 43, 43, 43, 44, 44, 45, 47,
47, 47, 47, 48, 49, 49, 50, 50, 50, 50, 50, 50, 51, 52, 52, 52,
52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54,
54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,
55, 55, 55, 55, 55), DATE = c("07/03", "07/06", "07/07", "07/08",
"07/09", "07/10", "07/11", "07/12", "07/13", "07/14", "07/16",
"07/18", "07/19", "07/20", "07/21", "07/22", "07/24", "07/25",
"07/26", "07/27", "07/28", "07/29", "07/30", "07/31", "08/01",
"08/02", "08/03", "08/04", "08/05", "08/07", "08/08", "08/09",
"08/10", "08/11", "08/12", "08/13", "08/14", "08/15", "08/16",
"08/17", "08/18", "08/20", "08/24", "08/26", "08/27", "08/28",
"08/29", "08/30", "08/31", "09/02", "09/03", "09/04", "09/05",
"09/06", "09/07", "09/08", "09/09", "09/10", "09/11", "09/12",
"09/13", "09/14", "09/15", "09/17", "09/18", "09/19", "09/20",
"09/21", "09/22", "09/23", "09/24", "09/26", "09/27", "09/28",
"09/29", "09/30", "10/01", "10/02", "10/03", "10/05", "10/06",
"10/08", "10/09", "10/10", "10/12", "10/13", "10/14", "10/17",
"10/18", "10/19", "10/22", "10/27", "10/28", "10/29", "11/01",
"11/03", "11/04", "11/05", "06/19", "07/06", "07/08", "07/12",
"07/17", "07/18", "07/20", "07/21", "07/22", "07/23", "07/24",
"07/25", "07/26", "07/27", "07/27", "07/29", "07/29", "07/31",
"07/31", "08/01", "08/02", "08/02", "08/03", "08/03", "08/04",
"08/05", "08/05", "08/07", "08/09", "08/10", "08/13", "08/15",
"08/16", "08/17", "08/18", "08/18", "08/20", "08/24", "08/25",
"08/26", "08/28", "08/29", "09/03", "09/04", "09/06", "09/08",
"09/10", "09/10", "09/11", "09/11", "09/12", "09/12", "09/14",
"09/14", "09/15", "09/16", "09/17", "09/18", "09/18", "09/19",
"09/19", "09/21", "09/21", "09/22", "09/22", "09/23", "09/23",
"09/24", "09/25", "09/25", "09/26", "09/26", "09/27", "09/27",
"09/28", "09/28", "09/29", "09/29", "09/30", "09/30", "10/01",
"10/01", "10/02", "10/03", "10/03", "10/04", "10/04", "10/06",
"10/06", "10/07", "10/08", "10/10", "10/10", "10/11", "10/11",
"10/12", "10/14", "10/15", "10/16", "10/16", "10/19", "10/20",
"10/20", "10/22", "10/22", "10/23", "10/24", "10/25", "10/26",
"10/26", "10/27", "10/27", "10/28", "10/28", "10/29", "10/29",
"10/30", "10/30", "10/31", "11/01", "11/01", "11/02", "11/03",
"11/03", "11/04", "11/05", "11/06", "11/07", "11/09", "11/10",
"11/11", "11/13", "11/16", "11/17", "11/21", "11/22", "11/23",
"11/27", "11/28", "11/29", "11/30", "12/02", "12/03", "12/05",
"12/09", "12/10", "12/11", "12/13", "12/14", "12/20", "12/21",
"12/21", "06/01", "06/06", "06/12", "06/14", "06/16", "06/17",
"06/18", "06/19", "06/21", "06/21", "06/22", "06/23", "06/24",
"06/24", "06/26", "06/26", "06/27", "06/27", "06/28", "06/30",
"06/30", "07/01", "07/01", "07/03", "07/05", "07/07", "07/08",
"07/09", "07/11", "07/12", "07/14", "07/16", "07/17", "07/17",
"07/18", "07/18", "07/19", "07/20", "07/21", "07/22", "07/23",
"07/25", "07/26", "07/27", "07/28", "07/29", "07/29", "07/30",
"08/01", "08/01", "08/02", "08/02", "08/03", "08/04", "08/05",
"08/06", "08/07", "08/08", "08/08", "08/09", "08/10", "08/11",
"08/12", "08/13", "08/13", "08/14", "08/15", "08/16", "08/18",
"08/19", "08/20", "08/21", "08/21", "08/25", "08/26", "08/28",
"09/02", "09/02", "09/04", "09/05", "09/06", "09/07", "09/08",
"09/08", "09/09", "09/10", "09/11", "09/12", "09/12", "09/13",
"09/13", "09/14", "09/14", "09/17", "09/18", "09/18", "09/19",
"09/20", "09/20", "09/23", "09/24", "09/26", "09/27", "09/28",
"09/29", "09/30", "09/30", "10/02", "10/03", "10/03", "10/04",
"10/05", "10/06", "10/08", "10/09", "10/09", "10/11", "10/12",
"10/12", "10/13", "10/14", "10/14", "10/15", "10/16", "10/16",
"10/18", "10/19", "10/19", "10/20", "10/20", "10/21", "10/21",
"10/22", "10/23", "10/23", "10/24", "10/25", "10/25", "10/27",
"10/27", "10/28", "10/29", "10/30", "10/30", "10/31", "10/31",
"11/01", "11/02", "11/07", "11/07", "11/17", "11/25", "11/27"
), site = c("A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
"A", "A", "A")), .Names = c("year", "date", "abundance", "DATE",
"site"), row.names = c(NA, 403L), class = "data.frame")

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep  4 23:00:12 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 4 Sep 2019 14:00:12 -0700
Subject: [R] Change Y-axis labels
In-Reply-To: <CAH6117KOVTMOyV7A=RCVU1Q=3=FCnDg39UO7F+UXS_hjtH_Vsw@mail.gmail.com>
References: <CAH6117KOVTMOyV7A=RCVU1Q=3=FCnDg39UO7F+UXS_hjtH_Vsw@mail.gmail.com>
Message-ID: <6442025b-e743-0958-d5af-7c6cfe06e3cd@comcast.net>


On 9/4/19 7:35 AM, Medic wrote:
> The Y scale is divided (by default) as:
> 0.0 ... 0.2 ... 0.4 ... 0.6 ... 0.8 ...1.0
> But I would like so:
> 0 ... 20 ... 40 ... 60 ... 80... 100
> (with rotating axis labels)
> When I use par function (marked as comment here) it turns out
> correctly for ONLY ONE picture?! Help me, please. (This is the code
> for restricted mean survival time.)
>
> install.packages("survival")
> install.packages("survRM2")
> library(survival)
> library(survRM2)
> #automatically creates a sample data
> D=rmst2.sample.data()
> time=D$time
> status=D$status
> arm=D$arm
> tau=NULL
> a=rmst2(time, status, arm, tau=10)
> #par(yaxt="n")
> plot(a, xlab="Years", ylab="Probability", density=60)
> #par(yaxt="s")
> #axis(side = 2, at = seq(0, 1, 0.2), labels = seq(0, 100, 20), las = 1)
The plot.rmst2 function has no capacity to accept dots-arguments.

This idea taken from Greg Snow posting from:

Subject:??? Re: [R] Add points to subplots
From:??? Greg Snow (538... at gmail.com)
Date:??? Jun 17, 2014 9:00:44 am
List:??? org.r-project.r-help

-----------------------------


draw.first.yax <- function() { par(yaxt="s")
 ??? axis(side = 2, at = seq(0, 1, 0.2), labels = seq(0, 100, 20), las = 
1);par(yaxt="n")
}
setHook('before.plot.new', draw.first.yax, "append")? # only plots? axis 
in the first subplot
par(yaxt="n")
plot(a, xlab="Years", ylab="Probability", density=60)

setHook('before.plot.new',NULL, 'replace' ) ## clean up

par(yaxt="s");axis(side = 2, at = seq(0, 1, 0.2), labels = seq(0, 100, 
20), las = 1) # now plot second axis annotation

-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Sep  4 23:39:15 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 5 Sep 2019 09:39:15 +1200
Subject: [R] 
 [effects] allEffects does not accept integer value for xlevels
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836D05421@FHSDB2D11-2.csu.mcmaster.ca>
References: <1659_1567603516_x84DOvZp005404_3bb9b027-c78c-f509-ee2f-8286723484ce@math.uni-giessen.de>
 <ACD1644AA6C67E4FBD0C350625508EC836D05421@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <0bbfe298-c0c6-af2d-2911-a51da3c83097@auckland.ac.nz>


I'm obviously not understanding something here, but it seems to me that 
the conjecture

>>> It appears to me that the cause is buried in effects:::Analyze.model
>>>
>>> in or close to the the lines
>>>
>>> if (is.numeric(xlevels) & length(xlevels) == 1L) {
>>>     levs <- xlevels
>>>     for (name in focal.predictors) xlevels[[name]] <- levs
>>>    }
>>>
>>>
>>>
>>> where xlevels -- while not being a list in this case --
>>> is subscripted by xlevels[[name]].

is not correct.  There is no problem with using [[...]] to extract 
entries from vectors.  E.g.:

x <- 1:3
names(x) <- c("mung","gorp","clyde")
x[["gorp"]]

produces

[1] 2

cheers,

Rolf

On 5/09/19 2:19 AM, Fox, John wrote:
> Dear Gerrit,
> 
> Yes, that appears to be a bug in Effect() -- too bad that it wasn't discovered earlier because a new version of the package was submitted yesterday, but thank you for the bug report.
> 
> We'll fix the bug, but until then a work-around is to specify the number of levels for each numeric predictor, as in
> 
> 	allEffects(mod.cowles, xlevels=list(neuroticism=4, extraversion=4))
> 
> I used 4 levels here to verify that this works correctly, since 5 is the default.
> 
> As well, although unrelated to this bug, you might take a look at predictorEffects(), which we recommend in preference to allEffects().
> 
> Best,
>   John
> 
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
> 
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Gerrit
>> Eichner
>> Sent: Wednesday, September 4, 2019 9:25 AM
>> To: r-help at r-project.org
>> Subject: [R] [effects] allEffects does not accept integer value for
>> xlevels
>>
>> Dear list,
>>
>> citing from allEffects' help page (of package effects 4.1-2):
>> "If xlevels=n is an integer, then each numeric predictor is represented by
>> n equally spaced values rounded to 'nice' numbers."
>>
>>
>> However, adapting the first example from allEffects' help page throws an
>> an error:
>>
>> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
>>                     data=Cowles, family=binomial) allEffects(mod.cowles,
>> xlevels=5) Error in xlevels[[name]] : subscript out of bounds
>>
>>
>> It appears to me that the cause is buried in effects:::Analyze.model
>>
>> in or close to the the lines
>>
>> if (is.numeric(xlevels) & length(xlevels) == 1L) {
>>     levs <- xlevels
>>     for (name in focal.predictors) xlevels[[name]] <- levs
>>    }
>>
>>
>>
>> where xlevels -- while not being a list in this case -- is subscripted by
>> xlevels[[name]].
>>
>> Is anyone aware of a workaround (without having to specify all numeric
>> predictors of the used model explicitly in a list and giving it to xlevels
>> when calling allEffects), and without having to write my own Analyze.model
>> function? ;-)
>>
>>
>>    Thx in advance and best regards  --  Gerrit
>>
>>
>>
>> PS:  sessionInfo()
>>
>> R version 3.6.1 (2019-07-05)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10 x64
>> (build 18362)
>>
>> Matrix products: default
>>
>> Random number generation:
>>    RNG:     Mersenne-Twister
>>    Normal:  Inversion
>>    Sample:  Rounding
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252 [3]
>> LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5]
>> LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] effects_4.1-2 carData_3.0-2
>>
>> loaded via a namespace (and not attached):
>>    [1] Rcpp_1.0.2        lattice_0.20-38   MASS_7.3-51.4     grid_3.6.1
>>
>>    [5] DBI_1.0.0         nlme_3.1-141      survey_3.36
>> estimability_1.3
>>    [9] minqa_1.2.4       nloptr_1.2.1      Matrix_1.2-17     boot_1.3-23
>>
>> [13] splines_3.6.1     lme4_1.1-21.9001  survival_2.44-1.1 compiler_3.6.1
>> [17] colorspace_1.4-1  mitools_2.4       nnet_7.3-12
>>
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>> http://www.uni-giessen.de/eichner
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep  5 00:32:37 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 4 Sep 2019 22:32:37 +0000
Subject: [R] 
 [effects] allEffects does not accept integer value for xlevels
In-Reply-To: <24268_1567633178_x84LdSb4025985_0bbfe298-c0c6-af2d-2911-a51da3c83097@auckland.ac.nz>
References: <1659_1567603516_x84DOvZp005404_3bb9b027-c78c-f509-ee2f-8286723484ce@math.uni-giessen.de>
 <ACD1644AA6C67E4FBD0C350625508EC836D05421@FHSDB2D11-2.csu.mcmaster.ca>
 <24268_1567633178_x84LdSb4025985_0bbfe298-c0c6-af2d-2911-a51da3c83097@auckland.ac.nz>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836D05B9F@FHSDB2D11-2.csu.mcmaster.ca>

Dear Rolf,

Thanks for trying to help. The bug wasn't in AnalyzeModel().

There was a bug in Effect.lm(), Effect.multinom(), and Effect.polr() in how xlevels=n (e.g., xlevels=4) was handled, now fixed in the development version of the effects package on R-Forge, from which it can be installed via install.packages("effects", repos="http://R-Forge.R-project.org"). Despite my implication to the contrary, xlevels=n works properly in predictorEffect() in the version of effects currently on CRAN.

I'll wait for a decent interval before updating effects again on CRAN.

Best,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rolf
> Turner
> Sent: Wednesday, September 4, 2019 5:39 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org; sandy at umn.edu
> Subject: Re: [R] [effects] allEffects does not accept integer value for
> xlevels
> 
> 
> I'm obviously not understanding something here, but it seems to me that
> the conjecture
> 
> >>> It appears to me that the cause is buried in effects:::Analyze.model
> >>>
> >>> in or close to the the lines
> >>>
> >>> if (is.numeric(xlevels) & length(xlevels) == 1L) {
> >>>     levs <- xlevels
> >>>     for (name in focal.predictors) xlevels[[name]] <- levs
> >>>    }
> >>>
> >>>
> >>>
> >>> where xlevels -- while not being a list in this case -- is
> >>> subscripted by xlevels[[name]].
> 
> is not correct.  There is no problem with using [[...]] to extract entries
> from vectors.  E.g.:
> 
> x <- 1:3
> names(x) <- c("mung","gorp","clyde")
> x[["gorp"]]
> 
> produces
> 
> [1] 2
> 
> cheers,
> 
> Rolf
> 
> On 5/09/19 2:19 AM, Fox, John wrote:
> > Dear Gerrit,
> >
> > Yes, that appears to be a bug in Effect() -- too bad that it wasn't
> discovered earlier because a new version of the package was submitted
> yesterday, but thank you for the bug report.
> >
> > We'll fix the bug, but until then a work-around is to specify the
> > number of levels for each numeric predictor, as in
> >
> > 	allEffects(mod.cowles, xlevels=list(neuroticism=4, extraversion=4))
> >
> > I used 4 levels here to verify that this works correctly, since 5 is the
> default.
> >
> > As well, although unrelated to this bug, you might take a look at
> predictorEffects(), which we recommend in preference to allEffects().
> >
> > Best,
> >   John
> >
> > --------------------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> Gerrit Eichner
> >> Sent: Wednesday, September 4, 2019 9:25 AM
> >> To: r-help at r-project.org
> >> Subject: [R] [effects] allEffects does not accept integer value for
> >> xlevels
> >>
> >> Dear list,
> >>
> >> citing from allEffects' help page (of package effects 4.1-2):
> >> "If xlevels=n is an integer, then each numeric predictor is
> >> represented by n equally spaced values rounded to 'nice' numbers."
> >>
> >>
> >> However, adapting the first example from allEffects' help page throws
> >> an an error:
> >>
> >> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
> >>                     data=Cowles, family=binomial)
> >> allEffects(mod.cowles,
> >> xlevels=5) Error in xlevels[[name]] : subscript out of bounds
> >>
> >>
> >> It appears to me that the cause is buried in effects:::Analyze.model
> >>
> >> in or close to the the lines
> >>
> >> if (is.numeric(xlevels) & length(xlevels) == 1L) {
> >>     levs <- xlevels
> >>     for (name in focal.predictors) xlevels[[name]] <- levs
> >>    }
> >>
> >>
> >>
> >> where xlevels -- while not being a list in this case -- is
> >> subscripted by xlevels[[name]].
> >>
> >> Is anyone aware of a workaround (without having to specify all
> >> numeric predictors of the used model explicitly in a list and giving
> >> it to xlevels when calling allEffects), and without having to write
> >> my own Analyze.model function? ;-)
> >>
> >>
> >>    Thx in advance and best regards  --  Gerrit
> >>
> >>
> >>
> >> PS:  sessionInfo()
> >>
> >> R version 3.6.1 (2019-07-05)
> >> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10
> >> x64 (build 18362)
> >>
> >> Matrix products: default
> >>
> >> Random number generation:
> >>    RNG:     Mersenne-Twister
> >>    Normal:  Inversion
> >>    Sample:  Rounding
> >>
> >> locale:
> >> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252 [3]
> >> LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5]
> >> LC_TIME=German_Germany.1252
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >> other attached packages:
> >> [1] effects_4.1-2 carData_3.0-2
> >>
> >> loaded via a namespace (and not attached):
> >>    [1] Rcpp_1.0.2        lattice_0.20-38   MASS_7.3-51.4     grid_3.6.1
> >>
> >>    [5] DBI_1.0.0         nlme_3.1-141      survey_3.36
> >> estimability_1.3
> >>    [9] minqa_1.2.4       nloptr_1.2.1      Matrix_1.2-17     boot_1.3-
> 23
> >>
> >> [13] splines_3.6.1     lme4_1.1-21.9001  survival_2.44-1.1
> compiler_3.6.1
> >> [17] colorspace_1.4-1  mitools_2.4       nnet_7.3-12
> >>
> >>
> >> ---------------------------------------------------------------------
> >> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> >> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> >> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> >> http://www.uni-giessen.de/eichner
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  5 00:06:16 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 4 Sep 2019 23:06:16 +0100
Subject: [R] creating a line plot for time series data for several years
In-Reply-To: <CAMwU6B2RtjySsQ9AKbijDJa5vE2SZ21QQ6ieXrdmfSiAzFwRwQ@mail.gmail.com>
References: <CAMwU6B2RtjySsQ9AKbijDJa5vE2SZ21QQ6ieXrdmfSiAzFwRwQ@mail.gmail.com>
Message-ID: <68e002c4-14ab-e276-75d4-3392860321f3@sapo.pt>

Hello,

Thanks for the reproducible example.
All you have to do is to use the aesthetic group = year in either 
ggplot() or geom_line().

This works:


library(ggplot2)

daT$date <- as.Date(daT$date)
daT$DATE <- format(daT$date, format="%m/%d")

Ab <- ggplot(daT, aes(x = as.factor(DATE),
                       y = abundance, colour = site)) +
   geom_line(aes(group = year)) +
   theme_bw()

Ab + facet_grid(year ~ .) +
   theme(axis.text.x = element_text(angle = 90,
                                    hjust = 1,
                                    size = 4))


Hope this helps,

Rui Barradas

?s 21:37 de 04/09/19, Marna Wagley escreveu:
> Hi R Users,
> I have been getting a trouble to create a time series plot (line) as I was
> trying to create a line graph for each year using month and date (in x
> axis). I would like to put only one x axis (month and date) for three years
> using the facet_grid, but it has not been creating a lineplot for me. I
> wanted to compare (visually) whether  the date of observing of the
> population vary by year.
> I used the following code but did not plot for me any line. Is there any
> possibility to create the lines for each year? A sample of the data is
> given for your information.
> 
> daT$DATE<-format(as.Date(daT$date), format="%m/%d")
> Ab<-ggplot(daT, aes(x= as.factor(DATE), y=abundance, colour=site)) +
>      geom_line() +
>      theme_bw()
> Ab+facet_grid(year~.)+theme(axis.text.x = element_text(angle = 90, hjust =
> 1, size=4))
> ###
> 
> daT<-structure(list(year = c(2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> 2018L, 2018L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> 2017L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L), date = structure(c(231L, 232L, 233L, 234L, 235L, 236L,
> 237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
> 248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L,
> 259L, 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L,
> 270L, 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L,
> 281L, 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L,
> 292L, 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L,
> 303L, 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L,
> 314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L,
> 325L, 326L, 327L, 328L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
> 125L, 126L, 127L, 128L, 129L, 130L, 131L, 131L, 132L, 132L, 133L,
> 133L, 134L, 135L, 135L, 136L, 136L, 137L, 138L, 138L, 139L, 140L,
> 141L, 142L, 143L, 144L, 145L, 146L, 146L, 147L, 148L, 149L, 150L,
> 151L, 152L, 153L, 154L, 155L, 156L, 157L, 157L, 158L, 158L, 159L,
> 159L, 160L, 160L, 161L, 162L, 163L, 164L, 164L, 165L, 165L, 166L,
> 166L, 167L, 167L, 168L, 168L, 169L, 170L, 170L, 171L, 171L, 172L,
> 172L, 173L, 173L, 174L, 174L, 175L, 175L, 176L, 176L, 177L, 178L,
> 178L, 179L, 179L, 180L, 180L, 181L, 182L, 183L, 183L, 184L, 184L,
> 185L, 186L, 187L, 188L, 188L, 189L, 190L, 190L, 191L, 191L, 192L,
> 193L, 194L, 195L, 195L, 196L, 196L, 197L, 197L, 198L, 198L, 199L,
> 199L, 200L, 201L, 201L, 202L, 203L, 203L, 204L, 205L, 206L, 207L,
> 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L, 216L, 217L, 218L,
> 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L, 227L, 228L, 229L,
> 230L, 230L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 9L, 10L, 11L,
> 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 16L, 17L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 27L, 28L, 28L, 29L, 30L,
> 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 38L, 39L, 40L, 40L, 41L,
> 41L, 42L, 43L, 44L, 45L, 46L, 47L, 47L, 48L, 49L, 50L, 51L, 52L,
> 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 59L, 60L, 61L, 62L, 63L,
> 63L, 64L, 65L, 66L, 67L, 68L, 68L, 69L, 70L, 71L, 72L, 72L, 73L,
> 73L, 74L, 74L, 75L, 76L, 76L, 77L, 78L, 78L, 79L, 80L, 81L, 82L,
> 83L, 84L, 85L, 85L, 86L, 87L, 87L, 88L, 89L, 90L, 91L, 92L, 92L,
> 93L, 94L, 94L, 95L, 96L, 96L, 97L, 98L, 98L, 99L, 100L, 100L,
> 101L, 101L, 102L, 102L, 103L, 104L, 104L, 105L, 106L, 106L, 107L,
> 107L, 108L, 109L, 110L, 110L, 111L, 111L, 112L, 113L, 114L, 114L,
> 115L, 116L, 117L), .Label = c("2016-06-01", "2016-06-06", "2016-06-12",
> "2016-06-14", "2016-06-16", "2016-06-17", "2016-06-18", "2016-06-19",
> "2016-06-21", "2016-06-22", "2016-06-23", "2016-06-24", "2016-06-26",
> "2016-06-27", "2016-06-28", "2016-06-30", "2016-07-01", "2016-07-03",
> "2016-07-05", "2016-07-07", "2016-07-08", "2016-07-09", "2016-07-11",
> "2016-07-12", "2016-07-14", "2016-07-16", "2016-07-17", "2016-07-18",
> "2016-07-19", "2016-07-20", "2016-07-21", "2016-07-22", "2016-07-23",
> "2016-07-25", "2016-07-26", "2016-07-27", "2016-07-28", "2016-07-29",
> "2016-07-30", "2016-08-01", "2016-08-02", "2016-08-03", "2016-08-04",
> "2016-08-05", "2016-08-06", "2016-08-07", "2016-08-08", "2016-08-09",
> "2016-08-10", "2016-08-11", "2016-08-12", "2016-08-13", "2016-08-14",
> "2016-08-15", "2016-08-16", "2016-08-18", "2016-08-19", "2016-08-20",
> "2016-08-21", "2016-08-25", "2016-08-26", "2016-08-28", "2016-09-02",
> "2016-09-04", "2016-09-05", "2016-09-06", "2016-09-07", "2016-09-08",
> "2016-09-09", "2016-09-10", "2016-09-11", "2016-09-12", "2016-09-13",
> "2016-09-14", "2016-09-17", "2016-09-18", "2016-09-19", "2016-09-20",
> "2016-09-23", "2016-09-24", "2016-09-26", "2016-09-27", "2016-09-28",
> "2016-09-29", "2016-09-30", "2016-10-02", "2016-10-03", "2016-10-04",
> "2016-10-05", "2016-10-06", "2016-10-08", "2016-10-09", "2016-10-11",
> "2016-10-12", "2016-10-13", "2016-10-14", "2016-10-15", "2016-10-16",
> "2016-10-18", "2016-10-19", "2016-10-20", "2016-10-21", "2016-10-22",
> "2016-10-23", "2016-10-24", "2016-10-25", "2016-10-27", "2016-10-28",
> "2016-10-29", "2016-10-30", "2016-10-31", "2016-11-01", "2016-11-02",
> "2016-11-07", "2016-11-17", "2016-11-25", "2016-11-27", "2017-06-19",
> "2017-07-06", "2017-07-08", "2017-07-12", "2017-07-17", "2017-07-18",
> "2017-07-20", "2017-07-21", "2017-07-22", "2017-07-23", "2017-07-24",
> "2017-07-25", "2017-07-26", "2017-07-27", "2017-07-29", "2017-07-31",
> "2017-08-01", "2017-08-02", "2017-08-03", "2017-08-04", "2017-08-05",
> "2017-08-07", "2017-08-09", "2017-08-10", "2017-08-13", "2017-08-15",
> "2017-08-16", "2017-08-17", "2017-08-18", "2017-08-20", "2017-08-24",
> "2017-08-25", "2017-08-26", "2017-08-28", "2017-08-29", "2017-09-03",
> "2017-09-04", "2017-09-06", "2017-09-08", "2017-09-10", "2017-09-11",
> "2017-09-12", "2017-09-14", "2017-09-15", "2017-09-16", "2017-09-17",
> "2017-09-18", "2017-09-19", "2017-09-21", "2017-09-22", "2017-09-23",
> "2017-09-24", "2017-09-25", "2017-09-26", "2017-09-27", "2017-09-28",
> "2017-09-29", "2017-09-30", "2017-10-01", "2017-10-02", "2017-10-03",
> "2017-10-04", "2017-10-06", "2017-10-07", "2017-10-08", "2017-10-10",
> "2017-10-11", "2017-10-12", "2017-10-14", "2017-10-15", "2017-10-16",
> "2017-10-19", "2017-10-20", "2017-10-22", "2017-10-23", "2017-10-24",
> "2017-10-25", "2017-10-26", "2017-10-27", "2017-10-28", "2017-10-29",
> "2017-10-30", "2017-10-31", "2017-11-01", "2017-11-02", "2017-11-03",
> "2017-11-04", "2017-11-05", "2017-11-06", "2017-11-07", "2017-11-09",
> "2017-11-10", "2017-11-11", "2017-11-13", "2017-11-16", "2017-11-17",
> "2017-11-21", "2017-11-22", "2017-11-23", "2017-11-27", "2017-11-28",
> "2017-11-29", "2017-11-30", "2017-12-02", "2017-12-03", "2017-12-05",
> "2017-12-09", "2017-12-10", "2017-12-11", "2017-12-13", "2017-12-14",
> "2017-12-20", "2017-12-21", "2018-07-03", "2018-07-06", "2018-07-07",
> "2018-07-08", "2018-07-09", "2018-07-10", "2018-07-11", "2018-07-12",
> "2018-07-13", "2018-07-14", "2018-07-16", "2018-07-18", "2018-07-19",
> "2018-07-20", "2018-07-21", "2018-07-22", "2018-07-24", "2018-07-25",
> "2018-07-26", "2018-07-27", "2018-07-28", "2018-07-29", "2018-07-30",
> "2018-07-31", "2018-08-01", "2018-08-02", "2018-08-03", "2018-08-04",
> "2018-08-05", "2018-08-07", "2018-08-08", "2018-08-09", "2018-08-10",
> "2018-08-11", "2018-08-12", "2018-08-13", "2018-08-14", "2018-08-15",
> "2018-08-16", "2018-08-17", "2018-08-18", "2018-08-20", "2018-08-24",
> "2018-08-26", "2018-08-27", "2018-08-28", "2018-08-29", "2018-08-30",
> "2018-08-31", "2018-09-02", "2018-09-03", "2018-09-04", "2018-09-05",
> "2018-09-06", "2018-09-07", "2018-09-08", "2018-09-09", "2018-09-10",
> "2018-09-11", "2018-09-12", "2018-09-13", "2018-09-14", "2018-09-15",
> "2018-09-17", "2018-09-18", "2018-09-19", "2018-09-20", "2018-09-21",
> "2018-09-22", "2018-09-23", "2018-09-24", "2018-09-26", "2018-09-27",
> "2018-09-28", "2018-09-29", "2018-09-30", "2018-10-01", "2018-10-02",
> "2018-10-03", "2018-10-05", "2018-10-06", "2018-10-08", "2018-10-09",
> "2018-10-10", "2018-10-12", "2018-10-13", "2018-10-14", "2018-10-17",
> "2018-10-18", "2018-10-19", "2018-10-22", "2018-10-27", "2018-10-28",
> "2018-10-29", "2018-11-01", "2018-11-03", "2018-11-04", "2018-11-05"
> ), class = "factor"), abundance = c(0, 2, 5, 6, 6, 7, 7, 7, 7,
> 9, 11, 13, 13, 13, 13, 14, 15, 15, 16, 17, 17, 18, 18, 19, 22,
> 23, 24, 25, 29, 31, 32, 34, 36, 36, 37, 37, 38, 39, 40, 40, 40,
> 40, 40, 41, 41, 41, 44, 44, 44, 47, 47, 47, 47, 47, 47, 47, 47,
> 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,
> 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,
> 48, 48, 48, 48, 48, 48, 48, 48, 48, 1, 2, 2, 2, 3, 4, 5, 6, 6,
> 6, 7, 9, 10, 11, 12, 14, 14, 15, 15, 16, 18, 19, 21, 22, 24,
> 25, 25, 26, 27, 28, 29, 30, 31, 31, 33, 33, 35, 36, 37, 38, 39,
> 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,
> 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,
> 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,
> 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43,
> 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
> 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
> 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 0,
> 1, 2, 3, 4, 4, 5, 6, 6, 7, 7, 7, 8, 8, 8, 9, 10, 10, 10, 10,
> 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 15, 16, 18, 19,
> 20, 21, 21, 21, 21, 21, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35,
> 35, 35, 36, 36, 37, 39, 41, 42, 42, 43, 43, 43, 44, 44, 45, 47,
> 47, 47, 47, 48, 49, 49, 50, 50, 50, 50, 50, 50, 51, 52, 52, 52,
> 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
> 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
> 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54,
> 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,
> 55, 55, 55, 55, 55), DATE = c("07/03", "07/06", "07/07", "07/08",
> "07/09", "07/10", "07/11", "07/12", "07/13", "07/14", "07/16",
> "07/18", "07/19", "07/20", "07/21", "07/22", "07/24", "07/25",
> "07/26", "07/27", "07/28", "07/29", "07/30", "07/31", "08/01",
> "08/02", "08/03", "08/04", "08/05", "08/07", "08/08", "08/09",
> "08/10", "08/11", "08/12", "08/13", "08/14", "08/15", "08/16",
> "08/17", "08/18", "08/20", "08/24", "08/26", "08/27", "08/28",
> "08/29", "08/30", "08/31", "09/02", "09/03", "09/04", "09/05",
> "09/06", "09/07", "09/08", "09/09", "09/10", "09/11", "09/12",
> "09/13", "09/14", "09/15", "09/17", "09/18", "09/19", "09/20",
> "09/21", "09/22", "09/23", "09/24", "09/26", "09/27", "09/28",
> "09/29", "09/30", "10/01", "10/02", "10/03", "10/05", "10/06",
> "10/08", "10/09", "10/10", "10/12", "10/13", "10/14", "10/17",
> "10/18", "10/19", "10/22", "10/27", "10/28", "10/29", "11/01",
> "11/03", "11/04", "11/05", "06/19", "07/06", "07/08", "07/12",
> "07/17", "07/18", "07/20", "07/21", "07/22", "07/23", "07/24",
> "07/25", "07/26", "07/27", "07/27", "07/29", "07/29", "07/31",
> "07/31", "08/01", "08/02", "08/02", "08/03", "08/03", "08/04",
> "08/05", "08/05", "08/07", "08/09", "08/10", "08/13", "08/15",
> "08/16", "08/17", "08/18", "08/18", "08/20", "08/24", "08/25",
> "08/26", "08/28", "08/29", "09/03", "09/04", "09/06", "09/08",
> "09/10", "09/10", "09/11", "09/11", "09/12", "09/12", "09/14",
> "09/14", "09/15", "09/16", "09/17", "09/18", "09/18", "09/19",
> "09/19", "09/21", "09/21", "09/22", "09/22", "09/23", "09/23",
> "09/24", "09/25", "09/25", "09/26", "09/26", "09/27", "09/27",
> "09/28", "09/28", "09/29", "09/29", "09/30", "09/30", "10/01",
> "10/01", "10/02", "10/03", "10/03", "10/04", "10/04", "10/06",
> "10/06", "10/07", "10/08", "10/10", "10/10", "10/11", "10/11",
> "10/12", "10/14", "10/15", "10/16", "10/16", "10/19", "10/20",
> "10/20", "10/22", "10/22", "10/23", "10/24", "10/25", "10/26",
> "10/26", "10/27", "10/27", "10/28", "10/28", "10/29", "10/29",
> "10/30", "10/30", "10/31", "11/01", "11/01", "11/02", "11/03",
> "11/03", "11/04", "11/05", "11/06", "11/07", "11/09", "11/10",
> "11/11", "11/13", "11/16", "11/17", "11/21", "11/22", "11/23",
> "11/27", "11/28", "11/29", "11/30", "12/02", "12/03", "12/05",
> "12/09", "12/10", "12/11", "12/13", "12/14", "12/20", "12/21",
> "12/21", "06/01", "06/06", "06/12", "06/14", "06/16", "06/17",
> "06/18", "06/19", "06/21", "06/21", "06/22", "06/23", "06/24",
> "06/24", "06/26", "06/26", "06/27", "06/27", "06/28", "06/30",
> "06/30", "07/01", "07/01", "07/03", "07/05", "07/07", "07/08",
> "07/09", "07/11", "07/12", "07/14", "07/16", "07/17", "07/17",
> "07/18", "07/18", "07/19", "07/20", "07/21", "07/22", "07/23",
> "07/25", "07/26", "07/27", "07/28", "07/29", "07/29", "07/30",
> "08/01", "08/01", "08/02", "08/02", "08/03", "08/04", "08/05",
> "08/06", "08/07", "08/08", "08/08", "08/09", "08/10", "08/11",
> "08/12", "08/13", "08/13", "08/14", "08/15", "08/16", "08/18",
> "08/19", "08/20", "08/21", "08/21", "08/25", "08/26", "08/28",
> "09/02", "09/02", "09/04", "09/05", "09/06", "09/07", "09/08",
> "09/08", "09/09", "09/10", "09/11", "09/12", "09/12", "09/13",
> "09/13", "09/14", "09/14", "09/17", "09/18", "09/18", "09/19",
> "09/20", "09/20", "09/23", "09/24", "09/26", "09/27", "09/28",
> "09/29", "09/30", "09/30", "10/02", "10/03", "10/03", "10/04",
> "10/05", "10/06", "10/08", "10/09", "10/09", "10/11", "10/12",
> "10/12", "10/13", "10/14", "10/14", "10/15", "10/16", "10/16",
> "10/18", "10/19", "10/19", "10/20", "10/20", "10/21", "10/21",
> "10/22", "10/23", "10/23", "10/24", "10/25", "10/25", "10/27",
> "10/27", "10/28", "10/29", "10/30", "10/30", "10/31", "10/31",
> "11/01", "11/02", "11/07", "11/07", "11/17", "11/25", "11/27"
> ), site = c("A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> "A", "A", "A")), .Names = c("year", "date", "abundance", "DATE",
> "site"), row.names = c(NA, 403L), class = "data.frame")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mchowe||2 @end|ng |rom gm@||@com  Thu Sep  5 03:38:43 2019
From: mchowe||2 @end|ng |rom gm@||@com (Michael Howell)
Date: Wed, 4 Sep 2019 20:38:43 -0500
Subject: [R] Packages for Nonlinear ARIMA Estimation
Message-ID: <CAFH+Q7xY1MyO9nTHYKVk19QK13arPXhWh5KKci1r-dfKi+p03Q@mail.gmail.com>

Hello,
I am looking for an R package that uses nonlinear least squares to fit
ARIMA models. Initially I was using tseries but according to the
documentation for the Arima function in tseries:

*The exact likelihood is computed via a state-space representation of the
ARIMA process, and the innovations and their variance found by a Kalman
filter.  *

Are there any alternative commands that use nonlinear least squares?

	[[alternative HTML version deleted]]


From m@|||P@dpo@t @end|ng |rom gm@||@com  Thu Sep  5 09:31:51 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Thu, 5 Sep 2019 10:31:51 +0300
Subject: [R] Change Y-axis labels
Message-ID: <CAH6117JbmPr3-jna-mRn2jg9A0GDh2VrWKvUA6u4uWgXqXa0pQ@mail.gmail.com>

For David Winsemius.
As always, You help out! Immensely grateful!


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Thu Sep  5 10:14:05 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Thu, 5 Sep 2019 10:14:05 +0200
Subject: [R] 
 [effects] allEffects does not accept integer value for xlevels
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836D05B9F@FHSDB2D11-2.csu.mcmaster.ca>
References: <1659_1567603516_x84DOvZp005404_3bb9b027-c78c-f509-ee2f-8286723484ce@math.uni-giessen.de>
 <ACD1644AA6C67E4FBD0C350625508EC836D05421@FHSDB2D11-2.csu.mcmaster.ca>
 <24268_1567633178_x84LdSb4025985_0bbfe298-c0c6-af2d-2911-a51da3c83097@auckland.ac.nz>
 <ACD1644AA6C67E4FBD0C350625508EC836D05B9F@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <14d30cf6-e8d2-956b-3b19-b97dffdd16a0@math.uni-giessen.de>

Dear John,

thank you for the quick response and fix! Sorry, that I didn't
detect the bug earlier, but everything had run smoothly sofar. ;-)
(I am aware of predictorEffects. I have in fact switched to it
recently. Excellent functionality; thx a lot for it! Actually,
experimenting with its ...levels arguments lead me to the
respective attempts with allEffects out of curiosity.)

Dear Rolf,

my conjecture was not about a "problem with using [[...]] to
*extract* entries from vectors", but about assigning a value to a
list component of an object which is not a list. I was referring
to xlevels[[name]] <- levs where xlevels is an integer. (But that
doesn't matter anymore because my conjecture pointed to the wrong
function anyway.)

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 05.09.2019 um 00:32 schrieb Fox, John:
> Dear Rolf,
> 
> Thanks for trying to help. The bug wasn't in AnalyzeModel().
> 
> There was a bug in Effect.lm(), Effect.multinom(), and Effect.polr() in how xlevels=n (e.g., xlevels=4) was handled, now fixed in the development version of the effects package on R-Forge, from which it can be installed via install.packages("effects", repos="http://R-Forge.R-project.org"). Despite my implication to the contrary, xlevels=n works properly in predictorEffect() in the version of effects currently on CRAN.
> 
> I'll wait for a decent interval before updating effects again on CRAN.
> 
> Best,
>   John
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rolf
>> Turner
>> Sent: Wednesday, September 4, 2019 5:39 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: r-help at r-project.org; sandy at umn.edu
>> Subject: Re: [R] [effects] allEffects does not accept integer value for
>> xlevels
>>
>>
>> I'm obviously not understanding something here, but it seems to me that
>> the conjecture
>>
>>>>> It appears to me that the cause is buried in effects:::Analyze.model
>>>>>
>>>>> in or close to the the lines
>>>>>
>>>>> if (is.numeric(xlevels) & length(xlevels) == 1L) {
>>>>>      levs <- xlevels
>>>>>      for (name in focal.predictors) xlevels[[name]] <- levs
>>>>>     }
>>>>>
>>>>>
>>>>>
>>>>> where xlevels -- while not being a list in this case -- is
>>>>> subscripted by xlevels[[name]].
>>
>> is not correct.  There is no problem with using [[...]] to extract entries
>> from vectors.  E.g.:
>>
>> x <- 1:3
>> names(x) <- c("mung","gorp","clyde")
>> x[["gorp"]]
>>
>> produces
>>
>> [1] 2
>>
>> cheers,
>>
>> Rolf
>>
>> On 5/09/19 2:19 AM, Fox, John wrote:
>>> Dear Gerrit,
>>>
>>> Yes, that appears to be a bug in Effect() -- too bad that it wasn't
>> discovered earlier because a new version of the package was submitted
>> yesterday, but thank you for the bug report.
>>>
>>> We'll fix the bug, but until then a work-around is to specify the
>>> number of levels for each numeric predictor, as in
>>>
>>> 	allEffects(mod.cowles, xlevels=list(neuroticism=4, extraversion=4))
>>>
>>> I used 4 levels here to verify that this works correctly, since 5 is the
>> default.
>>>
>>> As well, although unrelated to this bug, you might take a look at
>> predictorEffects(), which we recommend in preference to allEffects().
>>>
>>> Best,
>>>    John
>>>
>>> --------------------------------------
>>> John Fox, Professor Emeritus
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> Web: socialsciences.mcmaster.ca/jfox/
>>>
>>>
>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>> Gerrit Eichner
>>>> Sent: Wednesday, September 4, 2019 9:25 AM
>>>> To: r-help at r-project.org
>>>> Subject: [R] [effects] allEffects does not accept integer value for
>>>> xlevels
>>>>
>>>> Dear list,
>>>>
>>>> citing from allEffects' help page (of package effects 4.1-2):
>>>> "If xlevels=n is an integer, then each numeric predictor is
>>>> represented by n equally spaced values rounded to 'nice' numbers."
>>>>
>>>>
>>>> However, adapting the first example from allEffects' help page throws
>>>> an an error:
>>>>
>>>> mod.cowles <- glm(volunteer ~ sex + neuroticism*extraversion,
>>>>                      data=Cowles, family=binomial)
>>>> allEffects(mod.cowles,
>>>> xlevels=5) Error in xlevels[[name]] : subscript out of bounds
>>>>
>>>>
>>>> It appears to me that the cause is buried in effects:::Analyze.model
>>>>
>>>> in or close to the the lines
>>>>
>>>> if (is.numeric(xlevels) & length(xlevels) == 1L) {
>>>>      levs <- xlevels
>>>>      for (name in focal.predictors) xlevels[[name]] <- levs
>>>>     }
>>>>
>>>>
>>>>
>>>> where xlevels -- while not being a list in this case -- is
>>>> subscripted by xlevels[[name]].
>>>>
>>>> Is anyone aware of a workaround (without having to specify all
>>>> numeric predictors of the used model explicitly in a list and giving
>>>> it to xlevels when calling allEffects), and without having to write
>>>> my own Analyze.model function? ;-)
>>>>
>>>>
>>>>     Thx in advance and best regards  --  Gerrit
>>>>
>>>>
>>>>
>>>> PS:  sessionInfo()
>>>>
>>>> R version 3.6.1 (2019-07-05)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10
>>>> x64 (build 18362)
>>>>
>>>> Matrix products: default
>>>>
>>>> Random number generation:
>>>>     RNG:     Mersenne-Twister
>>>>     Normal:  Inversion
>>>>     Sample:  Rounding
>>>>
>>>> locale:
>>>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252 [3]
>>>> LC_MONETARY=German_Germany.1252 LC_NUMERIC=C [5]
>>>> LC_TIME=German_Germany.1252
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] effects_4.1-2 carData_3.0-2
>>>>
>>>> loaded via a namespace (and not attached):
>>>>     [1] Rcpp_1.0.2        lattice_0.20-38   MASS_7.3-51.4     grid_3.6.1
>>>>
>>>>     [5] DBI_1.0.0         nlme_3.1-141      survey_3.36
>>>> estimability_1.3
>>>>     [9] minqa_1.2.4       nloptr_1.2.1      Matrix_1.2-17     boot_1.3-
>> 23
>>>>
>>>> [13] splines_3.6.1     lme4_1.1-21.9001  survival_2.44-1.1
>> compiler_3.6.1
>>>> [17] colorspace_1.4-1  mitools_2.4       nnet_7.3-12
>>>>
>>>>
>>>> ---------------------------------------------------------------------
>>>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>>>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>>>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>>>> http://www.uni-giessen.de/eichner
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html and provide commented, minimal, self-contained,
>>>> reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Honorary Research Fellow
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Sep  5 10:54:06 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 5 Sep 2019 10:54:06 +0200
Subject: [R] mutate() error
Message-ID: <CAJuCY5xpEuYh5DO0-kjxAeGM7ytpvM6qmM_Bx09deeA6qK9zpg@mail.gmail.com>

Dear all,

I'm using this in a function inside a package. The code works fine when I
run it directly.
df %>%
   mutate(!!id_column := row_number())

When I run the function I get this error:
Error in mutate(., `:=`(!!id_column, row_number())) :
  argument "mutate" is missing, with no default

df is a data.frame, id_column a string, all functions are imported.

Can someone explain to me why I'm getting this error?

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

	[[alternative HTML version deleted]]


From R@|ner @end|ng |rom krug@@de  Thu Sep  5 12:41:13 2019
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Thu, 5 Sep 2019 12:41:13 +0200
Subject: [R] Bug in "==" with empty data frames
Message-ID: <B7264236-EC4B-4C66-90CF-AF8EC5B4E7A9@krugs.de>

Hi

The following code results in an error:


###########
> x <- data.frame(x = integer(0), y = integer(0))
> x == x
Error in matrix(if (is.null(value)) logical() else value, nrow = nr, dimnames = list(rn,  :
  length of 'dimnames' [2] not equal to array extent
>
###########

I would expect that it returns logical(0) as both have the same structure and both are empty, or even TRUE?

But definitely not an error.

Cheers,

Rainer

###########
> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-apple-darwin17.7.0 (64-bit)
Running under: macOS High Sierra 10.13.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.6.1
###########

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982


From HDor@n @end|ng |rom @|r@org  Thu Sep  5 15:43:36 2019
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Thu, 5 Sep 2019 13:43:36 +0000
Subject: [R] Help Installing Rtools
Message-ID: <BL0PR05MB481896DCAEB26A5CAC79E844CABB0@BL0PR05MB4818.namprd05.prod.outlook.com>

I've done the following steps, but am unable to source in the Cpp files. Details of my session and sessionInfo are below. Am I missing a package, or a critical step? I found one answer regarding the 'make" error on stackoverflow suggesting the problem is resolved by grabbing the more recent version of Rtools, which I have done.

Thanks.

> install.packages('installr')
> library(installr)
> install.Rtools()

This step installed Rtools35.exe correctly as far as I can tell. Then,

> library(devtools)
Loading required package: usethis
> library(Rcpp)
> sourceCpp("test.cpp")
Warning message:
In system(cmd) : 'make' not found
Error in sourceCpp("test.cpp") :
  Error 1 occurred building shared library.

WARNING: The tools required to build C++ code for R were not found.

Please download and install the appropriate version of Rtools:

http://cran.r-project.org/bin/windows/Rtools/

> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Rcpp_1.0.2      devtools_2.1.0  usethis_1.5.1   htmltab_0.7.1
[5] installr_0.22.0 stringr_1.4.0

loaded via a namespace (and not attached):
[1] magrittr_1.5      pkgload_1.0.2     R6_2.4.0          rlang_0.3.4
 [5] httr_1.4.1        tools_3.6.1       pkgbuild_1.0.5    sessioninfo_1.1.1
[9] cli_1.1.0         withr_2.1.2       remotes_2.1.0     rprojroot_1.3-2
[13] assertthat_0.2.1  digest_0.6.19     crayon_1.3.4      processx_3.4.1
[17] callr_3.3.1       fs_1.3.1          ps_1.3.0          testthat_2.2.1
[21] curl_4.0          memoise_1.1.0     glue_1.3.1        stringi_1.4.3
[25] compiler_3.6.1    backports_1.1.4   desc_1.2.0        prettyunits_1.0.2
[29] XML_3.98-1.20
>

	[[alternative HTML version deleted]]


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Thu Sep  5 18:44:53 2019
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Thu, 5 Sep 2019 09:44:53 -0700
Subject: [R] creating a line plot for time series data for several years
In-Reply-To: <68e002c4-14ab-e276-75d4-3392860321f3@sapo.pt>
References: <CAMwU6B2RtjySsQ9AKbijDJa5vE2SZ21QQ6ieXrdmfSiAzFwRwQ@mail.gmail.com>
 <68e002c4-14ab-e276-75d4-3392860321f3@sapo.pt>
Message-ID: <CAMwU6B01Rih_F0mdiG8rokvsu-E94ATP3njkW+tWgx7aWNKh=g@mail.gmail.com>

Thank you, Rui. It helped me a lot. It is highly appreciated.
thanks,

On Thu, Sep 5, 2019 at 1:14 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Thanks for the reproducible example.
> All you have to do is to use the aesthetic group = year in either
> ggplot() or geom_line().
>
> This works:
>
>
> library(ggplot2)
>
> daT$date <- as.Date(daT$date)
> daT$DATE <- format(daT$date, format="%m/%d")
>
> Ab <- ggplot(daT, aes(x = as.factor(DATE),
>                        y = abundance, colour = site)) +
>    geom_line(aes(group = year)) +
>    theme_bw()
>
> Ab + facet_grid(year ~ .) +
>    theme(axis.text.x = element_text(angle = 90,
>                                     hjust = 1,
>                                     size = 4))
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 21:37 de 04/09/19, Marna Wagley escreveu:
> > Hi R Users,
> > I have been getting a trouble to create a time series plot (line) as I
> was
> > trying to create a line graph for each year using month and date (in x
> > axis). I would like to put only one x axis (month and date) for three
> years
> > using the facet_grid, but it has not been creating a lineplot for me. I
> > wanted to compare (visually) whether  the date of observing of the
> > population vary by year.
> > I used the following code but did not plot for me any line. Is there any
> > possibility to create the lines for each year? A sample of the data is
> > given for your information.
> >
> > daT$DATE<-format(as.Date(daT$date), format="%m/%d")
> > Ab<-ggplot(daT, aes(x= as.factor(DATE), y=abundance, colour=site)) +
> >      geom_line() +
> >      theme_bw()
> > Ab+facet_grid(year~.)+theme(axis.text.x = element_text(angle = 90, hjust
> =
> > 1, size=4))
> > ###
> >
> > daT<-structure(list(year = c(2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L, 2018L,
> > 2018L, 2018L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L, 2017L,
> > 2017L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> > 2016L), date = structure(c(231L, 232L, 233L, 234L, 235L, 236L,
> > 237L, 238L, 239L, 240L, 241L, 242L, 243L, 244L, 245L, 246L, 247L,
> > 248L, 249L, 250L, 251L, 252L, 253L, 254L, 255L, 256L, 257L, 258L,
> > 259L, 260L, 261L, 262L, 263L, 264L, 265L, 266L, 267L, 268L, 269L,
> > 270L, 271L, 272L, 273L, 274L, 275L, 276L, 277L, 278L, 279L, 280L,
> > 281L, 282L, 283L, 284L, 285L, 286L, 287L, 288L, 289L, 290L, 291L,
> > 292L, 293L, 294L, 295L, 296L, 297L, 298L, 299L, 300L, 301L, 302L,
> > 303L, 304L, 305L, 306L, 307L, 308L, 309L, 310L, 311L, 312L, 313L,
> > 314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L, 323L, 324L,
> > 325L, 326L, 327L, 328L, 118L, 119L, 120L, 121L, 122L, 123L, 124L,
> > 125L, 126L, 127L, 128L, 129L, 130L, 131L, 131L, 132L, 132L, 133L,
> > 133L, 134L, 135L, 135L, 136L, 136L, 137L, 138L, 138L, 139L, 140L,
> > 141L, 142L, 143L, 144L, 145L, 146L, 146L, 147L, 148L, 149L, 150L,
> > 151L, 152L, 153L, 154L, 155L, 156L, 157L, 157L, 158L, 158L, 159L,
> > 159L, 160L, 160L, 161L, 162L, 163L, 164L, 164L, 165L, 165L, 166L,
> > 166L, 167L, 167L, 168L, 168L, 169L, 170L, 170L, 171L, 171L, 172L,
> > 172L, 173L, 173L, 174L, 174L, 175L, 175L, 176L, 176L, 177L, 178L,
> > 178L, 179L, 179L, 180L, 180L, 181L, 182L, 183L, 183L, 184L, 184L,
> > 185L, 186L, 187L, 188L, 188L, 189L, 190L, 190L, 191L, 191L, 192L,
> > 193L, 194L, 195L, 195L, 196L, 196L, 197L, 197L, 198L, 198L, 199L,
> > 199L, 200L, 201L, 201L, 202L, 203L, 203L, 204L, 205L, 206L, 207L,
> > 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L, 216L, 217L, 218L,
> > 219L, 220L, 221L, 222L, 223L, 224L, 225L, 226L, 227L, 228L, 229L,
> > 230L, 230L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 9L, 10L, 11L,
> > 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 16L, 17L, 17L, 18L, 19L,
> > 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 27L, 28L, 28L, 29L, 30L,
> > 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 38L, 39L, 40L, 40L, 41L,
> > 41L, 42L, 43L, 44L, 45L, 46L, 47L, 47L, 48L, 49L, 50L, 51L, 52L,
> > 52L, 53L, 54L, 55L, 56L, 57L, 58L, 59L, 59L, 60L, 61L, 62L, 63L,
> > 63L, 64L, 65L, 66L, 67L, 68L, 68L, 69L, 70L, 71L, 72L, 72L, 73L,
> > 73L, 74L, 74L, 75L, 76L, 76L, 77L, 78L, 78L, 79L, 80L, 81L, 82L,
> > 83L, 84L, 85L, 85L, 86L, 87L, 87L, 88L, 89L, 90L, 91L, 92L, 92L,
> > 93L, 94L, 94L, 95L, 96L, 96L, 97L, 98L, 98L, 99L, 100L, 100L,
> > 101L, 101L, 102L, 102L, 103L, 104L, 104L, 105L, 106L, 106L, 107L,
> > 107L, 108L, 109L, 110L, 110L, 111L, 111L, 112L, 113L, 114L, 114L,
> > 115L, 116L, 117L), .Label = c("2016-06-01", "2016-06-06", "2016-06-12",
> > "2016-06-14", "2016-06-16", "2016-06-17", "2016-06-18", "2016-06-19",
> > "2016-06-21", "2016-06-22", "2016-06-23", "2016-06-24", "2016-06-26",
> > "2016-06-27", "2016-06-28", "2016-06-30", "2016-07-01", "2016-07-03",
> > "2016-07-05", "2016-07-07", "2016-07-08", "2016-07-09", "2016-07-11",
> > "2016-07-12", "2016-07-14", "2016-07-16", "2016-07-17", "2016-07-18",
> > "2016-07-19", "2016-07-20", "2016-07-21", "2016-07-22", "2016-07-23",
> > "2016-07-25", "2016-07-26", "2016-07-27", "2016-07-28", "2016-07-29",
> > "2016-07-30", "2016-08-01", "2016-08-02", "2016-08-03", "2016-08-04",
> > "2016-08-05", "2016-08-06", "2016-08-07", "2016-08-08", "2016-08-09",
> > "2016-08-10", "2016-08-11", "2016-08-12", "2016-08-13", "2016-08-14",
> > "2016-08-15", "2016-08-16", "2016-08-18", "2016-08-19", "2016-08-20",
> > "2016-08-21", "2016-08-25", "2016-08-26", "2016-08-28", "2016-09-02",
> > "2016-09-04", "2016-09-05", "2016-09-06", "2016-09-07", "2016-09-08",
> > "2016-09-09", "2016-09-10", "2016-09-11", "2016-09-12", "2016-09-13",
> > "2016-09-14", "2016-09-17", "2016-09-18", "2016-09-19", "2016-09-20",
> > "2016-09-23", "2016-09-24", "2016-09-26", "2016-09-27", "2016-09-28",
> > "2016-09-29", "2016-09-30", "2016-10-02", "2016-10-03", "2016-10-04",
> > "2016-10-05", "2016-10-06", "2016-10-08", "2016-10-09", "2016-10-11",
> > "2016-10-12", "2016-10-13", "2016-10-14", "2016-10-15", "2016-10-16",
> > "2016-10-18", "2016-10-19", "2016-10-20", "2016-10-21", "2016-10-22",
> > "2016-10-23", "2016-10-24", "2016-10-25", "2016-10-27", "2016-10-28",
> > "2016-10-29", "2016-10-30", "2016-10-31", "2016-11-01", "2016-11-02",
> > "2016-11-07", "2016-11-17", "2016-11-25", "2016-11-27", "2017-06-19",
> > "2017-07-06", "2017-07-08", "2017-07-12", "2017-07-17", "2017-07-18",
> > "2017-07-20", "2017-07-21", "2017-07-22", "2017-07-23", "2017-07-24",
> > "2017-07-25", "2017-07-26", "2017-07-27", "2017-07-29", "2017-07-31",
> > "2017-08-01", "2017-08-02", "2017-08-03", "2017-08-04", "2017-08-05",
> > "2017-08-07", "2017-08-09", "2017-08-10", "2017-08-13", "2017-08-15",
> > "2017-08-16", "2017-08-17", "2017-08-18", "2017-08-20", "2017-08-24",
> > "2017-08-25", "2017-08-26", "2017-08-28", "2017-08-29", "2017-09-03",
> > "2017-09-04", "2017-09-06", "2017-09-08", "2017-09-10", "2017-09-11",
> > "2017-09-12", "2017-09-14", "2017-09-15", "2017-09-16", "2017-09-17",
> > "2017-09-18", "2017-09-19", "2017-09-21", "2017-09-22", "2017-09-23",
> > "2017-09-24", "2017-09-25", "2017-09-26", "2017-09-27", "2017-09-28",
> > "2017-09-29", "2017-09-30", "2017-10-01", "2017-10-02", "2017-10-03",
> > "2017-10-04", "2017-10-06", "2017-10-07", "2017-10-08", "2017-10-10",
> > "2017-10-11", "2017-10-12", "2017-10-14", "2017-10-15", "2017-10-16",
> > "2017-10-19", "2017-10-20", "2017-10-22", "2017-10-23", "2017-10-24",
> > "2017-10-25", "2017-10-26", "2017-10-27", "2017-10-28", "2017-10-29",
> > "2017-10-30", "2017-10-31", "2017-11-01", "2017-11-02", "2017-11-03",
> > "2017-11-04", "2017-11-05", "2017-11-06", "2017-11-07", "2017-11-09",
> > "2017-11-10", "2017-11-11", "2017-11-13", "2017-11-16", "2017-11-17",
> > "2017-11-21", "2017-11-22", "2017-11-23", "2017-11-27", "2017-11-28",
> > "2017-11-29", "2017-11-30", "2017-12-02", "2017-12-03", "2017-12-05",
> > "2017-12-09", "2017-12-10", "2017-12-11", "2017-12-13", "2017-12-14",
> > "2017-12-20", "2017-12-21", "2018-07-03", "2018-07-06", "2018-07-07",
> > "2018-07-08", "2018-07-09", "2018-07-10", "2018-07-11", "2018-07-12",
> > "2018-07-13", "2018-07-14", "2018-07-16", "2018-07-18", "2018-07-19",
> > "2018-07-20", "2018-07-21", "2018-07-22", "2018-07-24", "2018-07-25",
> > "2018-07-26", "2018-07-27", "2018-07-28", "2018-07-29", "2018-07-30",
> > "2018-07-31", "2018-08-01", "2018-08-02", "2018-08-03", "2018-08-04",
> > "2018-08-05", "2018-08-07", "2018-08-08", "2018-08-09", "2018-08-10",
> > "2018-08-11", "2018-08-12", "2018-08-13", "2018-08-14", "2018-08-15",
> > "2018-08-16", "2018-08-17", "2018-08-18", "2018-08-20", "2018-08-24",
> > "2018-08-26", "2018-08-27", "2018-08-28", "2018-08-29", "2018-08-30",
> > "2018-08-31", "2018-09-02", "2018-09-03", "2018-09-04", "2018-09-05",
> > "2018-09-06", "2018-09-07", "2018-09-08", "2018-09-09", "2018-09-10",
> > "2018-09-11", "2018-09-12", "2018-09-13", "2018-09-14", "2018-09-15",
> > "2018-09-17", "2018-09-18", "2018-09-19", "2018-09-20", "2018-09-21",
> > "2018-09-22", "2018-09-23", "2018-09-24", "2018-09-26", "2018-09-27",
> > "2018-09-28", "2018-09-29", "2018-09-30", "2018-10-01", "2018-10-02",
> > "2018-10-03", "2018-10-05", "2018-10-06", "2018-10-08", "2018-10-09",
> > "2018-10-10", "2018-10-12", "2018-10-13", "2018-10-14", "2018-10-17",
> > "2018-10-18", "2018-10-19", "2018-10-22", "2018-10-27", "2018-10-28",
> > "2018-10-29", "2018-11-01", "2018-11-03", "2018-11-04", "2018-11-05"
> > ), class = "factor"), abundance = c(0, 2, 5, 6, 6, 7, 7, 7, 7,
> > 9, 11, 13, 13, 13, 13, 14, 15, 15, 16, 17, 17, 18, 18, 19, 22,
> > 23, 24, 25, 29, 31, 32, 34, 36, 36, 37, 37, 38, 39, 40, 40, 40,
> > 40, 40, 41, 41, 41, 44, 44, 44, 47, 47, 47, 47, 47, 47, 47, 47,
> > 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,
> > 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,
> > 48, 48, 48, 48, 48, 48, 48, 48, 48, 1, 2, 2, 2, 3, 4, 5, 6, 6,
> > 6, 7, 9, 10, 11, 12, 14, 14, 15, 15, 16, 18, 19, 21, 22, 24,
> > 25, 25, 26, 27, 28, 29, 30, 31, 31, 33, 33, 35, 36, 37, 38, 39,
> > 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41,
> > 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,
> > 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42,
> > 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43,
> > 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
> > 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43,
> > 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 0,
> > 1, 2, 3, 4, 4, 5, 6, 6, 7, 7, 7, 8, 8, 8, 9, 10, 10, 10, 10,
> > 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 14, 15, 16, 18, 19,
> > 20, 21, 21, 21, 21, 21, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35,
> > 35, 35, 36, 36, 37, 39, 41, 42, 42, 43, 43, 43, 44, 44, 45, 47,
> > 47, 47, 47, 48, 49, 49, 50, 50, 50, 50, 50, 50, 51, 52, 52, 52,
> > 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
> > 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,
> > 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54,
> > 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55,
> > 55, 55, 55, 55, 55), DATE = c("07/03", "07/06", "07/07", "07/08",
> > "07/09", "07/10", "07/11", "07/12", "07/13", "07/14", "07/16",
> > "07/18", "07/19", "07/20", "07/21", "07/22", "07/24", "07/25",
> > "07/26", "07/27", "07/28", "07/29", "07/30", "07/31", "08/01",
> > "08/02", "08/03", "08/04", "08/05", "08/07", "08/08", "08/09",
> > "08/10", "08/11", "08/12", "08/13", "08/14", "08/15", "08/16",
> > "08/17", "08/18", "08/20", "08/24", "08/26", "08/27", "08/28",
> > "08/29", "08/30", "08/31", "09/02", "09/03", "09/04", "09/05",
> > "09/06", "09/07", "09/08", "09/09", "09/10", "09/11", "09/12",
> > "09/13", "09/14", "09/15", "09/17", "09/18", "09/19", "09/20",
> > "09/21", "09/22", "09/23", "09/24", "09/26", "09/27", "09/28",
> > "09/29", "09/30", "10/01", "10/02", "10/03", "10/05", "10/06",
> > "10/08", "10/09", "10/10", "10/12", "10/13", "10/14", "10/17",
> > "10/18", "10/19", "10/22", "10/27", "10/28", "10/29", "11/01",
> > "11/03", "11/04", "11/05", "06/19", "07/06", "07/08", "07/12",
> > "07/17", "07/18", "07/20", "07/21", "07/22", "07/23", "07/24",
> > "07/25", "07/26", "07/27", "07/27", "07/29", "07/29", "07/31",
> > "07/31", "08/01", "08/02", "08/02", "08/03", "08/03", "08/04",
> > "08/05", "08/05", "08/07", "08/09", "08/10", "08/13", "08/15",
> > "08/16", "08/17", "08/18", "08/18", "08/20", "08/24", "08/25",
> > "08/26", "08/28", "08/29", "09/03", "09/04", "09/06", "09/08",
> > "09/10", "09/10", "09/11", "09/11", "09/12", "09/12", "09/14",
> > "09/14", "09/15", "09/16", "09/17", "09/18", "09/18", "09/19",
> > "09/19", "09/21", "09/21", "09/22", "09/22", "09/23", "09/23",
> > "09/24", "09/25", "09/25", "09/26", "09/26", "09/27", "09/27",
> > "09/28", "09/28", "09/29", "09/29", "09/30", "09/30", "10/01",
> > "10/01", "10/02", "10/03", "10/03", "10/04", "10/04", "10/06",
> > "10/06", "10/07", "10/08", "10/10", "10/10", "10/11", "10/11",
> > "10/12", "10/14", "10/15", "10/16", "10/16", "10/19", "10/20",
> > "10/20", "10/22", "10/22", "10/23", "10/24", "10/25", "10/26",
> > "10/26", "10/27", "10/27", "10/28", "10/28", "10/29", "10/29",
> > "10/30", "10/30", "10/31", "11/01", "11/01", "11/02", "11/03",
> > "11/03", "11/04", "11/05", "11/06", "11/07", "11/09", "11/10",
> > "11/11", "11/13", "11/16", "11/17", "11/21", "11/22", "11/23",
> > "11/27", "11/28", "11/29", "11/30", "12/02", "12/03", "12/05",
> > "12/09", "12/10", "12/11", "12/13", "12/14", "12/20", "12/21",
> > "12/21", "06/01", "06/06", "06/12", "06/14", "06/16", "06/17",
> > "06/18", "06/19", "06/21", "06/21", "06/22", "06/23", "06/24",
> > "06/24", "06/26", "06/26", "06/27", "06/27", "06/28", "06/30",
> > "06/30", "07/01", "07/01", "07/03", "07/05", "07/07", "07/08",
> > "07/09", "07/11", "07/12", "07/14", "07/16", "07/17", "07/17",
> > "07/18", "07/18", "07/19", "07/20", "07/21", "07/22", "07/23",
> > "07/25", "07/26", "07/27", "07/28", "07/29", "07/29", "07/30",
> > "08/01", "08/01", "08/02", "08/02", "08/03", "08/04", "08/05",
> > "08/06", "08/07", "08/08", "08/08", "08/09", "08/10", "08/11",
> > "08/12", "08/13", "08/13", "08/14", "08/15", "08/16", "08/18",
> > "08/19", "08/20", "08/21", "08/21", "08/25", "08/26", "08/28",
> > "09/02", "09/02", "09/04", "09/05", "09/06", "09/07", "09/08",
> > "09/08", "09/09", "09/10", "09/11", "09/12", "09/12", "09/13",
> > "09/13", "09/14", "09/14", "09/17", "09/18", "09/18", "09/19",
> > "09/20", "09/20", "09/23", "09/24", "09/26", "09/27", "09/28",
> > "09/29", "09/30", "09/30", "10/02", "10/03", "10/03", "10/04",
> > "10/05", "10/06", "10/08", "10/09", "10/09", "10/11", "10/12",
> > "10/12", "10/13", "10/14", "10/14", "10/15", "10/16", "10/16",
> > "10/18", "10/19", "10/19", "10/20", "10/20", "10/21", "10/21",
> > "10/22", "10/23", "10/23", "10/24", "10/25", "10/25", "10/27",
> > "10/27", "10/28", "10/29", "10/30", "10/30", "10/31", "10/31",
> > "11/01", "11/02", "11/07", "11/07", "11/17", "11/25", "11/27"
> > ), site = c("A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A",
> > "A", "A", "A")), .Names = c("year", "date", "abundance", "DATE",
> > "site"), row.names = c(NA, 403L), class = "data.frame")
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Thu Sep  5 18:58:56 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Thu, 5 Sep 2019 11:58:56 -0500
Subject: [R] Is this a way to perform cross validation?
Message-ID: <CAMOcQfNBPmfDmGwbxJgZG6VwHp7ds-Cg5jm2HrKAQhPhL=e3cQ@mail.gmail.com>

Dear friends,

Hope you are all doing great. If I am not mistaken, cross validation is
about splitting the data into two parts: the training dataset and the test
dataset.
I have a dataset having the number of vehicles sold, from january 2008 up
to june 2019.

I decided to go for an 80-20 scheme (where I would use 80% of the data for
training, and the remaining 20% of the data for testing).

# I am currently using R version 3.6.1 / 64-bit
# I am using packages forecast and MLmetrics

So I did the following:
library(MLmetrics)
library(forecast)
#my data consists of 138 rows in total
TotalRows <- nrow(dataset)
TestRowStart  <-  floor(0.20*nrow(mydataframe)) + 1
mydataframe <- data.frame(dataset)
trainingrows <- nrow(mydataframe) - floor(0.20*nrow(mydataframe)) # this
obviously gives me a tiny little bit more than the 80% roughly 80.4%
mytrainingdata <- [1:trainingrows,] # took data from january 2008 to
february 2017
tsmytrainingdata <- ts(mytrainingdata$vehicles, start=c(2008,1),
end=c(2017,2), frequency=12)
myarimamodel <- auto.arima(tsmytrainingdata, lambda=0, biasadj=TRUE)
myarimaforec <- forecast(myarimamodel, h=36)
myarimaforecframe <- data.frame(myarimaforec$mean)
TestData <- mydataframe[TestRowStart:TotalRows,]
myarimamodelMAPE <- MAPE(myarimaforecframe[1:(TotalRows - TrainRowStart),],
TestData)

can this be considered cross validation?

here is the dput() if my dataset, in the case of the code I put above,
mydataframe = datframe (which shows in the dput)

structure(list(DATE = structure(c(47L, 35L, 82L, 1L, 94L, 70L,
59L, 13L, 128L, 117L, 106L, 24L, 48L, 36L, 83L, 2L, 95L, 71L,
60L, 14L, 129L, 118L, 107L, 25L, 49L, 37L, 84L, 3L, 96L, 72L,
61L, 15L, 130L, 119L, 108L, 26L, 50L, 38L, 85L, 4L, 97L, 73L,
62L, 16L, 131L, 120L, 109L, 27L, 51L, 39L, 86L, 5L, 98L, 74L,
63L, 17L, 132L, 121L, 110L, 28L, 52L, 40L, 87L, 6L, 99L, 75L,
64L, 18L, 133L, 122L, 111L, 29L, 53L, 41L, 88L, 7L, 100L, 76L,
65L, 19L, 134L, 123L, 112L, 30L, 54L, 42L, 89L, 8L, 101L, 77L,
66L, 20L, 135L, 124L, 113L, 31L, 55L, 43L, 90L, 9L, 102L, 78L,
67L, 21L, 136L, 125L, 114L, 32L, 56L, 44L, 91L, 10L, 103L, 79L,
68L, 22L, 137L, 126L, 115L, 33L, 57L, 45L, 92L, 11L, 104L, 80L,
69L, 23L, 138L, 127L, 116L, 34L, 58L, 46L, 93L, 12L, 105L, 81L
), .Label = c("Apr-08", "Apr-09", "Apr-10", "Apr-11", "Apr-12",
"Apr-13", "Apr-14", "Apr-15", "Apr-16", "Apr-17", "Apr-18", "Apr-19",
"Aug-08", "Aug-09", "Aug-10", "Aug-11", "Aug-12", "Aug-13", "Aug-14",
"Aug-15", "Aug-16", "Aug-17", "Aug-18", "Dec-08", "Dec-09", "Dec-10",
"Dec-11", "Dec-12", "Dec-13", "Dec-14", "Dec-15", "Dec-16", "Dec-17",
"Dec-18", "Feb-08", "Feb-09", "Feb-10", "Feb-11", "Feb-12", "Feb-13",
"Feb-14", "Feb-15", "Feb-16", "Feb-17", "Feb-18", "Feb-19", "Jan-08",
"Jan-09", "Jan-10", "Jan-11", "Jan-12", "Jan-13", "Jan-14", "Jan-15",
"Jan-16", "Jan-17", "Jan-18", "Jan-19", "Jul-08", "Jul-09", "Jul-10",
"Jul-11", "Jul-12", "Jul-13", "Jul-14", "Jul-15", "Jul-16", "Jul-17",
"Jul-18", "Jun-08", "Jun-09", "Jun-10", "Jun-11", "Jun-12", "Jun-13",
"Jun-14", "Jun-15", "Jun-16", "Jun-17", "Jun-18", "Jun-19", "Mar-08",
"Mar-09", "Mar-10", "Mar-11", "Mar-12", "Mar-13", "Mar-14", "Mar-15",
"Mar-16", "Mar-17", "Mar-18", "Mar-19", "May-08", "May-09", "May-10",
"May-11", "May-12", "May-13", "May-14", "May-15", "May-16", "May-17",
"May-18", "May-19", "Nov-08", "Nov-09", "Nov-10", "Nov-11", "Nov-12",
"Nov-13", "Nov-14", "Nov-15", "Nov-16", "Nov-17", "Nov-18", "Oct-08",
"Oct-09", "Oct-10", "Oct-11", "Oct-12", "Oct-13", "Oct-14", "Oct-15",
"Oct-16", "Oct-17", "Oct-18", "Sep-08", "Sep-09", "Sep-10", "Sep-11",
"Sep-12", "Sep-13", "Sep-14", "Sep-15", "Sep-16", "Sep-17", "Sep-18"
), class = "factor"), totalmov = c(18368L, 14629L, 19310L, 20273L,
16097L, 16003L, 16146L, 14312L, 15319L, 19480L, 14267L, 18309L,
12533L, 7262L, 4914L, 5854L, 7626L, 5708L, 7678L, 6927L, 5923L,
9020L, 8975L, 11214L, 8461L, 9512L, 13410L, 12526L, 11374L, 17829L,
13174L, 22175L, 14551L, 17311L, 16491L, 11970L, 14527L, 16905L,
16488L, 14356L, 13855L, 11468L, 16514L, 13025L, 14153L, 19022L,
18262L, 9609L, 18603L, 9389L, 15899L, 13395L, 10689L, 11137L,
13818L, 12983L, 10083L, 14301L, 11912L, 12106L, 12686L, 7947L,
11442L, 13656L, 12093L, 11433L, 14732L, 11175L, 10449L, 14286L,
10935L, 10627L, 12076L, 10170L, 9264L, 13859L, 9821L, 10384L,
12372L, 14902L, 11804L, 9911L, 11841L, 10127L, 12615L, 6851L,
9181L, 13667L, 12759L, 9531L, 12636L, 14683L, 10383L, 16141L,
12132L, 8123L, 12858L, 7811L, 10865L, 11931L, 10397L, 6020L,
9384L, 13473L, 12702L, 14671L, 12485L, 16787L, 11698L, 12988L,
13120L, 11411L, 12317L, 9905L, 13387L, 10928L, 10697L, 16790L,
10381L, 10121L, 11728L, 9625L, 9345L, 18263L, 17753L, 12488L,
14469L, 13134L, 17799L, 14770L, 17104L, 11912L, 16229L, 14273L,
13223L, 15277L, 15185L, 15568L)), class = "data.frame", row.names = c(NA,
-138L))

Best regards,

Paul

	[[alternative HTML version deleted]]


From g|@n|uc@@boo @end|ng |rom @oton@@c@uk  Thu Sep  5 18:06:39 2019
From: g|@n|uc@@boo @end|ng |rom @oton@@c@uk (Boo G.)
Date: Thu, 5 Sep 2019 16:06:39 +0000
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
Message-ID: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>

Hello,

I am trying to perform a Kolmogorov?Smirnov test to assess the difference between a distribution and samples drawn proportionally to size of different sizes. I managed to compute the Kolmogorov?Smirnov distance but I am lost with the p-value. I have looked into the ks.test function unsuccessfully. Can anyone help me with computing p-values for a two-tailed test?

Below a simplified version of my code.

Thanks in advance.
Gianluca


library(spatstat)

#reference distribution
d_1 <- sort(rpois(1000, 500))
p_1 <- d_1/sum(d_1)
m_1 <- data.frame(d_1, p_1)

#data frame to store the values of the siumation
d_stat <- data.frame(1:1000, NA, NA)
names(d_stat) <- c("sample_size", "ks_distance", "p_value")

#simulation
for (i in 1:1000) {
  #sample from the reference distribution
  m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
  m_2 <-m_2[order(m_2$d_1),]
  d_2 <- m_2$d_1
  p_2 <- m_2$p_1

  #weighted ecdf for the reference distribution and the sample
  f_d_1 <- ewcdf(d_1, normalise=F)
  f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))

  #kolmogorov-smirnov distance
  d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
}


	[[alternative HTML version deleted]]


From Go|denS @end|ng |rom NJHe@|th@org  Thu Sep  5 18:45:52 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Thu, 5 Sep 2019 16:45:52 +0000
Subject: [R] [R-devel] Source Code for function
Message-ID: <D87F40F8-24A1-444F-8741-F6E8F0EDB8C2@njhealth.org>

A non-text attachment was scrubbed...
Name: R Help_Function.pdf
Type: application/pdf
Size: 56946 bytes
Desc: R Help_Function.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190905/26d7bb02/attachment.pdf>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: getAnywhere(subset.data.frame).png
Type: image/png
Size: 143309 bytes
Desc: getAnywhere(subset.data.frame).png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190905/26d7bb02/attachment.png>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  5 20:29:48 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 5 Sep 2019 19:29:48 +0100
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
In-Reply-To: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
References: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
Message-ID: <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>

Hello,

I don't have the algorithms at hand but the KS statistic calculation is 
more complicated than your max/abs difference.

Anyway, why not use ks.test? it's not that difficult:


set.seed(1234)
#reference distribution
d_1 <- sort(rpois(1000, 500))
p_1 <- d_1/sum(d_1)
m_1 <- data.frame(d_1, p_1)

#data frame to store the values of the simulation
d_stat <- data.frame(1:1000, NA, NA)
names(d_stat) <- c("sample_size", "ks_distance", "p_value")

#simulation
for (i in 1:1000) {
   #sample from the reference distribution
   m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
   d_2 <- m_2$d_1

   ht <- ks.test(d_1, d_2)
   #kolmogorov-smirnov distance
   d_stat[i, 2] <- ht$statistic
   d_stat[i, 3] <- ht$p.value
}

hist(d_stat[, 2])
hist(d_stat[, 3])


Note that d_2 is not sorted, but the results are equal in the sense of 
function identical(), meaning they are *exactly* the same. Why shouldn't 
they?

Hope this helps,

Rui Barradas


?s 17:06 de 05/09/19, Boo G. escreveu:
> Hello,
> 
> I am trying to perform a Kolmogorov?Smirnov test to assess the difference between a distribution and samples drawn proportionally to size of different sizes. I managed to compute the Kolmogorov?Smirnov distance but I am lost with the p-value. I have looked into the ks.test function unsuccessfully. Can anyone help me with computing p-values for a two-tailed test?
> 
> Below a simplified version of my code.
> 
> Thanks in advance.
> Gianluca
> 
> 
> library(spatstat)
> 
> #reference distribution
> d_1 <- sort(rpois(1000, 500))
> p_1 <- d_1/sum(d_1)
> m_1 <- data.frame(d_1, p_1)
> 
> #data frame to store the values of the siumation
> d_stat <- data.frame(1:1000, NA, NA)
> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
> 
> #simulation
> for (i in 1:1000) {
>    #sample from the reference distribution
>    m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>    m_2 <-m_2[order(m_2$d_1),]
>    d_2 <- m_2$d_1
>    p_2 <- m_2$p_1
> 
>    #weighted ecdf for the reference distribution and the sample
>    f_d_1 <- ewcdf(d_1, normalise=F)
>    f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
> 
>    #kolmogorov-smirnov distance
>    d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
> }
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From g|@n|uc@@boo @end|ng |rom @oton@@c@uk  Thu Sep  5 20:42:36 2019
From: g|@n|uc@@boo @end|ng |rom @oton@@c@uk (Boo G.)
Date: Thu, 5 Sep 2019 18:42:36 +0000
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
In-Reply-To: <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
References: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
 <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
Message-ID: <731CE879-2AD5-42F8-8567-80712FAC330A@soton.ac.uk>

Thanks for your reply, Rui. 

I don?t think that I can use directly the ks.test because I have a weighted sample (see  m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]) and I want to account for that. That?s why I am trying to compute everything manually. 

Also, if you look at the results of the ks.test in your simulation, you will notice that the p-value always implies that the sample is always (even with same size = 1) drawn form the same distribution. This looks suspicious to me.

What are your thoughts?

> 

> On 5 Sep 2019, at 20:29, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> I don't have the algorithms at hand but the KS statistic calculation is more complicated than your max/abs difference.
> 
> Anyway, why not use ks.test? it's not that difficult:
> 
> 
> set.seed(1234)
> #reference distribution
> d_1 <- sort(rpois(1000, 500))
> p_1 <- d_1/sum(d_1)
> m_1 <- data.frame(d_1, p_1)
> 
> #data frame to store the values of the simulation
> d_stat <- data.frame(1:1000, NA, NA)
> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
> 
> #simulation
> for (i in 1:1000) {
>  #sample from the reference distribution
>  m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>  d_2 <- m_2$d_1
> 
>  ht <- ks.test(d_1, d_2)
>  #kolmogorov-smirnov distance
>  d_stat[i, 2] <- ht$statistic
>  d_stat[i, 3] <- ht$p.value
> }
> 
> hist(d_stat[, 2])
> hist(d_stat[, 3])
> 
> 
> Note that d_2 is not sorted, but the results are equal in the sense of function identical(), meaning they are *exactly* the same. Why shouldn't they?
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 17:06 de 05/09/19, Boo G. escreveu:
>> Hello,
>> I am trying to perform a Kolmogorov?Smirnov test to assess the difference between a distribution and samples drawn proportionally to size of different sizes. I managed to compute the Kolmogorov?Smirnov distance but I am lost with the p-value. I have looked into the ks.test function unsuccessfully. Can anyone help me with computing p-values for a two-tailed test?
>> Below a simplified version of my code.
>> Thanks in advance.
>> Gianluca
>> library(spatstat)
>> #reference distribution
>> d_1 <- sort(rpois(1000, 500))
>> p_1 <- d_1/sum(d_1)
>> m_1 <- data.frame(d_1, p_1)
>> #data frame to store the values of the siumation
>> d_stat <- data.frame(1:1000, NA, NA)
>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>> #simulation
>> for (i in 1:1000) {
>>   #sample from the reference distribution
>>   m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>   m_2 <-m_2[order(m_2$d_1),]
>>   d_2 <- m_2$d_1
>>   p_2 <- m_2$p_1
>>   #weighted ecdf for the reference distribution and the sample
>>   f_d_1 <- ewcdf(d_1, normalise=F)
>>   f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>   #kolmogorov-smirnov distance
>>   d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
>> }
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C0c709068527c41e062dd08d7322f0d72%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=y9jfixyNiroKwKZEJj0owuCcWoeFQKZdaG9WLe2xHQ8%3D&amp;reserved=0
>> PLEASE do read the posting guide https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C0c709068527c41e062dd08d7322f0d72%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=7n0doy4P1S1TpApX1zpUborAnUnxuOxYtn%2FQ%2BtVztGM%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  5 20:46:42 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 5 Sep 2019 19:46:42 +0100
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
In-Reply-To: <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
References: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
 <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
Message-ID: <9a8b56cc-8b7f-7f38-023b-80e5c3dcb969@sapo.pt>

Hello,

I'm sorry, but apparently I missed the point of your problem.
Please do not take my previous answer seriously.

But you can use ks.test, just in a different way than what I wrote 
previously.

Corrected code:


#simulation
for (i in 1:1000) {
   #sample from the reference distribution
   m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
   m_2 <-m_2[order(m_2$d_1),]
   d_2 <- m_2$d_1
   p_2 <- m_2$p_1

   #weighted ecdf for the reference distribution and the sample
   f_d_1 <- ewcdf(d_1, normalise=F)
   f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))

   #kolmogorov-smirnov distance
   x <- f_d_1(d_2)
   y <- f_d_2(d_2)
   ht <- ks.test(x, y)
   d_stat[i, 2] <- ht$statistic
   d_stat[i, 3] <- ht$p.value
}


Hope this helps,

Rui Barradas

?s 19:29 de 05/09/19, Rui Barradas escreveu:
> Hello,
> 
> I don't have the algorithms at hand but the KS statistic calculation is 
> more complicated than your max/abs difference.
> 
> Anyway, why not use ks.test? it's not that difficult:
> 
> 
> set.seed(1234)
> #reference distribution
> d_1 <- sort(rpois(1000, 500))
> p_1 <- d_1/sum(d_1)
> m_1 <- data.frame(d_1, p_1)
> 
> #data frame to store the values of the simulation
> d_stat <- data.frame(1:1000, NA, NA)
> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
> 
> #simulation
> for (i in 1:1000) {
>  ? #sample from the reference distribution
>  ? m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>  ? d_2 <- m_2$d_1
> 
>  ? ht <- ks.test(d_1, d_2)
>  ? #kolmogorov-smirnov distance
>  ? d_stat[i, 2] <- ht$statistic
>  ? d_stat[i, 3] <- ht$p.value
> }
> 
> hist(d_stat[, 2])
> hist(d_stat[, 3])
> 
> 
> Note that d_2 is not sorted, but the results are equal in the sense of 
> function identical(), meaning they are *exactly* the same. Why shouldn't 
> they?
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 17:06 de 05/09/19, Boo G. escreveu:
>> Hello,
>>
>> I am trying to perform a Kolmogorov?Smirnov test to assess the 
>> difference between a distribution and samples drawn proportionally to 
>> size of different sizes. I managed to compute the Kolmogorov?Smirnov 
>> distance but I am lost with the p-value. I have looked into the 
>> ks.test function unsuccessfully. Can anyone help me with computing 
>> p-values for a two-tailed test?
>>
>> Below a simplified version of my code.
>>
>> Thanks in advance.
>> Gianluca
>>
>>
>> library(spatstat)
>>
>> #reference distribution
>> d_1 <- sort(rpois(1000, 500))
>> p_1 <- d_1/sum(d_1)
>> m_1 <- data.frame(d_1, p_1)
>>
>> #data frame to store the values of the siumation
>> d_stat <- data.frame(1:1000, NA, NA)
>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>>
>> #simulation
>> for (i in 1:1000) {
>> ?? #sample from the reference distribution
>> ?? m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>> ?? m_2 <-m_2[order(m_2$d_1),]
>> ?? d_2 <- m_2$d_1
>> ?? p_2 <- m_2$p_1
>>
>> ?? #weighted ecdf for the reference distribution and the sample
>> ?? f_d_1 <- ewcdf(d_1, normalise=F)
>> ?? f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>
>> ?? #kolmogorov-smirnov distance
>> ?? d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
>> }
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g|@n|uc@@boo @end|ng |rom @oton@@c@uk  Thu Sep  5 21:09:11 2019
From: g|@n|uc@@boo @end|ng |rom @oton@@c@uk (Boo G.)
Date: Thu, 5 Sep 2019 19:09:11 +0000
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
In-Reply-To: <9a8b56cc-8b7f-7f38-023b-80e5c3dcb969@sapo.pt>
References: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
 <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
 <9a8b56cc-8b7f-7f38-023b-80e5c3dcb969@sapo.pt>
Message-ID: <FFE6EE50-7752-4A06-9588-E652EDA1CC95@soton.ac.uk>

Hello again.

I have tied this before but I see two problems:

1) According to the documentation I could read (including the ks.test code), the ks statistic would be max(abs(x - y)) and if you plot this for very low sample sizes you can actually see that this make sense. The results of ks.test(x, y) yields very different values.

2) Also in this case the p-values don?t make much sense, according to my previous interpretation.

Again, I could be wrong in my interpretation.

On 5 Sep 2019, at 20:46, Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>> wrote:

Hello,

I'm sorry, but apparently I missed the point of your problem.
Please do not take my previous answer seriously.

But you can use ks.test, just in a different way than what I wrote previously.

Corrected code:


#simulation
for (i in 1:1000) {
 #sample from the reference distribution
 m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
 m_2 <-m_2[order(m_2$d_1),]
 d_2 <- m_2$d_1
 p_2 <- m_2$p_1

 #weighted ecdf for the reference distribution and the sample
 f_d_1 <- ewcdf(d_1, normalise=F)
 f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))

 #kolmogorov-smirnov distance
 x <- f_d_1(d_2)
 y <- f_d_2(d_2)
 ht <- ks.test(x, y)
 d_stat[i, 2] <- ht$statistic
 d_stat[i, 3] <- ht$p.value
}


Hope this helps,

Rui Barradas

?s 19:29 de 05/09/19, Rui Barradas escreveu:
Hello,
I don't have the algorithms at hand but the KS statistic calculation is more complicated than your max/abs difference.
Anyway, why not use ks.test? it's not that difficult:
set.seed(1234)
#reference distribution
d_1 <- sort(rpois(1000, 500))
p_1 <- d_1/sum(d_1)
m_1 <- data.frame(d_1, p_1)
#data frame to store the values of the simulation
d_stat <- data.frame(1:1000, NA, NA)
names(d_stat) <- c("sample_size", "ks_distance", "p_value")
#simulation
for (i in 1:1000) {
  #sample from the reference distribution
  m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
  d_2 <- m_2$d_1
  ht <- ks.test(d_1, d_2)
  #kolmogorov-smirnov distance
  d_stat[i, 2] <- ht$statistic
  d_stat[i, 3] <- ht$p.value
}
hist(d_stat[, 2])
hist(d_stat[, 3])
Note that d_2 is not sorted, but the results are equal in the sense of function identical(), meaning they are *exactly* the same. Why shouldn't they?
Hope this helps,
Rui Barradas
?s 17:06 de 05/09/19, Boo G. escreveu:
Hello,

I am trying to perform a Kolmogorov?Smirnov test to assess the difference between a distribution and samples drawn proportionally to size of different sizes. I managed to compute the Kolmogorov?Smirnov distance but I am lost with the p-value. I have looked into the ks.test function unsuccessfully. Can anyone help me with computing p-values for a two-tailed test?

Below a simplified version of my code.

Thanks in advance.
Gianluca


library(spatstat)

#reference distribution
d_1 <- sort(rpois(1000, 500))
p_1 <- d_1/sum(d_1)
m_1 <- data.frame(d_1, p_1)

#data frame to store the values of the siumation
d_stat <- data.frame(1:1000, NA, NA)
names(d_stat) <- c("sample_size", "ks_distance", "p_value")

#simulation
for (i in 1:1000) {
   #sample from the reference distribution
   m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
   m_2 <-m_2[order(m_2$d_1),]
   d_2 <- m_2$d_1
   p_2 <- m_2$p_1

   #weighted ecdf for the reference distribution and the sample
   f_d_1 <- ewcdf(d_1, normalise=F)
   f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))

   #kolmogorov-smirnov distance
   d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
}


    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=ZntDJlPtp%2Bu%2FeO7xNZLbUQgLwpvS1M%2FUVNwovp%2FZPmA%3D&amp;reserved=0
PLEASE do read the posting guide https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=ZntDJlPtp%2Bu%2FeO7xNZLbUQgLwpvS1M%2FUVNwovp%2FZPmA%3D&amp;reserved=0
PLEASE do read the posting guide https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  5 21:21:14 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 5 Sep 2019 20:21:14 +0100
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
In-Reply-To: <FFE6EE50-7752-4A06-9588-E652EDA1CC95@soton.ac.uk>
References: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
 <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
 <9a8b56cc-8b7f-7f38-023b-80e5c3dcb969@sapo.pt>
 <FFE6EE50-7752-4A06-9588-E652EDA1CC95@soton.ac.uk>
Message-ID: <cee98204-19de-397a-d81c-585a31462bb7@sapo.pt>

Hello,

Inline.

?s 20:09 de 05/09/19, Boo G. escreveu:
> Hello again.
> 
> I have tied this before but I see two problems:
> 
> 1) According to the documentation I could read?(including the ks.test 
> code), the ks statistic would be?max(abs(x - y)) and if you plot this 
> for very low sample sizes you can actually see that this make sense. The 
> results of ks.test(x, y)?yields?very different values.

The problem is that the distribution of Dn is very difficult to compute. 
 From the reference [1] in the help page ?ks.test:

  	Kolmogorov's goodness-of-fit measure, Dn , for a sample CDF has 
consistently been set aside for methods such as the D+n or D-n of 
Smirnov, primarily, it seems, because of the difficulty of computing the 
distribution of Dn . As far as we know, no easy way to compute that 
distribution has ever been provided in the 70+ years since Kolmogorov's 
fundamental paper. We provide one here, a C procedure that provides 
Pr(Dn < d) with 13-15 digit accuracy for n ranging from 2 to at least 16000.


That is why I used ks.test and its Dn and p-values. Note that n >= 2, 
size = 1 is not covered (p-value == 1).

Also, the p-values distribution seem to become closer to a uniform with 
increasing sizes. Try

hist(d_stat[801:1000, 3])


[1]https://www.jstatsoft.org/article/view/v008i18


Hope this helps,

Rui Barradas

> 
> 2) Also in this case the p-values?don?t make much sense, according to my 
> previous?interpretation.
> 
> Again, I could be wrong in my interpretation.
> 
>> On 5 Sep 2019, at 20:46, Rui Barradas <ruipbarradas at sapo.pt 
>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>
>> Hello,
>>
>> I'm sorry, but apparently I missed the point of your problem.
>> Please do not take my previous answer seriously.
>>
>> But you can use ks.test, just in a different way than what I wrote 
>> previously.
>>
>> Corrected code:
>>
>>
>> #simulation
>> for (i in 1:1000) {
>> ?#sample from the reference distribution
>> ?m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>> ?m_2 <-m_2[order(m_2$d_1),]
>> ?d_2 <- m_2$d_1
>> ?p_2 <- m_2$p_1
>>
>> ?#weighted ecdf for the reference distribution and the sample
>> ?f_d_1 <- ewcdf(d_1, normalise=F)
>> ?f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>
>> ?#kolmogorov-smirnov distance
>> ?x <- f_d_1(d_2)
>> ?y <- f_d_2(d_2)
>> ?ht <- ks.test(x, y)
>> ?d_stat[i, 2] <- ht$statistic
>> ?d_stat[i, 3] <- ht$p.value
>> }
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 19:29 de 05/09/19, Rui Barradas escreveu:
>>> Hello,
>>> I don't have the algorithms at hand but the KS statistic calculation 
>>> is more complicated than your max/abs difference.
>>> Anyway, why not use ks.test? it's not that difficult:
>>> set.seed(1234)
>>> #reference distribution
>>> d_1 <- sort(rpois(1000, 500))
>>> p_1 <- d_1/sum(d_1)
>>> m_1 <- data.frame(d_1, p_1)
>>> #data frame to store the values of the simulation
>>> d_stat <- data.frame(1:1000, NA, NA)
>>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>>> #simulation
>>> for (i in 1:1000) {
>>> #sample from the reference distribution
>>> m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>> d_2 <- m_2$d_1
>>> ht <- ks.test(d_1, d_2)
>>> #kolmogorov-smirnov distance
>>> d_stat[i, 2] <- ht$statistic
>>> d_stat[i, 3] <- ht$p.value
>>> }
>>> hist(d_stat[, 2])
>>> hist(d_stat[, 3])
>>> Note that d_2 is not sorted, but the results are equal in the sense 
>>> of function identical(), meaning they are *exactly* the same. Why 
>>> shouldn't they?
>>> Hope this helps,
>>> Rui Barradas
>>> ?s 17:06 de 05/09/19, Boo G. escreveu:
>>>> Hello,
>>>>
>>>> I am trying to perform a Kolmogorov?Smirnov test to assess the 
>>>> difference between a distribution and samples drawn proportionally 
>>>> to size of different sizes. I managed to compute the 
>>>> Kolmogorov?Smirnov distance but I am lost with the p-value. I have 
>>>> looked into the ks.test function unsuccessfully. Can anyone help me 
>>>> with computing p-values for a two-tailed test?
>>>>
>>>> Below a simplified version of my code.
>>>>
>>>> Thanks in advance.
>>>> Gianluca
>>>>
>>>>
>>>> library(spatstat)
>>>>
>>>> #reference distribution
>>>> d_1 <- sort(rpois(1000, 500))
>>>> p_1 <- d_1/sum(d_1)
>>>> m_1 <- data.frame(d_1, p_1)
>>>>
>>>> #data frame to store the values of the siumation
>>>> d_stat <- data.frame(1:1000, NA, NA)
>>>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>>>>
>>>> #simulation
>>>> for (i in 1:1000) {
>>>> #sample from the reference distribution
>>>> m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>>> m_2 <-m_2[order(m_2$d_1),]
>>>> d_2 <- m_2$d_1
>>>> p_2 <- m_2$p_1
>>>>
>>>> #weighted ecdf for the reference distribution and the sample
>>>> f_d_1 <- ewcdf(d_1, normalise=F)
>>>> f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>>>
>>>> #kolmogorov-smirnov distance
>>>> d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
>>>> }
>>>>
>>>>
>>>> ????[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- 
>>>> To UNSUBSCRIBE and more, see
>>>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=ZntDJlPtp%2Bu%2FeO7xNZLbUQgLwpvS1M%2FUVNwovp%2FZPmA%3D&amp;reserved=0
>>>> PLEASE do read the posting 
>>>> guidehttps://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org>mailing list -- To 
>>> UNSUBSCRIBE and more, see
>>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=ZntDJlPtp%2Bu%2FeO7xNZLbUQgLwpvS1M%2FUVNwovp%2FZPmA%3D&amp;reserved=0
>>> PLEASE do read the posting 
>>> guidehttps://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
>>> and provide commented, minimal, self-contained, reproducible code.
>


From g|@n|uc@@boo @end|ng |rom @oton@@c@uk  Thu Sep  5 21:51:03 2019
From: g|@n|uc@@boo @end|ng |rom @oton@@c@uk (Boo G.)
Date: Thu, 5 Sep 2019 19:51:03 +0000
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
In-Reply-To: <cee98204-19de-397a-d81c-585a31462bb7@sapo.pt>
References: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
 <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
 <9a8b56cc-8b7f-7f38-023b-80e5c3dcb969@sapo.pt>
 <FFE6EE50-7752-4A06-9588-E652EDA1CC95@soton.ac.uk>
 <cee98204-19de-397a-d81c-585a31462bb7@sapo.pt>
Message-ID: <0FF57EE7-8848-436D-A752-1ACF7E336A51@soton.ac.uk>

Hello and thanks for your patience.

As far as I understand, the paper of Marsiglia and colleagues refers to CDF samples (i.e. from a hypothetical distribution ? e.g. a Poisson), while I have an ECDF sample (i.e. (pseudo-)observed data ? e.g. rpois(1000, 500). In my study, I am actually comparing the statistical distribution of people per hectares in a region (~50,000 observations) with samples from that distribution.

Agree that we cannot consider at p-values for low sample size. Still, somewhere above 100, I expect to see p-values between 0 and 0.05 (rejecting the fact that the sample comes from the reference distribution). Ideally, I would try the procedure suggested by Marsiglia to compute p-values but this is far beyond my coding skills.




> On 5 Sep 2019, at 21:21, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Inline.
> 
> ?s 20:09 de 05/09/19, Boo G. escreveu:
>> Hello again.
>> I have tied this before but I see two problems:
>> 1) According to the documentation I could read (including the ks.test code), the ks statistic would be max(abs(x - y)) and if you plot this for very low sample sizes you can actually see that this make sense. The results of ks.test(x, y) yields very different values.
> 
> The problem is that the distribution of Dn is very difficult to compute. From the reference [1] in the help page ?ks.test:
> 
> 	Kolmogorov's goodness-of-fit measure, Dn , for a sample CDF has consistently been set aside for methods such as the D+n or D-n of Smirnov, primarily, it seems, because of the difficulty of computing the distribution of Dn . As far as we know, no easy way to compute that distribution has ever been provided in the 70+ years since Kolmogorov's fundamental paper. We provide one here, a C procedure that provides Pr(Dn < d) with 13-15 digit accuracy for n ranging from 2 to at least 16000.
> 
> 
> That is why I used ks.test and its Dn and p-values. Note that n >= 2, size = 1 is not covered (p-value == 1).
> 
> Also, the p-values distribution seem to become closer to a uniform with increasing sizes. Try
> 
> hist(d_stat[801:1000, 3])
> 
> 
> [1]https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv008i18&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7Cfebe94a441914aa58a9908d732363a52%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=JBHkkXn6G4oLQZCV7HoqBLO4a3sMixTa16kOVFwXPlY%3D&amp;reserved=0
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
>> 2) Also in this case the p-values don?t make much sense, according to my previous interpretation.
>> Again, I could be wrong in my interpretation.
>>> On 5 Sep 2019, at 20:46, Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>>> 
>>> Hello,
>>> 
>>> I'm sorry, but apparently I missed the point of your problem.
>>> Please do not take my previous answer seriously.
>>> 
>>> But you can use ks.test, just in a different way than what I wrote previously.
>>> 
>>> Corrected code:
>>> 
>>> 
>>> #simulation
>>> for (i in 1:1000) {
>>>  #sample from the reference distribution
>>>  m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>>  m_2 <-m_2[order(m_2$d_1),]
>>>  d_2 <- m_2$d_1
>>>  p_2 <- m_2$p_1
>>> 
>>>  #weighted ecdf for the reference distribution and the sample
>>>  f_d_1 <- ewcdf(d_1, normalise=F)
>>>  f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>> 
>>>  #kolmogorov-smirnov distance
>>>  x <- f_d_1(d_2)
>>>  y <- f_d_2(d_2)
>>>  ht <- ks.test(x, y)
>>>  d_stat[i, 2] <- ht$statistic
>>>  d_stat[i, 3] <- ht$p.value
>>> }
>>> 
>>> 
>>> Hope this helps,
>>> 
>>> Rui Barradas
>>> 
>>> ?s 19:29 de 05/09/19, Rui Barradas escreveu:
>>>> Hello,
>>>> I don't have the algorithms at hand but the KS statistic calculation is more complicated than your max/abs difference.
>>>> Anyway, why not use ks.test? it's not that difficult:
>>>> set.seed(1234)
>>>> #reference distribution
>>>> d_1 <- sort(rpois(1000, 500))
>>>> p_1 <- d_1/sum(d_1)
>>>> m_1 <- data.frame(d_1, p_1)
>>>> #data frame to store the values of the simulation
>>>> d_stat <- data.frame(1:1000, NA, NA)
>>>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>>>> #simulation
>>>> for (i in 1:1000) {
>>>> #sample from the reference distribution
>>>> m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>>> d_2 <- m_2$d_1
>>>> ht <- ks.test(d_1, d_2)
>>>> #kolmogorov-smirnov distance
>>>> d_stat[i, 2] <- ht$statistic
>>>> d_stat[i, 3] <- ht$p.value
>>>> }
>>>> hist(d_stat[, 2])
>>>> hist(d_stat[, 3])
>>>> Note that d_2 is not sorted, but the results are equal in the sense of function identical(), meaning they are *exactly* the same. Why shouldn't they?
>>>> Hope this helps,
>>>> Rui Barradas
>>>> ?s 17:06 de 05/09/19, Boo G. escreveu:
>>>>> Hello,
>>>>> 
>>>>> I am trying to perform a Kolmogorov?Smirnov test to assess the difference between a distribution and samples drawn proportionally to size of different sizes. I managed to compute the Kolmogorov?Smirnov distance but I am lost with the p-value. I have looked into the ks.test function unsuccessfully. Can anyone help me with computing p-values for a two-tailed test?
>>>>> 
>>>>> Below a simplified version of my code.
>>>>> 
>>>>> Thanks in advance.
>>>>> Gianluca
>>>>> 
>>>>> 
>>>>> library(spatstat)
>>>>> 
>>>>> #reference distribution
>>>>> d_1 <- sort(rpois(1000, 500))
>>>>> p_1 <- d_1/sum(d_1)
>>>>> m_1 <- data.frame(d_1, p_1)
>>>>> 
>>>>> #data frame to store the values of the siumation
>>>>> d_stat <- data.frame(1:1000, NA, NA)
>>>>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>>>>> 
>>>>> #simulation
>>>>> for (i in 1:1000) {
>>>>> #sample from the reference distribution
>>>>> m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>>>> m_2 <-m_2[order(m_2$d_1),]
>>>>> d_2 <- m_2$d_1
>>>>> p_2 <- m_2$p_1
>>>>> 
>>>>> #weighted ecdf for the reference distribution and the sample
>>>>> f_d_1 <- ewcdf(d_1, normalise=F)
>>>>> f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>>>> 
>>>>> #kolmogorov-smirnov distance
>>>>> d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
>>>>> }
>>>>> 
>>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7Cfebe94a441914aa58a9908d732363a52%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=mZZ05M0Qrjy8EelRpDiKpozWtLbF2kSGG%2BjzlAYyzf4%3D&amp;reserved=0
>>>>> PLEASE do read the posting guidehttps://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org>mailing list -- To UNSUBSCRIBE and more, see
>>>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7Cfebe94a441914aa58a9908d732363a52%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=mZZ05M0Qrjy8EelRpDiKpozWtLbF2kSGG%2BjzlAYyzf4%3D&amp;reserved=0
>>>> PLEASE do read the posting guidehttps://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
>>>> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep  6 07:19:41 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 6 Sep 2019 06:19:41 +0100
Subject: [R] =?utf-8?q?P-values_Kolmogorov=E2=80=93Smirnov_test?=
In-Reply-To: <0FF57EE7-8848-436D-A752-1ACF7E336A51@soton.ac.uk>
References: <94161030-0FC7-43BA-A280-8528207E64C8@soton.ac.uk>
 <900d29b4-fa56-6352-49b1-65238b8fc0e1@sapo.pt>
 <9a8b56cc-8b7f-7f38-023b-80e5c3dcb969@sapo.pt>
 <FFE6EE50-7752-4A06-9588-E652EDA1CC95@soton.ac.uk>
 <cee98204-19de-397a-d81c-585a31462bb7@sapo.pt>
 <0FF57EE7-8848-436D-A752-1ACF7E336A51@soton.ac.uk>
Message-ID: <108d19f5-e04c-f3a7-faa5-3adf2e1e977a@sapo.pt>

Hello,

Yesterday wasn't one of my days.
The main problem I'm seeing is that the KS statistic is meant for 
continuous data and you have counts data assumed to follow a Poisson 
distribution. This might explain the nonsense results you are getting 
from ks.test.

Have you considered a chi-squared GOF test?

Hope this helps,

Rui Barradas

?s 20:51 de 05/09/19, Boo G. escreveu:
> Hello and thanks for your patience.
> 
> As far as I understand, the paper of Marsiglia and colleagues refers to CDF samples (i.e. from a hypothetical distribution ? e.g. a Poisson), while I have an ECDF sample (i.e. (pseudo-)observed data ? e.g. rpois(1000, 500). In my study, I am actually comparing the statistical distribution of people per hectares in a region (~50,000 observations) with samples from that distribution.
> 
> Agree that we cannot consider at p-values for low sample size. Still, somewhere above 100, I expect to see p-values between 0 and 0.05 (rejecting the fact that the sample comes from the reference distribution). Ideally, I would try the procedure suggested by Marsiglia to compute p-values but this is far beyond my coding skills.
> 
> 
> 
> 
>> On 5 Sep 2019, at 21:21, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> Inline.
>>
>> ?s 20:09 de 05/09/19, Boo G. escreveu:
>>> Hello again.
>>> I have tied this before but I see two problems:
>>> 1) According to the documentation I could read (including the ks.test code), the ks statistic would be max(abs(x - y)) and if you plot this for very low sample sizes you can actually see that this make sense. The results of ks.test(x, y) yields very different values.
>>
>> The problem is that the distribution of Dn is very difficult to compute. From the reference [1] in the help page ?ks.test:
>>
>> 	Kolmogorov's goodness-of-fit measure, Dn , for a sample CDF has consistently been set aside for methods such as the D+n or D-n of Smirnov, primarily, it seems, because of the difficulty of computing the distribution of Dn . As far as we know, no easy way to compute that distribution has ever been provided in the 70+ years since Kolmogorov's fundamental paper. We provide one here, a C procedure that provides Pr(Dn < d) with 13-15 digit accuracy for n ranging from 2 to at least 16000.
>>
>>
>> That is why I used ks.test and its Dn and p-values. Note that n >= 2, size = 1 is not covered (p-value == 1).
>>
>> Also, the p-values distribution seem to become closer to a uniform with increasing sizes. Try
>>
>> hist(d_stat[801:1000, 3])
>>
>>
>> [1]https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv008i18&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7Cfebe94a441914aa58a9908d732363a52%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=JBHkkXn6G4oLQZCV7HoqBLO4a3sMixTa16kOVFwXPlY%3D&amp;reserved=0
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>> 2) Also in this case the p-values don?t make much sense, according to my previous interpretation.
>>> Again, I could be wrong in my interpretation.
>>>> On 5 Sep 2019, at 20:46, Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>>>>
>>>> Hello,
>>>>
>>>> I'm sorry, but apparently I missed the point of your problem.
>>>> Please do not take my previous answer seriously.
>>>>
>>>> But you can use ks.test, just in a different way than what I wrote previously.
>>>>
>>>> Corrected code:
>>>>
>>>>
>>>> #simulation
>>>> for (i in 1:1000) {
>>>>   #sample from the reference distribution
>>>>   m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>>>   m_2 <-m_2[order(m_2$d_1),]
>>>>   d_2 <- m_2$d_1
>>>>   p_2 <- m_2$p_1
>>>>
>>>>   #weighted ecdf for the reference distribution and the sample
>>>>   f_d_1 <- ewcdf(d_1, normalise=F)
>>>>   f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>>>
>>>>   #kolmogorov-smirnov distance
>>>>   x <- f_d_1(d_2)
>>>>   y <- f_d_2(d_2)
>>>>   ht <- ks.test(x, y)
>>>>   d_stat[i, 2] <- ht$statistic
>>>>   d_stat[i, 3] <- ht$p.value
>>>> }
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> ?s 19:29 de 05/09/19, Rui Barradas escreveu:
>>>>> Hello,
>>>>> I don't have the algorithms at hand but the KS statistic calculation is more complicated than your max/abs difference.
>>>>> Anyway, why not use ks.test? it's not that difficult:
>>>>> set.seed(1234)
>>>>> #reference distribution
>>>>> d_1 <- sort(rpois(1000, 500))
>>>>> p_1 <- d_1/sum(d_1)
>>>>> m_1 <- data.frame(d_1, p_1)
>>>>> #data frame to store the values of the simulation
>>>>> d_stat <- data.frame(1:1000, NA, NA)
>>>>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>>>>> #simulation
>>>>> for (i in 1:1000) {
>>>>> #sample from the reference distribution
>>>>> m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>>>> d_2 <- m_2$d_1
>>>>> ht <- ks.test(d_1, d_2)
>>>>> #kolmogorov-smirnov distance
>>>>> d_stat[i, 2] <- ht$statistic
>>>>> d_stat[i, 3] <- ht$p.value
>>>>> }
>>>>> hist(d_stat[, 2])
>>>>> hist(d_stat[, 3])
>>>>> Note that d_2 is not sorted, but the results are equal in the sense of function identical(), meaning they are *exactly* the same. Why shouldn't they?
>>>>> Hope this helps,
>>>>> Rui Barradas
>>>>> ?s 17:06 de 05/09/19, Boo G. escreveu:
>>>>>> Hello,
>>>>>>
>>>>>> I am trying to perform a Kolmogorov?Smirnov test to assess the difference between a distribution and samples drawn proportionally to size of different sizes. I managed to compute the Kolmogorov?Smirnov distance but I am lost with the p-value. I have looked into the ks.test function unsuccessfully. Can anyone help me with computing p-values for a two-tailed test?
>>>>>>
>>>>>> Below a simplified version of my code.
>>>>>>
>>>>>> Thanks in advance.
>>>>>> Gianluca
>>>>>>
>>>>>>
>>>>>> library(spatstat)
>>>>>>
>>>>>> #reference distribution
>>>>>> d_1 <- sort(rpois(1000, 500))
>>>>>> p_1 <- d_1/sum(d_1)
>>>>>> m_1 <- data.frame(d_1, p_1)
>>>>>>
>>>>>> #data frame to store the values of the siumation
>>>>>> d_stat <- data.frame(1:1000, NA, NA)
>>>>>> names(d_stat) <- c("sample_size", "ks_distance", "p_value")
>>>>>>
>>>>>> #simulation
>>>>>> for (i in 1:1000) {
>>>>>> #sample from the reference distribution
>>>>>> m_2 <-m_1[(sample(nrow(m_1), size=i, prob=p_1, replace=F)),]
>>>>>> m_2 <-m_2[order(m_2$d_1),]
>>>>>> d_2 <- m_2$d_1
>>>>>> p_2 <- m_2$p_1
>>>>>>
>>>>>> #weighted ecdf for the reference distribution and the sample
>>>>>> f_d_1 <- ewcdf(d_1, normalise=F)
>>>>>> f_d_2 <- ewcdf(d_2, 1/p_2, normalise=F, adjust=1/length(d_2))
>>>>>>
>>>>>> #kolmogorov-smirnov distance
>>>>>> d_stat[i,2] <- max(abs(f_d_1(d_2) - f_d_2(d_2)))
>>>>>> }
>>>>>>
>>>>>>
>>>>>>      [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7Cfebe94a441914aa58a9908d732363a52%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=mZZ05M0Qrjy8EelRpDiKpozWtLbF2kSGG%2BjzlAYyzf4%3D&amp;reserved=0
>>>>>> PLEASE do read the posting guidehttps://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org <mailto:R-help at r-project.org>mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7Cfebe94a441914aa58a9908d732363a52%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=mZZ05M0Qrjy8EelRpDiKpozWtLbF2kSGG%2BjzlAYyzf4%3D&amp;reserved=0
>>>>> PLEASE do read the posting guidehttps://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&amp;data=01%7C01%7Cgianluca.boo%40soton.ac.uk%7C4b4a253a1edc4960297f08d732316627%7C4a5378f929f44d3ebe89669d03ada9d8%7C0&amp;sdata=YKZNBeGme6V9QGyV2%2F150H6rZnLy9bX7xly%2BQEf6O14%3D&amp;reserved=0
>>>>> and provide commented, minimal, self-contained, reproducible code.
>


From m@dhupu@u|ur| @end|ng |rom gm@||@com  Fri Sep  6 07:30:02 2019
From: m@dhupu@u|ur| @end|ng |rom gm@||@com (pusuluri madhu)
Date: Fri, 6 Sep 2019 11:00:02 +0530
Subject: [R] (no subject)
Message-ID: <CAALKAO8QEb61YnZLS2hVhxM6K_EpRyh8XtnSdecqDmgH-v=FOg@mail.gmail.com>

Please unsubscribe me

-- 

*Madhu Pusuluri, Ph D*
*Visiting Scientist*
*Genomics & Trait discovery- Genetic Gains*

*International Crops Research Institute for the Semi-Arid Tropics (ICRISAT)*

*Patancheru, Hyderabad,  Telangana 502324, INDIA.*

*E-mail: **m.pusuluri at cgiar.org <m.pusuluri at cgiar.org>**;
madhupusuluri at gmail.com
<https://outlook.office.com/owa/madhupusuluri at gmail.com>*

*Tel: +91 9912241982.*

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep  6 10:55:39 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 6 Sep 2019 20:55:39 +1200
Subject: [R] [FORGED]  (no subject)
In-Reply-To: <CAALKAO8QEb61YnZLS2hVhxM6K_EpRyh8XtnSdecqDmgH-v=FOg@mail.gmail.com>
References: <CAALKAO8QEb61YnZLS2hVhxM6K_EpRyh8XtnSdecqDmgH-v=FOg@mail.gmail.com>
Message-ID: <d1074540-0162-2379-c62e-f58542864b77@auckland.ac.nz>


On 6/09/19 5:30 PM, pusuluri madhu wrote:

> Please unsubscribe me

Go unsubscribe yourself! :-)

See the footer at the bottom of every r-help posting:

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help

HTH

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From p@u|@john@ton @end|ng |rom m@nche@ter@@c@uk  Fri Sep  6 11:57:57 2019
From: p@u|@john@ton @end|ng |rom m@nche@ter@@c@uk (Paul Johnston)
Date: Fri, 6 Sep 2019 09:57:57 +0000
Subject: [R] Help with fmodel in statisticalModeling package
Message-ID: <EE85AFC56BE9E84EB86F7739169F1BD6E8C67238@MBXP15.ds.man.ac.uk>

Hi

Anyone able to help me with this.
I'm doing a datacamp course and the effect of adding a "bogus variable" to a linear model.
I make a model and initially fmodel works fine.
When I have a second model which uses this "bogus variable" it complains about the type of this variable.

The code below works fine.

library(statisticalModeling)
library(mosaicData)
print(names(CPS85))

# Add bogus column to CPS85 (don't change)
CPS85$bogus <- rnorm(nrow(CPS85)) > 0
cat ("typeof(CPS88$bogus) is:", typeof(CPS85$bogus), "\n")
# Make the base model
base_model <- lm(wage ~ educ + sector + sex, data = CPS85)
print(fmodel(base_model))

# Make the bogus augmented model
aug_model <- lm(wage ~ educ + sector +sex  + bogus, data = CPS85)
#print(fmodel((aug_model)))

# Find the MSE of the base model
mean_base <- mean((CPS85$wage - predict(base_model, newdata = CPS85)) ^ 2)

# Find the MSE of the augmented model
mean_aug <- mean((CPS85$wage - predict(aug_model, newdata = CPS85)) ^ 2)
cat("Mean Square Error of base", mean_base,"\n")
cat("Mean Square Error of aug", mean_aug)

However if I uncomment #print(fmodel((aug_model)))
I get

Error: variable 'bogus' was fitted with type "logical" but type "character" was supplied

Any pointers gratefully accepted

Cheer Paul J


Paul Johnston
Field Support (Slough House)
University of Manchester
Room B29
Pariser  Building
Tel 07826 875504
IOSH Managing Safely
Cert No.: 506572



	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Fri Sep  6 15:04:06 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 6 Sep 2019 15:04:06 +0200
Subject: [R] Help with fmodel in statisticalModeling package
In-Reply-To: <EE85AFC56BE9E84EB86F7739169F1BD6E8C67238@MBXP15.ds.man.ac.uk>
References: <EE85AFC56BE9E84EB86F7739169F1BD6E8C67238@MBXP15.ds.man.ac.uk>
Message-ID: <01EB923D-8245-4361-9A98-54A5380DC38C@gmail.com>

I have no clue about the internals of fmodel() (and no real intention of getting one...), but pragmatically and to avoid getting sidetracked, how about converting the bogus variable to zero-one:

CPS85$bogus <- as.numeric(rnorm(nrow(CPS85)) > 0)

-pd

> On 6 Sep 2019, at 11:57 , Paul Johnston <paul.johnston at manchester.ac.uk> wrote:
> 
> Hi
> 
> Anyone able to help me with this.
> I'm doing a datacamp course and the effect of adding a "bogus variable" to a linear model.
> I make a model and initially fmodel works fine.
> When I have a second model which uses this "bogus variable" it complains about the type of this variable.
> 
> The code below works fine.
> 
> library(statisticalModeling)
> library(mosaicData)
> print(names(CPS85))
> 
> # Add bogus column to CPS85 (don't change)
> CPS85$bogus <- rnorm(nrow(CPS85)) > 0
> cat ("typeof(CPS88$bogus) is:", typeof(CPS85$bogus), "\n")
> # Make the base model
> base_model <- lm(wage ~ educ + sector + sex, data = CPS85)
> print(fmodel(base_model))
> 
> # Make the bogus augmented model
> aug_model <- lm(wage ~ educ + sector +sex  + bogus, data = CPS85)
> #print(fmodel((aug_model)))
> 
> # Find the MSE of the base model
> mean_base <- mean((CPS85$wage - predict(base_model, newdata = CPS85)) ^ 2)
> 
> # Find the MSE of the augmented model
> mean_aug <- mean((CPS85$wage - predict(aug_model, newdata = CPS85)) ^ 2)
> cat("Mean Square Error of base", mean_base,"\n")
> cat("Mean Square Error of aug", mean_aug)
> 
> However if I uncomment #print(fmodel((aug_model)))
> I get
> 
> Error: variable 'bogus' was fitted with type "logical" but type "character" was supplied
> 
> Any pointers gratefully accepted
> 
> Cheer Paul J
> 
> 
> Paul Johnston
> Field Support (Slough House)
> University of Manchester
> Room B29
> Pariser  Building
> Tel 07826 875504
> IOSH Managing Safely
> Cert No.: 506572
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From p@u|@john@ton @end|ng |rom m@nche@ter@@c@uk  Fri Sep  6 15:11:01 2019
From: p@u|@john@ton @end|ng |rom m@nche@ter@@c@uk (Paul Johnston)
Date: Fri, 6 Sep 2019 13:11:01 +0000
Subject: [R] Help with fmodel in statisticalModeling package
In-Reply-To: <01EB923D-8245-4361-9A98-54A5380DC38C@gmail.com>
References: <EE85AFC56BE9E84EB86F7739169F1BD6E8C67238@MBXP15.ds.man.ac.uk>
 <01EB923D-8245-4361-9A98-54A5380DC38C@gmail.com>
Message-ID: <EE85AFC56BE9E84EB86F7739169F1BD6E8C672FB@MBXP15.ds.man.ac.uk>

Many thanks, as you suggest that does allow the program to run.
As does (no pun intended) as.character()
If anyone knows what causes this I would be still keen to know.

Cheers Paul

-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: 06 September 2019 14:04
To: Paul Johnston <paul.johnston at manchester.ac.uk>
Cc: R-help at r-project.org
Subject: Re: [R] Help with fmodel in statisticalModeling package

I have no clue about the internals of fmodel() (and no real intention of getting one...), but pragmatically and to avoid getting sidetracked, how about converting the bogus variable to zero-one:

CPS85$bogus <- as.numeric(rnorm(nrow(CPS85)) > 0)

-pd

> On 6 Sep 2019, at 11:57 , Paul Johnston <paul.johnston at manchester.ac.uk> wrote:
> 
> Hi
> 
> Anyone able to help me with this.
> I'm doing a datacamp course and the effect of adding a "bogus variable" to a linear model.
> I make a model and initially fmodel works fine.
> When I have a second model which uses this "bogus variable" it complains about the type of this variable.
> 
> The code below works fine.
> 
> library(statisticalModeling)
> library(mosaicData)
> print(names(CPS85))
> 
> # Add bogus column to CPS85 (don't change) CPS85$bogus <- 
> rnorm(nrow(CPS85)) > 0 cat ("typeof(CPS88$bogus) is:", 
> typeof(CPS85$bogus), "\n") # Make the base model base_model <- lm(wage 
> ~ educ + sector + sex, data = CPS85)
> print(fmodel(base_model))
> 
> # Make the bogus augmented model
> aug_model <- lm(wage ~ educ + sector +sex  + bogus, data = CPS85)
> #print(fmodel((aug_model)))
> 
> # Find the MSE of the base model
> mean_base <- mean((CPS85$wage - predict(base_model, newdata = CPS85)) 
> ^ 2)
> 
> # Find the MSE of the augmented model
> mean_aug <- mean((CPS85$wage - predict(aug_model, newdata = CPS85)) ^ 
> 2) cat("Mean Square Error of base", mean_base,"\n") cat("Mean Square 
> Error of aug", mean_aug)
> 
> However if I uncomment #print(fmodel((aug_model))) I get
> 
> Error: variable 'bogus' was fitted with type "logical" but type 
> "character" was supplied
> 
> Any pointers gratefully accepted
> 
> Cheer Paul J
> 
> 
> Paul Johnston
> Field Support (Slough House)
> University of Manchester
> Room B29
> Pariser  Building
> Tel 07826 875504
> IOSH Managing Safely
> Cert No.: 506572
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j|ox @end|ng |rom mcm@@ter@c@  Fri Sep  6 15:34:35 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 6 Sep 2019 13:34:35 +0000
Subject: [R] Help Installing Rtools
In-Reply-To: <19299_1567691055_x85Di3vZ011626_BL0PR05MB481896DCAEB26A5CAC79E844CABB0@BL0PR05MB4818.namprd05.prod.outlook.com>
References: <19299_1567691055_x85Di3vZ011626_BL0PR05MB481896DCAEB26A5CAC79E844CABB0@BL0PR05MB4818.namprd05.prod.outlook.com>
Message-ID: <2815996D-7623-4D67-A2A2-B69FBB952986@mcmaster.ca>

Dear Harold,

Have you checked that the Rtools directory is on the Windows path? If not, you could try rerunning the Rtools installer and allow it to modify the path, or simply add the Rtools directory to the path yourself.

I hope that this helps,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Sep 5, 2019, at 9:43 AM, Doran, Harold <HDoran at air.org> wrote:
> 
> I've done the following steps, but am unable to source in the Cpp files. Details of my session and sessionInfo are below. Am I missing a package, or a critical step? I found one answer regarding the 'make" error on stackoverflow suggesting the problem is resolved by grabbing the more recent version of Rtools, which I have done.
> 
> Thanks.
> 
>> install.packages('installr')
>> library(installr)
>> install.Rtools()
> 
> This step installed Rtools35.exe correctly as far as I can tell. Then,
> 
>> library(devtools)
> Loading required package: usethis
>> library(Rcpp)
>> sourceCpp("test.cpp")
> Warning message:
> In system(cmd) : 'make' not found
> Error in sourceCpp("test.cpp") :
>  Error 1 occurred building shared library.
> 
> WARNING: The tools required to build C++ code for R were not found.
> 
> Please download and install the appropriate version of Rtools:
> 
> http://cran.r-project.org/bin/windows/Rtools/
> 
>> sessionInfo()
> R version 3.6.1 (2019-07-05)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18362)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] Rcpp_1.0.2      devtools_2.1.0  usethis_1.5.1   htmltab_0.7.1
> [5] installr_0.22.0 stringr_1.4.0
> 
> loaded via a namespace (and not attached):
> [1] magrittr_1.5      pkgload_1.0.2     R6_2.4.0          rlang_0.3.4
> [5] httr_1.4.1        tools_3.6.1       pkgbuild_1.0.5    sessioninfo_1.1.1
> [9] cli_1.1.0         withr_2.1.2       remotes_2.1.0     rprojroot_1.3-2
> [13] assertthat_0.2.1  digest_0.6.19     crayon_1.3.4      processx_3.4.1
> [17] callr_3.3.1       fs_1.3.1          ps_1.3.0          testthat_2.2.1
> [21] curl_4.0          memoise_1.1.0     glue_1.3.1        stringi_1.4.3
> [25] compiler_3.6.1    backports_1.1.4   desc_1.2.0        prettyunits_1.0.2
> [29] XML_3.98-1.20
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Go|denS @end|ng |rom NJHe@|th@org  Fri Sep  6 17:50:45 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Fri, 6 Sep 2019 15:50:45 +0000
Subject: [R] [R-devel] Source Code for function
Message-ID: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>

Hi all,

I have been attempting to access the source code for the keyword ?function? to better understand how it assigns and stores logical inputs, like in the subset() [base] function. Does anyone know how I can access the source code for this?

For example, if I have
norm <- function(x){
      sqrt(x%*%x))
}
I am looking for the source code for the ?function? portion, highlighted in red.

Thank you for your time and assistance,
Shelby Golden
Lab Researcher Technician
Dr. Russell Bowler?s Lab
Department of Medicine
National Jewish Health in Denver, CO
Phone: (303) 270-2598

NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep  6 18:44:41 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 6 Sep 2019 09:44:41 -0700
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
Message-ID: <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>

1. This is a plain text list; all html is stripped. So there is no red
highlighting.

2. There is no "source code" for "function" -- it is a reserved keyword.
Or are you looking for R's formal grammar -- e.g. how it parses input to
determine correct syntax?



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org> wrote:

> Hi all,
>
> I have been attempting to access the source code for the keyword
> ?function? to better understand how it assigns and stores logical inputs,
> like in the subset() [base] function. Does anyone know how I can access the
> source code for this?
>
> For example, if I have
> norm <- function(x){
>       sqrt(x%*%x))
> }
> I am looking for the source code for the ?function? portion, highlighted
> in red.
>
> Thank you for your time and assistance,
> Shelby Golden
> Lab Researcher Technician
> Dr. Russell Bowler?s Lab
> Department of Medicine
> National Jewish Health in Denver, CO
> Phone: (303) 270-2598
>
> NOTICE: This email message is for the sole use of the intended
> recipient(s) and may contain confidential and privileged information. Any
> unauthorized review, use, disclosure or distribution is prohibited. If you
> are not the intended recipient, please contact the sender by reply email
> and destroy all copies of the original message.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Go|denS @end|ng |rom NJHe@|th@org  Fri Sep  6 18:48:09 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Fri, 6 Sep 2019 16:48:09 +0000
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
Message-ID: <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>

Hello Bert,

Thank you for the reply and your clarifications. Yes, it might be helpful to look into R?s formal grammar to see how ?function? parses input to delegate correct syntax. Is that accessible online?

Thank you,
Shelby


From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Friday, September 6, 2019 at 10:44 AM
To: "Golden, Shelby" <GoldenS at NJHealth.org>
Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <GILLENWATERL at NJHEALTH.ORG>
Subject: Re: [R] [R-devel] Source Code for function

1. This is a plain text list; all html is stripped. So there is no red highlighting.

2. There is no "source code" for "function" -- it is a reserved keyword.
Or are you looking for R's formal grammar -- e.g. how it parses input to determine correct syntax?



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>> wrote:
Hi all,

I have been attempting to access the source code for the keyword ?function? to better understand how it assigns and stores logical inputs, like in the subset() [base] function. Does anyone know how I can access the source code for this?

For example, if I have
norm <- function(x){
      sqrt(x%*%x))
}
I am looking for the source code for the ?function? portion, highlighted in red.

Thank you for your time and assistance,
Shelby Golden
Lab Researcher Technician
Dr. Russell Bowler?s Lab
Department of Medicine
National Jewish Health in Denver, CO
Phone: (303) 270-2598

NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Fri Sep  6 19:10:01 2019
From: @zwj|08 @end|ng |rom gm@||@com (Wang Jiefei)
Date: Fri, 6 Sep 2019 13:10:01 -0400
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
Message-ID: <CAGiFhPPR4+UXKU8nnz5N=SjVykD4EKjSi=gO7xr5nRjfdyZYDw@mail.gmail.com>

Hi Shelby,

Not quite sure what you are trying to do. Mine might be off-topic but have
you seen this document?

http://adv-r.had.co.nz/Functions.html#function-components

It illustrates the components of a function.

Best,
Jiefei

On Fri, Sep 6, 2019 at 11:52 AM Golden, Shelby <GoldenS at njhealth.org> wrote:

> Hi all,
>
> I have been attempting to access the source code for the keyword
> ?function? to better understand how it assigns and stores logical inputs,
> like in the subset() [base] function. Does anyone know how I can access the
> source code for this?
>
> For example, if I have
> norm <- function(x){
>       sqrt(x%*%x))
> }
> I am looking for the source code for the ?function? portion, highlighted
> in red.
>
> Thank you for your time and assistance,
> Shelby Golden
> Lab Researcher Technician
> Dr. Russell Bowler?s Lab
> Department of Medicine
> National Jewish Health in Denver, CO
> Phone: (303) 270-2598
>
> NOTICE: This email message is for the sole use of the intended
> recipient(s) and may contain confidential and privileged information. Any
> unauthorized review, use, disclosure or distribution is prohibited. If you
> are not the intended recipient, please contact the sender by reply email
> and destroy all copies of the original message.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Fri Sep  6 19:14:10 2019
From: @zwj|08 @end|ng |rom gm@||@com (Wang Jiefei)
Date: Fri, 6 Sep 2019 13:14:10 -0400
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
Message-ID: <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>

If you are looking for an R code parser, I think the `parse` and `eval`
function might be a good start point. See the example below.

> parse(text="function(x)message(x)")
expression(function(x)message(x))
> eval(parse(text="function(x)message(x)"))
function(x)message(x)

Best,
Jiefei

On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org> wrote:

> Hello Bert,
>
> Thank you for the reply and your clarifications. Yes, it might be helpful
> to look into R?s formal grammar to see how ?function? parses input to
> delegate correct syntax. Is that accessible online?
>
> Thank you,
> Shelby
>
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Date: Friday, September 6, 2019 at 10:44 AM
> To: "Golden, Shelby" <GoldenS at NJHealth.org>
> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
> GILLENWATERL at NJHEALTH.ORG>
> Subject: Re: [R] [R-devel] Source Code for function
>
> 1. This is a plain text list; all html is stripped. So there is no red
> highlighting.
>
> 2. There is no "source code" for "function" -- it is a reserved keyword.
> Or are you looking for R's formal grammar -- e.g. how it parses input to
> determine correct syntax?
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
> <mailto:GoldenS at njhealth.org>> wrote:
> Hi all,
>
> I have been attempting to access the source code for the keyword
> ?function? to better understand how it assigns and stores logical inputs,
> like in the subset() [base] function. Does anyone know how I can access the
> source code for this?
>
> For example, if I have
> norm <- function(x){
>       sqrt(x%*%x))
> }
> I am looking for the source code for the ?function? portion, highlighted
> in red.
>
> Thank you for your time and assistance,
> Shelby Golden
> Lab Researcher Technician
> Dr. Russell Bowler?s Lab
> Department of Medicine
> National Jewish Health in Denver, CO
> Phone: (303) 270-2598
>
> NOTICE: This email message is for the sole use of the intended
> recipient(s) and may contain confidential and privileged information. Any
> unauthorized review, use, disclosure or distribution is prohibited. If you
> are not the intended recipient, please contact the sender by reply email
> and destroy all copies of the original message.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<
> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
> >
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html<
> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
> >
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep  6 20:30:02 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 6 Sep 2019 11:30:02 -0700
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
Message-ID: <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>

The following may be of use (it gives the parse tree of the text):

> z <- as.list(parse(text = "function(x)x %*% x"))
> z[[1]]
function(x) x %*% x
> z[[c(1,1)]]
`function`
> z[[c(1,2)]]
$x
> z[[c(1,3)]]
x %*% x
> z[[c(1,3,1)]]
`%*%`
> z[[c(1,3,2)]]
x
> z[[c(1,3,3)]]
x


Bert Gunter



On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com> wrote:

> If you are looking for an R code parser, I think the `parse` and `eval`
> function might be a good start point. See the example below.
>
> > parse(text="function(x)message(x)")
> expression(function(x)message(x))
> > eval(parse(text="function(x)message(x)"))
> function(x)message(x)
>
> Best,
> Jiefei
>
> On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org>
> wrote:
>
>> Hello Bert,
>>
>> Thank you for the reply and your clarifications. Yes, it might be helpful
>> to look into R?s formal grammar to see how ?function? parses input to
>> delegate correct syntax. Is that accessible online?
>>
>> Thank you,
>> Shelby
>>
>>
>> From: Bert Gunter <bgunter.4567 at gmail.com>
>> Date: Friday, September 6, 2019 at 10:44 AM
>> To: "Golden, Shelby" <GoldenS at NJHealth.org>
>> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
>> GILLENWATERL at NJHEALTH.ORG>
>> Subject: Re: [R] [R-devel] Source Code for function
>>
>> 1. This is a plain text list; all html is stripped. So there is no red
>> highlighting.
>>
>> 2. There is no "source code" for "function" -- it is a reserved keyword.
>> Or are you looking for R's formal grammar -- e.g. how it parses input to
>> determine correct syntax?
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
>> <mailto:GoldenS at njhealth.org>> wrote:
>> Hi all,
>>
>> I have been attempting to access the source code for the keyword
>> ?function? to better understand how it assigns and stores logical inputs,
>> like in the subset() [base] function. Does anyone know how I can access the
>> source code for this?
>>
>> For example, if I have
>> norm <- function(x){
>>       sqrt(x%*%x))
>> }
>> I am looking for the source code for the ?function? portion, highlighted
>> in red.
>>
>> Thank you for your time and assistance,
>> Shelby Golden
>> Lab Researcher Technician
>> Dr. Russell Bowler?s Lab
>> Department of Medicine
>> National Jewish Health in Denver, CO
>> Phone: (303) 270-2598
>>
>> NOTICE: This email message is for the sole use of the intended
>> recipient(s) and may contain confidential and privileged information. Any
>> unauthorized review, use, disclosure or distribution is prohibited. If you
>> are not the intended recipient, please contact the sender by reply email
>> and destroy all copies of the original message.
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help<
>> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
>> >
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html<
>> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
>> >
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Sep  6 21:00:06 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 6 Sep 2019 15:00:06 -0400
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
Message-ID: <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>

You might also want to look at the codetools package, for example the
showTree function " Prints a Lisp-style representation of R
expression."

> library(codetools)

> showTree(quote(x %*% x))
(%*% x x)
> showTree(quote(a+b))
(+ a b)
> showTree(quote(y ~ a+b))
(~ y (+ a b))

On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> The following may be of use (it gives the parse tree of the text):
>
> > z <- as.list(parse(text = "function(x)x %*% x"))
> > z[[1]]
> function(x) x %*% x
> > z[[c(1,1)]]
> `function`
> > z[[c(1,2)]]
> $x
> > z[[c(1,3)]]
> x %*% x
> > z[[c(1,3,1)]]
> `%*%`
> > z[[c(1,3,2)]]
> x
> > z[[c(1,3,3)]]
> x
>
>
> Bert Gunter
>
>
>
> On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com> wrote:
>
> > If you are looking for an R code parser, I think the `parse` and `eval`
> > function might be a good start point. See the example below.
> >
> > > parse(text="function(x)message(x)")
> > expression(function(x)message(x))
> > > eval(parse(text="function(x)message(x)"))
> > function(x)message(x)
> >
> > Best,
> > Jiefei
> >
> > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org>
> > wrote:
> >
> >> Hello Bert,
> >>
> >> Thank you for the reply and your clarifications. Yes, it might be helpful
> >> to look into R?s formal grammar to see how ?function? parses input to
> >> delegate correct syntax. Is that accessible online?
> >>
> >> Thank you,
> >> Shelby
> >>
> >>
> >> From: Bert Gunter <bgunter.4567 at gmail.com>
> >> Date: Friday, September 6, 2019 at 10:44 AM
> >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
> >> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
> >> GILLENWATERL at NJHEALTH.ORG>
> >> Subject: Re: [R] [R-devel] Source Code for function
> >>
> >> 1. This is a plain text list; all html is stripped. So there is no red
> >> highlighting.
> >>
> >> 2. There is no "source code" for "function" -- it is a reserved keyword.
> >> Or are you looking for R's formal grammar -- e.g. how it parses input to
> >> determine correct syntax?
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
> >> <mailto:GoldenS at njhealth.org>> wrote:
> >> Hi all,
> >>
> >> I have been attempting to access the source code for the keyword
> >> ?function? to better understand how it assigns and stores logical inputs,
> >> like in the subset() [base] function. Does anyone know how I can access the
> >> source code for this?
> >>
> >> For example, if I have
> >> norm <- function(x){
> >>       sqrt(x%*%x))
> >> }
> >> I am looking for the source code for the ?function? portion, highlighted
> >> in red.
> >>
> >> Thank you for your time and assistance,
> >> Shelby Golden
> >> Lab Researcher Technician
> >> Dr. Russell Bowler?s Lab
> >> Department of Medicine
> >> National Jewish Health in Denver, CO
> >> Phone: (303) 270-2598
> >>
> >> NOTICE: This email message is for the sole use of the intended
> >> recipient(s) and may contain confidential and privileged information. Any
> >> unauthorized review, use, disclosure or distribution is prohibited. If you
> >> are not the intended recipient, please contact the sender by reply email
> >> and destroy all copies of the original message.
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> >> UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help<
> >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
> >> >
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html<
> >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
> >> >
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Go|denS @end|ng |rom NJHe@|th@org  Fri Sep  6 22:07:02 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Fri, 6 Sep 2019 20:07:02 +0000
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
Message-ID: <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>

Thank you all for your reply. I should clarify, that I am looking to understand why the keyword function can take a logical argument (eg: x<4) and use that later inside the function's definition for logical evaluations.

Consider this example, which is a simplification of getAnywhere(subset.data.frame):
x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
test <- function(x, logic){
	e <- substitute(logic)
	r <- eval(e, x, parent.frame())
	r[r]
}


Shelby
 

?On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <r-help-bounces at r-project.org on behalf of rmh at temple.edu> wrote:

    You might also want to look at the codetools package, for example the
    showTree function " Prints a Lisp-style representation of R
    expression."
    
    > library(codetools)
    
    > showTree(quote(x %*% x))
    (%*% x x)
    > showTree(quote(a+b))
    (+ a b)
    > showTree(quote(y ~ a+b))
    (~ y (+ a b))
    
    On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >
    > The following may be of use (it gives the parse tree of the text):
    >
    > > z <- as.list(parse(text = "function(x)x %*% x"))
    > > z[[1]]
    > function(x) x %*% x
    > > z[[c(1,1)]]
    > `function`
    > > z[[c(1,2)]]
    > $x
    > > z[[c(1,3)]]
    > x %*% x
    > > z[[c(1,3,1)]]
    > `%*%`
    > > z[[c(1,3,2)]]
    > x
    > > z[[c(1,3,3)]]
    > x
    >
    >
    > Bert Gunter
    >
    >
    >
    > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com> wrote:
    >
    > > If you are looking for an R code parser, I think the `parse` and `eval`
    > > function might be a good start point. See the example below.
    > >
    > > > parse(text="function(x)message(x)")
    > > expression(function(x)message(x))
    > > > eval(parse(text="function(x)message(x)"))
    > > function(x)message(x)
    > >
    > > Best,
    > > Jiefei
    > >
    > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org>
    > > wrote:
    > >
    > >> Hello Bert,
    > >>
    > >> Thank you for the reply and your clarifications. Yes, it might be helpful
    > >> to look into R?s formal grammar to see how ?function? parses input to
    > >> delegate correct syntax. Is that accessible online?
    > >>
    > >> Thank you,
    > >> Shelby
    > >>
    > >>
    > >> From: Bert Gunter <bgunter.4567 at gmail.com>
    > >> Date: Friday, September 6, 2019 at 10:44 AM
    > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
    > >> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
    > >> GILLENWATERL at NJHEALTH.ORG>
    > >> Subject: Re: [R] [R-devel] Source Code for function
    > >>
    > >> 1. This is a plain text list; all html is stripped. So there is no red
    > >> highlighting.
    > >>
    > >> 2. There is no "source code" for "function" -- it is a reserved keyword.
    > >> Or are you looking for R's formal grammar -- e.g. how it parses input to
    > >> determine correct syntax?
    > >>
    > >>
    > >>
    > >> Bert Gunter
    > >>
    > >> "The trouble with having an open mind is that people keep coming along
    > >> and sticking things into it."
    > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    > >>
    > >>
    > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
    > >> <mailto:GoldenS at njhealth.org>> wrote:
    > >> Hi all,
    > >>
    > >> I have been attempting to access the source code for the keyword
    > >> ?function? to better understand how it assigns and stores logical inputs,
    > >> like in the subset() [base] function. Does anyone know how I can access the
    > >> source code for this?
    > >>
    > >> For example, if I have
    > >> norm <- function(x){
    > >>       sqrt(x%*%x))
    > >> }
    > >> I am looking for the source code for the ?function? portion, highlighted
    > >> in red.
    > >>
    > >> Thank you for your time and assistance,
    > >> Shelby Golden
    > >> Lab Researcher Technician
    > >> Dr. Russell Bowler?s Lab
    > >> Department of Medicine
    > >> National Jewish Health in Denver, CO
    > >> Phone: (303) 270-2598
    > >>
    > >> NOTICE: This email message is for the sole use of the intended
    > >> recipient(s) and may contain confidential and privileged information. Any
    > >> unauthorized review, use, disclosure or distribution is prohibited. If you
    > >> are not the intended recipient, please contact the sender by reply email
    > >> and destroy all copies of the original message.
    > >>         [[alternative HTML version deleted]]
    > >>
    > >> ______________________________________________
    > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
    > >> UNSUBSCRIBE and more, see
    > >> https://stat.ethz.ch/mailman/listinfo/r-help<
    > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
    > >> >
    > >> PLEASE do read the posting guide
    > >> http://www.R-project.org/posting-guide.html<
    > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
    > >> >
    > >> and provide commented, minimal, self-contained, reproducible code.
    > >>
    > >>         [[alternative HTML version deleted]]
    > >>
    > >> ______________________________________________
    > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > >> https://stat.ethz.ch/mailman/listinfo/r-help
    > >> PLEASE do read the posting guide
    > >> http://www.R-project.org/posting-guide.html
    > >> and provide commented, minimal, self-contained, reproducible code.
    > >>
    > >
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.

From Go|denS @end|ng |rom NJHe@|th@org  Fri Sep  6 22:28:21 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Fri, 6 Sep 2019 20:28:21 +0000
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <CAGiFhPPR4+UXKU8nnz5N=SjVykD4EKjSi=gO7xr5nRjfdyZYDw@mail.gmail.com>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGiFhPPR4+UXKU8nnz5N=SjVykD4EKjSi=gO7xr5nRjfdyZYDw@mail.gmail.com>
Message-ID: <9768D7CC-8BB1-4F61-8546-B9007D5777B3@njhealth.org>

Hello Jiefei,

Missed this in the subsequent emails. That is a very intriguing article, but I do not believe that it quite answers my question. Regardless, I will review it, so thank you for sending it my way!

Respectfully,
Shelby


From: Wang Jiefei <szwjf08 at gmail.com>
Date: Friday, September 6, 2019 at 11:10 AM
To: "Golden, Shelby" <GoldenS at NJHealth.org>
Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <GILLENWATERL at NJHEALTH.ORG>
Subject: Re: [R] [R-devel] Source Code for function

Hi Shelby,

Not quite sure what you are trying to do. Mine might be off-topic but have you seen this document?

http://adv-r.had.co.nz/Functions.html#function-components<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiYzZDQ2Y2Y3YzhmYmIwZmMzMz01RDcyOTJGNl81MzQ2N180NjY0XzEmJjBjMTRiYjE5NTI5MjI2MD0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRmFkdi1yJTJFaGFkJTJFY28lMkVueiUyRkZ1bmN0aW9ucyUyRWh0bWwlMjNmdW5jdGlvbi1jb21wb25lbnRz>

It illustrates the components of a function.

Best,
Jiefei

On Fri, Sep 6, 2019 at 11:52 AM Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>> wrote:
Hi all,

I have been attempting to access the source code for the keyword ?function? to better understand how it assigns and stores logical inputs, like in the subset() [base] function. Does anyone know how I can access the source code for this?

For example, if I have
norm <- function(x){
      sqrt(x%*%x))
}
I am looking for the source code for the ?function? portion, highlighted in red.

Thank you for your time and assistance,
Shelby Golden
Lab Researcher Technician
Dr. Russell Bowler?s Lab
Department of Medicine
National Jewish Health in Denver, CO
Phone: (303) 270-2598

NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiYyODRhOWIzMTgzZmQ0ZWQ0Nz01RDcyOTJGNl81MzQ2N180NjY0XzEmJmVlZTUyYjI5NzMzNjQ2Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiYyZTRkOGI3YTgzZTE0ZmQ2Nj01RDcyOTJGNl81MzQ2N180NjY0XzEmJmRlMDExYWY5OTJlM2Y2Nj0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From HDor@n @end|ng |rom @|r@org  Fri Sep  6 22:33:15 2019
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Fri, 6 Sep 2019 20:33:15 +0000
Subject: [R] Help Installing Rtools
In-Reply-To: <2815996D-7623-4D67-A2A2-B69FBB952986@mcmaster.ca>
References: <19299_1567691055_x85Di3vZ011626_BL0PR05MB481896DCAEB26A5CAC79E844CABB0@BL0PR05MB4818.namprd05.prod.outlook.com>
 <2815996D-7623-4D67-A2A2-B69FBB952986@mcmaster.ca>
Message-ID: <BL0PR05MB4818E8D3521325CA95093563CABA0@BL0PR05MB4818.namprd05.prod.outlook.com>

John

Indeed, this was the issue. I needed to modify my windows path to include both Rtools and the version of R I am using.

Thank you. 

-----Original Message-----
From: Fox, John <jfox at mcmaster.ca> 
Sent: Friday, September 6, 2019 9:35 AM
To: Doran, Harold <HDoran at air.org>
Cc: r-help at r-project.org
Subject: Re: [R] Help Installing Rtools

Dear Harold,

Have you checked that the Rtools directory is on the Windows path? If not, you could try rerunning the Rtools installer and allow it to modify the path, or simply add the Rtools directory to the path yourself.

I hope that this helps,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Sep 5, 2019, at 9:43 AM, Doran, Harold <HDoran at air.org> wrote:
> 
> I've done the following steps, but am unable to source in the Cpp files. Details of my session and sessionInfo are below. Am I missing a package, or a critical step? I found one answer regarding the 'make" error on stackoverflow suggesting the problem is resolved by grabbing the more recent version of Rtools, which I have done.
> 
> Thanks.
> 
>> install.packages('installr')
>> library(installr)
>> install.Rtools()
> 
> This step installed Rtools35.exe correctly as far as I can tell. Then,
> 
>> library(devtools)
> Loading required package: usethis
>> library(Rcpp)
>> sourceCpp("test.cpp")
> Warning message:
> In system(cmd) : 'make' not found
> Error in sourceCpp("test.cpp") :
>  Error 1 occurred building shared library.
> 
> WARNING: The tools required to build C++ code for R were not found.
> 
> Please download and install the appropriate version of Rtools:
> 
> http://cran.r-project.org/bin/windows/Rtools/
> 
>> sessionInfo()
> R version 3.6.1 (2019-07-05)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 10 
> x64 (build 18362)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252 [2] LC_CTYPE=English_United 
> States.1252 [3] LC_MONETARY=English_United States.1252 [4] 
> LC_NUMERIC=C [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] Rcpp_1.0.2      devtools_2.1.0  usethis_1.5.1   htmltab_0.7.1
> [5] installr_0.22.0 stringr_1.4.0
> 
> loaded via a namespace (and not attached):
> [1] magrittr_1.5      pkgload_1.0.2     R6_2.4.0          rlang_0.3.4
> [5] httr_1.4.1        tools_3.6.1       pkgbuild_1.0.5    sessioninfo_1.1.1
> [9] cli_1.1.0         withr_2.1.2       remotes_2.1.0     rprojroot_1.3-2
> [13] assertthat_0.2.1  digest_0.6.19     crayon_1.3.4      processx_3.4.1
> [17] callr_3.3.1       fs_1.3.1          ps_1.3.0          testthat_2.2.1
> [21] curl_4.0          memoise_1.1.0     glue_1.3.1        stringi_1.4.3
> [25] compiler_3.6.1    backports_1.1.4   desc_1.2.0        prettyunits_1.0.2
> [29] XML_3.98-1.20
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep  6 22:57:55 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 06 Sep 2019 13:57:55 -0700
Subject: [R] Is this a way to perform cross validation?
In-Reply-To: <CAMOcQfNBPmfDmGwbxJgZG6VwHp7ds-Cg5jm2HrKAQhPhL=e3cQ@mail.gmail.com>
References: <CAMOcQfNBPmfDmGwbxJgZG6VwHp7ds-Cg5jm2HrKAQhPhL=e3cQ@mail.gmail.com>
Message-ID: <05EA915E-B0F5-48D4-9C4A-8E337F3938B9@dcn.davis.ca.us>

Possibly. However, this is not a a question about R but about statistical theory, so is off-topic on this mailing list. Try Stack Exchange or consult a local statistician.

On September 5, 2019 9:58:56 AM PDT, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>Hope you are all doing great. If I am not mistaken, cross validation is
>about splitting the data into two parts: the training dataset and the
>test
>dataset.
>I have a dataset having the number of vehicles sold, from january 2008
>up
>to june 2019.
>
>I decided to go for an 80-20 scheme (where I would use 80% of the data
>for
>training, and the remaining 20% of the data for testing).
>
># I am currently using R version 3.6.1 / 64-bit
># I am using packages forecast and MLmetrics
>
>So I did the following:
>library(MLmetrics)
>library(forecast)
>#my data consists of 138 rows in total
>TotalRows <- nrow(dataset)
>TestRowStart  <-  floor(0.20*nrow(mydataframe)) + 1
>mydataframe <- data.frame(dataset)
>trainingrows <- nrow(mydataframe) - floor(0.20*nrow(mydataframe)) #
>this
>obviously gives me a tiny little bit more than the 80% roughly 80.4%
>mytrainingdata <- [1:trainingrows,] # took data from january 2008 to
>february 2017
>tsmytrainingdata <- ts(mytrainingdata$vehicles, start=c(2008,1),
>end=c(2017,2), frequency=12)
>myarimamodel <- auto.arima(tsmytrainingdata, lambda=0, biasadj=TRUE)
>myarimaforec <- forecast(myarimamodel, h=36)
>myarimaforecframe <- data.frame(myarimaforec$mean)
>TestData <- mydataframe[TestRowStart:TotalRows,]
>myarimamodelMAPE <- MAPE(myarimaforecframe[1:(TotalRows -
>TrainRowStart),],
>TestData)
>
>can this be considered cross validation?
>
>here is the dput() if my dataset, in the case of the code I put above,
>mydataframe = datframe (which shows in the dput)
>
>structure(list(DATE = structure(c(47L, 35L, 82L, 1L, 94L, 70L,
>59L, 13L, 128L, 117L, 106L, 24L, 48L, 36L, 83L, 2L, 95L, 71L,
>60L, 14L, 129L, 118L, 107L, 25L, 49L, 37L, 84L, 3L, 96L, 72L,
>61L, 15L, 130L, 119L, 108L, 26L, 50L, 38L, 85L, 4L, 97L, 73L,
>62L, 16L, 131L, 120L, 109L, 27L, 51L, 39L, 86L, 5L, 98L, 74L,
>63L, 17L, 132L, 121L, 110L, 28L, 52L, 40L, 87L, 6L, 99L, 75L,
>64L, 18L, 133L, 122L, 111L, 29L, 53L, 41L, 88L, 7L, 100L, 76L,
>65L, 19L, 134L, 123L, 112L, 30L, 54L, 42L, 89L, 8L, 101L, 77L,
>66L, 20L, 135L, 124L, 113L, 31L, 55L, 43L, 90L, 9L, 102L, 78L,
>67L, 21L, 136L, 125L, 114L, 32L, 56L, 44L, 91L, 10L, 103L, 79L,
>68L, 22L, 137L, 126L, 115L, 33L, 57L, 45L, 92L, 11L, 104L, 80L,
>69L, 23L, 138L, 127L, 116L, 34L, 58L, 46L, 93L, 12L, 105L, 81L
>), .Label = c("Apr-08", "Apr-09", "Apr-10", "Apr-11", "Apr-12",
>"Apr-13", "Apr-14", "Apr-15", "Apr-16", "Apr-17", "Apr-18", "Apr-19",
>"Aug-08", "Aug-09", "Aug-10", "Aug-11", "Aug-12", "Aug-13", "Aug-14",
>"Aug-15", "Aug-16", "Aug-17", "Aug-18", "Dec-08", "Dec-09", "Dec-10",
>"Dec-11", "Dec-12", "Dec-13", "Dec-14", "Dec-15", "Dec-16", "Dec-17",
>"Dec-18", "Feb-08", "Feb-09", "Feb-10", "Feb-11", "Feb-12", "Feb-13",
>"Feb-14", "Feb-15", "Feb-16", "Feb-17", "Feb-18", "Feb-19", "Jan-08",
>"Jan-09", "Jan-10", "Jan-11", "Jan-12", "Jan-13", "Jan-14", "Jan-15",
>"Jan-16", "Jan-17", "Jan-18", "Jan-19", "Jul-08", "Jul-09", "Jul-10",
>"Jul-11", "Jul-12", "Jul-13", "Jul-14", "Jul-15", "Jul-16", "Jul-17",
>"Jul-18", "Jun-08", "Jun-09", "Jun-10", "Jun-11", "Jun-12", "Jun-13",
>"Jun-14", "Jun-15", "Jun-16", "Jun-17", "Jun-18", "Jun-19", "Mar-08",
>"Mar-09", "Mar-10", "Mar-11", "Mar-12", "Mar-13", "Mar-14", "Mar-15",
>"Mar-16", "Mar-17", "Mar-18", "Mar-19", "May-08", "May-09", "May-10",
>"May-11", "May-12", "May-13", "May-14", "May-15", "May-16", "May-17",
>"May-18", "May-19", "Nov-08", "Nov-09", "Nov-10", "Nov-11", "Nov-12",
>"Nov-13", "Nov-14", "Nov-15", "Nov-16", "Nov-17", "Nov-18", "Oct-08",
>"Oct-09", "Oct-10", "Oct-11", "Oct-12", "Oct-13", "Oct-14", "Oct-15",
>"Oct-16", "Oct-17", "Oct-18", "Sep-08", "Sep-09", "Sep-10", "Sep-11",
>"Sep-12", "Sep-13", "Sep-14", "Sep-15", "Sep-16", "Sep-17", "Sep-18"
>), class = "factor"), totalmov = c(18368L, 14629L, 19310L, 20273L,
>16097L, 16003L, 16146L, 14312L, 15319L, 19480L, 14267L, 18309L,
>12533L, 7262L, 4914L, 5854L, 7626L, 5708L, 7678L, 6927L, 5923L,
>9020L, 8975L, 11214L, 8461L, 9512L, 13410L, 12526L, 11374L, 17829L,
>13174L, 22175L, 14551L, 17311L, 16491L, 11970L, 14527L, 16905L,
>16488L, 14356L, 13855L, 11468L, 16514L, 13025L, 14153L, 19022L,
>18262L, 9609L, 18603L, 9389L, 15899L, 13395L, 10689L, 11137L,
>13818L, 12983L, 10083L, 14301L, 11912L, 12106L, 12686L, 7947L,
>11442L, 13656L, 12093L, 11433L, 14732L, 11175L, 10449L, 14286L,
>10935L, 10627L, 12076L, 10170L, 9264L, 13859L, 9821L, 10384L,
>12372L, 14902L, 11804L, 9911L, 11841L, 10127L, 12615L, 6851L,
>9181L, 13667L, 12759L, 9531L, 12636L, 14683L, 10383L, 16141L,
>12132L, 8123L, 12858L, 7811L, 10865L, 11931L, 10397L, 6020L,
>9384L, 13473L, 12702L, 14671L, 12485L, 16787L, 11698L, 12988L,
>13120L, 11411L, 12317L, 9905L, 13387L, 10928L, 10697L, 16790L,
>10381L, 10121L, 11728L, 9625L, 9345L, 18263L, 17753L, 12488L,
>14469L, 13134L, 17799L, 14770L, 17104L, 11912L, 16229L, 14273L,
>13223L, 15277L, 15185L, 15568L)), class = "data.frame", row.names =
>c(NA,
>-138L))
>
>Best regards,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep  6 23:10:03 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 6 Sep 2019 14:10:03 -0700
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
Message-ID: <89122b4f-f76c-8cbb-1217-bbc7f8a21c12@comcast.net>


On 9/6/19 1:07 PM, Golden, Shelby wrote:
> Thank you all for your reply. I should clarify, that I am looking to understand why the keyword function can take a logical argument (eg: x<4) and use that later inside the function's definition for logical evaluations.
>
> Consider this example, which is a simplification of getAnywhere(subset.data.frame):
> x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
> test <- function(x, logic){
> 	e <- substitute(logic)
> 	r <- eval(e, x, parent.frame())
> 	r[r]
> }

x<4 is not really a logical argument in that context. It is rather an 
expression and will remain an expression until it needs to be evaluated. 
See this even simpler example:


 ?test <- function(x, logic, ... ){
 ???? e <- deparse( substitute(logic))
 ???? #r <- eval(e, x, parent.frame())
 ???? e
 ?}
 ?test(4, x<4)
#[1] "x < 4"


 ?test(4, is.logical(x < 4) )
[1] "is.logical(x < 4)"


Some of this you have already been told, but appears necessary to 
repeat. Expressions given to `function` are not necessarily evaluated. 
They will be evaluated if assigned names.


test(4, zed = is.logical(x < 4) )
#[1] ""

The function()-function will parse the contents of the parentheses for 
number of arguments and for parse()-ability. It will evaluate named 
arguments created with "=". In the context of parsing the formals of a 
function the "=" operator is different than the "<-" function.

The substitute function will not evaluate (since in the language of R 
operations it is "special"), but rather checks that the expression can 
be parsed by R's rules, i.e. is a valid parse tree. `deparse` returns 
the original character representation.

-- 

David


>
> Shelby
>   
>
> ?On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <r-help-bounces at r-project.org on behalf of rmh at temple.edu> wrote:
>
>      You might also want to look at the codetools package, for example the
>      showTree function " Prints a Lisp-style representation of R
>      expression."
>      
>      > library(codetools)
>      
>      > showTree(quote(x %*% x))
>      (%*% x x)
>      > showTree(quote(a+b))
>      (+ a b)
>      > showTree(quote(y ~ a+b))
>      (~ y (+ a b))
>      
>      On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>      >
>      > The following may be of use (it gives the parse tree of the text):
>      >
>      > > z <- as.list(parse(text = "function(x)x %*% x"))
>      > > z[[1]]
>      > function(x) x %*% x
>      > > z[[c(1,1)]]
>      > `function`
>      > > z[[c(1,2)]]
>      > $x
>      > > z[[c(1,3)]]
>      > x %*% x
>      > > z[[c(1,3,1)]]
>      > `%*%`
>      > > z[[c(1,3,2)]]
>      > x
>      > > z[[c(1,3,3)]]
>      > x
>      >
>      >
>      > Bert Gunter
>      >
>      >
>      >
>      > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com> wrote:
>      >
>      > > If you are looking for an R code parser, I think the `parse` and `eval`
>      > > function might be a good start point. See the example below.
>      > >
>      > > > parse(text="function(x)message(x)")
>      > > expression(function(x)message(x))
>      > > > eval(parse(text="function(x)message(x)"))
>      > > function(x)message(x)
>      > >
>      > > Best,
>      > > Jiefei
>      > >
>      > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org>
>      > > wrote:
>      > >
>      > >> Hello Bert,
>      > >>
>      > >> Thank you for the reply and your clarifications. Yes, it might be helpful
>      > >> to look into R?s formal grammar to see how ?function? parses input to
>      > >> delegate correct syntax. Is that accessible online?
>      > >>
>      > >> Thank you,
>      > >> Shelby
>      > >>
>      > >>
>      > >> From: Bert Gunter <bgunter.4567 at gmail.com>
>      > >> Date: Friday, September 6, 2019 at 10:44 AM
>      > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
>      > >> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
>      > >> GILLENWATERL at NJHEALTH.ORG>
>      > >> Subject: Re: [R] [R-devel] Source Code for function
>      > >>
>      > >> 1. This is a plain text list; all html is stripped. So there is no red
>      > >> highlighting.
>      > >>
>      > >> 2. There is no "source code" for "function" -- it is a reserved keyword.
>      > >> Or are you looking for R's formal grammar -- e.g. how it parses input to
>      > >> determine correct syntax?
>      > >>
>      > >>
>      > >>
>      > >> Bert Gunter
>      > >>
>      > >> "The trouble with having an open mind is that people keep coming along
>      > >> and sticking things into it."
>      > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>      > >>
>      > >>
>      > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
>      > >> <mailto:GoldenS at njhealth.org>> wrote:
>      > >> Hi all,
>      > >>
>      > >> I have been attempting to access the source code for the keyword
>      > >> ?function? to better understand how it assigns and stores logical inputs,
>      > >> like in the subset() [base] function. Does anyone know how I can access the
>      > >> source code for this?
>      > >>
>      > >> For example, if I have
>      > >> norm <- function(x){
>      > >>       sqrt(x%*%x))
>      > >> }
>      > >> I am looking for the source code for the ?function? portion, highlighted
>      > >> in red.
>      > >>
>      > >> Thank you for your time and assistance,
>      > >> Shelby Golden
>      > >> Lab Researcher Technician
>      > >> Dr. Russell Bowler?s Lab
>      > >> Department of Medicine
>      > >> National Jewish Health in Denver, CO
>      > >> Phone: (303) 270-2598
>      > >>
>      > >> NOTICE: This email message is for the sole use of the intended
>      > >> recipient(s) and may contain confidential and privileged information. Any
>      > >> unauthorized review, use, disclosure or distribution is prohibited. If you
>      > >> are not the intended recipient, please contact the sender by reply email
>      > >> and destroy all copies of the original message.
>      > >>         [[alternative HTML version deleted]]
>      > >>
>      > >> ______________________________________________
>      > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>      > >> UNSUBSCRIBE and more, see
>      > >> https://stat.ethz.ch/mailman/listinfo/r-help<
>      > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
>      > >> >
>      > >> PLEASE do read the posting guide
>      > >> http://www.R-project.org/posting-guide.html<
>      > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
>      > >> >
>      > >> and provide commented, minimal, self-contained, reproducible code.
>      > >>
>      > >>         [[alternative HTML version deleted]]
>      > >>
>      > >> ______________________________________________
>      > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > >> https://stat.ethz.ch/mailman/listinfo/r-help
>      > >> PLEASE do read the posting guide
>      > >> http://www.R-project.org/posting-guide.html
>      > >> and provide commented, minimal, self-contained, reproducible code.
>      > >>
>      > >
>      >
>      >         [[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      
>      ______________________________________________
>      R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      https://stat.ethz.ch/mailman/listinfo/r-help
>      PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      and provide commented, minimal, self-contained, reproducible code.
>      
>
>
> NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Go|denS @end|ng |rom NJHe@|th@org  Fri Sep  6 23:30:46 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Fri, 6 Sep 2019 21:30:46 +0000
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <89122b4f-f76c-8cbb-1217-bbc7f8a21c12@comcast.net>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
 <89122b4f-f76c-8cbb-1217-bbc7f8a21c12@comcast.net>
Message-ID: <1456FC9D-07A1-453E-AC07-2C9BD0306E66@njhealth.org>

Afternoon, David,

Thank you for your suggestions and insight. I have previously utilized parse, but in my exploration to improve my coding technique I came across this comment in stackoverflow.com (https://stackoverflow.com/questions/1743698/evaluate-expression-given-as-a-string - comment left Martin Maechler). In it, he suggests that usage parse is not a good method, saying that it is "rarely an efficient or safe means to construct expressions (or calls)". 

Perhaps you, or others in this community, disagree with what Martin has to say about parse in this application?

Shelby
 

?On 9/6/19, 3:10 PM, "David Winsemius" <dwinsemius at comcast.net> wrote:

    
    On 9/6/19 1:07 PM, Golden, Shelby wrote:
    > Thank you all for your reply. I should clarify, that I am looking to understand why the keyword function can take a logical argument (eg: x<4) and use that later inside the function's definition for logical evaluations.
    >
    > Consider this example, which is a simplification of getAnywhere(subset.data.frame):
    > x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
    > test <- function(x, logic){
    > 	e <- substitute(logic)
    > 	r <- eval(e, x, parent.frame())
    > 	r[r]
    > }
    
    x<4 is not really a logical argument in that context. It is rather an 
    expression and will remain an expression until it needs to be evaluated. 
    See this even simpler example:
    
    
      test <- function(x, logic, ... ){
          e <- deparse( substitute(logic))
          #r <- eval(e, x, parent.frame())
          e
      }
      test(4, x<4)
    #[1] "x < 4"
    
    
      test(4, is.logical(x < 4) )
    [1] "is.logical(x < 4)"
    
    
    Some of this you have already been told, but appears necessary to 
    repeat. Expressions given to `function` are not necessarily evaluated. 
    They will be evaluated if assigned names.
    
    
    test(4, zed = is.logical(x < 4) )
    #[1] ""
    
    The function()-function will parse the contents of the parentheses for 
    number of arguments and for parse()-ability. It will evaluate named 
    arguments created with "=". In the context of parsing the formals of a 
    function the "=" operator is different than the "<-" function.
    
    The substitute function will not evaluate (since in the language of R 
    operations it is "special"), but rather checks that the expression can 
    be parsed by R's rules, i.e. is a valid parse tree. `deparse` returns 
    the original character representation.
    
    -- 
    
    David
    
    
    >
    > Shelby
    >   
    >
    > On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <r-help-bounces at r-project.org on behalf of rmh at temple.edu> wrote:
    >
    >      You might also want to look at the codetools package, for example the
    >      showTree function " Prints a Lisp-style representation of R
    >      expression."
    >      
    >      > library(codetools)
    >      
    >      > showTree(quote(x %*% x))
    >      (%*% x x)
    >      > showTree(quote(a+b))
    >      (+ a b)
    >      > showTree(quote(y ~ a+b))
    >      (~ y (+ a b))
    >      
    >      On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >      >
    >      > The following may be of use (it gives the parse tree of the text):
    >      >
    >      > > z <- as.list(parse(text = "function(x)x %*% x"))
    >      > > z[[1]]
    >      > function(x) x %*% x
    >      > > z[[c(1,1)]]
    >      > `function`
    >      > > z[[c(1,2)]]
    >      > $x
    >      > > z[[c(1,3)]]
    >      > x %*% x
    >      > > z[[c(1,3,1)]]
    >      > `%*%`
    >      > > z[[c(1,3,2)]]
    >      > x
    >      > > z[[c(1,3,3)]]
    >      > x
    >      >
    >      >
    >      > Bert Gunter
    >      >
    >      >
    >      >
    >      > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com> wrote:
    >      >
    >      > > If you are looking for an R code parser, I think the `parse` and `eval`
    >      > > function might be a good start point. See the example below.
    >      > >
    >      > > > parse(text="function(x)message(x)")
    >      > > expression(function(x)message(x))
    >      > > > eval(parse(text="function(x)message(x)"))
    >      > > function(x)message(x)
    >      > >
    >      > > Best,
    >      > > Jiefei
    >      > >
    >      > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org>
    >      > > wrote:
    >      > >
    >      > >> Hello Bert,
    >      > >>
    >      > >> Thank you for the reply and your clarifications. Yes, it might be helpful
    >      > >> to look into R?s formal grammar to see how ?function? parses input to
    >      > >> delegate correct syntax. Is that accessible online?
    >      > >>
    >      > >> Thank you,
    >      > >> Shelby
    >      > >>
    >      > >>
    >      > >> From: Bert Gunter <bgunter.4567 at gmail.com>
    >      > >> Date: Friday, September 6, 2019 at 10:44 AM
    >      > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
    >      > >> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
    >      > >> GILLENWATERL at NJHEALTH.ORG>
    >      > >> Subject: Re: [R] [R-devel] Source Code for function
    >      > >>
    >      > >> 1. This is a plain text list; all html is stripped. So there is no red
    >      > >> highlighting.
    >      > >>
    >      > >> 2. There is no "source code" for "function" -- it is a reserved keyword.
    >      > >> Or are you looking for R's formal grammar -- e.g. how it parses input to
    >      > >> determine correct syntax?
    >      > >>
    >      > >>
    >      > >>
    >      > >> Bert Gunter
    >      > >>
    >      > >> "The trouble with having an open mind is that people keep coming along
    >      > >> and sticking things into it."
    >      > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    >      > >>
    >      > >>
    >      > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
    >      > >> <mailto:GoldenS at njhealth.org>> wrote:
    >      > >> Hi all,
    >      > >>
    >      > >> I have been attempting to access the source code for the keyword
    >      > >> ?function? to better understand how it assigns and stores logical inputs,
    >      > >> like in the subset() [base] function. Does anyone know how I can access the
    >      > >> source code for this?
    >      > >>
    >      > >> For example, if I have
    >      > >> norm <- function(x){
    >      > >>       sqrt(x%*%x))
    >      > >> }
    >      > >> I am looking for the source code for the ?function? portion, highlighted
    >      > >> in red.
    >      > >>
    >      > >> Thank you for your time and assistance,
    >      > >> Shelby Golden
    >      > >> Lab Researcher Technician
    >      > >> Dr. Russell Bowler?s Lab
    >      > >> Department of Medicine
    >      > >> National Jewish Health in Denver, CO
    >      > >> Phone: (303) 270-2598
    >      > >>
    >      > >> NOTICE: This email message is for the sole use of the intended
    >      > >> recipient(s) and may contain confidential and privileged information. Any
    >      > >> unauthorized review, use, disclosure or distribution is prohibited. If you
    >      > >> are not the intended recipient, please contact the sender by reply email
    >      > >> and destroy all copies of the original message.
    >      > >>         [[alternative HTML version deleted]]
    >      > >>
    >      > >> ______________________________________________
    >      > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
    >      > >> UNSUBSCRIBE and more, see
    >      > >> https://stat.ethz.ch/mailman/listinfo/r-help<
    >      > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
    >      > >> >
    >      > >> PLEASE do read the posting guide
    >      > >> http://www.R-project.org/posting-guide.html<
    >      > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
    >      > >> >
    >      > >> and provide commented, minimal, self-contained, reproducible code.
    >      > >>
    >      > >>         [[alternative HTML version deleted]]
    >      > >>
    >      > >> ______________________________________________
    >      > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >      > >> https://stat.ethz.ch/mailman/listinfo/r-help
    >      > >> PLEASE do read the posting guide
    >      > >> http://www.R-project.org/posting-guide.html
    >      > >> and provide commented, minimal, self-contained, reproducible code.
    >      > >>
    >      > >
    >      >
    >      >         [[alternative HTML version deleted]]
    >      >
    >      > ______________________________________________
    >      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >      > https://stat.ethz.ch/mailman/listinfo/r-help
    >      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >      > and provide commented, minimal, self-contained, reproducible code.
    >      
    >      ______________________________________________
    >      R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >      https://stat.ethz.ch/mailman/listinfo/r-help
    >      PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >      and provide commented, minimal, self-contained, reproducible code.
    >      
    >
    >
    > NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    


From pd@|gd @end|ng |rom gm@||@com  Sat Sep  7 00:02:48 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 7 Sep 2019 00:02:48 +0200
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <89122b4f-f76c-8cbb-1217-bbc7f8a21c12@comcast.net>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
 <89122b4f-f76c-8cbb-1217-bbc7f8a21c12@comcast.net>
Message-ID: <B3B78180-7D63-458C-A342-D63DFAAF2FE5@gmail.com>

Um... Let's get the concepts straight:

The "function" function doesn't evaluate anything. It just takes the list of formal arguments (including default expressions), the function body, and the current evaluation environment, and stiches them together into a function object, known as a "closure".

The action happens when a function is _called_. Then the actual arguments are combined with the formals, and the body expression is evaluated. You will find the source code for this in src/main/eval.c. It is a pretty complex beast, but the essential point for the present discussion is that actual arguments in function calls are passed in the form of so-called promises. These contain the expression passed, so that substitute() can extract it. It also enables lazy evaluation: putting off argument evaluation until the value is actually needed (possibly never).  

-pd

> On 6 Sep 2019, at 23:10 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On 9/6/19 1:07 PM, Golden, Shelby wrote:
>> Thank you all for your reply. I should clarify, that I am looking to understand why the keyword function can take a logical argument (eg: x<4) and use that later inside the function's definition for logical evaluations.
>> 
>> Consider this example, which is a simplification of getAnywhere(subset.data.frame):
>> x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
>> test <- function(x, logic){
>> 	e <- substitute(logic)
>> 	r <- eval(e, x, parent.frame())
>> 	r[r]
>> }
> 
> x<4 is not really a logical argument in that context. It is rather an expression and will remain an expression until it needs to be evaluated. See this even simpler example:
> 
> 
>  test <- function(x, logic, ... ){
>      e <- deparse( substitute(logic))
>      #r <- eval(e, x, parent.frame())
>      e
>  }
>  test(4, x<4)
> #[1] "x < 4"
> 
> 
>  test(4, is.logical(x < 4) )
> [1] "is.logical(x < 4)"
> 
> 
> Some of this you have already been told, but appears necessary to repeat. Expressions given to `function` are not necessarily evaluated. They will be evaluated if assigned names.
> 
> 
> test(4, zed = is.logical(x < 4) )
> #[1] ""
> 
> The function()-function will parse the contents of the parentheses for number of arguments and for parse()-ability. It will evaluate named arguments created with "=". In the context of parsing the formals of a function the "=" operator is different than the "<-" function.
> 
> The substitute function will not evaluate (since in the language of R operations it is "special"), but rather checks that the expression can be parsed by R's rules, i.e. is a valid parse tree. `deparse` returns the original character representation.
> 
> -- 
> 
> David
> 
> 
>> 
>> Shelby
>>  
>> ?On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <r-help-bounces at r-project.org on behalf of rmh at temple.edu> wrote:
>> 
>>     You might also want to look at the codetools package, for example the
>>     showTree function " Prints a Lisp-style representation of R
>>     expression."
>>          > library(codetools)
>>          > showTree(quote(x %*% x))
>>     (%*% x x)
>>     > showTree(quote(a+b))
>>     (+ a b)
>>     > showTree(quote(y ~ a+b))
>>     (~ y (+ a b))
>>          On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>     >
>>     > The following may be of use (it gives the parse tree of the text):
>>     >
>>     > > z <- as.list(parse(text = "function(x)x %*% x"))
>>     > > z[[1]]
>>     > function(x) x %*% x
>>     > > z[[c(1,1)]]
>>     > `function`
>>     > > z[[c(1,2)]]
>>     > $x
>>     > > z[[c(1,3)]]
>>     > x %*% x
>>     > > z[[c(1,3,1)]]
>>     > `%*%`
>>     > > z[[c(1,3,2)]]
>>     > x
>>     > > z[[c(1,3,3)]]
>>     > x
>>     >
>>     >
>>     > Bert Gunter
>>     >
>>     >
>>     >
>>     > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com> wrote:
>>     >
>>     > > If you are looking for an R code parser, I think the `parse` and `eval`
>>     > > function might be a good start point. See the example below.
>>     > >
>>     > > > parse(text="function(x)message(x)")
>>     > > expression(function(x)message(x))
>>     > > > eval(parse(text="function(x)message(x)"))
>>     > > function(x)message(x)
>>     > >
>>     > > Best,
>>     > > Jiefei
>>     > >
>>     > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org>
>>     > > wrote:
>>     > >
>>     > >> Hello Bert,
>>     > >>
>>     > >> Thank you for the reply and your clarifications. Yes, it might be helpful
>>     > >> to look into R?s formal grammar to see how ?function? parses input to
>>     > >> delegate correct syntax. Is that accessible online?
>>     > >>
>>     > >> Thank you,
>>     > >> Shelby
>>     > >>
>>     > >>
>>     > >> From: Bert Gunter <bgunter.4567 at gmail.com>
>>     > >> Date: Friday, September 6, 2019 at 10:44 AM
>>     > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
>>     > >> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
>>     > >> GILLENWATERL at NJHEALTH.ORG>
>>     > >> Subject: Re: [R] [R-devel] Source Code for function
>>     > >>
>>     > >> 1. This is a plain text list; all html is stripped. So there is no red
>>     > >> highlighting.
>>     > >>
>>     > >> 2. There is no "source code" for "function" -- it is a reserved keyword.
>>     > >> Or are you looking for R's formal grammar -- e.g. how it parses input to
>>     > >> determine correct syntax?
>>     > >>
>>     > >>
>>     > >>
>>     > >> Bert Gunter
>>     > >>
>>     > >> "The trouble with having an open mind is that people keep coming along
>>     > >> and sticking things into it."
>>     > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>     > >>
>>     > >>
>>     > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
>>     > >> <mailto:GoldenS at njhealth.org>> wrote:
>>     > >> Hi all,
>>     > >>
>>     > >> I have been attempting to access the source code for the keyword
>>     > >> ?function? to better understand how it assigns and stores logical inputs,
>>     > >> like in the subset() [base] function. Does anyone know how I can access the
>>     > >> source code for this?
>>     > >>
>>     > >> For example, if I have
>>     > >> norm <- function(x){
>>     > >>       sqrt(x%*%x))
>>     > >> }
>>     > >> I am looking for the source code for the ?function? portion, highlighted
>>     > >> in red.
>>     > >>
>>     > >> Thank you for your time and assistance,
>>     > >> Shelby Golden
>>     > >> Lab Researcher Technician
>>     > >> Dr. Russell Bowler?s Lab
>>     > >> Department of Medicine
>>     > >> National Jewish Health in Denver, CO
>>     > >> Phone: (303) 270-2598
>>     > >>
>>     > >> NOTICE: This email message is for the sole use of the intended
>>     > >> recipient(s) and may contain confidential and privileged information. Any
>>     > >> unauthorized review, use, disclosure or distribution is prohibited. If you
>>     > >> are not the intended recipient, please contact the sender by reply email
>>     > >> and destroy all copies of the original message.
>>     > >>         [[alternative HTML version deleted]]
>>     > >>
>>     > >> ______________________________________________
>>     > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>>     > >> UNSUBSCRIBE and more, see
>>     > >> https://stat.ethz.ch/mailman/listinfo/r-help<
>>     > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
>>     > >> >
>>     > >> PLEASE do read the posting guide
>>     > >> http://www.R-project.org/posting-guide.html<
>>     > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
>>     > >> >
>>     > >> and provide commented, minimal, self-contained, reproducible code.
>>     > >>
>>     > >>         [[alternative HTML version deleted]]
>>     > >>
>>     > >> ______________________________________________
>>     > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > >> https://stat.ethz.ch/mailman/listinfo/r-help
>>     > >> PLEASE do read the posting guide
>>     > >> http://www.R-project.org/posting-guide.html
>>     > >> and provide commented, minimal, self-contained, reproducible code.
>>     > >>
>>     > >
>>     >
>>     >         [[alternative HTML version deleted]]
>>     >
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>>          ______________________________________________
>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>     
>> 
>> NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Go|denS @end|ng |rom NJHe@|th@org  Sat Sep  7 00:15:32 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Fri, 6 Sep 2019 22:15:32 +0000
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <B3B78180-7D63-458C-A342-D63DFAAF2FE5@gmail.com>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
 <89122b4f-f76c-8cbb-1217-bbc7f8a21c12@comcast.net>
 <B3B78180-7D63-458C-A342-D63DFAAF2FE5@gmail.com>
Message-ID: <3B04ABDD-5346-41E5-8498-D946D4BE981C@njhealth.org>

Afternoon, Peter,

Thank you for your concise but informative reply, and for a link to the source code. These complex concepts do answer my question spot on, so thank you for taking the time to put them all together and summarizing them for me.

Is the standard nomenclature for arguments in function calls "promises"? I would like to look into this concept further. If there are other concepts you think I should look into further too, I would be happy to include those as well.

Regards,
Shelby
 

?On 9/6/19, 4:02 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:

    Um... Let's get the concepts straight:
    
    The "function" function doesn't evaluate anything. It just takes the list of formal arguments (including default expressions), the function body, and the current evaluation environment, and stiches them together into a function object, known as a "closure".
    
    The action happens when a function is _called_. Then the actual arguments are combined with the formals, and the body expression is evaluated. You will find the source code for this in src/main/eval.c. It is a pretty complex beast, but the essential point for the present discussion is that actual arguments in function calls are passed in the form of so-called promises. These contain the expression passed, so that substitute() can extract it. It also enables lazy evaluation: putting off argument evaluation until the value is actually needed (possibly never).  
    
    -pd
    
    > On 6 Sep 2019, at 23:10 , David Winsemius <dwinsemius at comcast.net> wrote:
    > 
    > 
    > On 9/6/19 1:07 PM, Golden, Shelby wrote:
    >> Thank you all for your reply. I should clarify, that I am looking to understand why the keyword function can take a logical argument (eg: x<4) and use that later inside the function's definition for logical evaluations.
    >> 
    >> Consider this example, which is a simplification of getAnywhere(subset.data.frame):
    >> x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
    >> test <- function(x, logic){
    >> 	e <- substitute(logic)
    >> 	r <- eval(e, x, parent.frame())
    >> 	r[r]
    >> }
    > 
    > x<4 is not really a logical argument in that context. It is rather an expression and will remain an expression until it needs to be evaluated. See this even simpler example:
    > 
    > 
    >  test <- function(x, logic, ... ){
    >      e <- deparse( substitute(logic))
    >      #r <- eval(e, x, parent.frame())
    >      e
    >  }
    >  test(4, x<4)
    > #[1] "x < 4"
    > 
    > 
    >  test(4, is.logical(x < 4) )
    > [1] "is.logical(x < 4)"
    > 
    > 
    > Some of this you have already been told, but appears necessary to repeat. Expressions given to `function` are not necessarily evaluated. They will be evaluated if assigned names.
    > 
    > 
    > test(4, zed = is.logical(x < 4) )
    > #[1] ""
    > 
    > The function()-function will parse the contents of the parentheses for number of arguments and for parse()-ability. It will evaluate named arguments created with "=". In the context of parsing the formals of a function the "=" operator is different than the "<-" function.
    > 
    > The substitute function will not evaluate (since in the language of R operations it is "special"), but rather checks that the expression can be parsed by R's rules, i.e. is a valid parse tree. `deparse` returns the original character representation.
    > 
    > -- 
    > 
    > David
    > 
    > 
    >> 
    >> Shelby
    >>  
    >> On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <r-help-bounces at r-project.org on behalf of rmh at temple.edu> wrote:
    >> 
    >>     You might also want to look at the codetools package, for example the
    >>     showTree function " Prints a Lisp-style representation of R
    >>     expression."
    >>          > library(codetools)
    >>          > showTree(quote(x %*% x))
    >>     (%*% x x)
    >>     > showTree(quote(a+b))
    >>     (+ a b)
    >>     > showTree(quote(y ~ a+b))
    >>     (~ y (+ a b))
    >>          On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >>     >
    >>     > The following may be of use (it gives the parse tree of the text):
    >>     >
    >>     > > z <- as.list(parse(text = "function(x)x %*% x"))
    >>     > > z[[1]]
    >>     > function(x) x %*% x
    >>     > > z[[c(1,1)]]
    >>     > `function`
    >>     > > z[[c(1,2)]]
    >>     > $x
    >>     > > z[[c(1,3)]]
    >>     > x %*% x
    >>     > > z[[c(1,3,1)]]
    >>     > `%*%`
    >>     > > z[[c(1,3,2)]]
    >>     > x
    >>     > > z[[c(1,3,3)]]
    >>     > x
    >>     >
    >>     >
    >>     > Bert Gunter
    >>     >
    >>     >
    >>     >
    >>     > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com> wrote:
    >>     >
    >>     > > If you are looking for an R code parser, I think the `parse` and `eval`
    >>     > > function might be a good start point. See the example below.
    >>     > >
    >>     > > > parse(text="function(x)message(x)")
    >>     > > expression(function(x)message(x))
    >>     > > > eval(parse(text="function(x)message(x)"))
    >>     > > function(x)message(x)
    >>     > >
    >>     > > Best,
    >>     > > Jiefei
    >>     > >
    >>     > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org>
    >>     > > wrote:
    >>     > >
    >>     > >> Hello Bert,
    >>     > >>
    >>     > >> Thank you for the reply and your clarifications. Yes, it might be helpful
    >>     > >> to look into R?s formal grammar to see how ?function? parses input to
    >>     > >> delegate correct syntax. Is that accessible online?
    >>     > >>
    >>     > >> Thank you,
    >>     > >> Shelby
    >>     > >>
    >>     > >>
    >>     > >> From: Bert Gunter <bgunter.4567 at gmail.com>
    >>     > >> Date: Friday, September 6, 2019 at 10:44 AM
    >>     > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
    >>     > >> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <
    >>     > >> GILLENWATERL at NJHEALTH.ORG>
    >>     > >> Subject: Re: [R] [R-devel] Source Code for function
    >>     > >>
    >>     > >> 1. This is a plain text list; all html is stripped. So there is no red
    >>     > >> highlighting.
    >>     > >>
    >>     > >> 2. There is no "source code" for "function" -- it is a reserved keyword.
    >>     > >> Or are you looking for R's formal grammar -- e.g. how it parses input to
    >>     > >> determine correct syntax?
    >>     > >>
    >>     > >>
    >>     > >>
    >>     > >> Bert Gunter
    >>     > >>
    >>     > >> "The trouble with having an open mind is that people keep coming along
    >>     > >> and sticking things into it."
    >>     > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    >>     > >>
    >>     > >>
    >>     > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org
    >>     > >> <mailto:GoldenS at njhealth.org>> wrote:
    >>     > >> Hi all,
    >>     > >>
    >>     > >> I have been attempting to access the source code for the keyword
    >>     > >> ?function? to better understand how it assigns and stores logical inputs,
    >>     > >> like in the subset() [base] function. Does anyone know how I can access the
    >>     > >> source code for this?
    >>     > >>
    >>     > >> For example, if I have
    >>     > >> norm <- function(x){
    >>     > >>       sqrt(x%*%x))
    >>     > >> }
    >>     > >> I am looking for the source code for the ?function? portion, highlighted
    >>     > >> in red.
    >>     > >>
    >>     > >> Thank you for your time and assistance,
    >>     > >> Shelby Golden
    >>     > >> Lab Researcher Technician
    >>     > >> Dr. Russell Bowler?s Lab
    >>     > >> Department of Medicine
    >>     > >> National Jewish Health in Denver, CO
    >>     > >> Phone: (303) 270-2598
    >>     > >>
    >>     > >> NOTICE: This email message is for the sole use of the intended
    >>     > >> recipient(s) and may contain confidential and privileged information. Any
    >>     > >> unauthorized review, use, disclosure or distribution is prohibited. If you
    >>     > >> are not the intended recipient, please contact the sender by reply email
    >>     > >> and destroy all copies of the original message.
    >>     > >>         [[alternative HTML version deleted]]
    >>     > >>
    >>     > >> ______________________________________________
    >>     > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
    >>     > >> UNSUBSCRIBE and more, see
    >>     > >> https://stat.ethz.ch/mailman/listinfo/r-help<
    >>     > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
    >>     > >> >
    >>     > >> PLEASE do read the posting guide
    >>     > >> http://www.R-project.org/posting-guide.html<
    >>     > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
    >>     > >> >
    >>     > >> and provide commented, minimal, self-contained, reproducible code.
    >>     > >>
    >>     > >>         [[alternative HTML version deleted]]
    >>     > >>
    >>     > >> ______________________________________________
    >>     > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>     > >> https://stat.ethz.ch/mailman/listinfo/r-help
    >>     > >> PLEASE do read the posting guide
    >>     > >> http://www.R-project.org/posting-guide.html
    >>     > >> and provide commented, minimal, self-contained, reproducible code.
    >>     > >>
    >>     > >
    >>     >
    >>     >         [[alternative HTML version deleted]]
    >>     >
    >>     > ______________________________________________
    >>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>     > https://stat.ethz.ch/mailman/listinfo/r-help
    >>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>     > and provide commented, minimal, self-contained, reproducible code.
    >>          ______________________________________________
    >>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>     https://stat.ethz.ch/mailman/listinfo/r-help
    >>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>     and provide commented, minimal, self-contained, reproducible code.
    >>     
    >> 
    >> NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Peter Dalgaard, Professor,
    Center for Statistics, Copenhagen Business School
    Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    Phone: (+45)38153501
    Office: A 4.23
    Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
    
    
    
    
    
    
    
    
    
    


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  7 00:50:56 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 6 Sep 2019 15:50:56 -0700
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <3B04ABDD-5346-41E5-8498-D946D4BE981C@njhealth.org>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
 <89122b4f-f76c-8cbb-1217-bbc7f8a21c12@comcast.net>
 <B3B78180-7D63-458C-A342-D63DFAAF2FE5@gmail.com>
 <3B04ABDD-5346-41E5-8498-D946D4BE981C@njhealth.org>
Message-ID: <CAGxFJbT1tmOsNknDcWTfmLujBNCpw_mb62GYT5rCEppQdZBZSg@mail.gmail.com>

It is time to end these queries and start your homework by consulting the
references you have already been given. Wickham's goes into all of this;
the R Language Definition that ships with R covers all of your questions
and more in detail; and numerous online references and tutorials -- A
search on "what is a promise in R" brings up numerous resources, for
example -- are available.

This list is for help. It is not a substitute for studying on your own.

Cheers,
Bert

On Fri, Sep 6, 2019 at 3:15 PM Golden, Shelby <GoldenS at njhealth.org> wrote:

> Afternoon, Peter,
>
> Thank you for your concise but informative reply, and for a link to the
> source code. These complex concepts do answer my question spot on, so thank
> you for taking the time to put them all together and summarizing them for
> me.
>
> Is the standard nomenclature for arguments in function calls "promises"? I
> would like to look into this concept further. If there are other concepts
> you think I should look into further too, I would be happy to include those
> as well.
>
> Regards,
> Shelby
>
>
> ?On 9/6/19, 4:02 PM, "peter dalgaard" <pdalgd at gmail.com> wrote:
>
>     Um... Let's get the concepts straight:
>
>     The "function" function doesn't evaluate anything. It just takes the
> list of formal arguments (including default expressions), the function
> body, and the current evaluation environment, and stiches them together
> into a function object, known as a "closure".
>
>     The action happens when a function is _called_. Then the actual
> arguments are combined with the formals, and the body expression is
> evaluated. You will find the source code for this in src/main/eval.c. It is
> a pretty complex beast, but the essential point for the present discussion
> is that actual arguments in function calls are passed in the form of
> so-called promises. These contain the expression passed, so that
> substitute() can extract it. It also enables lazy evaluation: putting off
> argument evaluation until the value is actually needed (possibly never).
>
>     -pd
>
>     > On 6 Sep 2019, at 23:10 , David Winsemius <dwinsemius at comcast.net>
> wrote:
>     >
>     >
>     > On 9/6/19 1:07 PM, Golden, Shelby wrote:
>     >> Thank you all for your reply. I should clarify, that I am looking
> to understand why the keyword function can take a logical argument (eg:
> x<4) and use that later inside the function's definition for logical
> evaluations.
>     >>
>     >> Consider this example, which is a simplification of
> getAnywhere(subset.data.frame):
>     >> x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9,
> 10))
>     >> test <- function(x, logic){
>     >>  e <- substitute(logic)
>     >>  r <- eval(e, x, parent.frame())
>     >>  r[r]
>     >> }
>     >
>     > x<4 is not really a logical argument in that context. It is rather
> an expression and will remain an expression until it needs to be evaluated.
> See this even simpler example:
>     >
>     >
>     >  test <- function(x, logic, ... ){
>     >      e <- deparse( substitute(logic))
>     >      #r <- eval(e, x, parent.frame())
>     >      e
>     >  }
>     >  test(4, x<4)
>     > #[1] "x < 4"
>     >
>     >
>     >  test(4, is.logical(x < 4) )
>     > [1] "is.logical(x < 4)"
>     >
>     >
>     > Some of this you have already been told, but appears necessary to
> repeat. Expressions given to `function` are not necessarily evaluated. They
> will be evaluated if assigned names.
>     >
>     >
>     > test(4, zed = is.logical(x < 4) )
>     > #[1] ""
>     >
>     > The function()-function will parse the contents of the parentheses
> for number of arguments and for parse()-ability. It will evaluate named
> arguments created with "=". In the context of parsing the formals of a
> function the "=" operator is different than the "<-" function.
>     >
>     > The substitute function will not evaluate (since in the language of
> R operations it is "special"), but rather checks that the expression can be
> parsed by R's rules, i.e. is a valid parse tree. `deparse` returns the
> original character representation.
>     >
>     > --
>     >
>     > David
>     >
>     >
>     >>
>     >> Shelby
>     >>
>     >> On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <
> r-help-bounces at r-project.org on behalf of rmh at temple.edu> wrote:
>     >>
>     >>     You might also want to look at the codetools package, for
> example the
>     >>     showTree function " Prints a Lisp-style representation of R
>     >>     expression."
>     >>          > library(codetools)
>     >>          > showTree(quote(x %*% x))
>     >>     (%*% x x)
>     >>     > showTree(quote(a+b))
>     >>     (+ a b)
>     >>     > showTree(quote(y ~ a+b))
>     >>     (~ y (+ a b))
>     >>          On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <
> bgunter.4567 at gmail.com> wrote:
>     >>     >
>     >>     > The following may be of use (it gives the parse tree of the
> text):
>     >>     >
>     >>     > > z <- as.list(parse(text = "function(x)x %*% x"))
>     >>     > > z[[1]]
>     >>     > function(x) x %*% x
>     >>     > > z[[c(1,1)]]
>     >>     > `function`
>     >>     > > z[[c(1,2)]]
>     >>     > $x
>     >>     > > z[[c(1,3)]]
>     >>     > x %*% x
>     >>     > > z[[c(1,3,1)]]
>     >>     > `%*%`
>     >>     > > z[[c(1,3,2)]]
>     >>     > x
>     >>     > > z[[c(1,3,3)]]
>     >>     > x
>     >>     >
>     >>     >
>     >>     > Bert Gunter
>     >>     >
>     >>     >
>     >>     >
>     >>     > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <
> szwjf08 at gmail.com> wrote:
>     >>     >
>     >>     > > If you are looking for an R code parser, I think the
> `parse` and `eval`
>     >>     > > function might be a good start point. See the example below.
>     >>     > >
>     >>     > > > parse(text="function(x)message(x)")
>     >>     > > expression(function(x)message(x))
>     >>     > > > eval(parse(text="function(x)message(x)"))
>     >>     > > function(x)message(x)
>     >>     > >
>     >>     > > Best,
>     >>     > > Jiefei
>     >>     > >
>     >>     > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <
> GoldenS at njhealth.org>
>     >>     > > wrote:
>     >>     > >
>     >>     > >> Hello Bert,
>     >>     > >>
>     >>     > >> Thank you for the reply and your clarifications. Yes, it
> might be helpful
>     >>     > >> to look into R?s formal grammar to see how ?function?
> parses input to
>     >>     > >> delegate correct syntax. Is that accessible online?
>     >>     > >>
>     >>     > >> Thank you,
>     >>     > >> Shelby
>     >>     > >>
>     >>     > >>
>     >>     > >> From: Bert Gunter <bgunter.4567 at gmail.com>
>     >>     > >> Date: Friday, September 6, 2019 at 10:44 AM
>     >>     > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
>     >>     > >> Cc: "r-help at R-project.org" <r-help at r-project.org>,
> "Gillenwater, Lucas" <
>     >>     > >> GILLENWATERL at NJHEALTH.ORG>
>     >>     > >> Subject: Re: [R] [R-devel] Source Code for function
>     >>     > >>
>     >>     > >> 1. This is a plain text list; all html is stripped. So
> there is no red
>     >>     > >> highlighting.
>     >>     > >>
>     >>     > >> 2. There is no "source code" for "function" -- it is a
> reserved keyword.
>     >>     > >> Or are you looking for R's formal grammar -- e.g. how it
> parses input to
>     >>     > >> determine correct syntax?
>     >>     > >>
>     >>     > >>
>     >>     > >>
>     >>     > >> Bert Gunter
>     >>     > >>
>     >>     > >> "The trouble with having an open mind is that people keep
> coming along
>     >>     > >> and sticking things into it."
>     >>     > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
> strip )
>     >>     > >>
>     >>     > >>
>     >>     > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <
> GoldenS at njhealth.org
>     >>     > >> <mailto:GoldenS at njhealth.org>> wrote:
>     >>     > >> Hi all,
>     >>     > >>
>     >>     > >> I have been attempting to access the source code for the
> keyword
>     >>     > >> ?function? to better understand how it assigns and stores
> logical inputs,
>     >>     > >> like in the subset() [base] function. Does anyone know how
> I can access the
>     >>     > >> source code for this?
>     >>     > >>
>     >>     > >> For example, if I have
>     >>     > >> norm <- function(x){
>     >>     > >>       sqrt(x%*%x))
>     >>     > >> }
>     >>     > >> I am looking for the source code for the ?function?
> portion, highlighted
>     >>     > >> in red.
>     >>     > >>
>     >>     > >> Thank you for your time and assistance,
>     >>     > >> Shelby Golden
>     >>     > >> Lab Researcher Technician
>     >>     > >> Dr. Russell Bowler?s Lab
>     >>     > >> Department of Medicine
>     >>     > >> National Jewish Health in Denver, CO
>     >>     > >> Phone: (303) 270-2598
>     >>     > >>
>     >>     > >> NOTICE: This email message is for the sole use of the
> intended
>     >>     > >> recipient(s) and may contain confidential and privileged
> information. Any
>     >>     > >> unauthorized review, use, disclosure or distribution is
> prohibited. If you
>     >>     > >> are not the intended recipient, please contact the sender
> by reply email
>     >>     > >> and destroy all copies of the original message.
>     >>     > >>         [[alternative HTML version deleted]]
>     >>     > >>
>     >>     > >> ______________________________________________
>     >>     > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing
> list -- To
>     >>     > >> UNSUBSCRIBE and more, see
>     >>     > >> https://stat.ethz.ch/mailman/listinfo/r-help<
>     >>     > >>
> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
>     >>     > >> >
>     >>     > >> PLEASE do read the posting guide
>     >>     > >> http://www.R-project.org/posting-guide.html<
>     >>     > >>
> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
>     >>     > >> >
>     >>     > >> and provide commented, minimal, self-contained,
> reproducible code.
>     >>     > >>
>     >>     > >>         [[alternative HTML version deleted]]
>     >>     > >>
>     >>     > >> ______________________________________________
>     >>     > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more, see
>     >>     > >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >>     > >> PLEASE do read the posting guide
>     >>     > >> http://www.R-project.org/posting-guide.html
>     >>     > >> and provide commented, minimal, self-contained,
> reproducible code.
>     >>     > >>
>     >>     > >
>     >>     >
>     >>     >         [[alternative HTML version deleted]]
>     >>     >
>     >>     > ______________________________________________
>     >>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> more, see
>     >>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     >>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >>     > and provide commented, minimal, self-contained, reproducible
> code.
>     >>          ______________________________________________
>     >>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
>     >>     https://stat.ethz.ch/mailman/listinfo/r-help
>     >>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >>     and provide commented, minimal, self-contained, reproducible
> code.
>     >>
>     >>
>     >> NOTICE: This email message is for the sole use of the intended
> recipient(s) and may contain confidential and privileged information. Any
> unauthorized review, use, disclosure or distribution is prohibited. If you
> are not the intended recipient, please contact the sender by reply email
> and destroy all copies of the original message.
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     --
>     Peter Dalgaard, Professor,
>     Center for Statistics, Copenhagen Business School
>     Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>     Phone: (+45)38153501
>     Office: A 4.23
>     Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From |redgoud@rz|@n @end|ng |rom gm@||@com  Sat Sep  7 11:58:20 2019
From: |redgoud@rz|@n @end|ng |rom gm@||@com (farshad goudarzian)
Date: Sat, 7 Sep 2019 02:58:20 -0700
Subject: [R] R bar chart
Message-ID: <CA+4txF8hVdeQ8dV7_QiKr=4nguC8u0uX5Gwm-7XmXDv8MNj5fw@mail.gmail.com>

Hello.
Here I attach a microsoft excel data base file and plot image to illustrate
my question.



my code:

ggplot(concretedata, aes(Company, Concrete, fill=
Type))+geom_bar(stat="identity")

As per the attachment plot, the bar chart for different parameters
(Concrete, Company and Type) is presented, but I dont know how to label
each area of my bar plot.

for example, the bottom left area of my chart should show the sum of
concrete provide by company A with type of C30 (16000 m3)
 or the top right area of my plot should present the total concrete volume
of company B with type of C25. (13000 m3)
but I dont know how to show the total concrete of each area

I know  the command is "geom_text", but it doesnt show the sum of concrete
volume, it shows all the numbers of concrete on top of each other.

thanks
best regards

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Sep  7 14:55:31 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 7 Sep 2019 13:55:31 +0100
Subject: [R] R bar chart
In-Reply-To: <CA+4txF8hVdeQ8dV7_QiKr=4nguC8u0uX5Gwm-7XmXDv8MNj5fw@mail.gmail.com>
References: <CA+4txF8hVdeQ8dV7_QiKr=4nguC8u0uX5Gwm-7XmXDv8MNj5fw@mail.gmail.com>
Message-ID: <1d54960b-59a6-739c-a83b-c0c8c32fe7c9@sapo.pt>

Hello,

There is no attached file, R-help is doesn't allow many file types.
Try reposting with the extension .txt or post the output of


dput(head(dataset, 20))


directly in your e-mail.

Hope this helps,

Rui Barradas

?s 10:58 de 07/09/19, farshad goudarzian escreveu:
> Hello.
> Here I attach a microsoft excel data base file and plot image to illustrate
> my question.
> 
> 
> 
> my code:
> 
> ggplot(concretedata, aes(Company, Concrete, fill=
> Type))+geom_bar(stat="identity")
> 
> As per the attachment plot, the bar chart for different parameters
> (Concrete, Company and Type) is presented, but I dont know how to label
> each area of my bar plot.
> 
> for example, the bottom left area of my chart should show the sum of
> concrete provide by company A with type of C30 (16000 m3)
>   or the top right area of my plot should present the total concrete volume
> of company B with type of C25. (13000 m3)
> but I dont know how to show the total concrete of each area
> 
> I know  the command is "geom_text", but it doesnt show the sum of concrete
> volume, it shows all the numbers of concrete on top of each other.
> 
> thanks
> best regards
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jte||er|@@rproject @end|ng |rom gm@||@com  Sat Sep  7 17:58:19 2019
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Sat, 7 Sep 2019 17:58:19 +0200
Subject: [R] How to use Conda with R + RStudio Server
Message-ID: <CAJXDcw1efRXetQMvBLGu3r1eivw6QL=swNK2yAPJB4suDpiKsA@mail.gmail.com>

Dear R-help Mailing List:

For reproducibility, I want to use Conda + R (IRkernel), which will allow
me to have within the same machine different "environments", with different
versions of R installed, and specific package versions:

http://know.continuum.io/rs/387-XNW-688/images/conda-cheatsheet.pdf

As a result, I could execute in my command prompt:

>> conda activate r_environment_A

>> jupyter lab

And develop in a R environment with a fixed set of packages, and anyone
with my same environment (Can be exported though a `conda env export` and
created though a `conda create`) could reproduce the same analyses in their
machine:

https://docs.anaconda.com/anaconda/user-guide/tasks/using-r-language/

https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/


However, instead of using Jupyter Lab, I would like to use "RStudio Server"
within my conda environment, but this is far more complicated, as I have
not been able to install it in an easy way, so that, changing my conda
environment, also changes my RStudio Server Environment:

https://www.rstudio.com/products/rstudio/download-server/

Anyone has any gess on how to do it?

Thank you!

Juan Telleria

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  7 19:48:49 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Sep 2019 10:48:49 -0700
Subject: [R] How to use Conda with R + RStudio Server
In-Reply-To: <CAJXDcw1efRXetQMvBLGu3r1eivw6QL=swNK2yAPJB4suDpiKsA@mail.gmail.com>
References: <CAJXDcw1efRXetQMvBLGu3r1eivw6QL=swNK2yAPJB4suDpiKsA@mail.gmail.com>
Message-ID: <0D71DB1F-4CF2-4932-B7D3-7F6B1055EB82@dcn.davis.ca.us>

You may get a response here (including my poorly-informed one) but this is off topic (_do read the Posting Guide_) so you are basically barking into the darkness here. You should be asking in the RStudio community forum.

As far as I am aware you have to run your RSS in a single environment, so conda is a poor match for that IDE. But hey... I could be wrong... go ask an expert.

On September 7, 2019 8:58:19 AM PDT, Juan Telleria Ruiz de Aguirre <jtelleria.rproject at gmail.com> wrote:
>Dear R-help Mailing List:
>
>For reproducibility, I want to use Conda + R (IRkernel), which will
>allow
>me to have within the same machine different "environments", with
>different
>versions of R installed, and specific package versions:
>
>http://know.continuum.io/rs/387-XNW-688/images/conda-cheatsheet.pdf
>
>As a result, I could execute in my command prompt:
>
>>> conda activate r_environment_A
>
>>> jupyter lab
>
>And develop in a R environment with a fixed set of packages, and anyone
>with my same environment (Can be exported though a `conda env export`
>and
>created though a `conda create`) could reproduce the same analyses in
>their
>machine:
>
>https://docs.anaconda.com/anaconda/user-guide/tasks/using-r-language/
>
>https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/
>
>
>However, instead of using Jupyter Lab, I would like to use "RStudio
>Server"
>within my conda environment, but this is far more complicated, as I
>have
>not been able to install it in an easy way, so that, changing my conda
>environment, also changes my RStudio Server Environment:
>
>https://www.rstudio.com/products/rstudio/download-server/
>
>Anyone has any gess on how to do it?
>
>Thank you!
>
>Juan Telleria
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@|kremk @end|ng |rom gm@||@com  Sat Sep  7 20:46:47 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sat, 7 Sep 2019 13:46:47 -0500
Subject: [R] new_index
Message-ID: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>

Hi All,

I have two data frames   with thousand  rows  and several columns. My
samples of the data frames are shown below

dat1 <-read.table(text="ID, x, y, z
ID , x, y, z
A, 10,  34, 12
B, 25,  42, 18
C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)

dat2 <-read.table(text="ID, x, y, z
ID, weight
A,  0.25
B,  0.42
C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)

My goal is to  create an index value  for each ID  by mutliplying the
first row of dat1 by the second  column of dat2.

  (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
  (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
  (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03

The  desired out put is
dat3
ID, Index
A 24.58
B  35.59
C  19.03

How do I do it in an efficent way?

Thank you,


From v@|kremk @end|ng |rom gm@||@com  Sat Sep  7 21:23:40 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sat, 7 Sep 2019 14:23:40 -0500
Subject: [R] new_index
In-Reply-To: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
References: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
Message-ID: <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>

Hi  all

Correction for my previous posting.
dat2 should be read as
dat2 <-read.table(text="ID, weight
A,  0.25
B,  0.42
C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)

On Sat, Sep 7, 2019 at 1:46 PM Val <valkremk at gmail.com> wrote:
>
> Hi All,
>
> I have two data frames   with thousand  rows  and several columns. My
> samples of the data frames are shown below
>
> dat1 <-read.table(text="ID, x, y, z
> ID , x, y, z
> A, 10,  34, 12
> B, 25,  42, 18
> C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>
> dat2 <-read.table(text="ID, x, y, z
> ID, weight
> A,  0.25
> B,  0.42
> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>
> My goal is to  create an index value  for each ID  by mutliplying the
> first row of dat1 by the second  column of dat2.
>
>   (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
>   (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
>   (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03
>
> The  desired out put is
> dat3
> ID, Index
> A 24.58
> B  35.59
> C  19.03
>
> How do I do it in an efficent way?
>
> Thank you,


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  7 21:38:12 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Sep 2019 12:38:12 -0700
Subject: [R] new_index
In-Reply-To: <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>
References: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
 <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>
Message-ID: <CAGxFJbTXtO4fs515X31g6R+Hyyvni_XU0dQF=FPQyBNF11r6rQ@mail.gmail.com>

dat1 is wrong also. It should read:

dat1 <-read.table(text="ID, x, y, z
                  A, 10,  34, 12
                  B, 25,  42, 18
                  C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)

Is this a homework problem?  This list has a no homework policy.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 7, 2019 at 12:24 PM Val <valkremk at gmail.com> wrote:

> Hi  all
>
> Correction for my previous posting.
> dat2 should be read as
> dat2 <-read.table(text="ID, weight
> A,  0.25
> B,  0.42
> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>
> On Sat, Sep 7, 2019 at 1:46 PM Val <valkremk at gmail.com> wrote:
> >
> > Hi All,
> >
> > I have two data frames   with thousand  rows  and several columns. My
> > samples of the data frames are shown below
> >
> > dat1 <-read.table(text="ID, x, y, z
> > ID , x, y, z
> > A, 10,  34, 12
> > B, 25,  42, 18
> > C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
> >
> > dat2 <-read.table(text="ID, x, y, z
> > ID, weight
> > A,  0.25
> > B,  0.42
> > C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
> >
> > My goal is to  create an index value  for each ID  by mutliplying the
> > first row of dat1 by the second  column of dat2.
> >
> >   (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
> >   (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
> >   (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03
> >
> > The  desired out put is
> > dat3
> > ID, Index
> > A 24.58
> > B  35.59
> > C  19.03
> >
> > How do I do it in an efficent way?
> >
> > Thank you,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Sep  7 23:24:46 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 7 Sep 2019 22:24:46 +0100
Subject: [R] new_index
In-Reply-To: <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>
References: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
 <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>
Message-ID: <7917f0f5-204a-cde3-95be-b46c3fcb67c0@sapo.pt>

Hello,

The problem itself is simple:

i <- match(dat1$ID, dat2$ID)
colSums(t(dat1[i, -1])*dat2[i, -1])
#    1     2     3
#24.58 35.59 17.10


But both dat1 and dat2 are wrong and can be read with read.csv


dat1 <- read.csv(text = "
ID , x, y, z
A, 10,  34, 12
B, 25,  42, 18
C, 14,  20,  8 ", stringsAsFactors = FALSE)

dat2 <- read.csv(text="
ID, weight
A,  0.25
B,  0.42
C,  0.65 ", stringsAsFactors = FALSE)


Simpler, no?


Hope this helps,

Rui Barradas


?s 20:23 de 07/09/19, Val escreveu:
> Hi  all
> 
> Correction for my previous posting.
> dat2 should be read as
> dat2 <-read.table(text="ID, weight
> A,  0.25
> B,  0.42
> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
> 
> On Sat, Sep 7, 2019 at 1:46 PM Val <valkremk at gmail.com> wrote:
>>
>> Hi All,
>>
>> I have two data frames   with thousand  rows  and several columns. My
>> samples of the data frames are shown below
>>
>> dat1 <-read.table(text="ID, x, y, z
>> ID , x, y, z
>> A, 10,  34, 12
>> B, 25,  42, 18
>> C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>>
>> dat2 <-read.table(text="ID, x, y, z
>> ID, weight
>> A,  0.25
>> B,  0.42
>> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>>
>> My goal is to  create an index value  for each ID  by mutliplying the
>> first row of dat1 by the second  column of dat2.
>>
>>    (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
>>    (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
>>    (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03
>>
>> The  desired out put is
>> dat3
>> ID, Index
>> A 24.58
>> B  35.59
>> C  19.03
>>
>> How do I do it in an efficent way?
>>
>> Thank you,
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep  8 00:10:04 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Sep 2019 15:10:04 -0700
Subject: [R] new_index
In-Reply-To: <CAGxFJbTXtO4fs515X31g6R+Hyyvni_XU0dQF=FPQyBNF11r6rQ@mail.gmail.com>
References: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
 <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>
 <CAGxFJbTXtO4fs515X31g6R+Hyyvni_XU0dQF=FPQyBNF11r6rQ@mail.gmail.com>
Message-ID: <6EAE2A15-1F53-49FD-9CCA-8AF2CB6AB89F@dcn.davis.ca.us>

Val has been posting to this list for almost a decade [1] so seems unlikely to be a student... but in all this time has yet to figure out how to post in plain text to avoid corruption of code on this plain text mailing list. The ability to generate small examples has improved, though execution still seems hazy. Why is there an ID column in dat2 at all?

Try

dat3 <- dat1[ 1,, drop=FALSE ]
dat3$Index <- as.matrix( dat1[ -1 ] ) %*% dat2$weight

[1] https://stat.ethz.ch/pipermail/r-help/2010-March/233533.html

On September 7, 2019 12:38:12 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>dat1 is wrong also. It should read:
>
>dat1 <-read.table(text="ID, x, y, z
>                  A, 10,  34, 12
>                  B, 25,  42, 18
>               C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>
>Is this a homework problem?  This list has a no homework policy.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sat, Sep 7, 2019 at 12:24 PM Val <valkremk at gmail.com> wrote:
>
>> Hi  all
>>
>> Correction for my previous posting.
>> dat2 should be read as
>> dat2 <-read.table(text="ID, weight
>> A,  0.25
>> B,  0.42
>> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>>
>> On Sat, Sep 7, 2019 at 1:46 PM Val <valkremk at gmail.com> wrote:
>> >
>> > Hi All,
>> >
>> > I have two data frames   with thousand  rows  and several columns.
>My
>> > samples of the data frames are shown below
>> >
>> > dat1 <-read.table(text="ID, x, y, z
>> > ID , x, y, z
>> > A, 10,  34, 12
>> > B, 25,  42, 18
>> > C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>> >
>> > dat2 <-read.table(text="ID, x, y, z
>> > ID, weight
>> > A,  0.25
>> > B,  0.42
>> > C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>> >
>> > My goal is to  create an index value  for each ID  by mutliplying
>the
>> > first row of dat1 by the second  column of dat2.
>> >
>> >   (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
>> >   (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
>> >   (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03
>> >
>> > The  desired out put is
>> > dat3
>> > ID, Index
>> > A 24.58
>> > B  35.59
>> > C  19.03
>> >
>> > How do I do it in an efficent way?
>> >
>> > Thank you,
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Sun Sep  8 00:17:13 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Sat, 7 Sep 2019 15:17:13 -0700
Subject: [R] Fwd:  new_index
In-Reply-To: <CAA99HCy-p9vVAk4ik2gv_K4nvW8MfEG9CdjrM9kHH5q3jRhXTw@mail.gmail.com>
References: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
 <CAA99HCy-p9vVAk4ik2gv_K4nvW8MfEG9CdjrM9kHH5q3jRhXTw@mail.gmail.com>
Message-ID: <CAA99HCzrVaTHcuuUx1WpTOTUo5DtAZaz9KcYziG1wALLChu7Gg@mail.gmail.com>

Hi Val, see below:

> dat1 <-read.table(text="ID, x, y, z
+ A, 10,  34, 12
+ B, 25,  42, 18
+ C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>
> dat2 <-read.table(text="ID, weight
+ A,  0.25
+ B,  0.42
+ C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>
> dat3 <- data.frame(ID = dat1[,1], Index = apply(dat1[,-1], 1, FUN= function(x) {sum(x*dat2[,2])} ), stringsAsFactors=F)
> dat3
  ID Index
1  A 24.58
2  B 35.59
3  C 17.10
>
> str(dat3)
'data.frame': 3 obs. of  2 variables:
 $ ID   : chr  "A" "B" "C"
 $ Index: num  24.6 35.6 17.1
>

The first two results "A" and "B" are identical to your example, but
your math in "C" appears a little off.

HTH, Bill.

W. Michels, Ph.D.

On Sat, Sep 7, 2019 at 11:47 AM Val <valkremk at gmail.com> wrote:
>
> Hi All,
>
> I have two data frames   with thousand  rows  and several columns. My
> samples of the data frames are shown below
>
> dat1 <-read.table(text="ID, x, y, z
> ID , x, y, z
> A, 10,  34, 12
> B, 25,  42, 18
> C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>
> dat2 <-read.table(text="ID, x, y, z
> ID, weight
> A,  0.25
> B,  0.42
> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>
> My goal is to  create an index value  for each ID  by mutliplying the
> first row of dat1 by the second  column of dat2.
>
>   (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
>   (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
>   (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03
>
> The  desired out put is
> dat3
> ID, Index
> A 24.58
> B  35.59
> C  19.03
>
> How do I do it in an efficent way?
>
> Thank you,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Sun Sep  8 06:03:37 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sat, 7 Sep 2019 23:03:37 -0500
Subject: [R] new_index
In-Reply-To: <6EAE2A15-1F53-49FD-9CCA-8AF2CB6AB89F@dcn.davis.ca.us>
References: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
 <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>
 <CAGxFJbTXtO4fs515X31g6R+Hyyvni_XU0dQF=FPQyBNF11r6rQ@mail.gmail.com>
 <6EAE2A15-1F53-49FD-9CCA-8AF2CB6AB89F@dcn.davis.ca.us>
Message-ID: <CAJOiR6bNQjegLnmzP6kXNz9zr3M8LU96+=cm=4Wsr=wq7=4ucQ@mail.gmail.com>

Thank you Jeff and all.   I wish to go back to my student life.
ID  is not  necessary in  dat2, sorry for that.

On Sat, Sep 7, 2019 at 5:10 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Val has been posting to this list for almost a decade [1] so seems unlikely to be a student... but in all this time has yet to figure out how to post in plain text to avoid corruption of code on this plain text mailing list. The ability to generate small examples has improved, though execution still seems hazy. Why is there an ID column in dat2 at all?
>
> Try
>
> dat3 <- dat1[ 1,, drop=FALSE ]
> dat3$Index <- as.matrix( dat1[ -1 ] ) %*% dat2$weight
>
> [1] https://stat.ethz.ch/pipermail/r-help/2010-March/233533.html
>
> On September 7, 2019 12:38:12 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >dat1 is wrong also. It should read:
> >
> >dat1 <-read.table(text="ID, x, y, z
> >                  A, 10,  34, 12
> >                  B, 25,  42, 18
> >               C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
> >
> >Is this a homework problem?  This list has a no homework policy.
> >
> >Cheers,
> >Bert
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Sat, Sep 7, 2019 at 12:24 PM Val <valkremk at gmail.com> wrote:
> >
> >> Hi  all
> >>
> >> Correction for my previous posting.
> >> dat2 should be read as
> >> dat2 <-read.table(text="ID, weight
> >> A,  0.25
> >> B,  0.42
> >> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
> >>
> >> On Sat, Sep 7, 2019 at 1:46 PM Val <valkremk at gmail.com> wrote:
> >> >
> >> > Hi All,
> >> >
> >> > I have two data frames   with thousand  rows  and several columns.
> >My
> >> > samples of the data frames are shown below
> >> >
> >> > dat1 <-read.table(text="ID, x, y, z
> >> > ID , x, y, z
> >> > A, 10,  34, 12
> >> > B, 25,  42, 18
> >> > C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
> >> >
> >> > dat2 <-read.table(text="ID, x, y, z
> >> > ID, weight
> >> > A,  0.25
> >> > B,  0.42
> >> > C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
> >> >
> >> > My goal is to  create an index value  for each ID  by mutliplying
> >the
> >> > first row of dat1 by the second  column of dat2.
> >> >
> >> >   (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
> >> >   (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
> >> >   (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03
> >> >
> >> > The  desired out put is
> >> > dat3
> >> > ID, Index
> >> > A 24.58
> >> > B  35.59
> >> > C  19.03
> >> >
> >> > How do I do it in an efficent way?
> >> >
> >> > Thank you,
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep  8 11:51:12 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Sep 2019 10:51:12 +0100
Subject: [R] new_index
In-Reply-To: <6EAE2A15-1F53-49FD-9CCA-8AF2CB6AB89F@dcn.davis.ca.us>
References: <CAJOiR6Z2pDcPd0fzvkSQdwJhqWobRDAFxw1kLhrZwTEZez+a-w@mail.gmail.com>
 <CAJOiR6bC+TMm8zq=470BsmGFKVu0P912d4C1aJzfpA-1SeKH0w@mail.gmail.com>
 <CAGxFJbTXtO4fs515X31g6R+Hyyvni_XU0dQF=FPQyBNF11r6rQ@mail.gmail.com>
 <6EAE2A15-1F53-49FD-9CCA-8AF2CB6AB89F@dcn.davis.ca.us>
Message-ID: <974ea9a1-2e34-6d86-9481-5ac7d95f0822@sapo.pt>

Hello,

Bert:

Quoting Jeff, "Val has been posting to this list for almost a decade". I 
didn't know about the "decade" part (didn't look it up) but that's why I 
answered the question.

Val:

It's not that hard to run the code you post *before* posting it. Please.

Rui Barradas

?s 23:10 de 07/09/19, Jeff Newmiller escreveu:
> Val has been posting to this list for almost a decade [1] so seems unlikely to be a student... but in all this time has yet to figure out how to post in plain text to avoid corruption of code on this plain text mailing list. The ability to generate small examples has improved, though execution still seems hazy. Why is there an ID column in dat2 at all?
> 
> Try
> 
> dat3 <- dat1[ 1,, drop=FALSE ]
> dat3$Index <- as.matrix( dat1[ -1 ] ) %*% dat2$weight
> 
> [1] https://stat.ethz.ch/pipermail/r-help/2010-March/233533.html
> 
> On September 7, 2019 12:38:12 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> dat1 is wrong also. It should read:
>>
>> dat1 <-read.table(text="ID, x, y, z
>>                   A, 10,  34, 12
>>                   B, 25,  42, 18
>>                C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>>
>> Is this a homework problem?  This list has a no homework policy.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Sep 7, 2019 at 12:24 PM Val <valkremk at gmail.com> wrote:
>>
>>> Hi  all
>>>
>>> Correction for my previous posting.
>>> dat2 should be read as
>>> dat2 <-read.table(text="ID, weight
>>> A,  0.25
>>> B,  0.42
>>> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>>>
>>> On Sat, Sep 7, 2019 at 1:46 PM Val <valkremk at gmail.com> wrote:
>>>>
>>>> Hi All,
>>>>
>>>> I have two data frames   with thousand  rows  and several columns.
>> My
>>>> samples of the data frames are shown below
>>>>
>>>> dat1 <-read.table(text="ID, x, y, z
>>>> ID , x, y, z
>>>> A, 10,  34, 12
>>>> B, 25,  42, 18
>>>> C, 14,  20,  8 ",sep=",",header=TRUE,stringsAsFactors=F)
>>>>
>>>> dat2 <-read.table(text="ID, x, y, z
>>>> ID, weight
>>>> A,  0.25
>>>> B,  0.42
>>>> C,  0.65 ",sep=",",header=TRUE,stringsAsFactors=F)
>>>>
>>>> My goal is to  create an index value  for each ID  by mutliplying
>> the
>>>> first row of dat1 by the second  column of dat2.
>>>>
>>>>    (10*0.25 ) + (34*0.42) + (12*0.65)=  24.58
>>>>    (25*0.25 ) + (42*0.42) + (18*0.65)=  35.59
>>>>    (14*0.25 ) + (20*0.42) + (  8*0.65)=  19.03
>>>>
>>>> The  desired out put is
>>>> dat3
>>>> ID, Index
>>>> A 24.58
>>>> B  35.59
>>>> C  19.03
>>>>
>>>> How do I do it in an efficent way?
>>>>
>>>> Thank you,
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jb@rth1235 @end|ng |rom gm@||@com  Mon Sep  9 02:25:08 2019
From: jb@rth1235 @end|ng |rom gm@||@com (Josh B)
Date: Sun, 8 Sep 2019 20:25:08 -0400
Subject: [R] ggmap Question
Message-ID: <CAGi70XXAcwcFpG7=VvYYAbK6kTz_jKydNjEyvk_Jsmub5CPMkQ@mail.gmail.com>

Hello r-help,

My question is regarding specific coding in ggmap.

I am mapping radio telemetry detections of shorebirds using ggmap. I want
the map to depict a specific point (lat/lon of a telemetry tower) where the
bird was detected, as well as the following variables associated with that
lat/long: date of detection and the number of individuals detected on that
date.

To avoid masking detections, I would like to include a graduated point that
will change size based upon the number of individuals detected. The goal is
to show what date a bird was detected at a telemetry tower and how many
birds were detected at that telemetry, using a color scale and graduated
symbol.

My thought is to have the graduated color symbol stack on itself, larger
symbol on the bottom and the smallest on the top (or make them transparent
enough so symbols underneath others can be seen) . This way the number of
individuals detected at the telemetry towers and the date they were
detected are represented by one image. See link for example image
<https://i.stack.imgur.com/fROg6.png>.


Sample Data:

X motusTagID         ts recvLat recvLon recvProjID recvSiteName
speciesSci num.det num.id
1 1      24741 2018-01-01    51.3   -80.6          1     Moosonee Calidris
canutus       4      1
2 2      24743 2018-01-04    51.3   -80.6          1     Moosonee Calidris
canutus       4      1
3 3      24747 2018-01-04    51.3   -80.6          1     Moosonee Calidris
canutus       4      1
4 4      25089 2018-01-04    51.3   -80.6          1     Moosonee Calidris
canutus       8      1
5 5      24779 2018-01-25    51.3   -80.6          1     Moosonee Calidris
canutus       4      1
6 6      24746 2018-01-25    51.3   -80.6          1     Moosonee Calidris
canutus       4      1

Sample Code I have Tried:

See link to another source for a sample of the code I tried.

https://stackoverflow.com/questions/57618926/how-do-i-code-in-r-so-my-time-stamp-field-is-represented-by-a-color-scale-and-th?noredirect=1#comment101931264_57618926


Thank you.


*Joshua N. Barth*

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Sep  9 07:01:23 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 9 Sep 2019 17:01:23 +1200
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
Message-ID: <CABcYAd+zk-sLe41OvJSta41huDTY7PAS=Z_eJgqcscJCHtFfoQ@mail.gmail.com>

> I am looking to understand why the keyword function can take a logical
argument
> (eg: x<4) and use that later inside the function's definition for logical
evaluations

The "function" keyword does not take a logical argument.
Let me show you some parallels:

f <- function (x, y) {x+y}          # R
(set! f (lambda (x y) (+ x y)))     ; Scheme
f = (x, y) => { return x+y; };      // Javascript
f = (x, y) => { return x+y; };      // C#, given a suitable declaration for
f
f = (x, y) -> { return x+y; }       // Java, given a suitable declaration
for f.
lambda x y; x+y end -> f;           // Pop-2, older than the others.

In all of these,
  - there is something ('function', 'lambda', '=>', '->') that
    says "here is an anonymous function"
  - there is a list of zero or more parameters
  - there is a body which may contain statements and may also
    return a result.
The keyword in itself does nothing.  The compiler recognises the
construction and generates code for a procedure that is bound to
the environment where it is created, so that it can find variables
other than those in its parameter list.

When it comes to passing parameters to a function, there is
nothing special about logical expressions in any of these languages.

Now there *is* something about functions in R that is special.
The S language (which R is based on) is the only one I am familiar
with that combines two properties:
 - it is an imperative language with side effects to variables
 - it does not evaluate function arguments when they are passed
   but when they are first *used*.
An obvious reason for this is to allow plotting methods to construct
labels from their arguments and to allow model fitting methods to
remember the form of the model.

If you want argument evaluation delayed for any other reason, it is
probably better to pass a function.  See
> ?integrate
 -- the first argument is a function, not a general expression
> ?optim
 -- the second argument is a function, not a general expression
(That is, the argument in question is an expression whose value must
be a function, not an expression to be manipulated *textually* or as
a formula.)



On Sat, 7 Sep 2019 at 08:07, Golden, Shelby <GoldenS at njhealth.org> wrote:

> Thank you all for your reply. I should clarify, that I am looking to
> understand why the keyword function can take a logical argument (eg: x<4)
> and use that later inside the function's definition for logical evaluations.
>
> Consider this example, which is a simplification of
> getAnywhere(subset.data.frame):
> x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
> test <- function(x, logic){
>         e <- substitute(logic)
>         r <- eval(e, x, parent.frame())
>         r[r]
> }
>
>
> Shelby
>
>
> ?On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <
> r-help-bounces at r-project.org on behalf of rmh at temple.edu> wrote:
>
>     You might also want to look at the codetools package, for example the
>     showTree function " Prints a Lisp-style representation of R
>     expression."
>
>     > library(codetools)
>
>     > showTree(quote(x %*% x))
>     (%*% x x)
>     > showTree(quote(a+b))
>     (+ a b)
>     > showTree(quote(y ~ a+b))
>     (~ y (+ a b))
>
>     On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>     >
>     > The following may be of use (it gives the parse tree of the text):
>     >
>     > > z <- as.list(parse(text = "function(x)x %*% x"))
>     > > z[[1]]
>     > function(x) x %*% x
>     > > z[[c(1,1)]]
>     > `function`
>     > > z[[c(1,2)]]
>     > $x
>     > > z[[c(1,3)]]
>     > x %*% x
>     > > z[[c(1,3,1)]]
>     > `%*%`
>     > > z[[c(1,3,2)]]
>     > x
>     > > z[[c(1,3,3)]]
>     > x
>     >
>     >
>     > Bert Gunter
>     >
>     >
>     >
>     > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com>
> wrote:
>     >
>     > > If you are looking for an R code parser, I think the `parse` and
> `eval`
>     > > function might be a good start point. See the example below.
>     > >
>     > > > parse(text="function(x)message(x)")
>     > > expression(function(x)message(x))
>     > > > eval(parse(text="function(x)message(x)"))
>     > > function(x)message(x)
>     > >
>     > > Best,
>     > > Jiefei
>     > >
>     > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <
> GoldenS at njhealth.org>
>     > > wrote:
>     > >
>     > >> Hello Bert,
>     > >>
>     > >> Thank you for the reply and your clarifications. Yes, it might be
> helpful
>     > >> to look into R?s formal grammar to see how ?function? parses
> input to
>     > >> delegate correct syntax. Is that accessible online?
>     > >>
>     > >> Thank you,
>     > >> Shelby
>     > >>
>     > >>
>     > >> From: Bert Gunter <bgunter.4567 at gmail.com>
>     > >> Date: Friday, September 6, 2019 at 10:44 AM
>     > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
>     > >> Cc: "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater,
> Lucas" <
>     > >> GILLENWATERL at NJHEALTH.ORG>
>     > >> Subject: Re: [R] [R-devel] Source Code for function
>     > >>
>     > >> 1. This is a plain text list; all html is stripped. So there is
> no red
>     > >> highlighting.
>     > >>
>     > >> 2. There is no "source code" for "function" -- it is a reserved
> keyword.
>     > >> Or are you looking for R's formal grammar -- e.g. how it parses
> input to
>     > >> determine correct syntax?
>     > >>
>     > >>
>     > >>
>     > >> Bert Gunter
>     > >>
>     > >> "The trouble with having an open mind is that people keep coming
> along
>     > >> and sticking things into it."
>     > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>     > >>
>     > >>
>     > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <
> GoldenS at njhealth.org
>     > >> <mailto:GoldenS at njhealth.org>> wrote:
>     > >> Hi all,
>     > >>
>     > >> I have been attempting to access the source code for the keyword
>     > >> ?function? to better understand how it assigns and stores logical
> inputs,
>     > >> like in the subset() [base] function. Does anyone know how I can
> access the
>     > >> source code for this?
>     > >>
>     > >> For example, if I have
>     > >> norm <- function(x){
>     > >>       sqrt(x%*%x))
>     > >> }
>     > >> I am looking for the source code for the ?function? portion,
> highlighted
>     > >> in red.
>     > >>
>     > >> Thank you for your time and assistance,
>     > >> Shelby Golden
>     > >> Lab Researcher Technician
>     > >> Dr. Russell Bowler?s Lab
>     > >> Department of Medicine
>     > >> National Jewish Health in Denver, CO
>     > >> Phone: (303) 270-2598
>     > >>
>     > >> NOTICE: This email message is for the sole use of the intended
>     > >> recipient(s) and may contain confidential and privileged
> information. Any
>     > >> unauthorized review, use, disclosure or distribution is
> prohibited. If you
>     > >> are not the intended recipient, please contact the sender by
> reply email
>     > >> and destroy all copies of the original message.
>     > >>         [[alternative HTML version deleted]]
>     > >>
>     > >> ______________________________________________
>     > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> -- To
>     > >> UNSUBSCRIBE and more, see
>     > >> https://stat.ethz.ch/mailman/listinfo/r-help<
>     > >>
> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
>     > >> >
>     > >> PLEASE do read the posting guide
>     > >> http://www.R-project.org/posting-guide.html<
>     > >>
> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
>     > >> >
>     > >> and provide commented, minimal, self-contained, reproducible code.
>     > >>
>     > >>         [[alternative HTML version deleted]]
>     > >>
>     > >> ______________________________________________
>     > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > >> https://stat.ethz.ch/mailman/listinfo/r-help
>     > >> PLEASE do read the posting guide
>     > >> http://www.R-project.org/posting-guide.html
>     > >> and provide commented, minimal, self-contained, reproducible code.
>     > >>
>     > >
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
> NOTICE: This email message is for the sole use of the intended
> recipient(s) and may contain confidential and privileged information. Any
> unauthorized review, use, disclosure or distribution is prohibited. If you
> are not the intended recipient, please contact the sender by reply email
> and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Mon Sep  9 13:54:28 2019
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Mon, 9 Sep 2019 04:54:28 -0700
Subject: [R] how to split a column by tab ?
Message-ID: <CAMwU6B2CTJOHu6QVg3RvtfJhbNzFEPo5WWAk5uAaV0Oo4=ivsg@mail.gmail.com>

Hi R User,
I was trying to split a column by tabs, I tried to split with several ways,
but I could not split it. Is there any possibilities?

The data example and the code I used
daT1<-c("Column number             1    2    3    4    5    6    7    8
 9   10   10   10   10   10   10   10",
"comes from position       1    7    2    6    3    5   15    9    4    8
10   11   12   13   14   16"
)
daT2 <- data.frame(do.call('rbind',
strsplit(as.character(daT1),'\t',fixed=T)))
colnames(daT2)
daT2

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep  9 14:46:29 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 9 Sep 2019 13:46:29 +0100
Subject: [R] how to split a column by tab ?
In-Reply-To: <CAMwU6B2CTJOHu6QVg3RvtfJhbNzFEPo5WWAk5uAaV0Oo4=ivsg@mail.gmail.com>
References: <CAMwU6B2CTJOHu6QVg3RvtfJhbNzFEPo5WWAk5uAaV0Oo4=ivsg@mail.gmail.com>
Message-ID: <0269f600-167a-92bf-0cd1-2f91d9260404@sapo.pt>

Hello,

You could try a character class instead of one character (the tab char).
There are two character classes that you can try, [:blank:] and 
[:space:], see ?regex.

strsplit(as.character(daT1), "[[:blank:]]+")

Then form the final result. I have changed rbind to cbind, it seemed 
more appropriate (?).

s <- strsplit(as.character(daT1), "[[:blank:]]+")
x <- lapply(s, function(.s) .s[!grepl("[[:alpha:]]+", .s)])
daT3 <- as.data.frame(do.call(cbind, x))
daT3


Hope this helps,

Rui Barradas

?s 12:54 de 09/09/19, Marna Wagley escreveu:
> Hi R User,
> I was trying to split a column by tabs, I tried to split with several ways,
> but I could not split it. Is there any possibilities?
> 
> The data example and the code I used
> daT1<-c("Column number             1    2    3    4    5    6    7    8
>   9   10   10   10   10   10   10   10",
> "comes from position       1    7    2    6    3    5   15    9    4    8
> 10   11   12   13   14   16"
> )
> daT2 <- data.frame(do.call('rbind',
> strsplit(as.character(daT1),'\t',fixed=T)))
> colnames(daT2)
> daT2
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cc|@rk42 @end|ng |rom u|c@edu  Mon Sep  9 04:14:57 2019
From: cc|@rk42 @end|ng |rom u|c@edu (Chase Clark)
Date: Sun, 8 Sep 2019 21:14:57 -0500
Subject: [R] install.packages handles package vs package dependencies
 differently
Message-ID: <CAMXexTc_DiW-f9p4Q1-K4w2fGW8wcHkqdr-PtqQ=SOi0m7KofA@mail.gmail.com>

First post, please excuse any ignorance.

install.packages() seems to only respect install.packages(lib=) for
the specified package (in the below case {purrr}) and will ignore any
dependencies ({magrittr}, {rlang}) if they are found in any of the
directories in .libPaths() (e.g. R_LIBS).  The reason for the
inconsistency between the specified package and its dependencies seems
to be here:
https://github.com/wch/r-source/blob/d6c208e464d20adc6ce080ecfaaab4ccf3f06271/src/library/utils/R/packages2.R#L84-L88

Where, only for dependencies, .libPaths() is first checked for
installed.packages; but the same check doesn't occur for the specified
package.

Code to reproduce:
```
a <- file.path(tempdir(), "temp")
dir.create(a)
install.packages("purrr", dependencies = "Imports", lib = a)
list.dirs(a, recursive = FALSE)
```

Definition of 'lib' from ?install/packages : "character vector giving
the library directories where to install the packages. Recycled as
needed. If missing, defaults to the first element of .libPaths(). "

So, is this the desired behavior?  It would mean it's ?impossible? to
install a package to another location if it happens to be located
within R_LIBS; it also seems weird to have it work for the specified
package but not its dependencies.


Best,
Chase Clark
PhD Candidate
Murphy Lab
Center for Biomolecular Sciences
Department of Medicinal Chemistry and Pharmacognosy
University of Illinois at Chicago


From @ndre@@v||@r@@|v@rez @end|ng |rom u@c@e@  Mon Sep  9 08:27:27 2019
From: @ndre@@v||@r@@|v@rez @end|ng |rom u@c@e@ (=?Windows-1252?Q?VILAR_=C1LVAREZ_ANDREA?=)
Date: Mon, 9 Sep 2019 06:27:27 +0000
Subject: [R] Problems installing Dependences of my package
In-Reply-To: <DB7PR04MB4506253C72DB8FC8D0B8D7A6ADBA0@DB7PR04MB4506.eurprd04.prod.outlook.com>
References: <DB7PR04MB4506253C72DB8FC8D0B8D7A6ADBA0@DB7PR04MB4506.eurprd04.prod.outlook.com>
Message-ID: <DB7PR04MB45064E637BD44D45CF1A4088ADB70@DB7PR04MB4506.eurprd04.prod.outlook.com>


Hi,

I am writting because I am doing a package in R and I have some problems installing dependences which appear at DESCRIPTION file.

First of all, I am not sure about the difference between ?Depends? and ?Imports?, but I only use ?Depends?.
My problem is that my package is going to be used at different computers and for different persons so I want that when other person use my package, it can be able to check  if the necesary packages are installed and if they are not installed, the package must be able to install  them.
I supposed that this problem was solved including the necesary packages and their versions at ?Depends?. And now, I have another problem because the versions are usually indicated using ?>=?, for example: forecast (>=8.7) but I need to use exactly the versi?n 8.7 because sometimes when packages are updated, they lost some functions. But if I use ?<=? or ?==? and the package is update to versi?n 8.8, my package installation fail.
How can I solve this? If I use R normaly (outside my package), I can install older versions of other packages using devtools::install_version() so why when I indicate ? forecast (<=8.7)? at Depends on the DESCRIPTION file, R is not able to install an older version if a new one is avaliable?

Thanks in advance for your attention.

Best regards,

Andrea.


	[[alternative HTML version deleted]]


From rhotuser m@iii@g oii y@hoo@co@jp  Mon Sep  9 10:21:04 2019
From: rhotuser m@iii@g oii y@hoo@co@jp (rhotuser m@iii@g oii y@hoo@co@jp)
Date: Mon, 9 Sep 2019 17:21:04 +0900 (JST)
Subject: [R] =?utf-8?q?structure_of=E3=80=80NIRsoil?=
References: <1904106974.923567.1568017264760.JavaMail.yahoo.ref@jws702103.mail.ssk.yahoo.co.jp>
Message-ID: <1904106974.923567.1568017264760.JavaMail.yahoo@jws702103.mail.ssk.yahoo.co.jp>

Dear Sir,

After installing prospectr,?
> data(NIRsoil)> mode(NIRsoil)[1] "list">?
I am a beginner and the structure of ?NIRsoil? is complicated.

Judging from the explanation of NIRsoil (see below),?there are six elements: NT, Ciso, CEC, train, validation, spc.

Please tell me how to know the structure of such ?NIRsoil?.
When using mode (NIRsoil) , The answer is just a ?list?.
Is there a command or function "Detailstructure (NIRsoil)"?
> NIRsoil
.
.? ? ?spc.2494? spc.2496? spc.24981? ?0.3724227 0.3724588 0.37256772? ?0.3159643 0.3164802 0.31681803? ?0.3416802 0.3422180 0.34263164? ?0.3650448 0.3654987 0.36580555? ?0.3050233 0.3058226 0.30640076? ?0.3599009 0.3603650 0.36070207? ?0.3365467 0.3369826 0.33725788? ?0.3922267 0.3926329 0.39288209? ?0.3149452 0.3153307 0.315540410? 0.4951153 0.4954152 0.495766411? 0.3414548 0.3418657 0.342114012? 0.3314737 0.3319690 0.332336513? 0.4153854 0.4156993 0.416079614? 0.3311567 0.3316245 0.331926815? 0.3289777 0.3294281 0.329720616? 0.4268982 0.4274236 0.427819517? 0.3421552 0.3426531 0.342981518? 0.3452011 0.3457459 0.346121719? 0.3497368 0.3497175 0.349840320? 0.3896840 0.3901652 0.390537521? 0.4062244 0.4066894 0.407021322? 0.3792031 0.3796499 0.379960123? 0.3252305 0.3256037 0.325836624? 0.3427994 0.3431511 0.343363125? 0.3410443 0.3414203 0.341648926? 0.3947710 0.3952165 0.395562027? 0.2930943 0.2934901 0.293697728? 0.4138924 0.4144398 0.414861929? 0.2906964 0.2910948 0.291324130? 0.4000607 0.4004497 0.400749131? 0.3275807 0.3278961 0.328067632? 0.3343273 0.3347059 0.334947033? 0.2923162 0.2927208 0.292952534? 0.3181143 0.3184221 0.318574835? 0.3959161 0.3963806 0.396695436? 0.3412020 0.3415608 0.341737737? 0.3109980 0.3119904 0.312796538? 0.3452408 0.3457109 0.346040139? 0.2352630 0.2357922 0.236104440? 0.3731434 0.3735985 0.373948341? 0.3776968 0.3780733 0.378314142? 0.4279117 0.4278319 0.427811343? 0.3499106 0.3502492 0.350448044? 0.4060152 0.4064416 0.406781645? 0.4434104 0.4437352 0.444117646? 0.3106347 0.3111292 0.311479047? 0.3048005 0.3052686 0.305555748? 0.3074032 0.3078929 0.308188549? 0.3099467 0.3103620 0.310607950? 0.4140719 0.4140101 0.414070551? 0.3047789 0.3051992 0.305453152? 0.4372076 0.4371921 0.437301153? 0.3784582 0.3788292 0.379046054? 0.3070685 0.3074959 0.307739255? 0.3929690 0.3930495 0.393248956? 0.3104950 0.3109303 0.311175657? 0.3110389 0.3114884 0.311783658? 0.3561086 0.3565895 0.356935659? 0.2946499 0.2950254 0.295230760? 0.3396696 0.3402275 0.340604561? 0.4174463 0.4174852 0.417609462? 0.3838490 0.3845536 0.385175463? 0.4214520 0.4217800 0.422008564? 0.3136719 0.3141062 0.314410265? 0.3137282 0.3141668 0.314444466? 0.4341556 0.4341235 0.434172067? 0.3028214 0.3032053 0.303438768? 0.2929183 0.2933525 0.293613269? 0.2901444 0.2905667 0.290814470? 0.2926482 0.2930853 0.293328871? 0.3964101 0.3968658 0.397207272? 0.3205706 0.3209653 0.321186973? 0.2965653 0.2970253 0.297328574? 0.3271259 0.3274269 0.327623075? 0.2910520 0.2914549 0.291697476? 0.3266725 0.3271569 0.327475777? 0.3405427 0.3410150 0.341319778? 0.3164929 0.3169560 0.317269479? 0.3489597 0.3495394 0.349918280? 0.3369682 0.3374025 0.337660681? 0.2608885 0.2613245 0.261581182? 0.3132109 0.3136024 0.313788183? 0.3155325 0.3159175 0.316144884? 0.3156847 0.3160608 0.316250785? 0.2751068 0.2754884 0.275712986? 0.2722970 0.2726988 0.272900087? 0.3421156 0.3424138 0.342577688? 0.4408897 0.4413919 0.441767389? 0.4094418 0.4098032 0.410052590? 0.2883307 0.2887366 0.288972191? 0.3368085 0.3373375 0.337674492? 0.2914632 0.2918586 0.292056993? 0.3701615 0.3703609 0.370657894? 0.3168159 0.3172900 0.317585795? 0.3141627 0.3145356 0.314785296? 0.2717998 0.2721882 0.272409297? 0.2994829 0.2998522 0.300074998? 0.4238313 0.4238643 0.423967099? 0.3173946 0.3178398 0.3181364100 0.3065352 0.3070051 0.3073053101 0.4119025 0.4122178 0.4126194102 0.2997539 0.3001756 0.3004323103 0.3195902 0.3200457 0.3203547104 0.3770273 0.3775299 0.3779288105 0.3119653 0.3123196 0.3125118106 0.3007703 0.3012067 0.3014555107 0.3583141 0.3586335 0.3588411108 0.3613160 0.3616626 0.3619002109 0.3012548 0.3016973 0.3019971110 0.3040114 0.3044745 0.3047490111 0.3886676 0.3889934 0.3894869112 0.3381325 0.3386472 0.3389995113 0.3228837 0.3232841 0.3235284114 0.3175641 0.3179575 0.3182012115 0.3255604 0.3259808 0.3262322116 0.3038366 0.3043306 0.3046326117 0.3040762 0.3045244 0.3048216118 0.3101427 0.3105674 0.3108223119 0.3186323 0.3190890 0.3194055120 0.3183660 0.3188377 0.3191515121 0.3716398 0.3723766 0.3729757122 0.3336347 0.3341000 0.3344247123 0.3013631 0.3017261 0.3018954124 0.3559751 0.3563222 0.3565449125 0.3467284 0.3475789 0.3482055126 0.2983477 0.2992734 0.3000016127 0.2966113 0.2970161 0.2972673128 0.3244559 0.3249162 0.3252265129 0.3687044 0.3692860 0.3697534130 0.2949226 0.2953484 0.2956104131 0.3449411 0.3454331 0.3457713132 0.3458079 0.3462659 0.3465872133 0.3879239 0.3882694 0.3884915134 0.3998409 0.3997933 0.3999189135 0.2591648 0.2596039 0.2598299136 0.3145797 0.3149986 0.3152637137 0.3184437 0.3188738 0.3191448138 0.3101936 0.3105727 0.3108114139 0.3263323 0.3267737 0.3270491140 0.3234212 0.3238232 0.3240880141 0.5669109 0.5681474 0.5693322142 0.4268930 0.4277861 0.4285390?[ reached getOption("max.print") -- 683?
Finally, another question: Why 142 lines ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 825 observed data and 5 variables, the reference said.

Reference-----------
| NIRsoil {prospectr} | R Documentation |


NIRSoil

Description
Soil spectral library of the ?Chimiometrie 2006?challenge. The database contains absorbance spectra ofdried and sieved soil samples measured between 1100 nm and2498 nm at 2 nm interval. The soil samples come fromagricultural fields collected from all over the Walloonregion in Belgium. Three parameters are associated with thespectral library: Nt (Total Nitrogen in g/Kg of dry soil),CEC (Cation Exchange Capacity in meq/100 g of dry soil) andCiso (Carbon in g/100 g of dry soil). Carbon content hasbeen measured following the ISO14235 method.
Usage
data(NIRsoil)

Format
A data frame of 825 observations and 5 variables
Details
The dataset includes 618 training and 207 test samples with5 variables: Nt (Total Nitrogen), Ciso (Carbon), CEC(Cation Exchange Capacity), train (vector of 0,1indicating training (1) and validation (0) samples) and spc(a matrix with absorbance NIR data and bandpositions as colnames). Nt, Ciso and CEC haverespectively 22 %, 11 % and 46 % of the observationswith missing values.
Source
Pierre Dardenne from Walloon Agricultural Research Centre,Belgium.
References
Fernandez Pierna, J.A., and Dardenne, P., 2008. Soilparameter quantification by NIRS as a Chemometric challengeat 'Chimiometrie 2006'. Chemometrics and IntelligentLaboratory Systems 91, 94-98.Minasny, B., and McBratney, A.B., 2008. Regression rules asa tool for predicting soil properties from infraredreflectance spectroscopy. Chemometrics and IntelligentLaboratory Systems 94, 72-79.
?Package prospectr version 0.1.3 Index



	[[alternative HTML version deleted]]


From khvorov45 @end|ng |rom gm@||@com  Mon Sep  9 00:06:14 2019
From: khvorov45 @end|ng |rom gm@||@com (Arseniy Khvorov)
Date: Mon, 9 Sep 2019 08:06:14 +1000
Subject: [R] [R-pkgs] New package sclr for scaled logit model
Message-ID: <b593e923-c8ab-4ed6-40e5-f350aa51200d@gmail.com>

A new package "sclr" for fitting the "scaled logit" model from Dunning 
(2006)? <doi:10.1002/sim.2282> is available.

CRAN: https://cran.r-project.org/package=sclr
Github: https://github.com/khvorov45/sclr

I appreciate any feedback.

Best regards,
Arseniy Khvorov

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  9 16:40:09 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Sep 2019 07:40:09 -0700
Subject: [R] Problems installing Dependences of my package
In-Reply-To: <DB7PR04MB45064E637BD44D45CF1A4088ADB70@DB7PR04MB4506.eurprd04.prod.outlook.com>
References: <DB7PR04MB4506253C72DB8FC8D0B8D7A6ADBA0@DB7PR04MB4506.eurprd04.prod.outlook.com>
 <DB7PR04MB45064E637BD44D45CF1A4088ADB70@DB7PR04MB4506.eurprd04.prod.outlook.com>
Message-ID: <070165B3-4D12-44FC-8F25-462C01EA8E9D@dcn.davis.ca.us>

Wrong mailing list (use R-package-devel. Don't post HTML... your email is full of unreadable characters.

On September 8, 2019 11:27:27 PM PDT, "VILAR ?LVAREZ ANDREA" <andrea.vilar.alvarez at usc.es> wrote:
>
>Hi,
>
>I am writting because I am doing a package in R and I have some
>problems installing dependences which appear at DESCRIPTION file.
>
>First of all, I am not sure about the difference between ?Depends? and
>?Imports?, but I only use ?Depends?.
>My problem is that my package is going to be used at different
>computers and for different persons so I want that when other person
>use my package, it can be able to check  if the necesary packages are
>installed and if they are not installed, the package must be able to
>install  them.
>I supposed that this problem was solved including the necesary packages
>and their versions at ?Depends?. And now, I have another problem
>because the versions are usually indicated using ?>=?, for example:
>forecast (>=8.7) but I need to use exactly the versi?n 8.7 because
>sometimes when packages are updated, they lost some functions. But if I
>use ?<=? or ?==? and the package is update to versi?n 8.8, my package
>installation fail.
>How can I solve this? If I use R normaly (outside my package), I can
>install older versions of other packages using
>devtools::install_version() so why when I indicate ? forecast (<=8.7)?
>at Depends on the DESCRIPTION file, R is not able to install an older
>version if a new one is avaliable?
>
>Thanks in advance for your attention.
>
>Best regards,
>
>Andrea.
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  9 16:59:05 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Sep 2019 07:59:05 -0700
Subject: [R] =?utf-8?q?structure_of=E3=80=80NIRsoil?=
In-Reply-To: <1904106974.923567.1568017264760.JavaMail.yahoo@jws702103.mail.ssk.yahoo.co.jp>
References: <1904106974.923567.1568017264760.JavaMail.yahoo.ref@jws702103.mail.ssk.yahoo.co.jp>
 <1904106974.923567.1568017264760.JavaMail.yahoo@jws702103.mail.ssk.yahoo.co.jp>
Message-ID: <646F472C-6C99-4968-85D9-596774FE489D@dcn.davis.ca.us>

Beginners should definitely read the Posting Guide mentioned in the footer of this and every message from this mailing list. One key point is that this mailing list is for plain text format only, and your message gets damaged to varying degrees when you fail to set the plain text format option in your email program. (there are too many email programs for us to be able to help you figure out how to do that... that is up to you.)

Another point from the PG worth mentioning is that contributed packages are not strictly speaking on topic here. There should be a hint as to where to ask questions about it in the description [1].

You should learn about the base R function str.  Try typing

?str

at the R console (command line)

[1] https://cran.r-project.org/web/packages/prospectr/index.html see URL

On September 9, 2019 1:21:04 AM PDT, rhotuser at yahoo.co.jp wrote:
>Dear Sir,
>
>After installing prospectr,?
>> data(NIRsoil)> mode(NIRsoil)[1] "list">?
>I am a beginner and the structure of ?NIRsoil? is complicated.
>
>Judging from the explanation of NIRsoil (see below),?there are six
>elements: NT, Ciso, CEC, train, validation, spc.
>
>Please tell me how to know the structure of such ?NIRsoil?.
>When using mode (NIRsoil) , The answer is just a ?list?.
>Is there a command or function "Detailstructure (NIRsoil)"?
>> NIRsoil
>.
>.? ? ?spc.2494? spc.2496? spc.24981? ?0.3724227 0.3724588 0.37256772?
>?0.3159643 0.3164802 0.31681803? ?0.3416802 0.3422180 0.34263164?
>?0.3650448 0.3654987 0.36580555? ?0.3050233 0.3058226 0.30640076?
>?0.3599009 0.3603650 0.36070207? ?0.3365467 0.3369826 0.33725788?
>?0.3922267 0.3926329 0.39288209? ?0.3149452 0.3153307 0.315540410?
>0.4951153 0.4954152 0.495766411? 0.3414548 0.3418657 0.342114012?
>0.3314737 0.3319690 0.332336513? 0.4153854 0.4156993 0.416079614?
>0.3311567 0.3316245 0.331926815? 0.3289777 0.3294281 0.329720616?
>0.4268982 0.4274236 0.427819517? 0.3421552 0.3426531 0.342981518?
>0.3452011 0.3457459 0.346121719? 0.3497368 0.3497175 0.349840320?
>0.3896840 0.3901652 0.390537521? 0.4062244 0.4066894 0.407021322?
>0.3792031 0.3796499 0.379960123? 0.3252305 0.3256037 0.325836624?
>0.3427994 0.3431511 0.343363125? 0.3410443 0.3414203 0.341648926?
>0.3947710 0.3952165 0.395562027? 0.2930943 0.2934901 0.293697728?
>0.4138924 0.4144398 0.414861929? 0.2906964 0.2910948 0.291324130?
>0.4000607 0.4004497 0.400749131? 0.3275807 0.3278961 0.328067632?
>0.3343273 0.3347059 0.334947033? 0.2923162 0.2927208 0.292952534?
>0.3181143 0.3184221 0.318574835? 0.3959161 0.3963806 0.396695436?
>0.3412020 0.3415608 0.341737737? 0.3109980 0.3119904 0.312796538?
>0.3452408 0.3457109 0.346040139? 0.2352630 0.2357922 0.236104440?
>0.3731434 0.3735985 0.373948341? 0.3776968 0.3780733 0.378314142?
>0.4279117 0.4278319 0.427811343? 0.3499106 0.3502492 0.350448044?
>0.4060152 0.4064416 0.406781645? 0.4434104 0.4437352 0.444117646?
>0.3106347 0.3111292 0.311479047? 0.3048005 0.3052686 0.305555748?
>0.3074032 0.3078929 0.308188549? 0.3099467 0.3103620 0.310607950?
>0.4140719 0.4140101 0.414070551? 0.3047789 0.3051992 0.305453152?
>0.4372076 0.4371921 0.437301153? 0.3784582 0.3788292 0.379046054?
>0.3070685 0.3074959 0.307739255? 0.3929690 0.3930495 0.393248956?
>0.3104950 0.3109303 0.311175657? 0.3110389 0.3114884 0.311783658?
>0.3561086 0.3565895 0.356935659? 0.2946499 0.2950254 0.295230760?
>0.3396696 0.3402275 0.340604561? 0.4174463 0.4174852 0.417609462?
>0.3838490 0.3845536 0.385175463? 0.4214520 0.4217800 0.422008564?
>0.3136719 0.3141062 0.314410265? 0.3137282 0.3141668 0.314444466?
>0.4341556 0.4341235 0.434172067? 0.3028214 0.3032053 0.303438768?
>0.2929183 0.2933525 0.293613269? 0.2901444 0.2905667 0.290814470?
>0.2926482 0.2930853 0.293328871? 0.3964101 0.3968658 0.397207272?
>0.3205706 0.3209653 0.321186973? 0.2965653 0.2970253 0.297328574?
>0.3271259 0.3274269 0.327623075? 0.2910520 0.2914549 0.291697476?
>0.3266725 0.3271569 0.327475777? 0.3405427 0.3410150 0.341319778?
>0.3164929 0.3169560 0.317269479? 0.3489597 0.3495394 0.349918280?
>0.3369682 0.3374025 0.337660681? 0.2608885 0.2613245 0.261581182?
>0.3132109 0.3136024 0.313788183? 0.3155325 0.3159175 0.316144884?
>0.3156847 0.3160608 0.316250785? 0.2751068 0.2754884 0.275712986?
>0.2722970 0.2726988 0.272900087? 0.3421156 0.3424138 0.342577688?
>0.4408897 0.4413919 0.441767389? 0.4094418 0.4098032 0.410052590?
>0.2883307 0.2887366 0.288972191? 0.3368085 0.3373375 0.337674492?
>0.2914632 0.2918586 0.292056993? 0.3701615 0.3703609 0.370657894?
>0.3168159 0.3172900 0.317585795? 0.3141627 0.3145356 0.314785296?
>0.2717998 0.2721882 0.272409297? 0.2994829 0.2998522 0.300074998?
>0.4238313 0.4238643 0.423967099? 0.3173946 0.3178398 0.3181364100
>0.3065352 0.3070051 0.3073053101 0.4119025 0.4122178 0.4126194102
>0.2997539 0.3001756 0.3004323103 0.3195902 0.3200457 0.3203547104
>0.3770273 0.3775299 0.3779288105 0.3119653 0.3123196 0.3125118106
>0.3007703 0.3012067 0.3014555107 0.3583141 0.3586335 0.3588411108
>0.3613160 0.3616626 0.3619002109 0.3012548 0.3016973 0.3019971110
>0.3040114 0.3044745 0.3047490111 0.3886676 0.3889934 0.3894869112
>0.3381325 0.3386472 0.3389995113 0.3228837 0.3232841 0.3235284114
>0.3175641 0.3179575 0.3182012115 0.3255604 0.3259808 0.3262322116
>0.3038366 0.3043306 0.3046326117 0.3040762 0.3045244 0.3048216118
>0.3101427 0.3105674 0.3108223119 0.3186323 0.3190890 0.3194055120
>0.3183660 0.3188377 0.3191515121 0.3716398 0.3723766 0.3729757122
>0.3336347 0.3341000 0.3344247123 0.3013631 0.3017261 0.3018954124
>0.3559751 0.3563222 0.3565449125 0.3467284 0.3475789 0.3482055126
>0.2983477 0.2992734 0.3000016127 0.2966113 0.2970161 0.2972673128
>0.3244559 0.3249162 0.3252265129 0.3687044 0.3692860 0.3697534130
>0.2949226 0.2953484 0.2956104131 0.3449411 0.3454331 0.3457713132
>0.3458079 0.3462659 0.3465872133 0.3879239 0.3882694 0.3884915134
>0.3998409 0.3997933 0.3999189135 0.2591648 0.2596039 0.2598299136
>0.3145797 0.3149986 0.3152637137 0.3184437 0.3188738 0.3191448138
>0.3101936 0.3105727 0.3108114139 0.3263323 0.3267737 0.3270491140
>0.3234212 0.3238232 0.3240880141 0.5669109 0.5681474 0.5693322142
>0.4268930 0.4277861 0.4285390?[ reached getOption("max.print") -- 683?
>Finally, another question: Why 142 lines ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
>? ? 825 observed data and 5 variables, the reference said.
>
>Reference-----------
>| NIRsoil {prospectr} | R Documentation |
>
>
>NIRSoil
>
>Description
>Soil spectral library of the ?Chimiometrie 2006?challenge. The database
>contains absorbance spectra ofdried and sieved soil samples measured
>between 1100 nm and2498 nm at 2 nm interval. The soil samples come
>fromagricultural fields collected from all over the Walloonregion in
>Belgium. Three parameters are associated with thespectral library: Nt
>(Total Nitrogen in g/Kg of dry soil),CEC (Cation Exchange Capacity in
>meq/100 g of dry soil) andCiso (Carbon in g/100 g of dry soil). Carbon
>content hasbeen measured following the ISO14235 method.
>Usage
>data(NIRsoil)
>
>Format
>A data frame of 825 observations and 5 variables
>Details
>The dataset includes 618 training and 207 test samples with5 variables:
>Nt (Total Nitrogen), Ciso (Carbon), CEC(Cation Exchange Capacity),
>train (vector of 0,1indicating training (1) and validation (0) samples)
>and spc(a matrix with absorbance NIR data and bandpositions as
>colnames). Nt, Ciso and CEC haverespectively 22 %, 11 % and 46 % of the
>observationswith missing values.
>Source
>Pierre Dardenne from Walloon Agricultural Research Centre,Belgium.
>References
>Fernandez Pierna, J.A., and Dardenne, P., 2008. Soilparameter
>quantification by NIRS as a Chemometric challengeat 'Chimiometrie
>2006'. Chemometrics and IntelligentLaboratory Systems 91,
>94-98.Minasny, B., and McBratney, A.B., 2008. Regression rules asa tool
>for predicting soil properties from infraredreflectance spectroscopy.
>Chemometrics and IntelligentLaboratory Systems 94, 72-79.
>?Package prospectr version 0.1.3 Index
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jonch@k @end|ng |rom gm@||@com  Sat Sep  7 20:34:29 2019
From: jonch@k @end|ng |rom gm@||@com (Jon Hak)
Date: Sat, 7 Sep 2019 12:34:29 -0600
Subject: [R] export the patch results landscapemetrics
Message-ID: <fd946e34-93ca-4b60-69fb-25c934f009d3@gmail.com>

I've used SDMTools and Fragstats frequently and I'm trying out the 
recently published landscapemetrics.? I'e worked through the agusta demo 
that came with the package so I think I've got a handle on how to 
process the models I would like to use, but I 'm a bit stumped.? the 
show_patches() is what I would like to export out to a new raster to 
display/use the patch results in a GIS. Show_pataches() creates a? 
Gabriel graph, but I want a raster similar to STMTools or regiongroup 
(ArcGIS).

Thanks for any help,

Jon


From n|co|@||ed|er @end|ng |rom gmx@de  Mon Sep  9 16:30:46 2019
From: n|co|@||ed|er @end|ng |rom gmx@de (Nicola Fiedler)
Date: Mon, 9 Sep 2019 16:30:46 +0200
Subject: [R] help
Message-ID: <204777EA-2470-4915-87F7-20356A2305D4@gmx.de>

Hi together,

I?m new using R and have a question concerning the Silhouette coefficient. I?ve clustered very easy objects with Affinity Propagation.
My data just has one numeric attribute.

apres <- apcluster(negDistMat(r=2), data, details=TRUE)
show(apres)



This worked very well. To compare with other algorithms I want to know the Silhouette coefficient.
The function I use for the other algorithms doesn?t work for AP (clvalid or fviz_nbclust).
So my question is, how I can get the Silhouette coefficient for the clustering with AP?

Thank you very much in advance for your help.


From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Sep  9 17:55:15 2019
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 9 Sep 2019 16:55:15 +0100
Subject: [R] Choosing specific Date Range from non-sequential Date
Message-ID: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>

Dear Contributors,
I have a data frame of the form:
1997-11-23 -2.91709629064653
1997-12-07 -0.960255426066815
1997-12-11 -1.98210752999868
1997-12-20 -1.10800598439855
1998-01-01 -1.00090115428118
1998-01-29 -1.03056081882709
1998-03-27 -0.873243859498216
1998-04-09 -2.06378384750109
1998-04-12 -2.06826431469008
1998-04-19 -2.49834620746286
1998-05-02 -6.4357083781542
1998-05-17 -2.25359807972754
1998-05-21 -2.55799006865995
1999-08-22 -2.25114162617707
1999-08-25 -1.47905397376409
1999-09-05 -0.641589808755325
1999-09-09 -0.648954682695949
1999-09-13 -0.726364489272492
1999-09-16 -1.28445236942011

The events happen randomly and so the date is non-sequential. It run form
1953 to 2019.

I would like to select all the events/dates between 1998 to 2005.

One of the things I tried is:
Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31").

But it didn't work.

I would be thankful if you could please redirect me.

Thank you very much.
Best regards
Ogbos

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep  9 18:55:48 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Sep 2019 09:55:48 -0700
Subject: [R] Choosing specific Date Range from non-sequential Date
In-Reply-To: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
Message-ID: <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>

I would guess that you first need to convert your textual dates to a
date-time object via as.date, but as you failed to provide a reproducible
example (e.g. via dput) I may be wrong. Maybe others may have greater
insight.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike <giftedlife2014 at gmail.com> wrote:

> Dear Contributors,
> I have a data frame of the form:
> 1997-11-23 -2.91709629064653
> 1997-12-07 -0.960255426066815
> 1997-12-11 -1.98210752999868
> 1997-12-20 -1.10800598439855
> 1998-01-01 -1.00090115428118
> 1998-01-29 -1.03056081882709
> 1998-03-27 -0.873243859498216
> 1998-04-09 -2.06378384750109
> 1998-04-12 -2.06826431469008
> 1998-04-19 -2.49834620746286
> 1998-05-02 -6.4357083781542
> 1998-05-17 -2.25359807972754
> 1998-05-21 -2.55799006865995
> 1999-08-22 -2.25114162617707
> 1999-08-25 -1.47905397376409
> 1999-09-05 -0.641589808755325
> 1999-09-09 -0.648954682695949
> 1999-09-13 -0.726364489272492
> 1999-09-16 -1.28445236942011
>
> The events happen randomly and so the date is non-sequential. It run form
> 1953 to 2019.
>
> I would like to select all the events/dates between 1998 to 2005.
>
> One of the things I tried is:
> Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31").
>
> But it didn't work.
>
> I would be thankful if you could please redirect me.
>
> Thank you very much.
> Best regards
> Ogbos
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  9 19:18:22 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Sep 2019 10:18:22 -0700
Subject: [R] Choosing specific Date Range from non-sequential Date
In-Reply-To: <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
 <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
Message-ID: <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>

Or the column is not named "date", or it is a factor... and the question is not posted in plain text....

On September 9, 2019 9:55:48 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>I would guess that you first need to convert your textual dates to a
>date-time object via as.date, but as you failed to provide a
>reproducible
>example (e.g. via dput) I may be wrong. Maybe others may have greater
>insight.
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike <giftedlife2014 at gmail.com>
>wrote:
>
>> Dear Contributors,
>> I have a data frame of the form:
>> 1997-11-23 -2.91709629064653
>> 1997-12-07 -0.960255426066815
>> 1997-12-11 -1.98210752999868
>> 1997-12-20 -1.10800598439855
>> 1998-01-01 -1.00090115428118
>> 1998-01-29 -1.03056081882709
>> 1998-03-27 -0.873243859498216
>> 1998-04-09 -2.06378384750109
>> 1998-04-12 -2.06826431469008
>> 1998-04-19 -2.49834620746286
>> 1998-05-02 -6.4357083781542
>> 1998-05-17 -2.25359807972754
>> 1998-05-21 -2.55799006865995
>> 1999-08-22 -2.25114162617707
>> 1999-08-25 -1.47905397376409
>> 1999-09-05 -0.641589808755325
>> 1999-09-09 -0.648954682695949
>> 1999-09-13 -0.726364489272492
>> 1999-09-16 -1.28445236942011
>>
>> The events happen randomly and so the date is non-sequential. It run
>form
>> 1953 to 2019.
>>
>> I would like to select all the events/dates between 1998 to 2005.
>>
>> One of the things I tried is:
>> Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31").
>>
>> But it didn't work.
>>
>> I would be thankful if you could please redirect me.
>>
>> Thank you very much.
>> Best regards
>> Ogbos
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  9 19:21:23 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Sep 2019 10:21:23 -0700
Subject: [R] export the patch results landscapemetrics
In-Reply-To: <fd946e34-93ca-4b60-69fb-25c934f009d3@gmail.com>
References: <fd946e34-93ca-4b60-69fb-25c934f009d3@gmail.com>
Message-ID: <FE0A1A4C-71AD-4695-9C6C-A38D421F81EB@dcn.davis.ca.us>

Wrong mailing list. Read the Posting Guide and the package description.

On September 7, 2019 11:34:29 AM PDT, Jon Hak <jonchak at gmail.com> wrote:
>I've used SDMTools and Fragstats frequently and I'm trying out the 
>recently published landscapemetrics.? I'e worked through the agusta
>demo 
>that came with the package so I think I've got a handle on how to 
>process the models I would like to use, but I 'm a bit stumped.? the 
>show_patches() is what I would like to export out to a new raster to 
>display/use the patch results in a GIS. Show_pataches() creates a? 
>Gabriel graph, but I want a raster similar to STMTools or regiongroup 
>(ArcGIS).
>
>Thanks for any help,
>
>Jon
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Mon Sep  9 20:03:15 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Mon, 9 Sep 2019 14:03:15 -0400
Subject: [R] help
In-Reply-To: <204777EA-2470-4915-87F7-20356A2305D4@gmx.de>
References: <204777EA-2470-4915-87F7-20356A2305D4@gmx.de>
Message-ID: <CAM_vju=2ACJzrNzxPh4fCeWNiKy-A6v933sGJrWRhiS1HkLBWQ@mail.gmail.com>

You can use the vector of integer cluster numbers with silhouette()
from the cluster package.

https://www.rdocumentation.org/packages/cluster/versions/2.1.0/topics/silhouette


But note that silhouette as an assessment metric makes roughly the
same assumptions that k-means does about the data structure, and may
not return useful results with other clustering methods.

Sarah

On Mon, Sep 9, 2019 at 12:01 PM Nicola Fiedler <nicolafiedler at gmx.de> wrote:
>
> Hi together,
>
> I?m new using R and have a question concerning the Silhouette coefficient. I?ve clustered very easy objects with Affinity Propagation.
> My data just has one numeric attribute.
>
> apres <- apcluster(negDistMat(r=2), data, details=TRUE)
> show(apres)
>
>
>
> This worked very well. To compare with other algorithms I want to know the Silhouette coefficient.
> The function I use for the other algorithms doesn?t work for AP (clvalid or fviz_nbclust).
> So my question is, how I can get the Silhouette coefficient for the clustering with AP?
>
> Thank you very much in advance for your help.
>
-- 
Sarah Goslee (she/her)
http://www.numberwrigtht.com


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep  9 20:16:36 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 9 Sep 2019 19:16:36 +0100
Subject: [R] how to split a column by tab ?
In-Reply-To: <CAMwU6B1K9EwupPn_oZMGY=pKURa8NTxA68DvnJ-BF1wPvB6jJw@mail.gmail.com>
References: <CAMwU6B2CTJOHu6QVg3RvtfJhbNzFEPo5WWAk5uAaV0Oo4=ivsg@mail.gmail.com>
 <0269f600-167a-92bf-0cd1-2f91d9260404@sapo.pt>
 <CAMwU6B1K9EwupPn_oZMGY=pKURa8NTxA68DvnJ-BF1wPvB6jJw@mail.gmail.com>
Message-ID: <58e2a1db-d332-b473-b8b0-5f8d5c2962e5@sapo.pt>

Hello,

I'm glad it helped.
One more thing. I forgot to set the column names, if you want to get 
them from the data, try something like this:

nms <- lapply(s, function(.s) .s[grepl("[[:alpha:]]+", .s)])
nms <- sapply(nms, paste, collapse = ".")
names(daT3) <- nms
daT3


Hope this helps,

Rui Barradas

?s 16:28 de 09/09/19, Marna Wagley escreveu:
> Thank you Rui. it helped a lot.
> Sincerely,
> MW
> 
> On Mon, Sep 9, 2019 at 6:47 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     You could try a character class instead of one character (the tab char).
>     There are two character classes that you can try, [:blank:] and
>     [:space:], see ?regex.
> 
>     strsplit(as.character(daT1), "[[:blank:]]+")
> 
>     Then form the final result. I have changed rbind to cbind, it seemed
>     more appropriate (?).
> 
>     s <- strsplit(as.character(daT1), "[[:blank:]]+")
>     x <- lapply(s, function(.s) .s[!grepl("[[:alpha:]]+", .s)])
>     daT3 <- as.data.frame(do.call(cbind, x))
>     daT3
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 12:54 de 09/09/19, Marna Wagley escreveu:
>      > Hi R User,
>      > I was trying to split a column by tabs, I tried to split with
>     several ways,
>      > but I could not split it. Is there any possibilities?
>      >
>      > The data example and the code I used
>      > daT1<-c("Column number? ? ? ? ? ? ?1? ? 2? ? 3? ? 4? ? 5? ? 6   
>     7? ? 8
>      >? ?9? ?10? ?10? ?10? ?10? ?10? ?10? ?10",
>      > "comes from position? ? ? ?1? ? 7? ? 2? ? 6? ? 3? ? 5? ?15? ? 9 
>      ? 4? ? 8
>      > 10? ?11? ?12? ?13? ?14? ?16"
>      > )
>      > daT2 <- data.frame(do.call('rbind',
>      > strsplit(as.character(daT1),'\t',fixed=T)))
>      > colnames(daT2)
>      > daT2
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Sep  9 21:14:50 2019
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 9 Sep 2019 20:14:50 +0100
Subject: [R] Choosing specific Date Range from non-sequential Date
In-Reply-To: <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
 <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
 <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>
Message-ID: <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>

Dear Bert and Jeff,
Thank you for looking at this.
I am surprised my message was not in plain text. It has been
configured to send message to the list in plain text earlier before.

The data again please.

1997-11-23 -2.91709629064653
1997-12-07 -0.960255426066815
1997-12-11 -1.98210752999868
1997-12-20 -1.10800598439855
1998-01-01 -1.00090115428118
1998-01-29 -1.03056081882709
1998-03-27 -0.873243859498216
1998-04-09 -2.06378384750109
1998-04-12 -2.06826431469008
1998-04-19 -2.49834620746286
1998-05-02 -6.4357083781542
1998-05-17 -2.25359807972754
1998-05-21 -2.55799006865995
1999-08-22 -2.25114162617707
1999-08-25 -1.47905397376409
1999-09-05 -0.641589808755325
1999-09-09 -0.648954682695949
1999-09-13 -0.726364489272492
1999-09-16 -1.28445236942011

The first column is  date and the second is another data of interest.

The date is long but note sequential. Runs randomly from 1953 to 2019.

I would like to select any range of date from year A to year B.

Thank you again for your help.
Best
Ogbos


On Mon, Sep 9, 2019 at 6:18 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Or the column is not named "date", or it is a factor... and the question is not posted in plain text....
>
> On September 9, 2019 9:55:48 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >I would guess that you first need to convert your textual dates to a
> >date-time object via as.date, but as you failed to provide a
> >reproducible
> >example (e.g. via dput) I may be wrong. Maybe others may have greater
> >insight.
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike <giftedlife2014 at gmail.com>
> >wrote:
> >
> >> Dear Contributors,
> >> I have a data frame of the form:
> >> 1997-11-23 -2.91709629064653
> >> 1997-12-07 -0.960255426066815
> >> 1997-12-11 -1.98210752999868
> >> 1997-12-20 -1.10800598439855
> >> 1998-01-01 -1.00090115428118
> >> 1998-01-29 -1.03056081882709
> >> 1998-03-27 -0.873243859498216
> >> 1998-04-09 -2.06378384750109
> >> 1998-04-12 -2.06826431469008
> >> 1998-04-19 -2.49834620746286
> >> 1998-05-02 -6.4357083781542
> >> 1998-05-17 -2.25359807972754
> >> 1998-05-21 -2.55799006865995
> >> 1999-08-22 -2.25114162617707
> >> 1999-08-25 -1.47905397376409
> >> 1999-09-05 -0.641589808755325
> >> 1999-09-09 -0.648954682695949
> >> 1999-09-13 -0.726364489272492
> >> 1999-09-16 -1.28445236942011
> >>
> >> The events happen randomly and so the date is non-sequential. It run
> >form
> >> 1953 to 2019.
> >>
> >> I would like to select all the events/dates between 1998 to 2005.
> >>
> >> One of the things I tried is:
> >> Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31").
> >>
> >> But it didn't work.
> >>
> >> I would be thankful if you could please redirect me.
> >>
> >> Thank you very much.
> >> Best regards
> >> Ogbos
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  9 21:22:22 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Sep 2019 12:22:22 -0700
Subject: [R] Choosing specific Date Range from non-sequential Date
In-Reply-To: <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
 <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
 <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>
 <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
Message-ID: <BB118400-4DA8-4237-9E59-A186CFDE679B@dcn.davis.ca.us>

Works for me. Apparently you are not showing us everything you are doing. As Bert recommended, you need to use the dput function rather than dumping numbers into the email if we are to know how your data are stored in memory which will affect what results you get. I highly recommend using the reprex package to verify that your example is reproducible.

On September 9, 2019 12:14:50 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Bert and Jeff,
>Thank you for looking at this.
>I am surprised my message was not in plain text. It has been
>configured to send message to the list in plain text earlier before.
>
>The data again please.
>
>1997-11-23 -2.91709629064653
>1997-12-07 -0.960255426066815
>1997-12-11 -1.98210752999868
>1997-12-20 -1.10800598439855
>1998-01-01 -1.00090115428118
>1998-01-29 -1.03056081882709
>1998-03-27 -0.873243859498216
>1998-04-09 -2.06378384750109
>1998-04-12 -2.06826431469008
>1998-04-19 -2.49834620746286
>1998-05-02 -6.4357083781542
>1998-05-17 -2.25359807972754
>1998-05-21 -2.55799006865995
>1999-08-22 -2.25114162617707
>1999-08-25 -1.47905397376409
>1999-09-05 -0.641589808755325
>1999-09-09 -0.648954682695949
>1999-09-13 -0.726364489272492
>1999-09-16 -1.28445236942011
>
>The first column is  date and the second is another data of interest.
>
>The date is long but note sequential. Runs randomly from 1953 to 2019.
>
>I would like to select any range of date from year A to year B.
>
>Thank you again for your help.
>Best
>Ogbos
>
>
>On Mon, Sep 9, 2019 at 6:18 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Or the column is not named "date", or it is a factor... and the
>question is not posted in plain text....
>>
>> On September 9, 2019 9:55:48 AM PDT, Bert Gunter
><bgunter.4567 at gmail.com> wrote:
>> >I would guess that you first need to convert your textual dates to a
>> >date-time object via as.date, but as you failed to provide a
>> >reproducible
>> >example (e.g. via dput) I may be wrong. Maybe others may have
>greater
>> >insight.
>> >
>> >Bert Gunter
>> >
>> >"The trouble with having an open mind is that people keep coming
>along
>> >and
>> >sticking things into it."
>> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> >On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike
><giftedlife2014 at gmail.com>
>> >wrote:
>> >
>> >> Dear Contributors,
>> >> I have a data frame of the form:
>> >> 1997-11-23 -2.91709629064653
>> >> 1997-12-07 -0.960255426066815
>> >> 1997-12-11 -1.98210752999868
>> >> 1997-12-20 -1.10800598439855
>> >> 1998-01-01 -1.00090115428118
>> >> 1998-01-29 -1.03056081882709
>> >> 1998-03-27 -0.873243859498216
>> >> 1998-04-09 -2.06378384750109
>> >> 1998-04-12 -2.06826431469008
>> >> 1998-04-19 -2.49834620746286
>> >> 1998-05-02 -6.4357083781542
>> >> 1998-05-17 -2.25359807972754
>> >> 1998-05-21 -2.55799006865995
>> >> 1999-08-22 -2.25114162617707
>> >> 1999-08-25 -1.47905397376409
>> >> 1999-09-05 -0.641589808755325
>> >> 1999-09-09 -0.648954682695949
>> >> 1999-09-13 -0.726364489272492
>> >> 1999-09-16 -1.28445236942011
>> >>
>> >> The events happen randomly and so the date is non-sequential. It
>run
>> >form
>> >> 1953 to 2019.
>> >>
>> >> I would like to select all the events/dates between 1998 to 2005.
>> >>
>> >> One of the things I tried is:
>> >> Year <- subset(MOSCFD50, date > "1998-01-01" & date <
>"2005-12-31").
>> >>
>> >> But it didn't work.
>> >>
>> >> I would be thankful if you could please redirect me.
>> >>
>> >> Thank you very much.
>> >> Best regards
>> >> Ogbos
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Sep  9 21:46:52 2019
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 9 Sep 2019 20:46:52 +0100
Subject: [R] Choosing specific Date Range from non-sequential Date: Problem
 Fixed
In-Reply-To: <BB118400-4DA8-4237-9E59-A186CFDE679B@dcn.davis.ca.us>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
 <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
 <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>
 <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
 <BB118400-4DA8-4237-9E59-A186CFDE679B@dcn.davis.ca.us>
Message-ID: <CAC8ss31RfpqA7J0TJNnf9Jaistj6cf8yhJ-sgMpcp5Cj-9Sr8w@mail.gmail.com>

Dear Bert and Jeff,
The result is an output of another code and it will be too long or
unnecessary to show all I'm I did to arrive at the given data frame.

Since my single line code works for Jeff, I had to take a second look
and try to get it working for me. I then read the data frame using
d<-read.table("MOSC",colClasses=c("Date","numeric"))  and tried:
Year <- subset(d1, d1[[1]] > "1998-01-01" & d1[[1]] < "2006-01-01")
and arrived at my goal.

Thank you for the hint.
Best regards
Ogbos


On Mon, Sep 9, 2019 at 8:22 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Works for me. Apparently you are not showing us everything you are doing. As Bert recommended, you need to use the dput function rather than dumping numbers into the email if we are to know how your data are stored in memory which will affect what results you get. I highly recommend using the reprex package to verify that your example is reproducible.
>
> On September 9, 2019 12:14:50 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> >Dear Bert and Jeff,
> >Thank you for looking at this.
> >I am surprised my message was not in plain text. It has been
> >configured to send message to the list in plain text earlier before.
> >
> >The data again please.
> >
> >1997-11-23 -2.91709629064653
> >1997-12-07 -0.960255426066815
> >1997-12-11 -1.98210752999868
> >1997-12-20 -1.10800598439855
> >1998-01-01 -1.00090115428118
> >1998-01-29 -1.03056081882709
> >1998-03-27 -0.873243859498216
> >1998-04-09 -2.06378384750109
> >1998-04-12 -2.06826431469008
> >1998-04-19 -2.49834620746286
> >1998-05-02 -6.4357083781542
> >1998-05-17 -2.25359807972754
> >1998-05-21 -2.55799006865995
> >1999-08-22 -2.25114162617707
> >1999-08-25 -1.47905397376409
> >1999-09-05 -0.641589808755325
> >1999-09-09 -0.648954682695949
> >1999-09-13 -0.726364489272492
> >1999-09-16 -1.28445236942011
> >
> >The first column is  date and the second is another data of interest.
> >
> >The date is long but note sequential. Runs randomly from 1953 to 2019.
> >
> >I would like to select any range of date from year A to year B.
> >
> >Thank you again for your help.
> >Best
> >Ogbos
> >
> >
> >On Mon, Sep 9, 2019 at 6:18 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us> wrote:
> >>
> >> Or the column is not named "date", or it is a factor... and the
> >question is not posted in plain text....
> >>
> >> On September 9, 2019 9:55:48 AM PDT, Bert Gunter
> ><bgunter.4567 at gmail.com> wrote:
> >> >I would guess that you first need to convert your textual dates to a
> >> >date-time object via as.date, but as you failed to provide a
> >> >reproducible
> >> >example (e.g. via dput) I may be wrong. Maybe others may have
> >greater
> >> >insight.
> >> >
> >> >Bert Gunter
> >> >
> >> >"The trouble with having an open mind is that people keep coming
> >along
> >> >and
> >> >sticking things into it."
> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> >On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike
> ><giftedlife2014 at gmail.com>
> >> >wrote:
> >> >
> >> >> Dear Contributors,
> >> >> I have a data frame of the form:
> >> >> 1997-11-23 -2.91709629064653
> >> >> 1997-12-07 -0.960255426066815
> >> >> 1997-12-11 -1.98210752999868
> >> >> 1997-12-20 -1.10800598439855
> >> >> 1998-01-01 -1.00090115428118
> >> >> 1998-01-29 -1.03056081882709
> >> >> 1998-03-27 -0.873243859498216
> >> >> 1998-04-09 -2.06378384750109
> >> >> 1998-04-12 -2.06826431469008
> >> >> 1998-04-19 -2.49834620746286
> >> >> 1998-05-02 -6.4357083781542
> >> >> 1998-05-17 -2.25359807972754
> >> >> 1998-05-21 -2.55799006865995
> >> >> 1999-08-22 -2.25114162617707
> >> >> 1999-08-25 -1.47905397376409
> >> >> 1999-09-05 -0.641589808755325
> >> >> 1999-09-09 -0.648954682695949
> >> >> 1999-09-13 -0.726364489272492
> >> >> 1999-09-16 -1.28445236942011
> >> >>
> >> >> The events happen randomly and so the date is non-sequential. It
> >run
> >> >form
> >> >> 1953 to 2019.
> >> >>
> >> >> I would like to select all the events/dates between 1998 to 2005.
> >> >>
> >> >> One of the things I tried is:
> >> >> Year <- subset(MOSCFD50, date > "1998-01-01" & date <
> >"2005-12-31").
> >> >>
> >> >> But it didn't work.
> >> >>
> >> >> I would be thankful if you could please redirect me.
> >> >>
> >> >> Thank you very much.
> >> >> Best regards
> >> >> Ogbos
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
>
> --
> Sent from my phone. Please excuse my brevity.


From wdun|@p @end|ng |rom t|bco@com  Mon Sep  9 22:09:19 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 9 Sep 2019 13:09:19 -0700
Subject: [R] Choosing specific Date Range from non-sequential Date
In-Reply-To: <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
 <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
 <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>
 <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
Message-ID: <CAF8bMcYNyJTu4j6q6x5KuEXf8fQKo0t=fTAMC-0y5OhCd0ezcg@mail.gmail.com>

To get a quick answer to your question you should provide a smallexample
that one can simply copy and paste into an R session.  It also helps to
show some details about how something does not work, more than " But it
didn't work."   E.g.,

d <- read.table(header=FALSE, text="1997-11-23 -2.91709629064653
1997-12-07 -0.960255426066815
1997-12-11 -1.98210752999868
1997-12-20 -1.10800598439855
1998-01-01 -1.00090115428118
1998-01-29 -1.03056081882709")
names(d) <- c("date", "measurement")
subset(d, date > "1997-12-15" & date < "1998-01-16")

which gave:

[1] date        measurement
<0 rows> (or 0-length row.names)
Warning messages:
1: In Ops.factor(date, "1997-12-15") : ?>? not meaningful for factors
2: In Ops.factor(date, "1998-01-16") : ?<? not meaningful for factors

People seeing the call to read.table() and the warning messages from
subset() could quickly and confidently recommend adding
the colClasses=c("Date", "numeric") to the call to read.table.  Without
that information, both questioners and helpers become frustrated.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Sep 9, 2019 at 12:15 PM Ogbos Okike <giftedlife2014 at gmail.com>
wrote:

> Dear Bert and Jeff,
> Thank you for looking at this.
> I am surprised my message was not in plain text. It has been
> configured to send message to the list in plain text earlier before.
>
> The data again please.
>
> 1997-11-23 -2.91709629064653
> 1997-12-07 -0.960255426066815
> 1997-12-11 -1.98210752999868
> 1997-12-20 -1.10800598439855
> 1998-01-01 -1.00090115428118
> 1998-01-29 -1.03056081882709
> 1998-03-27 -0.873243859498216
> 1998-04-09 -2.06378384750109
> 1998-04-12 -2.06826431469008
> 1998-04-19 -2.49834620746286
> 1998-05-02 -6.4357083781542
> 1998-05-17 -2.25359807972754
> 1998-05-21 -2.55799006865995
> 1999-08-22 -2.25114162617707
> 1999-08-25 -1.47905397376409
> 1999-09-05 -0.641589808755325
> 1999-09-09 -0.648954682695949
> 1999-09-13 -0.726364489272492
> 1999-09-16 -1.28445236942011
>
> The first column is  date and the second is another data of interest.
>
> The date is long but note sequential. Runs randomly from 1953 to 2019.
>
> I would like to select any range of date from year A to year B.
>
> Thank you again for your help.
> Best
> Ogbos
>
>
> On Mon, Sep 9, 2019 at 6:18 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > Or the column is not named "date", or it is a factor... and the question
> is not posted in plain text....
> >
> > On September 9, 2019 9:55:48 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > >I would guess that you first need to convert your textual dates to a
> > >date-time object via as.date, but as you failed to provide a
> > >reproducible
> > >example (e.g. via dput) I may be wrong. Maybe others may have greater
> > >insight.
> > >
> > >Bert Gunter
> > >
> > >"The trouble with having an open mind is that people keep coming along
> > >and
> > >sticking things into it."
> > >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > >On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike <giftedlife2014 at gmail.com>
> > >wrote:
> > >
> > >> Dear Contributors,
> > >> I have a data frame of the form:
> > >> 1997-11-23 -2.91709629064653
> > >> 1997-12-07 -0.960255426066815
> > >> 1997-12-11 -1.98210752999868
> > >> 1997-12-20 -1.10800598439855
> > >> 1998-01-01 -1.00090115428118
> > >> 1998-01-29 -1.03056081882709
> > >> 1998-03-27 -0.873243859498216
> > >> 1998-04-09 -2.06378384750109
> > >> 1998-04-12 -2.06826431469008
> > >> 1998-04-19 -2.49834620746286
> > >> 1998-05-02 -6.4357083781542
> > >> 1998-05-17 -2.25359807972754
> > >> 1998-05-21 -2.55799006865995
> > >> 1999-08-22 -2.25114162617707
> > >> 1999-08-25 -1.47905397376409
> > >> 1999-09-05 -0.641589808755325
> > >> 1999-09-09 -0.648954682695949
> > >> 1999-09-13 -0.726364489272492
> > >> 1999-09-16 -1.28445236942011
> > >>
> > >> The events happen randomly and so the date is non-sequential. It run
> > >form
> > >> 1953 to 2019.
> > >>
> > >> I would like to select all the events/dates between 1998 to 2005.
> > >>
> > >> One of the things I tried is:
> > >> Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31").
> > >>
> > >> But it didn't work.
> > >>
> > >> I would be thankful if you could please redirect me.
> > >>
> > >> Thank you very much.
> > >> Best regards
> > >> Ogbos
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep  9 22:35:45 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 9 Sep 2019 21:35:45 +0100
Subject: [R] Choosing specific Date Range from non-sequential Date
In-Reply-To: <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
 <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
 <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>
 <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
Message-ID: <3e4ecd10-2b6c-5b2d-32f7-63d76209def9@sapo.pt>

Hello,

I cannot reproduce the error but I coerce to class "Date" first.


MOSCFD50[[1]] <- as.Date(MOSCFD50[[1]])
names(MOSCFD50) <- c("date", "value")

# Your subset
Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31")

# Another way, if there are NA's, use which(i)
i <- MOSCFD50$date > "1998-01-01" & MOSCFD50$date < "2005-12-31"
Year2 <- MOSCFD50[i, ]

identical(Year, Year2)
#[1] TRUE


Data:


MOSCFD50 <- read.table(text = "
1997-11-23 -2.91709629064653
1997-12-07 -0.960255426066815
1997-12-11 -1.98210752999868
1997-12-20 -1.10800598439855
1998-01-01 -1.00090115428118
1998-01-29 -1.03056081882709
1998-03-27 -0.873243859498216
1998-04-09 -2.06378384750109
1998-04-12 -2.06826431469008
1998-04-19 -2.49834620746286
1998-05-02 -6.4357083781542
1998-05-17 -2.25359807972754
1998-05-21 -2.55799006865995
1999-08-22 -2.25114162617707
1999-08-25 -1.47905397376409
1999-09-05 -0.641589808755325
1999-09-09 -0.648954682695949
1999-09-13 -0.726364489272492
1999-09-16 -1.28445236942011
")


Hope this helps,

Rui Barradas


?s 20:14 de 09/09/19, Ogbos Okike escreveu:
> Dear Bert and Jeff,
> Thank you for looking at this.
> I am surprised my message was not in plain text. It has been
> configured to send message to the list in plain text earlier before.
> 
> The data again please.
> 
> 1997-11-23 -2.91709629064653
> 1997-12-07 -0.960255426066815
> 1997-12-11 -1.98210752999868
> 1997-12-20 -1.10800598439855
> 1998-01-01 -1.00090115428118
> 1998-01-29 -1.03056081882709
> 1998-03-27 -0.873243859498216
> 1998-04-09 -2.06378384750109
> 1998-04-12 -2.06826431469008
> 1998-04-19 -2.49834620746286
> 1998-05-02 -6.4357083781542
> 1998-05-17 -2.25359807972754
> 1998-05-21 -2.55799006865995
> 1999-08-22 -2.25114162617707
> 1999-08-25 -1.47905397376409
> 1999-09-05 -0.641589808755325
> 1999-09-09 -0.648954682695949
> 1999-09-13 -0.726364489272492
> 1999-09-16 -1.28445236942011
> 
> The first column is  date and the second is another data of interest.
> 
> The date is long but note sequential. Runs randomly from 1953 to 2019.
> 
> I would like to select any range of date from year A to year B.
> 
> Thank you again for your help.
> Best
> Ogbos
> 
> 
> On Mon, Sep 9, 2019 at 6:18 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Or the column is not named "date", or it is a factor... and the question is not posted in plain text....
>>
>> On September 9, 2019 9:55:48 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> I would guess that you first need to convert your textual dates to a
>>> date-time object via as.date, but as you failed to provide a
>>> reproducible
>>> example (e.g. via dput) I may be wrong. Maybe others may have greater
>>> insight.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike <giftedlife2014 at gmail.com>
>>> wrote:
>>>
>>>> Dear Contributors,
>>>> I have a data frame of the form:
>>>> 1997-11-23 -2.91709629064653
>>>> 1997-12-07 -0.960255426066815
>>>> 1997-12-11 -1.98210752999868
>>>> 1997-12-20 -1.10800598439855
>>>> 1998-01-01 -1.00090115428118
>>>> 1998-01-29 -1.03056081882709
>>>> 1998-03-27 -0.873243859498216
>>>> 1998-04-09 -2.06378384750109
>>>> 1998-04-12 -2.06826431469008
>>>> 1998-04-19 -2.49834620746286
>>>> 1998-05-02 -6.4357083781542
>>>> 1998-05-17 -2.25359807972754
>>>> 1998-05-21 -2.55799006865995
>>>> 1999-08-22 -2.25114162617707
>>>> 1999-08-25 -1.47905397376409
>>>> 1999-09-05 -0.641589808755325
>>>> 1999-09-09 -0.648954682695949
>>>> 1999-09-13 -0.726364489272492
>>>> 1999-09-16 -1.28445236942011
>>>>
>>>> The events happen randomly and so the date is non-sequential. It run
>>> form
>>>> 1953 to 2019.
>>>>
>>>> I would like to select all the events/dates between 1998 to 2005.
>>>>
>>>> One of the things I tried is:
>>>> Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31").
>>>>
>>>> But it didn't work.
>>>>
>>>> I would be thankful if you could please redirect me.
>>>>
>>>> Thank you very much.
>>>> Best regards
>>>> Ogbos
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@  Mon Sep  9 22:38:38 2019
From: m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@ (Marius Hofert)
Date: Mon, 9 Sep 2019 22:38:38 +0200
Subject: [R] R_BATCH_OPTIONS not respected?
Message-ID: <CAM3-KjbcUbDviH-3LzFiUGy_2MsPEreyUCz_wTxJgk-BZoE8Lg@mail.gmail.com>

Hi,

I typically start R with "--no-restore --no-save" (to avoid .RData
files being written) and would like to have the same behavior under 'R
CMD BATCH'. I use R_BATCH_OPTIONS="--no-restore --no-save" in my
~/.Renviron but running an R script with 'R CMD BATCH' still produces
a .RData file. What's the correct way of getting the '--no-restore
--no-save' options when in batch mode?

(This is on macOS 10.14.6 with R version 3.6.1)

Thanks & cheers,
M


From g||ted|||e2014 @end|ng |rom gm@||@com  Tue Sep 10 04:04:34 2019
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Tue, 10 Sep 2019 03:04:34 +0100
Subject: [R] Choosing specific Date Range from non-sequential Date
In-Reply-To: <3e4ecd10-2b6c-5b2d-32f7-63d76209def9@sapo.pt>
References: <CAC8ss30A8LGeDgY6wR3n_Q2k6uOHjT9dWKXBKumGh3_ZtmUi5A@mail.gmail.com>
 <CAGxFJbRVEG9NT5WE8-hC+HTRSPvV55+OG1CMQX7HN0tXrT1E_w@mail.gmail.com>
 <DF4E9CA5-432C-48D8-BCE2-BEA347E116E4@dcn.davis.ca.us>
 <CAC8ss33Uk7=wkxf5tDr3yEUHiVEf=anJq9PcaB6hOwD4b-LYPQ@mail.gmail.com>
 <3e4ecd10-2b6c-5b2d-32f7-63d76209def9@sapo.pt>
Message-ID: <CAC8ss33Vgn8dG5HxXJ3gnjjWd2+kpTTtjw5wnCbSoC7T0sBLiQ@mail.gmail.com>

Dear All,
Many thanks for all your contributions, suggestions and advice.
I find them all useful.
Best wishes
Ogbos

On Mon, Sep 9, 2019 at 9:35 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I cannot reproduce the error but I coerce to class "Date" first.
>
>
> MOSCFD50[[1]] <- as.Date(MOSCFD50[[1]])
> names(MOSCFD50) <- c("date", "value")
>
> # Your subset
> Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31")
>
> # Another way, if there are NA's, use which(i)
> i <- MOSCFD50$date > "1998-01-01" & MOSCFD50$date < "2005-12-31"
> Year2 <- MOSCFD50[i, ]
>
> identical(Year, Year2)
> #[1] TRUE
>
>
> Data:
>
>
> MOSCFD50 <- read.table(text = "
> 1997-11-23 -2.91709629064653
> 1997-12-07 -0.960255426066815
> 1997-12-11 -1.98210752999868
> 1997-12-20 -1.10800598439855
> 1998-01-01 -1.00090115428118
> 1998-01-29 -1.03056081882709
> 1998-03-27 -0.873243859498216
> 1998-04-09 -2.06378384750109
> 1998-04-12 -2.06826431469008
> 1998-04-19 -2.49834620746286
> 1998-05-02 -6.4357083781542
> 1998-05-17 -2.25359807972754
> 1998-05-21 -2.55799006865995
> 1999-08-22 -2.25114162617707
> 1999-08-25 -1.47905397376409
> 1999-09-05 -0.641589808755325
> 1999-09-09 -0.648954682695949
> 1999-09-13 -0.726364489272492
> 1999-09-16 -1.28445236942011
> ")
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 20:14 de 09/09/19, Ogbos Okike escreveu:
> > Dear Bert and Jeff,
> > Thank you for looking at this.
> > I am surprised my message was not in plain text. It has been
> > configured to send message to the list in plain text earlier before.
> >
> > The data again please.
> >
> > 1997-11-23 -2.91709629064653
> > 1997-12-07 -0.960255426066815
> > 1997-12-11 -1.98210752999868
> > 1997-12-20 -1.10800598439855
> > 1998-01-01 -1.00090115428118
> > 1998-01-29 -1.03056081882709
> > 1998-03-27 -0.873243859498216
> > 1998-04-09 -2.06378384750109
> > 1998-04-12 -2.06826431469008
> > 1998-04-19 -2.49834620746286
> > 1998-05-02 -6.4357083781542
> > 1998-05-17 -2.25359807972754
> > 1998-05-21 -2.55799006865995
> > 1999-08-22 -2.25114162617707
> > 1999-08-25 -1.47905397376409
> > 1999-09-05 -0.641589808755325
> > 1999-09-09 -0.648954682695949
> > 1999-09-13 -0.726364489272492
> > 1999-09-16 -1.28445236942011
> >
> > The first column is  date and the second is another data of interest.
> >
> > The date is long but note sequential. Runs randomly from 1953 to 2019.
> >
> > I would like to select any range of date from year A to year B.
> >
> > Thank you again for your help.
> > Best
> > Ogbos
> >
> >
> > On Mon, Sep 9, 2019 at 6:18 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> >>
> >> Or the column is not named "date", or it is a factor... and the question is not posted in plain text....
> >>
> >> On September 9, 2019 9:55:48 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >>> I would guess that you first need to convert your textual dates to a
> >>> date-time object via as.date, but as you failed to provide a
> >>> reproducible
> >>> example (e.g. via dput) I may be wrong. Maybe others may have greater
> >>> insight.
> >>>
> >>> Bert Gunter
> >>>
> >>> "The trouble with having an open mind is that people keep coming along
> >>> and
> >>> sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>>
> >>> On Mon, Sep 9, 2019 at 8:55 AM Ogbos Okike <giftedlife2014 at gmail.com>
> >>> wrote:
> >>>
> >>>> Dear Contributors,
> >>>> I have a data frame of the form:
> >>>> 1997-11-23 -2.91709629064653
> >>>> 1997-12-07 -0.960255426066815
> >>>> 1997-12-11 -1.98210752999868
> >>>> 1997-12-20 -1.10800598439855
> >>>> 1998-01-01 -1.00090115428118
> >>>> 1998-01-29 -1.03056081882709
> >>>> 1998-03-27 -0.873243859498216
> >>>> 1998-04-09 -2.06378384750109
> >>>> 1998-04-12 -2.06826431469008
> >>>> 1998-04-19 -2.49834620746286
> >>>> 1998-05-02 -6.4357083781542
> >>>> 1998-05-17 -2.25359807972754
> >>>> 1998-05-21 -2.55799006865995
> >>>> 1999-08-22 -2.25114162617707
> >>>> 1999-08-25 -1.47905397376409
> >>>> 1999-09-05 -0.641589808755325
> >>>> 1999-09-09 -0.648954682695949
> >>>> 1999-09-13 -0.726364489272492
> >>>> 1999-09-16 -1.28445236942011
> >>>>
> >>>> The events happen randomly and so the date is non-sequential. It run
> >>> form
> >>>> 1953 to 2019.
> >>>>
> >>>> I would like to select all the events/dates between 1998 to 2005.
> >>>>
> >>>> One of the things I tried is:
> >>>> Year <- subset(MOSCFD50, date > "1998-01-01" & date < "2005-12-31").
> >>>>
> >>>> But it didn't work.
> >>>>
> >>>> I would be thankful if you could please redirect me.
> >>>>
> >>>> Thank you very much.
> >>>> Best regards
> >>>> Ogbos
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From putr@_@utumn86 @end|ng |rom y@hoo@com  Tue Sep 10 04:19:36 2019
From: putr@_@utumn86 @end|ng |rom y@hoo@com (smart hendsome)
Date: Tue, 10 Sep 2019 02:19:36 +0000 (UTC)
Subject: [R] Moving 2nd column into 1st column using R
References: <1106371065.5054366.1568081976319.ref@mail.yahoo.com>
Message-ID: <1106371065.5054366.1568081976319@mail.yahoo.com>

Hi R-user,
I have a problem regarding R.? How can I move my 2nd column into 1st column.? For example I have data as below:
 mydf <- data.frame(matrix(1:6, ncol = 2))
?mydf
? X1 X2? ?1? ?4? ?2? ?5? ?3? ?6
I want move my 2nd column become like this:
? X1?? ?1? ?? ?2?? ?3?? ?4? ?5? ?6
Hope anyone can help me. Many thanks.

Zuhri
?
	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 10 05:48:20 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 9 Sep 2019 20:48:20 -0700
Subject: [R] Moving 2nd column into 1st column using R
In-Reply-To: <1106371065.5054366.1568081976319@mail.yahoo.com>
References: <1106371065.5054366.1568081976319.ref@mail.yahoo.com>
 <1106371065.5054366.1568081976319@mail.yahoo.com>
Message-ID: <573ac2e0-373c-ba4a-ae88-99c74782407e@comcast.net>


On 9/9/19 7:19 PM, smart hendsome via R-help wrote:
> Hi R-user,
> I have a problem regarding R.? How can I move my 2nd column into 1st column.? For example I have data as below:
>   mydf <- data.frame(matrix(1:6, ncol = 2))
>  ?mydf
>  ? X1 X2? ?1? ?4? ?2? ?5? ?3? ?6
> I want move my 2nd column become like this:
>  ? X1?? ?1? ?? ?2?? ?3?? ?4? ?5? ?6
> Hope anyone can help me. Many thanks.
>
> Zuhri
>   
> 	[[alternative HTML version deleted]]


I doubt that anyone can tell what your intentions are. You ahve posted 
in html and the mailserver does not interpret html code. So repost in 
plain text .... as the posting guide advises.


-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Sep 10 06:34:02 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Sep 2019 14:34:02 +1000
Subject: [R] Moving 2nd column into 1st column using R
In-Reply-To: <1106371065.5054366.1568081976319@mail.yahoo.com>
References: <1106371065.5054366.1568081976319.ref@mail.yahoo.com>
 <1106371065.5054366.1568081976319@mail.yahoo.com>
Message-ID: <CA+8X3fXKT7M6anwKh-wFGTCBvQW9596m_EWTt0f=H10OJ0Qx5w@mail.gmail.com>

Hi Zuhri,
Try:

mydf<-mydf[,c(2,1)]

You might be surprised.

Jim

On Tue, Sep 10, 2019 at 12:20 PM smart hendsome via R-help
<r-help at r-project.org> wrote:
>
> Hi R-user,
> I have a problem regarding R.  How can I move my 2nd column into 1st column.  For example I have data as below:
>  mydf <- data.frame(matrix(1:6, ncol = 2))
>  mydf
>   X1 X2   1   4   2   5   3   6
> I want move my 2nd column become like this:
>   X1    1      2    3    4   5   6
> Hope anyone can help me. Many thanks.
>
> Zuhri
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r-p@ck@ge@ @end|ng |rom r-project@org  Mon Sep  9 14:26:18 2019
From: r-p@ck@ge@ @end|ng |rom r-project@org (Ezequiel Toum via R-packages)
Date: Mon, 9 Sep 2019 09:26:18 -0300 (ART)
Subject: [R] =?utf-8?q?=5BR-pkgs=5D_New_package_=E2=80=98HBV=2EIANIGLA?=
 =?utf-8?q?=E2=80=99_for_hydrological_modeling?=
Message-ID: <970603173.12400643.1568031978544.JavaMail.zimbra@mendoza-conicet.gob.ar>



Hi, 




a new package ?HBV.IANIGLA? for hydrological modeling has been relesased. 

CRAN: [ https://cran.r-project.org/web/packages/HBV.IANIGLA/index.html | https://cran.r-project.org/web/packages/HBV.IANIGLA/index.html ] 


In case of doubts do not hesitate to write. 




Best, 

Ezequiel Toum 
-- 
Ezequiel Toum 
Ingeniero Civil 
Becario Doctoral 
https://www.mendoza-conicet.gob.ar/portal/ianigla/paginas/index/integrantes87 

Instituto Argentino de Nivolog?a, 
Glaciolog?a y Ciencias Ambientales (IANIGLA) 
CCT-CONICET-Mendoza 
C.C. 330, (5500) Mendoza, Argentina 
Tel: 54(261)5244266 
Fax: 54(261)5244201 

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From j|mm@@@uk @end|ng |rom gm@||@com  Tue Sep 10 11:51:37 2019
From: j|mm@@@uk @end|ng |rom gm@||@com (Jim Maas)
Date: Tue, 10 Sep 2019 10:51:37 +0100
Subject: [R] missing NEWS.pdf
Message-ID: <CAGQ6_y_CB8-k5nvjZtx5C9ox+Xhm2Yp=2ERMWBtVU0yOc9JV7g@mail.gmail.com>

I usually compile my own version of R on Ubuntu, now 18.04 and it works
fine. I recently tried to compile v 3.6.1 and it all worked until the end
of the "make install" which did not complete because it said it was missing
"NEWS.pdf".  Is this a bug or oversight, or have I done something wrong?
Thanks
J

-- 
Jim Maas
jimmaasuk  at gmail.com

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Sep 10 12:38:19 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 10 Sep 2019 12:38:19 +0200
Subject: [R] R_BATCH_OPTIONS not respected?
In-Reply-To: <CAM3-KjbcUbDviH-3LzFiUGy_2MsPEreyUCz_wTxJgk-BZoE8Lg@mail.gmail.com>
References: <CAM3-KjbcUbDviH-3LzFiUGy_2MsPEreyUCz_wTxJgk-BZoE8Lg@mail.gmail.com>
Message-ID: <23927.32027.55898.471597@stat.math.ethz.ch>

>>>>> Marius Hofert 
>>>>>     on Mon, 9 Sep 2019 22:38:38 +0200 writes:

    > Hi,
    > I typically start R with "--no-restore --no-save" (to avoid .RData
    > files being written) and would like to have the same behavior under 'R
    > CMD BATCH'. I use R_BATCH_OPTIONS="--no-restore --no-save" in my
    > ~/.Renviron but running an R script with 'R CMD BATCH' still produces
    > a .RData file. What's the correct way of getting the '--no-restore
    > --no-save' options when in batch mode?

    > (This is on macOS 10.14.6 with R version 3.6.1)

Maybe macOS is the problem?

It works fine on Linux:

export R_BATCH_OPTIONS='--no-save --no-restore'
R CMD BATCH <some>.R 

produces  <some>.Rout and nothing else  for me


Martin

    > Thanks & cheers,
    > M

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@  Tue Sep 10 13:37:22 2019
From: m@r|u@@ho|ert @end|ng |rom uw@ter|oo@c@ (Marius Hofert)
Date: Tue, 10 Sep 2019 13:37:22 +0200
Subject: [R] R_BATCH_OPTIONS not respected?
In-Reply-To: <ecb114ec674b42159dff91975950bf7e@connhm02.connect.uwaterloo.ca>
References: <CAM3-KjbcUbDviH-3LzFiUGy_2MsPEreyUCz_wTxJgk-BZoE8Lg@mail.gmail.com>
 <ecb114ec674b42159dff91975950bf7e@connhm02.connect.uwaterloo.ca>
Message-ID: <CAM3-KjZC7s28OTBL0W8xdu-xcgzhZQE9SvAXcqFg0uNcNUSsjA@mail.gmail.com>

On Tue, Sep 10, 2019 at 12:38 PM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Marius Hofert
> >>>>>     on Mon, 9 Sep 2019 22:38:38 +0200 writes:
>
>     > Hi,
>     > I typically start R with "--no-restore --no-save" (to avoid .RData
>     > files being written) and would like to have the same behavior under 'R
>     > CMD BATCH'. I use R_BATCH_OPTIONS="--no-restore --no-save" in my
>     > ~/.Renviron but running an R script with 'R CMD BATCH' still produces
>     > a .RData file. What's the correct way of getting the '--no-restore
>     > --no-save' options when in batch mode?
>
>     > (This is on macOS 10.14.6 with R version 3.6.1)
>
> Maybe macOS is the problem?
>
> It works fine on Linux:
>
> export R_BATCH_OPTIONS='--no-save --no-restore'
> R CMD BATCH <some>.R

Hoi Martin,

Thanks for helping. This also works for me, but not if I put
R_BATCH_OPTIONS="--no-restore --no-save" in ~/.Renviron.
If I have an R script called MWE.R containing
print(Sys.getenv("R_BATCH_OPTIONS")), I correctly see "--no-restore
--no-save"
being printed to .Rout, but still obtain .RData. (I also think this is
a macOS problem, but couldn't figure it out yet).

Cheers,
M

>
> produces  <some>.Rout and nothing else  for me
>
>
> Martin
>
>     > Thanks & cheers,
>     > M
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Tue Sep 10 13:52:32 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 10 Sep 2019 13:52:32 +0200
Subject: [R] missing NEWS.pdf
In-Reply-To: <CAGQ6_y_CB8-k5nvjZtx5C9ox+Xhm2Yp=2ERMWBtVU0yOc9JV7g@mail.gmail.com>
References: <CAGQ6_y_CB8-k5nvjZtx5C9ox+Xhm2Yp=2ERMWBtVU0yOc9JV7g@mail.gmail.com>
Message-ID: <DA867E2A-5802-4EB4-BCCD-A33397A4CA20@gmail.com>

I rarely do a full install, but isn't there a "make docs" step, which you may have omitted?

-pd

> On 10 Sep 2019, at 11:51 , Jim Maas <jimmaasuk at gmail.com> wrote:
> 
> I usually compile my own version of R on Ubuntu, now 18.04 and it works
> fine. I recently tried to compile v 3.6.1 and it all worked until the end
> of the "make install" which did not complete because it said it was missing
> "NEWS.pdf".  Is this a bug or oversight, or have I done something wrong?
> Thanks
> J
> 
> -- 
> Jim Maas
> jimmaasuk  at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Go|denS @end|ng |rom NJHe@|th@org  Tue Sep 10 20:13:47 2019
From: Go|denS @end|ng |rom NJHe@|th@org (Golden, Shelby)
Date: Tue, 10 Sep 2019 18:13:47 +0000
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <CABcYAd+zk-sLe41OvJSta41huDTY7PAS=Z_eJgqcscJCHtFfoQ@mail.gmail.com>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
 <CABcYAd+zk-sLe41OvJSta41huDTY7PAS=Z_eJgqcscJCHtFfoQ@mail.gmail.com>
Message-ID: <29557C58-3162-4414-B610-D8EBFDDD735A@njhealth.org>

Wow, this is great! Thank you, Richard, for going so in-depth with this explanation.

My ultimate goal is to create a vector that stores logical evaluations to be used later in a function that subsets data. I?ve coded multiple projects, now, that require this kind of sub-setting across multiple unique logical evaluations. So, streamlining the in-put and the out-put is ideal to minimize error and generalize my code.

I will look further into this information to see if it can help me get around using parse(text = )), which, to my understanding, is not a good coding method (https://stackoverflow.com/questions/1743698/evaluate-expression-given-as-a-string - comment left Martin Maechler).

Thank you again, and I hope you have a wonderful week!

Shelby


From: Richard O'Keefe <raoknz at gmail.com>
Date: Sunday, September 8, 2019 at 11:01 PM
To: "Golden, Shelby" <GoldenS at NJHealth.org>
Cc: "Richard M. Heiberger" <rmh at temple.edu>, Bert Gunter <bgunter.4567 at gmail.com>, "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <GILLENWATERL at NJHEALTH.ORG>
Subject: Re: [R] [R-devel] Source Code for function

> I am looking to understand why the keyword function can take a logical argument
> (eg: x<4) and use that later inside the function's definition for logical evaluations

The "function" keyword does not take a logical argument.
Let me show you some parallels:

f <- function (x, y) {x+y}          # R
(set! f (lambda (x y) (+ x y)))     ; Scheme
f = (x, y) => { return x+y; };      // Javascript
f = (x, y) => { return x+y; };      // C#, given a suitable declaration for f
f = (x, y) -> { return x+y; }       // Java, given a suitable declaration for f.
lambda x y; x+y end -> f;           // Pop-2, older than the others.

In all of these,
  - there is something ('function', 'lambda', '=>', '->') that
    says "here is an anonymous function"
  - there is a list of zero or more parameters
  - there is a body which may contain statements and may also
    return a result.
The keyword in itself does nothing.  The compiler recognises the
construction and generates code for a procedure that is bound to
the environment where it is created, so that it can find variables
other than those in its parameter list.

When it comes to passing parameters to a function, there is
nothing special about logical expressions in any of these languages.

Now there *is* something about functions in R that is special.
The S language (which R is based on) is the only one I am familiar
with that combines two properties:
 - it is an imperative language with side effects to variables
 - it does not evaluate function arguments when they are passed
   but when they are first *used*.
An obvious reason for this is to allow plotting methods to construct
labels from their arguments and to allow model fitting methods to
remember the form of the model.

If you want argument evaluation delayed for any other reason, it is
probably better to pass a function.  See
> ?integrate
 -- the first argument is a function, not a general expression
> ?optim
 -- the second argument is a function, not a general expression
(That is, the argument in question is an expression whose value must
be a function, not an expression to be manipulated *textually* or as
a formula.)



On Sat, 7 Sep 2019 at 08:07, Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>> wrote:
Thank you all for your reply. I should clarify, that I am looking to understand why the keyword function can take a logical argument (eg: x<4) and use that later inside the function's definition for logical evaluations.

Consider this example, which is a simplification of getAnywhere(subset.data.frame):
x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
test <- function(x, logic){
        e <- substitute(logic)
        r <- eval(e, x, parent.frame())
        r[r]
}


Shelby


On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of rmh at temple.edu<mailto:rmh at temple.edu>> wrote:

    You might also want to look at the codetools package, for example the
    showTree function " Prints a Lisp-style representation of R
    expression."

    > library(codetools)

    > showTree(quote(x %*% x))
    (%*% x x)
    > showTree(quote(a+b))
    (+ a b)
    > showTree(quote(y ~ a+b))
    (~ y (+ a b))

    On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:
    >
    > The following may be of use (it gives the parse tree of the text):
    >
    > > z <- as.list(parse(text = "function(x)x %*% x"))
    > > z[[1]]
    > function(x) x %*% x
    > > z[[c(1,1)]]
    > `function`
    > > z[[c(1,2)]]
    > $x
    > > z[[c(1,3)]]
    > x %*% x
    > > z[[c(1,3,1)]]
    > `%*%`
    > > z[[c(1,3,2)]]
    > x
    > > z[[c(1,3,3)]]
    > x
    >
    >
    > Bert Gunter
    >
    >
    >
    > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com<mailto:szwjf08 at gmail.com>> wrote:
    >
    > > If you are looking for an R code parser, I think the `parse` and `eval`
    > > function might be a good start point. See the example below.
    > >
    > > > parse(text="function(x)message(x)")
    > > expression(function(x)message(x))
    > > > eval(parse(text="function(x)message(x)"))
    > > function(x)message(x)
    > >
    > > Best,
    > > Jiefei
    > >
    > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>>
    > > wrote:
    > >
    > >> Hello Bert,
    > >>
    > >> Thank you for the reply and your clarifications. Yes, it might be helpful
    > >> to look into R?s formal grammar to see how ?function? parses input to
    > >> delegate correct syntax. Is that accessible online?
    > >>
    > >> Thank you,
    > >> Shelby
    > >>
    > >>
    > >> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
    > >> Date: Friday, September 6, 2019 at 10:44 AM
    > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
    > >> Cc: "r-help at R-project.org" <r-help at r-project.org<mailto:r-help at r-project.org>>, "Gillenwater, Lucas" <
    > >> GILLENWATERL at NJHEALTH.ORG<mailto:GILLENWATERL at NJHEALTH.ORG>>
    > >> Subject: Re: [R] [R-devel] Source Code for function
    > >>
    > >> 1. This is a plain text list; all html is stripped. So there is no red
    > >> highlighting.
    > >>
    > >> 2. There is no "source code" for "function" -- it is a reserved keyword.
    > >> Or are you looking for R's formal grammar -- e.g. how it parses input to
    > >> determine correct syntax?
    > >>
    > >>
    > >>
    > >> Bert Gunter
    > >>
    > >> "The trouble with having an open mind is that people keep coming along
    > >> and sticking things into it."
    > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    > >>
    > >>
    > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>
    > >> <mailto:GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>>> wrote:
    > >> Hi all,
    > >>
    > >> I have been attempting to access the source code for the keyword
    > >> ?function? to better understand how it assigns and stores logical inputs,
    > >> like in the subset() [base] function. Does anyone know how I can access the
    > >> source code for this?
    > >>
    > >> For example, if I have
    > >> norm <- function(x){
    > >>       sqrt(x%*%x))
    > >> }
    > >> I am looking for the source code for the ?function? portion, highlighted
    > >> in red.
    > >>
    > >> Thank you for your time and assistance,
    > >> Shelby Golden
    > >> Lab Researcher Technician
    > >> Dr. Russell Bowler?s Lab
    > >> Department of Medicine
    > >> National Jewish Health in Denver, CO
    > >> Phone: (303) 270-2598
    > >>
    > >> NOTICE: This email message is for the sole use of the intended
    > >> recipient(s) and may contain confidential and privileged information. Any
    > >> unauthorized review, use, disclosure or distribution is prohibited. If you
    > >> are not the intended recipient, please contact the sender by reply email
    > >> and destroy all copies of the original message.
    > >>         [[alternative HTML version deleted]]
    > >>
    > >> ______________________________________________
    > >> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
    > >> UNSUBSCRIBE and more, see
    > >> https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw><
    > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
    > >> >
    > >> PLEASE do read the posting guide
    > >> http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s><
    > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
    > >> >
    > >> and provide commented, minimal, self-contained, reproducible code.
    > >>
    > >>         [[alternative HTML version deleted]]
    > >>
    > >> ______________________________________________
    > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    > >> https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
    > >> PLEASE do read the posting guide
    > >> http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
    > >> and provide commented, minimal, self-contained, reproducible code.
    > >>
    > >
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
    > and provide commented, minimal, self-contained, reproducible code.

    ______________________________________________
    R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
    and provide commented, minimal, self-contained, reproducible code.



NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From gpetr|@ @end|ng |rom u@rk@edu  Tue Sep 10 23:44:34 2019
From: gpetr|@ @end|ng |rom u@rk@edu (Giovanni Petris)
Date: Tue, 10 Sep 2019 21:44:34 +0000
Subject: [R] Calling a LAPACK subroutine from R
Message-ID: <DM6PR04MB39154A2AC724DC1A1ED7ABFEC3B60@DM6PR04MB3915.namprd04.prod.outlook.com>


Hello R-helpers!

I am trying to call a LAPACK subroutine directly from my R code using .Fortran(), but R cannot find the symbol name. How can I register/load the appropriate library?

> ### AR(1) Precision matrix
> n <- 4L
> phi <- 0.64
> AB <- matrix(0, 2, n)
> AB[1, ] <- c(1, rep(1 + phi^2, n-2), 1)
> AB[2, -n] <- -phi
> round(AB, 3)
      [,1]  [,2]  [,3] [,4]
[1,]  1.00  1.41  1.41    1
[2,] -0.64 -0.64 -0.64    0
> 
> ### Cholesky factor
> AB.ch <- .Fortran("dpbtrf", UPLO = 'L', N = as.integer(n),
+                  KD = 1L, AB = AB, LDAB = 2L, INFO = as.integer(0))$AB
Error in .Fortran("dpbtrf", UPLO = "L", N = as.integer(n), KD = 1L, AB = AB,  : 
  Fortran symbol name "dpbtrf" not in load table
> sessionInfo()
R version 3.6.0 (2019-04-26)
Platform: x86_64-apple-darwin18.5.0 (64-bit)
Running under: macOS Mojave 10.14.6

Matrix products: default
BLAS/LAPACK: /usr/local/Cellar/openblas/0.3.6_1/lib/libopenblasp-r0.3.6.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.6.0 tools_3.6.0   

Thank you in advance for your help!

Best,
Giovanni Petris



--
Giovanni Petris, PhD
Professor
Director of Statistics
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701



From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep 11 03:54:57 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 10 Sep 2019 18:54:57 -0700
Subject: [R] [R-devel] Source Code for function
In-Reply-To: <29557C58-3162-4414-B610-D8EBFDDD735A@njhealth.org>
References: <65BDA5DE-C3A4-46C9-B7AB-73DDC9C5F881@njhealth.org>
 <CAGxFJbSjBHPDjv2=cd=xnwnQCyvTiJHYZLOssBhEqkPM7QBcDw@mail.gmail.com>
 <CA3D9EC2-94C4-482A-B8A2-1DAD54192CBF@njhealth.org>
 <CAGiFhPMe2_0Q_pXXNX9QFp9wBgPbGZK+1ueCfmCMoMvf74bdiQ@mail.gmail.com>
 <CAGxFJbRhTh1e56-eHCkjooErVqG8pU2hG5e_q8hRXfW9xMpwfw@mail.gmail.com>
 <CAGx1TMC5UmO1T6bbO9uzVf4pc4MZwm7bmZwXWwvps_i6u6_96Q@mail.gmail.com>
 <0F55EA10-574C-415D-A18C-7EA8C078EC15@njhealth.org>
 <CABcYAd+zk-sLe41OvJSta41huDTY7PAS=Z_eJgqcscJCHtFfoQ@mail.gmail.com>
 <29557C58-3162-4414-B610-D8EBFDDD735A@njhealth.org>
Message-ID: <604a626d-e2d6-4105-0316-764e368610c3@comcast.net>


On 9/10/19 11:13 AM, Golden, Shelby wrote:
> Wow, this is great! Thank you, Richard, for going so in-depth with this explanation.
>
> My ultimate goal is to create a vector that stores logical evaluations to be used later in a function that subsets data. I?ve coded multiple projects, now, that require this kind of sub-setting across multiple unique logical evaluations. So, streamlining the in-put and the out-put is ideal to minimize error and generalize my code.
>
> I will look further into this information to see if it can help me get around using parse(text = )), which, to my understanding, is not a good coding method (https://stackoverflow.com/questions/1743698/evaluate-expression-given-as-a-string - comment left Martin Maechler).


It appears you have in mind keeping around a set of "off-the-shelf" 
expressions that will be chosen for varying situations. It seems to me 
that you should instead be storing complex predefined logical 
constructions in functions that can be applied to multi-column objects 
like dataframes, data.tables, or matrices:


 > A_is_GT_B <- function(A, B){ A > B}
 > set.seed(123)
 > test <- data.frame(x=sample(10),y=sample(10), z=sample(10) )
 > test$x_GT_y <- with(test, A_is_GT_B(x,y))
 > test
 ??? x? y? z x_GT_y
1?? 3 10? 8? FALSE
2? 10? 5? 7?? TRUE
3?? 2? 3? 2? FALSE
4?? 8? 8? 1? FALSE
5?? 6? 1? 6?? TRUE
6?? 9? 4? 3?? TRUE
7?? 1? 6? 4? FALSE
8?? 7? 9 10? FALSE
9?? 5? 7? 9? FALSE

10? 4? 2? 5?? TRUE

The expressions then are encapsulated inside the function and you can 
make lists that carry multiple functions.

It does remain possible to have expression vectors:

exprs <- expression( x > y, x >+ z)

eval( exprs[[2]], test)

 > exprs <- expression( x > y, x >+ z)
 >
 > eval( exprs[[2]], test)
 ?[1] FALSE? TRUE FALSE? TRUE FALSE? TRUE FALSE FALSE FALSE FALSE


This however is considered poor practice. Notice that you are 
constrained to know ahead of time the column names of the arguments to 
be passed, whereas with the function-approach, the names are not 
required and you can use positional matching.

-- 

David.

>
> Thank you again, and I hope you have a wonderful week!
>
> Shelby
>
>
> From: Richard O'Keefe <raoknz at gmail.com>
> Date: Sunday, September 8, 2019 at 11:01 PM
> To: "Golden, Shelby" <GoldenS at NJHealth.org>
> Cc: "Richard M. Heiberger" <rmh at temple.edu>, Bert Gunter <bgunter.4567 at gmail.com>, "r-help at R-project.org" <r-help at r-project.org>, "Gillenwater, Lucas" <GILLENWATERL at NJHEALTH.ORG>
> Subject: Re: [R] [R-devel] Source Code for function
>
>> I am looking to understand why the keyword function can take a logical argument
>> (eg: x<4) and use that later inside the function's definition for logical evaluations
> The "function" keyword does not take a logical argument.
> Let me show you some parallels:
>
> f <- function (x, y) {x+y}          # R
> (set! f (lambda (x y) (+ x y)))     ; Scheme
> f = (x, y) => { return x+y; };      // Javascript
> f = (x, y) => { return x+y; };      // C#, given a suitable declaration for f
> f = (x, y) -> { return x+y; }       // Java, given a suitable declaration for f.
> lambda x y; x+y end -> f;           // Pop-2, older than the others.
>
> In all of these,
>    - there is something ('function', 'lambda', '=>', '->') that
>      says "here is an anonymous function"
>    - there is a list of zero or more parameters
>    - there is a body which may contain statements and may also
>      return a result.
> The keyword in itself does nothing.  The compiler recognises the
> construction and generates code for a procedure that is bound to
> the environment where it is created, so that it can find variables
> other than those in its parameter list.
>
> When it comes to passing parameters to a function, there is
> nothing special about logical expressions in any of these languages.
>
> Now there *is* something about functions in R that is special.
> The S language (which R is based on) is the only one I am familiar
> with that combines two properties:
>   - it is an imperative language with side effects to variables
>   - it does not evaluate function arguments when they are passed
>     but when they are first *used*.
> An obvious reason for this is to allow plotting methods to construct
> labels from their arguments and to allow model fitting methods to
> remember the form of the model.
>
> If you want argument evaluation delayed for any other reason, it is
> probably better to pass a function.  See
>> ?integrate
>   -- the first argument is a function, not a general expression
>> ?optim
>   -- the second argument is a function, not a general expression
> (That is, the argument in question is an expression whose value must
> be a function, not an expression to be manipulated *textually* or as
> a formula.)
>
>
>
> On Sat, 7 Sep 2019 at 08:07, Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>> wrote:
> Thank you all for your reply. I should clarify, that I am looking to understand why the keyword function can take a logical argument (eg: x<4) and use that later inside the function's definition for logical evaluations.
>
> Consider this example, which is a simplification of getAnywhere(subset.data.frame):
> x = data.frame("Col1" = c(1, 2, 3, 4, 5), "Col2" = c(6, 7, 8, 9, 10))
> test <- function(x, logic){
>          e <- substitute(logic)
>          r <- eval(e, x, parent.frame())
>          r[r]
> }
>
>
> Shelby
>
>
> On 9/6/19, 1:02 PM, "R-help on behalf of Richard M. Heiberger" <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> on behalf of rmh at temple.edu<mailto:rmh at temple.edu>> wrote:
>
>      You might also want to look at the codetools package, for example the
>      showTree function " Prints a Lisp-style representation of R
>      expression."
>
>      > library(codetools)
>
>      > showTree(quote(x %*% x))
>      (%*% x x)
>      > showTree(quote(a+b))
>      (+ a b)
>      > showTree(quote(y ~ a+b))
>      (~ y (+ a b))
>
>      On Fri, Sep 6, 2019 at 2:30 PM Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>> wrote:
>      >
>      > The following may be of use (it gives the parse tree of the text):
>      >
>      > > z <- as.list(parse(text = "function(x)x %*% x"))
>      > > z[[1]]
>      > function(x) x %*% x
>      > > z[[c(1,1)]]
>      > `function`
>      > > z[[c(1,2)]]
>      > $x
>      > > z[[c(1,3)]]
>      > x %*% x
>      > > z[[c(1,3,1)]]
>      > `%*%`
>      > > z[[c(1,3,2)]]
>      > x
>      > > z[[c(1,3,3)]]
>      > x
>      >
>      >
>      > Bert Gunter
>      >
>      >
>      >
>      > On Fri, Sep 6, 2019 at 10:14 AM Wang Jiefei <szwjf08 at gmail.com<mailto:szwjf08 at gmail.com>> wrote:
>      >
>      > > If you are looking for an R code parser, I think the `parse` and `eval`
>      > > function might be a good start point. See the example below.
>      > >
>      > > > parse(text="function(x)message(x)")
>      > > expression(function(x)message(x))
>      > > > eval(parse(text="function(x)message(x)"))
>      > > function(x)message(x)
>      > >
>      > > Best,
>      > > Jiefei
>      > >
>      > > On Fri, Sep 6, 2019 at 12:55 PM Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>>
>      > > wrote:
>      > >
>      > >> Hello Bert,
>      > >>
>      > >> Thank you for the reply and your clarifications. Yes, it might be helpful
>      > >> to look into R?s formal grammar to see how ?function? parses input to
>      > >> delegate correct syntax. Is that accessible online?
>      > >>
>      > >> Thank you,
>      > >> Shelby
>      > >>
>      > >>
>      > >> From: Bert Gunter <bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>>
>      > >> Date: Friday, September 6, 2019 at 10:44 AM
>      > >> To: "Golden, Shelby" <GoldenS at NJHealth.org>
>      > >> Cc: "r-help at R-project.org" <r-help at r-project.org<mailto:r-help at r-project.org>>, "Gillenwater, Lucas" <
>      > >> GILLENWATERL at NJHEALTH.ORG<mailto:GILLENWATERL at NJHEALTH.ORG>>
>      > >> Subject: Re: [R] [R-devel] Source Code for function
>      > >>
>      > >> 1. This is a plain text list; all html is stripped. So there is no red
>      > >> highlighting.
>      > >>
>      > >> 2. There is no "source code" for "function" -- it is a reserved keyword.
>      > >> Or are you looking for R's formal grammar -- e.g. how it parses input to
>      > >> determine correct syntax?
>      > >>
>      > >>
>      > >>
>      > >> Bert Gunter
>      > >>
>      > >> "The trouble with having an open mind is that people keep coming along
>      > >> and sticking things into it."
>      > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>      > >>
>      > >>
>      > >> On Fri, Sep 6, 2019 at 8:51 AM Golden, Shelby <GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>
>      > >> <mailto:GoldenS at njhealth.org<mailto:GoldenS at njhealth.org>>> wrote:
>      > >> Hi all,
>      > >>
>      > >> I have been attempting to access the source code for the keyword
>      > >> ?function? to better understand how it assigns and stores logical inputs,
>      > >> like in the subset() [base] function. Does anyone know how I can access the
>      > >> source code for this?
>      > >>
>      > >> For example, if I have
>      > >> norm <- function(x){
>      > >>       sqrt(x%*%x))
>      > >> }
>      > >> I am looking for the source code for the ?function? portion, highlighted
>      > >> in red.
>      > >>
>      > >> Thank you for your time and assistance,
>      > >> Shelby Golden
>      > >> Lab Researcher Technician
>      > >> Dr. Russell Bowler?s Lab
>      > >> Department of Medicine
>      > >> National Jewish Health in Denver, CO
>      > >> Phone: (303) 270-2598
>      > >>
>      > >> NOTICE: This email message is for the sole use of the intended
>      > >> recipient(s) and may contain confidential and privileged information. Any
>      > >> unauthorized review, use, disclosure or distribution is prohibited. If you
>      > >> are not the intended recipient, please contact the sender by reply email
>      > >> and destroy all copies of the original message.
>      > >>         [[alternative HTML version deleted]]
>      > >>
>      > >> ______________________________________________
>      > >> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To
>      > >> UNSUBSCRIBE and more, see
>      > >> https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw><
>      > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZmMWRiYmMxZjFmNmI5ZDBkMz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJjljNzlmMDA4YWRmZTZjMz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw
>      > >> >
>      > >> PLEASE do read the posting guide
>      > >> http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s><
>      > >> http://mx2.njhealth.org:32224/?dmVyPTEuMDAxJiZlMTkwYmMwMzFlNjk4ZTAzNz01RDcyOEQwN18yMjk2OF8zOTk2XzEmJmFkYTkxMWRkMWRhZTFkNz0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s
>      > >> >
>      > >> and provide commented, minimal, self-contained, reproducible code.
>      > >>
>      > >>         [[alternative HTML version deleted]]
>      > >>
>      > >> ______________________________________________
>      > >> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>      > >> https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
>      > >> PLEASE do read the posting guide
>      > >> http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
>      > >> and provide commented, minimal, self-contained, reproducible code.
>      > >>
>      > >
>      >
>      >         [[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
>      > and provide commented, minimal, self-contained, reproducible code.
>
>      ______________________________________________
>      R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>      https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
>      PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
>      and provide commented, minimal, self-contained, reproducible code.
>
>
>
> NOTICE: This email message is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized review, use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5MzIyNmQ5YTc2OTc0MDMzYT01RDc1RENCMl8zNTY3N183MjY1XzEmJjI4YTJmOGIzZjc0NWM4Mz0xMjMzJiZ1cmw9aHR0cHMlM0ElMkYlMkZzdGF0JTJFZXRoeiUyRWNoJTJGbWFpbG1hbiUyRmxpc3RpbmZvJTJGci1oZWxw>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://mx1.njhealth.org:32224/?dmVyPTEuMDAxJiY5NDMyMjY5YTZhOTY0MjIwYT01RDc1RENCMl8zNTY3N183MjY1XzEmJmNjOTMyODUyMjJmNTk4ND0xMjMzJiZ1cmw9aHR0cCUzQSUyRiUyRnd3dyUyRVItcHJvamVjdCUyRW9yZyUyRnBvc3RpbmctZ3VpZGUlMkVodG1s>
> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep 11 10:51:17 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 11 Sep 2019 08:51:17 +0000
Subject: [R] Moving 2nd column into 1st column using R
In-Reply-To: <CA+8X3fXKT7M6anwKh-wFGTCBvQW9596m_EWTt0f=H10OJ0Qx5w@mail.gmail.com>
References: <1106371065.5054366.1568081976319.ref@mail.yahoo.com>
 <1106371065.5054366.1568081976319@mail.yahoo.com>
 <CA+8X3fXKT7M6anwKh-wFGTCBvQW9596m_EWTt0f=H10OJ0Qx5w@mail.gmail.com>
Message-ID: <4912568bbd984ce690801bc784483cc6@SRVEXCHCM1302.precheza.cz>

Or maybe use stack

stack(mydf)

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jim Lemon
> Sent: Tuesday, September 10, 2019 6:34 AM
> To: smart hendsome <putra_autumn86 at yahoo.com>; r-help mailing list <r-
> help at r-project.org>
> Subject: Re: [R] Moving 2nd column into 1st column using R
>
> Hi Zuhri,
> Try:
>
> mydf<-mydf[,c(2,1)]
>
> You might be surprised.
>
> Jim
>
> On Tue, Sep 10, 2019 at 12:20 PM smart hendsome via R-help <r-help at r-
> project.org> wrote:
> >
> > Hi R-user,
> > I have a problem regarding R.  How can I move my 2nd column into 1st
> column.  For example I have data as below:
> >  mydf <- data.frame(matrix(1:6, ncol = 2))  mydf
> >   X1 X2   1   4   2   5   3   6
> > I want move my 2nd column become like this:
> >   X1    1      2    3    4   5   6
> > Hope anyone can help me. Many thanks.
> >
> > Zuhri
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From tr@xp|@yer @end|ng |rom gm@||@com  Wed Sep 11 14:36:15 2019
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 11 Sep 2019 14:36:15 +0200
Subject: [R] Moving 2nd column into 1st column using R
In-Reply-To: <1106371065.5054366.1568081976319@mail.yahoo.com>
References: <1106371065.5054366.1568081976319.ref@mail.yahoo.com>
 <1106371065.5054366.1568081976319@mail.yahoo.com>
Message-ID: <CAGAA5be-yHuOZb=O1KQCqwjKK=KRAec8pqm52ZZiy25dZsAK0g@mail.gmail.com>

On Tue, 10 Sep 2019 at 04:20, smart hendsome via R-help <
r-help at r-project.org> wrote:
>
> Hi R-user,
> I have a problem regarding R.  How can I move my 2nd column into 1st
column.  For example I have data as below:
>  mydf <- data.frame(matrix(1:6, ncol = 2))
>  mydf
>   X1 X2   1   4   2   5   3   6
> I want move my 2nd column become like this:
>   X1    1      2    3    4   5   6
> Hope anyone can help me. Many thanks.


I am not sure I understand your problem, but try:

mydf <- data.frame(matrix(1:6, ncol = 2, byrow = TRUE))

Regards
Martin

	[[alternative HTML version deleted]]


From gor@n@bro@trom @end|ng |rom umu@@e  Wed Sep 11 16:13:29 2019
From: gor@n@bro@trom @end|ng |rom umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Wed, 11 Sep 2019 16:13:29 +0200
Subject: [R] Calling a LAPACK subroutine from R
In-Reply-To: <DM6PR04MB39154A2AC724DC1A1ED7ABFEC3B60@DM6PR04MB3915.namprd04.prod.outlook.com>
References: <DM6PR04MB39154A2AC724DC1A1ED7ABFEC3B60@DM6PR04MB3915.namprd04.prod.outlook.com>
Message-ID: <82aa9ad8-570c-7dd5-16e0-a512742fe24d@umu.se>

Giovanni,

you are trying to open a can of worms. Se recent discussions on 
R-pkg-devel, Writing R Extensions, and the help page for .Fortran.

Best, G?ran

On 2019-09-10 23:44, Giovanni Petris wrote:
> 
> Hello R-helpers!
> 
> I am trying to call a LAPACK subroutine directly from my R code using .Fortran(), but R cannot find the symbol name. How can I register/load the appropriate library?
> 
>> ### AR(1) Precision matrix
>> n <- 4L
>> phi <- 0.64
>> AB <- matrix(0, 2, n)
>> AB[1, ] <- c(1, rep(1 + phi^2, n-2), 1)
>> AB[2, -n] <- -phi
>> round(AB, 3)
>        [,1]  [,2]  [,3] [,4]
> [1,]  1.00  1.41  1.41    1
> [2,] -0.64 -0.64 -0.64    0
>>
>> ### Cholesky factor
>> AB.ch <- .Fortran("dpbtrf", UPLO = 'L', N = as.integer(n),
> +                  KD = 1L, AB = AB, LDAB = 2L, INFO = as.integer(0))$AB
> Error in .Fortran("dpbtrf", UPLO = "L", N = as.integer(n), KD = 1L, AB = AB,  :
>    Fortran symbol name "dpbtrf" not in load table
>> sessionInfo()
> R version 3.6.0 (2019-04-26)
> Platform: x86_64-apple-darwin18.5.0 (64-bit)
> Running under: macOS Mojave 10.14.6
> 
> Matrix products: default
> BLAS/LAPACK: /usr/local/Cellar/openblas/0.3.6_1/lib/libopenblasp-r0.3.6.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.6.0 tools_3.6.0
> 
> Thank you in advance for your help!
> 
> Best,
> Giovanni Petris
> 
> 
> 
> --
> Giovanni Petris, PhD
> Professor
> Director of Statistics
> Department of Mathematical Sciences
> University of Arkansas - Fayetteville, AR 72701
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rc_grt @end|ng |rom y@hoo@|r  Wed Sep 11 16:21:49 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Wed, 11 Sep 2019 16:21:49 +0200
Subject: [R] Loading aliased file in MacOSX
Message-ID: <5c1e14c5-19a4-8ceb-8075-c8441000bac4@yahoo.fr>

If I try to load data from an alias file made using Cmd+Ctrl+A in finder 
for MacOSX, I get an error. Symbolic links are working well but 
sometimes, it is easier to use finder rather than terminal.

Has someone a solution to help R to read the original aliased file ?

Thanks

Here is a reproducible example:

A <- 10
save(A, file="A.Rdata")
rm(A)

# Make hard link
system(paste("ln A.Rdata B.Rdata"))
load(file="B.Rdata")
# It works
print(A)

rm(A)

# Make symbolic link
system(paste("ln -s A.Rdata C.Rdata"))
load(file="C.Rdata")
# It works
print(A)

rm(A)

# Make an alias of the A.Rdata file in finder using Cmd+Ctrl+A; the name 
of the new file is "A.Rdata alias"
load(file="A.Rdata alias")

It failed with this error:

Error in load(file = "A.Rdata alias") :
 ?? mauvais num??ro magique de restauration de fichier (le fichier est 
peut ??tre corrompu) -- aucune donn??e charg??e
De plus : Warning message:
 ?? file ???A.Rdata alias??? has magic number 'book'
Use of save versions prior to 2 is deprecated


From t@n@@@ @end|ng |rom gm@||@com  Wed Sep 11 22:14:03 2019
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 11 Sep 2019 13:14:03 -0700
Subject: [R] about paired or unpaired t.test or wilcox.test in R
Message-ID: <CA+JEM03sHA8PBhYaTexQarPjnCRrbhLLFvfwqK0gPPN=j-hPGQ@mail.gmail.com>

Dear all,

if would be great if you could please advise on the use of PAIRED or
UNPAIRED T.TEST or WILCOX.TEST in R :

let's say shall we have 2 samples :

-- CONTROL : where we measure the expression of 100 genes G1 ... G100 in
one million cells C1 ...C1mil

-- TREATMENT : where we measure the expression of 100 genes G1 ... G100 in
one million cells D1 ...D1mil

when we compare the expression of these 100 genes G1 ...G100, in CONTROL vs
TREATMENT, shall we use UNPAIRED TESTS, correct ?

as the cells in CONTROL C1..C1mil are different than the cells in TREATMENT
D1..D1mil ? thanks a lot !

-- bogdan

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep 11 23:05:56 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 11 Sep 2019 14:05:56 -0700
Subject: [R] about paired or unpaired t.test or wilcox.test in R
In-Reply-To: <CA+JEM03sHA8PBhYaTexQarPjnCRrbhLLFvfwqK0gPPN=j-hPGQ@mail.gmail.com>
References: <CA+JEM03sHA8PBhYaTexQarPjnCRrbhLLFvfwqK0gPPN=j-hPGQ@mail.gmail.com>
Message-ID: <532e82e5-6d8c-44f1-2123-e42b8711d0b6@comcast.net>


On 9/11/19 1:14 PM, Bogdan Tanasa wrote:
> Dear all,
>
> if would be great if you could please advise on the use of PAIRED or
> UNPAIRED T.TEST or WILCOX.TEST in R :
>
> let's say shall we have 2 samples :
>
> -- CONTROL : where we measure the expression of 100 genes G1 ... G100 in
> one million cells C1 ...C1mil
>
> -- TREATMENT : where we measure the expression of 100 genes G1 ... G100 in
> one million cells D1 ...D1mil
>
> when we compare the expression of these 100 genes G1 ...G100, in CONTROL vs
> TREATMENT, shall we use UNPAIRED TESTS, correct ?
>
> as the cells in CONTROL C1..C1mil are different than the cells in TREATMENT
> D1..D1mil ? thanks a lot !
>
> -- bogdan
>
> 	[[alternative HTML version deleted]]
 ????????? ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


Rhelp is a plain text list. It is specifically for help with R coding 
difficulties, and it is specifically NOT to advice about chosing 
analysis plans. You question raises serious analysis issues regarding 
multiple comparisons and distributional assumption which I believe are 
still the subject of research. A more welcoming venue might be the 
BioConductor mailing list or CrossValitdated.com.


-- 

David.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |@heemj@n93 @end|ng |rom y@hoo@com  Thu Sep 12 08:28:41 2019
From: |@heemj@n93 @end|ng |rom y@hoo@com (Faheem Jan)
Date: Thu, 12 Sep 2019 06:28:41 +0000 (UTC)
Subject: [R] Fw: How to read a file saved in Rstudio
In-Reply-To: <473388642.4086276.1568269568409@mail.yahoo.com>
References: <473388642.4086276.1568269568409.ref@mail.yahoo.com>
 <473388642.4086276.1568269568409@mail.yahoo.com>
Message-ID: <2083555668.4074553.1568269721731@mail.yahoo.com>



Subject: How to read a result? saved in Rstudio
 HI, i run the simulation result in other computer with high speed computer ,i save the result in the rda file. know i want to open this file rda file? in my laptop, the file loaded in my laptop , i got the error like this?load("C:/Users/Khan/Downloads/Poly.Slow.100.kappa08 (1).rda")> Poly.Slow.100.kappa08 (1).rdaError: unexpected symbol in "Poly.Slow.100.kappa08 (1).rda"?can any one help me to resolve my issue. thanks alot in advance? ??
  
	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 12 09:05:32 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 12 Sep 2019 00:05:32 -0700
Subject: [R] Fw: How to read a file saved in Rstudio
In-Reply-To: <2083555668.4074553.1568269721731@mail.yahoo.com>
References: <473388642.4086276.1568269568409.ref@mail.yahoo.com>
 <473388642.4086276.1568269568409@mail.yahoo.com>
 <2083555668.4074553.1568269721731@mail.yahoo.com>
Message-ID: <B24396EC-25BC-4BCF-82F7-387C4683FC77@dcn.davis.ca.us>

Use the correct function.. readRDS.

On September 11, 2019 11:28:41 PM PDT, Faheem Jan via R-help <r-help at r-project.org> wrote:
>
>
>Subject: How to read a result? saved in Rstudio
>HI, i run the simulation result in other computer with high speed
>computer ,i save the result in the rda file. know i want to open this
>file rda file? in my laptop, the file loaded in my laptop , i got the
>error like this?load("C:/Users/Khan/Downloads/Poly.Slow.100.kappa08
>(1).rda")> Poly.Slow.100.kappa08 (1).rdaError: unexpected symbol in
>"Poly.Slow.100.kappa08 (1).rda"?can any one help me to resolve my
>issue. thanks alot in advance? ??
>  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |@r@@on|ubo @end|ng |rom gm@||@com  Wed Sep 11 02:23:27 2019
From: |@r@@on|ubo @end|ng |rom gm@||@com (Lubo Larsson)
Date: Tue, 10 Sep 2019 19:23:27 -0500
Subject: [R] Inter-rater reliability for 3 unique raters with binary outcome
Message-ID: <CAF4B2TAJeXVM7bjdN+wthmjwPafeBXR66S-5ewfA6XA+k1sM2w@mail.gmail.com>

Hello,

I would like to know if there is an R utility for computing some
measure of inter-rater reliability/agreement for 3 raters (columns),
where each rating is a binary assessment. Further, the three raters
are unique (the same rater's assessment in any single column) so that
ideally the statistic would account for this fact.

I see there was a package "concord" that had a variety of utilities
for computing kappa stats but looks to me that it is no longer
available.


From bickis m@iii@g oii m@th@us@sk@c@  Wed Sep 11 22:51:26 2019
From: bickis m@iii@g oii m@th@us@sk@c@ (bickis m@iii@g oii m@th@us@sk@c@)
Date: Wed, 11 Sep 2019 14:51:26 -0600
Subject: [R] Strange behaviour of sapply function.
Message-ID: <8de986cf70b5e05f1ad87ff22bf7c59e.squirrel@math.usask.ca>

Here is are a few lines of my R session:

> class(income)
[1] "integer"
> class(sapply(1000*income-999,atv,sktaxb,sktax))
[1] "numeric"
> class(sapply(1000*income-1001,atv,sktaxb,sktax))
[1] "list"

Although "income" is a numeric array, and sapply works as expected
returning an array (the function "atv" returns a single numeric argument),
if subtract a large enough number from the first argument, the sapply
function now wants to return a list?   Am I missing something?

I am running version 3.3.2 on Mac OS 10.9.9


From egm@gnum @end|ng |rom y@hoo@|r  Wed Sep 11 23:00:32 2019
From: egm@gnum @end|ng |rom y@hoo@|r (Ernest GRAND)
Date: Wed, 11 Sep 2019 21:00:32 +0000 (UTC)
Subject: [R] Pspline program
References: <336210156.8190107.1568235632172.ref@mail.yahoo.com>
Message-ID: <336210156.8190107.1568235632172@mail.yahoo.com>

Hi,
I would like help from knowledgeble mai-listers in pspline matter.I just a beginner.
I have the following pspline program and I get strange (for me) results like :17.172881859251717.17297751018117.173073161111917.173168812047817.173264462992617.1733601139499for all file.
The file have?20234 data and keep 20234 data after processing by pspline.

library(sm)
library(pspline)
#Importing the dataset and converting into a matrix form#hist.df <- read.table('b1_27.txt', header=FALSE,col.names=c("A"), dec=".")
hist.df <- read.table("C:\\Users\\.....\\Desktop\\Pspline\\b1_27.txt", header=FALSE,col.names=c("A"), dec=".")
data <- as.matrix(hist.df$A,ncol=1)
#Getting a non-decreasing predictor variablex = c(1:20234)
#Fitting the pspline function, note that it will be a normal smoothing with order=2 and df = 4, method = 2 means degrees = df
res = smooth.Pspline(x,data,norder = 2,df=4,method=2)res
#Plotting the normal plot for the fitted values
sm.density(res$ysmth,model="normal")
setwd("C:\\Users\\....\\Desktop\\Pspline")
#writing the output into a tablewrite.table(res$ysmth, file = "b1_27_psp.txt", col.names = F,quote=F,row.names=F)
Thank you for your help.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: b1_27.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190911/f3891148/attachment.txt>

From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 12 11:19:20 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 12 Sep 2019 19:19:20 +1000
Subject: [R] 
 Inter-rater reliability for 3 unique raters with binary outcome
In-Reply-To: <CAF4B2TAJeXVM7bjdN+wthmjwPafeBXR66S-5ewfA6XA+k1sM2w@mail.gmail.com>
References: <CAF4B2TAJeXVM7bjdN+wthmjwPafeBXR66S-5ewfA6XA+k1sM2w@mail.gmail.com>
Message-ID: <CA+8X3fUW2U0a6UXa=QpKWgcKBKR3pTvYOm8ny1w+SFn18trKeg@mail.gmail.com>

Hi Lubo,
Have a look at the "irr" package. I transferred any unique functions
from concord to it to reduce duplication of functions in different
packages.

Jim

On Thu, Sep 12, 2019 at 7:03 PM Lubo Larsson <larssonlubo at gmail.com> wrote:
>
> Hello,
>
> I would like to know if there is an R utility for computing some
> measure of inter-rater reliability/agreement for 3 raters (columns),
> where each rating is a binary assessment. Further, the three raters
> are unique (the same rater's assessment in any single column) so that
> ideally the statistic would account for this fact.
>
> I see there was a package "concord" that had a variety of utilities
> for computing kappa stats but looks to me that it is no longer
> available.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Thu Sep 12 11:24:35 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 12 Sep 2019 12:24:35 +0300
Subject: [R] Strange behaviour of sapply function.
In-Reply-To: <8de986cf70b5e05f1ad87ff22bf7c59e.squirrel@math.usask.ca>
References: <8de986cf70b5e05f1ad87ff22bf7c59e.squirrel@math.usask.ca>
Message-ID: <CAGgJW74-1cpCCW7ix5Lk8ZSWj4HErp_wzXbw5qkyDAfVYqyu3A@mail.gmail.com>

Can you create a reproducible example?
You don't show: income, atv, sktaxb, sktax



On Thu, Sep 12, 2019 at 12:04 PM <bickis at math.usask.ca> wrote:

> Here is are a few lines of my R session:
>
> > class(income)
> [1] "integer"
> > class(sapply(1000*income-999,atv,sktaxb,sktax))
> [1] "numeric"
> > class(sapply(1000*income-1001,atv,sktaxb,sktax))
> [1] "list"
>
> Although "income" is a numeric array, and sapply works as expected
> returning an array (the function "atv" returns a single numeric argument),
> if subtract a large enough number from the first argument, the sapply
> function now wants to return a list?   Am I missing something?
>
> I am running version 3.3.2 on Mac OS 10.9.9
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 12 11:25:31 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 12 Sep 2019 19:25:31 +1000
Subject: [R] Strange behaviour of sapply function.
In-Reply-To: <8de986cf70b5e05f1ad87ff22bf7c59e.squirrel@math.usask.ca>
References: <8de986cf70b5e05f1ad87ff22bf7c59e.squirrel@math.usask.ca>
Message-ID: <CA+8X3fXV7CW9LUK7FB=asoqCSHRbatDmo4WUEL1DGTSR4B7-qQ@mail.gmail.com>

Hi bickis,
Putting on my dark glasses and flailing about with a big white stick*,
I would suggest that you look at what "atv" actually produces from
those three objects. I wouldn't be surprised to find quite different
things.

Jim
* blind guess

On Thu, Sep 12, 2019 at 7:04 PM <bickis at math.usask.ca> wrote:
>
> Here is are a few lines of my R session:
>
> > class(income)
> [1] "integer"
> > class(sapply(1000*income-999,atv,sktaxb,sktax))
> [1] "numeric"
> > class(sapply(1000*income-1001,atv,sktaxb,sktax))
> [1] "list"
>
> Although "income" is a numeric array, and sapply works as expected
> returning an array (the function "atv" returns a single numeric argument),
> if subtract a large enough number from the first argument, the sapply
> function now wants to return a list?   Am I missing something?
>
> I am running version 3.3.2 on Mac OS 10.9.9
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Sep 12 11:49:34 2019
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 12 Sep 2019 11:49:34 +0200
Subject: [R] Strange behaviour of sapply function.
In-Reply-To: <8de986cf70b5e05f1ad87ff22bf7c59e.squirrel@math.usask.ca>
Message-ID: <20190912114934.Horde.MJKMLxzUimeZNf0wf6gHRxY@webmail.your-server.de>


Quoting bickis at math.usask.ca:

> Here is are a few lines of my R session:
>
>> class(income)
> [1] "integer"
>> class(sapply(1000*income-999,atv,sktaxb,sktax))
> [1] "numeric"
>> class(sapply(1000*income-1001,atv,sktaxb,sktax))
> [1] "list"
>
> Although "income" is a numeric array, and sapply works as expected
> returning an array (the function "atv" returns a single numeric argument),
> if subtract a large enough number from the first argument, the sapply
> function now wants to return a list?   Am I missing something?
>
> I am running version 3.3.2 on Mac OS 10.9.9
>

You have not shown what 'income', 'atv', and so on are; so there is an  
infinity
of possible reasons why you get a list instead of a numeric vector.

One possible reason: what if 'atv' sometimes returns no value at all?

f <- function(x) x[x>0]
str(sapply(1:10, f))
## int [1:10] 1 2 3 4 5 6 7 8 9 10

str(sapply(-5:5, f))
## List of 11
##  $ : int(0)
##  $ : int(0)
##  $ : int(0)
##  $ : int(0)
##  $ : int(0)
##  $ : int(0)
##  $ : int 1
##  $ : int 2
##  $ : int 3
##  $ : int 4
##  $ : int 5

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep 12 13:10:02 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 12 Sep 2019 11:10:02 +0000
Subject: [R] test if something was plotted on pdf device
Message-ID: <b65499089c194cfe90a9584ae693afe7@SRVEXCHCM1302.precheza.cz>

Dear all

Is there any simple way checking whether after calling pdf device something was plotted into it?

In interactive session I used

if (dev.cur()==1) plot(ecdf(rnorm(100))) else plot(ecdf(rnorm(100)), add=T, col=i)
which enabled me to test if plot is open

But when I want to call eg. pdf("test.pdf") before cycle
dev.cur()==1 is FALSE even when no plot is drawn and plot.new error comes.

> pdf("test.pdf")

if (dev.cur()==1) plot(ecdf(rnorm(100))) else plot(ecdf(rnorm(100)), add=T, col=i)

Error in segments(ti.l, y, ti.r, y, col = col.hor, lty = lty, lwd = lwd,  :
  plot.new has not been called yet

Best regards
Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep 12 14:28:35 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 12 Sep 2019 08:28:35 -0400
Subject: [R] test if something was plotted on pdf device
In-Reply-To: <b65499089c194cfe90a9584ae693afe7@SRVEXCHCM1302.precheza.cz>
References: <b65499089c194cfe90a9584ae693afe7@SRVEXCHCM1302.precheza.cz>
Message-ID: <a553f483-72a9-8505-0612-a84a8f826838@gmail.com>

On 12/09/2019 7:10 a.m., PIKAL Petr wrote:
> Dear all
> 
> Is there any simple way checking whether after calling pdf device something was plotted into it?
> 
> In interactive session I used
> 
> if (dev.cur()==1) plot(ecdf(rnorm(100))) else plot(ecdf(rnorm(100)), add=T, col=i)
> which enabled me to test if plot is open
> 
> But when I want to call eg. pdf("test.pdf") before cycle
> dev.cur()==1 is FALSE even when no plot is drawn and plot.new error comes.
> 
>> pdf("test.pdf")
> 
> if (dev.cur()==1) plot(ecdf(rnorm(100))) else plot(ecdf(rnorm(100)), add=T, col=i)
> 
> Error in segments(ti.l, y, ti.r, y, col = col.hor, lty = lty, lwd = lwd,  :
>    plot.new has not been called yet
> 

I don't know if this is reliable or not, but you could use code like this:

   f <- tempfile()
   pdf(f)
   blankPlot <- recordPlot()
   dev.off()
   unlink(f)

   pdf("test.pdf")

   ...  unknown operations ...

   if (dev.cur() == 1 || identical(recordPlot(), blankPlot))
     plot(ecdf(rnorm(100)))
   else
     plot(ecdf(rnorm(100)), add=TRUE, col=i)



Duncan Murdoch


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 12 16:36:17 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 12 Sep 2019 07:36:17 -0700
Subject: [R] Fw: How to read a file saved in Rstudio
In-Reply-To: <1679088869.4077904.1568273379300@mail.yahoo.com>
References: <473388642.4086276.1568269568409.ref@mail.yahoo.com>
 <473388642.4086276.1568269568409@mail.yahoo.com>
 <2083555668.4074553.1568269721731@mail.yahoo.com>
 <B24396EC-25BC-4BCF-82F7-387C4683FC77@dcn.davis.ca.us>
 <1679088869.4077904.1568273379300@mail.yahoo.com>
Message-ID: <76C398A9-31C7-4A4D-8D80-8ED9A2B3F182@dcn.davis.ca.us>

Please keep the mailing list included with reply-all.

I misread your error. I suspect you need to use a newer version of R on your "pc".

On September 12, 2019 12:29:39 AM PDT, Faheem Jan <faheemjan93 at yahoo.com> wrote:
>Jeff Newmiller i dies not understand your answer,i run the simulation
>it give result in pc and i save the result in rda file but when i open
>it in my laptop the file loaded to Rstudio but does show the output
>that i save in the file
>
>On Thursday, September 12, 2019, 12:05:36 PM GMT+5, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:  
> 
> Use the correct function.. readRDS.
>
>On September 11, 2019 11:28:41 PM PDT, Faheem Jan via R-help
><r-help at r-project.org> wrote:
>>
>>
>>Subject: How to read a result? saved in Rstudio
>>HI, i run the simulation result in other computer with high speed
>>computer ,i save the result in the rda file. know i want to open this
>>file rda file? in my laptop, the file loaded in my laptop , i got the
>>error like this?load("C:/Users/Khan/Downloads/Poly.Slow.100.kappa08
>>(1).rda")> Poly.Slow.100.kappa08 (1).rdaError: unexpected symbol in
>>"Poly.Slow.100.kappa08 (1).rda"?can any one help me to resolve my
>>issue. thanks alot in advance? ??
>>? 
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Thu Sep 12 16:53:14 2019
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Thu, 12 Sep 2019 20:23:14 +0530
Subject: [R] Query about calculating the monthly average of daily data
 columns
Message-ID: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>

Dear R-users,

I have daily data from 03-01-1994 to 29-12-2000. In my datafile, he first
column is date and the second and third columns are the returns of the
country A, and B. Here, the date column is same for both countries. I want
to calculate the monthly average of both country's returns by using a loop,
and then, I want to export the results into excel.

Please help me in this regard.

Please find the attached datasheet.

Thank you.

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
09/12/19,
08:23:07 PM

From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 12 17:16:05 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 12 Sep 2019 08:16:05 -0700
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
Message-ID: <CAGxFJbRuFWKGKTFi4OzCYmixJ9VdgUtR4pq3cTfbY1Bm+6VHPg@mail.gmail.com>

No reproducible example, so hard to say. What class is your "date" column?
-- factor, character, Date?  See ?Date
Once you have an object of appropriate class -- see ?format.Date -- ?months
can extract the month and ?ave can do your averaging. No explicit looping
is needed.

The tidydata alternative universe can also do all these things if that's
where you prefer to live.

As usual, any attached data was stripped. See ?dput for one way to include
data in your post.

Cheers,
Bert


On Thu, Sep 12, 2019 at 7:54 AM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> Dear R-users,
>
> I have daily data from 03-01-1994 to 29-12-2000. In my datafile, he first
> column is date and the second and third columns are the returns of the
> country A, and B. Here, the date column is same for both countries. I want
> to calculate the monthly average of both country's returns by using a loop,
> and then, I want to export the results into excel.
>
> Please help me in this regard.
>
> Please find the attached datasheet.
>
> Thank you.
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>
> [image: Mailtrack]
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> Sender
> notified by
> Mailtrack
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> 09/12/19,
> 08:23:07 PM
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 12 17:38:27 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 12 Sep 2019 16:38:27 +0100
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
Message-ID: <527475a5-46da-6388-9adf-b9573125765e@sapo.pt>

Hello,

Please include data, say

dput(head(data, 20))  # post the output of this


But, is the problem as simple as

rowMeans(data[2:3], na.rm = TRUE)

?

Hope this helps,

Rui Barradas


?s 15:53 de 12/09/19, Subhamitra Patra escreveu:
> Dear R-users,
> 
> I have daily data from 03-01-1994 to 29-12-2000. In my datafile, he first
> column is date and the second and third columns are the returns of the
> country A, and B. Here, the date column is same for both countries. I want
> to calculate the monthly average of both country's returns by using a loop,
> and then, I want to export the results into excel.
> 
> Please help me in this regard.
> 
> Please find the attached datasheet.
> 
> Thank you.
>


From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Thu Sep 12 12:13:23 2019
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Thu, 12 Sep 2019 15:43:23 +0530
Subject: [R] How to calculate the monthly average from daily data
Message-ID: <CAOFE=kMPVAUgh988av1QRGjj4y4BD6V-YdHiEMTHSjVcW5M6YQ@mail.gmail.com>

Dear R-users,

I have daily data from 03-01-1994 to 03-08-2017. In my datafile, The first
column is date and the second and third columns are the returns and volume
data. I want to estimate the average returns, and volumes for each month,
then, I want to export the results into excel.

So please help me in this regard.

Please find the attached datasheet.

Thank you.

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
09/12/19,
03:40:34 PM

From bickis m@iii@g oii m@th@us@sk@c@  Thu Sep 12 17:12:01 2019
From: bickis m@iii@g oii m@th@us@sk@c@ (bickis m@iii@g oii m@th@us@sk@c@)
Date: Thu, 12 Sep 2019 09:12:01 -0600
Subject: [R] Strange behaviour of sapply function.
In-Reply-To: <20190912114934.Horde.MJKMLxzUimeZNf0wf6gHRxY@webmail.your-server.de>
References: <20190912114934.Horde.MJKMLxzUimeZNf0wf6gHRxY@webmail.your-server.de>
Message-ID: <11712c0943546a11af37eca189283c21.squirrel@math.usask.ca>

Thanks.    You are right.  I have realized that the atv function returns
empty for negative arguments.  I was not aware that this would affect how
sapply processes its result.

>
> Quoting bickis at math.usask.ca:
>
>> Here is are a few lines of my R session:
>>
>>> class(income)
>> [1] "integer"
>>> class(sapply(1000*income-999,atv,sktaxb,sktax))
>> [1] "numeric"
>>> class(sapply(1000*income-1001,atv,sktaxb,sktax))
>> [1] "list"
>>
>> Although "income" is a numeric array, and sapply works as expected
>> returning an array (the function "atv" returns a single numeric
>> argument),
>> if subtract a large enough number from the first argument, the sapply
>> function now wants to return a list?   Am I missing something?
>>
>> I am running version 3.3.2 on Mac OS 10.9.9
>>
>
> You have not shown what 'income', 'atv', and so on are; so there is an
> infinity
> of possible reasons why you get a list instead of a numeric vector.
>
> One possible reason: what if 'atv' sometimes returns no value at all?
>
> f <- function(x) x[x>0]
> str(sapply(1:10, f))
> ## int [1:10] 1 2 3 4 5 6 7 8 9 10
>
> str(sapply(-5:5, f))
> ## List of 11
> ##  $ : int(0)
> ##  $ : int(0)
> ##  $ : int(0)
> ##  $ : int(0)
> ##  $ : int(0)
> ##  $ : int(0)
> ##  $ : int 1
> ##  $ : int 2
> ##  $ : int 3
> ##  $ : int 4
> ##  $ : int 5
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>
>


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Thu Sep 12 18:27:48 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Thu, 12 Sep 2019 21:57:48 +0530
Subject: [R] A question on regular expression
Message-ID: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>

Hi,

I am wondering on what is the correct way to select a pattern which goes as -

{"(any character with any length)"}

The expressions " {" " and " "} " both are included in the pattern.

For example, the lookup of the above pattern in the text "
{"asaf455%"}57573blabla " will result in {"asaf455%"}

Any help will be highly appreciated.

Thanks,


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 12 18:59:30 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 12 Sep 2019 09:59:30 -0700
Subject: [R] A question on regular expression
In-Reply-To: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>
References: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>
Message-ID: <CAGxFJbRyUC443ixM6OaMcUEKRcLmbLwrNFWDAGArA27iv6JHAQ@mail.gmail.com>

> sub(".*(\\{.*\\}).*", "\\1","ab{cd$ }ed")
[1] "{cd$ }"

Use ".+" instead of ".*" within the {} if you don't want to return empty
{}'s.

You might wish to use the stringr package for string matching and
manipulation, as it provides a more user friendly and consistent interface
to these tasks.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 12, 2019 at 9:31 AM Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I am wondering on what is the correct way to select a pattern which goes
> as -
>
> {"(any character with any length)"}
>
> The expressions " {" " and " "} " both are included in the pattern.
>
> For example, the lookup of the above pattern in the text "
> {"asaf455%"}57573blabla " will result in {"asaf455%"}
>
> Any help will be highly appreciated.
>
> Thanks,
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Thu Sep 12 19:12:45 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Thu, 12 Sep 2019 22:42:45 +0530
Subject: [R] A question on regular expression
In-Reply-To: <CAGxFJbRyUC443ixM6OaMcUEKRcLmbLwrNFWDAGArA27iv6JHAQ@mail.gmail.com>
References: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>
 <CAGxFJbRyUC443ixM6OaMcUEKRcLmbLwrNFWDAGArA27iv6JHAQ@mail.gmail.com>
Message-ID: <CA+dpOJ=3x2XKp65=shsGV0=A3Vz514SM9Whzzkc5h3YwOF4XaA@mail.gmail.com>

Thanks Bert,

This works, but if in my text there are more than one patterns then
fails to generate desired result.

library(stringr)
str_extract_all(paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " "),
".*(\\{.*\\}).*")

This generates below -

[[1]]

[1] "ab{cd$ }ed ab{cad$ }ed"

I was expecting I would get a vector of length 2 with desired pattern.

Where did I make any mistake?

Thanks,

On Thu, Sep 12, 2019 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> > sub(".*(\\{.*\\}).*", "\\1","ab{cd$ }ed")
> [1] "{cd$ }"
>
> Use ".+" instead of ".*" within the {} if you don't want to return empty {}'s.
>
> You might wish to use the stringr package for string matching and manipulation, as it provides a more user friendly and consistent interface to these tasks.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Sep 12, 2019 at 9:31 AM Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>
>> Hi,
>>
>> I am wondering on what is the correct way to select a pattern which goes as -
>>
>> {"(any character with any length)"}
>>
>> The expressions " {" " and " "} " both are included in the pattern.
>>
>> For example, the lookup of the above pattern in the text "
>> {"asaf455%"}57573blabla " will result in {"asaf455%"}
>>
>> Any help will be highly appreciated.
>>
>> Thanks,
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep 12 20:49:12 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 12 Sep 2019 11:49:12 -0700
Subject: [R] A question on regular expression
In-Reply-To: <CA+dpOJ=3x2XKp65=shsGV0=A3Vz514SM9Whzzkc5h3YwOF4XaA@mail.gmail.com>
References: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>
 <CAGxFJbRyUC443ixM6OaMcUEKRcLmbLwrNFWDAGArA27iv6JHAQ@mail.gmail.com>
 <CA+dpOJ=3x2XKp65=shsGV0=A3Vz514SM9Whzzkc5h3YwOF4XaA@mail.gmail.com>
Message-ID: <CAGxFJbRhtY9BkDPNiu3Jh6ToSccS+ouA3fVZkNHxGCXF7y7d2w@mail.gmail.com>

You can't use the same regex for str_extract_all as I used for sub (or
gsub, which is what is required here)! If you do this sort of thing a lot,
you *must* learn more about regex's.

Anyway, this will do what you want I think:

z <- paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " ")  ## just for
readability

> str_extract_all(z,"\\{[^}]*\\}")
[[1]]
[1] "{cd$ }"  "{cad$ }"

Cheers,
Bert

On Thu, Sep 12, 2019 at 10:12 AM Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Thanks Bert,
>
> This works, but if in my text there are more than one patterns then
> fails to generate desired result.
>
> library(stringr)
> str_extract_all(paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " "),
> ".*(\\{.*\\}).*")
>
> This generates below -
>
> [[1]]
>
> [1] "ab{cd$ }ed ab{cad$ }ed"
>
> I was expecting I would get a vector of length 2 with desired pattern.
>
> Where did I make any mistake?
>
> Thanks,
>
> On Thu, Sep 12, 2019 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > > sub(".*(\\{.*\\}).*", "\\1","ab{cd$ }ed")
> > [1] "{cd$ }"
> >
> > Use ".+" instead of ".*" within the {} if you don't want to return empty
> {}'s.
> >
> > You might wish to use the stringr package for string matching and
> manipulation, as it provides a more user friendly and consistent interface
> to these tasks.
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Thu, Sep 12, 2019 at 9:31 AM Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
> >>
> >> Hi,
> >>
> >> I am wondering on what is the correct way to select a pattern which
> goes as -
> >>
> >> {"(any character with any length)"}
> >>
> >> The expressions " {" " and " "} " both are included in the pattern.
> >>
> >> For example, the lookup of the above pattern in the text "
> >> {"asaf455%"}57573blabla " will result in {"asaf455%"}
> >>
> >> Any help will be highly appreciated.
> >>
> >> Thanks,
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Thu Sep 12 20:54:10 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Fri, 13 Sep 2019 00:24:10 +0530
Subject: [R] A question on regular expression
In-Reply-To: <CAGxFJbRhtY9BkDPNiu3Jh6ToSccS+ouA3fVZkNHxGCXF7y7d2w@mail.gmail.com>
References: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>
 <CAGxFJbRyUC443ixM6OaMcUEKRcLmbLwrNFWDAGArA27iv6JHAQ@mail.gmail.com>
 <CA+dpOJ=3x2XKp65=shsGV0=A3Vz514SM9Whzzkc5h3YwOF4XaA@mail.gmail.com>
 <CAGxFJbRhtY9BkDPNiu3Jh6ToSccS+ouA3fVZkNHxGCXF7y7d2w@mail.gmail.com>
Message-ID: <CA+dpOJm7Gw0+kibFKQEyqGX+1_-K+2XgDFOrkoTqQukmvUkaSg@mail.gmail.com>

Awesome, thanks!

On Fri, Sep 13, 2019 at 12:19 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>
> You can't use the same regex for str_extract_all as I used for sub (or gsub, which is what is required here)! If you do this sort of thing a lot, you *must* learn more about regex's.
>
> Anyway, this will do what you want I think:
>
> z <- paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " ")  ## just for readability
>
> > str_extract_all(z,"\\{[^}]*\\}")
> [[1]]
> [1] "{cd$ }"  "{cad$ }"
>
> Cheers,
> Bert
>
> On Thu, Sep 12, 2019 at 10:12 AM Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>
>> Thanks Bert,
>>
>> This works, but if in my text there are more than one patterns then
>> fails to generate desired result.
>>
>> library(stringr)
>> str_extract_all(paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " "),
>> ".*(\\{.*\\}).*")
>>
>> This generates below -
>>
>> [[1]]
>>
>> [1] "ab{cd$ }ed ab{cad$ }ed"
>>
>> I was expecting I would get a vector of length 2 with desired pattern.
>>
>> Where did I make any mistake?
>>
>> Thanks,
>>
>> On Thu, Sep 12, 2019 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >
>> > > sub(".*(\\{.*\\}).*", "\\1","ab{cd$ }ed")
>> > [1] "{cd$ }"
>> >
>> > Use ".+" instead of ".*" within the {} if you don't want to return empty {}'s.
>> >
>> > You might wish to use the stringr package for string matching and manipulation, as it provides a more user friendly and consistent interface to these tasks.
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Thu, Sep 12, 2019 at 9:31 AM Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>> >>
>> >> Hi,
>> >>
>> >> I am wondering on what is the correct way to select a pattern which goes as -
>> >>
>> >> {"(any character with any length)"}
>> >>
>> >> The expressions " {" " and " "} " both are included in the pattern.
>> >>
>> >> For example, the lookup of the above pattern in the text "
>> >> {"asaf455%"}57573blabla " will result in {"asaf455%"}
>> >>
>> >> Any help will be highly appreciated.
>> >>
>> >> Thanks,
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 12 21:13:43 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 12 Sep 2019 20:13:43 +0100
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CAGxFJbQq=EMnvJP76dC7bE3Zb8r3CxEFED+Hc9--B3D9YQgeOg@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <527475a5-46da-6388-9adf-b9573125765e@sapo.pt>
 <CAGxFJbQq=EMnvJP76dC7bE3Zb8r3CxEFED+Hc9--B3D9YQgeOg@mail.gmail.com>
Message-ID: <ad4e8715-5a6a-5b78-26cd-6ed27a21033b@sapo.pt>

Hello,

Inline.

?s 17:33 de 12/09/19, Bert Gunter escreveu:
> But she wants *monthly* averages, Rui. 

Thanks, my mistake.

Ergo ave() or tidyData
> equivalent, right?

Maybe. But ave() returns as many values as the input length, this seems 
more suited for tapply or aggregate.


I will first create an example data set.

set.seed(1234)
start <- as.Date("03-01-1994", "%d-%m-%Y")
end <- as.Date("29-12-2000", "%d-%m-%Y")
date <- seq(start, end, by = "day")
date <- date[as.integer(format(date, "%u")) %in% 1:5]
df1 <- data.frame(date,
                   CountryA = rnorm(length(date)),
                   CountryB = rnorm(length(date)))


Now the averages by month

month <- zoo::as.yearmon(df1[[1]])
aggA <- aggregate(CountryA ~ month, df1, mean)
aggB <- aggregate(CountryB ~ month, df1, mean)
MonthReturns <- merge(aggA, aggB)
head(MonthReturns)


Final clean up.

rm(date, month, aggA, aggB)


Hope this helps,

Rui Barradas
> 
> -- Bert
> 
> On Thu, Sep 12, 2019 at 8:41 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     Please include data, say
> 
>     dput(head(data, 20))? # post the output of this
> 
> 
>     But, is the problem as simple as
> 
>     rowMeans(data[2:3], na.rm = TRUE)
> 
>     ?
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 15:53 de 12/09/19, Subhamitra Patra escreveu:
>      > Dear R-users,
>      >
>      > I have daily data from 03-01-1994 to 29-12-2000. In my datafile,
>     he first
>      > column is date and the second and third columns are the returns
>     of the
>      > country A, and B. Here, the date column is same for both
>     countries. I want
>      > to calculate the monthly average of both country's returns by
>     using a loop,
>      > and then, I want to export the results into excel.
>      >
>      > Please help me in this regard.
>      >
>      > Please find the attached datasheet.
>      >
>      > Thank you.
>      >
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 12 23:45:19 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 13 Sep 2019 07:45:19 +1000
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
Message-ID: <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>

Hi Subhamitra,
Your data didn't make it through, so I guess the first thing is to
guess what it looks like. Here's a try at just January and February of
1994 so that we can see the result on the screen. The logic will work
just as well for the whole seven years.

# create fake data for the first two months
spdat<-data.frame(
 dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
 returnA=sample(15:50,58,TRUE),returnB=sample(10:45,58,TRUE))
# I'll assume that the dates in your file are character, not factor
spdat$dates<-as.character(spdat$dates)
# if you only have to get the monthly averages, it can be done this way
spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2)
spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)
# get the averages by month and year - is this correct?
monthlyA<-by(spdat$returnA,spdat[,c("month","year")],mean)
monthlyB<-by(spdat$returnB,spdat[,c("month","year")],mean)

Now you have what you say you want:

monthlyA
month: 1
year: 1994
[1] 34.1
------------------------------------------------------------
month: 2
year: 1994
[1] 33.32143

monthlyB
month: 1
year: 1994
[1] 29.7
------------------------------------------------------------
month: 2
year: 1994
[1] 27.28571

Sorry I didn't use a loop (for(month in 1:12) ... for (year in
1994:2000) ...), too lazy.
Now you have to let us know how this information is to be formatted to
go into Excel. Excel will import the text as above, but I think you
want something that you can use for further calculations.

Jim

On Fri, Sep 13, 2019 at 12:54 AM Subhamitra Patra
<subhamitra.patra at gmail.com> wrote:
>
> Dear R-users,
>
> I have daily data from 03-01-1994 to 29-12-2000. In my datafile, he first
> column is date and the second and third columns are the returns of the
> country A, and B. Here, the date column is same for both countries. I want
> to calculate the monthly average of both country's returns by using a loop,
> and then, I want to export the results into excel.
>
> Please help me in this regard.
>
> Please find the attached datasheet.
>
> Thank you.
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences*
> *Indian Institute of Technology, Kharagpur*
> *INDIA*
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> 09/12/19,
> 08:23:07 PM
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Fri Sep 13 01:06:59 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Thu, 12 Sep 2019 18:06:59 -0500
Subject: [R] If statement
Message-ID: <CAJOiR6b-wq6X7EoAbW8mAcEbBhq4Dh3Uqi35Su5=DKAH-xfUgw@mail.gmail.com>

Hi all,

I am trying to use the  if else statement and create  two new columns
based on the existing two columns.  Below please find my sample data,

dat1 <-read.table(text="ID  a b c d
A private couple  25 35
B private single  24 38
C none  single    28 32
E none none 20 36 ",header=TRUE,stringsAsFactors=F)

dat1$z <- "Zero"
dat1$y <-  0

if a is "private" and (b is either "couple" rr "single"
    then  z value = a's value   and y value = c's value
if a is "none" and  ( b is either couple of single then  z= private
  then  z value =b's value  qnd  y value= d's value
else z value= Zero and y value=0

the desired out put looks like
ID          a      b      c     d     z       y
1  A private couple 25 35 private 25
2  B private single 24 38 private 24
3  C    none single 28 32 single  32
4  E    none   none 20 36 Zero    0

my attempt

if (dat1$a =="private"  &  (dat1$b =="couple"| dat1$b =="single"))
{
      dat1$z      <-   dat1$a
      dat1$y      <-   dat1$c
}

else if (dat1$a =="none"  &  (dat1$b =="couple"| dat1$b =="single")) {
    dat1$z      <-   dat1$b
    dat1$y      <-   dat1$c
  }
else
{ default value}
did not wok, how could I fix this?
Thank you in advance


From bgunter@4567 @end|ng |rom gm@||@com  Fri Sep 13 01:18:57 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 12 Sep 2019 16:18:57 -0700
Subject: [R] If statement
In-Reply-To: <CAJOiR6b-wq6X7EoAbW8mAcEbBhq4Dh3Uqi35Su5=DKAH-xfUgw@mail.gmail.com>
References: <CAJOiR6b-wq6X7EoAbW8mAcEbBhq4Dh3Uqi35Su5=DKAH-xfUgw@mail.gmail.com>
Message-ID: <CAGxFJbTdqhBMhPph8L9pXYhdoPFt+AuO0MAJ3ngdG7cCp9nUOg@mail.gmail.com>

You appear to be confusing && with &  and || with |  ; (the first of each
pair take a logical expression, the second of each a logical vector) ...
as well as if ... else with ifelse (the first is a flow control statement
taking a logical expression; the second is a function taking a logical
vector as an argument).  I suggest you spend some time with an appropriate
R tutorial to clarify your understanding. You'll get a better explanation
and examples if you do so than anything I can provide you.

Incidentally, in future, do not tell us "it did not work." Provide the
specific error message that burped out.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Sep 12, 2019 at 4:07 PM Val <valkremk at gmail.com> wrote:

> Hi all,
>
> I am trying to use the  if else statement and create  two new columns
> based on the existing two columns.  Below please find my sample data,
>
> dat1 <-read.table(text="ID  a b c d
> A private couple  25 35
> B private single  24 38
> C none  single    28 32
> E none none 20 36 ",header=TRUE,stringsAsFactors=F)
>
> dat1$z <- "Zero"
> dat1$y <-  0
>
> if a is "private" and (b is either "couple" rr "single"
>     then  z value = a's value   and y value = c's value
> if a is "none" and  ( b is either couple of single then  z= private
>   then  z value =b's value  qnd  y value= d's value
> else z value= Zero and y value=0
>
> the desired out put looks like
> ID          a      b      c     d     z       y
> 1  A private couple 25 35 private 25
> 2  B private single 24 38 private 24
> 3  C    none single 28 32 single  32
> 4  E    none   none 20 36 Zero    0
>
> my attempt
>
> if (dat1$a =="private"  &  (dat1$b =="couple"| dat1$b =="single"))
> {
>       dat1$z      <-   dat1$a
>       dat1$y      <-   dat1$c
> }
>
> else if (dat1$a =="none"  &  (dat1$b =="couple"| dat1$b =="single")) {
>     dat1$z      <-   dat1$b
>     dat1$y      <-   dat1$c
>   }
> else
> { default value}
> did not wok, how could I fix this?
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 13 02:01:47 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 12 Sep 2019 17:01:47 -0700
Subject: [R] If statement
In-Reply-To: <CAJOiR6b-wq6X7EoAbW8mAcEbBhq4Dh3Uqi35Su5=DKAH-xfUgw@mail.gmail.com>
References: <CAJOiR6b-wq6X7EoAbW8mAcEbBhq4Dh3Uqi35Su5=DKAH-xfUgw@mail.gmail.com>
Message-ID: <62D68EB5-261D-4FB9-9350-7520134A760C@dcn.davis.ca.us>

Use ifelse function, not if. If is only good for one logical value at a time, but you are working with long vectors of values simultaneously. I have no interest in doing all of your workfor you, but the concept is

cpl_or_sngl <- dat1$b %in% c( "couple", "single" )
a_pvt <- "private" == dat1$a
dat1$z <- with( dat1, ifelse( a_pvt & cpl_or_sngl, a, "Zero" ) )
dat1$y <- with( dat1, ifelse( a_pvt & cpl_or_sngl, c, 0 ) )

On September 12, 2019 4:06:59 PM PDT, Val <valkremk at gmail.com> wrote:
>Hi all,
>
>I am trying to use the  if else statement and create  two new columns
>based on the existing two columns.  Below please find my sample data,
>
>dat1 <-read.table(text="ID  a b c d
>A private couple  25 35
>B private single  24 38
>C none  single    28 32
>E none none 20 36 ",header=TRUE,stringsAsFactors=F)
>
>dat1$z <- "Zero"
>dat1$y <-  0
>
>if a is "private" and (b is either "couple" rr "single"
>    then  z value = a's value   and y value = c's value
>if a is "none" and  ( b is either couple of single then  z= private
>  then  z value =b's value  qnd  y value= d's value
>else z value= Zero and y value=0
>
>the desired out put looks like
>ID          a      b      c     d     z       y
>1  A private couple 25 35 private 25
>2  B private single 24 38 private 24
>3  C    none single 28 32 single  32
>4  E    none   none 20 36 Zero    0
>
>my attempt
>
>if (dat1$a =="private"  &  (dat1$b =="couple"| dat1$b =="single"))
>{
>      dat1$z      <-   dat1$a
>      dat1$y      <-   dat1$c
>}
>
>else if (dat1$a =="none"  &  (dat1$b =="couple"| dat1$b =="single")) {
>    dat1$z      <-   dat1$b
>    dat1$y      <-   dat1$c
>  }
>else
>{ default value}
>did not wok, how could I fix this?
>Thank you in advance
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Fri Sep 13 10:08:10 2019
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Fri, 13 Sep 2019 13:38:10 +0530
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
Message-ID: <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>

Dear Sir,

Thank you very much for your suggestion.

Yes, your suggested code worked. But, actually, I have data from 3rd
January 1994 to 3rd August 2017 for very large (i.e. for 84 countries)
sample. From this, I have given the example of the years up to 2000. Before
applying the same code for the long 24 years, I want to learn the logic
behind the code. Actually, some part of the code is not understandable to
me which I mentioned in the bold letter as follows.

"spdat<-data.frame(
  dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
  returnA=sample(*15:50*,58,TRUE),returnB=sample(*10:45*,58,TRUE))"

A. Here, I need to define the no. of days in a month, and the no. of
countries name separately, right? But, what is meant by 15:50, and 10:45 in
return A, and B respectively?

"# if you only have to get the monthly averages, it can be done this way
spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"

B. Here, I need to define the no. of months, and years separately, right?
or else what 2, and 3 (in bold) indicates?

"# get the averages by month and year - is this correct?
monthlyA<-by(*spdat$returnA*,spdat[,c("month","year")],mean)
monthlyB<-by(*spdat$returnB*,spdat[,c("month","year")],mean)"

C. From this part, I got the exact average values of both January and
February of 1994 for country A, and B. But, in code, I have a query that I
need to define  spdat$returnA, and  spdat$returnB separately before writing
this code, right? Like this, I need to define for each 84 countries
separately with their respective number of months, and years before writing
this code, right?

Yes, after obtaining the monthly average for each country's data, I need to
use them for further calculations. So, I want to export the result to
excel. But, until understanding the code, I think I willn't able to apply
for the entire sample, and cannot be able to discuss the format of the
resulted column to export to excel.

Therefore, kindly help me to understand the code.

Thank you very much, Sir, and thanks to this R forum for helping the
R-beginners.



[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
09/13/19,
12:57:58 PM

On Fri, Sep 13, 2019 at 3:15 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Subhamitra,
> Your data didn't make it through, so I guess the first thing is to
> guess what it looks like. Here's a try at just January and February of
> 1994 so that we can see the result on the screen. The logic will work
> just as well for the whole seven years.
>
> # create fake data for the first two months
> spdat<-data.frame(
>  dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
>  returnA=sample(15:50,58,TRUE),returnB=sample(10:45,58,TRUE))
> # I'll assume that the dates in your file are character, not factor
> spdat$dates<-as.character(spdat$dates)
> # if you only have to get the monthly averages, it can be done this way
> spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2)
> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)
> # get the averages by month and year - is this correct?
> monthlyA<-by(spdat$returnA,spdat[,c("month","year")],mean)
> monthlyB<-by(spdat$returnB,spdat[,c("month","year")],mean)
>
> Now you have what you say you want:
>
> monthlyA
> month: 1
> year: 1994
> [1] 34.1
> ------------------------------------------------------------
> month: 2
> year: 1994
> [1] 33.32143
>
> monthlyB
> month: 1
> year: 1994
> [1] 29.7
> ------------------------------------------------------------
> month: 2
> year: 1994
> [1] 27.28571
>
> Sorry I didn't use a loop (for(month in 1:12) ... for (year in
> 1994:2000) ...), too lazy.
> Now you have to let us know how this information is to be formatted to
> go into Excel. Excel will import the text as above, but I think you
> want something that you can use for further calculations.
>
> Jim
>
> On Fri, Sep 13, 2019 at 12:54 AM Subhamitra Patra
> <subhamitra.patra at gmail.com> wrote:
> >
> > Dear R-users,
> >
> > I have daily data from 03-01-1994 to 29-12-2000. In my datafile, he first
> > column is date and the second and third columns are the returns of the
> > country A, and B. Here, the date column is same for both countries. I
> want
> > to calculate the monthly average of both country's returns by using a
> loop,
> > and then, I want to export the results into excel.
> >
> > Please help me in this regard.
> >
> > Please find the attached datasheet.
> >
> > Thank you.
> >
> > --
> > *Best Regards,*
> > *Subhamitra Patra*
> > *Phd. Research Scholar*
> > *Department of Humanities and Social Sciences*
> > *Indian Institute of Technology, Kharagpur*
> > *INDIA*
> >
> > [image: Mailtrack]
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > Sender
> > notified by
> > Mailtrack
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > 09/12/19,
> > 08:23:07 PM
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From m@rc_grt @end|ng |rom y@hoo@|r  Fri Sep 13 11:56:55 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Fri, 13 Sep 2019 11:56:55 +0200
Subject: [R] Bug (?): file.copy() erases 'from' file if the "to" file
 already exists and is a symlinked file
Message-ID: <86b8fa05-aacc-b95a-ccec-9c1af5b27966@yahoo.fr>

If file.copy() is used to replace a symlinked file, it erases the 
original file and does not copy the file. The original file is lost.

 > version
 ???????????????????????????? _
platform???????????? x86_64-apple-darwin15.6.0
arch???????????????????? x86_64
os???????????????????????? darwin15.6.0
system???????????????? x86_64, darwin15.6.0
status???????????????? Patched
major?????????????????? 3
minor?????????????????? 6.1
year???????????????????? 2019
month?????????????????? 09
day?????????????????????? 06
svn rev?????????????? 77160
language???????????? R
version.string R version 3.6.1 Patched (2019-09-06 r77160)
nickname???????????? Action of the Toes

#########################

Here is a reproducible example:

A <- 10
save(A, file="A.Rdata")
file.symlink(from="A.Rdata", to="B.Rdata")
rm(A)

load(file="B.Rdata")
print(A)?????????????????????? # Perfect

system("ls -l")
## -rw-r--r--?? 1 marcgirondot?? staff?????????? 70 13 sep 11:44 A.Rdata
## lrwxr-xr-x?? 1 marcgirondot?? staff???????????? 7 13 sep 11:44 B.Rdata -> A.Rdata

file.copy(from="A.Rdata", to="B.Rdata", overwrite = TRUE)

system("ls -l")
## -rw-r--r--?? 1 marcgirondot?? staff???????????? 0 13 sep 11:44 A.Rdata
## lrwxr-xr-x?? 1 marcgirondot?? staff???????????? 7 13 sep 11:44 B.Rdata -> A.Rdata

###############

A.Rdata becomes empty: 0B
The content of A.Rdata is lost

################
In terminal the problem does not occur
################

marcgirondot$ ls
A.Rdata
marcgirondot$ ln -s A.Rdata B.Rdata
marcgirondot$ ls -l
-rw-r--r--?? 1 marcgirondot?? staff?????????? 70 13 sep 11:38 A.Rdata
lrwxr-xr-x?? 1 marcgirondot?? staff???????????? 7 13 sep 11:38 B.Rdata -> A.Rdata
marcgirondot$ cp A.Rdata B.Rdata
cp: B.Rdata and A.Rdata are identical (not copied).


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep 13 12:13:08 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 13 Sep 2019 10:13:08 +0000
Subject: [R] test if something was plotted on pdf device
In-Reply-To: <a553f483-72a9-8505-0612-a84a8f826838@gmail.com>
References: <b65499089c194cfe90a9584ae693afe7@SRVEXCHCM1302.precheza.cz>
 <a553f483-72a9-8505-0612-a84a8f826838@gmail.com>
Message-ID: <a679542484f547f7a3de2194243aec49@SRVEXCHCM1302.precheza.cz>

Dear Duncan

Thank you for the code, I will test it or at least check what it does. I finally found probably easier solution.

I stay with my original code

if (dev.cur()==1) plot(ecdf(velik[,"ecd"]), main = ufil[j], col=i) else
plot(ecdf(velik[,"ecd"]), add=T, col=i)

After plot is finished and cycle ends, I copy result to pdf device

dev.copy(pdf,paste(gsub(".xls", "", ufil)[j], ".pdf", sep=""))
dev.off()

Using this approach I could stay with my original code (almost), check if plot was initialised by dev.cur() and save it after it is finished to pdf.

The only obstacle is that my code flashes during plotting to basic device, however I can live with it.

Thank you again and best regards

Petr

> -----Original Message-----
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> Sent: Thursday, September 12, 2019 2:29 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <r-help at r-
> project.org>
> Subject: Re: [R] test if something was plotted on pdf device
>
> On 12/09/2019 7:10 a.m., PIKAL Petr wrote:
> > Dear all
> >
> > Is there any simple way checking whether after calling pdf device
> something was plotted into it?
> >
> > In interactive session I used
> >
> > if (dev.cur()==1) plot(ecdf(rnorm(100))) else plot(ecdf(rnorm(100)),
> > add=T, col=i) which enabled me to test if plot is open
> >
> > But when I want to call eg. pdf("test.pdf") before cycle
> > dev.cur()==1 is FALSE even when no plot is drawn and plot.new error
> comes.
> >
> >> pdf("test.pdf")
> >
> > if (dev.cur()==1) plot(ecdf(rnorm(100))) else plot(ecdf(rnorm(100)),
> > add=T, col=i)
> >
> > Error in segments(ti.l, y, ti.r, y, col = col.hor, lty = lty, lwd = lwd,  :
> >    plot.new has not been called yet
> >
>
> I don't know if this is reliable or not, but you could use code like this:
>
>    f <- tempfile()
>    pdf(f)
>    blankPlot <- recordPlot()
>    dev.off()
>    unlink(f)
>
>    pdf("test.pdf")
>
>    ...  unknown operations ...
>
>    if (dev.cur() == 1 || identical(recordPlot(), blankPlot))
>      plot(ecdf(rnorm(100)))
>    else
>      plot(ecdf(rnorm(100)), add=TRUE, col=i)
>
>
>
> Duncan Murdoch
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep 13 12:21:46 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 13 Sep 2019 10:21:46 +0000
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
 <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
Message-ID: <19730980fa3c4a62815536cc62740fd1@SRVEXCHCM1302.precheza.cz>

Hi

I may be completely wrong but reshape/aggregate should by what you want
spdat
       dates returnA returnB
1   1-1-1994      16      13
2   2-1-1994      44      10
3   3-1-1994      24      32
.....
> library(reshape2)
> spdat.m <- melt(spdat)
Using dates as id variables
> str(spdat.m)
'data.frame':   116 obs. of  3 variables:
 $ dates   : Factor w/ 58 levels "1-1-1994","1-2-1994",..: 1 23 44 47 49 51 53 55 57 3 ...
 $ variable: Factor w/ 2 levels "returnA","returnB": 1 1 1 1 1 1 1 1 1 1 ...
 $ value   : int  16 44 24 47 16 35 34 34 26 36 ...
> spdat.m$realdate <- as.Date(spdat.m[,1], format="%d-%m-%Y")
> aggregate(spdat.m$value, list(format(spdat.m$realdate, "%m.%Y"), spdat.m$variable), mean)
  Group.1 Group.2        x
1 01.1994 returnA 31.93333
2 02.1994 returnA 32.39286
3 01.1994 returnB 24.26667
4 02.1994 returnB 30.03571

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Subhamitra
> Patra
> Sent: Friday, September 13, 2019 10:08 AM
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Query about calculating the monthly average of daily data
> columns
>
> Dear Sir,
>
> Thank you very much for your suggestion.
>
> Yes, your suggested code worked. But, actually, I have data from 3rd January
> 1994 to 3rd August 2017 for very large (i.e. for 84 countries) sample. From
> this, I have given the example of the years up to 2000. Before applying the
> same code for the long 24 years, I want to learn the logic behind the code.
> Actually, some part of the code is not understandable to me which I
> mentioned in the bold letter as follows.
>
> "spdat<-data.frame(
>   dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
>   returnA=sample(*15:50*,58,TRUE),returnB=sample(*10:45*,58,TRUE))"
>
> A. Here, I need to define the no. of days in a month, and the no. of countries
> name separately, right? But, what is meant by 15:50, and 10:45 in return A,
> and B respectively?
>
> "# if you only have to get the monthly averages, it can be done this way
> spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
>
> B. Here, I need to define the no. of months, and years separately, right?
> or else what 2, and 3 (in bold) indicates?
>
> "# get the averages by month and year - is this correct?
> monthlyA<-by(*spdat$returnA*,spdat[,c("month","year")],mean)
> monthlyB<-by(*spdat$returnB*,spdat[,c("month","year")],mean)"
>
> C. From this part, I got the exact average values of both January and
> February of 1994 for country A, and B. But, in code, I have a query that I
> need to define  spdat$returnA, and  spdat$returnB separately before writing
> this code, right? Like this, I need to define for each 84 countries separately
> with their respective number of months, and years before writing this code,
> right?
>
> Yes, after obtaining the monthly average for each country's data, I need to
> use them for further calculations. So, I want to export the result to excel. But,
> until understanding the code, I think I willn't able to apply for the entire
> sample, and cannot be able to discuss the format of the resulted column to
> export to excel.
>
> Therefore, kindly help me to understand the code.
>
> Thank you very much, Sir, and thanks to this R forum for helping the R-
> beginners.
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> mpaign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> mpaign=signaturevirality5&>
> 09/13/19,
> 12:57:58 PM
>
> On Fri, Sep 13, 2019 at 3:15 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Subhamitra,
> > Your data didn't make it through, so I guess the first thing is to
> > guess what it looks like. Here's a try at just January and February of
> > 1994 so that we can see the result on the screen. The logic will work
> > just as well for the whole seven years.
> >
> > # create fake data for the first two months spdat<-data.frame(
> > dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
> >  returnA=sample(15:50,58,TRUE),returnB=sample(10:45,58,TRUE))
> > # I'll assume that the dates in your file are character, not factor
> > spdat$dates<-as.character(spdat$dates)
> > # if you only have to get the monthly averages, it can be done this
> > way
> > spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2)
> > spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)
> > # get the averages by month and year - is this correct?
> > monthlyA<-by(spdat$returnA,spdat[,c("month","year")],mean)
> > monthlyB<-by(spdat$returnB,spdat[,c("month","year")],mean)
> >
> > Now you have what you say you want:
> >
> > monthlyA
> > month: 1
> > year: 1994
> > [1] 34.1
> > ------------------------------------------------------------
> > month: 2
> > year: 1994
> > [1] 33.32143
> >
> > monthlyB
> > month: 1
> > year: 1994
> > [1] 29.7
> > ------------------------------------------------------------
> > month: 2
> > year: 1994
> > [1] 27.28571
> >
> > Sorry I didn't use a loop (for(month in 1:12) ... for (year in
> > 1994:2000) ...), too lazy.
> > Now you have to let us know how this information is to be formatted to
> > go into Excel. Excel will import the text as above, but I think you
> > want something that you can use for further calculations.
> >
> > Jim
> >
> > On Fri, Sep 13, 2019 at 12:54 AM Subhamitra Patra
> > <subhamitra.patra at gmail.com> wrote:
> > >
> > > Dear R-users,
> > >
> > > I have daily data from 03-01-1994 to 29-12-2000. In my datafile, he
> > > first column is date and the second and third columns are the
> > > returns of the country A, and B. Here, the date column is same for
> > > both countries. I
> > want
> > > to calculate the monthly average of both country's returns by using
> > > a
> > loop,
> > > and then, I want to export the results into excel.
> > >
> > > Please help me in this regard.
> > >
> > > Please find the attached datasheet.
> > >
> > > Thank you.
> > >
> > > --
> > > *Best Regards,*
> > > *Subhamitra Patra*
> > > *Phd. Research Scholar*
> > > *Department of Humanities and Social Sciences* *Indian Institute of
> > > Technology, Kharagpur*
> > > *INDIA*
> > >
> > > [image: Mailtrack]
> > > <
> >
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_cam
> paig
> > n=signaturevirality5&
> > >
> > > Sender
> > > notified by
> > > Mailtrack
> > > <
> >
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_cam
> paig
> > n=signaturevirality5&
> > >
> > > 09/12/19,
> > > 08:23:07 PM
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences* *Indian Institute of
> Technology, Kharagpur*
> *INDIA*
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 13 12:54:20 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 13 Sep 2019 20:54:20 +1000
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
 <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
Message-ID: <CA+8X3fVnYXzuS3EHyLpBm1Of3m6aZNkmP+bW46w0HztgAduZ-w@mail.gmail.com>

Hi Subhamitra,
I'll try to write my answers adjacent to your questions below.

On Fri, Sep 13, 2019 at 6:08 PM Subhamitra Patra <subhamitra.patra at gmail.com>
wrote:

> Dear Sir,
>
> Thank you very much for your suggestion.
>
> Yes, your suggested code worked. But, actually, I have data from 3rd
> January 1994 to 3rd August 2017 for very large (i.e. for 84 countries)
> sample. From this, I have given the example of the years up to 2000. Before
> applying the same code for the long 24 years, I want to learn the logic
> behind the code. Actually, some part of the code is not understandable to
> me which I mentioned in the bold letter as follows.
>
> "spdat<-data.frame(
>   dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
>   returnA=sample(*15:50*,58,TRUE),returnB=sample(*10:45*,58,TRUE))"
>
> A. Here, I need to define the no. of days in a month, and the no. of
> countries name separately, right? But, what is meant by 15:50, and 10:45 in
> return A, and B respectively?
>

To paraphrase Donald Trump, this is FAKE DATA! I have no idea what the real
values of return are, so I made them up using the "sample" function.
However, this is not meant to mislead anyone, just to show how whatever
numbers are in your data can be used in calculations. The colon (":")
operator creates a sequence of numbers starting with the one to the left
and ending with the one to the right.

>
> "# if you only have to get the monthly averages, it can be done this way
> spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
>
> B. Here, I need to define the no. of months, and years separately, right?
> or else what 2, and 3 (in bold) indicates?
>

To get the grouping variable of sequential months that you want, you only
need the month and year values of the dates in the first column. First I
used the "strsplit" function to split the date field at the hyphens, then
used "sapply" to extract ("[") the second (month) and third (year) parts as
two new columns. Because you have more than one year of data, you need the
year values or you will group all Januarys, all Februarys and so on. Notice
how I pass both of the new columns as a list (a data frame is a type of
list) in the call to get the mean of each month.

>
> "# get the averages by month and year - is this correct?
> monthlyA<-by(*spdat$returnA*,spdat[,c("month","year")],mean)
> monthlyB<-by(*spdat$returnB*,spdat[,c("month","year")],mean)"
>
> C. From this part, I got the exact average values of both January and
> February of 1994 for country A, and B. But, in code, I have a query that I
> need to define  spdat$returnA, and  spdat$returnB separately before writing
> this code, right? Like this, I need to define for each 84 countries
> separately with their respective number of months, and years before writing
> this code, right?
>

I don't think so. Because I don't know what your data looks like, I am
guessing that for each row, it has columns for each of the 84 countries. I
don't know what these columns are named, either. Maybe:

date             Australia   Belarus   ...    Zambia
01/01/1994   20             21                 22
...


> Yes, after obtaining the monthly average for each country's data, I need
> to use them for further calculations. So, I want to export the result to
> excel. But, until understanding the code, I think I willn't able to apply
> for the entire sample, and cannot be able to discuss the format of the
> resulted column to export to excel.
>

Say that we perform the grouped mean calculation for the first two country
columns like this:
monmeans<-sapply(spdat[,2:3],by,spdat[,c("month","year")],mean)
monmeans
    Australia  Belarus
[1,]  29.70000 30.43333
[2,]  34.17857 27.39286

We are presented with a 2x2 matrix of monthly means in just the format
someone might use for importing into Excel. The first row is January 1994,
the second February 1994 and so on. By expanding the columns to include all
the countries in your data, You should have the result you want.

Jim

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Fri Sep 13 12:59:07 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Fri, 13 Sep 2019 16:29:07 +0530
Subject: [R] A question on regular expression
In-Reply-To: <CAGxFJbRhtY9BkDPNiu3Jh6ToSccS+ouA3fVZkNHxGCXF7y7d2w@mail.gmail.com>
References: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>
 <CAGxFJbRyUC443ixM6OaMcUEKRcLmbLwrNFWDAGArA27iv6JHAQ@mail.gmail.com>
 <CA+dpOJ=3x2XKp65=shsGV0=A3Vz514SM9Whzzkc5h3YwOF4XaA@mail.gmail.com>
 <CAGxFJbRhtY9BkDPNiu3Jh6ToSccS+ouA3fVZkNHxGCXF7y7d2w@mail.gmail.com>
Message-ID: <CA+dpOJnZc_+R+geae2VAfVGKqENZVvp=2VS476umYvujZxzU6g@mail.gmail.com>

A quick question.

Could you please explain the -- [^}]* -- part in finding the pattern?

On Fri, Sep 13, 2019 at 12:19 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>
> You can't use the same regex for str_extract_all as I used for sub (or gsub, which is what is required here)! If you do this sort of thing a lot, you *must* learn more about regex's.
>
> Anyway, this will do what you want I think:
>
> z <- paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " ")  ## just for readability
>
> > str_extract_all(z,"\\{[^}]*\\}")
> [[1]]
> [1] "{cd$ }"  "{cad$ }"
>
> Cheers,
> Bert
>
> On Thu, Sep 12, 2019 at 10:12 AM Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>
>> Thanks Bert,
>>
>> This works, but if in my text there are more than one patterns then
>> fails to generate desired result.
>>
>> library(stringr)
>> str_extract_all(paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " "),
>> ".*(\\{.*\\}).*")
>>
>> This generates below -
>>
>> [[1]]
>>
>> [1] "ab{cd$ }ed ab{cad$ }ed"
>>
>> I was expecting I would get a vector of length 2 with desired pattern.
>>
>> Where did I make any mistake?
>>
>> Thanks,
>>
>> On Thu, Sep 12, 2019 at 10:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> >
>> > > sub(".*(\\{.*\\}).*", "\\1","ab{cd$ }ed")
>> > [1] "{cd$ }"
>> >
>> > Use ".+" instead of ".*" within the {} if you don't want to return empty {}'s.
>> >
>> > You might wish to use the stringr package for string matching and manipulation, as it provides a more user friendly and consistent interface to these tasks.
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Thu, Sep 12, 2019 at 9:31 AM Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>> >>
>> >> Hi,
>> >>
>> >> I am wondering on what is the correct way to select a pattern which goes as -
>> >>
>> >> {"(any character with any length)"}
>> >>
>> >> The expressions " {" " and " "} " both are included in the pattern.
>> >>
>> >> For example, the lookup of the above pattern in the text "
>> >> {"asaf455%"}57573blabla " will result in {"asaf455%"}
>> >>
>> >> Any help will be highly appreciated.
>> >>
>> >> Thanks,
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.


From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Fri Sep 13 15:20:18 2019
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Fri, 13 Sep 2019 18:50:18 +0530
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CA+8X3fVnYXzuS3EHyLpBm1Of3m6aZNkmP+bW46w0HztgAduZ-w@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
 <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
 <CA+8X3fVnYXzuS3EHyLpBm1Of3m6aZNkmP+bW46w0HztgAduZ-w@mail.gmail.com>
Message-ID: <CAOFE=kMAyQs6fH8UAdTvC-H0WnOSTtJe7OF0jj_CLnyZA4bDqQ@mail.gmail.com>

Dear Sir,

Yes, I understood the logic. But, still, I have a few queries that I
mentioned below your answers.

"# if you only have to get the monthly averages, it can be done this way
> spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
>
> B. Here, I need to define the no. of months, and years separately, right?
> or else what 2, and 3 (in bold) indicates?
>

To get the grouping variable of sequential months that you want, you only
need the month and year values of the dates in the first column. First I
used the "strsplit" function to split the date field at the hyphens, then
used "sapply" to extract ("[") the second (month) and *third (year)* parts
as two new columns. Because you have more than one year of data, you need
the year values or you will group all Januarys, all Februarys and so on.
Notice how I pass both of the new columns as a list (a data frame is a type
of list) in the call to get the mean of each month.

1. Here, as per my understanding, the "3" indicates the 3rd year, right?
But, you showed an average for 2 months of the same year. Then, what "3" in
the  spdat$year object indicate?


C. From this part, I got the exact average values of both January and
> February of 1994 for country A, and B. But, in code, I have a query that I
> need to define  spdat$returnA, and  spdat$returnB separately before writing
> this code, right? Like this, I need to define for each 84 countries
> separately with their respective number of months, and years before writing
> this code, right?
>

I don't think so. Because I don't know what your data looks like, I am
guessing that for each row, it has columns for each of the 84 countries. I
don't know what these columns are named, either. Maybe:

date             Australia   Belarus   ...    Zambia
01/01/1994   20             21                 22
...

Here, due to my misunderstanding about the code, I was wrong. But, what
data structure you guessed, it is absolutely right that for each row, I
have columns for each of the 84 countries. So, I think, I need to define
the date column with no. of months, and years once for all the countries.
Therefore, I got my answer to the first and third question in the previous
email (what you suggested) that I no need to define the column of each
country, as the date, and no. of observations are same for all countries.
But, the no. of days are different for each month, and similarly, for each
year. So, I think I need to define date for each year separately.  Hence, I
have given an example of 12 months, for 2 years (i.e. 1994, and 1995), and
have written the following code. Please correct me in case I am wrong.

 spdat<-data.frame(

dates=paste(c(1:21,1:20,1:23,1:21,1:22,1:22,1:21,1:23,1:22,1:21,1:22,1:22),c(rep(1,21),rep(2,20),
rep(3,23), rep(4,21),
rep(5,22),rep(6,22),rep(7,21),rep(8,23),rep(9,22),rep(10,21),rep(11,22),rep(12,22)
),rep(1994,260)
 dates1=
paste(c(1:22,1:20,1:23,1:20,1:23,1:22,1:21,1:23,1:21,1:22,1:22,1:21),c(rep(1,22),rep(2,20),
rep(3,23), rep(4,20),
rep(5,23),rep(6,22),rep(7,21),rep(8,23),rep(9,21),rep(10,21),rep(11,22),rep(12,21)
),rep(1995,259) ,sep="-")

Concerning the exporting of structure of the dataset to excel, I will have
12*84 matrix. But, please suggest me the way to proceed for the large
sample. I have mentioned below what I understood from your code. Please
correct me if I am wrong.
1. I need to define the date for each year as the no. of days in each month
are different for each year (as mentioned in my above code). For instance,
in my data file, Jan 1994 has 21 days while Jan 1995 has 22 days.
2. Need to define the date column as character.
3. Need to define the monthly average for each month, and year. So, now
code will be as follows.
spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2,3,4,5,6,7,8,9,10,11,12)
  %%%%As I need all months average sequentially.
spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)

Here, this meaning of "3", I am really unable to get.

4. Need to define each country with each month and year as mentioned in the
last part of your code.

Please suggest me in this regard.

Thank you.







[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
09/13/19,
06:41:41 PM

On Fri, Sep 13, 2019 at 4:24 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Subhamitra,
> I'll try to write my answers adjacent to your questions below.
>
> On Fri, Sep 13, 2019 at 6:08 PM Subhamitra Patra <
> subhamitra.patra at gmail.com> wrote:
>
>> Dear Sir,
>>
>> Thank you very much for your suggestion.
>>
>> Yes, your suggested code worked. But, actually, I have data from 3rd
>> January 1994 to 3rd August 2017 for very large (i.e. for 84 countries)
>> sample. From this, I have given the example of the years up to 2000. Before
>> applying the same code for the long 24 years, I want to learn the logic
>> behind the code. Actually, some part of the code is not understandable to
>> me which I mentioned in the bold letter as follows.
>>
>> "spdat<-data.frame(
>>   dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
>>   returnA=sample(*15:50*,58,TRUE),returnB=sample(*10:45*,58,TRUE))"
>>
>> A. Here, I need to define the no. of days in a month, and the no. of
>> countries name separately, right? But, what is meant by 15:50, and 10:45 in
>> return A, and B respectively?
>>
>
> To paraphrase Donald Trump, this is FAKE DATA! I have no idea what the
> real values of return are, so I made them up using the "sample" function.
> However, this is not meant to mislead anyone, just to show how whatever
> numbers are in your data can be used in calculations. The colon (":")
> operator creates a sequence of numbers starting with the one to the left
> and ending with the one to the right.
>
>>
>> "# if you only have to get the monthly averages, it can be done this way
>> spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
>> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
>>
>> B. Here, I need to define the no. of months, and years separately, right?
>> or else what 2, and 3 (in bold) indicates?
>>
>
> To get the grouping variable of sequential months that you want, you only
> need the month and year values of the dates in the first column. First I
> used the "strsplit" function to split the date field at the hyphens, then
> used "sapply" to extract ("[") the second (month) and third (year) parts as
> two new columns. Because you have more than one year of data, you need the
> year values or you will group all Januarys, all Februarys and so on. Notice
> how I pass both of the new columns as a list (a data frame is a type of
> list) in the call to get the mean of each month.
>
>>
>> "# get the averages by month and year - is this correct?
>> monthlyA<-by(*spdat$returnA*,spdat[,c("month","year")],mean)
>> monthlyB<-by(*spdat$returnB*,spdat[,c("month","year")],mean)"
>>
>> C. From this part, I got the exact average values of both January and
>> February of 1994 for country A, and B. But, in code, I have a query that I
>> need to define  spdat$returnA, and  spdat$returnB separately before writing
>> this code, right? Like this, I need to define for each 84 countries
>> separately with their respective number of months, and years before writing
>> this code, right?
>>
>
> I don't think so. Because I don't know what your data looks like, I am
> guessing that for each row, it has columns for each of the 84 countries. I
> don't know what these columns are named, either. Maybe:
>
> date             Australia   Belarus   ...    Zambia
> 01/01/1994   20             21                 22
> ...
>
>
>> Yes, after obtaining the monthly average for each country's data, I need
>> to use them for further calculations. So, I want to export the result to
>> excel. But, until understanding the code, I think I willn't able to apply
>> for the entire sample, and cannot be able to discuss the format of the
>> resulted column to export to excel.
>>
>
> Say that we perform the grouped mean calculation for the first two country
> columns like this:
> monmeans<-sapply(spdat[,2:3],by,spdat[,c("month","year")],mean)
> monmeans
>     Australia  Belarus
> [1,]  29.70000 30.43333
> [2,]  34.17857 27.39286
>
> We are presented with a 2x2 matrix of monthly means in just the format
> someone might use for importing into Excel. The first row is January 1994,
> the second February 1994 and so on. By expanding the columns to include all
> the countries in your data, You should have the result you want.
>
> Jim
>


-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Fri Sep 13 15:28:32 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 13 Sep 2019 15:28:32 +0200
Subject: [R] Bug (?): file.copy() erases 'from' file if the "to" file
 already exists and is a symlinked file
In-Reply-To: <86b8fa05-aacc-b95a-ccec-9c1af5b27966@yahoo.fr>
References: <86b8fa05-aacc-b95a-ccec-9c1af5b27966@yahoo.fr>
Message-ID: <FEBDAA17-B9A7-4860-84FC-4641609174BE@gmail.com>

However, notice that cat doesn't protect you in the same way:

Peters-iMac:tst pd$ echo stuff > A
Peters-iMac:tst pd$ ln -s A B
Peters-iMac:tst pd$ ls -l
total 8
-rw-r--r--  1 pd  staff  6 Sep 13 15:20 A
lrwxr-xr-x  1 pd  staff  1 Sep 13 15:20 B -> A
Peters-iMac:tst pd$ cp A B
cp: B and A are identical (not copied).
Peters-iMac:tst pd$ ls -l
total 8
-rw-r--r--  1 pd  staff  6 Sep 13 15:20 A
lrwxr-xr-x  1 pd  staff  1 Sep 13 15:20 B -> A
Peters-iMac:tst pd$ cat A > B
Peters-iMac:tst pd$ ls -l
total 0
-rw-r--r--  1 pd  staff  0 Sep 13 15:20 A
lrwxr-xr-x  1 pd  staff  1 Sep 13 15:20 B -> A

(& I suspect that cp did likewise in early Unices). Bug or not, it would be good if we could detect when "from" and "to" refer to the same file, but I'm not sure how to do that.

-pd

> On 13 Sep 2019, at 11:56 , Marc Girondot via R-help <r-help at r-project.org> wrote:
> 
> If file.copy() is used to replace a symlinked file, it erases the original file and does not copy the file. The original file is lost.
> 
> > version
> ???????????????????????????? _
> platform???????????? x86_64-apple-darwin15.6.0
> arch???????????????????? x86_64
> os???????????????????????? darwin15.6.0
> system???????????????? x86_64, darwin15.6.0
> status???????????????? Patched
> major?????????????????? 3
> minor?????????????????? 6.1
> year???????????????????? 2019
> month?????????????????? 09
> day?????????????????????? 06
> svn rev?????????????? 77160
> language???????????? R
> version.string R version 3.6.1 Patched (2019-09-06 r77160)
> nickname???????????? Action of the Toes
> 
> #########################
> 
> Here is a reproducible example:
> 
> A <- 10
> save(A, file="A.Rdata")
> file.symlink(from="A.Rdata", to="B.Rdata")
> rm(A)
> 
> load(file="B.Rdata")
> print(A)?????????????????????? # Perfect
> 
> system("ls -l")
> ## -rw-r--r--?? 1 marcgirondot?? staff?????????? 70 13 sep 11:44 A.Rdata
> ## lrwxr-xr-x?? 1 marcgirondot?? staff???????????? 7 13 sep 11:44 B.Rdata -> A.Rdata
> 
> file.copy(from="A.Rdata", to="B.Rdata", overwrite = TRUE)
> 
> system("ls -l")
> ## -rw-r--r--?? 1 marcgirondot?? staff???????????? 0 13 sep 11:44 A.Rdata
> ## lrwxr-xr-x?? 1 marcgirondot?? staff???????????? 7 13 sep 11:44 B.Rdata -> A.Rdata
> 
> ###############
> 
> A.Rdata becomes empty: 0B
> The content of A.Rdata is lost
> 
> ################
> In terminal the problem does not occur
> ################
> 
> marcgirondot$ ls
> A.Rdata
> marcgirondot$ ln -s A.Rdata B.Rdata
> marcgirondot$ ls -l
> -rw-r--r--?? 1 marcgirondot?? staff?????????? 70 13 sep 11:38 A.Rdata
> lrwxr-xr-x?? 1 marcgirondot?? staff???????????? 7 13 sep 11:38 B.Rdata -> A.Rdata
> marcgirondot$ cp A.Rdata B.Rdata
> cp: B.Rdata and A.Rdata are identical (not copied).
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep 13 15:33:11 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 13 Sep 2019 13:33:11 +0000
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CAOFE=kMAyQs6fH8UAdTvC-H0WnOSTtJe7OF0jj_CLnyZA4bDqQ@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
 <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
 <CA+8X3fVnYXzuS3EHyLpBm1Of3m6aZNkmP+bW46w0HztgAduZ-w@mail.gmail.com>
 <CAOFE=kMAyQs6fH8UAdTvC-H0WnOSTtJe7OF0jj_CLnyZA4bDqQ@mail.gmail.com>
Message-ID: <fcfb3138fcd74deb8ea541687523fe42@SRVEXCHCM1302.precheza.cz>

Hi

I am almost 100% sure that you would spare yourself much trouble if you changed your date column to real date

?as.Date

reshape your wide format to long one
library(reshape2)
?melt

to get 3 column data.frame with one date column, one country column and one value column

use ?aggregate and ?format to get summary value

something like
aggregate(value column, list(format(date column, "%m.%Y"), country column), mean)

But if you insist to scratch your left ear with right hand accross your head, you could continue your way.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Subhamitra
> Patra
> Sent: Friday, September 13, 2019 3:20 PM
> To: Jim Lemon <drjimlemon at gmail.com>; r-help mailing list <r-help at r-
> project.org>
> Subject: Re: [R] Query about calculating the monthly average of daily data
> columns
>
> Dear Sir,
>
> Yes, I understood the logic. But, still, I have a few queries that I mentioned
> below your answers.
>
> "# if you only have to get the monthly averages, it can be done this way
> > spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> > spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
> >
> > B. Here, I need to define the no. of months, and years separately, right?
> > or else what 2, and 3 (in bold) indicates?
> >
>
> To get the grouping variable of sequential months that you want, you only
> need the month and year values of the dates in the first column. First I used
> the "strsplit" function to split the date field at the hyphens, then used
> "sapply" to extract ("[") the second (month) and *third (year)* parts as two
> new columns. Because you have more than one year of data, you need the
> year values or you will group all Januarys, all Februarys and so on.
> Notice how I pass both of the new columns as a list (a data frame is a type of
> list) in the call to get the mean of each month.
>
> 1. Here, as per my understanding, the "3" indicates the 3rd year, right?
> But, you showed an average for 2 months of the same year. Then, what "3"
> in the  spdat$year object indicate?
>
>
> C. From this part, I got the exact average values of both January and
> > February of 1994 for country A, and B. But, in code, I have a query
> > that I need to define  spdat$returnA, and  spdat$returnB separately
> > before writing this code, right? Like this, I need to define for each
> > 84 countries separately with their respective number of months, and
> > years before writing this code, right?
> >
>
> I don't think so. Because I don't know what your data looks like, I am
> guessing that for each row, it has columns for each of the 84 countries. I
> don't know what these columns are named, either. Maybe:
>
> date             Australia   Belarus   ...    Zambia
> 01/01/1994   20             21                 22
> ...
>
> Here, due to my misunderstanding about the code, I was wrong. But, what
> data structure you guessed, it is absolutely right that for each row, I have
> columns for each of the 84 countries. So, I think, I need to define the date
> column with no. of months, and years once for all the countries.
> Therefore, I got my answer to the first and third question in the previous
> email (what you suggested) that I no need to define the column of each
> country, as the date, and no. of observations are same for all countries.
> But, the no. of days are different for each month, and similarly, for each
> year. So, I think I need to define date for each year separately.  Hence, I have
> given an example of 12 months, for 2 years (i.e. 1994, and 1995), and have
> written the following code. Please correct me in case I am wrong.
>
>  spdat<-data.frame(
>
> dates=paste(c(1:21,1:20,1:23,1:21,1:22,1:22,1:21,1:23,1:22,1:21,1:22,1:22),c(r
> ep(1,21),rep(2,20),
> rep(3,23), rep(4,21),
> rep(5,22),rep(6,22),rep(7,21),rep(8,23),rep(9,22),rep(10,21),rep(11,22),rep(12
> ,22)
> ),rep(1994,260)
>  dates1=
> paste(c(1:22,1:20,1:23,1:20,1:23,1:22,1:21,1:23,1:21,1:22,1:22,1:21),c(rep(1,2
> 2),rep(2,20),
> rep(3,23), rep(4,20),
> rep(5,23),rep(6,22),rep(7,21),rep(8,23),rep(9,21),rep(10,21),rep(11,22),rep(12
> ,21)
> ),rep(1995,259) ,sep="-")
>
> Concerning the exporting of structure of the dataset to excel, I will have
> 12*84 matrix. But, please suggest me the way to proceed for the large
> sample. I have mentioned below what I understood from your code. Please
> correct me if I am wrong.
> 1. I need to define the date for each year as the no. of days in each month
> are different for each year (as mentioned in my above code). For instance, in
> my data file, Jan 1994 has 21 days while Jan 1995 has 22 days.
> 2. Need to define the date column as character.
> 3. Need to define the monthly average for each month, and year. So, now
> code will be as follows.
> spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2,3,4,5,6,7,8,9,10,11,12)
>   %%%%As I need all months average sequentially.
> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)
>
> Here, this meaning of "3", I am really unable to get.
>
> 4. Need to define each country with each month and year as mentioned in
> the last part of your code.
>
> Please suggest me in this regard.
>
> Thank you.
>
>
>
>
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> mpaign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> mpaign=signaturevirality5&>
> 09/13/19,
> 06:41:41 PM
>
> On Fri, Sep 13, 2019 at 4:24 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Subhamitra,
> > I'll try to write my answers adjacent to your questions below.
> >
> > On Fri, Sep 13, 2019 at 6:08 PM Subhamitra Patra <
> > subhamitra.patra at gmail.com> wrote:
> >
> >> Dear Sir,
> >>
> >> Thank you very much for your suggestion.
> >>
> >> Yes, your suggested code worked. But, actually, I have data from 3rd
> >> January 1994 to 3rd August 2017 for very large (i.e. for 84
> >> countries) sample. From this, I have given the example of the years
> >> up to 2000. Before applying the same code for the long 24 years, I
> >> want to learn the logic behind the code. Actually, some part of the
> >> code is not understandable to me which I mentioned in the bold letter as
> follows.
> >>
> >> "spdat<-data.frame(
> >>   dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
> >>   returnA=sample(*15:50*,58,TRUE),returnB=sample(*10:45*,58,TRUE))"
> >>
> >> A. Here, I need to define the no. of days in a month, and the no. of
> >> countries name separately, right? But, what is meant by 15:50, and
> >> 10:45 in return A, and B respectively?
> >>
> >
> > To paraphrase Donald Trump, this is FAKE DATA! I have no idea what the
> > real values of return are, so I made them up using the "sample" function.
> > However, this is not meant to mislead anyone, just to show how
> > whatever numbers are in your data can be used in calculations. The
> > colon (":") operator creates a sequence of numbers starting with the
> > one to the left and ending with the one to the right.
> >
> >>
> >> "# if you only have to get the monthly averages, it can be done this
> >> way
> >> spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> >> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
> >>
> >> B. Here, I need to define the no. of months, and years separately, right?
> >> or else what 2, and 3 (in bold) indicates?
> >>
> >
> > To get the grouping variable of sequential months that you want, you
> > only need the month and year values of the dates in the first column.
> > First I used the "strsplit" function to split the date field at the
> > hyphens, then used "sapply" to extract ("[") the second (month) and
> > third (year) parts as two new columns. Because you have more than one
> > year of data, you need the year values or you will group all Januarys,
> > all Februarys and so on. Notice how I pass both of the new columns as
> > a list (a data frame is a type of
> > list) in the call to get the mean of each month.
> >
> >>
> >> "# get the averages by month and year - is this correct?
> >> monthlyA<-by(*spdat$returnA*,spdat[,c("month","year")],mean)
> >> monthlyB<-by(*spdat$returnB*,spdat[,c("month","year")],mean)"
> >>
> >> C. From this part, I got the exact average values of both January and
> >> February of 1994 for country A, and B. But, in code, I have a query
> >> that I need to define  spdat$returnA, and  spdat$returnB separately
> >> before writing this code, right? Like this, I need to define for each
> >> 84 countries separately with their respective number of months, and
> >> years before writing this code, right?
> >>
> >
> > I don't think so. Because I don't know what your data looks like, I am
> > guessing that for each row, it has columns for each of the 84
> > countries. I don't know what these columns are named, either. Maybe:
> >
> > date             Australia   Belarus   ...    Zambia
> > 01/01/1994   20             21                 22
> > ...
> >
> >
> >> Yes, after obtaining the monthly average for each country's data, I
> >> need to use them for further calculations. So, I want to export the
> >> result to excel. But, until understanding the code, I think I willn't
> >> able to apply for the entire sample, and cannot be able to discuss
> >> the format of the resulted column to export to excel.
> >>
> >
> > Say that we perform the grouped mean calculation for the first two
> > country columns like this:
> > monmeans<-sapply(spdat[,2:3],by,spdat[,c("month","year")],mean)
> > monmeans
> >     Australia  Belarus
> > [1,]  29.70000 30.43333
> > [2,]  34.17857 27.39286
> >
> > We are presented with a 2x2 matrix of monthly means in just the format
> > someone might use for importing into Excel. The first row is January
> > 1994, the second February 1994 and so on. By expanding the columns to
> > include all the countries in your data, You should have the result you want.
> >
> > Jim
> >
>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences* *Indian Institute of
> Technology, Kharagpur*
> *INDIA*
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 13 15:57:59 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 13 Sep 2019 06:57:59 -0700
Subject: [R] A question on regular expression
In-Reply-To: <CA+dpOJnZc_+R+geae2VAfVGKqENZVvp=2VS476umYvujZxzU6g@mail.gmail.com>
References: <CA+dpOJmo1MZbDrUb64+uZK0V+CJFpYAGmgA1CYdw-ijK9X4NoQ@mail.gmail.com>
 <CAGxFJbRyUC443ixM6OaMcUEKRcLmbLwrNFWDAGArA27iv6JHAQ@mail.gmail.com>
 <CA+dpOJ=3x2XKp65=shsGV0=A3Vz514SM9Whzzkc5h3YwOF4XaA@mail.gmail.com>
 <CAGxFJbRhtY9BkDPNiu3Jh6ToSccS+ouA3fVZkNHxGCXF7y7d2w@mail.gmail.com>
 <CA+dpOJnZc_+R+geae2VAfVGKqENZVvp=2VS476umYvujZxzU6g@mail.gmail.com>
Message-ID: <1326FC41-92D8-421F-B4BD-123EA2CD8EE5@dcn.davis.ca.us>

Regular expressions are in much more widespread use than merely R... and there are correspondingly more resources for learning than just R-help. Please do make use of them. Here are a couple that googling "regex character set carat" found:

https://www.regular-expressions.info/charclass.html
https://stackoverflow.com/questions/23352038/regex-excluding-specific-characters

On September 13, 2019 3:59:07 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>A quick question.
>
>Could you please explain the -- [^}]* -- part in finding the pattern?
>
>On Fri, Sep 13, 2019 at 12:19 AM Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>>
>>
>> You can't use the same regex for str_extract_all as I used for sub
>(or gsub, which is what is required here)! If you do this sort of thing
>a lot, you *must* learn more about regex's.
>>
>> Anyway, this will do what you want I think:
>>
>> z <- paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " ")  ## just for
>readability
>>
>> > str_extract_all(z,"\\{[^}]*\\}")
>> [[1]]
>> [1] "{cd$ }"  "{cad$ }"
>>
>> Cheers,
>> Bert
>>
>> On Thu, Sep 12, 2019 at 10:12 AM Christofer Bogaso
><bogaso.christofer at gmail.com> wrote:
>>>
>>> Thanks Bert,
>>>
>>> This works, but if in my text there are more than one patterns then
>>> fails to generate desired result.
>>>
>>> library(stringr)
>>> str_extract_all(paste("ab{cd$ }ed", "ab{cad$ }ed", collapse = " "),
>>> ".*(\\{.*\\}).*")
>>>
>>> This generates below -
>>>
>>> [[1]]
>>>
>>> [1] "ab{cd$ }ed ab{cad$ }ed"
>>>
>>> I was expecting I would get a vector of length 2 with desired
>pattern.
>>>
>>> Where did I make any mistake?
>>>
>>> Thanks,
>>>
>>> On Thu, Sep 12, 2019 at 10:29 PM Bert Gunter
><bgunter.4567 at gmail.com> wrote:
>>> >
>>> > > sub(".*(\\{.*\\}).*", "\\1","ab{cd$ }ed")
>>> > [1] "{cd$ }"
>>> >
>>> > Use ".+" instead of ".*" within the {} if you don't want to return
>empty {}'s.
>>> >
>>> > You might wish to use the stringr package for string matching and
>manipulation, as it provides a more user friendly and consistent
>interface to these tasks.
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming
>along and sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Thu, Sep 12, 2019 at 9:31 AM Christofer Bogaso
><bogaso.christofer at gmail.com> wrote:
>>> >>
>>> >> Hi,
>>> >>
>>> >> I am wondering on what is the correct way to select a pattern
>which goes as -
>>> >>
>>> >> {"(any character with any length)"}
>>> >>
>>> >> The expressions " {" " and " "} " both are included in the
>pattern.
>>> >>
>>> >> For example, the lookup of the above pattern in the text "
>>> >> {"asaf455%"}57573blabla " will result in {"asaf455%"}
>>> >>
>>> >> Any help will be highly appreciated.
>>> >>
>>> >> Thanks,
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible
>code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com  Fri Sep 13 15:58:44 2019
From: @ubh@m|tr@@p@tr@ @end|ng |rom gm@||@com (Subhamitra Patra)
Date: Fri, 13 Sep 2019 19:28:44 +0530
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <fcfb3138fcd74deb8ea541687523fe42@SRVEXCHCM1302.precheza.cz>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
 <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
 <CA+8X3fVnYXzuS3EHyLpBm1Of3m6aZNkmP+bW46w0HztgAduZ-w@mail.gmail.com>
 <CAOFE=kMAyQs6fH8UAdTvC-H0WnOSTtJe7OF0jj_CLnyZA4bDqQ@mail.gmail.com>
 <fcfb3138fcd74deb8ea541687523fe42@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAOFE=kMEZa8GaxRiSGrvYV6hsBSBqQA9TjGvE-3uWb=jGYCEKg@mail.gmail.com>

Dear PIKAL,

Thank you very much for your suggestion.

I tried your previous suggested code and getting the average value for each
month for both country A, and B. But in your recent email, you are
suggesting not to change the date column to real date. If I am going
through your recently suggested code, i.e.

 "aggregate(value column, list(format(date column, "%m.%Y"), country
column), mean)"

I am getting an Error that "*aggregate(value, list(format(date, "%m.%Y"),
country), mean) : **object 'value' not found"*.

Here, my query "*may I need to define the date column, country column, and
value column separately?"*

Further, I need something the average value result like below in the data
frame

Month       Country A   Country B
Jan 1994    26.66         35.78
Feb 1994    26.13         29.14

so that it will be easy for me to export to excel, and to use for the
further calculations.

Please suggest me in this regard.

Thank you.







[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
09/13/19,
07:22:53 PM

On Fri, Sep 13, 2019 at 7:03 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> I am almost 100% sure that you would spare yourself much trouble if you
> changed your date column to real date
>
> ?as.Date
>
> reshape your wide format to long one
> library(reshape2)
> ?melt
>
> to get 3 column data.frame with one date column, one country column and
> one value column
>
> use ?aggregate and ?format to get summary value
>
> something like
> aggregate(value column, list(format(date column, "%m.%Y"), country
> column), mean)
>
> But if you insist to scratch your left ear with right hand accross your
> head, you could continue your way.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Subhamitra
> > Patra
> > Sent: Friday, September 13, 2019 3:20 PM
> > To: Jim Lemon <drjimlemon at gmail.com>; r-help mailing list <r-help at r-
> > project.org>
> > Subject: Re: [R] Query about calculating the monthly average of daily
> data
> > columns
> >
> > Dear Sir,
> >
> > Yes, I understood the logic. But, still, I have a few queries that I
> mentioned
> > below your answers.
> >
> > "# if you only have to get the monthly averages, it can be done this way
> > > spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> > > spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
> > >
> > > B. Here, I need to define the no. of months, and years separately,
> right?
> > > or else what 2, and 3 (in bold) indicates?
> > >
> >
> > To get the grouping variable of sequential months that you want, you only
> > need the month and year values of the dates in the first column. First I
> used
> > the "strsplit" function to split the date field at the hyphens, then used
> > "sapply" to extract ("[") the second (month) and *third (year)* parts as
> two
> > new columns. Because you have more than one year of data, you need the
> > year values or you will group all Januarys, all Februarys and so on.
> > Notice how I pass both of the new columns as a list (a data frame is a
> type of
> > list) in the call to get the mean of each month.
> >
> > 1. Here, as per my understanding, the "3" indicates the 3rd year, right?
> > But, you showed an average for 2 months of the same year. Then, what "3"
> > in the  spdat$year object indicate?
> >
> >
> > C. From this part, I got the exact average values of both January and
> > > February of 1994 for country A, and B. But, in code, I have a query
> > > that I need to define  spdat$returnA, and  spdat$returnB separately
> > > before writing this code, right? Like this, I need to define for each
> > > 84 countries separately with their respective number of months, and
> > > years before writing this code, right?
> > >
> >
> > I don't think so. Because I don't know what your data looks like, I am
> > guessing that for each row, it has columns for each of the 84 countries.
> I
> > don't know what these columns are named, either. Maybe:
> >
> > date             Australia   Belarus   ...    Zambia
> > 01/01/1994   20             21                 22
> > ...
> >
> > Here, due to my misunderstanding about the code, I was wrong. But, what
> > data structure you guessed, it is absolutely right that for each row, I
> have
> > columns for each of the 84 countries. So, I think, I need to define the
> date
> > column with no. of months, and years once for all the countries.
> > Therefore, I got my answer to the first and third question in the
> previous
> > email (what you suggested) that I no need to define the column of each
> > country, as the date, and no. of observations are same for all countries.
> > But, the no. of days are different for each month, and similarly, for
> each
> > year. So, I think I need to define date for each year separately.
> Hence, I have
> > given an example of 12 months, for 2 years (i.e. 1994, and 1995), and
> have
> > written the following code. Please correct me in case I am wrong.
> >
> >  spdat<-data.frame(
> >
> >
> dates=paste(c(1:21,1:20,1:23,1:21,1:22,1:22,1:21,1:23,1:22,1:21,1:22,1:22),c(r
> > ep(1,21),rep(2,20),
> > rep(3,23), rep(4,21),
> >
> rep(5,22),rep(6,22),rep(7,21),rep(8,23),rep(9,22),rep(10,21),rep(11,22),rep(12
> > ,22)
> > ),rep(1994,260)
> >  dates1=
> >
> paste(c(1:22,1:20,1:23,1:20,1:23,1:22,1:21,1:23,1:21,1:22,1:22,1:21),c(rep(1,2
> > 2),rep(2,20),
> > rep(3,23), rep(4,20),
> >
> rep(5,23),rep(6,22),rep(7,21),rep(8,23),rep(9,21),rep(10,21),rep(11,22),rep(12
> > ,21)
> > ),rep(1995,259) ,sep="-")
> >
> > Concerning the exporting of structure of the dataset to excel, I will
> have
> > 12*84 matrix. But, please suggest me the way to proceed for the large
> > sample. I have mentioned below what I understood from your code. Please
> > correct me if I am wrong.
> > 1. I need to define the date for each year as the no. of days in each
> month
> > are different for each year (as mentioned in my above code). For
> instance, in
> > my data file, Jan 1994 has 21 days while Jan 1995 has 22 days.
> > 2. Need to define the date column as character.
> > 3. Need to define the monthly average for each month, and year. So, now
> > code will be as follows.
> >
> spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2,3,4,5,6,7,8,9,10,11,12)
> >   %%%%As I need all months average sequentially.
> > spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)
> >
> > Here, this meaning of "3", I am really unable to get.
> >
> > 4. Need to define each country with each month and year as mentioned in
> > the last part of your code.
> >
> > Please suggest me in this regard.
> >
> > Thank you.
> >
> >
> >
> >
> >
> >
> >
> > [image: Mailtrack]
> > <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> > mpaign=signaturevirality5&>
> > Sender
> > notified by
> > Mailtrack
> > <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> > mpaign=signaturevirality5&>
> > 09/13/19,
> > 06:41:41 PM
> >
> > On Fri, Sep 13, 2019 at 4:24 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > > Hi Subhamitra,
> > > I'll try to write my answers adjacent to your questions below.
> > >
> > > On Fri, Sep 13, 2019 at 6:08 PM Subhamitra Patra <
> > > subhamitra.patra at gmail.com> wrote:
> > >
> > >> Dear Sir,
> > >>
> > >> Thank you very much for your suggestion.
> > >>
> > >> Yes, your suggested code worked. But, actually, I have data from 3rd
> > >> January 1994 to 3rd August 2017 for very large (i.e. for 84
> > >> countries) sample. From this, I have given the example of the years
> > >> up to 2000. Before applying the same code for the long 24 years, I
> > >> want to learn the logic behind the code. Actually, some part of the
> > >> code is not understandable to me which I mentioned in the bold letter
> as
> > follows.
> > >>
> > >> "spdat<-data.frame(
> > >>
>  dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
> > >>   returnA=sample(*15:50*,58,TRUE),returnB=sample(*10:45*,58,TRUE))"
> > >>
> > >> A. Here, I need to define the no. of days in a month, and the no. of
> > >> countries name separately, right? But, what is meant by 15:50, and
> > >> 10:45 in return A, and B respectively?
> > >>
> > >
> > > To paraphrase Donald Trump, this is FAKE DATA! I have no idea what the
> > > real values of return are, so I made them up using the "sample"
> function.
> > > However, this is not meant to mislead anyone, just to show how
> > > whatever numbers are in your data can be used in calculations. The
> > > colon (":") operator creates a sequence of numbers starting with the
> > > one to the left and ending with the one to the right.
> > >
> > >>
> > >> "# if you only have to get the monthly averages, it can be done this
> > >> way
> > >> spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> > >> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
> > >>
> > >> B. Here, I need to define the no. of months, and years separately,
> right?
> > >> or else what 2, and 3 (in bold) indicates?
> > >>
> > >
> > > To get the grouping variable of sequential months that you want, you
> > > only need the month and year values of the dates in the first column.
> > > First I used the "strsplit" function to split the date field at the
> > > hyphens, then used "sapply" to extract ("[") the second (month) and
> > > third (year) parts as two new columns. Because you have more than one
> > > year of data, you need the year values or you will group all Januarys,
> > > all Februarys and so on. Notice how I pass both of the new columns as
> > > a list (a data frame is a type of
> > > list) in the call to get the mean of each month.
> > >
> > >>
> > >> "# get the averages by month and year - is this correct?
> > >> monthlyA<-by(*spdat$returnA*,spdat[,c("month","year")],mean)
> > >> monthlyB<-by(*spdat$returnB*,spdat[,c("month","year")],mean)"
> > >>
> > >> C. From this part, I got the exact average values of both January and
> > >> February of 1994 for country A, and B. But, in code, I have a query
> > >> that I need to define  spdat$returnA, and  spdat$returnB separately
> > >> before writing this code, right? Like this, I need to define for each
> > >> 84 countries separately with their respective number of months, and
> > >> years before writing this code, right?
> > >>
> > >
> > > I don't think so. Because I don't know what your data looks like, I am
> > > guessing that for each row, it has columns for each of the 84
> > > countries. I don't know what these columns are named, either. Maybe:
> > >
> > > date             Australia   Belarus   ...    Zambia
> > > 01/01/1994   20             21                 22
> > > ...
> > >
> > >
> > >> Yes, after obtaining the monthly average for each country's data, I
> > >> need to use them for further calculations. So, I want to export the
> > >> result to excel. But, until understanding the code, I think I willn't
> > >> able to apply for the entire sample, and cannot be able to discuss
> > >> the format of the resulted column to export to excel.
> > >>
> > >
> > > Say that we perform the grouped mean calculation for the first two
> > > country columns like this:
> > > monmeans<-sapply(spdat[,2:3],by,spdat[,c("month","year")],mean)
> > > monmeans
> > >     Australia  Belarus
> > > [1,]  29.70000 30.43333
> > > [2,]  34.17857 27.39286
> > >
> > > We are presented with a 2x2 matrix of monthly means in just the format
> > > someone might use for importing into Excel. The first row is January
> > > 1994, the second February 1994 and so on. By expanding the columns to
> > > include all the countries in your data, You should have the result you
> want.
> > >
> > > Jim
> > >
> >
> >
> > --
> > *Best Regards,*
> > *Subhamitra Patra*
> > *Phd. Research Scholar*
> > *Department of Humanities and Social Sciences* *Indian Institute of
> > Technology, Kharagpur*
> > *INDIA*
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>

-- 
*Best Regards,*
*Subhamitra Patra*
*Phd. Research Scholar*
*Department of Humanities and Social Sciences*
*Indian Institute of Technology, Kharagpur*
*INDIA*

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Sep 14 02:35:29 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 14 Sep 2019 10:35:29 +1000
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <CA+8X3fWmj6hJApGJ5bATwwKOvitDZoJcrVddxEOatHpD19rkxQ@mail.gmail.com>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
 <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
 <CA+8X3fVnYXzuS3EHyLpBm1Of3m6aZNkmP+bW46w0HztgAduZ-w@mail.gmail.com>
 <CAOFE=kMAyQs6fH8UAdTvC-H0WnOSTtJe7OF0jj_CLnyZA4bDqQ@mail.gmail.com>
 <CA+8X3fWmj6hJApGJ5bATwwKOvitDZoJcrVddxEOatHpD19rkxQ@mail.gmail.com>
Message-ID: <CA+8X3fXpeuaHrdZHr6wyQOd5Bswct2z1xMsjYn-98rTptP+6dA@mail.gmail.com>

Sorry, forgot to include the list.

On Sat, Sep 14, 2019 at 10:27 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> See inline
>
> On Fri, Sep 13, 2019 at 11:20 PM Subhamitra Patra <subhamitra.patra at gmail.com> wrote:
>>
>> Dear Sir,
>>
>> Yes, I understood the logic. But, still, I have a few queries that I mentioned below your answers.
>>
>>> "# if you only have to get the monthly averages, it can be done this way
>>> spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2)
>>> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)"
>>>
>>> B. Here, I need to define the no. of months, and years separately, right? or else what 2, and 3 (in bold) indicates?
>>
>>
>> To get the grouping variable of sequential months that you want, you only need the month and year values of the dates in the first column. First I used the "strsplit" function to split the date field at the hyphens, then used "sapply" to extract ("[") the second (month) and third (year) parts as two new columns. Because you have more than one year of data, you need the year values or you will group all Januarys, all Februarys and so on. Notice how I pass both of the new columns as a list (a data frame is a type of list) in the call to get the mean of each month.
>>
>> 1. Here, as per my understanding, the "3" indicates the 3rd year, right? But, you showed an average for 2 months of the same year. Then, what "3" in the  spdat$year object indicate?
>
>
> No, as I explained in the initial email and below, the "strsplit" function takes one or more strings (your dates) and breaks them at the specified character ("-"), So
>
> strsplit("1-1-1994","-")
> [[1]]
> [1] "1"    "1"    "1994"
>
> That is passed to the "sapply" function that applies the extraction ("[") operator to the result of "strsplit". The "3" indicates that you want to extract the third element, in this case, the year.
>
> > sapply(strsplit("1-1-1994","-"),"[",3)
> [1] "1994"
>
> So by splitting the dates and extracting the second (month) and third (year) element from each date, we have all the information needed to create a grouping variable for monthly averages.
>
>>
>>
>>> C. From this part, I got the exact average values of both January and February of 1994 for country A, and B. But, in code, I have a query that I need to define  spdat$returnA, and  spdat$returnB separately before writing this code, right? Like this, I need to define for each 84 countries separately with their respective number of months, and years before writing this code, right?
>>
>>
>> I don't think so. Because I don't know what your data looks like, I am guessing that for each row, it has columns for each of the 84 countries. I don't know what these columns are named, either. Maybe:
>>
>> date             Australia   Belarus   ...    Zambia
>> 01/01/1994   20             21                 22
>> ...
>>
>> Here, due to my misunderstanding about the code, I was wrong. But, what data structure you guessed, it is absolutely right that for each row, I have columns for each of the 84 countries. So, I think, I need to define the date column with no. of months, and years once for all the countries. Therefore, I got my answer to the first and third question in the previous email (what you suggested) that I no need to define the column of each country, as the date, and no. of observations are same for all countries. But, the no. of days are different for each month, and similarly, for each year. So, I think I need to define date for each year separately.  Hence, I have given an example of 12 months, for 2 years (i.e. 1994, and 1995), and have written the following code. Please correct me in case I am wrong.
>>
>>  spdat<-data.frame(
>>   dates=paste(c(1:21,1:20,1:23,1:21,1:22,1:22,1:21,1:23,1:22,1:21,1:22,1:22),c(rep(1,21),rep(2,20),rep(3,23), rep(4,21), rep(5,22),rep(6,22),rep(7,21),rep(8,23),rep(9,22),rep(10,21),rep(11,22),rep(12,22)),rep(1994,260)
>>  dates1=paste(c(1:22,1:20,1:23,1:20,1:23,1:22,1:21,1:23,1:21,1:22,1:22,1:21),c(rep(1,22),rep(2,20),rep(3,23), rep(4,20), rep(5,23),rep(6,22),rep(7,21),rep(8,23),rep(9,21),rep(10,21),rep(11,22),rep(12,21)),rep(1995,259) ,sep="-")
>>
> First, you don't have to recreate the data that you already have. I did because I don't have it and have to guess what it looks like. Remember neither I nor any of the others who have offered help have your data or even a representative sample. If you tried the code above, you surely must know that it doesn't work. I could create code that would produce the dates from 1-1-1994 to 31/12/1995 or any other stretch you would like, but it would only confuse you more.  _You already have the dates in your data file._ What I have shown you is how to use those dates to create the grouping variable that you want.
>
>> Concerning the exporting of structure of the dataset to excel, I will have 12*84 matrix. But, please suggest me the way to proceed for the large sample. I have mentioned below what I understood from your code. Please correct me if I am wrong.
>> 1. I need to define the date for each year as the no. of days in each month are different for each year (as mentioned in my above code). For instance, in my data file, Jan 1994 has 21 days while Jan 1995 has 22 days.
>> 2. Need to define the date column as character.
>> 3. Need to define the monthly average for each month, and year. So, now code will be as follows.
>> spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2,3,4,5,6,7,8,9,10,11,12)    %%%%As I need all months average sequentially.
>> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)
>>
>> Here, this meaning of "3", I am really unable to get
>
>
> You have missed the point here, as above. I didn't mean to suggest that you had to recreate the dates that you already have. What I did was to show how you could use the dates that you already have to create a grouping variable for your calculation.
>>
>> .
>>
>> 4. Need to define each country with each month and year as mentioned in the last part of your code.
>>
> What I did was to add the month and year of each row as two separate columns of data. You should be able to see that by looking at spdat after the "strsplit/sapply" operation. Then you have in each row the returns from your 84 countries _and_ the month/year for that row. When I used the "by" function to get the monthly means from spdat, I showed you how to use the same code on your data frame, after creating the month and year columns, to get the monthly average return for the 84 countries for as many years as you have. As this should return a matrix of successive months as rows and countries as columns, you should easily be able to import this into Excel.
>
> The reason I did it this way was to illustrate how to define the grouping variable from the existing information and perform an easily understood calculation. I thought that using methods that automatically perform the operations I used might allow you to get the result without understanding how you had gotten it. Like the data I didn't have, I took a guess at how much my example would help you understand what was happening and give you the skills to do it yourself. I do hope that you get to the point where you are able to think of my example as unsophisticated, for I could have done it with dplyr/ts/reshape and the rest.
>
> Jim


From jp @end|ng |rom th|nk@|@u@org  Sat Sep 14 03:49:53 2019
From: jp @end|ng |rom th|nk@|@u@org (Jerry Platt)
Date: Fri, 13 Sep 2019 21:49:53 -0400
Subject: [R] Announcing a New R Conference
Message-ID: <CAJGMDtgNXEVG0SLzrV3SWgj+W_H7ZNX-U8Na5ftyAJH2vCU-Tg@mail.gmail.com>

?Yes We CRAN? -- A Conference on R Packages and Applications

December 6-7-8, 2019 ~ Washington D.C.

https://www.thinksisu.org/event/YesWeCRAN
<https://www.thinksisu.org/event/yeswecran/>/

It is a pleasure to invite you to this inaugural conference focused on
sharing, introducing and applying R packages. The conference is organized
by The Sisu Advantage, an independent not-for-profit education organization
founded by former university faculty and administrators. It has organized
and hosted more than 20 academic conferences since 2015, and recently
relocated from California to near Washington, D.C. This conference venue is
in northern Virginia, 10 minutes from Dulles Int?l Airport, Washington
D.C., in The Club at One Loudoun, Ashburn VA 20147; see:
http://www.1lna.com/events/club.cfm

The Yes We CRAN Conference is for anyone in the R community or with an
interest in data analytics.  This Call for Papers is being extended to R
package developers and those with interesting applications of R
packages.  There
are more than 60,000 R packages available online (https://rdrr.io)! Surely
there are many hidden gems among them that merit more attention. Let's
shine a light on and celebrate them.

All proposals are peer-reviewed by faculty who have been tenured and
appointed to full rank.  You will be notified regarding acceptance within 14
days of your submission.  Accepted presenters also qualify to submit a
chapter for the forthcoming, edited book: ?A Sampler of R Packages and
Their Applications?.

You are encouraged to submit a proposed talk if you are:

   -

   a developer of a completed package on CRAN, GitHub, or other websites
   -

   a developer of works-in-progress that you envision becoming a package
   -

   creator of an interesting application that utilizes existing R packages
   -

   a subject-matter specialist advocating creation of a needed package.

The deadline for presenter and Early-Bird attendee registration is November
1.

ForIIf you are interested but cannot attend, we provide the option of a
peer-reviewed POSTER SESSION.

For more detailed information regarding conference logistics, please go here
:https://www.thinksisu.org/event/YesWeCRAN/

To submit an abstract for consideration, please go here:
https://www.thinksisu.org/submission-system/

For questions or inquiries, please contact: jp at thinksisu.org



Regards,

Jerry Platt, Ph.D., Emeritus Professor & Dean

Executive Director, The Sisu Advantage

	[[alternative HTML version deleted]]


From @yen @end|ng |rom hqu@edu@cn  Sat Sep 14 16:29:15 2019
From: @yen @end|ng |rom hqu@edu@cn (Steven Yen)
Date: Sat, 14 Sep 2019 22:29:15 +0800
Subject: [R] Warning from installing packages in R3.6.1
Message-ID: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>

Since updating to R3.6.1., I have received a WARNING message saying 
Rtools is required.
I get the same message installing online from CRAN and from a .zip file.
It looked like installation still went through in both cases, BUT,

Another student installed a .zip file and received the following error 
message:

Error in install.packages : invalid multibyte string at `<87><55>...

do I have to live with the message?

I hate to tell students to install Rtools, which they do not do much with.
Warning message is listed below. Thank you.
---

 > Install.packages("aod")
WARNING: Rtools is required to build R packages but it is not currently 
installed. Please download and install the appropriate version of Rtools 
before proceeding:

Package 'aod' successfully unpacked and MD5 sums checked.

-- 
syen at hqu.edu.cn


	[[alternative HTML version deleted]]


From c|eber@borge@ @end|ng |rom u||@@br  Sat Sep 14 20:18:54 2019
From: c|eber@borge@ @end|ng |rom u||@@br (Cleber Borges)
Date: Sat, 14 Sep 2019 15:18:54 -0300
Subject: [R] pkg reticulate + python3 + MSYS2 (windows)
Message-ID: <625eccff-a067-69f5-2db6-0790db58f01c@ufla.br>

To all R users
Good afternoon
Has anyone used the reticulate package with python3 within the MSYS2 
(windows) environment ???
With the python2 version works without problems.
But my goal is to use PyGI (Gtk3) which is officially supported on 
windows only by MSYS2.

Thanks in advance for any help!
Cleber Borges

########################

 > system("where python")
C:\Python27_64bit\python.exe
[1] 0
 > system("C:/msys64/mingw64/bin/python.exe -V")
Python 3.7.4
[1] 0
 > system("C:/Python27_64bit/python.exe -V")
Python 2.7.10
[1] 0
 > Sys.setenv(RETICULATE_PYTHON = "C:/msys64/mingw64/bin" )
 > library( reticulate )
 > py_discover_config()
python:???????? C:/msys64/mingw64/bin/python.exe
libpython:????? python37.dll
pythonhome:???? C:/building/msys64/mingw64
version:??????? 3.7.4 (default, Aug 15 2019, 18:17:27)? [GCC 9.2.0 64 
bit (AMD64)]
Architecture:?? 64bit
numpy:?????????? [NOT FOUND]

NOTE: Python version was forced by RETICULATE_PYTHON
 > py_available( TRUE )
[1] FALSE
 > py_available(? )
[1] FALSE
 > os <- import("os")
Error in py_initialize(config$python, config$libpython, 
config$pythonhome,? :
 ? python37.dll - N?o foi poss?vel encontrar o m?dulo especificado.

 >
 >


From chr|@momentu@ @end|ng |rom gm@||@com  Sat Sep 14 22:27:31 2019
From: chr|@momentu@ @end|ng |rom gm@||@com (Chris Chinedozie)
Date: Sat, 14 Sep 2019 17:27:31 -0300
Subject: [R] How can I compare two apriori rules created from the same
 dataset
Message-ID: <CALzXf6CpE4rR9JVY092Rwrp_kvAyOV6mt8UKFaC0TJEb_Dk4Dw@mail.gmail.com>

I have a dataset and I divided it into 2 datasets RANDOMLY A and B, where A
is 70% of the main dataset and B is 30%... Then I applied Apriori algorithm
on the both A and B separately, generating its rules..
I want to compare rules from dataset A to rules of dataset B
example:
A has the following rules
[(sex=0,age=1),(sex=1,age=1,money=0),(sex=0,age=2,money=2)]

B has the following rules
[(sex=0,age=1,money=1),(sex=0,age=1,money=0),(sex=1,age=1,money=0)]
A(sex=0,age=1) => B(sex=0,age=1,money=1) returns TRUE
A(sex=1,age=1,money=0) => B(sex=1,age=1,money=0)) returns TRUE
A(sex=0,age=2,money=2) => B(sex=1,age=1,money=0) returns FALSE


-- 
Chris G. Chinedozie
Universidade Federal do Rio de Janeiro

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep 14 22:53:53 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 14 Sep 2019 16:53:53 -0400
Subject: [R] Warning from installing packages in R3.6.1
In-Reply-To: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>
References: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>
Message-ID: <eff9305f-f2e9-6a61-f22e-57be31818585@gmail.com>

On 14/09/2019 10:29 a.m., Steven Yen wrote:
> Since updating to R3.6.1., I have received a WARNING message saying
> Rtools is required.
> I get the same message installing online from CRAN and from a .zip file.
> It looked like installation still went through in both cases, BUT,
> 
> Another student installed a .zip file and received the following error
> message:
> 
> Error in install.packages : invalid multibyte string at `<87><55>...
> 
> do I have to live with the message?
> 
> I hate to tell students to install Rtools, which they do not do much with.
> Warning message is listed below. Thank you.
> ---
> 
>   > Install.packages("aod")
> WARNING: Rtools is required to build R packages but it is not currently
> installed. Please download and install the appropriate version of Rtools
> before proceeding:
> 
> Package 'aod' successfully unpacked and MD5 sums checked.
> 

Did you really run "Install.packages", not "install.packages"?  R is 
case sensitive, so those are different.  But in any case, that message 
probably isn't coming from R, it is coming from some contributed package 
or front end.

Posting the result of sessionInfo() would help us to diagnose where the 
message is coming from.

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep 14 22:57:46 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 14 Sep 2019 13:57:46 -0700
Subject: [R] How can I compare two apriori rules created from the same
 dataset
In-Reply-To: <CALzXf6CpE4rR9JVY092Rwrp_kvAyOV6mt8UKFaC0TJEb_Dk4Dw@mail.gmail.com>
References: <CALzXf6CpE4rR9JVY092Rwrp_kvAyOV6mt8UKFaC0TJEb_Dk4Dw@mail.gmail.com>
Message-ID: <CAGxFJbQ-6zqZYkOMBdNZQKRE8k4gmFM1beUi5D6iY3X+WC0XBA@mail.gmail.com>

I am guessing that you are using the arules package, correct? If not, what
package? In future, please specify what package you refer to if not one of
those in a standard distro.

Usually, package specific questions should be directed to package
maintainers (?maintainer) or support sites for the packages, but you may
get lucky here. Sorry, but I can't help beyond that.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 14, 2019 at 1:35 PM Chris Chinedozie <chrismomentus at gmail.com>
wrote:

> I have a dataset and I divided it into 2 datasets RANDOMLY A and B, where A
> is 70% of the main dataset and B is 30%... Then I applied Apriori algorithm
> on the both A and B separately, generating its rules..
> I want to compare rules from dataset A to rules of dataset B
> example:
> A has the following rules
> [(sex=0,age=1),(sex=1,age=1,money=0),(sex=0,age=2,money=2)]
>
> B has the following rules
> [(sex=0,age=1,money=1),(sex=0,age=1,money=0),(sex=1,age=1,money=0)]
> A(sex=0,age=1) => B(sex=0,age=1,money=1) returns TRUE
> A(sex=1,age=1,money=0) => B(sex=1,age=1,money=0)) returns TRUE
> A(sex=0,age=2,money=2) => B(sex=1,age=1,money=0) returns FALSE
>
>
> --
> Chris G. Chinedozie
> Universidade Federal do Rio de Janeiro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From beno|t@v@|||@nt @end|ng |rom no-|og@org  Sun Sep 15 13:46:50 2019
From: beno|t@v@|||@nt @end|ng |rom no-|og@org (Benoit Vaillant)
Date: Sun, 15 Sep 2019 13:46:50 +0200
Subject: [R] How can I compare two apriori rules created from the same
 dataset
In-Reply-To: <CALzXf6CpE4rR9JVY092Rwrp_kvAyOV6mt8UKFaC0TJEb_Dk4Dw@mail.gmail.com>
References: <CALzXf6CpE4rR9JVY092Rwrp_kvAyOV6mt8UKFaC0TJEb_Dk4Dw@mail.gmail.com>
Message-ID: <20190915114650.3nng7ylvxdsjcjij@auroras.fr>

Hello Chris,

On Sat, Sep 14, 2019 at 05:27:31PM -0300, Chris Chinedozie wrote:
> I have a dataset and I divided it into 2 datasets RANDOMLY A and B, where A
> is 70% of the main dataset and B is 30%... Then I applied Apriori algorithm
> on the both A and B separately, generating its rules..

My best guess is that you don't want to do that.

Association rules hugely rely on support for building the itemset. And
then confidence for the orientation of the rule.

Both are very simple metrics. Yet if you divide your dataset, this
will lead to very different itemsets due to the algorithm.

> I want to compare rules from dataset A to rules of dataset B

Can you precise ? compare ??

> example:
> A has the following rules
> [(sex=0,age=1),(sex=1,age=1,money=0),(sex=0,age=2,money=2)]
> 
> B has the following rules
> [(sex=0,age=1,money=1),(sex=0,age=1,money=0),(sex=1,age=1,money=0)]

Aren't these itemsets rather than rules?

> A(sex=0,age=1) => B(sex=0,age=1,money=1) returns TRUE
> A(sex=1,age=1,money=0) => B(sex=1,age=1,money=0)) returns TRUE
> A(sex=0,age=2,money=2) => B(sex=1,age=1,money=0) returns FALSE

I don't see rules, nor sense.

Can you clarify?

Thanks!

-- 
Beno?t Vaillant

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190915/b102bb5d/attachment.sig>

From kry|ov@r00t @end|ng |rom gm@||@com  Sun Sep 15 14:04:03 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sun, 15 Sep 2019 15:04:03 +0300
Subject: [R] pkg reticulate + python3 + MSYS2 (windows)
In-Reply-To: <625eccff-a067-69f5-2db6-0790db58f01c@ufla.br>
References: <625eccff-a067-69f5-2db6-0790db58f01c@ufla.br>
Message-ID: <20190915150403.689e86f5@Tarkus>

On Sat, 14 Sep 2019 15:18:54 -0300
Cleber Borges <cleber.borges at ufla.br> wrote:

> python37.dll - N?o foi poss?vel encontrar o m?dulo especificado.

This might mean that python37.dll depends on another DLL which could not
be found. You might have to add C:/msys64/mingw64/bin/ and/or another
directory to the PATH environment variable to make it work. Use
Dependency Walker [*] or a similar tool to find out which DLLs
python37.dll depends on.

Alternatively, use Sysinternals Process Monitor [**] to see which files
does it try to open before a `reticulate` call fails.

-- 
Best regards,
Ivan

[*] http://dependencywalker.com/

[**] https://docs.microsoft.com/en-us/sysinternals/downloads/procmon


From k|ebyn @end|ng |rom y@hoo@com@br  Sun Sep 15 14:41:37 2019
From: k|ebyn @end|ng |rom y@hoo@com@br (Cleber N.Borges)
Date: Sun, 15 Sep 2019 09:41:37 -0300
Subject: [R] pkg reticulate + python3 + MSYS2 (windows)
In-Reply-To: <20190915150403.689e86f5@Tarkus>
References: <625eccff-a067-69f5-2db6-0790db58f01c@ufla.br>
 <20190915150403.689e86f5@Tarkus>
Message-ID: <c52697a3-3349-d7ad-d36b-9130b48034e9@yahoo.com.br>

Hello Ivan Krylov and all users,
I think I understand your observation but there is no file named by 
python37.dll on the computer.
It may be as static build inside python3.exe but if so should not give 
this error?
Thank you

Cleber Borges


Em 15/09/2019 09:04, Ivan Krylov escreveu:
> On Sat, 14 Sep 2019 15:18:54 -0300
> Cleber Borges <cleber.borges at ufla.br> wrote:
>
>> python37.dll - N??o foi poss??vel encontrar o m??dulo especificado.
> This might mean that python37.dll depends on another DLL which could not
> be found. You might have to add C:/msys64/mingw64/bin/ and/or another
> directory to the PATH environment variable to make it work. Use
> Dependency Walker [*] or a similar tool to find out which DLLs
> python37.dll depends on.
>
> Alternatively, use Sysinternals Process Monitor [**] to see which files
> does it try to open before a `reticulate` call fails.
>


From @yen @end|ng |rom hqu@edu@cn  Sun Sep 15 07:44:42 2019
From: @yen @end|ng |rom hqu@edu@cn (Steven Yen)
Date: Sun, 15 Sep 2019 13:44:42 +0800
Subject: [R] Warning from installing packages in R3.6.1
In-Reply-To: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>
References: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>
Message-ID: <e8c63d8b-dcce-dbac-c058-6624eaa4b0d8@hqu.edu.cn>

Can someone help me understand why Rtools is needed when installing a 
package from CRAN, and from a zipped file? What's the point?

On 9/14/2019 10:29 PM, Steven Yen wrote:
> Since updating to R3.6.1., I have received a WARNING message saying 
> Rtools is required.
> I get the same message installing online from CRAN and from a .zip file.
> It looked like installation still went through in both cases, BUT,
>
> Another student installed a .zip file and received the following error 
> message:
>
> Error in install.packages : invalid multibyte string at `<87><55>...
>
> do I have to live with the message?
>
> I hate to tell students to install Rtools, which they do not do much with.
> Warning message is listed below. Thank you.
> ---
>
> > Install.packages("aod")
> WARNING: Rtools is required to build R packages but it is not 
> currently installed. Please download and install the appropriate 
> version of Rtools before proceeding:
>
> Package 'aod' successfully unpacked and MD5 sums checked.
> -- 
> syen at hqu.edu.cn

-- 
syen at hqu.edu.cn


	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Sep 15 17:02:32 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 15 Sep 2019 11:02:32 -0400
Subject: [R] Warning from installing packages in R3.6.1
In-Reply-To: <e8c63d8b-dcce-dbac-c058-6624eaa4b0d8@hqu.edu.cn>
References: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>
 <e8c63d8b-dcce-dbac-c058-6624eaa4b0d8@hqu.edu.cn>
Message-ID: <544ac166-256c-6d0e-6249-873f490cf5b2@gmail.com>

On 15/09/2019 1:44 a.m., Steven Yen wrote:
> Can someone help me understand why Rtools is needed when installing a
> package from CRAN, and from a zipped file? What's the point?

Please don't just repeat your post when you've been asked for additional 
supporting information.

Duncan Murdoch

> 
> On 9/14/2019 10:29 PM, Steven Yen wrote:
>> Since updating to R3.6.1., I have received a WARNING message saying
>> Rtools is required.
>> I get the same message installing online from CRAN and from a .zip file.
>> It looked like installation still went through in both cases, BUT,
>>
>> Another student installed a .zip file and received the following error
>> message:
>>
>> Error in install.packages : invalid multibyte string at `<87><55>...
>>
>> do I have to live with the message?
>>
>> I hate to tell students to install Rtools, which they do not do much with.
>> Warning message is listed below. Thank you.
>> ---
>>
>>> Install.packages("aod")
>> WARNING: Rtools is required to build R packages but it is not
>> currently installed. Please download and install the appropriate
>> version of Rtools before proceeding:
>>
>> Package 'aod' successfully unpacked and MD5 sums checked.
>> -- 
>> syen at hqu.edu.cn
>


From @tyen @end|ng |rom ntu@edu@tw  Mon Sep 16 04:07:41 2019
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 16 Sep 2019 10:07:41 +0800
Subject: [R] Warning from installing packages in R3.6.1
In-Reply-To: <544ac166-256c-6d0e-6249-873f490cf5b2@gmail.com>
References: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>
 <e8c63d8b-dcce-dbac-c058-6624eaa4b0d8@hqu.edu.cn>
 <544ac166-256c-6d0e-6249-873f490cf5b2@gmail.com>
Message-ID: <efcdb124-cf63-74ed-e241-49e9b8b83dbf@ntu.edu.tw>

Hello Duncan:
Below I am sending
(1) message from installation of a .zip file;
(2) from installation of aod from CRAN;
(3) from running the line sessionInfo()

Looks like both installations were successful despite the warning 
message. Now the point seems to be to figure out why the warning arises. 
Thank you.
Steven Yen

===
 > install.packages("C:/Users/Bonnie/Desktop/yenlib1_1.1.0.zip", repos = 
NULL, type = "win.binary")
WARNING: Rtools is required to build R packages but is not currently 
installed. Please download and install the appropriate version of Rtools 
before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ?C:/Users/Bonnie/Documents/R/win-library/3.6?
(as ?lib? is unspecified)
package ?yenlib1? successfully unpacked and MD5 sums checked

 > install.packages("aod")
WARNING: Rtools is required to build R packages but is not currently 
installed. Please download and install the appropriate version of Rtools 
before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
Installing package into ?C:/Users/Bonnie/Documents/R/win-library/3.6?
(as ?lib? is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/aod_1.3.1.zip'
Content type 'application/zip' length 322953 bytes (315 KB)
downloaded 315 KB

package ?aod? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
C:\Users\Bonnie\AppData\Local\Temp\Rtmpikl35B\downloaded_packages

 > sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17763)

Matrix products: default

Random number generation:
 ?RNG:???? Mersenne-Twister
 ?Normal:? Inversion
 ?Sample:? Rounding

locale:
[1] LC_COLLATE=Chinese (Simplified)_China.936
[2] LC_CTYPE=Chinese (Simplified)_China.936
[3] LC_MONETARY=Chinese (Simplified)_China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_China.936

attached base packages:
[1] stats???? graphics? grDevices utils
[5] datasets? methods?? base

loaded via a namespace (and not attached):
[1] compiler_3.6.1 tools_3.6.1

On 9/15/2019 11:02 PM, Duncan Murdoch wrote:
> On 15/09/2019 1:44 a.m., Steven Yen wrote:
>> Can someone help me understand why Rtools is needed when installing a
>> package from CRAN, and from a zipped file? What's the point?
>
> Please don't just repeat your post when you've been asked for 
> additional supporting information.
>
> Duncan Murdoch
>
>>
>> On 9/14/2019 10:29 PM, Steven Yen wrote:
>>> Since updating to R3.6.1., I have received a WARNING message saying
>>> Rtools is required.
>>> I get the same message installing online from CRAN and from a .zip 
>>> file.
>>> It looked like installation still went through in both cases, BUT,
>>>
>>> Another student installed a .zip file and received the following error
>>> message:
>>>
>>> Error in install.packages : invalid multibyte string at `<87><55>...
>>>
>>> do I have to live with the message?
>>>
>>> I hate to tell students to install Rtools, which they do not do much 
>>> with.
>>> Warning message is listed below. Thank you.
>>> ---
>>>
>>>> Install.packages("aod")
>>> WARNING: Rtools is required to build R packages but it is not
>>> currently installed. Please download and install the appropriate
>>> version of Rtools before proceeding:
>>>
>>> Package 'aod' successfully unpacked and MD5 sums checked.
>>> -- 
>>> syen at hqu.edu.cn
>>
>

-- 
styen at ntu.edu.tw (S.T. Yen)


	[[alternative HTML version deleted]]


From n@m@t|o|| @end|ng |rom ucd@v|@@edu  Fri Sep 13 18:56:11 2019
From: n@m@t|o|| @end|ng |rom ucd@v|@@edu (Norman Matloff)
Date: Fri, 13 Sep 2019 09:56:11 -0700
Subject: [R] R Journal, Vol. 11, Issue 1
Message-ID: <CAKbPKxsjXrJMxOStvBHsryHO=hqc1+xdffNQR3pnH3GkTxNmpw@mail.gmail.com>

After a long delay, the issue was put online on Wednesday evening. As noted
in the editorial, we are taking measures to help ensure that future issues
will be more timely.

Norm Matloff

	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 16 10:25:25 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 16 Sep 2019 04:25:25 -0400
Subject: [R] Warning from installing packages in R3.6.1
In-Reply-To: <efcdb124-cf63-74ed-e241-49e9b8b83dbf@ntu.edu.tw>
References: <f12cd099-ca92-c58f-c996-603a4d4ba841@hqu.edu.cn>
 <e8c63d8b-dcce-dbac-c058-6624eaa4b0d8@hqu.edu.cn>
 <544ac166-256c-6d0e-6249-873f490cf5b2@gmail.com>
 <efcdb124-cf63-74ed-e241-49e9b8b83dbf@ntu.edu.tw>
Message-ID: <61c615ce-afa2-2938-1f91-fa7abdc29be8@gmail.com>

The message you are seeing is coming from RStudio, not from R.  You can 
see it here:

https://github.com/rstudio/rstudio/blob/cf5076a88a219a275a2d128191c12c1f8f4e3890/src/cpp/session/modules/build/SessionBuildEnvironment.cpp#L164-L168

It's possible that updating RStudio will make it go away; if not, you 
probably have to contact them to find out why it's showing up.  The R 
team can't do anything about it.

Duncan Murdoch

On 15/09/2019 10:07 p.m., Steven Yen wrote:
> Hello Duncan:
> Below I am sending
> (1) message from installation of a .zip file;
> (2) from installation of aod from CRAN;
> (3) from running the line sessionInfo()
> 
> Looks like both installations were successful despite the warning 
> message. Now the point seems to be to figure out why the warning arises. 
> Thank you.
> Steven Yen
> 
> ===
>  > install.packages("C:/Users/Bonnie/Desktop/yenlib1_1.1.0.zip", repos = 
> NULL, type = "win.binary")
> WARNING: Rtools is required to build R packages but is not currently 
> installed. Please download and install the appropriate version of Rtools 
> before proceeding:
> 
> https://cran.rstudio.com/bin/windows/Rtools/
> Installing package into ?C:/Users/Bonnie/Documents/R/win-library/3.6?
> (as ?lib? is unspecified)
> package ?yenlib1? successfully unpacked and MD5 sums checked
> 
>  > install.packages("aod")
> WARNING: Rtools is required to build R packages but is not currently 
> installed. Please download and install the appropriate version of Rtools 
> before proceeding:
> 
> https://cran.rstudio.com/bin/windows/Rtools/
> Installing package into ?C:/Users/Bonnie/Documents/R/win-library/3.6?
> (as ?lib? is unspecified)
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.6/aod_1.3.1.zip'
> Content type 'application/zip' length 322953 bytes (315 KB)
> downloaded 315 KB
> 
> package ?aod? successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
> C:\Users\Bonnie\AppData\Local\Temp\Rtmpikl35B\downloaded_packages
> 
>  > sessionInfo()
> R version 3.6.1 (2019-07-05)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17763)
> 
> Matrix products: default
> 
> Random number generation:
>  ?RNG:???? Mersenne-Twister
>  ?Normal:? Inversion
>  ?Sample:? Rounding
> 
> locale:
> [1] LC_COLLATE=Chinese (Simplified)_China.936
> [2] LC_CTYPE=Chinese (Simplified)_China.936
> [3] LC_MONETARY=Chinese (Simplified)_China.936
> [4] LC_NUMERIC=C
> [5] LC_TIME=Chinese (Simplified)_China.936
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils
> [5] datasets? methods?? base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.6.1 tools_3.6.1
> 
> On 9/15/2019 11:02 PM, Duncan Murdoch wrote:
>> On 15/09/2019 1:44 a.m., Steven Yen wrote:
>>> Can someone help me understand why Rtools is needed when installing a
>>> package from CRAN, and from a zipped file? What's the point?
>>
>> Please don't just repeat your post when you've been asked for 
>> additional supporting information.
>>
>> Duncan Murdoch
>>
>>>
>>> On 9/14/2019 10:29 PM, Steven Yen wrote:
>>>> Since updating to R3.6.1., I have received a WARNING message saying
>>>> Rtools is required.
>>>> I get the same message installing online from CRAN and from a .zip 
>>>> file.
>>>> It looked like installation still went through in both cases, BUT,
>>>>
>>>> Another student installed a .zip file and received the following error
>>>> message:
>>>>
>>>> Error in install.packages : invalid multibyte string at `<87><55>...
>>>>
>>>> do I have to live with the message?
>>>>
>>>> I hate to tell students to install Rtools, which they do not do much 
>>>> with.
>>>> Warning message is listed below. Thank you.
>>>> ---
>>>>
>>>>> Install.packages("aod")
>>>> WARNING: Rtools is required to build R packages but it is not
>>>> currently installed. Please download and install the appropriate
>>>> version of Rtools before proceeding:
>>>>
>>>> Package 'aod' successfully unpacked and MD5 sums checked.
>>>> -- 
>>>> syen at hqu.edu.cn
>>>
>>
> 
> -- 
> styen at ntu.edu.tw  (S.T. Yen)
>


From moh@mm@d|@n02 @end|ng |rom gm@||@com  Mon Sep 16 08:57:10 2019
From: moh@mm@d|@n02 @end|ng |rom gm@||@com (Mohammadian)
Date: Mon, 16 Sep 2019 11:27:10 +0430
Subject: [R] Problem with crossmeta package
Message-ID: <CALqdc3eWkLXTv+D-UVUNWwTd=AT5rQ3=xzU_LOBHgq=-NCTGpw@mail.gmail.com>

Hi!

I have difficulty crossmeta package. Especifically the datasets wont
download from NCBI through R.


# my code
library(crossmeta)
library(Biobase)
library(AnnotationDbi)

data_dir <- file.path(getwd(), "data") # specify where data will be downloaded
gse_names  <- c("GSE9601", "GSE15069", "GSE50841", "GSE34817", "GSE29689")
get_raw(gse_names, data_dir)

# R response:
No supplemental files found.
Check URL manually if in doubt

However, the supplemental files exist and I can download them.
I wondered if there is a way to use manually downloaded datasets for crossmet?


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Sep 16 13:00:26 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 16 Sep 2019 11:00:26 +0000
Subject: [R] Query about calculating the monthly average of daily data
 columns
In-Reply-To: <539f802bb81040b89408ef874be28244@SRVEXCHCM1302.precheza.cz>
References: <CAOFE=kNgBOAT-S1ESiC160EE7F7vtvrMD4AAoCpMZn72z4zuBA@mail.gmail.com>
 <CA+8X3fWHvBqYxRMyAN-vp9WhjX=b7CYZ2BaNHyifKgJh3P2k6g@mail.gmail.com>
 <CAOFE=kOsSR1eKFUeXMvU4A6JvBdt1ZCt66teuD5qfRkCfiwOVw@mail.gmail.com>
 <CA+8X3fVnYXzuS3EHyLpBm1Of3m6aZNkmP+bW46w0HztgAduZ-w@mail.gmail.com>
 <CAOFE=kMAyQs6fH8UAdTvC-H0WnOSTtJe7OF0jj_CLnyZA4bDqQ@mail.gmail.com>
 <fcfb3138fcd74deb8ea541687523fe42@SRVEXCHCM1302.precheza.cz>
 <CAOFE=kMEZa8GaxRiSGrvYV6hsBSBqQA9TjGvE-3uWb=jGYCEKg@mail.gmail.com>
 <539f802bb81040b89408ef874be28244@SRVEXCHCM1302.precheza.cz>
Message-ID: <af92b2007e8a4050af6abe296276e70d@SRVEXCHCM1302.precheza.cz>

Original email did not come through (some problems with formating).

Hi

No, on contrary. I **am** suggesting to change date column to real date asi it is easy to handle with appropriate functions.

Here are some fake data

> str(spdat)
'data.frame':?? 260 obs. of? 3 variables:
$ dates?? : Date, format: "1995-01-01" "1995-01-02" "1995-01-03" "1995-01-04" ...
$ coutryA : num? 0.188 0.405 -0.107 -0.596 -0.529 ...
$ countryB: num? 9.4 10.76 11.24 8.26 10.71 ..

> head(spdat)
?? ????dates??? coutryA? countryB
1 1995-01-01? 0.1875060? 9.402851
2 1995-01-02? 0.4045193 10.755112
3 1995-01-03 -0.1073904 11.243663
4 1995-01-04 -0.5959683? 8.256424
5 1995-01-05 -0.5293772 10.705431
6 1995-01-06 -0.2228029 10.171461

First I melt it
spdat.m <- melt(spdat, id.var="dates")

> head(spdat.m)
???? ??dates variable????? value
1 1995-01-01? coutryA? 0.1875060
2 1995-01-02? coutryA? 0.4045193
3 1995-01-03? coutryA -0.1073904
4 1995-01-04? coutryA -0.5959683
5 1995-01-05? coutryA -0.5293772
6 1995-01-06? coutryA -0.2228029

I do aggregation

> spdat.ag <- aggregate(spdat.m$value, list(format(spdat.m$dates, "%m.%Y"), spdat.m$variable), mean)

And now I use dcast ?to get required result.

> dcast(spdat.ag, Group.1~Group.2)
Using x as value column: use value.var to override.
?? Group.1????? coutryA? countryB
1? 01.1995? 0.098688137 10.177696
2? 02.1995? 0.352264682? 9.609261
3? 03.1995? 0.155521876 10.043503
4? 04.1995 -0.166092393 10.129844
5? 05.1995? 0.164665188 10.308275
6? 06.1995? 0.260633585 10.210129
7? 07.1995? 0.003671979 10.549016
8? 08.1995? 0.045295990 10.087435
9? 09.1995 -0.145488206? 9.689876
10 10.1995 -0.225645950? 9.743744
11 11.1995? 0.030273383 10.025435
12 12.1995? 0.043557468 10.105626

Cheers
Petr

Here are the data.

> dput(spdat)
spdat ?<- structure(list(dates = structure(c(9131, 9132, 9133, 9134, 9135, 
9136, 9137, 9138, 9139, 9140, 9141, 9142, 9143, 9144, 9145, 9146, 
9147, 9148, 9149, 9150, 9151, 9152, 9162, 9163, 9164, 9165, 9166, 
9167, 9168, 9169, 9170, 9171, 9172, 9173, 9174, 9175, 9176, 9177, 
9178, 9179, 9180, 9181, 9190, 9191, 9192, 9193, 9194, 9195, 9196, 
9197, 9198, 9199, 9200, 9201, 9202, 9203, 9204, 9205, 9206, 9207, 
9208, 9209, 9210, 9211, 9212, 9221, 9222, 9223, 9224, 9225, 9226, 
9227, 9228, 9229, 9230, 9231, 9232, 9233, 9234, 9235, 9236, 9237, 
9238, 9239, 9240, 9251, 9252, 9253, 9254, 9255, 9256, 9257, 9258, 
9259, 9260, 9261, 9262, 9263, 9264, 9265, 9266, 9267, 9268, 9269, 
9270, 9271, 9272, 9273, 9282, 9283, 9284, 9285, 9286, 9287, 9288, 
9289, 9290, 9291, 9292, 9293, 9294, 9295, 9296, 9297, 9298, 9299, 
9300, 9301, 9302, 9303, 9312, 9313, 9314, 9315, 9316, 9317, 9318, 
9319, 9320, 9321, 9322, 9323, 9324, 9325, 9326, 9327, 9328, 9329, 
9330, 9331, 9332, 9343, 9344, 9345, 9346, 9347, 9348, 9349, 9350, 
9351, 9352, 9353, 9354, 9355, 9356, 9357, 9358, 9359, 9360, 9361, 
9362, 9363, 9364, 9365, 9374, 9375, 9376, 9377, 9378, 9379, 9380, 
9381, 9382, 9383, 9384, 9385, 9386, 9387, 9388, 9389, 9390, 9391, 
9392, 9393, 9394, 9404, 9405, 9406, 9407, 9408, 9409, 9410, 9411, 
9412, 9413, 9414, 9415, 9416, 9417, 9418, 9419, 9420, 9421, 9422, 
9423, 9424, 9456, 9435, 9436, 9437, 9438, 9439, 9440, 9441, 9442, 
9443, 9444, 9445, 9446, 9447, 9448, 9449, 9450, 9451, 9452, 9453, 
9454, 9455, 9486, 9465, 9466, 9467, 9468, 9469, 9470, 9471, 9472, 
9473, 9474, 9475, 9476, 9477, 9478, 9479, 9480, 9481, 9482, 9483, 
9484, 9151), class = "Date"), coutryA = c(0.187506004416315, 
0.404519257417805, -0.107390371811605, -0.595968278805544, -0.529377240936012, 
-0.222802921207767, 0.413182392872818, 0.689673026532298, -1.2768723266992, 
-0.506308625809406, 0.113859233745174, -0.0963423819877653, 0.323987304768398, 
1.63846917270538, 0.893233423250338, 0.297732439150487, 0.949323101836486, 
-0.599518074708052, 0.366372319197032, -2.25734971953878, -0.190971733204918, 
-0.0874143568874351, 1.46699645184047, 0.00702170238687361, 0.11221346278474, 
-0.8060359607624, 0.340842350476532, 0.798838328074708, 0.449214745851041, 
-0.664972890558734, 0.521830282184173, -1.35020467264521, -0.95240631225826, 
1.25607320999849, 1.57018988549379, 0.99477900888445, -0.936218787378207, 
1.48489932847779, 0.529222943794807, 0.0995675049147771, 0.477770516727839, 
1.64567253670186, -0.0212651530684566, 0.558952796713992, 0.0409979382929057, 
0.428675380654606, 0.0919422583362682, -0.819694497340459, 1.23998830450888, 
0.607498144489643, -1.27724580163097, 1.41634774644371, -0.579094515769707, 
2.02039606694223, 0.0740478208705996, -1.69826944583929, -0.321482399813063, 
-0.489198601400924, 2.0066750686302, -1.90624857752322, 0.46762405849973, 
1.31264724137396, -0.0473627194710677, 0.141362267796145, 0.329709761206515, 
0.518454586458572, -1.39489985851779, -0.388303591187678, -0.668922704543522, 
0.0735115674875065, 1.30737242978235, 0.198503397980751, 0.257831448122427, 
-1.31173539205588, -1.45147941969116, 0.359725782295977, 0.612882118056585, 
-0.0733768753346202, -0.508349204402508, 1.35776663767231, 0.997807735669086, 
-1.41717534266382, -0.894170593324238, -0.68578120845151, -0.211509378018794, 
0.436738904337909, -1.46932152770435, 0.0817388759874159, -0.0389350881653141, 
0.709198476466861, -0.963669144724435, -0.548607422521798, -0.896886885575286, 
0.322231150840934, 1.37327611339939, 0.0310213133870952, 0.796577750757324, 
-0.2010067423637, -0.241723752424226, 1.37547329580654, -1.15382202538982, 
0.101454200596915, 0.273663839664217, 1.8315140887841, 1.86096518756473, 
-0.536393730924719, -0.45845011727266, 1.10226256157127, -0.385596991265563, 
3.20218061566932, -1.25865250042183, -0.13613128784276, 0.483329357746514, 
-0.597187329618306, 0.710977603908319, -1.07945708269043, -0.477626236401394, 
1.51034914684104, 2.35886426985999, -0.0250526828683629, -0.29439443478131, 
0.665774016744828, 0.464027472251246, 0.226658374792016, -0.802597030454373, 
0.825517059805602, -1.11293193130819, -1.27677400513873, 1.60776237113347, 
1.12490009531342, 0.95767047134623, 0.0475745549797055, -0.0591587460876868, 
-0.690617365240342, -1.62111622938126, -1.3545210707469, 1.8607927043106, 
0.764367674339969, 1.49261525602638, 0.549570728337346, -1.29658399741794, 
-1.6289903797869, 0.00573336252135834, 0.0300702149640632, 0.440810830115721, 
0.663568666361326, -0.126685900835146, -0.00221628368438927, 
0.815321995886579, -0.499280888368945, -0.271814047751667, -0.071025546459042, 
1.73165491816826, -0.0294770299043331, 0.833605607221529, -0.670108794857159, 
-0.303323318026829, 1.29039844459134, -0.818806702120603, -0.445515595649677, 
-0.0128796557666887, 0.320923705586147, 0.230597275812536, -1.54009153212366, 
-0.294702981688559, 0.581209734391958, 0.121384768986639, 0.502914098451111, 
-1.59018268505718, -0.635101104166451, 1.48005776676403, -0.25631761189957, 
0.171947814411552, 0.444646195980014, 0.172655758440111, -0.00432159794094836, 
-0.549321974240026, 0.585055026451421, -1.22813371480849, 0.846807540195381, 
0.319629441352597, 0.393525732059709, -1.40275675444594, 1.11062585584811, 
0.214809571213853, -0.636432711800391, -0.283087127251573, -1.46385553207618, 
0.436928676930225, -1.34231945433777, 0.451281957595763, -0.523155001924496, 
-2.69416779107545, 1.5513477373689, 0.989632029400036, 1.34636075948993, 
0.346147428691405, -0.464527560160041, 0.337233933370495, 1.11331396366389, 
-1.00060600083316, -0.734784444487169, 1.40476315358621, 1.01671092179193, 
-0.0144306250829694, -0.923555930346906, -1.02275966525015, 0.619422010219383, 
0.603484309754755, -0.774553813657576, 0.0932792545556387, -0.651884521428279, 
-0.61965612647073, -1.22104834441579, -1.31439612639271, -2.87707752518163, 
-0.0343801084491906, -0.640678302378492, -1.38653452986558, 0.884963139028743, 
-0.657454283462004, 0.462842665244993, -0.20881674837534, 0.6345884135548, 
0.707165108434729, -0.162090928425892, -0.998662309785188, 1.3130254639318, 
0.191890764940071, -0.0493619237876962, -0.55183232511689, 0.470263932874487, 
-0.217088645692971, 0.231550037620628, -0.530406537266415, -0.616522469083808, 
0.329347084038265, 1.49420692610475, 1.91750823142859, 0.753536143872474, 
0.766584887163714, -0.259803384094296, -0.402463714097741, -0.0229799209735185, 
-0.259677990559218, -1.41529707261105, 0.191362852138627, 1.54483266684747, 
-1.17947655378489, -0.426265411073274, 0.723010460481118, 1.37405142869537, 
-0.374771207936141, 0.0513905365832423, -0.369432731236118, -0.945441984794364, 
0.179506648255554, 0.31971255725438, -1.25117960937319, 2.46228549580083
), countryB = c(9.4028512714591, 10.7551115504652, 11.2436629228434, 
8.25642360904389, 10.7054313972395, 10.1714609666091, 10.3726975056206, 
10.6594299429162, 8.56250595443296, 10.5612153841067, 8.07612112826519, 
9.94704207511951, 11.392407273156, 10.4257690445268, 10.6339442533038, 
10.5314883825356, 10.3506665399033, 10.2426403362978, 10.8437715647564, 
10.8247200587034, 11.2449815064171, 9.2898697883112, 9.05418978124619, 
10.6080277672463, 9.19882175737148, 11.3589722806948, 10.4139334238189, 
9.44305216810892, 9.58426470056472, 8.84208362003176, 10.8125431356391, 
7.71357872650814, 8.73526671289828, 10.714693958224, 9.49976972594189, 
9.41896864941478, 7.33073349261249, 10.5268398982262, 9.92255671125184, 
10.5665378092202, 10.5035704895405, 7.93682068228084, 10.882421050424, 
9.3237610577468, 8.42128120513304, 9.46103753451174, 10.3472215515392, 
11.0483414005193, 10.3421689244599, 7.85120280889754, 11.6327644046254, 
9.57620745972098, 10.6553844719749, 10.8490250129346, 10.2742492933876, 
9.55428072119304, 9.0976351049804, 10.0731951766966, 10.6956488509516, 
11.1530744146062, 10.3496303024767, 9.52734980693306, 9.64478424894734, 
9.28301632295047, 10.9568790570688, 11.6052870914912, 9.58530202776537, 
11.1338134902295, 8.66685735149472, 11.0230863576875, 10.8000609212302, 
10.6510296259782, 11.831292326569, 9.53836122448974, 9.55805411377422, 
9.90336204189518, 9.36377040999133, 11.7041009433341, 9.95628297574831, 
10.718111342931, 10.4562688422472, 8.85976383099186, 8.94085496683824, 
8.19538394018434, 10.1058448260449, 9.70821289789561, 9.08757962570738, 
10.6599997541876, 10.0521137258219, 9.9924295699559, 11.8730269098299, 
11.2634470795907, 11.3854762443416, 9.56742053529845, 10.4101561978503, 
9.53376547865009, 9.75410966995361, 9.92804558924886, 8.36231430067066, 
10.7486459346681, 12.0143881312685, 11.0083060332839, 9.32820954213586, 
10.8420346742049, 9.73064414798223, 10.7593902723319, 10.976622155215, 
10.1039774975157, 8.36317871802524, 9.21809894958653, 10.1015362220683, 
11.4655736295123, 9.65528297274543, 9.67844310028008, 10.1516820910267, 
8.38764450852642, 10.163558398201, 11.1432463477237, 12.0509818193223, 
10.9896913965091, 11.1772406550953, 9.14396687337779, 9.93338627749979, 
10.9548864433126, 8.64911301751956, 11.706463972364, 11.1012846649741, 
8.7805267197408, 11.5802098773954, 10.2268513542863, 10.3509617168731, 
9.09646558899397, 11.2706666647314, 11.3984335011704, 11.4808985388742, 
10.5608771133999, 10.3684356806175, 10.4815588822618, 10.5818867877558, 
12.2561035284691, 8.6464271477849, 10.3412351841865, 10.7577574534162, 
11.1124067479261, 9.91627943243343, 10.6356898895291, 10.2107566441478, 
10.0672734202575, 10.2385787014999, 11.7112606160069, 10.0453801263575, 
8.84654136100724, 10.2173421609193, 9.27919801705716, 10.4755578829547, 
7.69340209082122, 9.24705253848083, 10.8415406794597, 8.69603117680965, 
11.2589214416702, 10.5425642239737, 10.1389355042458, 9.17267675180435, 
12.3052338002213, 10.0181674985326, 12.2715476751051, 9.64516268052739, 
10.6305299379912, 10.1829347684655, 9.97983942366781, 10.2559847744715, 
10.3092266661814, 9.75215330673072, 10.250464278709, 9.31118800061454, 
10.3310666767171, 9.09703848990093, 10.241195105962, 8.57290406448477, 
8.98090855172704, 8.64653101832229, 12.6791587435376, 9.56000538681993, 
10.4062255533723, 11.067091476284, 10.5255014737268, 10.2240941949978, 
9.13081571869084, 9.5942352120783, 9.2753466212409, 10.2789293993548, 
8.10255065585342, 9.48751297655077, 8.51198576785003, 9.46310532206947, 
9.86727270762806, 11.5149248124739, 9.31557156735022, 9.34351230206303, 
10.022139448869, 11.4111350893792, 8.57891783464065, 10.3761090924661, 
9.38300408584683, 9.33694577526158, 9.25815555686085, 9.29856853889735, 
8.4250073823245, 8.83022950824832, 9.1510846172981, 10.2553042376765, 
10.0739540955956, 9.04955917463259, 10.8927827168631, 9.44611041690694, 
10.7883395708593, 10.6010088332078, 7.72560864006592, 10.1760839916637, 
11.5576569894392, 11.384809257294, 8.73504353987083, 9.00585942714512, 
9.62327893504013, 10.3527072699866, 10.5220100705827, 8.74921668696853, 
8.56415116683662, 12.1348451793815, 10.9496674323819, 9.64443817181322, 
9.52977454697087, 10.4281877186725, 8.52701721410292, 11.6911584965782, 
10.2300108250139, 8.65368821276485, 11.7733431942379, 10.2060233777681, 
9.57291673029552, 9.82687667895106, 10.5939736188493, 11.2510605726337, 
10.3383384488323, 9.92301237292945, 10.0164623230529, 10.4939857044034, 
10.5631769648289, 10.935731043532, 11.0659359187168, 8.51697010486427, 
9.79512310587405, 9.35132038807071, 11.3286703149903, 10.4621597293933, 
10.4099459919071, 8.86246315190942, 9.30054044639769, 9.40346575227191, 
9.59278722974697)), row.names = c(NA, -260L), class = "data.frame")





From: Subhamitra Patra <mailto:subhamitra.patra at gmail.com> 
Sent: Friday, September 13, 2019 3:59 PM
To: PIKAL Petr <mailto:petr.pikal at precheza.cz>; r-help mailing list <mailto:r-help at r-project.org>
Subject: Re: [R] Query about calculating the monthly average of daily data columns

Dear PIKAL,

Thank you very much for your suggestion.

I tried your previous suggested code and getting the average value for each month for both country A, and B. But in your recent email, you are suggesting not to change the date column to real date. If I am going through your recently suggested code, i.e.

?"aggregate(value column, list(format(date column, "%m.%Y"), country column), mean)"

I am getting an?Error that "aggregate(value, list(format(date, "%m.%Y"), country), mean) :?object 'value' not found".?

Here, my query "may I need to define the date column, country column, and value column separately?"

Further, I need something the average value result like below in the data frame

Month? ? ? ?Country A? ?Country B
Jan 1994? ? 26.66? ? ? ? ?35.78
Feb 1994? ? 26.13? ? ? ? ?29.14

so that it will be easy for me to export to excel, and to use for the further calculations.

Please suggest me in this regard.

Thank you.





https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
Sender notified by 
https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5& 09/13/19, 07:22:53 PM 



On Fri, Sep 13, 2019 at 7:03 PM PIKAL Petr <mailto:petr.pikal at precheza.cz> wrote:
Hi

I am almost 100% sure that you would spare yourself much trouble if you changed your date column to real date

?as.Date

reshape your wide format to long one
library(reshape2)
?melt

to get 3 column data.frame with one date column, one country column and one value column

use ?aggregate and ?format to get summary value

something like
aggregate(value column, list(format(date column, "%m.%Y"), country column), mean)

But if you insist to scratch your left ear with right hand accross your head, you could continue your way.

Cheers
Petr

> -----Original Message-----
> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Subhamitra
> Patra
> Sent: Friday, September 13, 2019 3:20 PM
> To: Jim Lemon <mailto:drjimlemon at gmail.com>; r-help mailing list <r-help at r-
> http://project.org>
> Subject: Re: [R] Query about calculating the monthly average of daily data
> columns
>
> Dear Sir,
>
> Yes, I understood the logic. But, still, I have a few queries that I mentioned
> below your answers.
>
> "# if you only have to get the monthly averages, it can be done this way
> > spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> > spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
> >
> > B. Here, I need to define the no. of months, and years separately, right?
> > or else what 2, and 3 (in bold) indicates?
> >
>
> To get the grouping variable of sequential months that you want, you only
> need the month and year values of the dates in the first column. First I used
> the "strsplit" function to split the date field at the hyphens, then used
> "sapply" to extract ("[") the second (month) and *third (year)* parts as two
> new columns. Because you have more than one year of data, you need the
> year values or you will group all Januarys, all Februarys and so on.
> Notice how I pass both of the new columns as a list (a data frame is a type of
> list) in the call to get the mean of each month.
>
> 1. Here, as per my understanding, the "3" indicates the 3rd year, right?
> But, you showed an average for 2 months of the same year. Then, what "3"
> in the? spdat$year object indicate?
>
>
> C. From this part, I got the exact average values of both January and
> > February of 1994 for country A, and B. But, in code, I have a query
> > that I need to define? spdat$returnA, and? spdat$returnB separately
> > before writing this code, right? Like this, I need to define for each
> > 84 countries separately with their respective number of months, and
> > years before writing this code, right?
> >
>
> I don't think so. Because I don't know what your data looks like, I am
> guessing that for each row, it has columns for each of the 84 countries. I
> don't know what these columns are named, either. Maybe:
>
> date? ? ? ? ? ? ?Australia? ?Belarus? ?...? ? Zambia
> 01/01/1994? ?20? ? ? ? ? ? ?21? ? ? ? ? ? ? ? ?22
> ...
>
> Here, due to my misunderstanding about the code, I was wrong. But, what
> data structure you guessed, it is absolutely right that for each row, I have
> columns for each of the 84 countries. So, I think, I need to define the date
> column with no. of months, and years once for all the countries.
> Therefore, I got my answer to the first and third question in the previous
> email (what you suggested) that I no need to define the column of each
> country, as the date, and no. of observations are same for all countries.
> But, the no. of days are different for each month, and similarly, for each
> year. So, I think I need to define date for each year separately.? Hence, I have
> given an example of 12 months, for 2 years (i.e. 1994, and 1995), and have
> written the following code. Please correct me in case I am wrong.
>
>? spdat<-data.frame(
>
> dates=paste(c(1:21,1:20,1:23,1:21,1:22,1:22,1:21,1:23,1:22,1:21,1:22,1:22),c(r
> ep(1,21),rep(2,20),
> rep(3,23), rep(4,21),
> rep(5,22),rep(6,22),rep(7,21),rep(8,23),rep(9,22),rep(10,21),rep(11,22),rep(12
> ,22)
> ),rep(1994,260)
>? dates1=
> paste(c(1:22,1:20,1:23,1:20,1:23,1:22,1:21,1:23,1:21,1:22,1:22,1:21),c(rep(1,2
> 2),rep(2,20),
> rep(3,23), rep(4,20),
> rep(5,23),rep(6,22),rep(7,21),rep(8,23),rep(9,21),rep(10,21),rep(11,22),rep(12
> ,21)
> ),rep(1995,259) ,sep="-")
>
> Concerning the exporting of structure of the dataset to excel, I will have
> 12*84 matrix. But, please suggest me the way to proceed for the large
> sample. I have mentioned below what I understood from your code. Please
> correct me if I am wrong.
> 1. I need to define the date for each year as the no. of days in each month
> are different for each year (as mentioned in my above code). For instance, in
> my data file, Jan 1994 has 21 days while Jan 1995 has 22 days.
> 2. Need to define the date column as character.
> 3. Need to define the monthly average for each month, and year. So, now
> code will be as follows.
> spdat$month<-sapply(strsplit(spdat$dates,"-"),"[",2,3,4,5,6,7,8,9,10,11,12)
>? ?%%%%As I need all months average sequentially.
> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",3)
>
> Here, this meaning of "3", I am really unable to get.
>
> 4. Need to define each country with each month and year as mentioned in
> the last part of your code.
>
> Please suggest me in this regard.
>
> Thank you.
>
>
>
>
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> mpaign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_ca
> mpaign=signaturevirality5&>
> 09/13/19,
> 06:41:41 PM
>
> On Fri, Sep 13, 2019 at 4:24 PM Jim Lemon <mailto:drjimlemon at gmail.com> wrote:
>
> > Hi Subhamitra,
> > I'll try to write my answers adjacent to your questions below.
> >
> > On Fri, Sep 13, 2019 at 6:08 PM Subhamitra Patra <
> > mailto:subhamitra.patra at gmail.com> wrote:
> >
> >> Dear Sir,
> >>
> >> Thank you very much for your suggestion.
> >>
> >> Yes, your suggested code worked. But, actually, I have data from 3rd
> >> January 1994 to 3rd August 2017 for very large (i.e. for 84
> >> countries) sample. From this, I have given the example of the years
> >> up to 2000. Before applying the same code for the long 24 years, I
> >> want to learn the logic behind the code. Actually, some part of the
> >> code is not understandable to me which I mentioned in the bold letter as
> follows.
> >>
> >> "spdat<-data.frame(
> >>? ?dates=paste(c(1:30,1:28),c(rep(1,30),rep(2,28)),rep(1994,58),sep="-"),
> >>? ?returnA=sample(*15:50*,58,TRUE),returnB=sample(*10:45*,58,TRUE))"
> >>
> >> A. Here, I need to define the no. of days in a month, and the no. of
> >> countries name separately, right? But, what is meant by 15:50, and
> >> 10:45 in return A, and B respectively?
> >>
> >
> > To paraphrase Donald Trump, this is FAKE DATA! I have no idea what the
> > real values of return are, so I made them up using the "sample" function.
> > However, this is not meant to mislead anyone, just to show how
> > whatever numbers are in your data can be used in calculations. The
> > colon (":") operator creates a sequence of numbers starting with the
> > one to the left and ending with the one to the right.
> >
> >>
> >> "# if you only have to get the monthly averages, it can be done this
> >> way
> >> spdat$month<-sapply(strsplit(spdat$dates,"-"),"["*,2*)
> >> spdat$year<-sapply(strsplit(spdat$dates,"-"),"[",*3*)"
> >>
> >> B. Here, I need to define the no. of months, and years separately, right?
> >> or else what 2, and 3 (in bold) indicates?
> >>
> >
> > To get the grouping variable of sequential months that you want, you
> > only need the month and year values of the dates in the first column.
> > First I used the "strsplit" function to split the date field at the
> > hyphens, then used "sapply" to extract ("[") the second (month) and
> > third (year) parts as two new columns. Because you have more than one
> > year of data, you need the year values or you will group all Januarys,
> > all Februarys and so on. Notice how I pass both of the new columns as
> > a list (a data frame is a type of
> > list) in the call to get the mean of each month.
> >
> >>
> >> "# get the averages by month and year - is this correct?
> >> monthlyA<-by(*spdat$returnA*,spdat[,c("month","year")],mean)
> >> monthlyB<-by(*spdat$returnB*,spdat[,c("month","year")],mean)"
> >>
> >> C. From this part, I got the exact average values of both January and
> >> February of 1994 for country A, and B. But, in code, I have a query
> >> that I need to define? spdat$returnA, and? spdat$returnB separately
> >> before writing this code, right? Like this, I need to define for each
> >> 84 countries separately with their respective number of months, and
> >> years before writing this code, right?
> >>
> >
> > I don't think so. Because I don't know what your data looks like, I am
> > guessing that for each row, it has columns for each of the 84
> > countries. I don't know what these columns are named, either. Maybe:
> >
> > date? ? ? ? ? ? ?Australia? ?Belarus? ?...? ? Zambia
> > 01/01/1994? ?20? ? ? ? ? ? ?21? ? ? ? ? ? ? ? ?22
> > ...
> >
> >
> >> Yes, after obtaining the monthly average for each country's data, I
> >> need to use them for further calculations. So, I want to export the
> >> result to excel. But, until understanding the code, I think I willn't
> >> able to apply for the entire sample, and cannot be able to discuss
> >> the format of the resulted column to export to excel.
> >>
> >
> > Say that we perform the grouped mean calculation for the first two
> > country columns like this:
> > monmeans<-sapply(spdat[,2:3],by,spdat[,c("month","year")],mean)
> > monmeans
> >? ? ?Australia? Belarus
> > [1,]? 29.70000 30.43333
> > [2,]? 34.17857 27.39286
> >
> > We are presented with a 2x2 matrix of monthly means in just the format
> > someone might use for importing into Excel. The first row is January
> > 1994, the second February 1994 and so on. By expanding the columns to
> > include all the countries in your data, You should have the result you want.
> >
> > Jim
> >
>
>
> --
> *Best Regards,*
> *Subhamitra Patra*
> *Phd. Research Scholar*
> *Department of Humanities and Social Sciences* *Indian Institute of
> Technology, Kharagpur*
> *INDIA*
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/



-- 
Best Regards,
Subhamitra Patra
Phd. Research Scholar
Department of Humanities and Social Sciences
Indian Institute of Technology, Kharagpur
INDIA

From c@|@ndr@ @end|ng |rom rgzm@de  Tue Sep 17 08:48:43 2019
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 17 Sep 2019 08:48:43 +0200
Subject: [R] regex
Message-ID: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>

Dear useRs,

I still have problems using regular expressions. I have two problems for 
which I have found workarounds, but I'm sure there are better ways of 
doing it.

1) list CSV files with "_w_" in the name

Here is a sample of the files in the folder:
myfiles <- c("BU-072_1_E1_RE_SEC-01_local_a_0.2_0.2.csv", 
"BU-072_1_E1_RE_SEC-01_local_a_0.2_0.6.csv","BU-072_1_E1_RE_SEC-01_local_a_0.4_1.0.csv", 
"BU-072_1_E1_RE_SEC-01_local_a_1.0_0.2.csv","BU-072_1_E1_RE_SEC-01_local_a_1.0_0.6.csv", 
"BU-072_1_E1_RE_SEC-01_local_w_0.2_0.2.csv","BU-072_1_E1_RE_SEC-01_local_w_0.2_0.6.csv", 
"BU-072_1_E1_RE_SEC-01_local_w_0.4_1.0.csv","BU-072_1_E1_RE_SEC-01_local_w_1.0_0.2.csv", 
"BU-072_1_E1_RE_SEC-01_local_w_1.0_0.6.csv","BU-072_1_E1_RE_SEC-01_local_w_1.0_1.0.csv", 
"BU-072_1_E1_RE_SEC-01_local_a_0.2_0.2.xls","BU-072_1_E1_RE_SEC-01_local_a_0.2_0.6.xls", 
"BU-072_1_E1_RE_SEC-01_local_a_0.4_1.0.xls","BU-072_1_E1_RE_SEC-01_local_a_1.0_0.2.xls", 
"BU-072_1_E1_RE_SEC-01_local_a_1.0_0.6.xls","BU-072_1_E1_RE_SEC-01_local_w_0.2_0.2.xls", 
"BU-072_1_E1_RE_SEC-01_local_w_0.2_0.6.xls","BU-072_1_E1_RE_SEC-01_local_w_0.4_1.0.xls", 
"BU-072_1_E1_RE_SEC-01_local_w_1.0_0.2.xls","BU-072_1_E1_RE_SEC-01_local_w_1.0_0.6.xls", 
"BU-072_1_E1_RE_SEC-01_local_w_1.0_1.0.xls")

Here is what I did: CSVs <- list.files(path=..., pattern="\\.csv$") 
w.files <- CSVs[grep(pattern="_w_", CSVs)]

Of course, what I would like to do is list only the interesting files 
from the beginning, rather than subsetting the whole list of files. In 
other words, having a pattern that includes both "\\.csv$" and "_w_" in 
the list.files() call. I tried "_w_&\\.csv$" but it returns an empty vector.

2) The units of the variables are given in the original headers. I would 
like to extract the units. This is what I did: headers <- c("dist to 
origin on curve [mm]","segment on section [mm]", "angle 1 [degree]", 
"angle 2 [degree]","angle 3 [degree]") units.var <- 
gsub(pattern="^.*\\[|\\]$", "", headers)

It seems to be to overly complicated using gsub(). Isn't there a way to 
extract what is interesting rather than deleting what is not?

Thank you for your help! Best, Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Sep 17 09:14:24 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 17 Sep 2019 10:14:24 +0300
Subject: [R] regex
In-Reply-To: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
Message-ID: <20190917101424.69178d02@Tarkus>

On Tue, 17 Sep 2019 08:48:43 +0200
Ivan Calandra <calandra at rgzm.de> wrote:

> CSVs <- list.files(path=..., pattern="\\.csv$") 
> w.files <- CSVs[grep(pattern="_w_", CSVs)]
> 
> Of course, what I would like to do is list only the interesting files 
> from the beginning, rather than subsetting the whole list of files.

One way to express that would be "_w_.*\\.csv$", meaning that the
filename has to have "_w_" in it, followed by anything (any character
repeated any number of times, including 0), followed by ".csv" at the
end of the line.

> 2) The units of the variables are given in the original headers. I
> would like to extract the units. This is what I did: headers <-
> c("dist to origin on curve [mm]","segment on section [mm]", "angle 1
> [degree]", "angle 2 [degree]","angle 3 [degree]") units.var <- 
> gsub(pattern="^.*\\[|\\]$", "", headers)
> 
> It seems to be to overly complicated using gsub(). Isn't there a way
> to extract what is interesting rather than deleting what is not?

Pure-R way: use regmatches() + regexpr(). Both regmatches and regexpr
take the character vector as an argument, so duplication is hard to
avoid:

units <- regmatches(headers, regexpr('\\[.*\\]', headers))

The stringr package has an str_match() function with a nicer interface:
str_match(headers, '\\[.*\\]') -> units.

Such "greedy" patterns containing ".*" present a few pitfalls, e.g.
looking for text in parentheses using the pattern "\\(.*\\)" in
"...(abc)...(def)..." will match the whole "(abc)...(def)" instead of
single groups "(abc)" and "(def)", but with your examples the pattern
should work as presented. One other option would be to ask for "[",
followed by zero or more characters that are not "]", followed by "]":
'\\[[^]]*\\]'.

-- 
Best regards,
Ivan


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Sep 17 09:25:20 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 17 Sep 2019 10:25:20 +0300
Subject: [R] regex
In-Reply-To: <20190917101424.69178d02@Tarkus>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
 <20190917101424.69178d02@Tarkus>
Message-ID: <20190917102520.6fd91f99@Tarkus>

On Tue, 17 Sep 2019 10:14:24 +0300
Ivan Krylov <krylov.r00t at gmail.com> wrote:

> '\\[.*\\]'

Sorry, I forgot to take it into account that you don't want the [] in
your units, either. That's still doable, but requires so-called
look-around assertions in the regular expression:

'(?<=\\[).*(?=\\])'

This should match any characters that are preceded by "[" and followed
by "]", but without including the brackets in the match. This requires
passing perl = TRUE to regexpr(). stringr::str_match() understands this
pattern without any additional flags.

-- 
Best regards,
Ivan


From c@|@ndr@ @end|ng |rom rgzm@de  Tue Sep 17 15:39:13 2019
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 17 Sep 2019 15:39:13 +0200
Subject: [R] regex
In-Reply-To: <20190917101424.69178d02@Tarkus>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
 <20190917101424.69178d02@Tarkus>
Message-ID: <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>

Thank you Ivan for your help!

Your solution for the first problem is so simple I didn't even think 
about it!
What I find weird is that "_w_|\\.csv$" works as expected ("OR"), but is 
there no way to combine two patterns with an "AND"?

Your solution to the second problem is actually unfortunately even more 
complicated to me than the gsub() solution. But I'm glad I can learn 
about regmatches() and regexpr()!

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 17/09/2019 09:14, Ivan Krylov wrote:
> On Tue, 17 Sep 2019 08:48:43 +0200
> Ivan Calandra <calandra at rgzm.de> wrote:
>
>> CSVs <- list.files(path=..., pattern="\\.csv$")
>> w.files <- CSVs[grep(pattern="_w_", CSVs)]
>>
>> Of course, what I would like to do is list only the interesting files
>> from the beginning, rather than subsetting the whole list of files.
> One way to express that would be "_w_.*\\.csv$", meaning that the
> filename has to have "_w_" in it, followed by anything (any character
> repeated any number of times, including 0), followed by ".csv" at the
> end of the line.
>
>> 2) The units of the variables are given in the original headers. I
>> would like to extract the units. This is what I did: headers <-
>> c("dist to origin on curve [mm]","segment on section [mm]", "angle 1
>> [degree]", "angle 2 [degree]","angle 3 [degree]") units.var <-
>> gsub(pattern="^.*\\[|\\]$", "", headers)
>>
>> It seems to be to overly complicated using gsub(). Isn't there a way
>> to extract what is interesting rather than deleting what is not?
> Pure-R way: use regmatches() + regexpr(). Both regmatches and regexpr
> take the character vector as an argument, so duplication is hard to
> avoid:
>
> units <- regmatches(headers, regexpr('\\[.*\\]', headers))
>
> The stringr package has an str_match() function with a nicer interface:
> str_match(headers, '\\[.*\\]') -> units.
>
> Such "greedy" patterns containing ".*" present a few pitfalls, e.g.
> looking for text in parentheses using the pattern "\\(.*\\)" in
> "...(abc)...(def)..." will match the whole "(abc)...(def)" instead of
> single groups "(abc)" and "(def)", but with your examples the pattern
> should work as presented. One other option would be to ask for "[",
> followed by zero or more characters that are not "]", followed by "]":
> '\\[[^]]*\\]'.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Sep 17 16:38:46 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Sep 2019 07:38:46 -0700
Subject: [R] regex
In-Reply-To: <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
 <20190917101424.69178d02@Tarkus>
 <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>
Message-ID: <A7F2F0A0-EE28-4F23-808D-EAC8571B1630@dcn.davis.ca.us>

https://stackoverflow.com/questions/3041320/regex-and-operator/37692545

On September 17, 2019 6:39:13 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Thank you Ivan for your help!
>
>Your solution for the first problem is so simple I didn't even think 
>about it!
>What I find weird is that "_w_|\\.csv$" works as expected ("OR"), but
>is 
>there no way to combine two patterns with an "AND"?
>
>Your solution to the second problem is actually unfortunately even more
>
>complicated to me than the gsub() solution. But I'm glad I can learn 
>about regmatches() and regexpr()!
>
>Best,
>Ivan
>
>--
>Dr. Ivan Calandra
>TraCEr, laboratory for Traceology and Controlled Experiments
>MONREPOS Archaeological Research Centre and
>Museum for Human Behavioural Evolution
>Schloss Monrepos
>56567 Neuwied, Germany
>+49 (0) 2631 9772-243
>https://www.researchgate.net/profile/Ivan_Calandra
>
>On 17/09/2019 09:14, Ivan Krylov wrote:
>> On Tue, 17 Sep 2019 08:48:43 +0200
>> Ivan Calandra <calandra at rgzm.de> wrote:
>>
>>> CSVs <- list.files(path=..., pattern="\\.csv$")
>>> w.files <- CSVs[grep(pattern="_w_", CSVs)]
>>>
>>> Of course, what I would like to do is list only the interesting
>files
>>> from the beginning, rather than subsetting the whole list of files.
>> One way to express that would be "_w_.*\\.csv$", meaning that the
>> filename has to have "_w_" in it, followed by anything (any character
>> repeated any number of times, including 0), followed by ".csv" at the
>> end of the line.
>>
>>> 2) The units of the variables are given in the original headers. I
>>> would like to extract the units. This is what I did: headers <-
>>> c("dist to origin on curve [mm]","segment on section [mm]", "angle 1
>>> [degree]", "angle 2 [degree]","angle 3 [degree]") units.var <-
>>> gsub(pattern="^.*\\[|\\]$", "", headers)
>>>
>>> It seems to be to overly complicated using gsub(). Isn't there a way
>>> to extract what is interesting rather than deleting what is not?
>> Pure-R way: use regmatches() + regexpr(). Both regmatches and regexpr
>> take the character vector as an argument, so duplication is hard to
>> avoid:
>>
>> units <- regmatches(headers, regexpr('\\[.*\\]', headers))
>>
>> The stringr package has an str_match() function with a nicer
>interface:
>> str_match(headers, '\\[.*\\]') -> units.
>>
>> Such "greedy" patterns containing ".*" present a few pitfalls, e.g.
>> looking for text in parentheses using the pattern "\\(.*\\)" in
>> "...(abc)...(def)..." will match the whole "(abc)...(def)" instead of
>> single groups "(abc)" and "(def)", but with your examples the pattern
>> should work as presented. One other option would be to ask for "[",
>> followed by zero or more characters that are not "]", followed by
>"]":
>> '\\[[^]]*\\]'.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 17 16:42:33 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Sep 2019 07:42:33 -0700
Subject: [R] regex
In-Reply-To: <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
 <20190917101424.69178d02@Tarkus>
 <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>
Message-ID: <CAGxFJbSBtrg8sPgX3AUwrzL_uD6M-gE2QXe+NRvJXdJ4rZ3Srg@mail.gmail.com>

(For the units)

Why not simply:

sub(".*\\[(.+)\\]","\\1", headers)

Cheers,
Bert


On Tue, Sep 17, 2019 at 6:40 AM Ivan Calandra <calandra at rgzm.de> wrote:

> Thank you Ivan for your help!
>
> Your solution for the first problem is so simple I didn't even think
> about it!
> What I find weird is that "_w_|\\.csv$" works as expected ("OR"), but is
> there no way to combine two patterns with an "AND"?
>
> Your solution to the second problem is actually unfortunately even more
> complicated to me than the gsub() solution. But I'm glad I can learn
> about regmatches() and regexpr()!
>
> Best,
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 17/09/2019 09:14, Ivan Krylov wrote:
> > On Tue, 17 Sep 2019 08:48:43 +0200
> > Ivan Calandra <calandra at rgzm.de> wrote:
> >
> >> CSVs <- list.files(path=..., pattern="\\.csv$")
> >> w.files <- CSVs[grep(pattern="_w_", CSVs)]
> >>
> >> Of course, what I would like to do is list only the interesting files
> >> from the beginning, rather than subsetting the whole list of files.
> > One way to express that would be "_w_.*\\.csv$", meaning that the
> > filename has to have "_w_" in it, followed by anything (any character
> > repeated any number of times, including 0), followed by ".csv" at the
> > end of the line.
> >
> >> 2) The units of the variables are given in the original headers. I
> >> would like to extract the units. This is what I did: headers <-
> >> c("dist to origin on curve [mm]","segment on section [mm]", "angle 1
> >> [degree]", "angle 2 [degree]","angle 3 [degree]") units.var <-
> >> gsub(pattern="^.*\\[|\\]$", "", headers)
> >>
> >> It seems to be to overly complicated using gsub(). Isn't there a way
> >> to extract what is interesting rather than deleting what is not?
> > Pure-R way: use regmatches() + regexpr(). Both regmatches and regexpr
> > take the character vector as an argument, so duplication is hard to
> > avoid:
> >
> > units <- regmatches(headers, regexpr('\\[.*\\]', headers))
> >
> > The stringr package has an str_match() function with a nicer interface:
> > str_match(headers, '\\[.*\\]') -> units.
> >
> > Such "greedy" patterns containing ".*" present a few pitfalls, e.g.
> > looking for text in parentheses using the pattern "\\(.*\\)" in
> > "...(abc)...(def)..." will match the whole "(abc)...(def)" instead of
> > single groups "(abc)" and "(def)", but with your examples the pattern
> > should work as presented. One other option would be to ask for "[",
> > followed by zero or more characters that are not "]", followed by "]":
> > '\\[[^]]*\\]'.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Tue Sep 17 16:46:08 2019
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 17 Sep 2019 16:46:08 +0200
Subject: [R] regex
In-Reply-To: <A7F2F0A0-EE28-4F23-808D-EAC8571B1630@dcn.davis.ca.us>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
 <20190917101424.69178d02@Tarkus>
 <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>
 <A7F2F0A0-EE28-4F23-808D-EAC8571B1630@dcn.davis.ca.us>
Message-ID: <01ac1155-2826-b534-ddf8-52ad8a19ed19@rgzm.de>

Thanks Jeff!
It does indeed make sense that there is no "AND" corresponding to the "|".

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 17/09/2019 16:38, Jeff Newmiller wrote:
> https://stackoverflow.com/questions/3041320/regex-and-operator/37692545
>
> On September 17, 2019 6:39:13 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Thank you Ivan for your help!
>>
>> Your solution for the first problem is so simple I didn't even think
>> about it!
>> What I find weird is that "_w_|\\.csv$" works as expected ("OR"), but
>> is
>> there no way to combine two patterns with an "AND"?
>>
>> Your solution to the second problem is actually unfortunately even more
>>
>> complicated to me than the gsub() solution. But I'm glad I can learn
>> about regmatches() and regexpr()!
>>
>> Best,
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 17/09/2019 09:14, Ivan Krylov wrote:
>>> On Tue, 17 Sep 2019 08:48:43 +0200
>>> Ivan Calandra <calandra at rgzm.de> wrote:
>>>
>>>> CSVs <- list.files(path=..., pattern="\\.csv$")
>>>> w.files <- CSVs[grep(pattern="_w_", CSVs)]
>>>>
>>>> Of course, what I would like to do is list only the interesting
>> files
>>>> from the beginning, rather than subsetting the whole list of files.
>>> One way to express that would be "_w_.*\\.csv$", meaning that the
>>> filename has to have "_w_" in it, followed by anything (any character
>>> repeated any number of times, including 0), followed by ".csv" at the
>>> end of the line.
>>>
>>>> 2) The units of the variables are given in the original headers. I
>>>> would like to extract the units. This is what I did: headers <-
>>>> c("dist to origin on curve [mm]","segment on section [mm]", "angle 1
>>>> [degree]", "angle 2 [degree]","angle 3 [degree]") units.var <-
>>>> gsub(pattern="^.*\\[|\\]$", "", headers)
>>>>
>>>> It seems to be to overly complicated using gsub(). Isn't there a way
>>>> to extract what is interesting rather than deleting what is not?
>>> Pure-R way: use regmatches() + regexpr(). Both regmatches and regexpr
>>> take the character vector as an argument, so duplication is hard to
>>> avoid:
>>>
>>> units <- regmatches(headers, regexpr('\\[.*\\]', headers))
>>>
>>> The stringr package has an str_match() function with a nicer
>> interface:
>>> str_match(headers, '\\[.*\\]') -> units.
>>>
>>> Such "greedy" patterns containing ".*" present a few pitfalls, e.g.
>>> looking for text in parentheses using the pattern "\\(.*\\)" in
>>> "...(abc)...(def)..." will match the whole "(abc)...(def)" instead of
>>> single groups "(abc)" and "(def)", but with your examples the pattern
>>> should work as presented. One other option would be to ask for "[",
>>> followed by zero or more characters that are not "]", followed by
>> "]":
>>> '\\[[^]]*\\]'.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From c@|@ndr@ @end|ng |rom rgzm@de  Tue Sep 17 16:52:31 2019
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 17 Sep 2019 16:52:31 +0200
Subject: [R] regex
In-Reply-To: <CAGxFJbSBtrg8sPgX3AUwrzL_uD6M-gE2QXe+NRvJXdJ4rZ3Srg@mail.gmail.com>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
 <20190917101424.69178d02@Tarkus>
 <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>
 <CAGxFJbSBtrg8sPgX3AUwrzL_uD6M-gE2QXe+NRvJXdJ4rZ3Srg@mail.gmail.com>
Message-ID: <ea0e5db9-c3b0-d9ed-4e6c-05edf5476045@rgzm.de>

Thank you Bert.
That's more like what I was looking for.

Could you please tell me where I can find information on the "\\1"? This 
is the part I still don't get.

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 17/09/2019 16:42, Bert Gunter wrote:
> (For the units)
>
> Why not simply:
>
> sub(".*\\[(.+)\\]","\\1", headers)
>
> Cheers,
> Bert
>
>
> On Tue, Sep 17, 2019 at 6:40 AM Ivan Calandra <calandra at rgzm.de 
> <mailto:calandra at rgzm.de>> wrote:
>
>     Thank you Ivan for your help!
>
>     Your solution for the first problem is so simple I didn't even think
>     about it!
>     What I find weird is that "_w_|\\.csv$" works as expected ("OR"),
>     but is
>     there no way to combine two patterns with an "AND"?
>
>     Your solution to the second problem is actually unfortunately even
>     more
>     complicated to me than the gsub() solution. But I'm glad I can learn
>     about regmatches() and regexpr()!
>
>     Best,
>     Ivan
>
>     --
>     Dr. Ivan Calandra
>     TraCEr, laboratory for Traceology and Controlled Experiments
>     MONREPOS Archaeological Research Centre and
>     Museum for Human Behavioural Evolution
>     Schloss Monrepos
>     56567 Neuwied, Germany
>     +49 (0) 2631 9772-243
>     https://www.researchgate.net/profile/Ivan_Calandra
>
>     On 17/09/2019 09:14, Ivan Krylov wrote:
>     > On Tue, 17 Sep 2019 08:48:43 +0200
>     > Ivan Calandra <calandra at rgzm.de <mailto:calandra at rgzm.de>> wrote:
>     >
>     >> CSVs <- list.files(path=..., pattern="\\.csv$")
>     >> w.files <- CSVs[grep(pattern="_w_", CSVs)]
>     >>
>     >> Of course, what I would like to do is list only the interesting
>     files
>     >> from the beginning, rather than subsetting the whole list of files.
>     > One way to express that would be "_w_.*\\.csv$", meaning that the
>     > filename has to have "_w_" in it, followed by anything (any
>     character
>     > repeated any number of times, including 0), followed by ".csv"
>     at the
>     > end of the line.
>     >
>     >> 2) The units of the variables are given in the original headers. I
>     >> would like to extract the units. This is what I did: headers <-
>     >> c("dist to origin on curve [mm]","segment on section [mm]",
>     "angle 1
>     >> [degree]", "angle 2 [degree]","angle 3 [degree]") units.var <-
>     >> gsub(pattern="^.*\\[|\\]$", "", headers)
>     >>
>     >> It seems to be to overly complicated using gsub(). Isn't there
>     a way
>     >> to extract what is interesting rather than deleting what is not?
>     > Pure-R way: use regmatches() + regexpr(). Both regmatches and
>     regexpr
>     > take the character vector as an argument, so duplication is hard to
>     > avoid:
>     >
>     > units <- regmatches(headers, regexpr('\\[.*\\]', headers))
>     >
>     > The stringr package has an str_match() function with a nicer
>     interface:
>     > str_match(headers, '\\[.*\\]') -> units.
>     >
>     > Such "greedy" patterns containing ".*" present a few pitfalls, e.g.
>     > looking for text in parentheses using the pattern "\\(.*\\)" in
>     > "...(abc)...(def)..." will match the whole "(abc)...(def)"
>     instead of
>     > single groups "(abc)" and "(def)", but with your examples the
>     pattern
>     > should work as presented. One other option would be to ask for "[",
>     > followed by zero or more characters that are not "]", followed
>     by "]":
>     > '\\[[^]]*\\]'.
>     >
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 17 17:04:32 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Sep 2019 08:04:32 -0700
Subject: [R] regex
In-Reply-To: <ea0e5db9-c3b0-d9ed-4e6c-05edf5476045@rgzm.de>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
 <20190917101424.69178d02@Tarkus>
 <1428df81-de90-e572-f6c0-969324c0c441@rgzm.de>
 <CAGxFJbSBtrg8sPgX3AUwrzL_uD6M-gE2QXe+NRvJXdJ4rZ3Srg@mail.gmail.com>
 <ea0e5db9-c3b0-d9ed-4e6c-05edf5476045@rgzm.de>
Message-ID: <CAGxFJbRdpobwbQOESi+w+vHVSwYX4YbWbTTDQxnG7rPJw1eQqA@mail.gmail.com>

?regexp   ## Search the text on "backreference" .(or websearch it: "regular
expression backreference")

-- Bert


On Tue, Sep 17, 2019 at 7:52 AM Ivan Calandra <calandra at rgzm.de> wrote:

> Thank you Bert.
> That's more like what I was looking for.
>
> Could you please tell me where I can find information on the "\\1"? This
> is the part I still don't get.
>
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243https://www.researchgate.net/profile/Ivan_Calandra
>
> On 17/09/2019 16:42, Bert Gunter wrote:
>
> (For the units)
>
> Why not simply:
>
> sub(".*\\[(.+)\\]","\\1", headers)
>
> Cheers,
> Bert
>
>
> On Tue, Sep 17, 2019 at 6:40 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
>> Thank you Ivan for your help!
>>
>> Your solution for the first problem is so simple I didn't even think
>> about it!
>> What I find weird is that "_w_|\\.csv$" works as expected ("OR"), but is
>> there no way to combine two patterns with an "AND"?
>>
>> Your solution to the second problem is actually unfortunately even more
>> complicated to me than the gsub() solution. But I'm glad I can learn
>> about regmatches() and regexpr()!
>>
>> Best,
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 17/09/2019 09:14, Ivan Krylov wrote:
>> > On Tue, 17 Sep 2019 08:48:43 +0200
>> > Ivan Calandra <calandra at rgzm.de> wrote:
>> >
>> >> CSVs <- list.files(path=..., pattern="\\.csv$")
>> >> w.files <- CSVs[grep(pattern="_w_", CSVs)]
>> >>
>> >> Of course, what I would like to do is list only the interesting files
>> >> from the beginning, rather than subsetting the whole list of files.
>> > One way to express that would be "_w_.*\\.csv$", meaning that the
>> > filename has to have "_w_" in it, followed by anything (any character
>> > repeated any number of times, including 0), followed by ".csv" at the
>> > end of the line.
>> >
>> >> 2) The units of the variables are given in the original headers. I
>> >> would like to extract the units. This is what I did: headers <-
>> >> c("dist to origin on curve [mm]","segment on section [mm]", "angle 1
>> >> [degree]", "angle 2 [degree]","angle 3 [degree]") units.var <-
>> >> gsub(pattern="^.*\\[|\\]$", "", headers)
>> >>
>> >> It seems to be to overly complicated using gsub(). Isn't there a way
>> >> to extract what is interesting rather than deleting what is not?
>> > Pure-R way: use regmatches() + regexpr(). Both regmatches and regexpr
>> > take the character vector as an argument, so duplication is hard to
>> > avoid:
>> >
>> > units <- regmatches(headers, regexpr('\\[.*\\]', headers))
>> >
>> > The stringr package has an str_match() function with a nicer interface:
>> > str_match(headers, '\\[.*\\]') -> units.
>> >
>> > Such "greedy" patterns containing ".*" present a few pitfalls, e.g.
>> > looking for text in parentheses using the pattern "\\(.*\\)" in
>> > "...(abc)...(def)..." will match the whole "(abc)...(def)" instead of
>> > single groups "(abc)" and "(def)", but with your examples the pattern
>> > should work as presented. One other option would be to ask for "[",
>> > followed by zero or more characters that are not "]", followed by "]":
>> > '\\[[^]]*\\]'.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Sep 17 17:11:51 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 17 Sep 2019 15:11:51 +0000
Subject: [R] tune segmented fit
Message-ID: <1692ca903565440c9b8384aaad1428b0@SRVEXCHCM1302.precheza.cz>

Dear all

I am trying to find one breakpoint in my data. I use segmented package.

Here is my data
> dput(temp)

temp <- structure(list(spotreba = 0:40, sqsp = c(0, 1, 1.4142135623731, 
1.73205080756888, 2, 2.23606797749979, 2.44948974278318, 2.64575131106459, 
2.82842712474619, 3, 3.16227766016838, 3.3166247903554, 3.46410161513775, 
3.60555127546399, 3.74165738677394, 3.87298334620742, 4, 4.12310562561766, 
4.24264068711928, 4.35889894354067, 4.47213595499958, 4.58257569495584, 
4.69041575982343, 4.79583152331272, 4.89897948556636, 5, 5.09901951359278, 
5.19615242270663, 5.29150262212918, 5.3851648071345, 5.47722557505166, 
5.56776436283002, 5.65685424949238, 5.74456264653803, 5.8309518948453, 
5.91607978309962, 6, 6.08276253029822, 6.16441400296898, 6.2449979983984, 
6.32455532033676), variable = structure(c(5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L), .Label = c("vod1", "vod2", "vod3", "vod4", "vod5"
), class = "factor"), value = c(420, 438, 449, 456, 466, 472, 
476, 481, 487, 496, 507, 520, 535, 554, 577, 606, 639, 677, 722, 
776, 836, 897, 959, 1030, 1105, 1182, 1256, 1346, 1432, 1519, 
1613, 1704, 1802, 1894, 1998, 2097, 2189, 2290, 2393, 2502, 2608
), fit = c(334.519176009225, 405.569071381122, 434.998901649351, 
457.581204665804, 476.618966753019, 493.391571855035, 508.555165948505, 
522.499529840424, 535.478627289478, 547.668862124917, 559.198672901077, 
570.165020351817, 580.643233322383, 590.693216888952, 600.363541857, 
609.694237534363, 618.718757496814, 627.465399316641, 635.958352929605, 
644.218489884464, 704.452390602657, 811.399180061218, 915.82851606979, 
1017.91022567874, 1117.79585929747, 1215.6213312916, 1311.50908941826, 
1405.56991195017, 1497.904407726, 1588.60427702993, 1677.75337832018, 
1765.42863614133, 1851.70081819772, 1936.63520392068, 2020.29216249248, 
2102.72765487767, 2183.99367172737, 2264.13861689264, 2343.20764458285, 
2421.2429568385, 2498.28406688275)), row.names = 165:205, class =
"data.frame")


fit <- lm(value~sqsp, temp)
fit.s <- segmented(fit, seg.Z= ~sqsp, npsi=1, psi = 2, nboot=50, tol=1e-10,
quant=F)
plot(temp$sqsp, temp$value)
plot(fit.s, add=T)

You can see that first part is rather off measured points. I tried to fiddle
with seg.control but was not able to achieve better result. The only way how
to make closer fit to first part of data which I was able to find was to get
rid of points near estimated psi and refit model.

temp.v <- temp[-c(15:25),]
fit <- lm(value~sqsp, temp.v)
fit.s <- segmented(fit, seg.Z= ~sqsp, npsi=1, psi = 2, nboot=50, tol=1e-10,
quant=F)
plot(fit.s, add=T, col=2)

Is there any more elegant way how to achieve similar result?

Best regards.
Petr

From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Sep 17 21:48:53 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 17 Sep 2019 19:48:53 +0000 (UTC)
Subject: [R] Not the same length
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
Message-ID: <889918375.11729611.1568749733508@mail.yahoo.com>

Dear R-helpers,

Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
How can I solve the problem ??

Here is the reproducible R code 

? #? #? #? #? #? #? #? #? #? #
library(mgcv) 
 library(earth) 

n<-2000 
x<-runif(n, 0, 5) ? 
 y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10 ? 
y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) 
gam_model<- gam(y_obs~s(x)) 
mars_model<- earth(y_obs~x) ? 
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
MSE_MARS<-mean((mars_model$fitted.values - y_model)^2) ? 
MSE_GAM 
MSE_MARS
? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 17 22:27:15 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 17 Sep 2019 13:27:15 -0700
Subject: [R] Not the same length
In-Reply-To: <889918375.11729611.1568749733508@mail.yahoo.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
Message-ID: <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>


On 9/17/19 12:48 PM, varin sacha via R-help wrote:
> Dear R-helpers,
>
> Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
> How can I solve the problem ?
>
> Here is the reproducible R code
>
>  ? #? #? #? #? #? #? #? #? #? #
> library(mgcv)
>   library(earth)
>
> n<-2000
> x<-runif(n, 0, 5)
>   y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10
> # y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) # maybe not exactly your goal?


You didn't lay out any goals for analysis, so let me guess what was 
intended:


I suspect that you were hoping to model a mixture composed of 90% from 
one distribution and 10% from another. If I'm right about that guess 
then you would instead wat to join the samples from each distribution:

y_obs<-c( rnorm(n*0.9, y_model, 0.1),? rnorm(n*0.1, y_model, 0.5) )

-- 

David


> gam_model<- gam(y_obs~s(x))
> mars_model<- earth(y_obs~x)
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
> MSE_GAM
> MSE_MARS
>  ? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Tue Sep 17 22:32:45 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 17 Sep 2019 22:32:45 +0200
Subject: [R] Not the same length
In-Reply-To: <889918375.11729611.1568749733508@mail.yahoo.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
Message-ID: <76FEF752-F250-41FA-83FE-056AB9692DCA@gmail.com>

It depends on what you want to do, which is likely not what you do do.... 

You might be looking for

y_obs <- ifelse(runif(n) < .9, rnorm(n, y_model, 0.1), rnorm(n, y_model, 0.5))

-pd


> On 17 Sep 2019, at 21:48 , varin sacha via R-help <r-help at r-project.org> wrote:
> 
> Dear R-helpers,
> 
> Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
> How can I solve the problem ? 
> 
> Here is the reproducible R code 
> 
>   #  #  #  #  #  #  #  #  #  #
> library(mgcv) 
> library(earth) 
> 
> n<-2000 
> x<-runif(n, 0, 5)   
> y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10   
> y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) 
> gam_model<- gam(y_obs~s(x)) 
> mars_model<- earth(y_obs~x)   
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)   
> MSE_GAM 
> MSE_MARS
>   #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Sep 17 22:35:48 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 17 Sep 2019 20:35:48 +0000 (UTC)
Subject: [R] Not the same length
In-Reply-To: <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
Message-ID: <1381442295.11760985.1568752548209@mail.yahoo.com>

Many thanks David, it perfectly works.
Now, one last think. 
If I want my R code here below to run let's say B=500 times and at the end I want to get the average for the MSE_GAM and for the MSE_MARS. How can I do that ?

library(mgcv) 
library(earth) 
n<-2000 
x<-runif(n, 0, 5) 
z <- runif(n, 0, 5) 
a <- runif(n, 0, 5) ? 
y_model<- 0.1*x^3 - 0.5 * z^2 - a + 10 
y_obs <- c( rnorm(n*0.5, y_model, 0.1), rnorm(n*0.5, y_model, 0.5) ) 
 gam_model<- gam(y_obs~s(x)+s(z)+s(a)) 
 mars_model<-earth(y_obs~x+z+a) ? 
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
MSE_MARS<-mean((mars_model$fitted.values - y_model)^2) ? 
MSE_GAM 
MSE_MARS







Le mardi 17 septembre 2019 ? 22:27:54 UTC+2, David Winsemius <dwinsemius at comcast.net> a ?crit : 






On 9/17/19 12:48 PM, varin sacha via R-help wrote:
> Dear R-helpers,
>
> Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
> How can I solve the problem ?
>
> Here is the reproducible R code
>
>? ? #? #? #? #? #? #? #? #? #? #
> library(mgcv)
>? library(earth)
>
> n<-2000
> x<-runif(n, 0, 5)
>? y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10
> # y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) # maybe not exactly your goal?


You didn't lay out any goals for analysis, so let me guess what was 
intended:


I suspect that you were hoping to model a mixture composed of 90% from 
one distribution and 10% from another. If I'm right about that guess 
then you would instead wat to join the samples from each distribution:

y_obs<-c( rnorm(n*0.9, y_model, 0.1),? rnorm(n*0.1, y_model, 0.5) )

-- 

David


> gam_model<- gam(y_obs~s(x))
> mars_model<- earth(y_obs~x)
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
> MSE_GAM
> MSE_MARS
>? ? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Sep 17 22:36:31 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 17 Sep 2019 20:36:31 +0000 (UTC)
Subject: [R] Not the same length
In-Reply-To: <5d813e32.1c69fb81.a644f.97fc@mx.google.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <5d813e32.1c69fb81.a644f.97fc@mx.google.com>
Message-ID: <137015095.11766883.1568752591781@mail.yahoo.com>

Many thanks Ana, it perfectly works.







Le mardi 17 septembre 2019 ? 22:12:35 UTC+2, Ana PGG <anacream at gmail.com> a ?crit : 





Dear Varin Sacha,
?
My guess to try to help you is the following:
?
I think you may want to change this: 
y_obs <- rnorm(n*0.9, y_model, 0.1) + rnorm(n*0.1, y_model, 0.5) 
for:
y_obs <- c( rnorm(n*0.9, y_model, 0.1), rnorm(n*0.1, y_model, 0.5) )
then y_obs:
?
> length(y_obs)
[1] 2000
?
?
De: varin sacha via R-help
Enviado: martes, 17 de septiembre de 2019 21:49
Para: R-help Mailing List
Asunto: [R] Not the same length
?
Dear R-helpers,
?
Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
How can I solve the problem ??
?
Here is the reproducible R code 
?
? #? #? #? #? #? #? #? #? #? #
library(mgcv) 
?library(earth) 
?
n<-2000 
x<-runif(n, 0, 5) ? 
?y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10 ? 
y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) 
gam_model<- gam(y_obs~s(x)) 
mars_model<- earth(y_obs~x) ? 
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
MSE_MARS<-mean((mars_model$fitted.values - y_model)^2) ? 
MSE_GAM 
MSE_MARS
? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #
?
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
?


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 17 23:08:54 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 17 Sep 2019 14:08:54 -0700
Subject: [R] Not the same length
In-Reply-To: <1381442295.11760985.1568752548209@mail.yahoo.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
 <1381442295.11760985.1568752548209@mail.yahoo.com>
Message-ID: <42f560f7-eafc-3be4-0e57-68c5f3e886bf@comcast.net>


On 9/17/19 1:35 PM, varin sacha wrote:
> Many thanks David, it perfectly works.
> Now, one last think.
> If I want my R code here below to run let's say B=500 times and at the end I want to get the average for the MSE_GAM and for the MSE_MARS. How can I do that ?


The `replicate` function is designed for that purpose.


-- 

David.

>
> library(mgcv)
> library(earth)
> n<-2000
> x<-runif(n, 0, 5)
> z <- runif(n, 0, 5)
> a <- runif(n, 0, 5)
> y_model<- 0.1*x^3 - 0.5 * z^2 - a + 10
> y_obs <- c( rnorm(n*0.5, y_model, 0.1), rnorm(n*0.5, y_model, 0.5) )
>   gam_model<- gam(y_obs~s(x)+s(z)+s(a))
>   mars_model<-earth(y_obs~x+z+a)
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
> MSE_GAM
> MSE_MARS
>
>
>
>
>
>
>
> Le mardi 17 septembre 2019 ? 22:27:54 UTC+2, David Winsemius <dwinsemius at comcast.net> a ?crit :
>
>
>
>
>
>
> On 9/17/19 12:48 PM, varin sacha via R-help wrote:
>> Dear R-helpers,
>>
>> Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
>> How can I solve the problem ?
>>
>> Here is the reproducible R code
>>
>>  ? ? #? #? #? #? #? #? #? #? #? #
>> library(mgcv)
>>  ? library(earth)
>>
>> n<-2000
>> x<-runif(n, 0, 5)
>>  ? y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10
>> # y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) # maybe not exactly your goal?
>
> You didn't lay out any goals for analysis, so let me guess what was
> intended:
>
>
> I suspect that you were hoping to model a mixture composed of 90% from
> one distribution and 10% from another. If I'm right about that guess
> then you would instead wat to join the samples from each distribution:
>
> y_obs<-c( rnorm(n*0.9, y_model, 0.1),? rnorm(n*0.1, y_model, 0.5) )
>


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep 17 23:13:19 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 17 Sep 2019 14:13:19 -0700
Subject: [R] Not the same length
In-Reply-To: <42f560f7-eafc-3be4-0e57-68c5f3e886bf@comcast.net>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
 <1381442295.11760985.1568752548209@mail.yahoo.com>
 <42f560f7-eafc-3be4-0e57-68c5f3e886bf@comcast.net>
Message-ID: <ea07343b-1906-d32d-85e6-64afdb3754f1@comcast.net>


On 9/17/19 2:08 PM, David Winsemius wrote:
>
> On 9/17/19 1:35 PM, varin sacha wrote:
>> Many thanks David, it perfectly works.
>> Now, one last think.
>> If I want my R code here below to run let's say B=500 times and at 
>> the end I want to get the average for the MSE_GAM and for the 
>> MSE_MARS. How can I do that ?
>
>
> The `replicate` function is designed for that purpose.


Although I also just noticed that you were separately computing 
residuals. Many R regression functions return a residual vector. Your 
code would be a lot faster over the course of 500 repeats if you used 
the resid function:


 > str( resid(gam_model))
 ?num [1:2000] -0.1385 0.1848 -0.0567 0.0605 -0.3297 ...
 > str( resid(mars_model))
 ?num [1:2000, 1] -0.2181 0.294 -0.0773 0.1626 -0.3512 ...
 ?- attr(*, "dimnames")=List of 2
 ? ..$ : chr [1:2000] "1" "2" "3" "4" ...
 ? ..$ : chr "y_obs"


From tr@xp|@yer @end|ng |rom gm@||@com  Wed Sep 18 00:02:47 2019
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 18 Sep 2019 00:02:47 +0200
Subject: [R] R wrong, Python rigth in calcution
Message-ID: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>

Hi,
  I don't understand why R computes this wrong. I know I can use gmp and
R will do it correctly.

$ echo '569936821221962380720^3 + (-569936821113563493509)^3 +
(-472715493453327032)^3' | Rscript - [1] -4.373553e+46
Correct answer is 3 and Python can do it:

$ echo
'pow(569936821221962380720,3)+pow(-569936821113563493509,3)+pow(-472715493453327032,3)'|python3
3

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep 18 00:11:26 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 17 Sep 2019 18:11:26 -0400
Subject: [R] R wrong, Python rigth in calcution
In-Reply-To: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>
References: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>
Message-ID: <4168a207-258a-32bd-91b4-5979479fd111@gmail.com>

On 17/09/2019 6:02 p.m., Martin M?ller Skarbiniks Pedersen wrote:
> Hi,
>    I don't understand why R computes this wrong.

This is pretty well documented.  R uses double precision floating point 
values for these expressions, which have about 15 digit precision.  I 
believe for whole numbers Python uses variable size integer values, so 
should get integer calculations exactly right.

You can also tell R to use exact 32 bit integer calculations, but your 
values are too big for that, so it wouldn't work in this example.



  I know I can use gmp and
> R will do it correctly.
> 
> $ echo '569936821221962380720^3 + (-569936821113563493509)^3 +
> (-472715493453327032)^3' | Rscript - [1] -4.373553e+46
> Correct answer is 3 and Python can do it:
> 
> $ echo
> 'pow(569936821221962380720,3)+pow(-569936821113563493509,3)+pow(-472715493453327032,3)'|python3
> 3
> 
> 	[[alternative HTML version deleted]]

Please don't post HTML to the list -- it's a plain text list.  That's 
also pretty well documented.

Duncan Murdoch


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Sep 18 00:09:35 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 18 Sep 2019 01:09:35 +0300
Subject: [R] R wrong, Python rigth in calcution
In-Reply-To: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>
References: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>
Message-ID: <20190918010935.1fa4b880@Tarkus>

On Wed, 18 Sep 2019 00:02:47 +0200
Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:

> I know I can use gmp and R will do it correctly.

Which is equivalent to what Python does: it uses so-called long
arithmetic, allowing scalar variables with as many digits as it fits in
the computer memory. R by default uses floating-point arithmetic, which
is subject to problems described in [*].

-- 
Best regards,
Ivan

[*] https://www.itu.dk/~sestoft/bachelor/IEEE754_article.pdf or
https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html


From |vv9 @end|ng |rom cdc@gov  Wed Sep 18 00:14:41 2019
From: |vv9 @end|ng |rom cdc@gov (Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP))
Date: Tue, 17 Sep 2019 22:14:41 +0000
Subject: [R] bi-directional bar chart with a central axis
Message-ID: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>

Hi R-help,

I have this data:

my.dta <-data.frame(matrix(c(
26.3,	21.4,
20.1,	13.4,
7.9,	3.9,
16.5,	14.6,
5.3,	3.6,
38.6,	25.6,
34.4,	21.6,
77.4,	79.5,
58.2,	56.1,
80.5,	84,
37.7,	31.9,
19.9,	28.1,
6.2,	5.9	
), nrow=13, ncol=2, byrow=T, 
dimnames=list(c('A',	'B',	'C',	'D', 	'E',	'F',	'G',   'H',	'I',	'J',	'K',	'L',	'M'), 
c("Males", "Females"))
))

I want to make a graph that looks like this:

https://i1.wp.com/stephanieevergreen.com/wp-content/uploads/2012/11/backtoback11.jpg?resize=864%2C379&ssl=1

Any help would be highly appreciated!

Best,

Jen


From rmh @end|ng |rom temp|e@edu  Wed Sep 18 00:26:45 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 17 Sep 2019 18:26:45 -0400
Subject: [R] R wrong, Python rigth in calcution
In-Reply-To: <4168a207-258a-32bd-91b4-5979479fd111@gmail.com>
References: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>
 <4168a207-258a-32bd-91b4-5979479fd111@gmail.com>
Message-ID: <CAGx1TMAoG-xwXKAfckMiczHE6hupFjDREv=9Xd+AG5KJJQ0EQA@mail.gmail.com>

Your numbers are 70 bits long, R double precision numbers are 53 bits long.
You need Rmpfr to get the higher precision.

> log(569936821221962380720, 2)
[1] 68.94936
> print(569936821221962380720, digits=22)
[1] 569936821221962350592

> library(Rmpfr)
> mpfr("569936821221962380720", 70)
1 'mpfr' number of precision  70   bits
[1] 569936821221962380720
>
> mpfr("569936821221962380720", 210)^3 + (mpfr("-569936821113563493509", 210))^3 + (mpfr("-472715493453327032", 210))^3
1 'mpfr' number of precision  210   bits
[1] 3

See FAQ 7.31 and the help files for Rmpfr

Rich




On Tue, Sep 17, 2019 at 6:13 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 17/09/2019 6:02 p.m., Martin M?ller Skarbiniks Pedersen wrote:
> > Hi,
> >    I don't understand why R computes this wrong.
>
> This is pretty well documented.  R uses double precision floating point
> values for these expressions, which have about 15 digit precision.  I
> believe for whole numbers Python uses variable size integer values, so
> should get integer calculations exactly right.
>
> You can also tell R to use exact 32 bit integer calculations, but your
> values are too big for that, so it wouldn't work in this example.
>
>
>
>   I know I can use gmp and
> > R will do it correctly.
> >
> > $ echo '569936821221962380720^3 + (-569936821113563493509)^3 +
> > (-472715493453327032)^3' | Rscript - [1] -4.373553e+46
> > Correct answer is 3 and Python can do it:
> >
> > $ echo
> > 'pow(569936821221962380720,3)+pow(-569936821113563493509,3)+pow(-472715493453327032,3)'|python3
> > 3
> >
> >       [[alternative HTML version deleted]]
>
> Please don't post HTML to the list -- it's a plain text list.  That's
> also pretty well documented.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep 18 00:31:47 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 17 Sep 2019 15:31:47 -0700
Subject: [R] bi-directional bar chart with a central axis
In-Reply-To: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
References: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
Message-ID: <65b5624c-e04c-57d5-4245-986b4be6321c@comcast.net>


On 9/17/19 3:14 PM, Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP) via 
R-help wrote:
> Hi R-help,
>
> I have this data:
>
> my.dta <-data.frame(matrix(c(
> 26.3,	21.4,
> 20.1,	13.4,
> 7.9,	3.9,
> 16.5,	14.6,
> 5.3,	3.6,
> 38.6,	25.6,
> 34.4,	21.6,
> 77.4,	79.5,
> 58.2,	56.1,
> 80.5,	84,
> 37.7,	31.9,
> 19.9,	28.1,
> 6.2,	5.9	
> ), nrow=13, ncol=2, byrow=T,
> dimnames=list(c('A',	'B',	'C',	'D', 	'E',	'F',	'G',   'H',	'I',	'J',	'K',	'L',	'M'),
> c("Males", "Females"))
> ))
>
> I want to make a graph that looks like this:
>
> https://i1.wp.com/stephanieevergreen.com/wp-content/uploads/2012/11/backtoback11.jpg?resize=864%2C379&ssl=1


I suppose it helps to know that these are called "pyramid charts" 
because of their common use in demographic circles for displaying 
comparative population structures of men and women ("population pyramids").


https://markmail.org/search/?q=list%3Aorg.r-project.r-help+pyramid+chart


Also look in the plotrix package since I seem to remember that it has 
one nicely documented and illustrated.

-- 

David.

>
> Any help would be highly appreciated!
>
> Best,
>
> Jen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |vv9 @end|ng |rom cdc@gov  Wed Sep 18 00:36:32 2019
From: |vv9 @end|ng |rom cdc@gov (Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP))
Date: Tue, 17 Sep 2019 22:36:32 +0000
Subject: [R] bi-directional bar chart with a central axis
In-Reply-To: <65b5624c-e04c-57d5-4245-986b4be6321c@comcast.net>
References: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
 <65b5624c-e04c-57d5-4245-986b4be6321c@comcast.net>
Message-ID: <SN6PR09MB2544DB2A63A966444350C2E0918F0@SN6PR09MB2544.namprd09.prod.outlook.com>

Oh, I guess I just wasn't thinking of them as population pyramids since the variables A-M are actually responses to unrelated survey questions and not age bins.  But that's silo'd thinking because why would that matter?

Thanks for the brain nudge.  I'll check out the plotrix link.

Jen

-----Original Message-----
From: David Winsemius <dwinsemius at comcast.net> 
Sent: Tuesday, September 17, 2019 6:32 PM
To: Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP) <fvv9 at cdc.gov>; r-help at r-project.org
Subject: Re: [R] bi-directional bar chart with a central axis


On 9/17/19 3:14 PM, Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP) via R-help wrote:
> Hi R-help,
>
> I have this data:
>
> my.dta <-data.frame(matrix(c(
> 26.3,	21.4,
> 20.1,	13.4,
> 7.9,	3.9,
> 16.5,	14.6,
> 5.3,	3.6,
> 38.6,	25.6,
> 34.4,	21.6,
> 77.4,	79.5,
> 58.2,	56.1,
> 80.5,	84,
> 37.7,	31.9,
> 19.9,	28.1,
> 6.2,	5.9	
> ), nrow=13, ncol=2, byrow=T,
> dimnames=list(c('A',	'B',	'C',	'D', 	'E',	'F',	'G',   'H',	'I',	'J',	'K',	'L',	'M'),
> c("Males", "Females"))
> ))
>
> I want to make a graph that looks like this:
>
> https://i1.wp.com/stephanieevergreen.com/wp-content/uploads/2012/11/ba
> cktoback11.jpg?resize=864%2C379&ssl=1


I suppose it helps to know that these are called "pyramid charts" 
because of their common use in demographic circles for displaying comparative population structures of men and women ("population pyramids").


https://markmail.org/search/?q=list%3Aorg.r-project.r-help+pyramid+chart


Also look in the plotrix package since I seem to remember that it has 
one nicely documented and illustrated.

-- 

David.

>
> Any help would be highly appreciated!
>
> Best,
>
> Jen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 18 00:42:55 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 18 Sep 2019 08:42:55 +1000
Subject: [R] bi-directional bar chart with a central axis
In-Reply-To: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
References: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
Message-ID: <CA+8X3fXpLmW9X6RTNa9qwLFYMWUo3x8xgz=hyKm3CiL0VJzjfg@mail.gmail.com>

Hi Jennifer,
This is one way:

library(plotrix)
pyramid.plot(my.dta[,1],my.dta[,2],
 labels=c("Statement 1","Statement 2","Statement 3",
 "Statement 4","Statement 5","Statement 6",
 "Statement 7","Statement 8","Statement 9",
 "Statement 10","Statement 11","Statement 12","Statement 13"),
 top.labels=c("Males","Statement","Females"),
 main="My pyramid plot",unit="percent",gap=25)

If you want to really get into pyramid plots, see the "pyramid" package.

Jim

On Wed, Sep 18, 2019 at 8:23 AM Sabatier, Jennifer F.
(CDC/DDPHSIS/CGH/DGHP) via R-help <r-help at r-project.org> wrote:
>
> Hi R-help,
>
> I have this data:
>
> my.dta <-data.frame(matrix(c(
> 26.3,   21.4,
> 20.1,   13.4,
> 7.9,    3.9,
> 16.5,   14.6,
> 5.3,    3.6,
> 38.6,   25.6,
> 34.4,   21.6,
> 77.4,   79.5,
> 58.2,   56.1,
> 80.5,   84,
> 37.7,   31.9,
> 19.9,   28.1,
> 6.2,    5.9
> ), nrow=13, ncol=2, byrow=T,
> dimnames=list(c('A',    'B',    'C',    'D',    'E',    'F',    'G',   'H',     'I',    'J',    'K',    'L',    'M'),
> c("Males", "Females"))
> ))
>
> I want to make a graph that looks like this:
>
> https://i1.wp.com/stephanieevergreen.com/wp-content/uploads/2012/11/backtoback11.jpg?resize=864%2C379&ssl=1
>
> Any help would be highly appreciated!
>
> Best,
>
> Jen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |vv9 @end|ng |rom cdc@gov  Wed Sep 18 00:51:25 2019
From: |vv9 @end|ng |rom cdc@gov (Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP))
Date: Tue, 17 Sep 2019 22:51:25 +0000
Subject: [R] bi-directional bar chart with a central axis
In-Reply-To: <CA+8X3fXpLmW9X6RTNa9qwLFYMWUo3x8xgz=hyKm3CiL0VJzjfg@mail.gmail.com>
References: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
 <CA+8X3fXpLmW9X6RTNa9qwLFYMWUo3x8xgz=hyKm3CiL0VJzjfg@mail.gmail.com>
Message-ID: <SN6PR09MB2544583799CDB95664F3C994918F0@SN6PR09MB2544.namprd09.prod.outlook.com>

Thanks, Jim (author of plotrix!), that's a real easy way to do it!

I'll play around with options.

Jen

-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com> 
Sent: Tuesday, September 17, 2019 6:43 PM
To: Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP) <fvv9 at cdc.gov>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] bi-directional bar chart with a central axis

Hi Jennifer,
This is one way:

library(plotrix)
pyramid.plot(my.dta[,1],my.dta[,2],
 labels=c("Statement 1","Statement 2","Statement 3",  "Statement 4","Statement 5","Statement 6",  "Statement 7","Statement 8","Statement 9",  "Statement 10","Statement 11","Statement 12","Statement 13"),  top.labels=c("Males","Statement","Females"),
 main="My pyramid plot",unit="percent",gap=25)

If you want to really get into pyramid plots, see the "pyramid" package.

Jim

On Wed, Sep 18, 2019 at 8:23 AM Sabatier, Jennifer F.
(CDC/DDPHSIS/CGH/DGHP) via R-help <r-help at r-project.org> wrote:
>
> Hi R-help,
>
> I have this data:
>
> my.dta <-data.frame(matrix(c(
> 26.3,   21.4,
> 20.1,   13.4,
> 7.9,    3.9,
> 16.5,   14.6,
> 5.3,    3.6,
> 38.6,   25.6,
> 34.4,   21.6,
> 77.4,   79.5,
> 58.2,   56.1,
> 80.5,   84,
> 37.7,   31.9,
> 19.9,   28.1,
> 6.2,    5.9
> ), nrow=13, ncol=2, byrow=T,
> dimnames=list(c('A',    'B',    'C',    'D',    'E',    'F',    'G',   'H',     'I',    'J',    'K',    'L',    'M'),
> c("Males", "Females"))
> ))
>
> I want to make a graph that looks like this:
>
> https://i1.wp.com/stephanieevergreen.com/wp-content/uploads/2012/11/ba
> cktoback11.jpg?resize=864%2C379&ssl=1
>
> Any help would be highly appreciated!
>
> Best,
>
> Jen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From rmh @end|ng |rom temp|e@edu  Wed Sep 18 00:54:05 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 17 Sep 2019 18:54:05 -0400
Subject: [R] bi-directional bar chart with a central axis
In-Reply-To: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
References: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
Message-ID: <CAGx1TMB5OYa7nqURa3HYBKOutn6ozQ1tkqKPkJHojwsLQqmYNg@mail.gmail.com>

I would use the likert function in the HH package

> library(HH)
> likert(my.dta)
> as.pyramidLikert(likert(my.dta))
>

See the demo

demo("likert-paper", package="HH", ask=FALSE)

for more complex examples,  including the population pyramid.
We can also get the multiple coloring that your posted example shows.

Rich

On Tue, Sep 17, 2019 at 6:23 PM Sabatier, Jennifer F.
(CDC/DDPHSIS/CGH/DGHP) via R-help <r-help at r-project.org> wrote:
>
> Hi R-help,
>
> I have this data:
>
> my.dta <-data.frame(matrix(c(
> 26.3,   21.4,
> 20.1,   13.4,
> 7.9,    3.9,
> 16.5,   14.6,
> 5.3,    3.6,
> 38.6,   25.6,
> 34.4,   21.6,
> 77.4,   79.5,
> 58.2,   56.1,
> 80.5,   84,
> 37.7,   31.9,
> 19.9,   28.1,
> 6.2,    5.9
> ), nrow=13, ncol=2, byrow=T,
> dimnames=list(c('A',    'B',    'C',    'D',    'E',    'F',    'G',   'H',     'I',    'J',    'K',    'L',    'M'),
> c("Males", "Females"))
> ))
>
> I want to make a graph that looks like this:
>
> https://i1.wp.com/stephanieevergreen.com/wp-content/uploads/2012/11/backtoback11.jpg?resize=864%2C379&ssl=1
>
> Any help would be highly appreciated!
>
> Best,
>
> Jen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |vv9 @end|ng |rom cdc@gov  Wed Sep 18 01:02:59 2019
From: |vv9 @end|ng |rom cdc@gov (Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP))
Date: Tue, 17 Sep 2019 23:02:59 +0000
Subject: [R] bi-directional bar chart with a central axis
In-Reply-To: <CAGx1TMB5OYa7nqURa3HYBKOutn6ozQ1tkqKPkJHojwsLQqmYNg@mail.gmail.com>
References: <SN6PR09MB254475046443A8A22F5BD480918F0@SN6PR09MB2544.namprd09.prod.outlook.com>
 <CAGx1TMB5OYa7nqURa3HYBKOutn6ozQ1tkqKPkJHojwsLQqmYNg@mail.gmail.com>
Message-ID: <SN6PR09MB2544BE366B99F2EF4FA5591F918F0@SN6PR09MB2544.namprd09.prod.outlook.com>

Oh, that's a nice option, too.  Thanks!


-----Original Message-----
From: Richard M. Heiberger <rmh at temple.edu> 
Sent: Tuesday, September 17, 2019 6:54 PM
To: Sabatier, Jennifer F. (CDC/DDPHSIS/CGH/DGHP) <fvv9 at cdc.gov>
Cc: r-help at r-project.org
Subject: Re: [R] bi-directional bar chart with a central axis

I would use the likert function in the HH package

> library(HH)
> likert(my.dta)
> as.pyramidLikert(likert(my.dta))
>

See the demo

demo("likert-paper", package="HH", ask=FALSE)

for more complex examples,  including the population pyramid.
We can also get the multiple coloring that your posted example shows.

Rich

On Tue, Sep 17, 2019 at 6:23 PM Sabatier, Jennifer F.
(CDC/DDPHSIS/CGH/DGHP) via R-help <r-help at r-project.org> wrote:
>
> Hi R-help,
>
> I have this data:
>
> my.dta <-data.frame(matrix(c(
> 26.3,   21.4,
> 20.1,   13.4,
> 7.9,    3.9,
> 16.5,   14.6,
> 5.3,    3.6,
> 38.6,   25.6,
> 34.4,   21.6,
> 77.4,   79.5,
> 58.2,   56.1,
> 80.5,   84,
> 37.7,   31.9,
> 19.9,   28.1,
> 6.2,    5.9
> ), nrow=13, ncol=2, byrow=T,
> dimnames=list(c('A',    'B',    'C',    'D',    'E',    'F',    'G',   'H',     'I',    'J',    'K',    'L',    'M'),
> c("Males", "Females"))
> ))
>
> I want to make a graph that looks like this:
>
> https://i1.wp.com/stephanieevergreen.com/wp-content/uploads/2012/11/ba
> cktoback11.jpg?resize=864%2C379&ssl=1
>
> Any help would be highly appreciated!
>
> Best,
>
> Jen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @purd|e@@ @end|ng |rom gm@||@com  Wed Sep 18 01:59:37 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 18 Sep 2019 11:59:37 +1200
Subject: [R] R wrong, Python rigth in calcution
In-Reply-To: <20190918010935.1fa4b880@Tarkus>
References: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>
 <20190918010935.1fa4b880@Tarkus>
Message-ID: <CAB8pepyi1rAG0QWr_eWWm_vKqL5KO5kmeqR1ZWDAUxYFYhM8Gw@mail.gmail.com>

> R by default uses floating-point arithmetic, which
> is subject to problems described in [*].

Yes.

I want to note that both graphics and modern statistics, require
efficient floating point arithmetic.
So, R does what it's designed to do...


From r@oknz @end|ng |rom gm@||@com  Wed Sep 18 08:11:25 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 18 Sep 2019 18:11:25 +1200
Subject: [R] R wrong, Python rigth in calcution
In-Reply-To: <CAB8pepyi1rAG0QWr_eWWm_vKqL5KO5kmeqR1ZWDAUxYFYhM8Gw@mail.gmail.com>
References: <CAGAA5bc621Q_y+CyYnARJ5UYCNQj45qC+-hxxG8iMq636wG6ow@mail.gmail.com>
 <20190918010935.1fa4b880@Tarkus>
 <CAB8pepyi1rAG0QWr_eWWm_vKqL5KO5kmeqR1ZWDAUxYFYhM8Gw@mail.gmail.com>
Message-ID: <CABcYAdKbi285Zs_gJvqq0BNC11uzYiCB4KLi9DfVehzJe4RL7Q@mail.gmail.com>

Here's a tip for the original poster.
> ?numeric
and then follow the link it suggests
> ?double
which says amongst other things
     All R platforms are required to work with values conforming to the
     IEC 60559 (also known as IEEE 754) standard.  This basically works
     with a precision of 53 bits, and represents to that precision a
     range of absolute values from about 2e-308 to 2e+308.
and reminds us that
> .Machine
will give you the parameters of the 'double' type.


On Wed, 18 Sep 2019 at 12:03, Abby Spurdle <spurdle.a at gmail.com> wrote:

> > R by default uses floating-point arithmetic, which
> > is subject to problems described in [*].
>
> Yes.
>
> I want to note that both graphics and modern statistics, require
> efficient floating point arithmetic.
> So, R does what it's designed to do...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Sep 18 11:01:27 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 18 Sep 2019 11:01:27 +0200
Subject: [R] Not the same length
In-Reply-To: <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
Message-ID: <62B8499F-3519-4CFB-8E23-6FBDDB92C5DE@gmail.com>

Um, I think not... The mean of the last 200 observation won't line up with the x and z. 

Possibly, if what you want is the last 200 obs to have a different variance, 

y_obs <- y_model + c(rnorm(0.9 * n, 0, 0.1), rnorm(0.1 * n, 0, 0.5))

or

y_obs <- rnorm(n, y_model, rep(c(0.1, 0.5), c(.9 * n, .1 * n)))

-pd


> On 17 Sep 2019, at 22:27 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On 9/17/19 12:48 PM, varin sacha via R-help wrote:
>> Dear R-helpers,
>> 
>> Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
>> How can I solve the problem ?
>> 
>> Here is the reproducible R code
>> 
>>   #  #  #  #  #  #  #  #  #  #
>> library(mgcv)
>>  library(earth)
>> 
>> n<-2000
>> x<-runif(n, 0, 5)
>>  y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10
>> # y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) # maybe not exactly your goal?
> 
> 
> You didn't lay out any goals for analysis, so let me guess what was intended:
> 
> 
> I suspect that you were hoping to model a mixture composed of 90% from one distribution and 10% from another. If I'm right about that guess then you would instead wat to join the samples from each distribution:
> 
> y_obs<-c( rnorm(n*0.9, y_model, 0.1),  rnorm(n*0.1, y_model, 0.5) )
> 
> -- 
> 
> David
> 
> 
>> gam_model<- gam(y_obs~s(x))
>> mars_model<- earth(y_obs~x)
>> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
>> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
>> MSE_GAM
>> MSE_MARS
>>   #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Wed Sep 18 12:54:44 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Wed, 18 Sep 2019 16:24:44 +0530
Subject: [R] How to use breaks argument in hist() function correctly?
Message-ID: <CA+dpOJ=HyuC-+PruyTJh7ypE7p4bfO5NRKNf=Y3Y+QnQEzeTFg@mail.gmail.com>

Hi,

I have a numerical vector as below

x = c(92958.2014593977, -379826.025677203, 881937.411562002, 25761.5278163719,
-11837.158273897, 48450.8089746788, -415505.62910869, -168462.98512054,
328504.255373387, -298966.051027528, 237133.794811816, -49610.1148173768,
-92459.1170329526, -261611.557495123, -314388.279999876, -432257.362693919,
-1031328.04402229, 79654.3696754137, 107072.114744956, -43384.1420067487,
410881.767122128, 1107540.47690119, -187319.627164858, -363126.966946238,
264885.548330589, -127020.002396109, 150315.10537545, 609502.016523236,
218679.801620448, 901573.599806465, 8289.59210428538, -860908.637977889,
39680.5921457494, -70270.7462533897, 1135442.61429015, 133964.991179536,
1603815.51357657, 2509929.42959337, 193680.587201446, -167020.153065672,
-55258.5415736386, -121185.161514792, -1003115.2769274, 1345368.12703686,
91665.388397883, 137350.320344812, 29866.332965572, 558999.444304371,
523687.666679187, -867194.523170726, -271190.308507375, -423629.796389981,
96407.0505512169, 193397.770743584, -1231855.39144784, 324272.89909045,
-1586859.60653751, 252986.272621096, -1008329.14877038, -24090.2255466315,
159815.745712707, 969037.929787668, -586905.922684562, 573133.370665267,
-285493.361916026, -368392.707593945, -199242.654709143, 151002.480443041,
-678758.615800119, 467477.655111104, -267683.37512503, -1541813.6353232,
-6723.49019530666, 373.233886695949, 59116.2440402955, -1369030.26511923,
1527024.1822942, 63951.299612343, -535128.407281035, 304507.377244809,
141771.552178838, 98963.774668207, 10810.9015935012, 1022008.90830883,
276804.330003406, -304607.247552493, -15767.6578367545, -204454.923166458,
722866.275157944, 137685.886832198, 590201.29119819, 904805.824902981,
-47417.8588758472, 55097.1936075327, 144426.170076371, 1020559.38779514,
-7019.11334737329, 488224.043025845, -28272.5766026849, -295384.449673914,
-93475.8799719289, -367939.725072447, -1244135.36327203, -863835.124327735,
-1399240.55792133, 241146.794430078, -96612.1109580967, -9159.41140641969,
-240291.731366074, -7482.02181888149, 71427.8225121907, -228401.89341468,
948738.649629141, -327368.940001115, -53374.866091836, 126448.573738739,
344962.4459403, 270571.141270723, 746988.197131718, -253220.465177424,
-362652.833437272, -4385.56796251462, -114398.64639441, 454240.63525686,
-1239567.92855698, -389939.987378005, -364083.196493484, 24693.1882238397,
4635.22406457209, 57992.688805147, -67934.5184434773, 123034.937557127,
483909.751375248, -167441.867070132, -382537.019103907, 267584.10264059,
-188944.743935369, -47062.5409102427, -860201.712919788, -203096.090898701,
44317.9727734545, 375924.206160012, 67000.7086638517, 137607.783105903,
-306430.502044082, -669552.84790218, -72629.0354820569, 251145.827045551,
-230557.16727732, -112594.52630222, 74052.4425890159, -105774.458850881,
-241185.430318678, -296663.488112722, 156807.699193046, -520102.742784345,
-56451.5201730288, -23171.0259034268, -107945.719878344, -158480.929620835,
-769507.414580615, -83077.050717928, 477248.698330914, 27706.3803488034,
70485.7144565997, 302213.341425514, -322119.331851626, -476228.406727923,
-99453.524756431, -673693.791106482, 38765.0473434452, 63302.3087165867,
116619.019966859, -167803.424492692, 82982.1864557734, -262627.809345438,
643538.235642472, -90724.2065826313, -435531.286293254, -371820.753318447,
-224713.223837607, -538987.838068522, -195841.454277966, 13924.6120356087,
-415252.7309228, 209424.879456433, 485624.048364534, 74317.8482029741,
19994.939065553, -460452.302259829, -141374.457424938, -77310.8968822459,
56112.3979095014, -150891.122921784, -679395.088755517, -523803.739201696,
-69888.2239139985, -4463.34352237508, -63616.8025699607, 906704.585396864,
1096575.89875834, -382869.397851591, -624324.630106468, -468837.009485095,
-49963.2943695135, 17038.2753380311, 756286.614911188, -995536.510249994,
308899.601761641, -375123.707808525, -113921.428586057, -61573.6957341075,
55239.3511454715, -46731.8391379398, 697843.754042485, 265162.29364751,
1133747.94683337, -355974.319924194, 30699.0482856455, -19680.791041683,
-624454.313911307, 94983.7375389124, 744849.080038272, 172732.610815633,
-120546.157860821, 62579.2205127864, -621204.554941904, 293869.359181081,
-108505.317455271, 646163.583792489, -502636.630380265, 502413.155645464,
-49238.362688755, 108812.985894042, -139113.621347874, 1120034.73283877,
-296008.55142246, -845627.626734492, 116082.364002893, 85096.4224949463,
-84149.6401610159, 611729.398657364, -783642.839894851, -9788.4825023263,
-58734.3009729933, -110950.384570162, -53258.3833170316, -20519.0858192393,
456910.655858686, 48830.1071552214, -358333.95721609, 80046.3518406906,
-224193.119044228, 45897.0722281932, -4895.48804178487, 735710.318540904,
183571.602770915, -103173.288434665, 554285.106452708, 536724.819749035,
-38962.2828892764, 26730.2338615816, -267784.282389664, 659763.691652086,
331635.73797362, -305496.497141735, 337703.432388682, 26793.2725583163,
-214055.61511956, 433283.794587772, 26322.8583007973, 425589.473694935,
760717.980878795, 846383.092695917, -121781.599418283, 22765.984683561,
-596872.133685553, 51016.4424322632, 467025.462325698, -148373.671711807,
-97450.7147576735, 7382.29995650104, -117964.772809025, -341687.304035859,
-64135.4936418714, 925622.18739822, 509465.265446495, 666959.054624484,
101266.034014433, -54356.9278096486, -169574.607400605, -491502.82033228,
-1431395.03624151, -41954.234018976, -91514.0781150778, 36094.5145963667,
-247758.21106228, 386406.544125574, -641366.891879003, 431862.530550072,
-283519.781039346, -176768.699381518, -85100.6040966148, 42919.1786790648,
-573792.209418182, -145083.358546141, -103592.591445374, 319209.00200335,
-370175.637619263, 34696.5118008997, 79583.3105203735, 503595.367049541,
-434262.168819613, -132424.172094326, 630382.147524522, -1330812.5932007,
-7750.462191761, -52914.945661348, -222040.592341358, -415562.175846289,
-71531.5958861226, -456099.947517153, 419065.115234754, 64284.5966914758,
4226.19375637705, 94078.3527038254, 89893.58540033, -607610.417024073,
683856.387361433, -512127.869824724, 11208.9177003014, -101394.077581535,
183026.233407253, -449379.145236669, -115660.001087383, -427573.119007334,
149949.670761132, -30407.0906389678, 43589.1678439909, 849824.902598111,
152884.005705639, -196505.577342962, -500734.692731424, -724491.634413791,
25817.4670523092, -33508.328927694, -207970.139008736, 233644.555631856,
28621.8629536495, 97538.1943793821, -457171.816247728, 19677.4619186778,
45873.6550271451, 66012.2155865722, -176547.315860871, -252790.80957217,
-375137.893142149, 116509.511838958, -27345.0227510922, 169791.737389099,
428414.3658631, -176651.274187717, -376051.900674277, -244132.733506922,
343127.394965013, 6888.21779774424, 24855.7977502716, -146245.224251319,
233807.28504872, 385247.635117681, 398739.686465815, -86857.8501653977,
21314.8285674162, -52351.3519254668, 130547.331367762, 286512.515038983,
-11334.6942366484, 417334.891406081, -236507.700402914, 18979.6967512829,
224208.680482475, 189826.430999614, -7258.57319459158, 480647.58173687,
-920781.096620284, -11715.9303767758, 115138.804482871, 48173.3682232096,
-35953.8062163407, -166496.453697499, 66640.8786572668, -285594.787789923,
-168011.566368402, 59329.1235053135, 278322.35446075, -327158.568212705,
191785.529412968, -3305.56372526809, 82220.2970326393, -57371.8575741457,
29341.7002043565, 401576.094427155, 103000.389358117, 158704.130969137,
-514696.863379762, 22590.8081844391, 34442.031907286, 62017.6376087912,
80386.3513537029, 570827.663317477, 330694.482577645, -163011.12596347,
357264.862382688, -57457.4294474906, 64054.0423064279, -30460.8776071838,
-188482.387265618, -40987.6612274076, -346628.308614365, 219713.48060811,
-12846.3190258391, -186723.019837828, 41894.5779905318, 288502.730124394,
-680756.196621792, 50965.4917067681, 322152.722049961, -37810.7271030323,
118804.015303478, -386601.929404725, 272579.430812827, -502413.434160233,
-719749.806882519, 514899.338261728, -83692.3953531943, 96278.7775390785,
107099.14569242, 63089.5998775806, -400090.250678807, -417651.577893759,
-21815.3476344813, -12499.3359054499, -67383.6387324494, -45190.9746238859,
-547072.030384359, 227028.825648466, 514573.742851474, 13213.6331764028,
36001.4594874159, -113745.611884801, -143365.507627705, 98207.6198896104,
-63701.0617007566, -346627.341147577, -228029.155206697, 32764.801933128,
-102035.876104106, -308868.306952677, -24975.2423467947, -419056.019442505,
169256.186409902, -395262.800231971, 28049.9974599825, -22327.4109009305,
196011.797876105, 8731.27421508938, -94532.8400731803, 182528.705947351,
43904.0479470682, -5155.54753837923, 0.0390195048762285, 335137.943324063,
149892.173794739, -455238.616489036, -470468.157469437, -210957.41457195,
-112399.973854372, 0.0390195048762285, 36751.597937829, -39659.6468497995,
-471901.629267993, -57759.0181146788, 157642.498220902, -76041.4762532663,
-302713.936102669, 200322.226180072, 187185.116242184, 314843.071829449,
103708.528822083, 646825.527145422, 21685.7472169203, -87035.001937924,
-68616.108554161, 0, -255740.780923924, -235035.014691348, -167510.232122243,
80041.4665010063, 37480.0620537293, -708586.902282354, 0, -1056670.22825388,
107964.769490756, -497235.817501127, -35879.0490961091, 106578.767855109,
17307.9650293591, 399799.483613206, -475418.037641737, -269889.151871367,
275749.740226646, 23257.2835354894, -57223.0923813023, -40235.9737272142,
244475.582447499, 211746.43851584, -238737.843477682, 194398.815768936,
-51046.7575107877, -16393.5220745578, 234583.944040839, 245597.268471896,
226491.127910954, 68031.1209177937, 304995.571277675, 27091.6327221229,
23517.759526894, 378297.049138133, -414861.25445413, -3913.80818506534,
-436710.139665648, -220258.814397665, -147063.765148713, -344834.731183853,
-136380.752418312, 100107.560348566, -37335.4974639193, 134800.10180764,
28287.8149560302, -0.0390000000000044, 18400.94597946, 180143.188705458,
-91477.9974889573, 9799.57265117294, 73687.0604853566, 8176.24148451805,
0, -46130.0248887956, 248988.399950314, 587283.929234732, -82405.4103124134,
-528395.397678478, 204266.58524619, -0.0390000000000044, 793816.4036475,
-52837.8228498849, 194674.195214817, -221611.691755024, -337214.779568087,
-84645.076202543, 0, 60602.9519462416, -81278.8675375711, -300423.81924462,
-114660.861700869, -590733.711804247, 21570.4802435367, 0, -279081.673452396,
-86335.9025447065, -128578.335372795, -475461.464378638, 187120.274341227,
70576.2420958521, 0, -287121.178095001, 100685.889807059, -328140.577072372,
-136735.050343852, 453321.059514423, 18884.7222768003, 0, -392425.170680979,
-397462.224555713, -36585.5447158241, 430605.988629104, 52271.7195134694,
-67238.935959769, 0, 475877.728963908, -119504.969001221, 229314.215881955,
-1451584.32057008, -505936.831875351, 132871.504136963, 0, -793387.589474244,
-124403.021388163, -684233.633192161, -204293.975103517, 965570.006101678,
176935.832176459, 0, 2357280.48309751, -736612.228515493, 37098.6281604306,
-29170.2097097916, -459157.840979475, 18708.6684187747, -0.0390000000000044,
241801.043566553, 51431.1806852506, -169141.353565765, -555603.994389542,
610591.810551731, 34416.5313897469, 0, -355902.000913511, 145679.234659847,
605141.667654153, -481457.573700277, -643941.536057472, 7544.70106671585,
0, 47476.4186170675, 655386.536084584, 346964.742597715, -510720.09249525,
141847.077195927, -99458.5376396593, 0, 332955.166201158, 479325.709439097,
-155322.932150271, 433306.402010137, 506967.357251955, -12296.1048235667,
0, -311290.714578155, 399931.56489403, 649193.229013061, 111179.364172584,
820523.690196543, -108964.899802192, 261420.492745567, -309355.784544135,
279294.807952869, 283383.352309925, 821365.674135911, -14492.7515847964,
0, -868349.061846558, 554090.574080701, 820030.598963576, 694138.112813682,
667716.858988038, -69903.8193919229, 0.0390195048762285, -289996.827537312,
1607567.81561339, -382534.263402658, -468703.737020675, 557555.283080131,
225702.351793511, 0, 107619.931491242, 344400.942706433, 285839.268137692,
490004.487833009, -407211.400557737, 6696.23838936677, 0, 54952.2805125559,
-3247.01372716344, -165682.464249165, 27598.2004707502, 66120.3237572016,
41039.132401479, 0, -506189.647986148, 7266.06286180984, 590088.700081297,
-523836.850042262, 329260.521230443, 73748.6019032789, 0, -449959.390520899,
-598151.180103554, 1198121.502617, 13951.2730930629, 466982.452913929,
116271.218524388, 0, -482087.7774194, -409043.287510022, -197708.017945446,
-222502.493632367, -103073.837265574, 7236.96703471105, 0, -119841.125142244,
-336686.522946499, 474532.1557969, -91073.5139604443, 483958.491343141,
30421.838304926, 0, 565878.590184546, 903924.652932578, 468863.87173798,
-14344.2568955454, 543058.322533088, -112725.036156905, 0, -27155.874582832,
137668.137318294, 549407.450186635, -1139876.87403188, -376136.972873135,
-80645.1469371228, 0, -142214.677748352, -335730.066808485, -394729.282986429,
132681.914036489, -384507.62170033, -42567.9743232172, 0, 375289.35541649,
765719.135586415, 473684.134778998, -290433.281148925, -136613.298491729,
23549.9245829994, -4715.92243093635, 856701.826978566, -131964.718076686,
-289257.670203511, 199472.390078666, 20390.4642542883, 0, -1348680.21239986,
-506667.461138505, -639720.568549759, -91678.693358034, -186335.605946278,
3621.35301592202, 0.0390195048762285, -417385.103916983, -724599.902928311,
58904.4119171019, 588947.972724066, 125394.495193281, -56035.87456732,
0, -246496.711828449, -293716.353316494, -552076.935544717, -197951.856072471,
497064.085630282, 103330.602004799, 0, -184082.116179022, 470163.061315822,
370514.13838027, -267576.015412011, 412122.058353276, 6775.14252297303,
0, -197873.308878244, 113176.237913598, 347497.597727335, 81145.0830500092,
-326233.091492163, 40884.8874507538, 0, 119375.194472887, 67420.8460250924,
-169320.752755597, -325727.708077848, -141912.278280032, -57105.023227473,
0, -178405.120845797, -53318.6794726175, -404456.960379784, 27987.0061628747,
-140141.725443231, -7394.49906328211, 0, -63724.0232221751, -200709.865764158,
1171064.63104159, 323473.274218214, 379917.317688412, -25564.0830692365,
0, -21460.0208135243, 344441.632986099, -281434.813456558, -364179.107329069,
-208035.462499754, -54762.5273708044, 0, -263850.635531756, -27670.8590434237,
-233188.595718569, 506981.609135572, -91173.4496068811, 42793.2374512536,
0, 256681.239879202, 361367.08185984, -64360.3495686117, -382109.073016999,
-430583.663711505, 18937.5159713557, 0, 96659.9492273728, -219928.070181746,
261414.839820517, 409609.401529891, 320549.126738313, -24856.3413476205,
0, -14194.5048765915, 324807.471132209, 62983.7542986701, -218680.864671832,
-113790.8610279, 17826.2568067902, 0, -245288.192575869, 153844.224967531,
635914.035219256, 297690.807936566, -688477.427322861, -63902.4325038975,
0, -245744.84616234, -160917.204894242, 805012.825548535, 375489.315050971,
-314814.677099653, -57367.2532666434, 0, 265519.914650158, 471187.373528659,
-277622.81963841, -73079.6944552284, -221982.274439438, -32095.5978354649,
0, -129088.574636866, -28626.3310864481, 0, 44651.0981074855,
195425.73129076, 24354.2093473602, -0.0390000000000044, -311226.106783226,
-258656.047379568, 0, 204418.449251498, -638466.556829467, -54684.2659188848,
0, 381952.63157765, 490414.836411988, -43143.1180128762, 240039.320254774,
-69376.6922024121, -49863.6875365029, 0, -70456.61333261, 303993.181383124,
60764.0999749857, 494444.543919188, 155062.304782859, -70273.0125213102,
16756.7259283977, -100734.775911482, -78399.7891902767, 1384874.02031502,
664971.689670853, 103679.885107961, 0, -500351.85697082, -178458.863042291,
469894.593563622, -438267.814871562, 264490.01664722, 37434.884061936,
0, 510298.492480026, -1531363.22232399, 286998.361857664, -471071.595716128,
-28469.7290622593, -59480.2196713628, 0, 318996.345592816, -950369.508297324,
-267186.576333817, 409935.316511621, -256790.336665586, 3768.59867396145,
0, -88154.4872307698, 56743.5568939772, 545943.838133454, -103394.959982909,
194681.810437213, -37258.2219661424, 0, -458446.075900654, 325620.884072826,
261605.263613712, 117332.339196911, 326785.580617146, -27474.9802647599,
0, 182387.219083191, -438811.292364903, -479085.324629612, -724206.450544344,
442047.05657424, 50026.1556862607, -0.0390000000000044, 392283.750621281,
318511.691037823, 114911.641359255, -86219.5099008976, 314157.097232884,
-51245.2715103605, 0.0390195048762285, -468468.103718263, 352660.253719016,
89438.1740701936, 60337.5015826219, -165098.200498873, -364.82151558145,
0.0390195048762285, -129189.008592897, -461434.450223194, -595834.622962502,
-732170.026919363, -164666.310247213, -10134.0079690374, 0, -284286.278619152,
36800.2922751199, -2067.76534540687, -6827.23835745471, -354095.310949415,
-59229.009833746, 0, 178764.504196656, -8577.1131527567, -228628.724902249,
229371.721602191, 116379.933564907, 27284.3286512687, 0.0390195048762285,
-397078.939186381, 553331.765577148, -182918.365710518, 211409.606038653,
10122.3565684361, -10767.0430259766, -0.0390000000000044, -50613.0926555352,
-191947.879515343, 526883.050771712, 209124.740735993, 6075.32683394427,
-53200.1826924931, -0.0390000000000044, -13996.5887328365, -444554.001248481,
197201.507524214, -7647.22292103213, -952.029475301654, -22086.0551896758,
0, -16820.0741479584, -468582.143440083, 208541.502008877, -400597.301023835,
59324.4233350213, -7929.04185090297, -0.0390000000000044, -139292.889393244,
-169016.134069063, -18680.2056164774, 266669.794145764, -69078.4502983131,
24890.7444795467, 0, 325611.510493075, 450773.082412255, 12053.4490497745,
-229093.838488447, -166211.181005526, -16397.4374617285, 0.0390195048762285,
7913.48259131119, 29643.5823814949, 174732.463296739, -283501.825602436,
54467.2479291425, 25651.8672942784, 0, 99861.0407173691, 24597.1430291968,
-153723.888870958, -214972.105293131, -37977.1333374684, -828.677284068771,
-0.0390000000000044, -250843.732615281, -168007.270931716, -109547.087501819,
-276526.00897838, -249631.83234376, -11442.0501632789, -0.0390000000000044,
162026.244314854, 209166.297494434, -244217.557267604, -167948.948699892,
-155712.494877031, 892.942504226637, 0.0390195048762285, -148218.492978137,
279268.228297628, -88459.5084252129, -246269.740482312, 126616.334219898,
-21744.0187541791, 0, 110799.165227452, -550371.333161807, 136335.402087683,
71081.6034787078, 4938.0891590437, -22522.6704171085, 200988.774527789,
-36164.4363160187, -119133.463400691, 63724.3423417965, 247338.330137732,
13416.1911553306, -3975.15765463608, 24612.9347125312, -82679.0308733731,
346781.753785694, -172319.120485387, 975.916771472377, 55887.1242471693,
-224144.457882754, -369046.070767925, 334740.224468953, 133339.205879309,
-9879.21926455217, 0.0390195048762285, -97117.0811281616, 196007.779334733,
54090.9431562634, 69677.5220610845, 254721.40261747, -19014.727877809,
-0.0390000000000044, -125884.021820622, 177173.475776283, -110984.337066046,
348288.512602021, 374850.347749425, 42490.6609861627, 0, -303453.636890066,
-78540.1630422476, -109022.038218275, -209148.388401315, 164979.555202176,
53516.970980741, 0, -255421.211339204, 158889.893715836, -285174.368259312,
-136898.885703143, -232569.155323701, -21783.3735107945, 0, 43342.5491827807,
-154645.108353499, -389626.981458598, -42563.8093041327, -106299.33773613,
-22404.5314915718, -105333.763605645, 300984.234225055, -230394.797475435,
-724485.590183983, -93442.9536058113, 8008.69598736465, 0, 461003.519176015,
482550.055486119, -326020.941089073, 702101.809998014, 326097.586101123,
63090.7669156126, 0, -94245.5232805013, -513902.085233714, 144574.493307756,
-500942.567513754, 134575.134002212, 23069.7062731782, 0, 482136.544823212,
270587.675513015, -377413.791127105, 811826.941393858, -47221.0087850639,
15594.37123049, 0, 322076.846635732, -367752.234477249, 270052.208032134,
21238.7110611406, 306179.058384112, 5501.67700253881, 0, -199745.111132869,
102410.049420472, -231757.619556354, 363356.411238454, 490736.657209141,
7878.63269968232, 0, -153913.032939484, 649320.769741573, -42996.7332100079,
82616.6774567946, -266584.628866147, 104610.931820876, 0.0390195048762285,
-193459.245050452, -190871.019338125, -186376.651912743, -82765.3087592242,
-213975.992967376, -6377.17451707479, 0, 187666.358166527, -561576.02357565,
22594.0600497778, -366366.9035905, -1028127.55973093, -25251.6891540467,
0.0390195048762285, 102836.426176511, -7198.45013860136, 291372.089810479,
-126878.973614494, -263928.271891768, -16167.9249036157, 0, 43644.9079520843,
-762625.070775256, -291948.325270492, 300382.307094392, -654486.812680507,
85384.2563936351, 0, -88736.2740542908, -7868.27988055637, 331808.92178929,
-263922.629988663, -773166.942477735, -59280.5434536302, 0, 470080.031265531,
486165.176295504, -135376.607004037, 214413.621877114, 276943.865088675,
15154.5671318414, 0, -324390.339689125, 75908.9347830929, -230733.589847692,
318380.508851761, -293973.004230226, -17744.1202589633, -0.0390000000000044,
618118.195737977, 353650.190465144, 445880.907932169, -171424.375995123,
452986.404625022, 3036.20663408337, -0.0390000000000044, 1062561.51711357,
472665.603634668, -499167.315444823, -734996.01564479, -124448.543634461,
-5622.5049684512, -0.0390000000000044, 129902.977464334, -132064.901061959,
64282.1888055519, 0.0390195048762285, -201292.155945282, 9220.44509517555,
-0.0390000000000044, -316730.459314209, -20525.8209706341, -29004.9136901343,
-0.0390000000000044, 458478.030026522, 81586.312211733, 0.0390195048762285,
-134678.932605067, 283327.333978638, -210417.60656906, -487545.943339705,
-6525.92608752091, 11637.2851498163, -0.0390000000000044, 507347.757363322,
-137485.646842542, 188088.643186468, -4066174.86810666, -1032514.36828399,
108847.494817068, 0, 791860.691479671, -213715.673400183, 1324024.59560125,
-403824.442965452, 184073.341745611, 40189.0193028279, -0.0390000000000044,
525915.100546247, 363464.041498222, 407152.099435168, 1675540.59889003,
205226.292147749, 105076.953485897, 0.0390195048762285, -50719.6873005749,
97414.7687655811, -55148.4661419116, -200482.857304442, -567832.901733926,
-103131.287856226, -0.0390000000000044, -91327.2170262781, 114777.356449262,
136685.502532627, 478369.854418218, -312221.214521486, -65682.7358225499,
0, -155685.018515712, -199177.992439029, 183582.505261238, 270243.660730011,
-348929.235653529, -29959.7831838142, 0.0390195048762285, 276904.158681192,
-269485.926642612, -601662.212540186, -89287.7668366619, -430690.278857094,
98098.9275916149, 0.0390195048762285, 415270.357252486, -227487.885836433,
-576858.75255965, 439587.397043779, -72211.1985931339, -28788.6984269492,
0, -92930.2202137985, 285985.534713615, -220337.989378342, -731754.196659329,
64321.4834251423, 398.507611679556, 0, 294780.534475733, 374365.042256007,
-558298.515305844, 407981.132828032, -736027.314215928, -78490.3828092808,
0.0390195048762285, -298005.118557684, -106242.616214473, 687576.113166217,
-153599.516112101, 597063.995316294, 79955.7069117654, -0.0390000000000044,
417223.378114183, -234311.884085523, 45420.478744352, 455696.517435112,
-178841.355310611, -7723.15381229715, -0.0390000000000044, 157122.192247785,
-717537.57730847, -546663.259457788, -310158.230583305, 59550.2168797106,
26986.1848368087, 0, 522613.850141923, -44463.0508627074, -682207.635711803,
-835300.948255266, 372788.341495282, -41657.2637488423, -0.0390000000000044,
122292.947786914, -118958.410291773, -369117.10849454, 257617.081846177,
139189.999264687, 36769.8126361053, -0.0390000000000044, -628290.565787727,
-795462.277111254, 307554.710478614, 1222030.97032663, 713318.042087609,
-148050.282804399, -0.0390000000000044, -350653.544079332, -487640.412937263,
469123.421791911, 272852.164609701, -681621.328104045, -111583.910184976,
0, 104433.71370186, -549849.094817313, -415717.906590806, 270365.318151125,
491323.094061352, 48267.5150970486, 0.0390195048762285, 50941.1516350525,
-105313.870260356, -360210.768298464, 37972.9724577314, 223071.459277248,
-138578.684019058, 0.0390195048762285, 16667.0850315625, -1669.16189955389,
37848.3245482788, 654232.069173093, 368974.134608878, 53137.7481215514,
-0.0390000000000044, 114464.50233507, -319760.954652096, 781198.484217955,
415164.949987879, -502333.7897317, -22553.1590751249, 0, 386330.628388539,
-23721.549329344, 81378.7622165195, -259140.693344057, 78297.70303,
87282.4860704868, 0.0390195048762285, -187840.319924304, -22053.3003726119,
-119276.616359917, 144946.482922327, 95128.2730634099, 27666.4542034838,
0.0390195048762285, 251488.895173803, -686390.138017146, 378546.812585061,
-343495.830300434, 312219.316046833, -221.597840918512, -0.0390000000000044,
656398.65888048, -104505.417992213, 221827.186101971, 124603.740939192,
861578.563072788, 123233.451394075, 0, 101288.914873362, 710330.245672313,
1183955.15261785, -840912.625983386, -319869.039173635, -5827.29298255884,
0.0390195048762285, -400801.686099512, -346904.747562644, 655993.220304874,
-245261.429002587, 60810.564460045, -26428.0552726151, 0, 71072.5173626143,
72920.3820474423, 342379.56159339, 708062.831368821, 427376.263206645,
83101.0587192262, 0, 783243.765998376, -1045940.27133011, -161145.6997207,
38875.8523667146, 270726.01431664, 102134.16340864, -0.0390000000000044,
261944.011067293, -862163.329543587, 59725.151710014, 45560.3381891341,
-57530.6681616876, -55269.0722628376, -0.0390000000000044, -220247.194423249,
967197.291432708, -150808.552542964, 174688.085752766, -48480.7657346432,
-2885.75309799535, -0.0390000000000044, -80730.368759679, -117398.315603203,
372363.75096326, 363040.426534184, 1177140.78031658, 251690.422391106,
0, 3452034.51229956, -111279.447878959, -250704.812274433, -1075177.17075252,
-467878.610319999, -129913.531648512, 0, 1052537.36076061, 1526377.28885803,
-336613.763046696, -356409.512909958, 1498462.73472141, 124128.70690916,
0, -99575.5897118994, -1162490.27167616, -241305.451553955, 71591.8150772758,
221753.151731608, -30099.1143091218, 0, -244914.522201468, -259804.057466302,
-728131.832421127, 900519.951448378, -799657.832193851, 130885.968287402,
0, -52167.5826851328, 504409.295616509, 1300424.78441576, -294083.206467293,
-267339.570018078, -4632.81662741184, 0, 853884.997617557, 163161.67879033,
-743140.431865549, -39159.8940514744, -596432.894381403, -489.948496348417,
0, -771818.9086432, -396566.474718801, -488522.007986759, -322519.123590265,
-439887.412813621, -18237.2823504247, 0, 15199.3450380726, 882656.909735028,
-368017.956183111, -904459.58632761, 347878.022271072, 6452.05506304858,
0, 293611.867597225, -167774.943346338, 729100.134009611, -1423758.76528479,
-344674.334080768, -1700.67067612087, 0, 124186.14258285, 880257.818248461,
61639.3820561054, 418551.231996187, -611728.150232683, -1830.12407979669,
0, 138956.331043692, -621189.175051699, 19400.493016211, 239811.323639335,
165654.164272122, 54960.1691360546, 0, -146012.213624507, -32733.0108983296,
-165338.010192922, -74594.0327656692, -251793.146237776, 82721.7343098886,
0, -185792.406535621, -423825.596523159, 266755.32200355, -254492.256207949,
-432438.64408513, 43009.8885527976, 0, 441189.327867746, -241587.926893129,
-359529.428794775, 240657.112557487, 516516.479291287, 32464.8678235453,
0, -757165.456461308, -334118.1302625, -32930.6043895907, 966157.172059503,
-499098.214684272, 13143.9971756606, 0, 826059.214436754, 856169.136393278,
570475.860833162, -464302.75891756, 1176459.09868583, -34989.640743276,
0, -164604.635403118, -100847.709530831, -437251.413671235, 552181.889986011,
125395.318835901, 123338.539623345, -0.0390000000000044, 135769.58533786,
-46821.3749309707, -298190.017078578, 117163.532003545, 0, 0,
0, 212983.103161801, -512896.44930345, 110332.807183794, -7563.97155784612,
-29014.0300137318, -49913.7675000671, -0.448868514791554, 1184145.4239976,
138459.337025028, 1263533.27581096, 1132594.0107997, 526802.293143484,
363848.045040318, 1.94058822106601, -650995.606259771, 365926.36156573,
303877.463780822, 3240.86248437041, 1940027.9862433, -41834.4613627808,
-3.85750830246918, -129434.25294958, -549367.101422798, 153734.04390567,
-1532692.23859055, -907202.308577724, 36152.3303085305, -0.830043272607144,
874559.931471143, -909342.209398651, 274927.122811488, -322330.997960151,
-1225939.91194111, -148676.548488952, -0.55355151820784, -311873.568866687,
1136174.73212114, -65119.8291033855, 362411.541557494, 763002.686766724,
110331.936503987, -0.347524004821157, 404885.093463446, 469476.422170561,
313813.416556882, 560749.817677653, -482245.399092919, -22080.7667821803,
0.835799038747631, -934461.214224207, 925414.553189891, -768238.344313897,
257357.620407682, 411203.512338195, -16047.1119363399, -3.30605907506658,
-864897.380730838, 537834.100597385, 98857.9530721416, -782088.90065692,
151951.765147568, -50732.0681977504, 1.85112380819457, 214021.321066593,
-1087884.5620327, -642567.744215527, -480452.954694592, -729880.104057032,
-4561.75441494796, 0.0788207126405996, 77896.0501971397, 926669.316281905,
-760333.22583231, 1122798.35162061, -1577919.78217232, -104841.767397575,
-0.52613609596393, 479705.189648157, 1156562.87327825, -810077.555094365,
-514668.80072939, 272475.525788962, -104739.171337302, 0.0704638630190552,
272793.544758114, -454103.551765905, 1046258.09095604, -160475.573193086,
143313.137864412, -19532.8153702827, -0.17159959749412, -704111.198808967,
-583369.676722747, -261762.912509876, 214671.581263792, 701382.248548697,
-39015.1387433404, -0.466511480649595, 771644.489143001, 1144447.36113538,
-76104.1049544494, 1179625.84027416, -493457.755158948, 3662.29446110004,
-0.780327189379466, -665518.250494947, -1277109.60515789, -421802.980409576,
-49044.1107723257, 119183.696821751, -114908.269872012, -7.63781985743387,
-309855.694120185, -1267118.11507658, -53197.2770593066, 702853.626375132,
-1168593.8278627, -38476.7218322247, 1.88075263239151, 360464.948709667,
-451776.547235346, 1073075.3780936, 878076.697374264, 1142329.40187676,
39828.9071618289, -1.56895829642405, -137085.198896086, 1655828.7128598,
480036.273931022, -415825.838988577, 937240.657510177, 22078.5565934129,
1.1696494397288, 13905.2045966725, -804549.764439301, 176377.776818163,
-165268.192774081, 635485.16611632, 32058.5790051319, -1.79834286491877,
-199056.785347188, -447034.904903806, 99435.0019958235, 292687.045144768,
106584.533214753, 23733.5038078122, 0.757312520979568, 441172.357845112,
-420714.346543101, -616213.652808971, 170503.46410341, -17285.0899043416,
31073.5409085332, 0.109608364871736, -192510.512458429, -25514.12446222,
473078.83536466, 416119.183626047, 38688.9203188218, 82493.9220142876,
1.40870473922256, -805507.019492379, -800270.191361448, -150048.977812476,
-336246.574492321, 679675.603974693, -15900.9078747745, -0.0498329105301624,
509127.762199126, 89823.9910008119, -69374.9994898348, 1031944.86141822,
-450564.422942861, 72433.4178653258, -1.67787578479119, -782793.183224089,
-666576.022709582, -52579.4545225305, -1328217.26007806, 3391430.15019308,
-36899.9331782318, 3.89768264518407, 1286110.28210833, -473793.390371595,
-588683.728983871, -579711.484899109, 163067.181334192, 1507.1828149074,
0.961916623513784, -518059.38296519, 1466398.243878, 38548.6631919937,
316263.518582104, -457252.596415167, -150056.335192077, 0.503066450577447,
-587556.061242795, -1945082.27838089, 430104.991515802, -874045.841625823,
375669.422348837, 379826.033627652, 4.55961468032831, -722643.598413397,
949791.409255599, -125000.578329553, 414507.858983872, 81301.1698030928,
-41421.422905525, 0.23443541378806, 349634.39817374, 206159.389364886,
-171688.180816275, -259556.795715628, 776619.021780188, -38586.0587540062,
0.174530359404762, 458890.950079616, 87351.621206337, -109747.080354324,
-203433.933672753, 258447.49386935, 8295.09347273768, -0.765779504004323,
-443923.908338955, 175596.601790444, 3532.93226268073, -458553.849786203,
857145.327024336, -58700.8479085652, -0.0599806806534759, -48202.0818092764,
203910.743215457, 440819.413843871, -304405.383609747, 675285.81966806,
-10819.2211474697, -0.304587743070636, 51239.0839633315, -116881.84096912,
-242094.703108759, 62174.1958571357, -196972.263265054, -23010.9710813549,
2.25551907887176, -96087.6275527137, 23403.8458501194, -353063.809422422,
-309849.845908518, -1013972.33087027, -10664.0739743922, 0.723252247684872,
-47568.7352909489, -193441.024022429, 424143.196856536, 206497.257273117,
645548.442607811, 84524.9944347116, 0.243749233254403, 194743.170900073,
778430.625198823, -1327.36638776853, -234237.323194264, 252813.861524462,
12825.0878367661, -1.14235982563736, -142715.484418077, -186782.088701177,
-146716.144885514, -240422.280650495, 614661.039189968, -39455.2389521195,
-0.665549666337014, 588214.225622685, -496587.124221711, -331273.292465428,
258367.905125984, -178768.113125402, 34222.6967088589, -0.488808822931229,
-91051.9097490469, 328042.470410259, -304969.320008644, 153809.950647346,
1016290.69044115, 36545.9736877277, 7.63438378157161, -770376.781276765,
802118.223828555, -827212.457391376, 184475.616173862, -842909.544036342,
-85939.3145287338, 0.139858236212178, 131150.339179262, -624564.259803266,
-149890.186735877, 399494.626730305, 349040.516977361, -9078.97029663942,
-0.97657879690758, -25521.6516332705, -289329.487466754, 1794.06608685441,
109857.794802284, 346019.248150712, 55529.1120299645, -2.13067551335629,
-270932.363618753, 162563.035012237, 165202.580758492, -269070.494007096,
68950.6504011439, -64655.2289513167, 12.3436907575666, -1054332.9029259,
-808330.238738194, 103323.40007864, 125969.527483452, 593112.426890825,
45974.7084115449, 5.99361060040172, -995688.54510629, -487233.681260215,
433101.52423077, -28952.8107155296, 129175.123983006, -28488.1441111609,
-2.32446750475319, -530459.445527634, -23739.9346532509, -645443.149724427,
-460433.055433532, -84154.6877063064, -68539.469104535, -1.02239141732126,
100813.710192657, -169139.241159384, -255826.195076693, -155437.261304867,
-349627.317701097, -8857.09896792944, 1.170115692395, 227746.530059119,
-153554.955200597, -21897.768826222, -608042.622759881, -599230.834299122,
-4947.12603797521, 3.23194699890041, -54544.5118677688, -100801.791300864,
-118777.161601057, 85644.5004302306, 593987.190195945, -16084.8718472366,
0.918950981353822, 808065.485314525, -387127.67153309, 343057.433999068,
610188.5085837, 547920.514662969, 22905.9189232694, 0.212471440013776,
-0.334820771670364, -9760.51226854886, -292060.108058866, 149711.804094227,
-215821.943770995, 52131.0082331534, -0.679856982819708, 4.37195571870305,
-766471.732643893, -311932.043446921, 429258.244478974, -241019.267806738,
63030.3342000214, -0.491397944332623, 248791.216195691, -25250.7149076552,
-492835.022580452, 37158.6473094208, -82329.0952911061, 30381.5566372352,
-1.42353263501367, 558276.408256123, -530683.929772509, 43164.8635077819,
-395344.71954871, 349402.89815207, -87894.7012437207, -0.698357701114884,
238877.485624055, -569778.531092712, -37770.725580281, -439002.274228942,
-228851.187503489, 61436.4600006672, -0.377220838298103, 405826.945073561,
103066.431143013, -148174.746760546, -210967.080999126, 139829.593309277,
60691.5242889719, -1.45477020729827, 378364.303258737, -251465.43915257,
73637.8143261174, -337754.38857644, -512842.837136735, 40178.5389352309,
1.62467227479468, -187314.341002131, -305105.877598533, -230147.387449364,
761932.892745528, 240815.540741457, 111925.54147767, 1.2347125443046,
-321635.58695427, -290272.867252394, 94229.1814062621, -113320.112905531,
527458.506965894, -15811.0950218225, 0.957160771645822, 174768.871765807,
398027.0089539, -380835.548706458, 543637.970470723, 519470.857674187,
-67341.9491465138, 1.31383604142993, 261175.437555478, -1545.24479741293,
354118.176758968, 169144.196496997, 180760.874826798, -18549.2664258269,
60669.3190437187, -590654.127242372, 93548.7725053475, -695288.389108197,
522686.438703242, -214824.460306086, -26114.4656333086, -0.229562788159544,
-173262.83592552, 709637.643234735, 79505.7742829168, 296949.209344625,
-1986.43711949308, -1601.38915045831, -4.85772066596214, 373234.469380759,
-140382.601833601, -439486.846151822, -549662.736272065, 47430.5250751876,
-26399.7755399897, -0.686169433064969, 715501.757167393, 400259.057196214,
13346.0146380121, 26718.7626107054, 126445.32194971, 33638.7594523421,
0.813547635988178, -105683.110335082, 435965.430332249, 95403.8910628198,
-481050.846294631, 64153.6566738995, 33043.7624899443, -0.233028368125731,
-90886.1678643211, 484335.338546848, 437403.768217222, -379688.383507617,
-40769.4085559782, 36692.4878439563, -8596.16048702984, 470296.442190532,
124439.488143896, 373685.524496639, -158786.621594549, -105247.453338068,
-4126.28884894295, -1.47112147691444, -209597.787638488, -97291.3823946401,
452569.865394461, 660125.623198972, -445349.422184596, -72945.9971565026,
-1.67594269703528, 15699.9042449935, -90757.8436348567, -543251.945342915,
259298.835795079, 357993.286041491, 10500.6351800535, 0.849006996940302,
-356638.709054055, 430469.769238303, 988943.898152086, -118891.608157918,
-186565.855273002, -13674.9756615686, -0.451710670723791, -47872.0424773118,
-389116.178406173, -187131.931544438, 249747.213125397, 189116.297037467,
8454.44872690222, 1.47075940254537, 46817.2680409656, 90661.0830671839,
398325.610160954, 117155.035657961, -8711.36390834203, -51543.7886710254,
-1.96159580044462, -418745.171702333, 214379.173492304, -387702.417997556,
-313114.224353174, 170618.164035238, -49770.7369261911, -1.39382879596211,
78955.7929677602, -317513.490571421, -213205.842556053, -584900.413071782,
-199145.497920399, -10504.3847755026, -1.8870508069577, -169974.855111851,
275371.331769416, 343218.411588482, -250146.154012138, -22421.0334962054,
-3757.75604240176, -0.184115213415397, -435712.81857957, 193583.408269913,
-608129.009687867, -41519.2388064597, -369523.048108753, 14024.856298694,
0.598791675498988, -92480.2561059163, 253238.446427851, 93636.5304617214,
355684.755882405, -379472.803965865, -75420.3629707051, 0.633804830139507,
-37723.8986497204, 397022.488565321, -752575.674747607, -492066.087379648,
-448223.623970308, -11157.5740266794, -0.44791905923326, 284247.068283859,
-356611.936623746, -322276.644180769, 443885.764563407, 414857.392688213,
-39307.2104301387, 0.154987283899936, -190531.01954913, -171209.508930312,
-15264.8753869927, 466276.930003453, 193999.520555962, -63783.8757522016,
-0.324211123080758, 575690.585433969, 140757.68748233, 356058.195352473,
573739.218395347, -203113.259169499, -21197.1662909565, -0.101051316159451,
365804.489718196, -60121.4723270389, 154575.306892957, 499421.063555352,
626.570916012138, -46002.0565745076, -0.302928342564448, 212803.761542056,
-50474.1827634641, -983505.540875834, 390340.095407959, -117225.626099831,
15486.221300223, 3.36208571360414, 120353.368518598, -43922.0506901111,
535025.644342653, -325500.549220098, 15215.4012872553, 11369.1866617949,
-2.6733510390521, -62746.1247628681, -41217.3676101551, 97337.5478447712,
-437022.614333498, -587088.867203041, 8663.80087396323, -2.81930705460169,
544084.350552567, -194665.658437026, -474303.90251148, 47089.2189303614,
52044.708094571, 59114.4914864782, 1.97175853692898, -702873.214187209,
-192594.894741777, -44756.175774177, -115395.48054871, -416289.961599669,
19243.1784288124, -0.34401384803914, 497046.927831415, -254602.093815812,
-600285.747340646, 661167.899836084, 73615.4503674458, 49462.8334854496,
2.65197027381195, 74010.9410777649, -120281.028654509, 199602.933369611,
84939.4201310658, 390794.545297178, 43123.7839036421, 2.76123903271996,
-39393.858821654, -25215.3072503919, -87695.8424332909, 681595.032473105,
336558.096481148, -86652.0357470236, -1.69505178520407, 239294.631233719,
-2551.02350250426, -45867.4197825044, -405843.981957054, -433510.952973442,
-3886.64560189383, -0.585438919126716, 213247.45043155, 121737.950401034,
-207778.819322602, 402946.475669372, 197819.724211416, 31511.8135341855,
-0.287290613288253, -44304.1792546737, 417419.543310009, 864531.053610092,
-120100.437211121, -220528.3221337, -29452.3859885195, -0.278893637011173,
214253.945191957, 213796.623376107, -550540.216200165, -12116.0818141295,
169851.161824274, -4912.83310938924, -1147.01328636259, -533817.948590498,
355010.089900658, -246329.189176917, 136684.012181338, 164689.160754399,
44734.962462357, 0.687617438086121, 418249.634705275, 586852.908494586,
500221.914440418, -125828.056738882, 569051.292493796, -11359.4357959364,
0.734040693755395, -157953.050498003, -194144.846435625, 159611.290482169,
222634.637028813, 283723.289220194, 25672.7465048742, 616.019030782489,
138567.790130216, -205141.780611072, 94173.8697132266, 182291.359598616,
-687694.022494064, -87850.8496682753, 0.571112834965966, 39166.5292247086,
-250652.355065713, 663169.626446704, 110896.80785048, -95561.245801989,
-21264.8403690933, -0.245911613253347, -160297.292762285, -265314.252381569,
-164241.562618595, -332906.33143816, 363165.094282941, -34670.5039814225,
1.84836474590221, -258969.118747497, 188832.554912581, -74400.7810299972,
-384886.715592592, -252004.427661765, 18718.0958141181, 0.846501982374679,
-669.150366401549, -136164.90261595, -472551.411708157, -201210.382601339,
124752.284807634, -19570.715109723, -0.253193856171099, 0.866911841107836,
-112174.091638734, 3283.36484285798, -225581.252008734, -564407.157766663,
52909.0103524324, -0.604538669390019, -115259.246052021, 448932.910474423,
650025.966491053, -63333.6426010272, 149470.590572872, 18334.3931332014,
-0.439506387526617, -1392.97072737573, 21697.850585154, -758959.655826269,
-35195.9038952245, 411273.34432515, -21223.0559373178, -3.4962274663365,
-342035.682929145, 297815.338110005, -291405.382610352, 494012.260732564,
-379403.248459113, 74474.2166145356, -1.06574977239644, 29880.8653746963,
-4886.94303533196, -210182.547081464, 301734.388528379, 854343.102866212,
-3892.14856155674, 1.40382016401682, 549056.242096429, -112364.138373,
380088.065337126, 291488.552332436, 73409.2123056685, -61879.0997852081,
-0.639435974964493, 103714.929539531, 414848.27648521, -157120.797096035,
280867.257163763, 45611.2167994122, -18249.1645848915, -0.250996861963904,
2324.87429633775, -105434.284511345, 182777.421313059, 334637.845829162,
-50402.7063731416, -119361.38156966, -0.579710376215114, 161987.895191185,
204871.858689241, 664204.960689558, 343864.366976734, 635610.743832244,
-96019.9943959462, -2.78287058858445, 223940.060616283, -444043.884606283,
140005.348418627, -75703.6422567518, -751227.936101957, -9148.93310907192,
-0.636451359133324, 29397.4816700069, 398324.361100115, -209175.704801674,
633488.215141836, 787687.908089592, 29440.5821588683, -0.2500585252221,
-143097.326781838, -114797.902963819, -581275.100059571, 516574.930898529,
248463.568208775, 104543.070694524, 1.60091782864983, -368902.419202698,
239964.045493573, -557410.990294082, 43874.7209892128, 113868.312746422,
29758.6499198484, 1.0416798519871, 12152.6162887028, -709808.708200817,
-212157.837637936, -86584.9333134385, 119268.776408179, 19816.7907387121,
-0.222235264868781, -118999.800943694, -661846.024792731, 148453.236205698,
-198255.818362457, -91065.7742200357, 44728.1197292919, -0.298488088236409,
14874.4853767394, 287064.835578629, 104226.974571131, 426608.364609386,
384112.161964605, 34940.8071400329, 1.97807462459604, 54674.5979877085,
-132282.644530739, 20791.899124619, 34937.6368832572, 62061.9180091976,
16467.2368391754, -0.558064415894874, 97208.4729903377, 58498.6102185582,
-167167.894618437, 163434.083945409, 123365.958767946, -38494.8990481168,
0.0632364670855726, 129932.58693482, 238101.40155474, -501113.58015545,
-186079.725861603, 90512.7002652543, 7247.80173566601, 0.208906244779166,
49504.5959298972, -37598.5102920599, -659742.898701273, -170275.33873514,
-14381.7185175271, 7220.39522287804, 0.733060615008382, -569150.496856227,
-41199.9835920449, 261456.508431599, 358701.056972404, 39309.0269982611,
-77080.6525971282, -3.21959372557366, -102702.569884871, 294953.356154138,
-395338.955391595, 360737.675339021, -533562.044426142, 30059.0355589319,
0, -485377.057439916, 289124.797013418, -308270.650867299, 602841.843639431,
63713.9856345581, -64172.9824101041, 0.0390195048762285, -18072.1220569555,
97716.9642924921, 76572.2212415675, 2470.42475020646, 739410.791023085,
-26974.7177125456, 0, 380044.560690408, 724952.450009499, 57233.6474051622,
28038.419392239, -231816.655477011, -48805.2591175288, -0.0390000000000044,
554212.528373654, -41661.4315296956, 374918.309394534, -176137.4007854,
-406985.921717131, -42967.5570292135, 0, 650009.68098304, -401007.429049733,
21321.9766216372, 3108.33735649223, -115169.378554176, -39331.9311741647,
0, -181130.407195509, -210538.633915801, 440086.385271864, -460251.352236625,
74788.192922612, -39089.894058956, 0, -12512.8511791581, 49660.527994718,
-152827.582343717, 907083.182236652, -427230.37019585, 138171.436371292,
0, 230190.97756307, -303429.008860114, -312469.012792172, 322036.171845101,
-160683.325202816, -5804.64242044523, 0, -50270.3734076749, -542714.085461664,
258853.131646172, 315000.533698754, -215877.037004863, 6129.20169442105,
0, 224174.054861113, 22932.8469025961, 72466.3591182846, 299865.152513392,
620596.557035012, 30528.6666351762, 0, 432885.944264468, -569968.398601476,
434193.477117182, -70516.1709908492, -157657.902256126, 46282.9497806456,
0, 69817.9090433985, -201907.970463657, 12646.0315448356, 611276.259602801,
-362904.402464875, -50091.1292814856, 0, -21465.1392525689, 120298.172027106,
-275538.756366311, 752870.199661686, 377855.811785498, -59957.4006903867,
0, 242581.966390384, 360285.31857188, -55460.2003679164, -19768.2776583378,
342086.483182684, -48314.1629683354, -0.0390000000000044, 75758.008094813,
-232986.580427601, -558831.983886635, -379130.767186877, 223378.079567889,
-44489.3578210266, 0, -102047.56031235, -596657.741634109, -409718.688410994,
-251001.275795543, 101288.115755764, -49742.0341991841, 0, 314338.261338023,
-109796.32154767, 4981.4173191276, 24529.9990851288, -593681.894966965,
20513.4817152197, 0, -475834.957888301, 371436.633074039, 273287.123742901,
730222.595940584, 231609.963080369, -46489.0271928241, 0, 17703.7796039158,
-201705.46430191, 482271.359236496, -160792.735558924, -31169.5366026477,
-37730.3358669593, 0.0390195048762285, -160650.38033108, -327909.536083539,
-48936.3574478152, 318488.354334035, -93240.251751266, -10697.1107173841,
0, 18338.3817931969, 16027.9319348424, -106137.347581375, -154472.956277086,
312103.021369136, 27256.7605129305, -0.0390000000000044, 52901.2679994607,
-565477.86005398, 265457.837142564, -1295465.8600692, -249249.325943376,
4217.29667690397, 10993.83142549, -190612.01217773, -126481.520265757,
-446211.455419932, -60588.8227399307, 342257.349207623, 7069.4562341614,
0, -34155.9443169096, -390243.315646375, -298431.392874557, 127045.805640707,
-27503.7865941085, 19919.5772703024, 0, 368410.760757193, 256081.343476485,
-588813.324713638, -31820.1259164268, -4894.38037524587, -3339.18048876361,
0, -109351.582042936, 22803.3930999242, -532188.341018045, 379014.709287203,
-209420.460955246, -6106.32573333691, 0, -310705.522907437, 311994.573029367,
577311.962823487, 503839.889630994, 73486.3654876998, -148093.294519856,
-0.0117931322616463, 200333.050868587, -156898.517671003, -90960.627320574,
-232098.597529717, 385574.871832863, 34148.4821176916, 0.0390195048762285,
245628.104353565, 13064.2820977622, 673110.069090808, 602388.968064926,
333802.359442129, 117336.901867655, 0, -132085.327276172, -22104.1319673426,
-89258.7341848743, 813902.511652048, 187894.340554827, -58534.1411117304,
0, 401123.25111419, -50412.5164197232, 352917.32953702, 471007.869324956,
-1462690.94394259, -101673.367240701, 0, -77998.8561992655, 42677.2659702527,
214633.362947158, -111411.452676499, -565780.07082258, -28956.5478733124,
0, 14511.6889820215, -299253.204708441, -35371.5367951968, -213084.033672759,
165440.235984428, -41563.7068033373, 0, 272263.246686791, 342961.856212813,
-464927.825380237, -1158.51216366384, -731770.029899211, 2197.77807937099,
0, 366084.099520566, 353560.120274768, -527099.719653057, -354462.470397102,
23058.6767925143, 39092.9346594248, 0, 68768.1256515729, -53723.0997328149,
865717.004986807, 308861.8274636, -71932.8009824469, 31965.737813913,
0, -90793.7070101672, -57805.3318499619, -349356.122214827, 324499.050226239,
-442640.126211577, -11960.2308551751, 0, 27165.984174823, -496527.984470555,
-105545.64814941, 659917.896990033, -470007.004440225, 4979.29030123016,
0, -396568.656005793, -38934.311202257, 106799.003402736, 213338.981468588,
327172.530866476, -5233.52349551524, 0, -47502.4515278783, -72417.1467200766,
653484.35126587, -92648.7460098199, -3233.32465660806, 29345.5325340027,
0, -235276.123635367, -8085.28062041313, -176715.661475211, 28852.7921834861,
-90712.8139977853, 6684.15438538088, 0, 23091.3502385902, 5613.30618173497,
388409.673062188, 103551.158151142, 279437.371614545, -25657.936438231,
0, -347163.239371664, -638401.61934589, 431570.6795893, 395023.302773711,
-433195.627571962, -18972.8105174433, 0, -506739.285553855, 395763.737022434,
-268305.679979052, 53499.6681794225, 260010.994180304, -38900.1802124548,
0, -8975.7698143267, 197713.712651446, -167425.915160878, 225029.030931452,
-426574.040247294, 709.951980378177, 344.39282972583, 189443.5367389,
-28896.2889688424, 139032.37432649, 190205.441708241, 16487.735835022,
-477.381837819444, -0.0390000000000044, 209528.834861704, 566730.674885216,
322575.907703106, 38636.8911420965, -313533.21349995, -13272.940665971,
0, 43989.4999869042, 73377.5778304944, 306212.048794163, 5923.18822185303,
-224098.632883127, -22864.2598605881, 0, 586585.190280267, 228930.634138658,
409478.407704985, 146902.113837214, -433899.909484737, -1366475.59274039,
-1046202.31417455, -1978777.99743019, -746205.453746535, -1678781.13700218,
-1358507.85843634, -2291083.54169199, -443600.229484737, -1376175.91274039,
-1055902.63417455, -1988478.31743019, -755905.773746534, -1688481.45700218,
-1368208.17843634, -2300783.86169199, 1658798.83218968, 726223.148934031,
1046496.42749987, 113920.74424422, 1346493.28792788, 413917.604672233,
734190.883238072, -198384.800017578, 1649098.51218968, 716522.828934031,
1036796.10749987, 104220.42424422, 1336792.96792788, 404217.284672233,
724490.563238072, -208085.120017578, -390490.461315715, -1323066.14457136,
-1002792.86600552, -1935368.54926117, -702796.005577512, -1635371.68883316,
-1315098.41026732, -2247674.09352297, -400190.781315715, -1332766.46457136,
-1012493.18600552, -1945068.86926117, -712496.325577512, -1645072.00883316,
-1324798.73026732, -2257374.41352297, 1702208.2803587, 769632.597103054,
1089905.87566889, 157330.192413242, 1389902.7360969, 457327.052841255,
777600.331407096, -154975.351848555, 1692507.9603587, 759932.277103054,
1080205.55566889, 147629.872413242, 1380202.4160969, 447626.732841255,
767900.011407096, -164675.671848556, -422680.6084808, -1355256.29173645,
-1034983.01317061, -1967558.69642626, -734986.152742597, -1667561.83599825,
-1347288.55743241, -2279864.24068805, -432380.9284808, -1364956.61173645,
-1044683.33317061, -1977259.01642626, -744686.472742597, -1677262.15599825,
-1356988.87743241, -2289564.56068806, 1670018.13319361, 737442.449937968,
1057715.72850381, 125140.045248157, 1357712.58893182, 425136.905676171,
745410.184242009, -187165.499013641, 1660317.81319361, 727742.129937968,
1048015.40850381, 115439.725248157, 1348012.26893182, 415436.585676171,
735709.864242009, -196865.819013641, -379271.160311777, -1311846.84356743,
-991573.565001587, -1924149.24825723, -691576.704573575, -1624152.38782922,
-1303879.10926338, -2236454.79251903, -388971.480311777, -1321547.16356743,
-1001273.88500159, -1933849.56825723, -701277.024573575, -1633852.70782922,
-1313579.42926338, -2246155.11251903, 1713427.58136264, 780851.898106991,
1101125.17667283, 168549.493417179, 1401122.03710084, 468546.353845192,
788819.632411033, -143756.050844618, 1703727.26136264, 771151.578106991,
1091424.85667283, 158849.173417179, 1391421.71710084, 458846.033845192,
779119.312411033, -153456.370844618, 24092.4629115268, -908483.220344123,
-588209.941778283, -1520785.62503393, -288213.081350271, -1220788.76460592,
-900515.486040081, -1833091.16929573, 14392.1429115268, -918183.540344123,
-597910.261778283, -1530485.94503393, -297913.401350271, -1230489.08460592,
-910215.806040081, -1842791.48929573, 2116791.20458594, 1184215.52133029,
1504488.79989613, 571913.116640484, 1804485.66032414, 871909.977068497,
1192183.25563434, 259607.572378685, 2107090.88458594, 1174515.20133029,
1494788.47989613, 562212.796640484, 1794785.34032415, 862209.657068496,
1182482.93563434, 249907.252378685, 67501.911080549, -865073.7721751,
-544800.493609261, -1477376.17686491, -244803.633181249, -1177379.3164369,
-857106.037871058, -1789681.7211267, 57801.591080549, -874774.0921751,
-554500.813609261, -1487076.49686491, -254503.953181249, -1187079.6364369,
-866806.357871058, -1799382.0411267, 2160200.65275497, 1227624.96949932,
1547898.24806516, 615322.564809505, 1847895.10849317, 915319.425237518,
1235592.70380336, 303017.020547708, 2150500.33275497, 1217924.64949932,
1538197.92806516, 605622.244809506, 1838194.78849317, 905619.105237518,
1225892.38380336, 293316.700547708, 35311.7639154639, -897263.919340186,
-576990.640774346, -1509566.32402999, -276993.780346334, -1209569.46360198,
-889296.185036144, -1821871.86829179, 25611.4439154639, -906964.239340186,
-586690.960774346, -1519266.64402999, -286694.100346334, -1219269.78360198,
-898996.505036144, -1831572.18829179, 2128010.50558988, 1195434.82233423,
1515708.10090007, 583132.417644421, 1815704.96132808, 883129.278072434,
1203402.55663827, 270826.873382623, 2118310.18558988, 1185734.50233423,
1506007.78090007, 573432.097644421, 1806004.64132808, 873428.958072433,
1193702.23663827, 261126.553382623, 78721.2120844861, -853854.471171163,
-533581.192605324, -1466156.87586097, -233584.332177312, -1166160.01543296,
-845886.736867121, -1778462.42012277, 69020.8920844861, -863554.791171163,
-543281.512605324, -1475857.19586097, -243284.652177312, -1175860.33543296,
-855587.056867121, -1788162.74012277, 2171419.9537589, 1238844.27050325,
1559117.54906909, 626541.865813442, 1859114.40949711, 926538.726241455,
1246812.0048073, 314236.321551645, 2161719.6337589, 1229143.95050325,
1549417.2290691, 616841.545813442, 1849414.0894971, 916838.406241455,
1237111.6848073, 304536.001551645)

Now, with hist() function, I have 2 observations -

> hist(x, breaks = 18, plot = FALSE)$breaks
 [1] -4500000 -4000000 -3500000 -3000000 -2500000 -2000000 -1500000
-1000000  -500000        0   500000  1000000  1500000  2000000
2500000  3000000
[17]  3500000
> hist(x, breaks = 20, plot = FALSE)$breaks
 [1] -4500000 -4000000 -3500000 -3000000 -2500000 -2000000 -1500000
-1000000  -500000        0   500000  1000000  1500000  2000000
2500000  3000000
[17]  3500000

When I had breaks = 18, I get total number of cells as 16, which is
same when I put breaks = 20

In the 2nd case I was expecting total number of cells (i.e. bars) as
20 i.e. if I understand the documentation correctly I should expect
total number of cells (bars) should be same as breaks argument in
hist() function.

How to make that happen?


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 18 13:10:18 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 18 Sep 2019 21:10:18 +1000
Subject: [R] How to use breaks argument in hist() function correctly?
In-Reply-To: <CA+dpOJ=HyuC-+PruyTJh7ypE7p4bfO5NRKNf=Y3Y+QnQEzeTFg@mail.gmail.com>
References: <CA+dpOJ=HyuC-+PruyTJh7ypE7p4bfO5NRKNf=Y3Y+QnQEzeTFg@mail.gmail.com>
Message-ID: <CA+8X3fV11nKcPwN7TAZVXQdxiFWEsz70ft9s==iYiKU4oErPng@mail.gmail.com>

Hi Cristofer,
If you just ask for a number of breaks, you will get what "hist"
thinks you should. Try this or something similar:

hist(x,breaks=seq(min(x),max(x),length.out=21))

Jim

On Wed, Sep 18, 2019 at 8:55 PM Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
>
> Hi,
>
> I have a numerical vector as below
>
> x = c(92958.2014593977, -379826.025677203, 881937.411562002, 25761.5278163719,
> -11837.158273897, 48450.8089746788, -415505.62910869, -168462.98512054,
> 328504.255373387, -298966.051027528, 237133.794811816, -49610.1148173768,
> -92459.1170329526, -261611.557495123, -314388.279999876, -432257.362693919,
> -1031328.04402229, 79654.3696754137, 107072.114744956, -43384.1420067487,
> 410881.767122128, 1107540.47690119, -187319.627164858, -363126.966946238,
> 264885.548330589, -127020.002396109, 150315.10537545, 609502.016523236,
> 218679.801620448, 901573.599806465, 8289.59210428538, -860908.637977889,
> 39680.5921457494, -70270.7462533897, 1135442.61429015, 133964.991179536,
> 1603815.51357657, 2509929.42959337, 193680.587201446, -167020.153065672,
> -55258.5415736386, -121185.161514792, -1003115.2769274, 1345368.12703686,
> 91665.388397883, 137350.320344812, 29866.332965572, 558999.444304371,
> 523687.666679187, -867194.523170726, -271190.308507375, -423629.796389981,
> 96407.0505512169, 193397.770743584, -1231855.39144784, 324272.89909045,
> -1586859.60653751, 252986.272621096, -1008329.14877038, -24090.2255466315,
> 159815.745712707, 969037.929787668, -586905.922684562, 573133.370665267,
> -285493.361916026, -368392.707593945, -199242.654709143, 151002.480443041,
> -678758.615800119, 467477.655111104, -267683.37512503, -1541813.6353232,
> -6723.49019530666, 373.233886695949, 59116.2440402955, -1369030.26511923,
> 1527024.1822942, 63951.299612343, -535128.407281035, 304507.377244809,
> 141771.552178838, 98963.774668207, 10810.9015935012, 1022008.90830883,
> 276804.330003406, -304607.247552493, -15767.6578367545, -204454.923166458,
> 722866.275157944, 137685.886832198, 590201.29119819, 904805.824902981,
> -47417.8588758472, 55097.1936075327, 144426.170076371, 1020559.38779514,
> -7019.11334737329, 488224.043025845, -28272.5766026849, -295384.449673914,
> -93475.8799719289, -367939.725072447, -1244135.36327203, -863835.124327735,
> -1399240.55792133, 241146.794430078, -96612.1109580967, -9159.41140641969,
> -240291.731366074, -7482.02181888149, 71427.8225121907, -228401.89341468,
> 948738.649629141, -327368.940001115, -53374.866091836, 126448.573738739,
> 344962.4459403, 270571.141270723, 746988.197131718, -253220.465177424,
> -362652.833437272, -4385.56796251462, -114398.64639441, 454240.63525686,
> -1239567.92855698, -389939.987378005, -364083.196493484, 24693.1882238397,
> 4635.22406457209, 57992.688805147, -67934.5184434773, 123034.937557127,
> 483909.751375248, -167441.867070132, -382537.019103907, 267584.10264059,
> -188944.743935369, -47062.5409102427, -860201.712919788, -203096.090898701,
> 44317.9727734545, 375924.206160012, 67000.7086638517, 137607.783105903,
> -306430.502044082, -669552.84790218, -72629.0354820569, 251145.827045551,
> -230557.16727732, -112594.52630222, 74052.4425890159, -105774.458850881,
> -241185.430318678, -296663.488112722, 156807.699193046, -520102.742784345,
> -56451.5201730288, -23171.0259034268, -107945.719878344, -158480.929620835,
> -769507.414580615, -83077.050717928, 477248.698330914, 27706.3803488034,
> 70485.7144565997, 302213.341425514, -322119.331851626, -476228.406727923,
> -99453.524756431, -673693.791106482, 38765.0473434452, 63302.3087165867,
> 116619.019966859, -167803.424492692, 82982.1864557734, -262627.809345438,
> 643538.235642472, -90724.2065826313, -435531.286293254, -371820.753318447,
> -224713.223837607, -538987.838068522, -195841.454277966, 13924.6120356087,
> -415252.7309228, 209424.879456433, 485624.048364534, 74317.8482029741,
> 19994.939065553, -460452.302259829, -141374.457424938, -77310.8968822459,
> 56112.3979095014, -150891.122921784, -679395.088755517, -523803.739201696,
> -69888.2239139985, -4463.34352237508, -63616.8025699607, 906704.585396864,
> 1096575.89875834, -382869.397851591, -624324.630106468, -468837.009485095,
> -49963.2943695135, 17038.2753380311, 756286.614911188, -995536.510249994,
> 308899.601761641, -375123.707808525, -113921.428586057, -61573.6957341075,
> 55239.3511454715, -46731.8391379398, 697843.754042485, 265162.29364751,
> 1133747.94683337, -355974.319924194, 30699.0482856455, -19680.791041683,
> -624454.313911307, 94983.7375389124, 744849.080038272, 172732.610815633,
> -120546.157860821, 62579.2205127864, -621204.554941904, 293869.359181081,
> -108505.317455271, 646163.583792489, -502636.630380265, 502413.155645464,
> -49238.362688755, 108812.985894042, -139113.621347874, 1120034.73283877,
> -296008.55142246, -845627.626734492, 116082.364002893, 85096.4224949463,
> -84149.6401610159, 611729.398657364, -783642.839894851, -9788.4825023263,
> -58734.3009729933, -110950.384570162, -53258.3833170316, -20519.0858192393,
> 456910.655858686, 48830.1071552214, -358333.95721609, 80046.3518406906,
> -224193.119044228, 45897.0722281932, -4895.48804178487, 735710.318540904,
> 183571.602770915, -103173.288434665, 554285.106452708, 536724.819749035,
> -38962.2828892764, 26730.2338615816, -267784.282389664, 659763.691652086,
> 331635.73797362, -305496.497141735, 337703.432388682, 26793.2725583163,
> -214055.61511956, 433283.794587772, 26322.8583007973, 425589.473694935,
> 760717.980878795, 846383.092695917, -121781.599418283, 22765.984683561,
> -596872.133685553, 51016.4424322632, 467025.462325698, -148373.671711807,
> -97450.7147576735, 7382.29995650104, -117964.772809025, -341687.304035859,
> -64135.4936418714, 925622.18739822, 509465.265446495, 666959.054624484,
> 101266.034014433, -54356.9278096486, -169574.607400605, -491502.82033228,
> -1431395.03624151, -41954.234018976, -91514.0781150778, 36094.5145963667,
> -247758.21106228, 386406.544125574, -641366.891879003, 431862.530550072,
> -283519.781039346, -176768.699381518, -85100.6040966148, 42919.1786790648,
> -573792.209418182, -145083.358546141, -103592.591445374, 319209.00200335,
> -370175.637619263, 34696.5118008997, 79583.3105203735, 503595.367049541,
> -434262.168819613, -132424.172094326, 630382.147524522, -1330812.5932007,
> -7750.462191761, -52914.945661348, -222040.592341358, -415562.175846289,
> -71531.5958861226, -456099.947517153, 419065.115234754, 64284.5966914758,
> 4226.19375637705, 94078.3527038254, 89893.58540033, -607610.417024073,
> 683856.387361433, -512127.869824724, 11208.9177003014, -101394.077581535,
> 183026.233407253, -449379.145236669, -115660.001087383, -427573.119007334,
> 149949.670761132, -30407.0906389678, 43589.1678439909, 849824.902598111,
> 152884.005705639, -196505.577342962, -500734.692731424, -724491.634413791,
> 25817.4670523092, -33508.328927694, -207970.139008736, 233644.555631856,
> 28621.8629536495, 97538.1943793821, -457171.816247728, 19677.4619186778,
> 45873.6550271451, 66012.2155865722, -176547.315860871, -252790.80957217,
> -375137.893142149, 116509.511838958, -27345.0227510922, 169791.737389099,
> 428414.3658631, -176651.274187717, -376051.900674277, -244132.733506922,
> 343127.394965013, 6888.21779774424, 24855.7977502716, -146245.224251319,
> 233807.28504872, 385247.635117681, 398739.686465815, -86857.8501653977,
> 21314.8285674162, -52351.3519254668, 130547.331367762, 286512.515038983,
> -11334.6942366484, 417334.891406081, -236507.700402914, 18979.6967512829,
> 224208.680482475, 189826.430999614, -7258.57319459158, 480647.58173687,
> -920781.096620284, -11715.9303767758, 115138.804482871, 48173.3682232096,
> -35953.8062163407, -166496.453697499, 66640.8786572668, -285594.787789923,
> -168011.566368402, 59329.1235053135, 278322.35446075, -327158.568212705,
> 191785.529412968, -3305.56372526809, 82220.2970326393, -57371.8575741457,
> 29341.7002043565, 401576.094427155, 103000.389358117, 158704.130969137,
> -514696.863379762, 22590.8081844391, 34442.031907286, 62017.6376087912,
> 80386.3513537029, 570827.663317477, 330694.482577645, -163011.12596347,
> 357264.862382688, -57457.4294474906, 64054.0423064279, -30460.8776071838,
> -188482.387265618, -40987.6612274076, -346628.308614365, 219713.48060811,
> -12846.3190258391, -186723.019837828, 41894.5779905318, 288502.730124394,
> -680756.196621792, 50965.4917067681, 322152.722049961, -37810.7271030323,
> 118804.015303478, -386601.929404725, 272579.430812827, -502413.434160233,
> -719749.806882519, 514899.338261728, -83692.3953531943, 96278.7775390785,
> 107099.14569242, 63089.5998775806, -400090.250678807, -417651.577893759,
> -21815.3476344813, -12499.3359054499, -67383.6387324494, -45190.9746238859,
> -547072.030384359, 227028.825648466, 514573.742851474, 13213.6331764028,
> 36001.4594874159, -113745.611884801, -143365.507627705, 98207.6198896104,
> -63701.0617007566, -346627.341147577, -228029.155206697, 32764.801933128,
> -102035.876104106, -308868.306952677, -24975.2423467947, -419056.019442505,
> 169256.186409902, -395262.800231971, 28049.9974599825, -22327.4109009305,
> 196011.797876105, 8731.27421508938, -94532.8400731803, 182528.705947351,
> 43904.0479470682, -5155.54753837923, 0.0390195048762285, 335137.943324063,
> 149892.173794739, -455238.616489036, -470468.157469437, -210957.41457195,
> -112399.973854372, 0.0390195048762285, 36751.597937829, -39659.6468497995,
> -471901.629267993, -57759.0181146788, 157642.498220902, -76041.4762532663,
> -302713.936102669, 200322.226180072, 187185.116242184, 314843.071829449,
> 103708.528822083, 646825.527145422, 21685.7472169203, -87035.001937924,
> -68616.108554161, 0, -255740.780923924, -235035.014691348, -167510.232122243,
> 80041.4665010063, 37480.0620537293, -708586.902282354, 0, -1056670.22825388,
> 107964.769490756, -497235.817501127, -35879.0490961091, 106578.767855109,
> 17307.9650293591, 399799.483613206, -475418.037641737, -269889.151871367,
> 275749.740226646, 23257.2835354894, -57223.0923813023, -40235.9737272142,
> 244475.582447499, 211746.43851584, -238737.843477682, 194398.815768936,
> -51046.7575107877, -16393.5220745578, 234583.944040839, 245597.268471896,
> 226491.127910954, 68031.1209177937, 304995.571277675, 27091.6327221229,
> 23517.759526894, 378297.049138133, -414861.25445413, -3913.80818506534,
> -436710.139665648, -220258.814397665, -147063.765148713, -344834.731183853,
> -136380.752418312, 100107.560348566, -37335.4974639193, 134800.10180764,
> 28287.8149560302, -0.0390000000000044, 18400.94597946, 180143.188705458,
> -91477.9974889573, 9799.57265117294, 73687.0604853566, 8176.24148451805,
> 0, -46130.0248887956, 248988.399950314, 587283.929234732, -82405.4103124134,
> -528395.397678478, 204266.58524619, -0.0390000000000044, 793816.4036475,
> -52837.8228498849, 194674.195214817, -221611.691755024, -337214.779568087,
> -84645.076202543, 0, 60602.9519462416, -81278.8675375711, -300423.81924462,
> -114660.861700869, -590733.711804247, 21570.4802435367, 0, -279081.673452396,
> -86335.9025447065, -128578.335372795, -475461.464378638, 187120.274341227,
> 70576.2420958521, 0, -287121.178095001, 100685.889807059, -328140.577072372,
> -136735.050343852, 453321.059514423, 18884.7222768003, 0, -392425.170680979,
> -397462.224555713, -36585.5447158241, 430605.988629104, 52271.7195134694,
> -67238.935959769, 0, 475877.728963908, -119504.969001221, 229314.215881955,
> -1451584.32057008, -505936.831875351, 132871.504136963, 0, -793387.589474244,
> -124403.021388163, -684233.633192161, -204293.975103517, 965570.006101678,
> 176935.832176459, 0, 2357280.48309751, -736612.228515493, 37098.6281604306,
> -29170.2097097916, -459157.840979475, 18708.6684187747, -0.0390000000000044,
> 241801.043566553, 51431.1806852506, -169141.353565765, -555603.994389542,
> 610591.810551731, 34416.5313897469, 0, -355902.000913511, 145679.234659847,
> 605141.667654153, -481457.573700277, -643941.536057472, 7544.70106671585,
> 0, 47476.4186170675, 655386.536084584, 346964.742597715, -510720.09249525,
> 141847.077195927, -99458.5376396593, 0, 332955.166201158, 479325.709439097,
> -155322.932150271, 433306.402010137, 506967.357251955, -12296.1048235667,
> 0, -311290.714578155, 399931.56489403, 649193.229013061, 111179.364172584,
> 820523.690196543, -108964.899802192, 261420.492745567, -309355.784544135,
> 279294.807952869, 283383.352309925, 821365.674135911, -14492.7515847964,
> 0, -868349.061846558, 554090.574080701, 820030.598963576, 694138.112813682,
> 667716.858988038, -69903.8193919229, 0.0390195048762285, -289996.827537312,
> 1607567.81561339, -382534.263402658, -468703.737020675, 557555.283080131,
> 225702.351793511, 0, 107619.931491242, 344400.942706433, 285839.268137692,
> 490004.487833009, -407211.400557737, 6696.23838936677, 0, 54952.2805125559,
> -3247.01372716344, -165682.464249165, 27598.2004707502, 66120.3237572016,
> 41039.132401479, 0, -506189.647986148, 7266.06286180984, 590088.700081297,
> -523836.850042262, 329260.521230443, 73748.6019032789, 0, -449959.390520899,
> -598151.180103554, 1198121.502617, 13951.2730930629, 466982.452913929,
> 116271.218524388, 0, -482087.7774194, -409043.287510022, -197708.017945446,
> -222502.493632367, -103073.837265574, 7236.96703471105, 0, -119841.125142244,
> -336686.522946499, 474532.1557969, -91073.5139604443, 483958.491343141,
> 30421.838304926, 0, 565878.590184546, 903924.652932578, 468863.87173798,
> -14344.2568955454, 543058.322533088, -112725.036156905, 0, -27155.874582832,
> 137668.137318294, 549407.450186635, -1139876.87403188, -376136.972873135,
> -80645.1469371228, 0, -142214.677748352, -335730.066808485, -394729.282986429,
> 132681.914036489, -384507.62170033, -42567.9743232172, 0, 375289.35541649,
> 765719.135586415, 473684.134778998, -290433.281148925, -136613.298491729,
> 23549.9245829994, -4715.92243093635, 856701.826978566, -131964.718076686,
> -289257.670203511, 199472.390078666, 20390.4642542883, 0, -1348680.21239986,
> -506667.461138505, -639720.568549759, -91678.693358034, -186335.605946278,
> 3621.35301592202, 0.0390195048762285, -417385.103916983, -724599.902928311,
> 58904.4119171019, 588947.972724066, 125394.495193281, -56035.87456732,
> 0, -246496.711828449, -293716.353316494, -552076.935544717, -197951.856072471,
> 497064.085630282, 103330.602004799, 0, -184082.116179022, 470163.061315822,
> 370514.13838027, -267576.015412011, 412122.058353276, 6775.14252297303,
> 0, -197873.308878244, 113176.237913598, 347497.597727335, 81145.0830500092,
> -326233.091492163, 40884.8874507538, 0, 119375.194472887, 67420.8460250924,
> -169320.752755597, -325727.708077848, -141912.278280032, -57105.023227473,
> 0, -178405.120845797, -53318.6794726175, -404456.960379784, 27987.0061628747,
> -140141.725443231, -7394.49906328211, 0, -63724.0232221751, -200709.865764158,
> 1171064.63104159, 323473.274218214, 379917.317688412, -25564.0830692365,
> 0, -21460.0208135243, 344441.632986099, -281434.813456558, -364179.107329069,
> -208035.462499754, -54762.5273708044, 0, -263850.635531756, -27670.8590434237,
> -233188.595718569, 506981.609135572, -91173.4496068811, 42793.2374512536,
> 0, 256681.239879202, 361367.08185984, -64360.3495686117, -382109.073016999,
> -430583.663711505, 18937.5159713557, 0, 96659.9492273728, -219928.070181746,
> 261414.839820517, 409609.401529891, 320549.126738313, -24856.3413476205,
> 0, -14194.5048765915, 324807.471132209, 62983.7542986701, -218680.864671832,
> -113790.8610279, 17826.2568067902, 0, -245288.192575869, 153844.224967531,
> 635914.035219256, 297690.807936566, -688477.427322861, -63902.4325038975,
> 0, -245744.84616234, -160917.204894242, 805012.825548535, 375489.315050971,
> -314814.677099653, -57367.2532666434, 0, 265519.914650158, 471187.373528659,
> -277622.81963841, -73079.6944552284, -221982.274439438, -32095.5978354649,
> 0, -129088.574636866, -28626.3310864481, 0, 44651.0981074855,
> 195425.73129076, 24354.2093473602, -0.0390000000000044, -311226.106783226,
> -258656.047379568, 0, 204418.449251498, -638466.556829467, -54684.2659188848,
> 0, 381952.63157765, 490414.836411988, -43143.1180128762, 240039.320254774,
> -69376.6922024121, -49863.6875365029, 0, -70456.61333261, 303993.181383124,
> 60764.0999749857, 494444.543919188, 155062.304782859, -70273.0125213102,
> 16756.7259283977, -100734.775911482, -78399.7891902767, 1384874.02031502,
> 664971.689670853, 103679.885107961, 0, -500351.85697082, -178458.863042291,
> 469894.593563622, -438267.814871562, 264490.01664722, 37434.884061936,
> 0, 510298.492480026, -1531363.22232399, 286998.361857664, -471071.595716128,
> -28469.7290622593, -59480.2196713628, 0, 318996.345592816, -950369.508297324,
> -267186.576333817, 409935.316511621, -256790.336665586, 3768.59867396145,
> 0, -88154.4872307698, 56743.5568939772, 545943.838133454, -103394.959982909,
> 194681.810437213, -37258.2219661424, 0, -458446.075900654, 325620.884072826,
> 261605.263613712, 117332.339196911, 326785.580617146, -27474.9802647599,
> 0, 182387.219083191, -438811.292364903, -479085.324629612, -724206.450544344,
> 442047.05657424, 50026.1556862607, -0.0390000000000044, 392283.750621281,
> 318511.691037823, 114911.641359255, -86219.5099008976, 314157.097232884,
> -51245.2715103605, 0.0390195048762285, -468468.103718263, 352660.253719016,
> 89438.1740701936, 60337.5015826219, -165098.200498873, -364.82151558145,
> 0.0390195048762285, -129189.008592897, -461434.450223194, -595834.622962502,
> -732170.026919363, -164666.310247213, -10134.0079690374, 0, -284286.278619152,
> 36800.2922751199, -2067.76534540687, -6827.23835745471, -354095.310949415,
> -59229.009833746, 0, 178764.504196656, -8577.1131527567, -228628.724902249,
> 229371.721602191, 116379.933564907, 27284.3286512687, 0.0390195048762285,
> -397078.939186381, 553331.765577148, -182918.365710518, 211409.606038653,
> 10122.3565684361, -10767.0430259766, -0.0390000000000044, -50613.0926555352,
> -191947.879515343, 526883.050771712, 209124.740735993, 6075.32683394427,
> -53200.1826924931, -0.0390000000000044, -13996.5887328365, -444554.001248481,
> 197201.507524214, -7647.22292103213, -952.029475301654, -22086.0551896758,
> 0, -16820.0741479584, -468582.143440083, 208541.502008877, -400597.301023835,
> 59324.4233350213, -7929.04185090297, -0.0390000000000044, -139292.889393244,
> -169016.134069063, -18680.2056164774, 266669.794145764, -69078.4502983131,
> 24890.7444795467, 0, 325611.510493075, 450773.082412255, 12053.4490497745,
> -229093.838488447, -166211.181005526, -16397.4374617285, 0.0390195048762285,
> 7913.48259131119, 29643.5823814949, 174732.463296739, -283501.825602436,
> 54467.2479291425, 25651.8672942784, 0, 99861.0407173691, 24597.1430291968,
> -153723.888870958, -214972.105293131, -37977.1333374684, -828.677284068771,
> -0.0390000000000044, -250843.732615281, -168007.270931716, -109547.087501819,
> -276526.00897838, -249631.83234376, -11442.0501632789, -0.0390000000000044,
> 162026.244314854, 209166.297494434, -244217.557267604, -167948.948699892,
> -155712.494877031, 892.942504226637, 0.0390195048762285, -148218.492978137,
> 279268.228297628, -88459.5084252129, -246269.740482312, 126616.334219898,
> -21744.0187541791, 0, 110799.165227452, -550371.333161807, 136335.402087683,
> 71081.6034787078, 4938.0891590437, -22522.6704171085, 200988.774527789,
> -36164.4363160187, -119133.463400691, 63724.3423417965, 247338.330137732,
> 13416.1911553306, -3975.15765463608, 24612.9347125312, -82679.0308733731,
> 346781.753785694, -172319.120485387, 975.916771472377, 55887.1242471693,
> -224144.457882754, -369046.070767925, 334740.224468953, 133339.205879309,
> -9879.21926455217, 0.0390195048762285, -97117.0811281616, 196007.779334733,
> 54090.9431562634, 69677.5220610845, 254721.40261747, -19014.727877809,
> -0.0390000000000044, -125884.021820622, 177173.475776283, -110984.337066046,
> 348288.512602021, 374850.347749425, 42490.6609861627, 0, -303453.636890066,
> -78540.1630422476, -109022.038218275, -209148.388401315, 164979.555202176,
> 53516.970980741, 0, -255421.211339204, 158889.893715836, -285174.368259312,
> -136898.885703143, -232569.155323701, -21783.3735107945, 0, 43342.5491827807,
> -154645.108353499, -389626.981458598, -42563.8093041327, -106299.33773613,
> -22404.5314915718, -105333.763605645, 300984.234225055, -230394.797475435,
> -724485.590183983, -93442.9536058113, 8008.69598736465, 0, 461003.519176015,
> 482550.055486119, -326020.941089073, 702101.809998014, 326097.586101123,
> 63090.7669156126, 0, -94245.5232805013, -513902.085233714, 144574.493307756,
> -500942.567513754, 134575.134002212, 23069.7062731782, 0, 482136.544823212,
> 270587.675513015, -377413.791127105, 811826.941393858, -47221.0087850639,
> 15594.37123049, 0, 322076.846635732, -367752.234477249, 270052.208032134,
> 21238.7110611406, 306179.058384112, 5501.67700253881, 0, -199745.111132869,
> 102410.049420472, -231757.619556354, 363356.411238454, 490736.657209141,
> 7878.63269968232, 0, -153913.032939484, 649320.769741573, -42996.7332100079,
> 82616.6774567946, -266584.628866147, 104610.931820876, 0.0390195048762285,
> -193459.245050452, -190871.019338125, -186376.651912743, -82765.3087592242,
> -213975.992967376, -6377.17451707479, 0, 187666.358166527, -561576.02357565,
> 22594.0600497778, -366366.9035905, -1028127.55973093, -25251.6891540467,
> 0.0390195048762285, 102836.426176511, -7198.45013860136, 291372.089810479,
> -126878.973614494, -263928.271891768, -16167.9249036157, 0, 43644.9079520843,
> -762625.070775256, -291948.325270492, 300382.307094392, -654486.812680507,
> 85384.2563936351, 0, -88736.2740542908, -7868.27988055637, 331808.92178929,
> -263922.629988663, -773166.942477735, -59280.5434536302, 0, 470080.031265531,
> 486165.176295504, -135376.607004037, 214413.621877114, 276943.865088675,
> 15154.5671318414, 0, -324390.339689125, 75908.9347830929, -230733.589847692,
> 318380.508851761, -293973.004230226, -17744.1202589633, -0.0390000000000044,
> 618118.195737977, 353650.190465144, 445880.907932169, -171424.375995123,
> 452986.404625022, 3036.20663408337, -0.0390000000000044, 1062561.51711357,
> 472665.603634668, -499167.315444823, -734996.01564479, -124448.543634461,
> -5622.5049684512, -0.0390000000000044, 129902.977464334, -132064.901061959,
> 64282.1888055519, 0.0390195048762285, -201292.155945282, 9220.44509517555,
> -0.0390000000000044, -316730.459314209, -20525.8209706341, -29004.9136901343,
> -0.0390000000000044, 458478.030026522, 81586.312211733, 0.0390195048762285,
> -134678.932605067, 283327.333978638, -210417.60656906, -487545.943339705,
> -6525.92608752091, 11637.2851498163, -0.0390000000000044, 507347.757363322,
> -137485.646842542, 188088.643186468, -4066174.86810666, -1032514.36828399,
> 108847.494817068, 0, 791860.691479671, -213715.673400183, 1324024.59560125,
> -403824.442965452, 184073.341745611, 40189.0193028279, -0.0390000000000044,
> 525915.100546247, 363464.041498222, 407152.099435168, 1675540.59889003,
> 205226.292147749, 105076.953485897, 0.0390195048762285, -50719.6873005749,
> 97414.7687655811, -55148.4661419116, -200482.857304442, -567832.901733926,
> -103131.287856226, -0.0390000000000044, -91327.2170262781, 114777.356449262,
> 136685.502532627, 478369.854418218, -312221.214521486, -65682.7358225499,
> 0, -155685.018515712, -199177.992439029, 183582.505261238, 270243.660730011,
> -348929.235653529, -29959.7831838142, 0.0390195048762285, 276904.158681192,
> -269485.926642612, -601662.212540186, -89287.7668366619, -430690.278857094,
> 98098.9275916149, 0.0390195048762285, 415270.357252486, -227487.885836433,
> -576858.75255965, 439587.397043779, -72211.1985931339, -28788.6984269492,
> 0, -92930.2202137985, 285985.534713615, -220337.989378342, -731754.196659329,
> 64321.4834251423, 398.507611679556, 0, 294780.534475733, 374365.042256007,
> -558298.515305844, 407981.132828032, -736027.314215928, -78490.3828092808,
> 0.0390195048762285, -298005.118557684, -106242.616214473, 687576.113166217,
> -153599.516112101, 597063.995316294, 79955.7069117654, -0.0390000000000044,
> 417223.378114183, -234311.884085523, 45420.478744352, 455696.517435112,
> -178841.355310611, -7723.15381229715, -0.0390000000000044, 157122.192247785,
> -717537.57730847, -546663.259457788, -310158.230583305, 59550.2168797106,
> 26986.1848368087, 0, 522613.850141923, -44463.0508627074, -682207.635711803,
> -835300.948255266, 372788.341495282, -41657.2637488423, -0.0390000000000044,
> 122292.947786914, -118958.410291773, -369117.10849454, 257617.081846177,
> 139189.999264687, 36769.8126361053, -0.0390000000000044, -628290.565787727,
> -795462.277111254, 307554.710478614, 1222030.97032663, 713318.042087609,
> -148050.282804399, -0.0390000000000044, -350653.544079332, -487640.412937263,
> 469123.421791911, 272852.164609701, -681621.328104045, -111583.910184976,
> 0, 104433.71370186, -549849.094817313, -415717.906590806, 270365.318151125,
> 491323.094061352, 48267.5150970486, 0.0390195048762285, 50941.1516350525,
> -105313.870260356, -360210.768298464, 37972.9724577314, 223071.459277248,
> -138578.684019058, 0.0390195048762285, 16667.0850315625, -1669.16189955389,
> 37848.3245482788, 654232.069173093, 368974.134608878, 53137.7481215514,
> -0.0390000000000044, 114464.50233507, -319760.954652096, 781198.484217955,
> 415164.949987879, -502333.7897317, -22553.1590751249, 0, 386330.628388539,
> -23721.549329344, 81378.7622165195, -259140.693344057, 78297.70303,
> 87282.4860704868, 0.0390195048762285, -187840.319924304, -22053.3003726119,
> -119276.616359917, 144946.482922327, 95128.2730634099, 27666.4542034838,
> 0.0390195048762285, 251488.895173803, -686390.138017146, 378546.812585061,
> -343495.830300434, 312219.316046833, -221.597840918512, -0.0390000000000044,
> 656398.65888048, -104505.417992213, 221827.186101971, 124603.740939192,
> 861578.563072788, 123233.451394075, 0, 101288.914873362, 710330.245672313,
> 1183955.15261785, -840912.625983386, -319869.039173635, -5827.29298255884,
> 0.0390195048762285, -400801.686099512, -346904.747562644, 655993.220304874,
> -245261.429002587, 60810.564460045, -26428.0552726151, 0, 71072.5173626143,
> 72920.3820474423, 342379.56159339, 708062.831368821, 427376.263206645,
> 83101.0587192262, 0, 783243.765998376, -1045940.27133011, -161145.6997207,
> 38875.8523667146, 270726.01431664, 102134.16340864, -0.0390000000000044,
> 261944.011067293, -862163.329543587, 59725.151710014, 45560.3381891341,
> -57530.6681616876, -55269.0722628376, -0.0390000000000044, -220247.194423249,
> 967197.291432708, -150808.552542964, 174688.085752766, -48480.7657346432,
> -2885.75309799535, -0.0390000000000044, -80730.368759679, -117398.315603203,
> 372363.75096326, 363040.426534184, 1177140.78031658, 251690.422391106,
> 0, 3452034.51229956, -111279.447878959, -250704.812274433, -1075177.17075252,
> -467878.610319999, -129913.531648512, 0, 1052537.36076061, 1526377.28885803,
> -336613.763046696, -356409.512909958, 1498462.73472141, 124128.70690916,
> 0, -99575.5897118994, -1162490.27167616, -241305.451553955, 71591.8150772758,
> 221753.151731608, -30099.1143091218, 0, -244914.522201468, -259804.057466302,
> -728131.832421127, 900519.951448378, -799657.832193851, 130885.968287402,
> 0, -52167.5826851328, 504409.295616509, 1300424.78441576, -294083.206467293,
> -267339.570018078, -4632.81662741184, 0, 853884.997617557, 163161.67879033,
> -743140.431865549, -39159.8940514744, -596432.894381403, -489.948496348417,
> 0, -771818.9086432, -396566.474718801, -488522.007986759, -322519.123590265,
> -439887.412813621, -18237.2823504247, 0, 15199.3450380726, 882656.909735028,
> -368017.956183111, -904459.58632761, 347878.022271072, 6452.05506304858,
> 0, 293611.867597225, -167774.943346338, 729100.134009611, -1423758.76528479,
> -344674.334080768, -1700.67067612087, 0, 124186.14258285, 880257.818248461,
> 61639.3820561054, 418551.231996187, -611728.150232683, -1830.12407979669,
> 0, 138956.331043692, -621189.175051699, 19400.493016211, 239811.323639335,
> 165654.164272122, 54960.1691360546, 0, -146012.213624507, -32733.0108983296,
> -165338.010192922, -74594.0327656692, -251793.146237776, 82721.7343098886,
> 0, -185792.406535621, -423825.596523159, 266755.32200355, -254492.256207949,
> -432438.64408513, 43009.8885527976, 0, 441189.327867746, -241587.926893129,
> -359529.428794775, 240657.112557487, 516516.479291287, 32464.8678235453,
> 0, -757165.456461308, -334118.1302625, -32930.6043895907, 966157.172059503,
> -499098.214684272, 13143.9971756606, 0, 826059.214436754, 856169.136393278,
> 570475.860833162, -464302.75891756, 1176459.09868583, -34989.640743276,
> 0, -164604.635403118, -100847.709530831, -437251.413671235, 552181.889986011,
> 125395.318835901, 123338.539623345, -0.0390000000000044, 135769.58533786,
> -46821.3749309707, -298190.017078578, 117163.532003545, 0, 0,
> 0, 212983.103161801, -512896.44930345, 110332.807183794, -7563.97155784612,
> -29014.0300137318, -49913.7675000671, -0.448868514791554, 1184145.4239976,
> 138459.337025028, 1263533.27581096, 1132594.0107997, 526802.293143484,
> 363848.045040318, 1.94058822106601, -650995.606259771, 365926.36156573,
> 303877.463780822, 3240.86248437041, 1940027.9862433, -41834.4613627808,
> -3.85750830246918, -129434.25294958, -549367.101422798, 153734.04390567,
> -1532692.23859055, -907202.308577724, 36152.3303085305, -0.830043272607144,
> 874559.931471143, -909342.209398651, 274927.122811488, -322330.997960151,
> -1225939.91194111, -148676.548488952, -0.55355151820784, -311873.568866687,
> 1136174.73212114, -65119.8291033855, 362411.541557494, 763002.686766724,
> 110331.936503987, -0.347524004821157, 404885.093463446, 469476.422170561,
> 313813.416556882, 560749.817677653, -482245.399092919, -22080.7667821803,
> 0.835799038747631, -934461.214224207, 925414.553189891, -768238.344313897,
> 257357.620407682, 411203.512338195, -16047.1119363399, -3.30605907506658,
> -864897.380730838, 537834.100597385, 98857.9530721416, -782088.90065692,
> 151951.765147568, -50732.0681977504, 1.85112380819457, 214021.321066593,
> -1087884.5620327, -642567.744215527, -480452.954694592, -729880.104057032,
> -4561.75441494796, 0.0788207126405996, 77896.0501971397, 926669.316281905,
> -760333.22583231, 1122798.35162061, -1577919.78217232, -104841.767397575,
> -0.52613609596393, 479705.189648157, 1156562.87327825, -810077.555094365,
> -514668.80072939, 272475.525788962, -104739.171337302, 0.0704638630190552,
> 272793.544758114, -454103.551765905, 1046258.09095604, -160475.573193086,
> 143313.137864412, -19532.8153702827, -0.17159959749412, -704111.198808967,
> -583369.676722747, -261762.912509876, 214671.581263792, 701382.248548697,
> -39015.1387433404, -0.466511480649595, 771644.489143001, 1144447.36113538,
> -76104.1049544494, 1179625.84027416, -493457.755158948, 3662.29446110004,
> -0.780327189379466, -665518.250494947, -1277109.60515789, -421802.980409576,
> -49044.1107723257, 119183.696821751, -114908.269872012, -7.63781985743387,
> -309855.694120185, -1267118.11507658, -53197.2770593066, 702853.626375132,
> -1168593.8278627, -38476.7218322247, 1.88075263239151, 360464.948709667,
> -451776.547235346, 1073075.3780936, 878076.697374264, 1142329.40187676,
> 39828.9071618289, -1.56895829642405, -137085.198896086, 1655828.7128598,
> 480036.273931022, -415825.838988577, 937240.657510177, 22078.5565934129,
> 1.1696494397288, 13905.2045966725, -804549.764439301, 176377.776818163,
> -165268.192774081, 635485.16611632, 32058.5790051319, -1.79834286491877,
> -199056.785347188, -447034.904903806, 99435.0019958235, 292687.045144768,
> 106584.533214753, 23733.5038078122, 0.757312520979568, 441172.357845112,
> -420714.346543101, -616213.652808971, 170503.46410341, -17285.0899043416,
> 31073.5409085332, 0.109608364871736, -192510.512458429, -25514.12446222,
> 473078.83536466, 416119.183626047, 38688.9203188218, 82493.9220142876,
> 1.40870473922256, -805507.019492379, -800270.191361448, -150048.977812476,
> -336246.574492321, 679675.603974693, -15900.9078747745, -0.0498329105301624,
> 509127.762199126, 89823.9910008119, -69374.9994898348, 1031944.86141822,
> -450564.422942861, 72433.4178653258, -1.67787578479119, -782793.183224089,
> -666576.022709582, -52579.4545225305, -1328217.26007806, 3391430.15019308,
> -36899.9331782318, 3.89768264518407, 1286110.28210833, -473793.390371595,
> -588683.728983871, -579711.484899109, 163067.181334192, 1507.1828149074,
> 0.961916623513784, -518059.38296519, 1466398.243878, 38548.6631919937,
> 316263.518582104, -457252.596415167, -150056.335192077, 0.503066450577447,
> -587556.061242795, -1945082.27838089, 430104.991515802, -874045.841625823,
> 375669.422348837, 379826.033627652, 4.55961468032831, -722643.598413397,
> 949791.409255599, -125000.578329553, 414507.858983872, 81301.1698030928,
> -41421.422905525, 0.23443541378806, 349634.39817374, 206159.389364886,
> -171688.180816275, -259556.795715628, 776619.021780188, -38586.0587540062,
> 0.174530359404762, 458890.950079616, 87351.621206337, -109747.080354324,
> -203433.933672753, 258447.49386935, 8295.09347273768, -0.765779504004323,
> -443923.908338955, 175596.601790444, 3532.93226268073, -458553.849786203,
> 857145.327024336, -58700.8479085652, -0.0599806806534759, -48202.0818092764,
> 203910.743215457, 440819.413843871, -304405.383609747, 675285.81966806,
> -10819.2211474697, -0.304587743070636, 51239.0839633315, -116881.84096912,
> -242094.703108759, 62174.1958571357, -196972.263265054, -23010.9710813549,
> 2.25551907887176, -96087.6275527137, 23403.8458501194, -353063.809422422,
> -309849.845908518, -1013972.33087027, -10664.0739743922, 0.723252247684872,
> -47568.7352909489, -193441.024022429, 424143.196856536, 206497.257273117,
> 645548.442607811, 84524.9944347116, 0.243749233254403, 194743.170900073,
> 778430.625198823, -1327.36638776853, -234237.323194264, 252813.861524462,
> 12825.0878367661, -1.14235982563736, -142715.484418077, -186782.088701177,
> -146716.144885514, -240422.280650495, 614661.039189968, -39455.2389521195,
> -0.665549666337014, 588214.225622685, -496587.124221711, -331273.292465428,
> 258367.905125984, -178768.113125402, 34222.6967088589, -0.488808822931229,
> -91051.9097490469, 328042.470410259, -304969.320008644, 153809.950647346,
> 1016290.69044115, 36545.9736877277, 7.63438378157161, -770376.781276765,
> 802118.223828555, -827212.457391376, 184475.616173862, -842909.544036342,
> -85939.3145287338, 0.139858236212178, 131150.339179262, -624564.259803266,
> -149890.186735877, 399494.626730305, 349040.516977361, -9078.97029663942,
> -0.97657879690758, -25521.6516332705, -289329.487466754, 1794.06608685441,
> 109857.794802284, 346019.248150712, 55529.1120299645, -2.13067551335629,
> -270932.363618753, 162563.035012237, 165202.580758492, -269070.494007096,
> 68950.6504011439, -64655.2289513167, 12.3436907575666, -1054332.9029259,
> -808330.238738194, 103323.40007864, 125969.527483452, 593112.426890825,
> 45974.7084115449, 5.99361060040172, -995688.54510629, -487233.681260215,
> 433101.52423077, -28952.8107155296, 129175.123983006, -28488.1441111609,
> -2.32446750475319, -530459.445527634, -23739.9346532509, -645443.149724427,
> -460433.055433532, -84154.6877063064, -68539.469104535, -1.02239141732126,
> 100813.710192657, -169139.241159384, -255826.195076693, -155437.261304867,
> -349627.317701097, -8857.09896792944, 1.170115692395, 227746.530059119,
> -153554.955200597, -21897.768826222, -608042.622759881, -599230.834299122,
> -4947.12603797521, 3.23194699890041, -54544.5118677688, -100801.791300864,
> -118777.161601057, 85644.5004302306, 593987.190195945, -16084.8718472366,
> 0.918950981353822, 808065.485314525, -387127.67153309, 343057.433999068,
> 610188.5085837, 547920.514662969, 22905.9189232694, 0.212471440013776,
> -0.334820771670364, -9760.51226854886, -292060.108058866, 149711.804094227,
> -215821.943770995, 52131.0082331534, -0.679856982819708, 4.37195571870305,
> -766471.732643893, -311932.043446921, 429258.244478974, -241019.267806738,
> 63030.3342000214, -0.491397944332623, 248791.216195691, -25250.7149076552,
> -492835.022580452, 37158.6473094208, -82329.0952911061, 30381.5566372352,
> -1.42353263501367, 558276.408256123, -530683.929772509, 43164.8635077819,
> -395344.71954871, 349402.89815207, -87894.7012437207, -0.698357701114884,
> 238877.485624055, -569778.531092712, -37770.725580281, -439002.274228942,
> -228851.187503489, 61436.4600006672, -0.377220838298103, 405826.945073561,
> 103066.431143013, -148174.746760546, -210967.080999126, 139829.593309277,
> 60691.5242889719, -1.45477020729827, 378364.303258737, -251465.43915257,
> 73637.8143261174, -337754.38857644, -512842.837136735, 40178.5389352309,
> 1.62467227479468, -187314.341002131, -305105.877598533, -230147.387449364,
> 761932.892745528, 240815.540741457, 111925.54147767, 1.2347125443046,
> -321635.58695427, -290272.867252394, 94229.1814062621, -113320.112905531,
> 527458.506965894, -15811.0950218225, 0.957160771645822, 174768.871765807,
> 398027.0089539, -380835.548706458, 543637.970470723, 519470.857674187,
> -67341.9491465138, 1.31383604142993, 261175.437555478, -1545.24479741293,
> 354118.176758968, 169144.196496997, 180760.874826798, -18549.2664258269,
> 60669.3190437187, -590654.127242372, 93548.7725053475, -695288.389108197,
> 522686.438703242, -214824.460306086, -26114.4656333086, -0.229562788159544,
> -173262.83592552, 709637.643234735, 79505.7742829168, 296949.209344625,
> -1986.43711949308, -1601.38915045831, -4.85772066596214, 373234.469380759,
> -140382.601833601, -439486.846151822, -549662.736272065, 47430.5250751876,
> -26399.7755399897, -0.686169433064969, 715501.757167393, 400259.057196214,
> 13346.0146380121, 26718.7626107054, 126445.32194971, 33638.7594523421,
> 0.813547635988178, -105683.110335082, 435965.430332249, 95403.8910628198,
> -481050.846294631, 64153.6566738995, 33043.7624899443, -0.233028368125731,
> -90886.1678643211, 484335.338546848, 437403.768217222, -379688.383507617,
> -40769.4085559782, 36692.4878439563, -8596.16048702984, 470296.442190532,
> 124439.488143896, 373685.524496639, -158786.621594549, -105247.453338068,
> -4126.28884894295, -1.47112147691444, -209597.787638488, -97291.3823946401,
> 452569.865394461, 660125.623198972, -445349.422184596, -72945.9971565026,
> -1.67594269703528, 15699.9042449935, -90757.8436348567, -543251.945342915,
> 259298.835795079, 357993.286041491, 10500.6351800535, 0.849006996940302,
> -356638.709054055, 430469.769238303, 988943.898152086, -118891.608157918,
> -186565.855273002, -13674.9756615686, -0.451710670723791, -47872.0424773118,
> -389116.178406173, -187131.931544438, 249747.213125397, 189116.297037467,
> 8454.44872690222, 1.47075940254537, 46817.2680409656, 90661.0830671839,
> 398325.610160954, 117155.035657961, -8711.36390834203, -51543.7886710254,
> -1.96159580044462, -418745.171702333, 214379.173492304, -387702.417997556,
> -313114.224353174, 170618.164035238, -49770.7369261911, -1.39382879596211,
> 78955.7929677602, -317513.490571421, -213205.842556053, -584900.413071782,
> -199145.497920399, -10504.3847755026, -1.8870508069577, -169974.855111851,
> 275371.331769416, 343218.411588482, -250146.154012138, -22421.0334962054,
> -3757.75604240176, -0.184115213415397, -435712.81857957, 193583.408269913,
> -608129.009687867, -41519.2388064597, -369523.048108753, 14024.856298694,
> 0.598791675498988, -92480.2561059163, 253238.446427851, 93636.5304617214,
> 355684.755882405, -379472.803965865, -75420.3629707051, 0.633804830139507,
> -37723.8986497204, 397022.488565321, -752575.674747607, -492066.087379648,
> -448223.623970308, -11157.5740266794, -0.44791905923326, 284247.068283859,
> -356611.936623746, -322276.644180769, 443885.764563407, 414857.392688213,
> -39307.2104301387, 0.154987283899936, -190531.01954913, -171209.508930312,
> -15264.8753869927, 466276.930003453, 193999.520555962, -63783.8757522016,
> -0.324211123080758, 575690.585433969, 140757.68748233, 356058.195352473,
> 573739.218395347, -203113.259169499, -21197.1662909565, -0.101051316159451,
> 365804.489718196, -60121.4723270389, 154575.306892957, 499421.063555352,
> 626.570916012138, -46002.0565745076, -0.302928342564448, 212803.761542056,
> -50474.1827634641, -983505.540875834, 390340.095407959, -117225.626099831,
> 15486.221300223, 3.36208571360414, 120353.368518598, -43922.0506901111,
> 535025.644342653, -325500.549220098, 15215.4012872553, 11369.1866617949,
> -2.6733510390521, -62746.1247628681, -41217.3676101551, 97337.5478447712,
> -437022.614333498, -587088.867203041, 8663.80087396323, -2.81930705460169,
> 544084.350552567, -194665.658437026, -474303.90251148, 47089.2189303614,
> 52044.708094571, 59114.4914864782, 1.97175853692898, -702873.214187209,
> -192594.894741777, -44756.175774177, -115395.48054871, -416289.961599669,
> 19243.1784288124, -0.34401384803914, 497046.927831415, -254602.093815812,
> -600285.747340646, 661167.899836084, 73615.4503674458, 49462.8334854496,
> 2.65197027381195, 74010.9410777649, -120281.028654509, 199602.933369611,
> 84939.4201310658, 390794.545297178, 43123.7839036421, 2.76123903271996,
> -39393.858821654, -25215.3072503919, -87695.8424332909, 681595.032473105,
> 336558.096481148, -86652.0357470236, -1.69505178520407, 239294.631233719,
> -2551.02350250426, -45867.4197825044, -405843.981957054, -433510.952973442,
> -3886.64560189383, -0.585438919126716, 213247.45043155, 121737.950401034,
> -207778.819322602, 402946.475669372, 197819.724211416, 31511.8135341855,
> -0.287290613288253, -44304.1792546737, 417419.543310009, 864531.053610092,
> -120100.437211121, -220528.3221337, -29452.3859885195, -0.278893637011173,
> 214253.945191957, 213796.623376107, -550540.216200165, -12116.0818141295,
> 169851.161824274, -4912.83310938924, -1147.01328636259, -533817.948590498,
> 355010.089900658, -246329.189176917, 136684.012181338, 164689.160754399,
> 44734.962462357, 0.687617438086121, 418249.634705275, 586852.908494586,
> 500221.914440418, -125828.056738882, 569051.292493796, -11359.4357959364,
> 0.734040693755395, -157953.050498003, -194144.846435625, 159611.290482169,
> 222634.637028813, 283723.289220194, 25672.7465048742, 616.019030782489,
> 138567.790130216, -205141.780611072, 94173.8697132266, 182291.359598616,
> -687694.022494064, -87850.8496682753, 0.571112834965966, 39166.5292247086,
> -250652.355065713, 663169.626446704, 110896.80785048, -95561.245801989,
> -21264.8403690933, -0.245911613253347, -160297.292762285, -265314.252381569,
> -164241.562618595, -332906.33143816, 363165.094282941, -34670.5039814225,
> 1.84836474590221, -258969.118747497, 188832.554912581, -74400.7810299972,
> -384886.715592592, -252004.427661765, 18718.0958141181, 0.846501982374679,
> -669.150366401549, -136164.90261595, -472551.411708157, -201210.382601339,
> 124752.284807634, -19570.715109723, -0.253193856171099, 0.866911841107836,
> -112174.091638734, 3283.36484285798, -225581.252008734, -564407.157766663,
> 52909.0103524324, -0.604538669390019, -115259.246052021, 448932.910474423,
> 650025.966491053, -63333.6426010272, 149470.590572872, 18334.3931332014,
> -0.439506387526617, -1392.97072737573, 21697.850585154, -758959.655826269,
> -35195.9038952245, 411273.34432515, -21223.0559373178, -3.4962274663365,
> -342035.682929145, 297815.338110005, -291405.382610352, 494012.260732564,
> -379403.248459113, 74474.2166145356, -1.06574977239644, 29880.8653746963,
> -4886.94303533196, -210182.547081464, 301734.388528379, 854343.102866212,
> -3892.14856155674, 1.40382016401682, 549056.242096429, -112364.138373,
> 380088.065337126, 291488.552332436, 73409.2123056685, -61879.0997852081,
> -0.639435974964493, 103714.929539531, 414848.27648521, -157120.797096035,
> 280867.257163763, 45611.2167994122, -18249.1645848915, -0.250996861963904,
> 2324.87429633775, -105434.284511345, 182777.421313059, 334637.845829162,
> -50402.7063731416, -119361.38156966, -0.579710376215114, 161987.895191185,
> 204871.858689241, 664204.960689558, 343864.366976734, 635610.743832244,
> -96019.9943959462, -2.78287058858445, 223940.060616283, -444043.884606283,
> 140005.348418627, -75703.6422567518, -751227.936101957, -9148.93310907192,
> -0.636451359133324, 29397.4816700069, 398324.361100115, -209175.704801674,
> 633488.215141836, 787687.908089592, 29440.5821588683, -0.2500585252221,
> -143097.326781838, -114797.902963819, -581275.100059571, 516574.930898529,
> 248463.568208775, 104543.070694524, 1.60091782864983, -368902.419202698,
> 239964.045493573, -557410.990294082, 43874.7209892128, 113868.312746422,
> 29758.6499198484, 1.0416798519871, 12152.6162887028, -709808.708200817,
> -212157.837637936, -86584.9333134385, 119268.776408179, 19816.7907387121,
> -0.222235264868781, -118999.800943694, -661846.024792731, 148453.236205698,
> -198255.818362457, -91065.7742200357, 44728.1197292919, -0.298488088236409,
> 14874.4853767394, 287064.835578629, 104226.974571131, 426608.364609386,
> 384112.161964605, 34940.8071400329, 1.97807462459604, 54674.5979877085,
> -132282.644530739, 20791.899124619, 34937.6368832572, 62061.9180091976,
> 16467.2368391754, -0.558064415894874, 97208.4729903377, 58498.6102185582,
> -167167.894618437, 163434.083945409, 123365.958767946, -38494.8990481168,
> 0.0632364670855726, 129932.58693482, 238101.40155474, -501113.58015545,
> -186079.725861603, 90512.7002652543, 7247.80173566601, 0.208906244779166,
> 49504.5959298972, -37598.5102920599, -659742.898701273, -170275.33873514,
> -14381.7185175271, 7220.39522287804, 0.733060615008382, -569150.496856227,
> -41199.9835920449, 261456.508431599, 358701.056972404, 39309.0269982611,
> -77080.6525971282, -3.21959372557366, -102702.569884871, 294953.356154138,
> -395338.955391595, 360737.675339021, -533562.044426142, 30059.0355589319,
> 0, -485377.057439916, 289124.797013418, -308270.650867299, 602841.843639431,
> 63713.9856345581, -64172.9824101041, 0.0390195048762285, -18072.1220569555,
> 97716.9642924921, 76572.2212415675, 2470.42475020646, 739410.791023085,
> -26974.7177125456, 0, 380044.560690408, 724952.450009499, 57233.6474051622,
> 28038.419392239, -231816.655477011, -48805.2591175288, -0.0390000000000044,
> 554212.528373654, -41661.4315296956, 374918.309394534, -176137.4007854,
> -406985.921717131, -42967.5570292135, 0, 650009.68098304, -401007.429049733,
> 21321.9766216372, 3108.33735649223, -115169.378554176, -39331.9311741647,
> 0, -181130.407195509, -210538.633915801, 440086.385271864, -460251.352236625,
> 74788.192922612, -39089.894058956, 0, -12512.8511791581, 49660.527994718,
> -152827.582343717, 907083.182236652, -427230.37019585, 138171.436371292,
> 0, 230190.97756307, -303429.008860114, -312469.012792172, 322036.171845101,
> -160683.325202816, -5804.64242044523, 0, -50270.3734076749, -542714.085461664,
> 258853.131646172, 315000.533698754, -215877.037004863, 6129.20169442105,
> 0, 224174.054861113, 22932.8469025961, 72466.3591182846, 299865.152513392,
> 620596.557035012, 30528.6666351762, 0, 432885.944264468, -569968.398601476,
> 434193.477117182, -70516.1709908492, -157657.902256126, 46282.9497806456,
> 0, 69817.9090433985, -201907.970463657, 12646.0315448356, 611276.259602801,
> -362904.402464875, -50091.1292814856, 0, -21465.1392525689, 120298.172027106,
> -275538.756366311, 752870.199661686, 377855.811785498, -59957.4006903867,
> 0, 242581.966390384, 360285.31857188, -55460.2003679164, -19768.2776583378,
> 342086.483182684, -48314.1629683354, -0.0390000000000044, 75758.008094813,
> -232986.580427601, -558831.983886635, -379130.767186877, 223378.079567889,
> -44489.3578210266, 0, -102047.56031235, -596657.741634109, -409718.688410994,
> -251001.275795543, 101288.115755764, -49742.0341991841, 0, 314338.261338023,
> -109796.32154767, 4981.4173191276, 24529.9990851288, -593681.894966965,
> 20513.4817152197, 0, -475834.957888301, 371436.633074039, 273287.123742901,
> 730222.595940584, 231609.963080369, -46489.0271928241, 0, 17703.7796039158,
> -201705.46430191, 482271.359236496, -160792.735558924, -31169.5366026477,
> -37730.3358669593, 0.0390195048762285, -160650.38033108, -327909.536083539,
> -48936.3574478152, 318488.354334035, -93240.251751266, -10697.1107173841,
> 0, 18338.3817931969, 16027.9319348424, -106137.347581375, -154472.956277086,
> 312103.021369136, 27256.7605129305, -0.0390000000000044, 52901.2679994607,
> -565477.86005398, 265457.837142564, -1295465.8600692, -249249.325943376,
> 4217.29667690397, 10993.83142549, -190612.01217773, -126481.520265757,
> -446211.455419932, -60588.8227399307, 342257.349207623, 7069.4562341614,
> 0, -34155.9443169096, -390243.315646375, -298431.392874557, 127045.805640707,
> -27503.7865941085, 19919.5772703024, 0, 368410.760757193, 256081.343476485,
> -588813.324713638, -31820.1259164268, -4894.38037524587, -3339.18048876361,
> 0, -109351.582042936, 22803.3930999242, -532188.341018045, 379014.709287203,
> -209420.460955246, -6106.32573333691, 0, -310705.522907437, 311994.573029367,
> 577311.962823487, 503839.889630994, 73486.3654876998, -148093.294519856,
> -0.0117931322616463, 200333.050868587, -156898.517671003, -90960.627320574,
> -232098.597529717, 385574.871832863, 34148.4821176916, 0.0390195048762285,
> 245628.104353565, 13064.2820977622, 673110.069090808, 602388.968064926,
> 333802.359442129, 117336.901867655, 0, -132085.327276172, -22104.1319673426,
> -89258.7341848743, 813902.511652048, 187894.340554827, -58534.1411117304,
> 0, 401123.25111419, -50412.5164197232, 352917.32953702, 471007.869324956,
> -1462690.94394259, -101673.367240701, 0, -77998.8561992655, 42677.2659702527,
> 214633.362947158, -111411.452676499, -565780.07082258, -28956.5478733124,
> 0, 14511.6889820215, -299253.204708441, -35371.5367951968, -213084.033672759,
> 165440.235984428, -41563.7068033373, 0, 272263.246686791, 342961.856212813,
> -464927.825380237, -1158.51216366384, -731770.029899211, 2197.77807937099,
> 0, 366084.099520566, 353560.120274768, -527099.719653057, -354462.470397102,
> 23058.6767925143, 39092.9346594248, 0, 68768.1256515729, -53723.0997328149,
> 865717.004986807, 308861.8274636, -71932.8009824469, 31965.737813913,
> 0, -90793.7070101672, -57805.3318499619, -349356.122214827, 324499.050226239,
> -442640.126211577, -11960.2308551751, 0, 27165.984174823, -496527.984470555,
> -105545.64814941, 659917.896990033, -470007.004440225, 4979.29030123016,
> 0, -396568.656005793, -38934.311202257, 106799.003402736, 213338.981468588,
> 327172.530866476, -5233.52349551524, 0, -47502.4515278783, -72417.1467200766,
> 653484.35126587, -92648.7460098199, -3233.32465660806, 29345.5325340027,
> 0, -235276.123635367, -8085.28062041313, -176715.661475211, 28852.7921834861,
> -90712.8139977853, 6684.15438538088, 0, 23091.3502385902, 5613.30618173497,
> 388409.673062188, 103551.158151142, 279437.371614545, -25657.936438231,
> 0, -347163.239371664, -638401.61934589, 431570.6795893, 395023.302773711,
> -433195.627571962, -18972.8105174433, 0, -506739.285553855, 395763.737022434,
> -268305.679979052, 53499.6681794225, 260010.994180304, -38900.1802124548,
> 0, -8975.7698143267, 197713.712651446, -167425.915160878, 225029.030931452,
> -426574.040247294, 709.951980378177, 344.39282972583, 189443.5367389,
> -28896.2889688424, 139032.37432649, 190205.441708241, 16487.735835022,
> -477.381837819444, -0.0390000000000044, 209528.834861704, 566730.674885216,
> 322575.907703106, 38636.8911420965, -313533.21349995, -13272.940665971,
> 0, 43989.4999869042, 73377.5778304944, 306212.048794163, 5923.18822185303,
> -224098.632883127, -22864.2598605881, 0, 586585.190280267, 228930.634138658,
> 409478.407704985, 146902.113837214, -433899.909484737, -1366475.59274039,
> -1046202.31417455, -1978777.99743019, -746205.453746535, -1678781.13700218,
> -1358507.85843634, -2291083.54169199, -443600.229484737, -1376175.91274039,
> -1055902.63417455, -1988478.31743019, -755905.773746534, -1688481.45700218,
> -1368208.17843634, -2300783.86169199, 1658798.83218968, 726223.148934031,
> 1046496.42749987, 113920.74424422, 1346493.28792788, 413917.604672233,
> 734190.883238072, -198384.800017578, 1649098.51218968, 716522.828934031,
> 1036796.10749987, 104220.42424422, 1336792.96792788, 404217.284672233,
> 724490.563238072, -208085.120017578, -390490.461315715, -1323066.14457136,
> -1002792.86600552, -1935368.54926117, -702796.005577512, -1635371.68883316,
> -1315098.41026732, -2247674.09352297, -400190.781315715, -1332766.46457136,
> -1012493.18600552, -1945068.86926117, -712496.325577512, -1645072.00883316,
> -1324798.73026732, -2257374.41352297, 1702208.2803587, 769632.597103054,
> 1089905.87566889, 157330.192413242, 1389902.7360969, 457327.052841255,
> 777600.331407096, -154975.351848555, 1692507.9603587, 759932.277103054,
> 1080205.55566889, 147629.872413242, 1380202.4160969, 447626.732841255,
> 767900.011407096, -164675.671848556, -422680.6084808, -1355256.29173645,
> -1034983.01317061, -1967558.69642626, -734986.152742597, -1667561.83599825,
> -1347288.55743241, -2279864.24068805, -432380.9284808, -1364956.61173645,
> -1044683.33317061, -1977259.01642626, -744686.472742597, -1677262.15599825,
> -1356988.87743241, -2289564.56068806, 1670018.13319361, 737442.449937968,
> 1057715.72850381, 125140.045248157, 1357712.58893182, 425136.905676171,
> 745410.184242009, -187165.499013641, 1660317.81319361, 727742.129937968,
> 1048015.40850381, 115439.725248157, 1348012.26893182, 415436.585676171,
> 735709.864242009, -196865.819013641, -379271.160311777, -1311846.84356743,
> -991573.565001587, -1924149.24825723, -691576.704573575, -1624152.38782922,
> -1303879.10926338, -2236454.79251903, -388971.480311777, -1321547.16356743,
> -1001273.88500159, -1933849.56825723, -701277.024573575, -1633852.70782922,
> -1313579.42926338, -2246155.11251903, 1713427.58136264, 780851.898106991,
> 1101125.17667283, 168549.493417179, 1401122.03710084, 468546.353845192,
> 788819.632411033, -143756.050844618, 1703727.26136264, 771151.578106991,
> 1091424.85667283, 158849.173417179, 1391421.71710084, 458846.033845192,
> 779119.312411033, -153456.370844618, 24092.4629115268, -908483.220344123,
> -588209.941778283, -1520785.62503393, -288213.081350271, -1220788.76460592,
> -900515.486040081, -1833091.16929573, 14392.1429115268, -918183.540344123,
> -597910.261778283, -1530485.94503393, -297913.401350271, -1230489.08460592,
> -910215.806040081, -1842791.48929573, 2116791.20458594, 1184215.52133029,
> 1504488.79989613, 571913.116640484, 1804485.66032414, 871909.977068497,
> 1192183.25563434, 259607.572378685, 2107090.88458594, 1174515.20133029,
> 1494788.47989613, 562212.796640484, 1794785.34032415, 862209.657068496,
> 1182482.93563434, 249907.252378685, 67501.911080549, -865073.7721751,
> -544800.493609261, -1477376.17686491, -244803.633181249, -1177379.3164369,
> -857106.037871058, -1789681.7211267, 57801.591080549, -874774.0921751,
> -554500.813609261, -1487076.49686491, -254503.953181249, -1187079.6364369,
> -866806.357871058, -1799382.0411267, 2160200.65275497, 1227624.96949932,
> 1547898.24806516, 615322.564809505, 1847895.10849317, 915319.425237518,
> 1235592.70380336, 303017.020547708, 2150500.33275497, 1217924.64949932,
> 1538197.92806516, 605622.244809506, 1838194.78849317, 905619.105237518,
> 1225892.38380336, 293316.700547708, 35311.7639154639, -897263.919340186,
> -576990.640774346, -1509566.32402999, -276993.780346334, -1209569.46360198,
> -889296.185036144, -1821871.86829179, 25611.4439154639, -906964.239340186,
> -586690.960774346, -1519266.64402999, -286694.100346334, -1219269.78360198,
> -898996.505036144, -1831572.18829179, 2128010.50558988, 1195434.82233423,
> 1515708.10090007, 583132.417644421, 1815704.96132808, 883129.278072434,
> 1203402.55663827, 270826.873382623, 2118310.18558988, 1185734.50233423,
> 1506007.78090007, 573432.097644421, 1806004.64132808, 873428.958072433,
> 1193702.23663827, 261126.553382623, 78721.2120844861, -853854.471171163,
> -533581.192605324, -1466156.87586097, -233584.332177312, -1166160.01543296,
> -845886.736867121, -1778462.42012277, 69020.8920844861, -863554.791171163,
> -543281.512605324, -1475857.19586097, -243284.652177312, -1175860.33543296,
> -855587.056867121, -1788162.74012277, 2171419.9537589, 1238844.27050325,
> 1559117.54906909, 626541.865813442, 1859114.40949711, 926538.726241455,
> 1246812.0048073, 314236.321551645, 2161719.6337589, 1229143.95050325,
> 1549417.2290691, 616841.545813442, 1849414.0894971, 916838.406241455,
> 1237111.6848073, 304536.001551645)
>
> Now, with hist() function, I have 2 observations -
>
> > hist(x, breaks = 18, plot = FALSE)$breaks
>  [1] -4500000 -4000000 -3500000 -3000000 -2500000 -2000000 -1500000
> -1000000  -500000        0   500000  1000000  1500000  2000000
> 2500000  3000000
> [17]  3500000
> > hist(x, breaks = 20, plot = FALSE)$breaks
>  [1] -4500000 -4000000 -3500000 -3000000 -2500000 -2000000 -1500000
> -1000000  -500000        0   500000  1000000  1500000  2000000
> 2500000  3000000
> [17]  3500000
>
> When I had breaks = 18, I get total number of cells as 16, which is
> same when I put breaks = 20
>
> In the 2nd case I was expecting total number of cells (i.e. bars) as
> 20 i.e. if I understand the documentation correctly I should expect
> total number of cells (bars) should be same as breaks argument in
> hist() function.
>
> How to make that happen?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S@E|||@on @end|ng |rom LGCGroup@com  Wed Sep 18 13:13:59 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Wed, 18 Sep 2019 11:13:59 +0000
Subject: [R] How to use breaks argument in hist() function correctly?
In-Reply-To: <CA+dpOJ=HyuC-+PruyTJh7ypE7p4bfO5NRKNf=Y3Y+QnQEzeTFg@mail.gmail.com>
References: <CA+dpOJ=HyuC-+PruyTJh7ypE7p4bfO5NRKNf=Y3Y+QnQEzeTFg@mail.gmail.com>
Message-ID: <6be8672780584fe8b922700f43198187@GBDCVPEXC08.corp.lgc-group.com>

> When I had breaks = 18, I get total number of cells as 16, which is
> same when I put breaks = 20
>
> In the 2nd case I was expecting total number of cells (i.e. bars) as
> 20 i.e. if I understand the documentation correctly I should expect
> total number of cells (bars) should be same as breaks argument in
> hist() function.

You do not _quite_ understand the documentation correctly.
?hist says
"In the last three cases the number is a suggestion only; as
the breakpoints will be set to 'pretty' values"
That includes specification of a single number of breaks.

> How to make that happen?
Specify a vector of breaks with 20 intervals (21 values). 
For example,
breaks=seq(-4500000, 3500000, length.out=21)
This gives a bin width of 4e5. 

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From r@oknz @end|ng |rom gm@||@com  Wed Sep 18 13:13:39 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 18 Sep 2019 23:13:39 +1200
Subject: [R] regex
In-Reply-To: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
References: <47065ea2-bbf3-acf7-b857-565df0773943@rgzm.de>
Message-ID: <CABcYAd+AM1rHgcFefz_2jUBN41HBTFZj-ewpWK=bCdwY5FWyRw@mail.gmail.com>

A little note on quoting in regular expressions.
I find writing \\. when I want a quoted . somewhat confusing,
so I would use the pattern "_w_.*[.]csv$".

Better still, if you want to match file names,
there is a function glob2rx that converts shell ("glob")
patterns into regular expression patterns.  Thus
> grep(glob2rx("*_w_*.csv"), myfiles, value=TRUE)
[1] "BU-072_1_E1_RE_SEC-01_local_w_0.2_0.2.csv"
[2] "BU-072_1_E1_RE_SEC-01_local_w_0.2_0.6.csv"
[3] "BU-072_1_E1_RE_SEC-01_local_w_0.4_1.0.csv"
[4] "BU-072_1_E1_RE_SEC-01_local_w_1.0_0.2.csv"
[5] "BU-072_1_E1_RE_SEC-01_local_w_1.0_0.6.csv"
[6] "BU-072_1_E1_RE_SEC-01_local_w_1.0_1.0.csv"

So the simplest way to get what you want is
CSVs <- list.files(path=..., pattern=glob2rx("*_w_*.csv"))

In fact ?list.files mentions glob2rx.


On Tue, 17 Sep 2019 at 18:49, Ivan Calandra <calandra at rgzm.de> wrote:

> Dear useRs,
>
> I still have problems using regular expressions. I have two problems for
> which I have found workarounds, but I'm sure there are better ways of
> doing it.
>
> 1) list CSV files with "_w_" in the name
>
> Here is a sample of the files in the folder:
> myfiles <- c("BU-072_1_E1_RE_SEC-01_local_a_0.2_0.2.csv",
> "BU-072_1_E1_RE_SEC-01_local_a_0.2_0.6.csv","BU-072_1_E1_RE_SEC-01_local_a_0.4_1.0.csv",
>
> "BU-072_1_E1_RE_SEC-01_local_a_1.0_0.2.csv","BU-072_1_E1_RE_SEC-01_local_a_1.0_0.6.csv",
>
> "BU-072_1_E1_RE_SEC-01_local_w_0.2_0.2.csv","BU-072_1_E1_RE_SEC-01_local_w_0.2_0.6.csv",
>
> "BU-072_1_E1_RE_SEC-01_local_w_0.4_1.0.csv","BU-072_1_E1_RE_SEC-01_local_w_1.0_0.2.csv",
>
> "BU-072_1_E1_RE_SEC-01_local_w_1.0_0.6.csv","BU-072_1_E1_RE_SEC-01_local_w_1.0_1.0.csv",
>
> "BU-072_1_E1_RE_SEC-01_local_a_0.2_0.2.xls","BU-072_1_E1_RE_SEC-01_local_a_0.2_0.6.xls",
>
> "BU-072_1_E1_RE_SEC-01_local_a_0.4_1.0.xls","BU-072_1_E1_RE_SEC-01_local_a_1.0_0.2.xls",
>
> "BU-072_1_E1_RE_SEC-01_local_a_1.0_0.6.xls","BU-072_1_E1_RE_SEC-01_local_w_0.2_0.2.xls",
>
> "BU-072_1_E1_RE_SEC-01_local_w_0.2_0.6.xls","BU-072_1_E1_RE_SEC-01_local_w_0.4_1.0.xls",
>
> "BU-072_1_E1_RE_SEC-01_local_w_1.0_0.2.xls","BU-072_1_E1_RE_SEC-01_local_w_1.0_0.6.xls",
>
> "BU-072_1_E1_RE_SEC-01_local_w_1.0_1.0.xls")
>
> Here is what I did: CSVs <- list.files(path=..., pattern="\\.csv$")
> w.files <- CSVs[grep(pattern="_w_", CSVs)]
>
> Of course, what I would like to do is list only the interesting files
> from the beginning, rather than subsetting the whole list of files. In
> other words, having a pattern that includes both "\\.csv$" and "_w_" in
> the list.files() call. I tried "_w_&\\.csv$" but it returns an empty
> vector.
>
> 2) The units of the variables are given in the original headers. I would
> like to extract the units. This is what I did: headers <- c("dist to
> origin on curve [mm]","segment on section [mm]", "angle 1 [degree]",
> "angle 2 [degree]","angle 3 [degree]") units.var <-
> gsub(pattern="^.*\\[|\\]$", "", headers)
>
> It seems to be to overly complicated using gsub(). Isn't there a way to
> extract what is interesting rather than deleting what is not?
>
> Thank you for your help! Best, Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From huze|@@kh@||| @end|ng |rom um|ch@edu  Wed Sep 18 14:43:23 2019
From: huze|@@kh@||| @end|ng |rom um|ch@edu (Huzefa Khalil)
Date: Wed, 18 Sep 2019 08:43:23 -0400
Subject: [R] Help needed with eval parse
Message-ID: <CADsG8gMidfhzNDuLiMXgt3pQptrjenXNwborMqkwM+ae3G1DKw@mail.gmail.com>

Hello R-users,

I have been running a script which produces objects based on the
column names of a data.frame. The column names are of the form CB_1-1,
CB_1-2, etc. Now this calculation was rather long and memory
intensive, so I would rather not have to do it again after fixing the
column names using "make.names". As a consequence, I am left with a
bunch of R objects with `-` in the name.
Accessing them is proving challenging and any help would be appreciated.

Reproducible example:
`cb_1-2` <- "hello world"
t <- "cb_1-2"
t <- as.name(t)
t <- eval(parse(text = t))

Error in eval(parse(text = t)) : object 'cb_1' not found

Thanks.
huzefa


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep 18 16:05:58 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 18 Sep 2019 10:05:58 -0400
Subject: [R] Help needed with eval parse
In-Reply-To: <CADsG8gMidfhzNDuLiMXgt3pQptrjenXNwborMqkwM+ae3G1DKw@mail.gmail.com>
References: <CADsG8gMidfhzNDuLiMXgt3pQptrjenXNwborMqkwM+ae3G1DKw@mail.gmail.com>
Message-ID: <5568f35d-3eb0-a2fb-88b9-d41131a66f99@gmail.com>

On 18/09/2019 8:43 a.m., Huzefa Khalil wrote:
> Hello R-users,
> 
> I have been running a script which produces objects based on the
> column names of a data.frame. The column names are of the form CB_1-1,
> CB_1-2, etc. Now this calculation was rather long and memory
> intensive, so I would rather not have to do it again after fixing the
> column names using "make.names". As a consequence, I am left with a
> bunch of R objects with `-` in the name.
> Accessing them is proving challenging and any help would be appreciated.
> 
> Reproducible example:
> `cb_1-2` <- "hello world"
> t <- "cb_1-2"
> t <- as.name(t)
> t <- eval(parse(text = t))
> 
> Error in eval(parse(text = t)) : object 'cb_1' not found

After t <- as.name(t), you already have language:  no need to parse it 
again.  So

   eval(t)

works.  If you have more complicated expressions, use call() to set them 
?p.  For example, call("paste0", t, "!") evaluates to

   paste0(`cb_1-2`, "!")

and evaluating that expression via

   eval(call("paste0", t, "!"))

gives

[1] "hello world!"

Don't go back and forth between language objects and text 
representations of them, because it's hard to do that without 
introducing changes.  In other words, don't use eval(parse()).

Duncan Murdoch


From huze|@@kh@||| @end|ng |rom um|ch@edu  Wed Sep 18 16:30:16 2019
From: huze|@@kh@||| @end|ng |rom um|ch@edu (Huzefa Khalil)
Date: Wed, 18 Sep 2019 10:30:16 -0400
Subject: [R] Help needed with eval parse
In-Reply-To: <5568f35d-3eb0-a2fb-88b9-d41131a66f99@gmail.com>
References: <CADsG8gMidfhzNDuLiMXgt3pQptrjenXNwborMqkwM+ae3G1DKw@mail.gmail.com>
 <5568f35d-3eb0-a2fb-88b9-d41131a66f99@gmail.com>
Message-ID: <CADsG8gN3hVCfke2g3JPKdGdx-W69e-2DjU0si0cxzS4RHZ4nCg@mail.gmail.com>

That worked! Thanks for the explanation.

On Wed, Sep 18, 2019 at 10:06 AM Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> On 18/09/2019 8:43 a.m., Huzefa Khalil wrote:
> > Hello R-users,
> >
> > I have been running a script which produces objects based on the
> > column names of a data.frame. The column names are of the form CB_1-1,
> > CB_1-2, etc. Now this calculation was rather long and memory
> > intensive, so I would rather not have to do it again after fixing the
> > column names using "make.names". As a consequence, I am left with a
> > bunch of R objects with `-` in the name.
> > Accessing them is proving challenging and any help would be appreciated.
> >
> > Reproducible example:
> > `cb_1-2` <- "hello world"
> > t <- "cb_1-2"
> > t <- as.name(t)
> > t <- eval(parse(text = t))
> >
> > Error in eval(parse(text = t)) : object 'cb_1' not found
>
> After t <- as.name(t), you already have language:  no need to parse it
> again.  So
>
>    eval(t)
>
> works.  If you have more complicated expressions, use call() to set them
> ?p.  For example, call("paste0", t, "!") evaluates to
>
>    paste0(`cb_1-2`, "!")
>
> and evaluating that expression via
>
>    eval(call("paste0", t, "!"))
>
> gives
>
> [1] "hello world!"
>
> Don't go back and forth between language objects and text
> representations of them, because it's hard to do that without
> introducing changes.  In other words, don't use eval(parse()).
>
> Duncan Murdoch


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Sep 18 16:47:41 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 18 Sep 2019 14:47:41 +0000 (UTC)
Subject: [R] Not the same length
In-Reply-To: <62B8499F-3519-4CFB-8E23-6FBDDB92C5DE@gmail.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
 <62B8499F-3519-4CFB-8E23-6FBDDB92C5DE@gmail.com>
Message-ID: <131501993.12284244.1568818061750@mail.yahoo.com>

Dear Peter Dalgaard,

Really appreciated, but my code does not work. There is still a problem ! Here below the reproducible example with 20 variables


library(mgcv) 
library(earth) 
n<-2000 
x<-runif(n, 0, 5) 
z <- rnorm(n, 2, 3) 
a <- runif(n, 0, 5) 
b <- rnorm(n, 2, 3) 
c <- runif(n, 0, 5) 
d <- rnorm(n, 2, 3) 
e <- runif(n, 0, 5) 
f <- rnorm(n, 2, 3) 
g <- runif(n, 0, 5) 
h <- rnorm(n, 2, 3) 
i <-runif(n, 0, 5) 
j <-rnorm(n, 2, 3) 
k <-runif(n, 0, 5) 
l <-rnorm(n, 2, 3) 
m <-runif(n, 0, 5)
 n <-rnorm(n, 2, 3) 
o <-runif(n, 0, 5) 
p <-rnorm(n, 2, 3) 
q <-runif(n, 0, 5) 
r <-rnorm(n, 2, 3) ? 
y_model<- 0.1*x^3 - 0.5 * z^2 - a^2 + b^2 + 2*c + 3*d - 4*e + 3.5*f - 4.5*g+ 2.5*h + 5.5*i^2 -1.5*j - 6*k + l + 2*m + n + 3*o - 4.5*p + q - r + 10 
y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) ) ? 
gam_model<- gam(y_obs~s(x)+s(z)+s(a)+s(b)+s(c)+s(d)+s(e)+s(f)+s(g)+s(h)+s(i)+s(j)+s(k)+s(l)+s(m)+s(n)+s(o)+s(p)+s(q)+s(r)) 
mars_model<-earth(y_obs~x+z+a+b+c+d+e+f+g+h+i+j+k+l+m+n+o+p+q+r) ? 
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
MSE_MARS<-mean((mars_model$fitted.values - y_model)^2) ? 
MSE_GAM 
MSE_MARS






Le mercredi 18 septembre 2019 ? 11:04:26 UTC+2, peter dalgaard <pdalgd at gmail.com> a ?crit : 





Um, I think not... The mean of the last 200 observation won't line up with the x and z. 

Possibly, if what you want is the last 200 obs to have a different variance, 

y_obs <- y_model + c(rnorm(0.9 * n, 0, 0.1), rnorm(0.1 * n, 0, 0.5))

or

y_obs <- rnorm(n, y_model, rep(c(0.1, 0.5), c(.9 * n, .1 * n)))

-pd


> On 17 Sep 2019, at 22:27 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On 9/17/19 12:48 PM, varin sacha via R-help wrote:
>> Dear R-helpers,
>> 
>> Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
>> How can I solve the problem ?
>> 
>> Here is the reproducible R code
>> 
>>? #? #? #? #? #? #? #? #? #? #
>> library(mgcv)
>>? library(earth)
>> 
>> n<-2000
>> x<-runif(n, 0, 5)
>>? y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10
>> # y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) # maybe not exactly your goal?
> 
> 
> You didn't lay out any goals for analysis, so let me guess what was intended:
> 
> 
> I suspect that you were hoping to model a mixture composed of 90% from one distribution and 10% from another. If I'm right about that guess then you would instead wat to join the samples from each distribution:
> 
> y_obs<-c( rnorm(n*0.9, y_model, 0.1),? rnorm(n*0.1, y_model, 0.5) )
> 
> -- 
> 
> David
> 
> 
>> gam_model<- gam(y_obs~s(x))
>> mars_model<- earth(y_obs~x)
>> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
>> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
>> MSE_GAM
>> MSE_MARS
>>? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Wed Sep 18 19:07:38 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 18 Sep 2019 19:07:38 +0200
Subject: [R] Not the same length
In-Reply-To: <131501993.12284244.1568818061750@mail.yahoo.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
 <62B8499F-3519-4CFB-8E23-6FBDDB92C5DE@gmail.com>
 <131501993.12284244.1568818061750@mail.yahoo.com>
Message-ID: <40642370-D475-47CE-B08D-55CF3AA45911@gmail.com>

Redefining n is probably not a good idea...

[...snip...]
> m <-runif(n, 0, 5)
> n <-rnorm(n, 2, 3) 

Oops! n is now a vector of length 2000.

[...snip...]

> y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) )

now length(n*0.97) == 2000 > 1, so rnorm(n*0.97, ...) gets you a length 2000 vector (check ?rnorm), and  c() of 2 of those is a vector of length 4000.

[...etc...]
>   
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From @n@cre@m @end|ng |rom gm@||@com  Tue Sep 17 22:12:34 2019
From: @n@cre@m @end|ng |rom gm@||@com (Ana PGG)
Date: Tue, 17 Sep 2019 22:12:34 +0200
Subject: [R] Not the same length
In-Reply-To: <889918375.11729611.1568749733508@mail.yahoo.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
Message-ID: <5d813e32.1c69fb81.a644f.97fc@mx.google.com>

Dear Varin Sacha,

My guess to try to help you is the following:

I think you may want to change this: 
y_obs <- rnorm(n*0.9, y_model, 0.1) + rnorm(n*0.1, y_model, 0.5) 
for:
y_obs <- c( rnorm(n*0.9, y_model, 0.1), rnorm(n*0.1, y_model, 0.5) )
then y_obs:

> length(y_obs)
[1] 2000


De: varin sacha via R-help
Enviado: martes, 17 de septiembre de 2019 21:49
Para: R-help Mailing List
Asunto: [R] Not the same length

Dear R-helpers,

Doing dput(x) and dput(y_obs), the 2 vectors are not the same length (1800 for y_obs and 2000 for x)
How can I solve the problem ??

Here is the reproducible R code 

? #? #? #? #? #? #? #? #? #? #
library(mgcv) 
 library(earth) 

n<-2000 
x<-runif(n, 0, 5) ? 
 y_model<- 0.1*x^3 - 0.5 * x^2 - x + 10 ? 
y_obs<-rnorm(n*0.9, y_model, 0.1)+rnorm(n*0.1, y_model, 0.5) 
gam_model<- gam(y_obs~s(x)) 
mars_model<- earth(y_obs~x) ? 
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
MSE_MARS<-mean((mars_model$fitted.values - y_model)^2) ? 
MSE_GAM 
MSE_MARS
? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #? #

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From benj@m|n@|@ng @end|ng |rom crg@eu  Wed Sep 18 08:00:00 2019
From: benj@m|n@|@ng @end|ng |rom crg@eu (Benjamin Lang)
Date: Wed, 18 Sep 2019 08:00:00 +0200
Subject: [R] The "--slave" option
Message-ID: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>

Dear R project,

I have a very simple question:

How, in late 2019, is there an option called "--slave" to "make R run as
quietly as possible"?

Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
R was presumably developed, based on its atrocious syntax, documentation
and usability (I think I only need to say "NaN", "NULL", and "NA").

This is a disgrace and it should have been addressed one or two decades
ago. Why not just "--quiet"?

Please do not mention "backwards compatibility". For the historically
inclined, it does not make much of a difference whether the term evokes the
Roman, Greek, American or modern kind of slavery for you: it is as
disgusting as it gets.

Thank you,
Ben

-- 
Benjamin Lang, PhD
http://orcid.org/0000-0001-6358-8380

Marie Sklodowska-Curie Postdoctoral Fellow (MSCA-IF)
Gene Function and Evolution (Dr. Gian Tartaglia)
Centre for Genomic Regulation (CRG), Barcelona, Spain

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Wed Sep 18 20:57:32 2019
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Wed, 18 Sep 2019 14:57:32 -0400
Subject: [R] The "--slave" option
In-Reply-To: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
Message-ID: <CAJc=yOHmZrMA1T7t2xnjwY_GA16ZuNH9nG0+-RzhOTddNdS_tg@mail.gmail.com>

For what it's worth, this is an ongoing conversation in computer
science and engineering. And has been so for decades.

Not R, but related to this it's only in the past few months that a
fork of the photo-manipulation software GIMP (slur for handicapped)
renames it (GLIMPSE).

Note, I am not saying this isn't a battle worth fighting.

On Wed, Sep 18, 2019 at 1:52 PM Benjamin Lang <benjamin.lang at crg.eu> wrote:
>
> Dear R project,
>
> I have a very simple question:
>
> How, in late 2019, is there an option called "--slave" to "make R run as
> quietly as possible"?
>
> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
> R was presumably developed, based on its atrocious syntax, documentation
> and usability (I think I only need to say "NaN", "NULL", and "NA").
>
> This is a disgrace and it should have been addressed one or two decades
> ago. Why not just "--quiet"?
>
> Please do not mention "backwards compatibility". For the historically
> inclined, it does not make much of a difference whether the term evokes the
> Roman, Greek, American or modern kind of slavery for you: it is as
> disgusting as it gets.
>
> Thank you,
> Ben
>
> --
> Benjamin Lang, PhD
> http://orcid.org/0000-0001-6358-8380
>
> Marie Sklodowska-Curie Postdoctoral Fellow (MSCA-IF)
> Gene Function and Evolution (Dr. Gian Tartaglia)
> Centre for Genomic Regulation (CRG), Barcelona, Spain
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Sep 18 22:29:58 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 18 Sep 2019 20:29:58 +0000 (UTC)
Subject: [R] Not the same length
In-Reply-To: <40642370-D475-47CE-B08D-55CF3AA45911@gmail.com>
References: <889918375.11729611.1568749733508.ref@mail.yahoo.com>
 <889918375.11729611.1568749733508@mail.yahoo.com>
 <690d9d1f-8fd1-b2be-b389-fb571af83c15@comcast.net>
 <62B8499F-3519-4CFB-8E23-6FBDDB92C5DE@gmail.com>
 <131501993.12284244.1568818061750@mail.yahoo.com>
 <40642370-D475-47CE-B08D-55CF3AA45911@gmail.com>
Message-ID: <1192240459.12506751.1568838598342@mail.yahoo.com>

Argggg ! What a pity, I have not seen it ! Many thanks !



Le mercredi 18 septembre 2019 ? 19:07:42 UTC+2, peter dalgaard <pdalgd at gmail.com> a ?crit : 





Redefining n is probably not a good idea...

[...snip...]
> m <-runif(n, 0, 5)
> n <-rnorm(n, 2, 3) 

Oops! n is now a vector of length 2000.

[...snip...]

> y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) )

now length(n*0.97) == 2000 > 1, so rnorm(n*0.97, ...) gets you a length 2000 vector (check ?rnorm), and? c() of 2 of those is a vector of length 4000.

[...etc...]

>? 
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com


From knoxy1827 @end|ng |rom gm@||@com  Tue Sep 17 18:55:31 2019
From: knoxy1827 @end|ng |rom gm@||@com (Thomas Knox)
Date: Tue, 17 Sep 2019 17:55:31 +0100
Subject: [R] Problem loading packages in R 3.6.1
Message-ID: <1CF01761-9E5B-43A0-A85A-BDE1CF11B254@gmail.com>

I have recently installed R 3.6.1 on my MacBook running Mac OS Mojave 10.14.5 in order to run a custom package called MH1823 (probability of detection).  This package requires me to load the following packages from CRAN, tcltk, tcltk2, survival and xlsx.

I have installed survival, xlsx and tlctk2 (i believe tcltk is embedded).  When I look at Package Manager i see that although the above packages are installed they are not loaded.  I can load survival but when I try to load ?xlsx? i get the following  error message is:

Error: package or namespace load failed for ?xlsx?:
 .onLoad failed in loadNamespace() for 'rJava', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so, 6): Library not loaded: /Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so
  Reason: image not found
starting httpd help server ? done


there may be a couple of hints in here.

 .onLoad failed in loadNamespace() for 'rJava', details  suggests the problem starts with calling rJava.

the next line in the error:
error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
I have checked this path and see no problems, everything seems to stack up and I find jJava.so where it is supposed to be.  However in the next line:
 dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so, 6): Library not loaded: /Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
I don?t know what the number , 6 after Java.so means but have presumed version number and may be why Java8 is not working.  I also note the path ?. /JavaVirtualMachines/jdk-11.0.1.jdk/ appears as . /JavaVirtualMachines/1.6.0.jdk/
suggesting a different build

the same occurs when I try to load the local source package MH1823

When I try to load HM1823 I get the error message:
* installing *source* package ?mh1823? ...
** using staged installation
** R
** data
** inst
** byte-compile and prepare package for lazy loading
Error: package or namespace load failed for ?xlsx?:
 .onLoad failed in loadNamespace() for 'rJava', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so, 6): Library not loaded: /Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so
  Reason: image not found
Error: package ?xlsx? could not be loaded
Execution halted
ERROR: lazy loading failed for package ?mh1823?
* removing ?/Library/Frameworks/R.framework/Versions/3.6/Resources/library/mh1823?
> 

I find that the error message is substantially the same suggesting rJava and/or the version of Java.  I have tried removing Java 8 from my machine and installing Java 6 but don?t see any difference.  It is easy to see that Java 8 has been removed but not easy to see that 6 is installed properly as the path names are still the same.

When I try to load either tcltk or tcltk2, my instance of R stops responding entirely.

I have also installed Xquartz as I believe this is needed for Mac OS X

Can anyone provide some advice on what the issue might be?  I have tried reading through the FAQ?s but not found anything to point me in the right direction.

Regards,

Tom Knox
	[[alternative HTML version deleted]]


From p@tze|t @end|ng |rom g@h@rv@rd@edu  Wed Sep 18 21:22:01 2019
From: p@tze|t @end|ng |rom g@h@rv@rd@edu (Patzelt, Edward)
Date: Wed, 18 Sep 2019 14:22:01 -0500
Subject: [R] Data conversion
Message-ID: <CAB9UfhTRMT_H9cnkz4-X8F+fsx_M9zTWgU6-Wbmn-P52t+BBVw@mail.gmail.com>

Hi R Help,

How would I convert the data below so that I have it formatted with trials
along the rows and then each type of measure separately? e.g.,
            Subject RT OnOff Feedback
Trial_1
Trial_2
Trial_3
Trial_4

Thanks!

Edward





structure(list(TAP_ID = "967372   ", TAP_Date = NA_real_, TAP_Time = 29700,
    TAP_Study = "                      ", SexOfTarget = "M",
    SexOfSubj = "M", OperatorName = "                ", LowThresh = 220,
    HighThresh = 1320, Trial1 = 1, Trial2 = 2, Trial3 = 3, Trial4 = 4,
    Trial5 = 5, Trial6 = 6, Trial7 = 7, Trial8 = 8, Trial9 = 9,
    Trial10 = 10, Trial11 = 11, Trial12 = 12, Trial13 = 13, Trial14 = 14,
    Trial15 = 15, Trial16 = 16, Trial17 = 17, Trial18 = 18, Trial19 = 19,
    Trial20 = 20, Trial21 = 21, Trial22 = 22, Trial23 = 23, Trial24 = 24,
    Trial25 = 25, Trial26 = 26, Trial27 = 27, Trial28 = 28, ITI1 = 5,
    ITI2 = 5, ITI3 = 5, ITI4 = 5, ITI5 = 5, ITI6 = 5, ITI7 = 5,
    ITI8 = 5, ITI9 = 5, ITI10 = 5, ITI11 = 5, ITI12 = 5, ITI13 = 5,
    ITI14 = 5, ITI15 = 5, ITI16 = 5, ITI17 = 5, ITI18 = 5, ITI19 = 5,
    ITI20 = 5, ITI21 = 5, ITI22 = 5, ITI23 = 5, ITI24 = 5, ITI25 = 5,
    ITI26 = 5, ITI27 = 5, ITI28 = 5, Shock1 = 0, Shock2 = 0,
    Shock3 = 0, Shock4 = 0, Shock5 = 0, Shock6 = 0, Shock7 = 0,
    Shock8 = 0, Shock9 = 0, Shock10 = 0, Shock11 = 0, Shock12 = 0,
    Shock13 = 0, Shock14 = 0, Shock15 = 0, Shock16 = 0, Shock17 = 0,
    Shock18 = 0, Shock19 = 0, Shock20 = 0, Shock21 = 0, Shock22 = 0,
    Shock23 = 0, Shock24 = 0, Shock25 = 0, Shock26 = 0, Shock27 = 0,
    Shock28 = 0, Delay1 = 1102, Delay2 = 993, Delay3 = 446, Delay4 = 613,
    Delay5 = 649, Delay6 = 333, Delay7 = 342, Delay8 = 366, Delay9 = 360,
    Delay10 = 307, Delay11 = 372, Delay12 = 335, Delay13 = 328,
    Delay14 = 296, Delay15 = 521, Delay16 = 393, Delay17 = 491,
    Delay18 = 467, Delay19 = 401, Delay20 = 483, Delay21 = 312,
    Delay22 = 311, Delay23 = 274, Delay24 = 348, Delay25 = 422,
    Delay26 = 305, Delay27 = 637, Delay28 = 429, Hold1 = 1203,
    Hold2 = 598, Hold3 = 1209, Hold4 = 1373, Hold5 = 1170, Hold6 = 1442,
    Hold7 = 2192, Hold8 = 1802, Hold9 = 1891, Hold10 = 1880,
    Hold11 = 1204, Hold12 = 1597, Hold13 = 809, Hold14 = 848,
    Hold15 = 1328, Hold16 = 767, Hold17 = 1053, Hold18 = 1648,
    Hold19 = 1365, Hold20 = 1889, Hold21 = 1452, Hold22 = 1468,
    Hold23 = 1595, Hold24 = 2060, Hold25 = 1213, Hold26 = 1060,
    Hold27 = 745, Hold28 = 1110, RTdelay1 = 800, RTdelay2 = 251,
    RTdelay3 = 422, RTdelay4 = 264, RTdelay5 = 397, RTdelay6 = 472,
    RTdelay7 = 225, RTdelay8 = 228, RTdelay9 = 430, RTdelay10 = 527,
    RTdelay11 = 244, RTdelay12 = 747, RTdelay13 = 269, RTdelay14 = 330,
    RTdelay15 = 400, RTdelay16 = 401, RTdelay17 = 394, RTdelay18 = 364,
    RTdelay19 = 210, RTdelay20 = 415, RTdelay21 = 267, RTdelay22 = 248,
    RTdelay23 = 209, RTdelay24 = 277, RTdelay25 = 498, RTdelay26 = 663,
    RTdelay27 = 331, RTdelay28 = 494, RTheld1 = 2318, RTheld2 = 2039,
    RTheld3 = 2594, RTheld4 = 2061, RTheld5 = 1501, RTheld6 = 1070,
    RTheld7 = 2492, RTheld8 = 1532, RTheld9 = 2034, RTheld10 = 2338,
    RTheld11 = 1095, RTheld12 = 2227, RTheld13 = 2402, RTheld14 = 1057,
    RTheld15 = 1718, RTheld16 = 1789, RTheld17 = 1611, RTheld18 = 1824,
    RTheld19 = 1582, RTheld20 = 2749, RTheld21 = 1407, RTheld22 = 1780,
    RTheld23 = 1103, RTheld24 = 1513, RTheld25 = 1562, RTheld26 = 2283,
    RTheld27 = 2722, RTheld28 = 2703, RT1 = 284, RT2 = 228, RT3 = 226,
    RT4 = 186, RT5 = 208, RT6 = 223, RT7 = 206, RT8 = 189, RT9 = 229,
    RT10 = 198, RT11 = 224, RT12 = 203, RT13 = 199, RT14 = 224,
    RT15 = 220, RT16 = 208, RT17 = 270, RT18 = 188, RT19 = 205,
    RT20 = 191, RT21 = 190, RT22 = 183, RT23 = 193, RT24 = 176,
    RT25 = 195, RT26 = 196, RT27 = 185, RT28 = 160, Feedback1 = 2,
    Feedback2 = 2, Feedback3 = 3, Feedback4 = 3, Feedback5 = 2,
    Feedback6 = 3, Feedback7 = 4, Feedback8 = 5, Feedback9 = 5,
    Feedback10 = 6, Feedback11 = 5, Feedback12 = 6, Feedback13 = 6,
    Feedback14 = 7, Feedback15 = 9, Feedback16 = 8, Feedback17 = 9,
    Feedback18 = 8, Feedback19 = 8, Feedback20 = 9, Feedback21 = 20,
    Feedback22 = 9, Feedback23 = 8, Feedback24 = 9, Feedback25 = 8,
    Feedback26 = 8, Feedback27 = 9, Feedback28 = 8, OnOff1 = 1,
    OnOff2 = 0, OnOff3 = 0, OnOff4 = 1, OnOff5 = 0, OnOff6 = 1,
    OnOff7 = 0, OnOff8 = 0, OnOff9 = 1, OnOff10 = 1, OnOff11 = 0,
    OnOff12 = 1, OnOff13 = 0, OnOff14 = 1, OnOff15 = 1, OnOff16 = 0,
    OnOff17 = 1, OnOff18 = 0, OnOff19 = 1, OnOff20 = 0, OnOff21 = 0,
    OnOff22 = 1, OnOff23 = 0, OnOff24 = 1, OnOff25 = 0, OnOff26 = 1,
    OnOff27 = 0, OnOff28 = 1), class = "data.frame", row.names = c(NA,
-1L), variable.labels = c(TAP_ID = "", TAP_Date = "", TAP_Time = "",
TAP_Study = "", SexOfTarget = "", SexOfSubj = "", OperatorName = "",
LowThresh = "", HighThresh = "", Trial1 = "Trial number 1", Trial2 = "Trial
number 2",
Trial3 = "Trial number 3", Trial4 = "Trial number 4", Trial5 = "Trial
number 5",
Trial6 = "Trial number 6", Trial7 = "Trial number 7", Trial8 = "Trial
number 8",
Trial9 = "Trial number 9", Trial10 = "Trial number 10", Trial11 = "Trial
number 11",
Trial12 = "Trial number 12", Trial13 = "Trial number 13", Trial14 = "Trial
number 14",
Trial15 = "Trial number 15", Trial16 = "Trial number 16", Trial17 = "Trial
number 17",
Trial18 = "Trial number 18", Trial19 = "Trial number 19", Trial20 = "Trial
number 20",
Trial21 = "Trial number 21", Trial22 = "Trial number 22", Trial23 = "Trial
number 23",
Trial24 = "Trial number 24", Trial25 = "Trial number 25", Trial26 = "Trial
number 26",
Trial27 = "Trial number 27", Trial28 = "Trial number 28", ITI1 = "ITI in
seconds = time between end of trial to beginning of next trial  1",
ITI2 = "ITI in seconds = time between end of trial to beginning of next
trial  2",
ITI3 = "ITI in seconds = time between end of trial to beginning of next
trial  3",
ITI4 = "ITI in seconds = time between end of trial to beginning of next
trial  4",
ITI5 = "ITI in seconds = time between end of trial to beginning of next
trial  5",
ITI6 = "ITI in seconds = time between end of trial to beginning of next
trial  6",
ITI7 = "ITI in seconds = time between end of trial to beginning of next
trial  7",
ITI8 = "ITI in seconds = time between end of trial to beginning of next
trial  8",
ITI9 = "ITI in seconds = time between end of trial to beginning of next
trial  9",
ITI10 = "ITI in seconds = time between end of trial to beginning of next
trial  10",
ITI11 = "ITI in seconds = time between end of trial to beginning of next
trial  11",
ITI12 = "ITI in seconds = time between end of trial to beginning of next
trial  12",
ITI13 = "ITI in seconds = time between end of trial to beginning of next
trial  13",
ITI14 = "ITI in seconds = time between end of trial to beginning of next
trial  14",
ITI15 = "ITI in seconds = time between end of trial to beginning of next
trial  15",
ITI16 = "ITI in seconds = time between end of trial to beginning of next
trial  16",
ITI17 = "ITI in seconds = time between end of trial to beginning of next
trial  17",
ITI18 = "ITI in seconds = time between end of trial to beginning of next
trial  18",
ITI19 = "ITI in seconds = time between end of trial to beginning of next
trial  19",
ITI20 = "ITI in seconds = time between end of trial to beginning of next
trial  20",
ITI21 = "ITI in seconds = time between end of trial to beginning of next
trial  21",
ITI22 = "ITI in seconds = time between end of trial to beginning of next
trial  22",
ITI23 = "ITI in seconds = time between end of trial to beginning of next
trial  23",
ITI24 = "ITI in seconds = time between end of trial to beginning of next
trial  24",
ITI25 = "ITI in seconds = time between end of trial to beginning of next
trial  25",
ITI26 = "ITI in seconds = time between end of trial to beginning of next
trial  26",
ITI27 = "ITI in seconds = time between end of trial to beginning of next
trial  27",
ITI28 = "ITI in seconds = time between end of trial to beginning of next
trial  28",
Shock1 = "Shock selection = our primary DV  1", Shock2 = "Shock selection =
our primary DV  2",
Shock3 = "Shock selection = our primary DV  3", Shock4 = "Shock selection =
our primary DV  4",
Shock5 = "Shock selection = our primary DV  5", Shock6 = "Shock selection =
our primary DV  6",
Shock7 = "Shock selection = our primary DV  7", Shock8 = "Shock selection =
our primary DV  8",
Shock9 = "Shock selection = our primary DV  9", Shock10 = "Shock selection
= our primary DV  10",
Shock11 = "Shock selection = our primary DV  11", Shock12 = "Shock
selection = our primary DV  12",
Shock13 = "Shock selection = our primary DV  13", Shock14 = "Shock
selection = our primary DV  14",
Shock15 = "Shock selection = our primary DV  15", Shock16 = "Shock
selection = our primary DV  16",
Shock17 = "Shock selection = our primary DV  17", Shock18 = "Shock
selection = our primary DV  18",
Shock19 = "Shock selection = our primary DV  19", Shock20 = "Shock
selection = our primary DV  20",
Shock21 = "Shock selection = our primary DV  21", Shock22 = "Shock
selection = our primary DV  22",
Shock23 = "Shock selection = our primary DV  23", Shock24 = "Shock
selection = our primary DV  24",
Shock25 = "Shock selection = our primary DV  25", Shock26 = "Shock
selection = our primary DV  26",
Shock27 = "Shock selection = our primary DV  27", Shock28 = "Shock
selection = our primary DV  28",
Delay1 = "Select switch delay (msec) = time from ?set? to select shock 1",
Delay2 = "Select switch delay (msec) = time from ?set? to select shock 2",
Delay3 = "Select switch delay (msec) = time from ?set? to select shock 3",
Delay4 = "Select switch delay (msec) = time from ?set? to select shock 4",
Delay5 = "Select switch delay (msec) = time from ?set? to select shock 5",
Delay6 = "Select switch delay (msec) = time from ?set? to select shock 6",
Delay7 = "Select switch delay (msec) = time from ?set? to select shock 7",
Delay8 = "Select switch delay (msec) = time from ?set? to select shock 8",
Delay9 = "Select switch delay (msec) = time from ?set? to select shock 9",
Delay10 = "Select switch delay (msec) = time from ?set? to select shock
10",
Delay11 = "Select switch delay (msec) = time from ?set? to select shock
11",
Delay12 = "Select switch delay (msec) = time from ?set? to select shock
12",
Delay13 = "Select switch delay (msec) = time from ?set? to select shock
13",
Delay14 = "Select switch delay (msec) = time from ?set? to select shock
14",
Delay15 = "Select switch delay (msec) = time from ?set? to select shock
15",
Delay16 = "Select switch delay (msec) = time from ?set? to select shock
16",
Delay17 = "Select switch delay (msec) = time from ?set? to select shock
17",
Delay18 = "Select switch delay (msec) = time from ?set? to select shock
18",
Delay19 = "Select switch delay (msec) = time from ?set? to select shock
19",
Delay20 = "Select switch delay (msec) = time from ?set? to select shock
20",
Delay21 = "Select switch delay (msec) = time from ?set? to select shock
21",
Delay22 = "Select switch delay (msec) = time from ?set? to select shock
22",
Delay23 = "Select switch delay (msec) = time from ?set? to select shock
23",
Delay24 = "Select switch delay (msec) = time from ?set? to select shock
24",
Delay25 = "Select switch delay (msec) = time from ?set? to select shock
25",
Delay26 = "Select switch delay (msec) = time from ?set? to select shock
26",
Delay27 = "Select switch delay (msec) = time from ?set? to select shock
27",
Delay28 = "Select switch delay (msec) = time from ?set? to select shock
28",
Hold1 = "Select switch hold (msec) = how long select button held 1",
Hold2 = "Select switch hold (msec) = how long select button held 2",
Hold3 = "Select switch hold (msec) = how long select button held 3",
Hold4 = "Select switch hold (msec) = how long select button held 4",
Hold5 = "Select switch hold (msec) = how long select button held 5",
Hold6 = "Select switch hold (msec) = how long select button held 6",
Hold7 = "Select switch hold (msec) = how long select button held 7",
Hold8 = "Select switch hold (msec) = how long select button held 8",
Hold9 = "Select switch hold (msec) = how long select button held 9",
Hold10 = "Select switch hold (msec) = how long select button held 10",
Hold11 = "Select switch hold (msec) = how long select button held 11",
Hold12 = "Select switch hold (msec) = how long select button held 12",
Hold13 = "Select switch hold (msec) = how long select button held 13",
Hold14 = "Select switch hold (msec) = how long select button held 14",
Hold15 = "Select switch hold (msec) = how long select button held 15",
Hold16 = "Select switch hold (msec) = how long select button held 16",
Hold17 = "Select switch hold (msec) = how long select button held 17",
Hold18 = "Select switch hold (msec) = how long select button held 18",
Hold19 = "Select switch hold (msec) = how long select button held 19",
Hold20 = "Select switch hold (msec) = how long select button held 20",
Hold21 = "Select switch hold (msec) = how long select button held 21",
Hold22 = "Select switch hold (msec) = how long select button held 22",
Hold23 = "Select switch hold (msec) = how long select button held 23",
Hold24 = "Select switch hold (msec) = how long select button held 24",
Hold25 = "Select switch hold (msec) = how long select button held 25",
Hold26 = "Select switch hold (msec) = how long select button held 26",
Hold27 = "Select switch hold (msec) = how long select button held 27",
Hold28 = "Select switch hold (msec) = how long select button held 28",
RTdelay1 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  1",
RTdelay2 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  2",
RTdelay3 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  3",
RTdelay4 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  4",
RTdelay5 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  5",
RTdelay6 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  6",
RTdelay7 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  7",
RTdelay8 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  8",
RTdelay9 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  9",
RTdelay10 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  10",
RTdelay11 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  11",
RTdelay12 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  12",
RTdelay13 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  13",
RTdelay14 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  14",
RTdelay15 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  15",
RTdelay16 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  16",
RTdelay17 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  17",
RTdelay18 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  18",
RTdelay19 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  19",
RTdelay20 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  20",
RTdelay21 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  21",
RTdelay22 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  22",
RTdelay23 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  23",
RTdelay24 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  24",
RTdelay25 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  25",
RTdelay26 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  26",
RTdelay27 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  27",
RTdelay28 = "RT switch delay (msec) = time from ?press? to holding ?press?
button down  28",
RTheld1 = "Foreperiod duration (msec) = time RT (?press?) button held down
1",
RTheld2 = "Foreperiod duration (msec) = time RT (?press?) button held down
2",
RTheld3 = "Foreperiod duration (msec) = time RT (?press?) button held down
3",
RTheld4 = "Foreperiod duration (msec) = time RT (?press?) button held down
4",
RTheld5 = "Foreperiod duration (msec) = time RT (?press?) button held down
5",
RTheld6 = "Foreperiod duration (msec) = time RT (?press?) button held down
6",
RTheld7 = "Foreperiod duration (msec) = time RT (?press?) button held down
7",
RTheld8 = "Foreperiod duration (msec) = time RT (?press?) button held down
8",
RTheld9 = "Foreperiod duration (msec) = time RT (?press?) button held down
9",
RTheld10 = "Foreperiod duration (msec) = time RT (?press?) button held down
10",
RTheld11 = "Foreperiod duration (msec) = time RT (?press?) button held down
11",
RTheld12 = "Foreperiod duration (msec) = time RT (?press?) button held down
12",
RTheld13 = "Foreperiod duration (msec) = time RT (?press?) button held down
13",
RTheld14 = "Foreperiod duration (msec) = time RT (?press?) button held down
14",
RTheld15 = "Foreperiod duration (msec) = time RT (?press?) button held down
15",
RTheld16 = "Foreperiod duration (msec) = time RT (?press?) button held down
16",
RTheld17 = "Foreperiod duration (msec) = time RT (?press?) button held down
17",
RTheld18 = "Foreperiod duration (msec) = time RT (?press?) button held down
18",
RTheld19 = "Foreperiod duration (msec) = time RT (?press?) button held down
19",
RTheld20 = "Foreperiod duration (msec) = time RT (?press?) button held down
20",
RTheld21 = "Foreperiod duration (msec) = time RT (?press?) button held down
21",
RTheld22 = "Foreperiod duration (msec) = time RT (?press?) button held down
22",
RTheld23 = "Foreperiod duration (msec) = time RT (?press?) button held down
23",
RTheld24 = "Foreperiod duration (msec) = time RT (?press?) button held down
24",
RTheld25 = "Foreperiod duration (msec) = time RT (?press?) button held down
25",
RTheld26 = "Foreperiod duration (msec) = time RT (?press?) button held down
26",
RTheld27 = "Foreperiod duration (msec) = time RT (?press?) button held down
27",
RTheld28 = "Foreperiod duration (msec) = time RT (?press?) button held down
28",
RT1 = "Reaction Time (msec) time from signal to releasing ?press? button
1",
RT2 = "Reaction Time (msec) time from signal to releasing ?press? button
2",
RT3 = "Reaction Time (msec) time from signal to releasing ?press? button
3",
RT4 = "Reaction Time (msec) time from signal to releasing ?press? button
4",
RT5 = "Reaction Time (msec) time from signal to releasing ?press? button
5",
RT6 = "Reaction Time (msec) time from signal to releasing ?press? button
6",
RT7 = "Reaction Time (msec) time from signal to releasing ?press? button
7",
RT8 = "Reaction Time (msec) time from signal to releasing ?press? button
8",
RT9 = "Reaction Time (msec) time from signal to releasing ?press? button
9",
RT10 = "Reaction Time (msec) time from signal to releasing ?press? button
10",
RT11 = "Reaction Time (msec) time from signal to releasing ?press? button
11",
RT12 = "Reaction Time (msec) time from signal to releasing ?press? button
12",
RT13 = "Reaction Time (msec) time from signal to releasing ?press? button
13",
RT14 = "Reaction Time (msec) time from signal to releasing ?press? button
14",
RT15 = "Reaction Time (msec) time from signal to releasing ?press? button
15",
RT16 = "Reaction Time (msec) time from signal to releasing ?press? button
16",
RT17 = "Reaction Time (msec) time from signal to releasing ?press? button
17",
RT18 = "Reaction Time (msec) time from signal to releasing ?press? button
18",
RT19 = "Reaction Time (msec) time from signal to releasing ?press? button
19",
RT20 = "Reaction Time (msec) time from signal to releasing ?press? button
20",
RT21 = "Reaction Time (msec) time from signal to releasing ?press? button
21",
RT22 = "Reaction Time (msec) time from signal to releasing ?press? button
22",
RT23 = "Reaction Time (msec) time from signal to releasing ?press? button
23",
RT24 = "Reaction Time (msec) time from signal to releasing ?press? button
24",
RT25 = "Reaction Time (msec) time from signal to releasing ?press? button
25",
RT26 = "Reaction Time (msec) time from signal to releasing ?press? button
26",
RT27 = "Reaction Time (msec) time from signal to releasing ?press? button
27",
RT28 = "Reaction Time (msec) time from signal to releasing ?press? button
28",
Feedback1 = "Feedback (shock) 1", Feedback2 = "Feedback (shock) 2",
Feedback3 = "Feedback (shock) 3", Feedback4 = "Feedback (shock) 4",
Feedback5 = "Feedback (shock) 5", Feedback6 = "Feedback (shock) 6",
Feedback7 = "Feedback (shock) 7", Feedback8 = "Feedback (shock) 8",
Feedback9 = "Feedback (shock) 9", Feedback10 = "Feedback (shock) 10",
Feedback11 = "Feedback (shock) 11", Feedback12 = "Feedback (shock) 12",
Feedback13 = "Feedback (shock) 13", Feedback14 = "Feedback (shock) 14",
Feedback15 = "Feedback (shock) 15", Feedback16 = "Feedback (shock) 16",
Feedback17 = "Feedback (shock) 17", Feedback18 = "Feedback (shock) 18",
Feedback19 = "Feedback (shock) 19", Feedback20 = "Feedback (shock) 20",
Feedback21 = "Feedback (shock) 21", Feedback22 = "Feedback (shock) 22",
Feedback23 = "Feedback (shock) 23", Feedback24 = "Feedback (shock) 24",
Feedback25 = "Feedback (shock) 25", Feedback26 = "Feedback (shock) 26",
Feedback27 = "Feedback (shock) 27", Feedback28 = "Feedback (shock) 28",
OnOff1 = "Shock on (1) or off (0) 1", OnOff2 = "Shock on (1) or off (0) 2",
OnOff3 = "Shock on (1) or off (0) 3", OnOff4 = "Shock on (1) or off (0) 4",
OnOff5 = "Shock on (1) or off (0) 5", OnOff6 = "Shock on (1) or off (0) 6",
OnOff7 = "Shock on (1) or off (0) 7", OnOff8 = "Shock on (1) or off (0) 8",
OnOff9 = "Shock on (1) or off (0) 9", OnOff10 = "Shock on (1) or off (0)
10",
OnOff11 = "Shock on (1) or off (0) 11", OnOff12 = "Shock on (1) or off (0)
12",
OnOff13 = "Shock on (1) or off (0) 13", OnOff14 = "Shock on (1) or off (0)
14",
OnOff15 = "Shock on (1) or off (0) 15", OnOff16 = "Shock on (1) or off (0)
16",
OnOff17 = "Shock on (1) or off (0) 17", OnOff18 = "Shock on (1) or off (0)
18",
OnOff19 = "Shock on (1) or off (0) 19", OnOff20 = "Shock on (1) or off (0)
20",
OnOff21 = "Shock on (1) or off (0) 21", OnOff22 = "Shock on (1) or off (0)
22",
OnOff23 = "Shock on (1) or off (0) 23", OnOff24 = "Shock on (1) or off (0)
24",
OnOff25 = "Shock on (1) or off (0) 25", OnOff26 = "Shock on (1) or off (0)
26",
OnOff27 = "Shock on (1) or off (0) 27", OnOff28 = "Shock on (1) or off (0)
28"
), codepage = 65001L)

-- 
Edward H Patzelt, PhD
Postdoctoral Fellow | Chicago DBT Institute <https://www.cdbti.com>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 18 23:43:07 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Sep 2019 07:43:07 +1000
Subject: [R] Data conversion
In-Reply-To: <CAB9UfhTRMT_H9cnkz4-X8F+fsx_M9zTWgU6-Wbmn-P52t+BBVw@mail.gmail.com>
References: <CAB9UfhTRMT_H9cnkz4-X8F+fsx_M9zTWgU6-Wbmn-P52t+BBVw@mail.gmail.com>
Message-ID: <CA+8X3fV4HCZomL-D_aCXE7crgng5maDj76Oqm0xeap1uU9U7uw@mail.gmail.com>

Hi Edward,
Say your "data frame" is named "epdat". This may do it:

epmat<-matrix(epdat[10:289],nrow=28)
colnames(epmat)<-sub("1","",names(epdat[10:289])[seq(1,270,by=28)])

This one looks like the Sorceror's Apprentice tangled with one of
those experimental schedule scripting programs.

Jim

On Thu, Sep 19, 2019 at 7:04 AM Patzelt, Edward <patzelt at g.harvard.edu> wrote:
>
> Hi R Help,
>
> How would I convert the data below so that I have it formatted with trials
> along the rows and then each type of measure separately? e.g.,
>             Subject RT OnOff Feedback
> Trial_1
> Trial_2
> Trial_3
> Trial_4
>
> Thanks!
>
> Edward
>
>
>
>
>
> structure(list(TAP_ID = "967372   ", TAP_Date = NA_real_, TAP_Time = 29700,
>     TAP_Study = "                      ", SexOfTarget = "M",
>     SexOfSubj = "M", OperatorName = "                ", LowThresh = 220,
>     HighThresh = 1320, Trial1 = 1, Trial2 = 2, Trial3 = 3, Trial4 = 4,
>     Trial5 = 5, Trial6 = 6, Trial7 = 7, Trial8 = 8, Trial9 = 9,
>     Trial10 = 10, Trial11 = 11, Trial12 = 12, Trial13 = 13, Trial14 = 14,
>     Trial15 = 15, Trial16 = 16, Trial17 = 17, Trial18 = 18, Trial19 = 19,
>     Trial20 = 20, Trial21 = 21, Trial22 = 22, Trial23 = 23, Trial24 = 24,
>     Trial25 = 25, Trial26 = 26, Trial27 = 27, Trial28 = 28, ITI1 = 5,
>     ITI2 = 5, ITI3 = 5, ITI4 = 5, ITI5 = 5, ITI6 = 5, ITI7 = 5,
>     ITI8 = 5, ITI9 = 5, ITI10 = 5, ITI11 = 5, ITI12 = 5, ITI13 = 5,
>     ITI14 = 5, ITI15 = 5, ITI16 = 5, ITI17 = 5, ITI18 = 5, ITI19 = 5,
>     ITI20 = 5, ITI21 = 5, ITI22 = 5, ITI23 = 5, ITI24 = 5, ITI25 = 5,
>     ITI26 = 5, ITI27 = 5, ITI28 = 5, Shock1 = 0, Shock2 = 0,
>     Shock3 = 0, Shock4 = 0, Shock5 = 0, Shock6 = 0, Shock7 = 0,
>     Shock8 = 0, Shock9 = 0, Shock10 = 0, Shock11 = 0, Shock12 = 0,
>     Shock13 = 0, Shock14 = 0, Shock15 = 0, Shock16 = 0, Shock17 = 0,
>     Shock18 = 0, Shock19 = 0, Shock20 = 0, Shock21 = 0, Shock22 = 0,
>     Shock23 = 0, Shock24 = 0, Shock25 = 0, Shock26 = 0, Shock27 = 0,
>     Shock28 = 0, Delay1 = 1102, Delay2 = 993, Delay3 = 446, Delay4 = 613,
>     Delay5 = 649, Delay6 = 333, Delay7 = 342, Delay8 = 366, Delay9 = 360,
>     Delay10 = 307, Delay11 = 372, Delay12 = 335, Delay13 = 328,
>     Delay14 = 296, Delay15 = 521, Delay16 = 393, Delay17 = 491,
>     Delay18 = 467, Delay19 = 401, Delay20 = 483, Delay21 = 312,
>     Delay22 = 311, Delay23 = 274, Delay24 = 348, Delay25 = 422,
>     Delay26 = 305, Delay27 = 637, Delay28 = 429, Hold1 = 1203,
>     Hold2 = 598, Hold3 = 1209, Hold4 = 1373, Hold5 = 1170, Hold6 = 1442,
>     Hold7 = 2192, Hold8 = 1802, Hold9 = 1891, Hold10 = 1880,
>     Hold11 = 1204, Hold12 = 1597, Hold13 = 809, Hold14 = 848,
>     Hold15 = 1328, Hold16 = 767, Hold17 = 1053, Hold18 = 1648,
>     Hold19 = 1365, Hold20 = 1889, Hold21 = 1452, Hold22 = 1468,
>     Hold23 = 1595, Hold24 = 2060, Hold25 = 1213, Hold26 = 1060,
>     Hold27 = 745, Hold28 = 1110, RTdelay1 = 800, RTdelay2 = 251,
>     RTdelay3 = 422, RTdelay4 = 264, RTdelay5 = 397, RTdelay6 = 472,
>     RTdelay7 = 225, RTdelay8 = 228, RTdelay9 = 430, RTdelay10 = 527,
>     RTdelay11 = 244, RTdelay12 = 747, RTdelay13 = 269, RTdelay14 = 330,
>     RTdelay15 = 400, RTdelay16 = 401, RTdelay17 = 394, RTdelay18 = 364,
>     RTdelay19 = 210, RTdelay20 = 415, RTdelay21 = 267, RTdelay22 = 248,
>     RTdelay23 = 209, RTdelay24 = 277, RTdelay25 = 498, RTdelay26 = 663,
>     RTdelay27 = 331, RTdelay28 = 494, RTheld1 = 2318, RTheld2 = 2039,
>     RTheld3 = 2594, RTheld4 = 2061, RTheld5 = 1501, RTheld6 = 1070,
>     RTheld7 = 2492, RTheld8 = 1532, RTheld9 = 2034, RTheld10 = 2338,
>     RTheld11 = 1095, RTheld12 = 2227, RTheld13 = 2402, RTheld14 = 1057,
>     RTheld15 = 1718, RTheld16 = 1789, RTheld17 = 1611, RTheld18 = 1824,
>     RTheld19 = 1582, RTheld20 = 2749, RTheld21 = 1407, RTheld22 = 1780,
>     RTheld23 = 1103, RTheld24 = 1513, RTheld25 = 1562, RTheld26 = 2283,
>     RTheld27 = 2722, RTheld28 = 2703, RT1 = 284, RT2 = 228, RT3 = 226,
>     RT4 = 186, RT5 = 208, RT6 = 223, RT7 = 206, RT8 = 189, RT9 = 229,
>     RT10 = 198, RT11 = 224, RT12 = 203, RT13 = 199, RT14 = 224,
>     RT15 = 220, RT16 = 208, RT17 = 270, RT18 = 188, RT19 = 205,
>     RT20 = 191, RT21 = 190, RT22 = 183, RT23 = 193, RT24 = 176,
>     RT25 = 195, RT26 = 196, RT27 = 185, RT28 = 160, Feedback1 = 2,
>     Feedback2 = 2, Feedback3 = 3, Feedback4 = 3, Feedback5 = 2,
>     Feedback6 = 3, Feedback7 = 4, Feedback8 = 5, Feedback9 = 5,
>     Feedback10 = 6, Feedback11 = 5, Feedback12 = 6, Feedback13 = 6,
>     Feedback14 = 7, Feedback15 = 9, Feedback16 = 8, Feedback17 = 9,
>     Feedback18 = 8, Feedback19 = 8, Feedback20 = 9, Feedback21 = 20,
>     Feedback22 = 9, Feedback23 = 8, Feedback24 = 9, Feedback25 = 8,
>     Feedback26 = 8, Feedback27 = 9, Feedback28 = 8, OnOff1 = 1,
>     OnOff2 = 0, OnOff3 = 0, OnOff4 = 1, OnOff5 = 0, OnOff6 = 1,
>     OnOff7 = 0, OnOff8 = 0, OnOff9 = 1, OnOff10 = 1, OnOff11 = 0,
>     OnOff12 = 1, OnOff13 = 0, OnOff14 = 1, OnOff15 = 1, OnOff16 = 0,
>     OnOff17 = 1, OnOff18 = 0, OnOff19 = 1, OnOff20 = 0, OnOff21 = 0,
>     OnOff22 = 1, OnOff23 = 0, OnOff24 = 1, OnOff25 = 0, OnOff26 = 1,
>     OnOff27 = 0, OnOff28 = 1), class = "data.frame", row.names = c(NA,
> -1L), variable.labels = c(TAP_ID = "", TAP_Date = "", TAP_Time = "",
> TAP_Study = "", SexOfTarget = "", SexOfSubj = "", OperatorName = "",
> LowThresh = "", HighThresh = "", Trial1 = "Trial number 1", Trial2 = "Trial
> number 2",
> Trial3 = "Trial number 3", Trial4 = "Trial number 4", Trial5 = "Trial
> number 5",
> Trial6 = "Trial number 6", Trial7 = "Trial number 7", Trial8 = "Trial
> number 8",
> Trial9 = "Trial number 9", Trial10 = "Trial number 10", Trial11 = "Trial
> number 11",
> Trial12 = "Trial number 12", Trial13 = "Trial number 13", Trial14 = "Trial
> number 14",
> Trial15 = "Trial number 15", Trial16 = "Trial number 16", Trial17 = "Trial
> number 17",
> Trial18 = "Trial number 18", Trial19 = "Trial number 19", Trial20 = "Trial
> number 20",
> Trial21 = "Trial number 21", Trial22 = "Trial number 22", Trial23 = "Trial
> number 23",
> Trial24 = "Trial number 24", Trial25 = "Trial number 25", Trial26 = "Trial
> number 26",
> Trial27 = "Trial number 27", Trial28 = "Trial number 28", ITI1 = "ITI in
> seconds = time between end of trial to beginning of next trial  1",
> ITI2 = "ITI in seconds = time between end of trial to beginning of next
> trial  2",
> ITI3 = "ITI in seconds = time between end of trial to beginning of next
> trial  3",
> ITI4 = "ITI in seconds = time between end of trial to beginning of next
> trial  4",
> ITI5 = "ITI in seconds = time between end of trial to beginning of next
> trial  5",
> ITI6 = "ITI in seconds = time between end of trial to beginning of next
> trial  6",
> ITI7 = "ITI in seconds = time between end of trial to beginning of next
> trial  7",
> ITI8 = "ITI in seconds = time between end of trial to beginning of next
> trial  8",
> ITI9 = "ITI in seconds = time between end of trial to beginning of next
> trial  9",
> ITI10 = "ITI in seconds = time between end of trial to beginning of next
> trial  10",
> ITI11 = "ITI in seconds = time between end of trial to beginning of next
> trial  11",
> ITI12 = "ITI in seconds = time between end of trial to beginning of next
> trial  12",
> ITI13 = "ITI in seconds = time between end of trial to beginning of next
> trial  13",
> ITI14 = "ITI in seconds = time between end of trial to beginning of next
> trial  14",
> ITI15 = "ITI in seconds = time between end of trial to beginning of next
> trial  15",
> ITI16 = "ITI in seconds = time between end of trial to beginning of next
> trial  16",
> ITI17 = "ITI in seconds = time between end of trial to beginning of next
> trial  17",
> ITI18 = "ITI in seconds = time between end of trial to beginning of next
> trial  18",
> ITI19 = "ITI in seconds = time between end of trial to beginning of next
> trial  19",
> ITI20 = "ITI in seconds = time between end of trial to beginning of next
> trial  20",
> ITI21 = "ITI in seconds = time between end of trial to beginning of next
> trial  21",
> ITI22 = "ITI in seconds = time between end of trial to beginning of next
> trial  22",
> ITI23 = "ITI in seconds = time between end of trial to beginning of next
> trial  23",
> ITI24 = "ITI in seconds = time between end of trial to beginning of next
> trial  24",
> ITI25 = "ITI in seconds = time between end of trial to beginning of next
> trial  25",
> ITI26 = "ITI in seconds = time between end of trial to beginning of next
> trial  26",
> ITI27 = "ITI in seconds = time between end of trial to beginning of next
> trial  27",
> ITI28 = "ITI in seconds = time between end of trial to beginning of next
> trial  28",
> Shock1 = "Shock selection = our primary DV  1", Shock2 = "Shock selection =
> our primary DV  2",
> Shock3 = "Shock selection = our primary DV  3", Shock4 = "Shock selection =
> our primary DV  4",
> Shock5 = "Shock selection = our primary DV  5", Shock6 = "Shock selection =
> our primary DV  6",
> Shock7 = "Shock selection = our primary DV  7", Shock8 = "Shock selection =
> our primary DV  8",
> Shock9 = "Shock selection = our primary DV  9", Shock10 = "Shock selection
> = our primary DV  10",
> Shock11 = "Shock selection = our primary DV  11", Shock12 = "Shock
> selection = our primary DV  12",
> Shock13 = "Shock selection = our primary DV  13", Shock14 = "Shock
> selection = our primary DV  14",
> Shock15 = "Shock selection = our primary DV  15", Shock16 = "Shock
> selection = our primary DV  16",
> Shock17 = "Shock selection = our primary DV  17", Shock18 = "Shock
> selection = our primary DV  18",
> Shock19 = "Shock selection = our primary DV  19", Shock20 = "Shock
> selection = our primary DV  20",
> Shock21 = "Shock selection = our primary DV  21", Shock22 = "Shock
> selection = our primary DV  22",
> Shock23 = "Shock selection = our primary DV  23", Shock24 = "Shock
> selection = our primary DV  24",
> Shock25 = "Shock selection = our primary DV  25", Shock26 = "Shock
> selection = our primary DV  26",
> Shock27 = "Shock selection = our primary DV  27", Shock28 = "Shock
> selection = our primary DV  28",
> Delay1 = "Select switch delay (msec) = time from ?set? to select shock 1",
> Delay2 = "Select switch delay (msec) = time from ?set? to select shock 2",
> Delay3 = "Select switch delay (msec) = time from ?set? to select shock 3",
> Delay4 = "Select switch delay (msec) = time from ?set? to select shock 4",
> Delay5 = "Select switch delay (msec) = time from ?set? to select shock 5",
> Delay6 = "Select switch delay (msec) = time from ?set? to select shock 6",
> Delay7 = "Select switch delay (msec) = time from ?set? to select shock 7",
> Delay8 = "Select switch delay (msec) = time from ?set? to select shock 8",
> Delay9 = "Select switch delay (msec) = time from ?set? to select shock 9",
> Delay10 = "Select switch delay (msec) = time from ?set? to select shock
> 10",
> Delay11 = "Select switch delay (msec) = time from ?set? to select shock
> 11",
> Delay12 = "Select switch delay (msec) = time from ?set? to select shock
> 12",
> Delay13 = "Select switch delay (msec) = time from ?set? to select shock
> 13",
> Delay14 = "Select switch delay (msec) = time from ?set? to select shock
> 14",
> Delay15 = "Select switch delay (msec) = time from ?set? to select shock
> 15",
> Delay16 = "Select switch delay (msec) = time from ?set? to select shock
> 16",
> Delay17 = "Select switch delay (msec) = time from ?set? to select shock
> 17",
> Delay18 = "Select switch delay (msec) = time from ?set? to select shock
> 18",
> Delay19 = "Select switch delay (msec) = time from ?set? to select shock
> 19",
> Delay20 = "Select switch delay (msec) = time from ?set? to select shock
> 20",
> Delay21 = "Select switch delay (msec) = time from ?set? to select shock
> 21",
> Delay22 = "Select switch delay (msec) = time from ?set? to select shock
> 22",
> Delay23 = "Select switch delay (msec) = time from ?set? to select shock
> 23",
> Delay24 = "Select switch delay (msec) = time from ?set? to select shock
> 24",
> Delay25 = "Select switch delay (msec) = time from ?set? to select shock
> 25",
> Delay26 = "Select switch delay (msec) = time from ?set? to select shock
> 26",
> Delay27 = "Select switch delay (msec) = time from ?set? to select shock
> 27",
> Delay28 = "Select switch delay (msec) = time from ?set? to select shock
> 28",
> Hold1 = "Select switch hold (msec) = how long select button held 1",
> Hold2 = "Select switch hold (msec) = how long select button held 2",
> Hold3 = "Select switch hold (msec) = how long select button held 3",
> Hold4 = "Select switch hold (msec) = how long select button held 4",
> Hold5 = "Select switch hold (msec) = how long select button held 5",
> Hold6 = "Select switch hold (msec) = how long select button held 6",
> Hold7 = "Select switch hold (msec) = how long select button held 7",
> Hold8 = "Select switch hold (msec) = how long select button held 8",
> Hold9 = "Select switch hold (msec) = how long select button held 9",
> Hold10 = "Select switch hold (msec) = how long select button held 10",
> Hold11 = "Select switch hold (msec) = how long select button held 11",
> Hold12 = "Select switch hold (msec) = how long select button held 12",
> Hold13 = "Select switch hold (msec) = how long select button held 13",
> Hold14 = "Select switch hold (msec) = how long select button held 14",
> Hold15 = "Select switch hold (msec) = how long select button held 15",
> Hold16 = "Select switch hold (msec) = how long select button held 16",
> Hold17 = "Select switch hold (msec) = how long select button held 17",
> Hold18 = "Select switch hold (msec) = how long select button held 18",
> Hold19 = "Select switch hold (msec) = how long select button held 19",
> Hold20 = "Select switch hold (msec) = how long select button held 20",
> Hold21 = "Select switch hold (msec) = how long select button held 21",
> Hold22 = "Select switch hold (msec) = how long select button held 22",
> Hold23 = "Select switch hold (msec) = how long select button held 23",
> Hold24 = "Select switch hold (msec) = how long select button held 24",
> Hold25 = "Select switch hold (msec) = how long select button held 25",
> Hold26 = "Select switch hold (msec) = how long select button held 26",
> Hold27 = "Select switch hold (msec) = how long select button held 27",
> Hold28 = "Select switch hold (msec) = how long select button held 28",
> RTdelay1 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  1",
> RTdelay2 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  2",
> RTdelay3 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  3",
> RTdelay4 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  4",
> RTdelay5 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  5",
> RTdelay6 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  6",
> RTdelay7 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  7",
> RTdelay8 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  8",
> RTdelay9 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  9",
> RTdelay10 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  10",
> RTdelay11 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  11",
> RTdelay12 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  12",
> RTdelay13 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  13",
> RTdelay14 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  14",
> RTdelay15 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  15",
> RTdelay16 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  16",
> RTdelay17 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  17",
> RTdelay18 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  18",
> RTdelay19 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  19",
> RTdelay20 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  20",
> RTdelay21 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  21",
> RTdelay22 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  22",
> RTdelay23 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  23",
> RTdelay24 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  24",
> RTdelay25 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  25",
> RTdelay26 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  26",
> RTdelay27 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  27",
> RTdelay28 = "RT switch delay (msec) = time from ?press? to holding ?press?
> button down  28",
> RTheld1 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 1",
> RTheld2 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 2",
> RTheld3 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 3",
> RTheld4 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 4",
> RTheld5 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 5",
> RTheld6 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 6",
> RTheld7 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 7",
> RTheld8 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 8",
> RTheld9 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 9",
> RTheld10 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 10",
> RTheld11 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 11",
> RTheld12 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 12",
> RTheld13 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 13",
> RTheld14 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 14",
> RTheld15 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 15",
> RTheld16 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 16",
> RTheld17 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 17",
> RTheld18 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 18",
> RTheld19 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 19",
> RTheld20 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 20",
> RTheld21 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 21",
> RTheld22 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 22",
> RTheld23 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 23",
> RTheld24 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 24",
> RTheld25 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 25",
> RTheld26 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 26",
> RTheld27 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 27",
> RTheld28 = "Foreperiod duration (msec) = time RT (?press?) button held down
> 28",
> RT1 = "Reaction Time (msec) time from signal to releasing ?press? button
> 1",
> RT2 = "Reaction Time (msec) time from signal to releasing ?press? button
> 2",
> RT3 = "Reaction Time (msec) time from signal to releasing ?press? button
> 3",
> RT4 = "Reaction Time (msec) time from signal to releasing ?press? button
> 4",
> RT5 = "Reaction Time (msec) time from signal to releasing ?press? button
> 5",
> RT6 = "Reaction Time (msec) time from signal to releasing ?press? button
> 6",
> RT7 = "Reaction Time (msec) time from signal to releasing ?press? button
> 7",
> RT8 = "Reaction Time (msec) time from signal to releasing ?press? button
> 8",
> RT9 = "Reaction Time (msec) time from signal to releasing ?press? button
> 9",
> RT10 = "Reaction Time (msec) time from signal to releasing ?press? button
> 10",
> RT11 = "Reaction Time (msec) time from signal to releasing ?press? button
> 11",
> RT12 = "Reaction Time (msec) time from signal to releasing ?press? button
> 12",
> RT13 = "Reaction Time (msec) time from signal to releasing ?press? button
> 13",
> RT14 = "Reaction Time (msec) time from signal to releasing ?press? button
> 14",
> RT15 = "Reaction Time (msec) time from signal to releasing ?press? button
> 15",
> RT16 = "Reaction Time (msec) time from signal to releasing ?press? button
> 16",
> RT17 = "Reaction Time (msec) time from signal to releasing ?press? button
> 17",
> RT18 = "Reaction Time (msec) time from signal to releasing ?press? button
> 18",
> RT19 = "Reaction Time (msec) time from signal to releasing ?press? button
> 19",
> RT20 = "Reaction Time (msec) time from signal to releasing ?press? button
> 20",
> RT21 = "Reaction Time (msec) time from signal to releasing ?press? button
> 21",
> RT22 = "Reaction Time (msec) time from signal to releasing ?press? button
> 22",
> RT23 = "Reaction Time (msec) time from signal to releasing ?press? button
> 23",
> RT24 = "Reaction Time (msec) time from signal to releasing ?press? button
> 24",
> RT25 = "Reaction Time (msec) time from signal to releasing ?press? button
> 25",
> RT26 = "Reaction Time (msec) time from signal to releasing ?press? button
> 26",
> RT27 = "Reaction Time (msec) time from signal to releasing ?press? button
> 27",
> RT28 = "Reaction Time (msec) time from signal to releasing ?press? button
> 28",
> Feedback1 = "Feedback (shock) 1", Feedback2 = "Feedback (shock) 2",
> Feedback3 = "Feedback (shock) 3", Feedback4 = "Feedback (shock) 4",
> Feedback5 = "Feedback (shock) 5", Feedback6 = "Feedback (shock) 6",
> Feedback7 = "Feedback (shock) 7", Feedback8 = "Feedback (shock) 8",
> Feedback9 = "Feedback (shock) 9", Feedback10 = "Feedback (shock) 10",
> Feedback11 = "Feedback (shock) 11", Feedback12 = "Feedback (shock) 12",
> Feedback13 = "Feedback (shock) 13", Feedback14 = "Feedback (shock) 14",
> Feedback15 = "Feedback (shock) 15", Feedback16 = "Feedback (shock) 16",
> Feedback17 = "Feedback (shock) 17", Feedback18 = "Feedback (shock) 18",
> Feedback19 = "Feedback (shock) 19", Feedback20 = "Feedback (shock) 20",
> Feedback21 = "Feedback (shock) 21", Feedback22 = "Feedback (shock) 22",
> Feedback23 = "Feedback (shock) 23", Feedback24 = "Feedback (shock) 24",
> Feedback25 = "Feedback (shock) 25", Feedback26 = "Feedback (shock) 26",
> Feedback27 = "Feedback (shock) 27", Feedback28 = "Feedback (shock) 28",
> OnOff1 = "Shock on (1) or off (0) 1", OnOff2 = "Shock on (1) or off (0) 2",
> OnOff3 = "Shock on (1) or off (0) 3", OnOff4 = "Shock on (1) or off (0) 4",
> OnOff5 = "Shock on (1) or off (0) 5", OnOff6 = "Shock on (1) or off (0) 6",
> OnOff7 = "Shock on (1) or off (0) 7", OnOff8 = "Shock on (1) or off (0) 8",
> OnOff9 = "Shock on (1) or off (0) 9", OnOff10 = "Shock on (1) or off (0)
> 10",
> OnOff11 = "Shock on (1) or off (0) 11", OnOff12 = "Shock on (1) or off (0)
> 12",
> OnOff13 = "Shock on (1) or off (0) 13", OnOff14 = "Shock on (1) or off (0)
> 14",
> OnOff15 = "Shock on (1) or off (0) 15", OnOff16 = "Shock on (1) or off (0)
> 16",
> OnOff17 = "Shock on (1) or off (0) 17", OnOff18 = "Shock on (1) or off (0)
> 18",
> OnOff19 = "Shock on (1) or off (0) 19", OnOff20 = "Shock on (1) or off (0)
> 20",
> OnOff21 = "Shock on (1) or off (0) 21", OnOff22 = "Shock on (1) or off (0)
> 22",
> OnOff23 = "Shock on (1) or off (0) 23", OnOff24 = "Shock on (1) or off (0)
> 24",
> OnOff25 = "Shock on (1) or off (0) 25", OnOff26 = "Shock on (1) or off (0)
> 26",
> OnOff27 = "Shock on (1) or off (0) 27", OnOff28 = "Shock on (1) or off (0)
> 28"
> ), codepage = 65001L)
>
> --
> Edward H Patzelt, PhD
> Postdoctoral Fellow | Chicago DBT Institute <https://www.cdbti.com>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 18 23:58:58 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Sep 2019 14:58:58 -0700
Subject: [R] The "--slave" option
In-Reply-To: <CAJc=yOHmZrMA1T7t2xnjwY_GA16ZuNH9nG0+-RzhOTddNdS_tg@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <CAJc=yOHmZrMA1T7t2xnjwY_GA16ZuNH9nG0+-RzhOTddNdS_tg@mail.gmail.com>
Message-ID: <120FCF35-CF2C-4AA8-9F70-E03233CF9964@dcn.davis.ca.us>

I think there is no confusion except in the minds of those with nothing better to do. I agree with Antirez, quoted in [1], which nevertheless indicates that perspective lost the debate.

Any accurate alternative notation will have similar connotations because in fact the "slave" side of that relationship is completely subordinate to the "master" side... there is no escaping that fact. It requires a very different and more complicated architecture to achieve a "peer" relationship, which often is not worth the effort or even appropriate.

So while Dr Lang may be mollified by a change in notation, someone else  is going to find the new words offensive and make the same PC argument since the implications of the architecture have not changed. In fact there should never have been a parallel drawn between the morality of human slavery and computing architectures to begin with.

[1] https://www.vice.com/en_us/article/8x7akv/masterslave-terminology-was-removed-from-python-programming-language

On September 18, 2019 11:57:32 AM PDT, "Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:
>For what it's worth, this is an ongoing conversation in computer
>science and engineering. And has been so for decades.
>
>Not R, but related to this it's only in the past few months that a
>fork of the photo-manipulation software GIMP (slur for handicapped)
>renames it (GLIMPSE).
>
>Note, I am not saying this isn't a battle worth fighting.
>
>On Wed, Sep 18, 2019 at 1:52 PM Benjamin Lang <benjamin.lang at crg.eu>
>wrote:
>>
>> Dear R project,
>>
>> I have a very simple question:
>>
>> How, in late 2019, is there an option called "--slave" to "make R run
>as
>> quietly as possible"?
>>
>> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970
>when
>> R was presumably developed, based on its atrocious syntax,
>documentation
>> and usability (I think I only need to say "NaN", "NULL", and "NA").
>>
>> This is a disgrace and it should have been addressed one or two
>decades
>> ago. Why not just "--quiet"?
>>
>> Please do not mention "backwards compatibility". For the historically
>> inclined, it does not make much of a difference whether the term
>evokes the
>> Roman, Greek, American or modern kind of slavery for you: it is as
>> disgusting as it gets.
>>
>> Thank you,
>> Ben
>>
>> --
>> Benjamin Lang, PhD
>> http://orcid.org/0000-0001-6358-8380
>>
>> Marie Sklodowska-Curie Postdoctoral Fellow (MSCA-IF)
>> Gene Function and Evolution (Dr. Gian Tartaglia)
>> Centre for Genomic Regulation (CRG), Barcelona, Spain
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Sep 19 01:10:09 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 19 Sep 2019 11:10:09 +1200
Subject: [R] The "--slave" option
In-Reply-To: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
Message-ID: <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>


On 18/09/19 6:00 PM, Benjamin Lang wrote:

> Dear R project,
> 
> I have a very simple question:
> 
> How, in late 2019, is there an option called "--slave" to "make R run as
> quietly as possible"?
> 
> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
> R was presumably developed, based on its atrocious syntax, documentation
> and usability (I think I only need to say "NaN", "NULL", and "NA").
> 
> This is a disgrace and it should have been addressed one or two decades
> ago. Why not just "--quiet"?
> 
> Please do not mention "backwards compatibility".

Personally I much prefer backwards compatibility to political correctness.

> For the historically
> inclined, it does not make much of a difference whether the term evokes the
> Roman, Greek, American or modern kind of slavery for you: it is as
> disgusting as it gets.

IMHO this is a precious PC quibble, taking offence where no offence is 
intended.

If you are really concerned about literal slavery --- as everyone should 
be --- then join/contribute to an appropriate activist organisation 
(e.g. Amnesty International, which is my personal choice).

cheers,

Rolf Turner


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @purd|e@@ @end|ng |rom gm@||@com  Thu Sep 19 07:10:14 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 19 Sep 2019 17:10:14 +1200
Subject: [R] The "--slave" option
In-Reply-To: <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
Message-ID: <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>

> Personally I much prefer backwards compatibility to political correctness.

I agree with Rolf, here.
And as someone that's planning to write a Linux Terminal Emulator, in
the medium-term future, I *strongly* defend this approach.

And to the original poster.
Haven't you seen The Matrix?
(Second best movie ever, after the Shawshank Redemption).

I would prefer the technology to be my slave, than I be a
prisoner/slave to the technology.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 19 10:11:17 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 19 Sep 2019 01:11:17 -0700
Subject: [R] Problem loading packages in R 3.6.1
In-Reply-To: <1CF01761-9E5B-43A0-A85A-BDE1CF11B254@gmail.com>
References: <1CF01761-9E5B-43A0-A85A-BDE1CF11B254@gmail.com>
Message-ID: <D94021B2-AC88-43EA-BAAA-7AF9A96BD8DB@dcn.davis.ca.us>

Since no answer has been forthcoming, my advice is to read the Posting Guide. There is a more appropriate list for your question, and you should take the warning about posting using plain text format on all r-project mailing lists seriously.

On September 17, 2019 9:55:31 AM PDT, Thomas Knox <knoxy1827 at gmail.com> wrote:
>I have recently installed R 3.6.1 on my MacBook running Mac OS Mojave
>10.14.5 in order to run a custom package called MH1823 (probability of
>detection).  This package requires me to load the following packages
>from CRAN, tcltk, tcltk2, survival and xlsx.
>
>I have installed survival, xlsx and tlctk2 (i believe tcltk is
>embedded).  When I look at Package Manager i see that although the
>above packages are installed they are not loaded.  I can load survival
>but when I try to load ?xlsx? i get the following  error message is:
>
>Error: package or namespace load failed for ?xlsx?:
> .onLoad failed in loadNamespace() for 'rJava', details:
>  call: dyn.load(file, DLLpath = DLLpath, ...)
>error: unable to load shared object
>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
>dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so,
>6): Library not loaded:
>/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
>Referenced from:
>/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so
>  Reason: image not found
>starting httpd help server ? done
>
>
>there may be a couple of hints in here.
>
>.onLoad failed in loadNamespace() for 'rJava', details  suggests the
>problem starts with calling rJava.
>
>the next line in the error:
>error: unable to load shared object
>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
>I have checked this path and see no problems, everything seems to stack
>up and I find jJava.so where it is supposed to be.  However in the next
>line:
>dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so,
>6): Library not loaded:
>/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
>I don?t know what the number , 6 after Java.so means but have presumed
>version number and may be why Java8 is not working.  I also note the
>path ?. /JavaVirtualMachines/jdk-11.0.1.jdk/ appears as .
>/JavaVirtualMachines/1.6.0.jdk/
>suggesting a different build
>
>the same occurs when I try to load the local source package MH1823
>
>When I try to load HM1823 I get the error message:
>* installing *source* package ?mh1823? ...
>** using staged installation
>** R
>** data
>** inst
>** byte-compile and prepare package for lazy loading
>Error: package or namespace load failed for ?xlsx?:
> .onLoad failed in loadNamespace() for 'rJava', details:
>  call: dyn.load(file, DLLpath = DLLpath, ...)
>error: unable to load shared object
>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
>dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so,
>6): Library not loaded:
>/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
>Referenced from:
>/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so
>  Reason: image not found
>Error: package ?xlsx? could not be loaded
>Execution halted
>ERROR: lazy loading failed for package ?mh1823?
>* removing
>?/Library/Frameworks/R.framework/Versions/3.6/Resources/library/mh1823?
>> 
>
>I find that the error message is substantially the same suggesting
>rJava and/or the version of Java.  I have tried removing Java 8 from my
>machine and installing Java 6 but don?t see any difference.  It is easy
>to see that Java 8 has been removed but not easy to see that 6 is
>installed properly as the path names are still the same.
>
>When I try to load either tcltk or tcltk2, my instance of R stops
>responding entirely.
>
>I have also installed Xquartz as I believe this is needed for Mac OS X
>
>Can anyone provide some advice on what the issue might be?  I have
>tried reading through the FAQ?s but not found anything to point me in
>the right direction.
>
>Regards,
>
>Tom Knox
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 19 10:41:06 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Sep 2019 18:41:06 +1000
Subject: [R] problem with pyramid.plot
In-Reply-To: <CAMOABhMj5eLaE09bx=P4nR-i39sPW-uQSCD5oLOaYkMVuSi=MA@mail.gmail.com>
References: <CAMOABhMj5eLaE09bx=P4nR-i39sPW-uQSCD5oLOaYkMVuSi=MA@mail.gmail.com>
Message-ID: <CA+8X3fVykTyMCTSGSMh95mrj4OM7sHXfP7VJfKz4+C7D=zFrnA@mail.gmail.com>

Hi Christophe,
Your call to pyramid.plot is okay. I would make a couple of suggestions:

par(mar=pyramid.plot(males.overweight,females.overweight,
 top.labels=c("Males","Labels","Females"),laxlab=seq(0,60,by=10),
 raxlab=seq(0,30,by=10),labels=agelabels,lxcol="#74c476",rxcol="#9e9ac8",
 gap=11,show.values=TRUE))

However, I do not have shiny nor do I know how to use it. I suspect that
you may have to ask shiny for a replot rather than update. Winston
Chang (winston
at rstudio.com) is the maintainer and probably the best person to ask.

Jim

On Thu, Sep 19, 2019 at 5:55 PM Christophe greaume <cgrecup at gmail.com>
wrote:

> Hello Jim,
>
>
>
> I?ve got a problem with using pyramid.plot in shiny.
>
> I?ve made an example (PyramidOK.R) that?s working. When user change the
> value on the slider the pyramid and the exceltable change.
>
> But in my application, pyramid doesn?t change while values are ok.
>
> When I cut excelOutput("AirlineByAircraft") in UI.R, pyramid change when
> user change the value of the slider.
>
> Please consider data as non public
>  shiny.zip
> <https://drive.google.com/file/d/1aRAkG1ruX_e0jl_P4gCwH0SMpcrXm-Vo/view?usp=drive_web>
>
> Could you help me?
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Thu Sep 19 10:55:36 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 19 Sep 2019 20:55:36 +1200
Subject: [R] The "--slave" option
In-Reply-To: <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
Message-ID: <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>

One of my grandfathers was from Croatia.  Guess what the word "slave" is
derived
from?  That's right, Slavs.  This goes back to the 9th century.  And then
of course
my grandfather's people were enslaved by the Ottoman empire, which was only
defeated
a little over a hundred years ago.  My other grandfather was from the
British isles,
where to this day followers of the same prophet are enslaving people like me
(except for being female).  So I'm sorry, but I'm not impressed.

How many computers are "servers"?  There's that whole client-server thing.
Guess what "server" comes from?  That's right, the Latin word "servus",
which
means guess what?  You got it again: "slave".  Are we to abolish the word
"server"?  What about the word "client"?  Ah, that's part of the
client-patron
system from Rome, so what about the patriarchy, eh?

We are dealing with something called "the genetic fallacy".
"The genetic *fallacy* (also known as the *fallacy of origins* ...)
 is a *fallacy* of irrelevance that is based solely on someone's
 or something's history, *origin*, or source rather than its
 current meaning or context."  (Wikipedia.)

Context matters.



On Thu, 19 Sep 2019 at 17:10, Abby Spurdle <spurdle.a at gmail.com> wrote:

> > Personally I much prefer backwards compatibility to political
> correctness.
>
> I agree with Rolf, here.
> And as someone that's planning to write a Linux Terminal Emulator, in
> the medium-term future, I *strongly* defend this approach.
>
> And to the original poster.
> Haven't you seen The Matrix?
> (Second best movie ever, after the Shawshank Redemption).
>
> I would prefer the technology to be my slave, than I be a
> prisoner/slave to the technology.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Thu Sep 19 11:17:50 2019
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Thu, 19 Sep 2019 21:17:50 +1200
Subject: [R] The "--slave" option
In-Reply-To: <120FCF35-CF2C-4AA8-9F70-E03233CF9964@dcn.davis.ca.us>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <CAJc=yOHmZrMA1T7t2xnjwY_GA16ZuNH9nG0+-RzhOTddNdS_tg@mail.gmail.com>
 <120FCF35-CF2C-4AA8-9F70-E03233CF9964@dcn.davis.ca.us>
Message-ID: <20190919091750.GA4258@slingshot.co.nz>

On Wed, 18-Sep-2019 at 02:58PM -0700, Jeff Newmiller wrote:

|> I think there is no confusion except in the minds of those with
|> nothing better to do. I agree with Antirez, quoted in [1], which
|> nevertheless indicates that perspective lost the debate.

I agree with Jeff.  Automotive hydraulics have used terms such as
'master-cylinders' and 'slave-cylinders' without such an issue for a
century or more.  

If we have nothing else to do, we might want to purge ESS of its
so-called 'inferior processes', but it ain't me, Babe.

BTW: I've used R for 20+ years and never used a --slave option.
Should I get an award?


|> Any accurate alternative notation will have similar connotations
|> because in fact the "slave" side of that relationship is completely
|> subordinate to the "master" side... there is no escaping that
|> fact. It requires a very different and more complicated
|> architecture to achieve a "peer" relationship, which often is not
|> worth the effort or even appropriate.


|> So while Dr Lang may be mollified by a change in notation, someone
|> else is going to find the new words offensive and make the same PC
|> argument since the implications of the architecture have not
|> changed. In fact there should never have been a parallel drawn
|> between the morality of human slavery and computing architectures
|> to begin with.



|> [1] https://www.vice.com/en_us/article/8x7akv/masterslave-terminology-was-removed-from-python-programming-language
|> 
|> On September 18, 2019 11:57:32 AM PDT, "Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:
|> >For what it's worth, this is an ongoing conversation in computer
|> >science and engineering. And has been so for decades.
|> >
|> >Not R, but related to this it's only in the past few months that a
|> >fork of the photo-manipulation software GIMP (slur for handicapped)
|> >renames it (GLIMPSE).
|> >
|> >Note, I am not saying this isn't a battle worth fighting.
|> >
|> >On Wed, Sep 18, 2019 at 1:52 PM Benjamin Lang <benjamin.lang at crg.eu>
|> >wrote:
|> >>
|> >> Dear R project,
|> >>
|> >> I have a very simple question:
|> >>
|> >> How, in late 2019, is there an option called "--slave" to "make R run
|> >as
|> >> quietly as possible"?
|> >>
|> >> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970
|> >when
|> >> R was presumably developed, based on its atrocious syntax,
|> >documentation
|> >> and usability (I think I only need to say "NaN", "NULL", and "NA").
|> >>
|> >> This is a disgrace and it should have been addressed one or two
|> >decades
|> >> ago. Why not just "--quiet"?
|> >>
|> >> Please do not mention "backwards compatibility". For the historically
|> >> inclined, it does not make much of a difference whether the term
|> >evokes the
|> >> Roman, Greek, American or modern kind of slavery for you: it is as
|> >> disgusting as it gets.
|> >>
|> >> Thank you,
|> >> Ben
|> >>
|> >> --
|> >> Benjamin Lang, PhD
|> >> http://orcid.org/0000-0001-6358-8380
|> >>
|> >> Marie Sklodowska-Curie Postdoctoral Fellow (MSCA-IF)
|> >> Gene Function and Evolution (Dr. Gian Tartaglia)
|> >> Centre for Genomic Regulation (CRG), Barcelona, Spain
|> >>
|> >>         [[alternative HTML version deleted]]
|> >>
|> >> ______________________________________________
|> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> >> https://stat.ethz.ch/mailman/listinfo/r-help
|> >> PLEASE do read the posting guide
|> >http://www.R-project.org/posting-guide.html
|> >> and provide commented, minimal, self-contained, reproducible code.
|> >
|> >______________________________________________
|> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> >https://stat.ethz.ch/mailman/listinfo/r-help
|> >PLEASE do read the posting guide
|> >http://www.R-project.org/posting-guide.html
|> >and provide commented, minimal, self-contained, reproducible code.
|> 
|> -- 
|> Sent from my phone. Please excuse my brevity.
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From S|cotte@Hugue@ @end|ng |rom m@yo@edu  Thu Sep 19 15:58:01 2019
From: S|cotte@Hugue@ @end|ng |rom m@yo@edu (Sicotte, Hugues, Ph.D.)
Date: Thu, 19 Sep 2019 13:58:01 +0000
Subject: [R] [EXTERNAL] Re:  The "--slave" option
In-Reply-To: <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
Message-ID: <771925$ce4kjj@ironport10.mayo.edu>

I prefer backward compatibility to PC too, but since we're on the topic,

My personal PC advocacy  is against the term blacklist always being associated with some "negatives".

A search of CRAN found several packages using this term.
I advocate using a more descriptive term, such.

Falsepositivelist
truenegativelist
forbiddenlist
etc..

Package maintainers can keep the old term, but please mark it as deprecated.
Thank you for your consideration.

Hugues Sicotte 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rolf Turner
Sent: Wednesday, September 18, 2019 6:10 PM
To: Benjamin Lang
Cc: r-help at r-project.org
Subject: [EXTERNAL] Re: [R] The "--slave" option


On 18/09/19 6:00 PM, Benjamin Lang wrote:

> Dear R project,
> 
> I have a very simple question:
> 
> How, in late 2019, is there an option called "--slave" to "make R run as
> quietly as possible"?
> 
> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
> R was presumably developed, based on its atrocious syntax, documentation
> and usability (I think I only need to say "NaN", "NULL", and "NA").
> 
> This is a disgrace and it should have been addressed one or two decades
> ago. Why not just "--quiet"?
> 
> Please do not mention "backwards compatibility".

Personally I much prefer backwards compatibility to political correctness.

> For the historically
> inclined, it does not make much of a difference whether the term evokes the
> Roman, Greek, American or modern kind of slavery for you: it is as
> disgusting as it gets.

IMHO this is a precious PC quibble, taking offence where no offence is 
intended.

If you are really concerned about literal slavery --- as everyone should 
be --- then join/contribute to an appropriate activist organisation 
(e.g. Amnesty International, which is my personal choice).

cheers,

Rolf Turner


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From |@heemj@n93 @end|ng |rom y@hoo@com  Thu Sep 19 19:09:32 2019
From: |@heemj@n93 @end|ng |rom y@hoo@com (Faheem Jan)
Date: Thu, 19 Sep 2019 17:09:32 +0000 (UTC)
Subject: [R] Conversion of multivariate time series to functional time series
References: <836930804.6665187.1568912972334.ref@mail.yahoo.com>
Message-ID: <836930804.6665187.1568912972334@mail.yahoo.com>

Hi, i am try to generalize the Functional autoregressive model of order one FAR(1) to FAR(p) through? functional principle component by? choosing a particular amount of variation, then using the functional scores of functional principle component? for the prediction of vector autoregressive model i.e VAR(p) time series through VAR package, now i want to transform these prediction into functional form, this can be done through karhunen loeve transformation but how i could do this R. Can any body help me in this regard

	[[alternative HTML version deleted]]


From m@x|m @end|ng |rom |om|n@one  Thu Sep 19 09:25:31 2019
From: m@x|m @end|ng |rom |om|n@one (Maksim Fomin)
Date: Thu, 19 Sep 2019 07:25:31 +0000
Subject: [R] The "--slave" option
Message-ID: <LXzpKjIkEoxZ4JRGu67g4JPpF4kS4m3xz99y-Px7QGmkOJ3mTQMpyJo3oaj_AauvWy67e148gpTWU-MSW7NmNkpBiJ6CRF7uzJnplVmUAdA=@fomin.one>

> How, in late 2019, is there an option called "--slave" to "make R run as
quietly as possible"?

The word "slave" is fine for computer science because a) none tries to make a real person slave and b) historical reasons and backwards compability. You may be against b), but this is your problem.

What is wrong here, is that some minor group striking for political correctness tries to impose its behavior in technical field. It's a shame that sometimes such group wins (for example, as in the Python case).

Best regards,
Maxim Fomin


From |@ngbnj @end|ng |rom gm@||@com  Thu Sep 19 11:51:13 2019
From: |@ngbnj @end|ng |rom gm@||@com (Benjamin Lang)
Date: Thu, 19 Sep 2019 11:51:13 +0200
Subject: [R] [SPAM] Re:  The "--slave" option
In-Reply-To: <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
Message-ID: <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>

Dear Richard,

Thank you, that?s interesting. There is also something called an ?etymological fallacy?. I think current usage is more useful here than the ?science of truth?, i.e. the Ancient Greek idea that the (sometimes inferred) derivation of a word allows us to grasp ?the truth of it?. 

In current usage, a ?server? is someone who brings you dishes in a restaurant. A ?client? is a customer. A ?slave? is a human being forced to perform work under duress and considered nothing more than a machine, say a dishwasher or a tractor. And in some regions, this echoes on and is offensive and hurtful to some.

A new user, wanting to reduce output from R, would probably reach for ?-q? or ??quiet?. This makes sense in the same way that ??stentorian? is not a good alternative to ??verbose?. 

Best,
Ben

> On 19 Sep 2019, at 10:55, Richard O'Keefe <raoknz at gmail.com> wrote:
> 
> One of my grandfathers was from Croatia.  Guess what the word "slave" is derived
> from?  That's right, Slavs.  This goes back to the 9th century.  And then of course
> my grandfather's people were enslaved by the Ottoman empire, which was only defeated
> a little over a hundred years ago.  My other grandfather was from the British isles,
> where to this day followers of the same prophet are enslaving people like me
> (except for being female).  So I'm sorry, but I'm not impressed.
> 
> How many computers are "servers"?  There's that whole client-server thing.
> Guess what "server" comes from?  That's right, the Latin word "servus", which
> means guess what?  You got it again: "slave".  Are we to abolish the word
> "server"?  What about the word "client"?  Ah, that's part of the client-patron
> system from Rome, so what about the patriarchy, eh?
> 
> We are dealing with something called "the genetic fallacy".
> "The genetic fallacy (also known as the fallacy of origins ...)
>  is a fallacy of irrelevance that is based solely on someone's
>  or something's history, origin, or source rather than its
>  current meaning or context."  (Wikipedia.)
> 
> Context matters.
> 
> 
> 
>> On Thu, 19 Sep 2019 at 17:10, Abby Spurdle <spurdle.a at gmail.com> wrote:
>> > Personally I much prefer backwards compatibility to political correctness.
>> 
>> I agree with Rolf, here.
>> And as someone that's planning to write a Linux Terminal Emulator, in
>> the medium-term future, I *strongly* defend this approach.
>> 
>> And to the original poster.
>> Haven't you seen The Matrix?
>> (Second best movie ever, after the Shawshank Redemption).
>> 
>> I would prefer the technology to be my slave, than I be a
>> prisoner/slave to the technology.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rhotuser m@iii@g oii y@hoo@co@jp  Thu Sep 19 15:08:15 2019
From: rhotuser m@iii@g oii y@hoo@co@jp (rhotuser m@iii@g oii y@hoo@co@jp)
Date: Thu, 19 Sep 2019 22:08:15 +0900 (JST)
Subject: [R] The way giving the suitable data structure to the obtained data
 for the use of "prospectr"
References: <1225069296.2272257.1568898495426.JavaMail.yahoo.ref@jws705103.mail.ssk.yahoo.co.jp>
Message-ID: <1225069296.2272257.1568898495426.JavaMail.yahoo@jws705103.mail.ssk.yahoo.co.jp>

Dear Sir,
? ? I want to use the "prospectr" for the obtained spectra like the attached file, "Nirspectra".
? However, my understanding level of the data structure of "NIRsoil" is not yet enough.
? reference:? https://cran.r-project.org/web/packages/prospectr/vignettes/prospectr-intro.pdf
data(NIRsoil)str(NIRsoil) ----->? A little complicated for me.
I have 2 questions.
?I want to make the data structure of "Nirspectra" to be applied directly for "prospectre".
1. Please tell me the detail way for giving suitable data structure toward? "Nirspectra".
? abc<-read.csv('Nirspectra.csv')

? -------------------------------------------------------------------------------? My estimation of the final data sturucture of "Nirspectra"? for the direct use of "prospectr"
?'data.frame':? ?57 obs. of? 3 variables:? ?$ train: num? 1 1 0 1 1 0 1 1 0 1 ...? ?$ dep? : num? 87.300003 87 87.099998 89.699997 84.900002 84.699997 89.300003...? ?$ spc? : num [2:58, 1:36] ...
2. Which is right, num [2:58, 1:36] or num [1:58, 1:36] ?
Best Regards,
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Nirspectra.csv
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190919/0165df88/attachment.ksh>

From s@rez@@i@vi@@ m@iii@g oii m@ii@um@@c@ir  Thu Sep 19 16:06:23 2019
From: s@rez@@i@vi@@ m@iii@g oii m@ii@um@@c@ir (s@rez@@i@vi@@ m@iii@g oii m@ii@um@@c@ir)
Date: Thu, 19 Sep 2019 18:36:23 +0430
Subject: [R] Help
Message-ID: <ad923cf41e8641f1838b64f041b67ea3@mail.um.ac.ir>

Hello,

I' have just tried to submit a package to CRAN which has a Bioconductor
dependency. I import "GeneticsPed" in my package but
 when installing it, have this error:

ERROR: dependency 'GeneticsPed' is not available for package 'LRQMM'
        * removing 'C:/Users/.../LRQMM'.

or this check: 
https://cran.um.ac.ir/web/checks/check_results_LRQMM.html

I tried "biocViews " in description file with empty form, but not been
succeed.

How can i solving this problem?

Thanks,

Sayyed Reza Alavian
	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Thu Sep 19 18:27:13 2019
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Thu, 19 Sep 2019 09:27:13 -0700
Subject: [R] If Loop With Lagged Variable
Message-ID: <AA78281199CE43069DEF380C612AC733@OWNERPC>

Attached is every at bat for the Arizona Diamondback?s first three games of 2018 ? BBdata1.rda.  I added the Date and DHCode variables by parsing the first variable labeled GameID.

BBdata2 is a reduced dataset with five variables as shown in the str() command.

data.frame':	234 obs. of  5 variables:
 $ GameID : Factor w/ 3 levels "ARI201803290",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ Date   : Date, format: "2018-03-29" "2018-03-29" "2018-03-29" "2018-03-29" ...
 $ DHCode : Factor w/ 1 level "0": 1 1 1 1 1 1 1 1 1 1 ...
 $ GameNum: num  1 1 1 1 1 1 1 1 1 1 ...
 $ Date2  : Date, format: NA "2018-03-29" "2018-03-29" "2018-03-29" ...
  I?m trying to increment the GameNum (game number) to game 2 when the date changes from 2018-03-29 to 2018-03-30 in row 81 and to game 3 in row 165.

According to my R for Dummies book the following code should work but it doesn?t.  I keep getting the following error.  Any suggestions?

if(ari18.test3$Date > lag(ari18.test3$Date)) {ari18.test3$gameNum <- ari18.tesm3$GameNum + 1}
Warning message:
In if (ari18.test3$Date > lag(ari18.test3$Date)) { :
  the condition has length > 1 and only the first element will be used
 
     
            >  
     


Thanks.

From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Sep 19 21:03:50 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 19 Sep 2019 12:03:50 -0700
Subject: [R] Problem loading packages in R 3.6.1
In-Reply-To: <D94021B2-AC88-43EA-BAAA-7AF9A96BD8DB@dcn.davis.ca.us>
References: <1CF01761-9E5B-43A0-A85A-BDE1CF11B254@gmail.com>
 <D94021B2-AC88-43EA-BAAA-7AF9A96BD8DB@dcn.davis.ca.us>
Message-ID: <068889e7-c2a6-8952-011f-9a603bb67448@comcast.net>


On 9/19/19 1:11 AM, Jeff Newmiller wrote:
> Since no answer has been forthcoming, my advice is to read the Posting Guide. There is a more appropriate list for your question, and you should take the warning about posting using plain text format on all r-project mailing lists seriously.
>
> On September 17, 2019 9:55:31 AM PDT, Thomas Knox <knoxy1827 at gmail.com> wrote:
>> I have recently installed R 3.6.1 on my MacBook running Mac OS Mojave
>> 10.14.5 in order to run a custom package called MH1823 (probability of
>> detection).  This package requires me to load the following packages
> >from CRAN, tcltk, tcltk2, survival and xlsx.

Which down below we see requires that the java development kit be 
installed correctly for xlsx. This has been a recurrent issue on the Mac 
and there are many question about it on the correct mailing list, which 
is not rhelp, but rather R-SIG-mac.


Here's a link to the MarkLogic archive of r-sig-mac


https://markmail.org/search/?q=+list%3Aorg.r-project.r-sig-mac+install+java#query:list%3Aorg.r-project.r-sig-mac%20install%20java%20order%3Adate-backward+page:1+state:facets


... and if you don't want to use it then try rseek.org with a search 
strategy of "install java mac". If that doesn't satisfy, then subscribe 
and post a question on r-sig-mac with a full description of? results of 
trying to install a newer version of java. I have version 10.0.1 on my 
Mojave laptop.


-- 

David.

>> I have installed survival, xlsx and tlctk2 (i believe tcltk is
>> embedded).  When I look at Package Manager i see that although the
>> above packages are installed they are not loaded.  I can load survival
>> but when I try to load ?xlsx? i get the following  error message is:
>>
>> Error: package or namespace load failed for ?xlsx?:
>> .onLoad failed in loadNamespace() for 'rJava', details:
>>   call: dyn.load(file, DLLpath = DLLpath, ...)
>> error: unable to load shared object
>> '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
>> dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so,
>> 6): Library not loaded:
>> /Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
>> Referenced from:
>> /Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so
>>   Reason: image not found
>> starting httpd help server ? done
>>
>>
>> there may be a couple of hints in here.
>>
>> .onLoad failed in loadNamespace() for 'rJava', details  suggests the
>> problem starts with calling rJava.
>>
>> the next line in the error:
>> error: unable to load shared object
>> '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
>> I have checked this path and see no problems, everything seems to stack
>> up and I find jJava.so where it is supposed to be.  However in the next
>> line:
>> dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so,
>> 6): Library not loaded:
>> /Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
>> I don?t know what the number , 6 after Java.so means but have presumed
>> version number and may be why Java8 is not working.  I also note the
>> path ?. /JavaVirtualMachines/jdk-11.0.1.jdk/ appears as .
>> /JavaVirtualMachines/1.6.0.jdk/
>> suggesting a different build
>>
>> the same occurs when I try to load the local source package MH1823
>>
>> When I try to load HM1823 I get the error message:
>> * installing *source* package ?mh1823? ...
>> ** using staged installation
>> ** R
>> ** data
>> ** inst
>> ** byte-compile and prepare package for lazy loading
>> Error: package or namespace load failed for ?xlsx?:
>> .onLoad failed in loadNamespace() for 'rJava', details:
>>   call: dyn.load(file, DLLpath = DLLpath, ...)
>> error: unable to load shared object
>> '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so':
>> dlopen(/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so,
>> 6): Library not loaded:
>> /Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/lib/server/libjvm.dylib
>> Referenced from:
>> /Library/Frameworks/R.framework/Versions/3.6/Resources/library/rJava/libs/rJava.so
>>   Reason: image not found
>> Error: package ?xlsx? could not be loaded
>> Execution halted
>> ERROR: lazy loading failed for package ?mh1823?
>> * removing
>> ?/Library/Frameworks/R.framework/Versions/3.6/Resources/library/mh1823?
>> I find that the error message is substantially the same suggesting
>> rJava and/or the version of Java.  I have tried removing Java 8 from my
>> machine and installing Java 6 but don?t see any difference.  It is easy
>> to see that Java 8 has been removed but not easy to see that 6 is
>> installed properly as the path names are still the same.
>>
>> When I try to load either tcltk or tcltk2, my instance of R stops
>> responding entirely.
>>
>> I have also installed Xquartz as I believe this is needed for Mac OS X
>>
>> Can anyone provide some advice on what the issue might be?  I have
>> tried reading through the FAQ?s but not found anything to point me in
>> the right direction.
>>
>> Regards,
>>
>> Tom Knox
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Sep 19 22:03:29 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 19 Sep 2019 23:03:29 +0300
Subject: [R] [SPAM] Re:  The "--slave" option
In-Reply-To: <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
Message-ID: <20190919230329.56387ab5@parabola>

On Thu, 19 Sep 2019 11:51:13 +0200
Benjamin Lang <langbnj at gmail.com> wrote:

> A new user, wanting to reduce output from R, would probably reach for
> ?-q? or ??quiet?.

Not to argue against your point, but note that (1) --quiet is already a
flag which means something else and (2) --slave is not only a command
line option, but also a structure field name. You can find it in
src/include/R_ext/RStartup.h, not far away from typedef enum { ...
SA_SUICIDE } SA_TYPE. There is also a public API endpoint R_Suicide in
src/include/Rinterface.h.

One could think that R sources should come with trigger warnings or
something.

-- 
Best regards,
Ivan


From roy@mende|@@ohn @end|ng |rom no@@@gov  Thu Sep 19 22:12:46 2019
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 19 Sep 2019 13:12:46 -0700
Subject: [R] [SPAM] Re:  The "--slave" option
In-Reply-To: <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
Message-ID: <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>

Hi Ben:

Without commenting one way or another on your point,  your initial post seemed a lot like trolling because of:

> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
> R was presumably developed, based on its atrocious syntax, documentation
> and usability (I think I only need to say "NaN", "NULL", and "NA").
> 

You are certainly welcome to your opinions about R,  but these comments are totally aside from what I assume is your main point,  and because of this my first reaction was don't feed the trolls.

My $0.02.

-Roy

> On Sep 19, 2019, at 2:51 AM, Benjamin Lang <langbnj at gmail.com> wrote:
> 
> Dear Richard,
> 
> Thank you, that?s interesting. There is also something called an ?etymological fallacy?. I think current usage is more useful here than the ?science of truth?, i.e. the Ancient Greek idea that the (sometimes inferred) derivation of a word allows us to grasp ?the truth of it?. 
> 
> In current usage, a ?server? is someone who brings you dishes in a restaurant. A ?client? is a customer. A ?slave? is a human being forced to perform work under duress and considered nothing more than a machine, say a dishwasher or a tractor. And in some regions, this echoes on and is offensive and hurtful to some.
> 
> A new user, wanting to reduce output from R, would probably reach for ?-q? or ??quiet?. This makes sense in the same way that ??stentorian? is not a good alternative to ??verbose?. 
> 
> Best,
> Ben
> 
>> On 19 Sep 2019, at 10:55, Richard O'Keefe <raoknz at gmail.com> wrote:
>> 
>> One of my grandfathers was from Croatia.  Guess what the word "slave" is derived
>> from?  That's right, Slavs.  This goes back to the 9th century.  And then of course
>> my grandfather's people were enslaved by the Ottoman empire, which was only defeated
>> a little over a hundred years ago.  My other grandfather was from the British isles,
>> where to this day followers of the same prophet are enslaving people like me
>> (except for being female).  So I'm sorry, but I'm not impressed.
>> 
>> How many computers are "servers"?  There's that whole client-server thing.
>> Guess what "server" comes from?  That's right, the Latin word "servus", which
>> means guess what?  You got it again: "slave".  Are we to abolish the word
>> "server"?  What about the word "client"?  Ah, that's part of the client-patron
>> system from Rome, so what about the patriarchy, eh?
>> 
>> We are dealing with something called "the genetic fallacy".
>> "The genetic fallacy (also known as the fallacy of origins ...)
>> is a fallacy of irrelevance that is based solely on someone's
>> or something's history, origin, or source rather than its
>> current meaning or context."  (Wikipedia.)
>> 
>> Context matters.
>> 
>> 
>> 
>>> On Thu, 19 Sep 2019 at 17:10, Abby Spurdle <spurdle.a at gmail.com> wrote:
>>>> Personally I much prefer backwards compatibility to political correctness.
>>> 
>>> I agree with Rolf, here.
>>> And as someone that's planning to write a Linux Terminal Emulator, in
>>> the medium-term future, I *strongly* defend this approach.
>>> 
>>> And to the original poster.
>>> Haven't you seen The Matrix?
>>> (Second best movie ever, after the Shawshank Redemption).
>>> 
>>> I would prefer the technology to be my slave, than I be a
>>> prisoner/slave to the technology.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 19 23:09:32 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 19 Sep 2019 22:09:32 +0100
Subject: [R] If Loop With Lagged Variable
In-Reply-To: <AA78281199CE43069DEF380C612AC733@OWNERPC>
References: <AA78281199CE43069DEF380C612AC733@OWNERPC>
Message-ID: <e1b134d2-6401-5f71-1052-c59dece78249@sapo.pt>

Hello,

There was no attachment, R-Help allows only a limited number of file 
types, see the posting guide and try reposting.

As for the question, try ifelse, the vectorized fom of if/else.

ifelse(ari18.test3$Date > lag(ari18.test3$Date), ari18.tesm3$GameNum + 
1, ari18.test3$gameNum)


(Not tested, since there is no data.)

Hope this helps,

Rui Barradas

?s 17:27 de 19/09/19, Phillip Heinrich escreveu:
> Attached is every at bat for the Arizona Diamondback?s first three games of 2018 ? BBdata1.rda.  I added the Date and DHCode variables by parsing the first variable labeled GameID.
> 
> BBdata2 is a reduced dataset with five variables as shown in the str() command.
> 
> data.frame':	234 obs. of  5 variables:
>   $ GameID : Factor w/ 3 levels "ARI201803290",..: 1 1 1 1 1 1 1 1 1 1 ...
>   $ Date   : Date, format: "2018-03-29" "2018-03-29" "2018-03-29" "2018-03-29" ...
>   $ DHCode : Factor w/ 1 level "0": 1 1 1 1 1 1 1 1 1 1 ...
>   $ GameNum: num  1 1 1 1 1 1 1 1 1 1 ...
>   $ Date2  : Date, format: NA "2018-03-29" "2018-03-29" "2018-03-29" ...
>    I?m trying to increment the GameNum (game number) to game 2 when the date changes from 2018-03-29 to 2018-03-30 in row 81 and to game 3 in row 165.
> 
> According to my R for Dummies book the following code should work but it doesn?t.  I keep getting the following error.  Any suggestions?
> 
> if(ari18.test3$Date > lag(ari18.test3$Date)) {ari18.test3$gameNum <- ari18.tesm3$GameNum + 1}
> Warning message:
> In if (ari18.test3$Date > lag(ari18.test3$Date)) { :
>    the condition has length > 1 and only the first element will be used
>   
>       
>              >
>       
> 
> 
> Thanks.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 19 23:28:05 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 19 Sep 2019 22:28:05 +0100
Subject: [R] If Loop With Lagged Variable
In-Reply-To: <e1b134d2-6401-5f71-1052-c59dece78249@sapo.pt>
References: <AA78281199CE43069DEF380C612AC733@OWNERPC>
 <e1b134d2-6401-5f71-1052-c59dece78249@sapo.pt>
Message-ID: <42c92c07-a801-d4ec-e6b5-742bb08b65d4@sapo.pt>

Hello,

The following might be a better solution.
I include a minimal data set as an example.


Date <- c(rep(as.Date("2018-03-29"), 4),
           rep(as.Date("2018-03-30"), 4),
           rep(as.Date("2018-04-01"), 4))

ari18.test3 <- data.frame(Date)
ari18.test3$GameNum <- 1

#---

d <- c(0, diff(ari18.test3$Date) != 0)
ari18.test3$GameNum <- ari18.test3$GameNum + cumsum(d)

ari18.test3
#         Date GameNum
#1  2018-03-29       1
#2  2018-03-29       1
#3  2018-03-29       1
#4  2018-03-29       1
#5  2018-03-30       2
#6  2018-03-30       2
#7  2018-03-30       2
#8  2018-03-30       2
#9  2018-04-01       3
#10 2018-04-01       3
#11 2018-04-01       3
#12 2018-04-01       3


Hope this helps,

Rui Barradas

?s 22:09 de 19/09/19, Rui Barradas escreveu:
> Hello,
> 
> There was no attachment, R-Help allows only a limited number of file 
> types, see the posting guide and try reposting.
> 
> As for the question, try ifelse, the vectorized fom of if/else.
> 
> ifelse(ari18.test3$Date > lag(ari18.test3$Date), ari18.tesm3$GameNum + 
> 1, ari18.test3$gameNum)
> 
> 
> (Not tested, since there is no data.)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 17:27 de 19/09/19, Phillip Heinrich escreveu:
>> Attached is every at bat for the Arizona Diamondback?s first three 
>> games of 2018 ? BBdata1.rda.? I added the Date and DHCode variables by 
>> parsing the first variable labeled GameID.
>>
>> BBdata2 is a reduced dataset with five variables as shown in the str() 
>> command.
>>
>> data.frame':??? 234 obs. of? 5 variables:
>> ? $ GameID : Factor w/ 3 levels "ARI201803290",..: 1 1 1 1 1 1 1 1 1 1 
>> ...
>> ? $ Date?? : Date, format: "2018-03-29" "2018-03-29" "2018-03-29" 
>> "2018-03-29" ...
>> ? $ DHCode : Factor w/ 1 level "0": 1 1 1 1 1 1 1 1 1 1 ...
>> ? $ GameNum: num? 1 1 1 1 1 1 1 1 1 1 ...
>> ? $ Date2? : Date, format: NA "2018-03-29" "2018-03-29" "2018-03-29" ...
>> ?? I?m trying to increment the GameNum (game number) to game 2 when 
>> the date changes from 2018-03-29 to 2018-03-30 in row 81 and to game 3 
>> in row 165.
>>
>> According to my R for Dummies book the following code should work but 
>> it doesn?t.? I keep getting the following error.? Any suggestions?
>>
>> if(ari18.test3$Date > lag(ari18.test3$Date)) {ari18.test3$gameNum <- 
>> ari18.tesm3$GameNum + 1}
>> Warning message:
>> In if (ari18.test3$Date > lag(ari18.test3$Date)) { :
>> ?? the condition has length > 1 and only the first element will be used
>> ???????????? >
>>
>>
>> Thanks.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep 19 23:50:20 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 20 Sep 2019 07:50:20 +1000
Subject: [R] 
 The way giving the suitable data structure to the obtained data
 for the use of "prospectr"
In-Reply-To: <1225069296.2272257.1568898495426.JavaMail.yahoo@jws705103.mail.ssk.yahoo.co.jp>
References: <1225069296.2272257.1568898495426.JavaMail.yahoo.ref@jws705103.mail.ssk.yahoo.co.jp>
 <1225069296.2272257.1568898495426.JavaMail.yahoo@jws705103.mail.ssk.yahoo.co.jp>
Message-ID: <CA+8X3fXtj2pXL34ppUfdW+unae-jqxc_Z5kEjdwPXruo9TLZjA@mail.gmail.com>

Hi rhotuser,
Your question is really not about R, but about understanding IR
spectroscopy methods for soil composition. That's not my field, and
you will be lucky to find someone on this help list who is:
1) an expert in the field
2) willing to explain the methods used in the prospectr package
Maybe reading an introduction to the field will be a good start:

https://en.wikipedia.org/wiki/Near-infrared_spectroscopy

then a Google search for "NIR soil analysis"

Jim

On Fri, Sep 20, 2019 at 3:39 AM <rhotuser at yahoo.co.jp> wrote:
>
> Dear Sir,
>     I want to use the "prospectr" for the obtained spectra like the attached file, "Nirspectra".
>   However, my understanding level of the data structure of "NIRsoil" is not yet enough.
>   reference:  https://cran.r-project.org/web/packages/prospectr/vignettes/prospectr-intro.pdf
> data(NIRsoil)str(NIRsoil) ----->  A little complicated for me.
> I have 2 questions.
>  I want to make the data structure of "Nirspectra" to be applied directly for "prospectre".
> 1. Please tell me the detail way for giving suitable data structure toward? "Nirspectra".
>   abc<-read.csv('Nirspectra.csv')
>
>   -------------------------------------------------------------------------------  My estimation of the final data sturucture of "Nirspectra"  for the direct use of "prospectr"
>  'data.frame':   57 obs. of  3 variables:   $ train: num  1 1 0 1 1 0 1 1 0 1 ...   $ dep  : num  87.300003 87 87.099998 89.699997 84.900002 84.699997 89.300003...   $ spc  : num [2:58, 1:36] ...
> 2. Which is right, num [2:58, 1:36] or num [1:58, 1:36] ?
> Best Regards,______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 20 01:04:59 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 19 Sep 2019 19:04:59 -0400
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
Message-ID: <9ca5095d-d339-a9ce-b92b-6b3cadbcab60@gmail.com>

On 19/09/2019 4:12 p.m., Roy Mendelssohn - NOAA Federal via R-help wrote:
> Hi Ben:
> 
> Without commenting one way or another on your point,  your initial post seemed a lot like trolling because of:
> 
>> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
>> R was presumably developed, based on its atrocious syntax, documentation
>> and usability (I think I only need to say "NaN", "NULL", and "NA").
>>
> 
> You are certainly welcome to your opinions about R,  but these comments are totally aside from what I assume is your main point,  and because of this my first reaction was don't feed the trolls.

Why have a second reaction?  Trolls are bullies, bullies should be ignored.

Duncan Murdoch


From r@oknz @end|ng |rom gm@||@com  Fri Sep 20 05:14:44 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 20 Sep 2019 15:14:44 +1200
Subject: [R] [SPAM] Re:  The "--slave" option
In-Reply-To: <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
Message-ID: <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>

Nobody would use "stentorian" as an alternative to "verbose" because they
mean very different things.
  "verbose" means "using many words"
  "stentorian" means "talking very loudly, like Stentor, whose voice was as
powerful
                      as fifty voices of other men".
You can be verbose while talking in a whisper.
You can be stentorian while being laconic.

If you don't like the word "slave", the option "--silent" is there for you
to use.

The "master-slave" design pattern is in hundreds of books (although I note
that
Erlang uses different terminology).  Your car has a master hydraulic
cylinder and
slave cylinders.  The analogy is pervasive in technology.  See a very short
list
at https://en.wikipedia.org/wiki/Master/slave_(technology)
which ends with "Global Language Monitor
<https://en.wikipedia.org/wiki/Global_Language_Monitor> found the term
"master/slave" to be the most
egregious example of political correctness
<https://en.wikipedia.org/wiki/Political_correctness> in 2004, and named it
the most politically
incorrect term of that year."

The one thing "slave" does not mean in technology is any kind of human
being.

On Thu, 19 Sep 2019 at 21:51, Benjamin Lang <langbnj at gmail.com> wrote:

> Dear Richard,
>
> Thank you, that?s interesting. There is also something called an
> ?etymological fallacy?. I think current usage is more useful here than the
> ?science of truth?, i.e. the Ancient Greek idea that the (sometimes
> inferred) derivation of a word allows us to grasp ?the truth of it?.
>
> In current usage, a ?server? is someone who brings you dishes in a
> restaurant. A ?client? is a customer. A ?slave? is a human being forced to
> perform work under duress and considered nothing more than a machine, say a
> dishwasher or a tractor. And in some regions, this echoes on and is
> offensive and hurtful to some.
>
> A new user, wanting to reduce output from R, would probably reach for ?-q?
> or ??quiet?. This makes sense in the same way that ??stentorian? is not a
> good alternative to ??verbose?.
>
> Best,
> Ben
>
> On 19 Sep 2019, at 10:55, Richard O'Keefe <raoknz at gmail.com> wrote:
>
> One of my grandfathers was from Croatia.  Guess what the word "slave" is
> derived
> from?  That's right, Slavs.  This goes back to the 9th century.  And then
> of course
> my grandfather's people were enslaved by the Ottoman empire, which was
> only defeated
> a little over a hundred years ago.  My other grandfather was from the
> British isles,
> where to this day followers of the same prophet are enslaving people like
> me
> (except for being female).  So I'm sorry, but I'm not impressed.
>
> How many computers are "servers"?  There's that whole client-server thing.
> Guess what "server" comes from?  That's right, the Latin word "servus",
> which
> means guess what?  You got it again: "slave".  Are we to abolish the word
> "server"?  What about the word "client"?  Ah, that's part of the
> client-patron
> system from Rome, so what about the patriarchy, eh?
>
> We are dealing with something called "the genetic fallacy".
> "The genetic *fallacy* (also known as the *fallacy of origins* ...)
>  is a *fallacy* of irrelevance that is based solely on someone's
>  or something's history, *origin*, or source rather than its
>  current meaning or context."  (Wikipedia.)
>
> Context matters.
>
>
>
> On Thu, 19 Sep 2019 at 17:10, Abby Spurdle <spurdle.a at gmail.com> wrote:
>
>> > Personally I much prefer backwards compatibility to political
>> correctness.
>>
>> I agree with Rolf, here.
>> And as someone that's planning to write a Linux Terminal Emulator, in
>> the medium-term future, I *strongly* defend this approach.
>>
>> And to the original poster.
>> Haven't you seen The Matrix?
>> (Second best movie ever, after the Shawshank Redemption).
>>
>> I would prefer the technology to be my slave, than I be a
>> prisoner/slave to the technology.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 20 08:32:27 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 19 Sep 2019 23:32:27 -0700
Subject: [R] Help
In-Reply-To: <ad923cf41e8641f1838b64f041b67ea3@mail.um.ac.ir>
References: <ad923cf41e8641f1838b64f041b67ea3@mail.um.ac.ir>
Message-ID: <5E8D81D4-968E-4683-83CD-58013B6D6EFA@dcn.davis.ca.us>

Wrong mailing list. Read the Posting Guide. And use plain-text format to avoid us seeing something different than you intended.

On September 19, 2019 7:06:23 AM PDT, "s.rezaalavian--- via R-help" <r-help at r-project.org> wrote:
>Hello,
>
>I' have just tried to submit a package to CRAN which has a Bioconductor
>dependency. I import "GeneticsPed" in my package but
> when installing it, have this error:
>
>ERROR: dependency 'GeneticsPed' is not available for package 'LRQMM'
>        * removing 'C:/Users/.../LRQMM'.
>
>or this check: 
>https://cran.um.ac.ir/web/checks/check_results_LRQMM.html
>
>I tried "biocViews " in description file with empty form, but not been
>succeed.
>
>How can i solving this problem?
>
>Thanks,
>
>Sayyed Reza Alavian
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |@-m| @end|ng |rom @r||@@|t  Fri Sep 20 06:40:05 2019
From: |@-m| @end|ng |rom @r||@@|t (Francesco Ariis)
Date: Fri, 20 Sep 2019 06:40:05 +0200
Subject: [R] The "--slave" option
In-Reply-To: <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
Message-ID: <20190920044005.t4xe4nqmvkmdidju@x60s.casa>

On Fri, Sep 20, 2019 at 03:14:44PM +1200, Richard O'Keefe wrote:
> The one thing "slave" does not mean in technology is any kind of human
> being.

At risk of repeating what someone else said, we are most likely
not dealing with a human but with a "supernatural being, often
represented as of diminutive size, but sometimes as a giant, and
fabled to inhabit caves, hills, and like places", as from
exhibit A

On Wed, Sep 18, 2019 at 08:00:00AM +0200, Benjamin Lang wrote:
> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
> R was presumably developed, based on its atrocious syntax, documentation
> and usability (I think I only need to say "NaN", "NULL", and "NA").

I suggest not to fatten such a magical creature!


From |@ngbnj @end|ng |rom gm@||@com  Fri Sep 20 02:35:59 2019
From: |@ngbnj @end|ng |rom gm@||@com (Benjamin Lang)
Date: Fri, 20 Sep 2019 02:35:59 +0200
Subject: [R] [SPAM] Re:  The "--slave" option
In-Reply-To: <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
Message-ID: <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>

Hi Roy,

Thank you, I?m sorry ? I couldn?t resist fitting in a little dig there because that?s one of my main frustrations with actually using R, and to me it seemed to make some sort of sense because I was complaining about backwardness in a way (so a steep learning curve seemed to fit in). The error messages are so cryptic that I wonder how anyone ever used R before Google (e.g. https://stackoverflow.com/questions/27350636/r-argument-is-of-length-zero-in-if-statement).

I?m a bit appalled 50% of the responses think correctness and not being a jerk to some fraction of people is a bad thing and trigger warnings have been brought up (in a funny way). I should have done my research and noticed ?quiet is indeed an existing option, though.

If I had an R-related wish, it would be that ??slave? becomes ?-Q? in the documentation and is silently maintained for compatibility.

My original post came out of watching ?12 Years A Slave? and if you haven?t, I recommend it. The powerlessness and ultra-grating injustice and the irony of slavery being easily justified by the Bible while abolition is not is an experience.

Thanks,
Ben

P.S. Do any R developers actually read this?

> On 19 Sep 2019, at 22:12, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Hi Ben:
> 
> Without commenting one way or another on your point,  your initial post seemed a lot like trolling because of:
> 
>> Let me reiterate that it is 2019, i.e. "The Future", rather than 1970 when
>> R was presumably developed, based on its atrocious syntax, documentation
>> and usability (I think I only need to say "NaN", "NULL", and "NA").
>> 
> 
> You are certainly welcome to your opinions about R,  but these comments are totally aside from what I assume is your main point,  and because of this my first reaction was don't feed the trolls.
> 
> My $0.02.
> 
> -Roy
> 
>> On Sep 19, 2019, at 2:51 AM, Benjamin Lang <langbnj at gmail.com> wrote:
>> 
>> Dear Richard,
>> 
>> Thank you, that?s interesting. There is also something called an ?etymological fallacy?. I think current usage is more useful here than the ?science of truth?, i.e. the Ancient Greek idea that the (sometimes inferred) derivation of a word allows us to grasp ?the truth of it?. 
>> 
>> In current usage, a ?server? is someone who brings you dishes in a restaurant. A ?client? is a customer. A ?slave? is a human being forced to perform work under duress and considered nothing more than a machine, say a dishwasher or a tractor. And in some regions, this echoes on and is offensive and hurtful to some.
>> 
>> A new user, wanting to reduce output from R, would probably reach for ?-q? or ??quiet?. This makes sense in the same way that ??stentorian? is not a good alternative to ??verbose?. 
>> 
>> Best,
>> Ben
>> 
>>> On 19 Sep 2019, at 10:55, Richard O'Keefe <raoknz at gmail.com> wrote:
>>> 
>>> One of my grandfathers was from Croatia.  Guess what the word "slave" is derived
>>> from?  That's right, Slavs.  This goes back to the 9th century.  And then of course
>>> my grandfather's people were enslaved by the Ottoman empire, which was only defeated
>>> a little over a hundred years ago.  My other grandfather was from the British isles,
>>> where to this day followers of the same prophet are enslaving people like me
>>> (except for being female).  So I'm sorry, but I'm not impressed.
>>> 
>>> How many computers are "servers"?  There's that whole client-server thing.
>>> Guess what "server" comes from?  That's right, the Latin word "servus", which
>>> means guess what?  You got it again: "slave".  Are we to abolish the word
>>> "server"?  What about the word "client"?  Ah, that's part of the client-patron
>>> system from Rome, so what about the patriarchy, eh?
>>> 
>>> We are dealing with something called "the genetic fallacy".
>>> "The genetic fallacy (also known as the fallacy of origins ...)
>>> is a fallacy of irrelevance that is based solely on someone's
>>> or something's history, origin, or source rather than its
>>> current meaning or context."  (Wikipedia.)
>>> 
>>> Context matters.
>>> 
>>> 
>>> 
>>>>> On Thu, 19 Sep 2019 at 17:10, Abby Spurdle <spurdle.a at gmail.com> wrote:
>>>>> Personally I much prefer backwards compatibility to political correctness.
>>>> 
>>>> I agree with Rolf, here.
>>>> And as someone that's planning to write a Linux Terminal Emulator, in
>>>> the medium-term future, I *strongly* defend this approach.
>>>> 
>>>> And to the original poster.
>>>> Haven't you seen The Matrix?
>>>> (Second best movie ever, after the Shawshank Redemption).
>>>> 
>>>> I would prefer the technology to be my slave, than I be a
>>>> prisoner/slave to the technology.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 

	[[alternative HTML version deleted]]


From mr@hm@nku|mrt @end|ng |rom gm@||@com  Fri Sep 20 10:40:02 2019
From: mr@hm@nku|mrt @end|ng |rom gm@||@com (Moshiur Rahman)
Date: Fri, 20 Sep 2019 17:40:02 +0900
Subject: [R] annotation help in ggplot2
Message-ID: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>

Dear ggplot2 experts,

I'm struggling to make a plot having family id in x-axis and female id
below that family id where each 4 families have a single female id.

I also need to add male id on top of each bar which I can do before
grid.arrange, but fail after doing it. So, any suggestions?

Please find below my codes and help me to complete it perfectly.
#data
data <- read.table("R-help_ggplot2.csv", header=TRUE, sep=",")
names(data)
#packages
library(ggplot2)
library(grid)
library(gridExtra)
library(scales)
library(ggpubr)
#plot codes
p1 =
ggplot(data,aes(x=factor(family),y=offs.surv.perct,fill=factor(treat)))+
    geom_bar(stat="identity", position="dodge")+
    #facet_wrap(~ Female)+
    geom_bar(stat="identity", position="dodge", colour="black",
show.legend= TRUE) + # show_guide = TRUE gives legend boarder
    #geom_hline(yintercept=15, size=0.5, linetype = 2)+ ### middle line
    scale_fill_manual(values=c("grey", "white")) + # grey80 is closer to
white than black
    xlab("Family") +
    ylab (expression(paste("Offspring survival rate (%)"))) +
    #coord_cartesian(xlim=c(0,40), ylim=c(0,60), clip="off")+
    scale_y_continuous(expand = c(0, 0), limits = c(0, 60))+
    theme(legend.title = element_text(colour="black", size=12))+
    theme(legend.text = element_text(colour="black", size=11))+
    theme(legend.background = element_blank())+
    theme(legend.key = element_blank())+
    theme(legend.box.background = element_blank())+
    theme(legend.key.size = unit(2, "mm"),legend.key.width =
unit(0.5,"cm"))+
    theme(legend.position=c(0.05,0.9),legend.direction
="vertical",legend.box = "vertical")+ # add legend on top
    theme(panel.background = element_rect(fill = "transparent"))+
    theme(axis.line = element_line(colour =
"black"),axis.text.x=element_text(size=10,
colour="black"),axis.text.y=element_text(size=10, colour="black"),
        axis.title.y = element_text(size=12, colour =
"black",margin=margin(0,5,0,0)),
        axis.title.x = element_blank(),
        strip.text.x = element_blank(),# remove top level title (high and
low)
        strip.background = element_blank(),# remove top level background
        panel.grid.major = element_blank(),# remove grid line within the
plot
        panel.grid.minor = element_blank(),
        panel.border = element_blank())
p1

### legend correction
p2<- p1 + guides(fill = guide_legend(title="Fertilization group",keywidth =
1,keyheight = 1,
                             title.theme = element_text(size=12, colour =
"black", angle = 0)))+
  theme(legend.text = element_text(size = 12, colour = "black", angle = 0))

p2

###plot margins
p3<-p2+theme(plot.margin = unit(c(1,1,1.7,1), "lines"))
p3

#x-axis label
p4<-grid.arrange(
  p3,
  bottom = textGrob(
    "Family and female number",
    gp = gpar(fontsize = 12, cex=1), #fontface = "bold",
    vjust = 0.5, hjust = 0.5,x = 0.52))

# annotation (NOT WORKING)
p5<-p4+annotate("text", label = "M1", x = 1, y = 25.03, fontface = 1,
size=3,angle = 90)
p5
p6<-p5+annotate("text", label = "M2", x = 2, y = 18.37, fontface = 1,
size=3,angle = 90)
p6
p7<-p6+annotate("text", label = "M3", x = 3, y = 21.7, fontface = 1,
size=3,angle = 90)
p7
p8<-p7+annotate("text", label = "M1-2-3", x = 4, y = 19.1, fontface= 1,
size=3,angle = 90)
p8
Fig1.1<-p8+annotate("segment", size=0.3, x=c(1,1,4),xend=c(1,4,4),
                         y= c(26,28,28), yend=c(28,28,21))+
  annotate("text",x=2.45,y=29.5,fontface = 1, size=3,angle =
90,label=c("F1"))

Fig1.1

Please find attached also my data.

Any assistance will be highly appreciated.

Regards,

Moshi


JSPS Postdoctoral Fellow
Laboratory of Population Biology
Department of Marine Biosciences
Graduate School of Marine Science and Technology
Tokyo University of Marine Science and Technology
4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
Mobile: 050-6874-9072

From mr@hm@nku|mrt @end|ng |rom gm@||@com  Fri Sep 20 10:51:45 2019
From: mr@hm@nku|mrt @end|ng |rom gm@||@com (Moshiur Rahman)
Date: Fri, 20 Sep 2019 17:51:45 +0900
Subject: [R] annotation help in ggplot2
In-Reply-To: <CAODjwAGqH3+_co6sXePONPdvLjT7F3JXeMfPhf66ov-qbcu6+Q@mail.gmail.com>
References: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>
 <CAODjwAGqH3+_co6sXePONPdvLjT7F3JXeMfPhf66ov-qbcu6+Q@mail.gmail.com>
Message-ID: <CAGNSkSn4MkGuwLeoBLbgNbO8JFD7cWOARDCv_FJCu9OOoYGZkw@mail.gmail.com>

Thanks Rishi,

Please find attached the data herewith.



On Fri, Sep 20, 2019 at 5:48 PM ??? ( ??? / rIsHi ) <rishi.dasroy at gmail.com>
wrote:

> There are no attached data .
>
> On Fri, Sep 20, 2019 at 11:40 AM Moshiur Rahman <mrahmankufmrt at gmail.com>
> wrote:
>
>> Dear ggplot2 experts,
>>
>> I'm struggling to make a plot having family id in x-axis and female id
>> below that family id where each 4 families have a single female id.
>>
>> I also need to add male id on top of each bar which I can do before
>> grid.arrange, but fail after doing it. So, any suggestions?
>>
>> Please find below my codes and help me to complete it perfectly.
>> #data
>> data <- read.table("R-help_ggplot2.csv", header=TRUE, sep=",")
>> names(data)
>> #packages
>> library(ggplot2)
>> library(grid)
>> library(gridExtra)
>> library(scales)
>> library(ggpubr)
>> #plot codes
>> p1 =
>> ggplot(data,aes(x=factor(family),y=offs.surv.perct,fill=factor(treat)))+
>>     geom_bar(stat="identity", position="dodge")+
>>     #facet_wrap(~ Female)+
>>     geom_bar(stat="identity", position="dodge", colour="black",
>> show.legend= TRUE) + # show_guide = TRUE gives legend boarder
>>     #geom_hline(yintercept=15, size=0.5, linetype = 2)+ ### middle line
>>     scale_fill_manual(values=c("grey", "white")) + # grey80 is closer to
>> white than black
>>     xlab("Family") +
>>     ylab (expression(paste("Offspring survival rate (%)"))) +
>>     #coord_cartesian(xlim=c(0,40), ylim=c(0,60), clip="off")+
>>     scale_y_continuous(expand = c(0, 0), limits = c(0, 60))+
>>     theme(legend.title = element_text(colour="black", size=12))+
>>     theme(legend.text = element_text(colour="black", size=11))+
>>     theme(legend.background = element_blank())+
>>     theme(legend.key = element_blank())+
>>     theme(legend.box.background = element_blank())+
>>     theme(legend.key.size = unit(2, "mm"),legend.key.width =
>> unit(0.5,"cm"))+
>>     theme(legend.position=c(0.05,0.9),legend.direction
>> ="vertical",legend.box = "vertical")+ # add legend on top
>>     theme(panel.background = element_rect(fill = "transparent"))+
>>     theme(axis.line = element_line(colour =
>> "black"),axis.text.x=element_text(size=10,
>> colour="black"),axis.text.y=element_text(size=10, colour="black"),
>>         axis.title.y = element_text(size=12, colour =
>> "black",margin=margin(0,5,0,0)),
>>         axis.title.x = element_blank(),
>>         strip.text.x = element_blank(),# remove top level title (high and
>> low)
>>         strip.background = element_blank(),# remove top level background
>>         panel.grid.major = element_blank(),# remove grid line within the
>> plot
>>         panel.grid.minor = element_blank(),
>>         panel.border = element_blank())
>> p1
>>
>> ### legend correction
>> p2<- p1 + guides(fill = guide_legend(title="Fertilization group",keywidth
>> =
>> 1,keyheight = 1,
>>                              title.theme = element_text(size=12, colour =
>> "black", angle = 0)))+
>>   theme(legend.text = element_text(size = 12, colour = "black", angle =
>> 0))
>>
>> p2
>>
>> ###plot margins
>> p3<-p2+theme(plot.margin = unit(c(1,1,1.7,1), "lines"))
>> p3
>>
>> #x-axis label
>> p4<-grid.arrange(
>>   p3,
>>   bottom = textGrob(
>>     "Family and female number",
>>     gp = gpar(fontsize = 12, cex=1), #fontface = "bold",
>>     vjust = 0.5, hjust = 0.5,x = 0.52))
>>
>> # annotation (NOT WORKING)
>> p5<-p4+annotate("text", label = "M1", x = 1, y = 25.03, fontface = 1,
>> size=3,angle = 90)
>> p5
>> p6<-p5+annotate("text", label = "M2", x = 2, y = 18.37, fontface = 1,
>> size=3,angle = 90)
>> p6
>> p7<-p6+annotate("text", label = "M3", x = 3, y = 21.7, fontface = 1,
>> size=3,angle = 90)
>> p7
>> p8<-p7+annotate("text", label = "M1-2-3", x = 4, y = 19.1, fontface= 1,
>> size=3,angle = 90)
>> p8
>> Fig1.1<-p8+annotate("segment", size=0.3, x=c(1,1,4),xend=c(1,4,4),
>>                          y= c(26,28,28), yend=c(28,28,21))+
>>   annotate("text",x=2.45,y=29.5,fontface = 1, size=3,angle =
>> 90,label=c("F1"))
>>
>> Fig1.1
>>
>> Please find attached also my data.
>>
>> Any assistance will be highly appreciated.
>>
>> Regards,
>>
>> Moshi
>>
>>
>> JSPS Postdoctoral Fellow
>> Laboratory of Population Biology
>> Department of Marine Biosciences
>> Graduate School of Marine Science and Technology
>> Tokyo University of Marine Science and Technology
>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
>> Mobile: 050-6874-9072
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
>
>
>
> With regards
> Rishi Das Roy
>


-- 
Md. Moshiur Rahman, PhD

JSPS Postdoctoral Fellow
Laboratory of Population Biology
Department of Marine Biosciences
Graduate School of Marine Science and Technology
Tokyo University of Marine Science and Technology
4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
Mobile: 050-6874-9072

.........................

Professor
Fisheries and Marine Resource Technology Discipline
Khulna University, Khulna - 9208
BANGLADESH.
Google scholar:
https://scholar.google.com.au/citations?user=uElrJSsAAAAJ&hl=en
ResearchGate: https://www.researchgate.net/profile/Md_Moshiur_Rahman2
ORCID: https://orcid.org/my-orcid

From r@oknz @end|ng |rom gm@||@com  Fri Sep 20 11:07:57 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 20 Sep 2019 21:07:57 +1200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
 <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
Message-ID: <CABcYAdJ-MC3rhyLoacGvji_XHX_zzVUq3q4HsEUf-f=qvzfWPg@mail.gmail.com>

Not being a jerk is a good thing.
Unthinking political correctness is not the same thing at all.
The point has already been made that the relationship between
a "master" process or cylinder and a "slave" one is intrinsically
a dominance relation where the "master" tells the "slave" what to
do.  No amount of mucking around with audible or written words
will affect the *meaning*.  Even boss/worker is uncomfortably
close to master/slave and is going to trigger anyone who is
triggered by words rather than actual oppression (such as having
someone hostile attempt to control your speech, and intrinsically
oppressive act which presumes that the would-be controller has
some sort of *right* to dominate the potential controllee).

If we ever hear of someone using R who is or was a slave, we'll
ask for *their* opinion on the matter.

It has also been noted that euphemisms erode surprisingly quickly.
In my daughters' generation, the euphemism "toilet" for the jakes
is being replaced by "bathroom" -- with the result that I never
know which room they're going too, we have to use the ridiculous
"bathroom bathroom" to indicate the place where you wash yourself --
and I'm sure another term for the necessary house will be along
soon.  In fact, we're already starting to say "wharepaku" (Foh-
Re-Pah-Koo) for clarity.  Dear knows what that will be replaced
by.  So shunning the word "slave" is not only ineffective, it
won't even be ineffective for long; whatever replaces it will
itself be the target of cries of "being a jerk".

The really annoying thing about this is that it does nothing whatsoever
to improve the actual condition of any living person.

As for NULL, NA, and NaN, you really cannot blame R for NaN.
S existed before IEEE arithmetic, and it's not *that* hard to
keep NULL and NA apart.  length(NULL) is 0.  There is literally
nothing there.  It's what c() gives you.  length(NA) is 1. There is
a place for something but it was missing or undefined.
IEEE arithmetic introduced NaN, which means "there should be something
here but your calculation went wrong, the *mathematical* result might
be defined but this machine cannot compute it."
Frankly, IEEE arithmetic made a lot of things simpler, but a lot of
other things more complicated.  You should see what it did to
floating-point comparison in C.

As for the syntax of S, it comes from the same organisation as C.
Having used GLIM, GENSTSTAT, SPSS, and BASIS (don't ask), S was a
revelation that statistics environments did not have to be arcane.

As for the documentation of R, it's pretty much the best of any open
source programming/statistics tool I've used, and most impressively,
has a huge library of packages whose authors have also produced
comparatively good documentation, but the standards of free software.

Run time error messages?  Yes, they could be improved.  Quite a bit.
You've probably heard about the famous Multics error message.  One
day, on startup at a Multics site, the machine wrote
   Hodie natus est radici frater.
You probably haven't heard about the Burroughs B6700 ESPOL compiler.
One of its error messages was
   IF YOU KNOW WHAT THIS MEANS, IMPLEMENT IT.
It's an open source project.  If you think an error message could be
improved, you can patch your copy and send the patch to the maintainer.
The following sentence was written by a biostatistician:
"Help files are frequently more than a little obscure."
That was written about a commercial package, not R.

SPSS costs NZD 156/month for one user, or about NZD 1871/year.
SAS prices are scary.  I don't know what the licence terms for the
free-as-in-beer "University Edition" are; since I'm no longer at a
university I suspect I wouldn't qualify.
I rather liked GLIM, but it's dead, and the syntax was idiosyncratic.
I also rather liked GENSTAT, but when you look for the price and are
invited to "ask for a quote", my "I-can't-afford-this" alarm goes off.
Plus the pages I viewed are for Windows only.

Thing is, for the price of one year for one user on one machine,
you could fund quite a bit of error message improvement for R.

As for slavery and the Bible, what's translated "slavery" in the OT is
not the "chattel slavery" that was practiced in the 19th century.
Slavery was banned in England by William the Conqueror, of all
people, and the first "official" ban on slavery by any religion that I
ever heard of was when the Vatican ruled that the native
inhabitants of the Americas could not be made slaves.  Many of
the Abolitionists derived their opposition to chattel slavery from
the Bible.  The practice of African slavery was, as a matter of
history, learned from another religion entirely, whose prophet
bought and sold black slaves himself.

Serfdom is close to slavery.  ("Serf" comes from "servus".)
http://www.scottishmining.co.uk/429.html
describes the way salt-workers and colliers were bound to the
land in Scotland, so that 'And thus it came about that the nineteenth century
had dawned before it could be said in truth of Scotland, in the words
of Cowper:?
There are no slaves at home : then why abroad?"'
These were native Scots.

Enslavement is the vile extreme of the desire to control other people.
Let those who oppose slavery oppose that desire whatever form it takes.
(Want to read about man's inhumanity to man?  Read "The Gulag Archipelago.")

Can we perhaps return to helping each other with the use of R?


From |@ngbnj @end|ng |rom gm@||@com  Fri Sep 20 11:36:34 2019
From: |@ngbnj @end|ng |rom gm@||@com (Benjamin Lang)
Date: Fri, 20 Sep 2019 11:36:34 +0200
Subject: [R] [SPAM] Re:  The "--slave" option
In-Reply-To: <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
Message-ID: <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>

Hi Richard,

Sure, it's a silly example, but it makes about as much sense as using
"slave" to mean "quiet". Also, there is no "--master" option so it's not
exactly the master/slave terminology here either.

My only point is that I think it's very distasteful to give such a
needlessly awful name to an option in what has become a very broadly used
piece of software. It would be good to update it, I think.

If anyone knows how to actually pass this on to the R
developers/contributors, please let me know.

Thanks,
Ben

On Fri, 20 Sep 2019 at 05:14, Richard O'Keefe <raoknz at gmail.com> wrote:

> Nobody would use "stentorian" as an alternative to "verbose" because they
> mean very different things.
>   "verbose" means "using many words"
>   "stentorian" means "talking very loudly, like Stentor, whose voice was
> as powerful
>                       as fifty voices of other men".
> You can be verbose while talking in a whisper.
> You can be stentorian while being laconic.
>
> If you don't like the word "slave", the option "--silent" is there for you
> to use.
>
> The "master-slave" design pattern is in hundreds of books (although I note
> that
> Erlang uses different terminology).  Your car has a master hydraulic
> cylinder and
> slave cylinders.  The analogy is pervasive in technology.  See a very
> short list
> at https://en.wikipedia.org/wiki/Master/slave_(technology)
> which ends with "Global Language Monitor
> <https://en.wikipedia.org/wiki/Global_Language_Monitor> found the term
> "master/slave" to be the most
> egregious example of political correctness
> <https://en.wikipedia.org/wiki/Political_correctness> in 2004, and named
> it the most politically
> incorrect term of that year."
>
> The one thing "slave" does not mean in technology is any kind of human
> being.
>
> On Thu, 19 Sep 2019 at 21:51, Benjamin Lang <langbnj at gmail.com> wrote:
>
>> Dear Richard,
>>
>> Thank you, that?s interesting. There is also something called an
>> ?etymological fallacy?. I think current usage is more useful here than the
>> ?science of truth?, i.e. the Ancient Greek idea that the (sometimes
>> inferred) derivation of a word allows us to grasp ?the truth of it?.
>>
>> In current usage, a ?server? is someone who brings you dishes in a
>> restaurant. A ?client? is a customer. A ?slave? is a human being forced to
>> perform work under duress and considered nothing more than a machine, say a
>> dishwasher or a tractor. And in some regions, this echoes on and is
>> offensive and hurtful to some.
>>
>> A new user, wanting to reduce output from R, would probably reach for
>> ?-q? or ??quiet?. This makes sense in the same way that ??stentorian? is
>> not a good alternative to ??verbose?.
>>
>> Best,
>> Ben
>>
>> On 19 Sep 2019, at 10:55, Richard O'Keefe <raoknz at gmail.com> wrote:
>>
>> One of my grandfathers was from Croatia.  Guess what the word "slave" is
>> derived
>> from?  That's right, Slavs.  This goes back to the 9th century.  And then
>> of course
>> my grandfather's people were enslaved by the Ottoman empire, which was
>> only defeated
>> a little over a hundred years ago.  My other grandfather was from the
>> British isles,
>> where to this day followers of the same prophet are enslaving people like
>> me
>> (except for being female).  So I'm sorry, but I'm not impressed.
>>
>> How many computers are "servers"?  There's that whole client-server thing.
>> Guess what "server" comes from?  That's right, the Latin word "servus",
>> which
>> means guess what?  You got it again: "slave".  Are we to abolish the word
>> "server"?  What about the word "client"?  Ah, that's part of the
>> client-patron
>> system from Rome, so what about the patriarchy, eh?
>>
>> We are dealing with something called "the genetic fallacy".
>> "The genetic *fallacy* (also known as the *fallacy of origins* ...)
>>  is a *fallacy* of irrelevance that is based solely on someone's
>>  or something's history, *origin*, or source rather than its
>>  current meaning or context."  (Wikipedia.)
>>
>> Context matters.
>>
>>
>>
>> On Thu, 19 Sep 2019 at 17:10, Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>>> > Personally I much prefer backwards compatibility to political
>>> correctness.
>>>
>>> I agree with Rolf, here.
>>> And as someone that's planning to write a Linux Terminal Emulator, in
>>> the medium-term future, I *strongly* defend this approach.
>>>
>>> And to the original poster.
>>> Haven't you seen The Matrix?
>>> (Second best movie ever, after the Shawshank Redemption).
>>>
>>> I would prefer the technology to be my slave, than I be a
>>> prisoner/slave to the technology.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From mr@hm@nku|mrt @end|ng |rom gm@||@com  Fri Sep 20 13:15:18 2019
From: mr@hm@nku|mrt @end|ng |rom gm@||@com (Moshiur Rahman)
Date: Fri, 20 Sep 2019 20:15:18 +0900
Subject: [R] annotation help in ggplot2
In-Reply-To: <CAODjwAG8VChCCibZx85MSYG0817jF-p6F=msRw73Zq5x1owCTw@mail.gmail.com>
References: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>
 <CAODjwAGqH3+_co6sXePONPdvLjT7F3JXeMfPhf66ov-qbcu6+Q@mail.gmail.com>
 <CAGNSkSn4MkGuwLeoBLbgNbO8JFD7cWOARDCv_FJCu9OOoYGZkw@mail.gmail.com>
 <CAODjwAG8VChCCibZx85MSYG0817jF-p6F=msRw73Zq5x1owCTw@mail.gmail.com>
Message-ID: <CAGNSkS=G5jN0QwHRkquzkoVE3CFbtDZb_3672KBpS+VV4Kr6nQ@mail.gmail.com>

Thanks a lot Rishi for your very cordial effort and great help. But still I
need some help to improve it as the plot doesn't clearly depict which
female belongs to which family and this can be detected by drawing a line
from 1-4 for F1, 5-8 for F2....

Another problem I can see that the position of MID (P1,2,3...) is not
looking well which are somehow noisy.

Finally, can we drop the bars at the bottom of x-axis that I did
with scale_y_continuous?

Please do me some favour to complete this plot which I need for a
publication.

With kind regards,

Moshi

On Fri, Sep 20, 2019 at 7:45 PM ??? ( ??? / rIsHi ) <rishi.dasroy at gmail.com>
wrote:

> Here is the solution inspired by this post
> https://stackoverflow.com/questions/18165863/multirow-axis-labels-with-nested-grouping-variables
>
>
> > data$Female <-  factor(data$Female, levels =
> c("F1","F2","F3","F4","F5","F6","F7","F8","F9","F10"))
> >
> ggplot(data,aes(x=family,y=offs.surv.perct,fill=treat))+geom_bar(stat="identity",
> position="dodge")+
>   geom_text(aes(label = MID),  angle=90)+
>   facet_wrap(~Female, strip.position = "bottom", scales = "free_x",nrow=1)+
>   theme(panel.spacing = unit(0, "lines"),
>         strip.background = element_blank(),
>         strip.placement = "outside")
>
>
> On Fri, Sep 20, 2019 at 11:51 AM Moshiur Rahman <mrahmankufmrt at gmail.com>
> wrote:
>
>> Thanks Rishi,
>>
>> Please find attached the data herewith.
>>
>>
>>
>> On Fri, Sep 20, 2019 at 5:48 PM ??? ( ??? / rIsHi ) <
>> rishi.dasroy at gmail.com> wrote:
>>
>>> There are no attached data .
>>>
>>> On Fri, Sep 20, 2019 at 11:40 AM Moshiur Rahman <mrahmankufmrt at gmail.com>
>>> wrote:
>>>
>>>> Dear ggplot2 experts,
>>>>
>>>> I'm struggling to make a plot having family id in x-axis and female id
>>>> below that family id where each 4 families have a single female id.
>>>>
>>>> I also need to add male id on top of each bar which I can do before
>>>> grid.arrange, but fail after doing it. So, any suggestions?
>>>>
>>>> Please find below my codes and help me to complete it perfectly.
>>>> #data
>>>> data <- read.table("R-help_ggplot2.csv", header=TRUE, sep=",")
>>>> names(data)
>>>> #packages
>>>> library(ggplot2)
>>>> library(grid)
>>>> library(gridExtra)
>>>> library(scales)
>>>> library(ggpubr)
>>>> #plot codes
>>>> p1 =
>>>> ggplot(data,aes(x=factor(family),y=offs.surv.perct,fill=factor(treat)))+
>>>>     geom_bar(stat="identity", position="dodge")+
>>>>     #facet_wrap(~ Female)+
>>>>     geom_bar(stat="identity", position="dodge", colour="black",
>>>> show.legend= TRUE) + # show_guide = TRUE gives legend boarder
>>>>     #geom_hline(yintercept=15, size=0.5, linetype = 2)+ ### middle line
>>>>     scale_fill_manual(values=c("grey", "white")) + # grey80 is closer to
>>>> white than black
>>>>     xlab("Family") +
>>>>     ylab (expression(paste("Offspring survival rate (%)"))) +
>>>>     #coord_cartesian(xlim=c(0,40), ylim=c(0,60), clip="off")+
>>>>     scale_y_continuous(expand = c(0, 0), limits = c(0, 60))+
>>>>     theme(legend.title = element_text(colour="black", size=12))+
>>>>     theme(legend.text = element_text(colour="black", size=11))+
>>>>     theme(legend.background = element_blank())+
>>>>     theme(legend.key = element_blank())+
>>>>     theme(legend.box.background = element_blank())+
>>>>     theme(legend.key.size = unit(2, "mm"),legend.key.width =
>>>> unit(0.5,"cm"))+
>>>>     theme(legend.position=c(0.05,0.9),legend.direction
>>>> ="vertical",legend.box = "vertical")+ # add legend on top
>>>>     theme(panel.background = element_rect(fill = "transparent"))+
>>>>     theme(axis.line = element_line(colour =
>>>> "black"),axis.text.x=element_text(size=10,
>>>> colour="black"),axis.text.y=element_text(size=10, colour="black"),
>>>>         axis.title.y = element_text(size=12, colour =
>>>> "black",margin=margin(0,5,0,0)),
>>>>         axis.title.x = element_blank(),
>>>>         strip.text.x = element_blank(),# remove top level title (high
>>>> and
>>>> low)
>>>>         strip.background = element_blank(),# remove top level background
>>>>         panel.grid.major = element_blank(),# remove grid line within the
>>>> plot
>>>>         panel.grid.minor = element_blank(),
>>>>         panel.border = element_blank())
>>>> p1
>>>>
>>>> ### legend correction
>>>> p2<- p1 + guides(fill = guide_legend(title="Fertilization
>>>> group",keywidth =
>>>> 1,keyheight = 1,
>>>>                              title.theme = element_text(size=12, colour
>>>> =
>>>> "black", angle = 0)))+
>>>>   theme(legend.text = element_text(size = 12, colour = "black", angle =
>>>> 0))
>>>>
>>>> p2
>>>>
>>>> ###plot margins
>>>> p3<-p2+theme(plot.margin = unit(c(1,1,1.7,1), "lines"))
>>>> p3
>>>>
>>>> #x-axis label
>>>> p4<-grid.arrange(
>>>>   p3,
>>>>   bottom = textGrob(
>>>>     "Family and female number",
>>>>     gp = gpar(fontsize = 12, cex=1), #fontface = "bold",
>>>>     vjust = 0.5, hjust = 0.5,x = 0.52))
>>>>
>>>> # annotation (NOT WORKING)
>>>> p5<-p4+annotate("text", label = "M1", x = 1, y = 25.03, fontface = 1,
>>>> size=3,angle = 90)
>>>> p5
>>>> p6<-p5+annotate("text", label = "M2", x = 2, y = 18.37, fontface = 1,
>>>> size=3,angle = 90)
>>>> p6
>>>> p7<-p6+annotate("text", label = "M3", x = 3, y = 21.7, fontface = 1,
>>>> size=3,angle = 90)
>>>> p7
>>>> p8<-p7+annotate("text", label = "M1-2-3", x = 4, y = 19.1, fontface= 1,
>>>> size=3,angle = 90)
>>>> p8
>>>> Fig1.1<-p8+annotate("segment", size=0.3, x=c(1,1,4),xend=c(1,4,4),
>>>>                          y= c(26,28,28), yend=c(28,28,21))+
>>>>   annotate("text",x=2.45,y=29.5,fontface = 1, size=3,angle =
>>>> 90,label=c("F1"))
>>>>
>>>> Fig1.1
>>>>
>>>> Please find attached also my data.
>>>>
>>>> Any assistance will be highly appreciated.
>>>>
>>>> Regards,
>>>>
>>>> Moshi
>>>>
>>>>
>>>> JSPS Postdoctoral Fellow
>>>> Laboratory of Population Biology
>>>> Department of Marine Biosciences
>>>> Graduate School of Marine Science and Technology
>>>> Tokyo University of Marine Science and Technology
>>>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
>>>> Mobile: 050-6874-9072
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>>
>>>
>>>
>>> With regards
>>> Rishi Das Roy
>>>
>>
>>
>> --
>> Md. Moshiur Rahman, PhD
>>
>> JSPS Postdoctoral Fellow
>> Laboratory of Population Biology
>> Department of Marine Biosciences
>> Graduate School of Marine Science and Technology
>> Tokyo University of Marine Science and Technology
>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
>> Mobile: 050-6874-9072
>>
>> .........................
>>
>> Professor
>> Fisheries and Marine Resource Technology Discipline
>> Khulna University, Khulna - 9208
>> BANGLADESH.
>> Google scholar:
>> https://scholar.google.com.au/citations?user=uElrJSsAAAAJ&hl=en
>> ResearchGate: https://www.researchgate.net/profile/Md_Moshiur_Rahman2
>> ORCID: https://orcid.org/my-orcid
>>
>
>
> --
>
>
>
> With regards
> Rishi Das Roy
>


-- 
Md. Moshiur Rahman, PhD

JSPS Postdoctoral Fellow
Laboratory of Population Biology
Department of Marine Biosciences
Graduate School of Marine Science and Technology
Tokyo University of Marine Science and Technology
4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
Mobile: 050-6874-9072

.........................

Professor
Fisheries and Marine Resource Technology Discipline
Khulna University, Khulna - 9208
BANGLADESH.
Google scholar:
https://scholar.google.com.au/citations?user=uElrJSsAAAAJ&hl=en
ResearchGate: https://www.researchgate.net/profile/Md_Moshiur_Rahman2
ORCID: https://orcid.org/my-orcid

	[[alternative HTML version deleted]]


From r|@h|@d@@roy @end|ng |rom gm@||@com  Fri Sep 20 10:47:55 2019
From: r|@h|@d@@roy @end|ng |rom gm@||@com (=?UTF-8?B?4KaL4Ka34Ka/ICAoIOCki+Ckt+CkvyAvIHJJc0hpICk=?=)
Date: Fri, 20 Sep 2019 11:47:55 +0300
Subject: [R] annotation help in ggplot2
In-Reply-To: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>
References: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>
Message-ID: <CAODjwAGqH3+_co6sXePONPdvLjT7F3JXeMfPhf66ov-qbcu6+Q@mail.gmail.com>

There are no attached data .

On Fri, Sep 20, 2019 at 11:40 AM Moshiur Rahman <mrahmankufmrt at gmail.com>
wrote:

> Dear ggplot2 experts,
>
> I'm struggling to make a plot having family id in x-axis and female id
> below that family id where each 4 families have a single female id.
>
> I also need to add male id on top of each bar which I can do before
> grid.arrange, but fail after doing it. So, any suggestions?
>
> Please find below my codes and help me to complete it perfectly.
> #data
> data <- read.table("R-help_ggplot2.csv", header=TRUE, sep=",")
> names(data)
> #packages
> library(ggplot2)
> library(grid)
> library(gridExtra)
> library(scales)
> library(ggpubr)
> #plot codes
> p1 =
> ggplot(data,aes(x=factor(family),y=offs.surv.perct,fill=factor(treat)))+
>     geom_bar(stat="identity", position="dodge")+
>     #facet_wrap(~ Female)+
>     geom_bar(stat="identity", position="dodge", colour="black",
> show.legend= TRUE) + # show_guide = TRUE gives legend boarder
>     #geom_hline(yintercept=15, size=0.5, linetype = 2)+ ### middle line
>     scale_fill_manual(values=c("grey", "white")) + # grey80 is closer to
> white than black
>     xlab("Family") +
>     ylab (expression(paste("Offspring survival rate (%)"))) +
>     #coord_cartesian(xlim=c(0,40), ylim=c(0,60), clip="off")+
>     scale_y_continuous(expand = c(0, 0), limits = c(0, 60))+
>     theme(legend.title = element_text(colour="black", size=12))+
>     theme(legend.text = element_text(colour="black", size=11))+
>     theme(legend.background = element_blank())+
>     theme(legend.key = element_blank())+
>     theme(legend.box.background = element_blank())+
>     theme(legend.key.size = unit(2, "mm"),legend.key.width =
> unit(0.5,"cm"))+
>     theme(legend.position=c(0.05,0.9),legend.direction
> ="vertical",legend.box = "vertical")+ # add legend on top
>     theme(panel.background = element_rect(fill = "transparent"))+
>     theme(axis.line = element_line(colour =
> "black"),axis.text.x=element_text(size=10,
> colour="black"),axis.text.y=element_text(size=10, colour="black"),
>         axis.title.y = element_text(size=12, colour =
> "black",margin=margin(0,5,0,0)),
>         axis.title.x = element_blank(),
>         strip.text.x = element_blank(),# remove top level title (high and
> low)
>         strip.background = element_blank(),# remove top level background
>         panel.grid.major = element_blank(),# remove grid line within the
> plot
>         panel.grid.minor = element_blank(),
>         panel.border = element_blank())
> p1
>
> ### legend correction
> p2<- p1 + guides(fill = guide_legend(title="Fertilization group",keywidth =
> 1,keyheight = 1,
>                              title.theme = element_text(size=12, colour =
> "black", angle = 0)))+
>   theme(legend.text = element_text(size = 12, colour = "black", angle = 0))
>
> p2
>
> ###plot margins
> p3<-p2+theme(plot.margin = unit(c(1,1,1.7,1), "lines"))
> p3
>
> #x-axis label
> p4<-grid.arrange(
>   p3,
>   bottom = textGrob(
>     "Family and female number",
>     gp = gpar(fontsize = 12, cex=1), #fontface = "bold",
>     vjust = 0.5, hjust = 0.5,x = 0.52))
>
> # annotation (NOT WORKING)
> p5<-p4+annotate("text", label = "M1", x = 1, y = 25.03, fontface = 1,
> size=3,angle = 90)
> p5
> p6<-p5+annotate("text", label = "M2", x = 2, y = 18.37, fontface = 1,
> size=3,angle = 90)
> p6
> p7<-p6+annotate("text", label = "M3", x = 3, y = 21.7, fontface = 1,
> size=3,angle = 90)
> p7
> p8<-p7+annotate("text", label = "M1-2-3", x = 4, y = 19.1, fontface= 1,
> size=3,angle = 90)
> p8
> Fig1.1<-p8+annotate("segment", size=0.3, x=c(1,1,4),xend=c(1,4,4),
>                          y= c(26,28,28), yend=c(28,28,21))+
>   annotate("text",x=2.45,y=29.5,fontface = 1, size=3,angle =
> 90,label=c("F1"))
>
> Fig1.1
>
> Please find attached also my data.
>
> Any assistance will be highly appreciated.
>
> Regards,
>
> Moshi
>
>
> JSPS Postdoctoral Fellow
> Laboratory of Population Biology
> Department of Marine Biosciences
> Graduate School of Marine Science and Technology
> Tokyo University of Marine Science and Technology
> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
> Mobile: 050-6874-9072
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 



With regards
Rishi Das Roy

	[[alternative HTML version deleted]]


From r|@h|@d@@roy @end|ng |rom gm@||@com  Fri Sep 20 12:45:42 2019
From: r|@h|@d@@roy @end|ng |rom gm@||@com (=?UTF-8?B?4KaL4Ka34Ka/ICAoIOCki+Ckt+CkvyAvIHJJc0hpICk=?=)
Date: Fri, 20 Sep 2019 13:45:42 +0300
Subject: [R] annotation help in ggplot2
In-Reply-To: <CAGNSkSn4MkGuwLeoBLbgNbO8JFD7cWOARDCv_FJCu9OOoYGZkw@mail.gmail.com>
References: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>
 <CAODjwAGqH3+_co6sXePONPdvLjT7F3JXeMfPhf66ov-qbcu6+Q@mail.gmail.com>
 <CAGNSkSn4MkGuwLeoBLbgNbO8JFD7cWOARDCv_FJCu9OOoYGZkw@mail.gmail.com>
Message-ID: <CAODjwAG8VChCCibZx85MSYG0817jF-p6F=msRw73Zq5x1owCTw@mail.gmail.com>

Here is the solution inspired by this post
https://stackoverflow.com/questions/18165863/multirow-axis-labels-with-nested-grouping-variables


> data$Female <-  factor(data$Female, levels =
c("F1","F2","F3","F4","F5","F6","F7","F8","F9","F10"))
>
ggplot(data,aes(x=family,y=offs.surv.perct,fill=treat))+geom_bar(stat="identity",
position="dodge")+
  geom_text(aes(label = MID),  angle=90)+
  facet_wrap(~Female, strip.position = "bottom", scales = "free_x",nrow=1)+
  theme(panel.spacing = unit(0, "lines"),
        strip.background = element_blank(),
        strip.placement = "outside")


On Fri, Sep 20, 2019 at 11:51 AM Moshiur Rahman <mrahmankufmrt at gmail.com>
wrote:

> Thanks Rishi,
>
> Please find attached the data herewith.
>
>
>
> On Fri, Sep 20, 2019 at 5:48 PM ??? ( ??? / rIsHi ) <
> rishi.dasroy at gmail.com> wrote:
>
>> There are no attached data .
>>
>> On Fri, Sep 20, 2019 at 11:40 AM Moshiur Rahman <mrahmankufmrt at gmail.com>
>> wrote:
>>
>>> Dear ggplot2 experts,
>>>
>>> I'm struggling to make a plot having family id in x-axis and female id
>>> below that family id where each 4 families have a single female id.
>>>
>>> I also need to add male id on top of each bar which I can do before
>>> grid.arrange, but fail after doing it. So, any suggestions?
>>>
>>> Please find below my codes and help me to complete it perfectly.
>>> #data
>>> data <- read.table("R-help_ggplot2.csv", header=TRUE, sep=",")
>>> names(data)
>>> #packages
>>> library(ggplot2)
>>> library(grid)
>>> library(gridExtra)
>>> library(scales)
>>> library(ggpubr)
>>> #plot codes
>>> p1 =
>>> ggplot(data,aes(x=factor(family),y=offs.surv.perct,fill=factor(treat)))+
>>>     geom_bar(stat="identity", position="dodge")+
>>>     #facet_wrap(~ Female)+
>>>     geom_bar(stat="identity", position="dodge", colour="black",
>>> show.legend= TRUE) + # show_guide = TRUE gives legend boarder
>>>     #geom_hline(yintercept=15, size=0.5, linetype = 2)+ ### middle line
>>>     scale_fill_manual(values=c("grey", "white")) + # grey80 is closer to
>>> white than black
>>>     xlab("Family") +
>>>     ylab (expression(paste("Offspring survival rate (%)"))) +
>>>     #coord_cartesian(xlim=c(0,40), ylim=c(0,60), clip="off")+
>>>     scale_y_continuous(expand = c(0, 0), limits = c(0, 60))+
>>>     theme(legend.title = element_text(colour="black", size=12))+
>>>     theme(legend.text = element_text(colour="black", size=11))+
>>>     theme(legend.background = element_blank())+
>>>     theme(legend.key = element_blank())+
>>>     theme(legend.box.background = element_blank())+
>>>     theme(legend.key.size = unit(2, "mm"),legend.key.width =
>>> unit(0.5,"cm"))+
>>>     theme(legend.position=c(0.05,0.9),legend.direction
>>> ="vertical",legend.box = "vertical")+ # add legend on top
>>>     theme(panel.background = element_rect(fill = "transparent"))+
>>>     theme(axis.line = element_line(colour =
>>> "black"),axis.text.x=element_text(size=10,
>>> colour="black"),axis.text.y=element_text(size=10, colour="black"),
>>>         axis.title.y = element_text(size=12, colour =
>>> "black",margin=margin(0,5,0,0)),
>>>         axis.title.x = element_blank(),
>>>         strip.text.x = element_blank(),# remove top level title (high and
>>> low)
>>>         strip.background = element_blank(),# remove top level background
>>>         panel.grid.major = element_blank(),# remove grid line within the
>>> plot
>>>         panel.grid.minor = element_blank(),
>>>         panel.border = element_blank())
>>> p1
>>>
>>> ### legend correction
>>> p2<- p1 + guides(fill = guide_legend(title="Fertilization
>>> group",keywidth =
>>> 1,keyheight = 1,
>>>                              title.theme = element_text(size=12, colour =
>>> "black", angle = 0)))+
>>>   theme(legend.text = element_text(size = 12, colour = "black", angle =
>>> 0))
>>>
>>> p2
>>>
>>> ###plot margins
>>> p3<-p2+theme(plot.margin = unit(c(1,1,1.7,1), "lines"))
>>> p3
>>>
>>> #x-axis label
>>> p4<-grid.arrange(
>>>   p3,
>>>   bottom = textGrob(
>>>     "Family and female number",
>>>     gp = gpar(fontsize = 12, cex=1), #fontface = "bold",
>>>     vjust = 0.5, hjust = 0.5,x = 0.52))
>>>
>>> # annotation (NOT WORKING)
>>> p5<-p4+annotate("text", label = "M1", x = 1, y = 25.03, fontface = 1,
>>> size=3,angle = 90)
>>> p5
>>> p6<-p5+annotate("text", label = "M2", x = 2, y = 18.37, fontface = 1,
>>> size=3,angle = 90)
>>> p6
>>> p7<-p6+annotate("text", label = "M3", x = 3, y = 21.7, fontface = 1,
>>> size=3,angle = 90)
>>> p7
>>> p8<-p7+annotate("text", label = "M1-2-3", x = 4, y = 19.1, fontface= 1,
>>> size=3,angle = 90)
>>> p8
>>> Fig1.1<-p8+annotate("segment", size=0.3, x=c(1,1,4),xend=c(1,4,4),
>>>                          y= c(26,28,28), yend=c(28,28,21))+
>>>   annotate("text",x=2.45,y=29.5,fontface = 1, size=3,angle =
>>> 90,label=c("F1"))
>>>
>>> Fig1.1
>>>
>>> Please find attached also my data.
>>>
>>> Any assistance will be highly appreciated.
>>>
>>> Regards,
>>>
>>> Moshi
>>>
>>>
>>> JSPS Postdoctoral Fellow
>>> Laboratory of Population Biology
>>> Department of Marine Biosciences
>>> Graduate School of Marine Science and Technology
>>> Tokyo University of Marine Science and Technology
>>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
>>> Mobile: 050-6874-9072
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>>
>>
>>
>> With regards
>> Rishi Das Roy
>>
>
>
> --
> Md. Moshiur Rahman, PhD
>
> JSPS Postdoctoral Fellow
> Laboratory of Population Biology
> Department of Marine Biosciences
> Graduate School of Marine Science and Technology
> Tokyo University of Marine Science and Technology
> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
> Mobile: 050-6874-9072
>
> .........................
>
> Professor
> Fisheries and Marine Resource Technology Discipline
> Khulna University, Khulna - 9208
> BANGLADESH.
> Google scholar:
> https://scholar.google.com.au/citations?user=uElrJSsAAAAJ&hl=en
> ResearchGate: https://www.researchgate.net/profile/Md_Moshiur_Rahman2
> ORCID: https://orcid.org/my-orcid
>


-- 



With regards
Rishi Das Roy

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Sep 20 15:26:53 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 20 Sep 2019 06:26:53 -0700
Subject: [R] annotation help in ggplot2
In-Reply-To: <CAGNSkS=G5jN0QwHRkquzkoVE3CFbtDZb_3672KBpS+VV4Kr6nQ@mail.gmail.com>
References: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>
 <CAODjwAGqH3+_co6sXePONPdvLjT7F3JXeMfPhf66ov-qbcu6+Q@mail.gmail.com>
 <CAGNSkSn4MkGuwLeoBLbgNbO8JFD7cWOARDCv_FJCu9OOoYGZkw@mail.gmail.com>
 <CAODjwAG8VChCCibZx85MSYG0817jF-p6F=msRw73Zq5x1owCTw@mail.gmail.com>
 <CAGNSkS=G5jN0QwHRkquzkoVE3CFbtDZb_3672KBpS+VV4Kr6nQ@mail.gmail.com>
Message-ID: <03BF4B17-F120-46DA-BEDB-8C4C6FF2F72F@dcn.davis.ca.us>

Using this list as a labor pool to procure code for generating publication-quality plots is abuse. Please read the Posting Guide and the documentation for the ggplot package or go pay someone offlist for their services.

On September 20, 2019 4:15:18 AM PDT, Moshiur Rahman <mrahmankufmrt at gmail.com> wrote:
>Thanks a lot Rishi for your very cordial effort and great help. But
>still I
>need some help to improve it as the plot doesn't clearly depict which
>female belongs to which family and this can be detected by drawing a
>line
>from 1-4 for F1, 5-8 for F2....
>
>Another problem I can see that the position of MID (P1,2,3...) is not
>looking well which are somehow noisy.
>
>Finally, can we drop the bars at the bottom of x-axis that I did
>with scale_y_continuous?
>
>Please do me some favour to complete this plot which I need for a
>publication.
>
>With kind regards,
>
>Moshi
>
>On Fri, Sep 20, 2019 at 7:45 PM ??? ( ??? / rIsHi )
><rishi.dasroy at gmail.com>
>wrote:
>
>> Here is the solution inspired by this post
>>
>https://stackoverflow.com/questions/18165863/multirow-axis-labels-with-nested-grouping-variables
>>
>>
>> > data$Female <-  factor(data$Female, levels =
>> c("F1","F2","F3","F4","F5","F6","F7","F8","F9","F10"))
>> >
>>
>ggplot(data,aes(x=family,y=offs.surv.perct,fill=treat))+geom_bar(stat="identity",
>> position="dodge")+
>>   geom_text(aes(label = MID),  angle=90)+
>>   facet_wrap(~Female, strip.position = "bottom", scales =
>"free_x",nrow=1)+
>>   theme(panel.spacing = unit(0, "lines"),
>>         strip.background = element_blank(),
>>         strip.placement = "outside")
>>
>>
>> On Fri, Sep 20, 2019 at 11:51 AM Moshiur Rahman
><mrahmankufmrt at gmail.com>
>> wrote:
>>
>>> Thanks Rishi,
>>>
>>> Please find attached the data herewith.
>>>
>>>
>>>
>>> On Fri, Sep 20, 2019 at 5:48 PM ??? ( ??? / rIsHi ) <
>>> rishi.dasroy at gmail.com> wrote:
>>>
>>>> There are no attached data .
>>>>
>>>> On Fri, Sep 20, 2019 at 11:40 AM Moshiur Rahman
><mrahmankufmrt at gmail.com>
>>>> wrote:
>>>>
>>>>> Dear ggplot2 experts,
>>>>>
>>>>> I'm struggling to make a plot having family id in x-axis and
>female id
>>>>> below that family id where each 4 families have a single female
>id.
>>>>>
>>>>> I also need to add male id on top of each bar which I can do
>before
>>>>> grid.arrange, but fail after doing it. So, any suggestions?
>>>>>
>>>>> Please find below my codes and help me to complete it perfectly.
>>>>> #data
>>>>> data <- read.table("R-help_ggplot2.csv", header=TRUE, sep=",")
>>>>> names(data)
>>>>> #packages
>>>>> library(ggplot2)
>>>>> library(grid)
>>>>> library(gridExtra)
>>>>> library(scales)
>>>>> library(ggpubr)
>>>>> #plot codes
>>>>> p1 =
>>>>>
>ggplot(data,aes(x=factor(family),y=offs.surv.perct,fill=factor(treat)))+
>>>>>     geom_bar(stat="identity", position="dodge")+
>>>>>     #facet_wrap(~ Female)+
>>>>>     geom_bar(stat="identity", position="dodge", colour="black",
>>>>> show.legend= TRUE) + # show_guide = TRUE gives legend boarder
>>>>>     #geom_hline(yintercept=15, size=0.5, linetype = 2)+ ### middle
>line
>>>>>     scale_fill_manual(values=c("grey", "white")) + # grey80 is
>closer to
>>>>> white than black
>>>>>     xlab("Family") +
>>>>>     ylab (expression(paste("Offspring survival rate (%)"))) +
>>>>>     #coord_cartesian(xlim=c(0,40), ylim=c(0,60), clip="off")+
>>>>>     scale_y_continuous(expand = c(0, 0), limits = c(0, 60))+
>>>>>     theme(legend.title = element_text(colour="black", size=12))+
>>>>>     theme(legend.text = element_text(colour="black", size=11))+
>>>>>     theme(legend.background = element_blank())+
>>>>>     theme(legend.key = element_blank())+
>>>>>     theme(legend.box.background = element_blank())+
>>>>>     theme(legend.key.size = unit(2, "mm"),legend.key.width =
>>>>> unit(0.5,"cm"))+
>>>>>     theme(legend.position=c(0.05,0.9),legend.direction
>>>>> ="vertical",legend.box = "vertical")+ # add legend on top
>>>>>     theme(panel.background = element_rect(fill = "transparent"))+
>>>>>     theme(axis.line = element_line(colour =
>>>>> "black"),axis.text.x=element_text(size=10,
>>>>> colour="black"),axis.text.y=element_text(size=10, colour="black"),
>>>>>         axis.title.y = element_text(size=12, colour =
>>>>> "black",margin=margin(0,5,0,0)),
>>>>>         axis.title.x = element_blank(),
>>>>>         strip.text.x = element_blank(),# remove top level title
>(high
>>>>> and
>>>>> low)
>>>>>         strip.background = element_blank(),# remove top level
>background
>>>>>         panel.grid.major = element_blank(),# remove grid line
>within the
>>>>> plot
>>>>>         panel.grid.minor = element_blank(),
>>>>>         panel.border = element_blank())
>>>>> p1
>>>>>
>>>>> ### legend correction
>>>>> p2<- p1 + guides(fill = guide_legend(title="Fertilization
>>>>> group",keywidth =
>>>>> 1,keyheight = 1,
>>>>>                              title.theme = element_text(size=12,
>colour
>>>>> =
>>>>> "black", angle = 0)))+
>>>>>   theme(legend.text = element_text(size = 12, colour = "black",
>angle =
>>>>> 0))
>>>>>
>>>>> p2
>>>>>
>>>>> ###plot margins
>>>>> p3<-p2+theme(plot.margin = unit(c(1,1,1.7,1), "lines"))
>>>>> p3
>>>>>
>>>>> #x-axis label
>>>>> p4<-grid.arrange(
>>>>>   p3,
>>>>>   bottom = textGrob(
>>>>>     "Family and female number",
>>>>>     gp = gpar(fontsize = 12, cex=1), #fontface = "bold",
>>>>>     vjust = 0.5, hjust = 0.5,x = 0.52))
>>>>>
>>>>> # annotation (NOT WORKING)
>>>>> p5<-p4+annotate("text", label = "M1", x = 1, y = 25.03, fontface =
>1,
>>>>> size=3,angle = 90)
>>>>> p5
>>>>> p6<-p5+annotate("text", label = "M2", x = 2, y = 18.37, fontface =
>1,
>>>>> size=3,angle = 90)
>>>>> p6
>>>>> p7<-p6+annotate("text", label = "M3", x = 3, y = 21.7, fontface =
>1,
>>>>> size=3,angle = 90)
>>>>> p7
>>>>> p8<-p7+annotate("text", label = "M1-2-3", x = 4, y = 19.1,
>fontface= 1,
>>>>> size=3,angle = 90)
>>>>> p8
>>>>> Fig1.1<-p8+annotate("segment", size=0.3, x=c(1,1,4),xend=c(1,4,4),
>>>>>                          y= c(26,28,28), yend=c(28,28,21))+
>>>>>   annotate("text",x=2.45,y=29.5,fontface = 1, size=3,angle =
>>>>> 90,label=c("F1"))
>>>>>
>>>>> Fig1.1
>>>>>
>>>>> Please find attached also my data.
>>>>>
>>>>> Any assistance will be highly appreciated.
>>>>>
>>>>> Regards,
>>>>>
>>>>> Moshi
>>>>>
>>>>>
>>>>> JSPS Postdoctoral Fellow
>>>>> Laboratory of Population Biology
>>>>> Department of Marine Biosciences
>>>>> Graduate School of Marine Science and Technology
>>>>> Tokyo University of Marine Science and Technology
>>>>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
>>>>> Mobile: 050-6874-9072
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>> --
>>>>
>>>>
>>>>
>>>> With regards
>>>> Rishi Das Roy
>>>>
>>>
>>>
>>> --
>>> Md. Moshiur Rahman, PhD
>>>
>>> JSPS Postdoctoral Fellow
>>> Laboratory of Population Biology
>>> Department of Marine Biosciences
>>> Graduate School of Marine Science and Technology
>>> Tokyo University of Marine Science and Technology
>>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
>>> Mobile: 050-6874-9072
>>>
>>> .........................
>>>
>>> Professor
>>> Fisheries and Marine Resource Technology Discipline
>>> Khulna University, Khulna - 9208
>>> BANGLADESH.
>>> Google scholar:
>>> https://scholar.google.com.au/citations?user=uElrJSsAAAAJ&hl=en
>>> ResearchGate:
>https://www.researchgate.net/profile/Md_Moshiur_Rahman2
>>> ORCID: https://orcid.org/my-orcid
>>>
>>
>>
>> --
>>
>>
>>
>> With regards
>> Rishi Das Roy
>>

-- 
Sent from my phone. Please excuse my brevity.


From S@E|||@on @end|ng |rom LGCGroup@com  Fri Sep 20 16:29:04 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Fri, 20 Sep 2019 14:29:04 +0000
Subject: [R] [SPAM] Re:  The "--slave" option
In-Reply-To: <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
Message-ID: <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>

> Sure, it's a silly example, but it makes about as much sense as using
> "slave" to mean "quiet". 
It doesn't. It's a set of options chosen for when R is called as a slave process from a controlling process, and in that it is a reasonable description of the circumstance.

--quiet is a separate command line option with different effect.




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From ||n_@h|k@| @end|ng |rom hotm@||@com  Fri Sep 20 17:30:46 2019
From: ||n_@h|k@| @end|ng |rom hotm@||@com (Zachary Lim)
Date: Fri, 20 Sep 2019 15:30:46 +0000
Subject: [R] Creating a simple function
Message-ID: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>

Hi,

I'm trying to create a simple function that takes a dataframe as its only argument. I've been using gmodels::CrossTable, but it requires a lot of arguments, e.g.:

#this runs fine
CrossTable(data$col1, data$col2, prop.chisq = FALSE, prop.c = FALSE, prop.t = FALSE, format = "SPSS")

Moreover, I wanted to make it compatible with piping, so I decided to create the following function:

ctab <- function(data) {
  CrossTable(data[,1], data[,2], prop.chisq = FALSE, prop.c = FALSE, prop.t = FALSE, format = "SPSS")
}

When I try to use this function, however, I get the following error:

#this results in 'Error: Must use a vector in `[`, not an object of class matrix.'
data %>% select(col1, col2) %>% ctab()

I tried searching online but couldn't find much about that error (except for in specific and unrelated cases). Moreover, when I created a very simple dataset, it turns out there's no problem:

#this runs fine
data.frame(C1 = c('x','y','x','y'), C2 = c('a','a','b','b')) %>% ctab()


Is this a problem with my function or the data? If it's the data, why does directly calling CrossTable work?

Thanks!

Best,
Zach

	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Fri Sep 20 19:46:45 2019
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Fri, 20 Sep 2019 10:46:45 -0700
Subject: [R] Loop With Dates
Message-ID: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>

With the data snippet below I?m trying to increment the ?count? vector by one each time the date changes.  

         Date count
1   2018-03-29     1
2   2018-03-29     1
3   2018-03-29     1
81  2018-03-30     1
82  2018-03-30     1
83  2018-03-30     1
165 2018-03-31     1
166 2018-03-31     1
167 2018-03-31     1
 
     
            >  
     


I can get count to change when the date changes with the following code:

test2 <- transform(test2,
+                   count = ifelse(Date == lag(Date,1),count,count+1))
> test2
          Date count
1   2018-03-29    NA
2   2018-03-29     1
3   2018-03-29     1
81  2018-03-30     2
82  2018-03-30     1
83  2018-03-30     1
165 2018-03-31     2
166 2018-03-31     1
167 2018-03-31     1
 
     
           

     


...but I want all three March 30 rows to have a count of 2 and the March 31 rows to be equal to 3.  Any suggestions?

Thanks.
	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 20 19:59:46 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 20 Sep 2019 13:59:46 -0400
Subject: [R] Creating a simple function
In-Reply-To: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
References: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
Message-ID: <49a5f808-0f87-89b1-11bb-b4ffdae5d250@gmail.com>

On 20/09/2019 11:30 a.m., Zachary Lim wrote:
> Hi,
> 
> I'm trying to create a simple function that takes a dataframe as its only argument. I've been using gmodels::CrossTable, but it requires a lot of arguments, e.g.:
> 
> #this runs fine
> CrossTable(data$col1, data$col2, prop.chisq = FALSE, prop.c = FALSE, prop.t = FALSE, format = "SPSS")
> 
> Moreover, I wanted to make it compatible with piping, so I decided to create the following function:
> 
> ctab <- function(data) {
>    CrossTable(data[,1], data[,2], prop.chisq = FALSE, prop.c = FALSE, prop.t = FALSE, format = "SPSS")
> }
> 
> When I try to use this function, however, I get the following error:
> 
> #this results in 'Error: Must use a vector in `[`, not an object of class matrix.'
> data %>% select(col1, col2) %>% ctab()
> 
> I tried searching online but couldn't find much about that error (except for in specific and unrelated cases). Moreover, when I created a very simple dataset, it turns out there's no problem:
> 
> #this runs fine
> data.frame(C1 = c('x','y','x','y'), C2 = c('a','a','b','b')) %>% ctab()
> 
> 
> Is this a problem with my function or the data? If it's the data, why does directly calling CrossTable work?

Presumably  data %>% select(col1, col2)  isn't giving you a dataframe. 
However, you haven't given us a reproducible example, so I can't tell 
you what it's doing.  But that's where you should look.

Duncan Murdoch


From @n@cre@m @end|ng |rom gm@||@com  Fri Sep 20 20:40:06 2019
From: @n@cre@m @end|ng |rom gm@||@com (Ana PGG)
Date: Fri, 20 Sep 2019 20:40:06 +0200
Subject: [R] Loop With Dates
In-Reply-To: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
References: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
Message-ID: <5d851d06.1c69fb81.957e.dcaa@mx.google.com>

Hi Phillip,

This can be done in several ways as most things in programming. Here is one posible solution:

dates <- c("2018-03-29", "2018-03-29", "2018-03-29", 
           "2018-03-30", "2018-03-30", "2018-03-30", 
           "2018-03-31", "2018-03-31", "2018-03-31")
dates <- as.data.frame(as.Date(dates))
library(zoo)
dates <- zoo(dates)
colnames(dates) <- "dates"
dates$lag <- lag(dates, -1, na.pad = TRUE)
dates[1, 2] <- dates[1, 1]
dates$count <- cumsum(!(dates$dates == dates$lag)) + 1
dates$lag <- NULL

> dates
  dates.object count
1 2018-03-29   1    
2 2018-03-29   1    
3 2018-03-29   1    
4 2018-03-30   2    
5 2018-03-30   2    
6 2018-03-30   2    
7 2018-03-31   3    
8 2018-03-31   3    
9 2018-03-31   3    


De: Phillip Heinrich
Enviado: viernes, 20 de septiembre de 2019 19:47
Para: r-help
Asunto: [R] Loop With Dates

With the data snippet below I?m trying to increment the ?count? vector by one each time the date changes.  

         Date count
1   2018-03-29     1
2   2018-03-29     1
3   2018-03-29     1
81  2018-03-30     1
82  2018-03-30     1
83  2018-03-30     1
165 2018-03-31     1
166 2018-03-31     1
167 2018-03-31     1
 
     
            >  
     


I can get count to change when the date changes with the following code:

test2 <- transform(test2,
+                   count = ifelse(Date == lag(Date,1),count,count+1))
> test2
          Date count
1   2018-03-29    NA
2   2018-03-29     1
3   2018-03-29     1
81  2018-03-30     2
82  2018-03-30     1
83  2018-03-30     1
165 2018-03-31     2
166 2018-03-31     1
167 2018-03-31     1
 
     
           

     


...but I want all three March 30 rows to have a count of 2 and the March 31 rows to be equal to 3.  Any suggestions?

Thanks.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep 20 20:57:13 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 20 Sep 2019 19:57:13 +0100
Subject: [R] Loop With Dates
In-Reply-To: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
References: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
Message-ID: <5c1e266d-7dc0-52a3-6b30-c143fa833a5e@sapo.pt>

Hello,

Maybe I am not understanding but isn't this what you have asked in your 
previous question and my 2nd post (adapted) does?
If not, where does it fail?

Hope this helps,

Rui Barradas

?s 18:46 de 20/09/19, Phillip Heinrich escreveu:
> With the data snippet below I?m trying to increment the ?count? vector by one each time the date changes.
> 
>           Date count
> 1   2018-03-29     1
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     1
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     1
> 166 2018-03-31     1
> 167 2018-03-31     1
>   
>       
>              >
>       
> 
> 
> I can get count to change when the date changes with the following code:
> 
> test2 <- transform(test2,
> +                   count = ifelse(Date == lag(Date,1),count,count+1))
>> test2
>            Date count
> 1   2018-03-29    NA
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     2
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     2
> 166 2018-03-31     1
> 167 2018-03-31     1
>   
>       
>             
> 
>       
> 
> 
> ...but I want all three March 30 rows to have a count of 2 and the March 31 rows to be equal to 3.  Any suggestions?
> 
> Thanks.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep 20 21:05:27 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 20 Sep 2019 20:05:27 +0100
Subject: [R] Creating a simple function
In-Reply-To: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
References: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
Message-ID: <1a37a805-b0c0-5934-5528-1cf06e26abcb@sapo.pt>

Hello,

Something like this?


ctab <- function(data) {
   gmodels::CrossTable(as.matrix(data), prop.chisq = FALSE, prop.c = 
FALSE, prop.t = FALSE, format = "SPSS")
}

mtcars %>% select(cyl, gear) %>% ctab()


Hope this helps,

Rui Barradas

?s 16:30 de 20/09/19, Zachary Lim escreveu:
> Hi,
> 
> I'm trying to create a simple function that takes a dataframe as its only argument. I've been using gmodels::CrossTable, but it requires a lot of arguments, e.g.:
> 
> #this runs fine
> CrossTable(data$col1, data$col2, prop.chisq = FALSE, prop.c = FALSE, prop.t = FALSE, format = "SPSS")
> 
> Moreover, I wanted to make it compatible with piping, so I decided to create the following function:
> 
> ctab <- function(data) {
>    CrossTable(data[,1], data[,2], prop.chisq = FALSE, prop.c = FALSE, prop.t = FALSE, format = "SPSS")
> }
> 
> When I try to use this function, however, I get the following error:
> 
> #this results in 'Error: Must use a vector in `[`, not an object of class matrix.'
> data %>% select(col1, col2) %>% ctab()
> 
> I tried searching online but couldn't find much about that error (except for in specific and unrelated cases). Moreover, when I created a very simple dataset, it turns out there's no problem:
> 
> #this runs fine
> data.frame(C1 = c('x','y','x','y'), C2 = c('a','a','b','b')) %>% ctab()
> 
> 
> Is this a problem with my function or the data? If it's the data, why does directly calling CrossTable work?
> 
> Thanks!
> 
> Best,
> Zach
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@oknz @end|ng |rom gm@||@com  Fri Sep 20 23:39:18 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 21 Sep 2019 09:39:18 +1200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>

Ah, *now* we're getting somewhere.  There is something that *can* be
done that's genuinely helpful.
>From the R(1) manual page:
       -q, --quiet
              Don't print startup message

       --silent
              Same as --quiet

       --slave
              Make R run as quietly as possible

It might have been better to use --nobanner instead of --quiet.  So perhaps

    -q, --quiet
        Don't print the startup message.  This is the only output that
is suppressed.

    --silent
        Same as --quiet.  Suppress the startup message only.

    --slave
        Make R run as quietly as possible.  This is for use when running R as a
        subordinate process.  See "Introduction to Sub-Processes in R"
        https://cran.r-project.org/web/packages/subprocess/vignettes/intro.html
        for an example.

On Sat, 21 Sep 2019 at 02:29, Stephen Ellison <S.Ellison at lgcgroup.com> wrote:
>
> > Sure, it's a silly example, but it makes about as much sense as using
> > "slave" to mean "quiet".
> It doesn't. It's a set of options chosen for when R is called as a slave process from a controlling process, and in that it is a reasonable description of the circumstance.
>
> --quiet is a separate command line option with different effect.
>
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}


From mr@hm@nku|mrt @end|ng |rom gm@||@com  Sat Sep 21 00:20:12 2019
From: mr@hm@nku|mrt @end|ng |rom gm@||@com (Moshiur Rahman)
Date: Sat, 21 Sep 2019 07:20:12 +0900
Subject: [R] annotation help in ggplot2
In-Reply-To: <03BF4B17-F120-46DA-BEDB-8C4C6FF2F72F@dcn.davis.ca.us>
References: <CAGNSkS=53CDw7Gga7OvmE6VwpXJP_t0kw1gz5YZZ3798TGeXiw@mail.gmail.com>
 <CAODjwAGqH3+_co6sXePONPdvLjT7F3JXeMfPhf66ov-qbcu6+Q@mail.gmail.com>
 <CAGNSkSn4MkGuwLeoBLbgNbO8JFD7cWOARDCv_FJCu9OOoYGZkw@mail.gmail.com>
 <CAODjwAG8VChCCibZx85MSYG0817jF-p6F=msRw73Zq5x1owCTw@mail.gmail.com>
 <CAGNSkS=G5jN0QwHRkquzkoVE3CFbtDZb_3672KBpS+VV4Kr6nQ@mail.gmail.com>
 <03BF4B17-F120-46DA-BEDB-8C4C6FF2F72F@dcn.davis.ca.us>
Message-ID: <CAGNSkSkjsyVY=p9cN=Nd9hvU4b+dYnM-z3SCVF+Ga-6N7CEkYw@mail.gmail.com>

Thanks everyone especially Rishi to solve
this issue

Regards,

Moshichi

On Fri, Sep 20, 2019 at 22:26 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Using this list as a labor pool to procure code for generating
> publication-quality plots is abuse. Please read the Posting Guide and the
> documentation for the ggplot package or go pay someone offlist for their
> services.
>
> On September 20, 2019 4:15:18 AM PDT, Moshiur Rahman <
> mrahmankufmrt at gmail.com> wrote:
> >Thanks a lot Rishi for your very cordial effort and great help. But
> >still I
> >need some help to improve it as the plot doesn't clearly depict which
> >female belongs to which family and this can be detected by drawing a
> >line
> >from 1-4 for F1, 5-8 for F2....
> >
> >Another problem I can see that the position of MID (P1,2,3...) is not
> >looking well which are somehow noisy.
> >
> >Finally, can we drop the bars at the bottom of x-axis that I did
> >with scale_y_continuous?
> >
> >Please do me some favour to complete this plot which I need for a
> >publication.
> >
> >With kind regards,
> >
> >Moshi
> >
> >On Fri, Sep 20, 2019 at 7:45 PM ??? ( ??? / rIsHi )
> ><rishi.dasroy at gmail.com>
> >wrote:
> >
> >> Here is the solution inspired by this post
> >>
> >
> https://stackoverflow.com/questions/18165863/multirow-axis-labels-with-nested-grouping-variables
> >>
> >>
> >> > data$Female <-  factor(data$Female, levels =
> >> c("F1","F2","F3","F4","F5","F6","F7","F8","F9","F10"))
> >> >
> >>
>
> >ggplot(data,aes(x=family,y=offs.surv.perct,fill=treat))+geom_bar(stat="identity",
> >> position="dodge")+
> >>   geom_text(aes(label = MID),  angle=90)+
> >>   facet_wrap(~Female, strip.position = "bottom", scales =
> >"free_x",nrow=1)+
> >>   theme(panel.spacing = unit(0, "lines"),
> >>         strip.background = element_blank(),
> >>         strip.placement = "outside")
> >>
> >>
> >> On Fri, Sep 20, 2019 at 11:51 AM Moshiur Rahman
> ><mrahmankufmrt at gmail.com>
> >> wrote:
> >>
> >>> Thanks Rishi,
> >>>
> >>> Please find attached the data herewith.
> >>>
> >>>
> >>>
> >>> On Fri, Sep 20, 2019 at 5:48 PM ??? ( ??? / rIsHi ) <
> >>> rishi.dasroy at gmail.com> wrote:
> >>>
> >>>> There are no attached data .
> >>>>
> >>>> On Fri, Sep 20, 2019 at 11:40 AM Moshiur Rahman
> ><mrahmankufmrt at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> Dear ggplot2 experts,
> >>>>>
> >>>>> I'm struggling to make a plot having family id in x-axis and
> >female id
> >>>>> below that family id where each 4 families have a single female
> >id.
> >>>>>
> >>>>> I also need to add male id on top of each bar which I can do
> >before
> >>>>> grid.arrange, but fail after doing it. So, any suggestions?
> >>>>>
> >>>>> Please find below my codes and help me to complete it perfectly.
> >>>>> #data
> >>>>> data <- read.table("R-help_ggplot2.csv", header=TRUE, sep=",")
> >>>>> names(data)
> >>>>> #packages
> >>>>> library(ggplot2)
> >>>>> library(grid)
> >>>>> library(gridExtra)
> >>>>> library(scales)
> >>>>> library(ggpubr)
> >>>>> #plot codes
> >>>>> p1 =
> >>>>>
> >ggplot(data,aes(x=factor(family),y=offs.surv.perct,fill=factor(treat)))+
> >>>>>     geom_bar(stat="identity", position="dodge")+
> >>>>>     #facet_wrap(~ Female)+
> >>>>>     geom_bar(stat="identity", position="dodge", colour="black",
> >>>>> show.legend= TRUE) + # show_guide = TRUE gives legend boarder
> >>>>>     #geom_hline(yintercept=15, size=0.5, linetype = 2)+ ### middle
> >line
> >>>>>     scale_fill_manual(values=c("grey", "white")) + # grey80 is
> >closer to
> >>>>> white than black
> >>>>>     xlab("Family") +
> >>>>>     ylab (expression(paste("Offspring survival rate (%)"))) +
> >>>>>     #coord_cartesian(xlim=c(0,40), ylim=c(0,60), clip="off")+
> >>>>>     scale_y_continuous(expand = c(0, 0), limits = c(0, 60))+
> >>>>>     theme(legend.title = element_text(colour="black", size=12))+
> >>>>>     theme(legend.text = element_text(colour="black", size=11))+
> >>>>>     theme(legend.background = element_blank())+
> >>>>>     theme(legend.key = element_blank())+
> >>>>>     theme(legend.box.background = element_blank())+
> >>>>>     theme(legend.key.size = unit(2, "mm"),legend.key.width =
> >>>>> unit(0.5,"cm"))+
> >>>>>     theme(legend.position=c(0.05,0.9),legend.direction
> >>>>> ="vertical",legend.box = "vertical")+ # add legend on top
> >>>>>     theme(panel.background = element_rect(fill = "transparent"))+
> >>>>>     theme(axis.line = element_line(colour =
> >>>>> "black"),axis.text.x=element_text(size=10,
> >>>>> colour="black"),axis.text.y=element_text(size=10, colour="black"),
> >>>>>         axis.title.y = element_text(size=12, colour =
> >>>>> "black",margin=margin(0,5,0,0)),
> >>>>>         axis.title.x = element_blank(),
> >>>>>         strip.text.x = element_blank(),# remove top level title
> >(high
> >>>>> and
> >>>>> low)
> >>>>>         strip.background = element_blank(),# remove top level
> >background
> >>>>>         panel.grid.major = element_blank(),# remove grid line
> >within the
> >>>>> plot
> >>>>>         panel.grid.minor = element_blank(),
> >>>>>         panel.border = element_blank())
> >>>>> p1
> >>>>>
> >>>>> ### legend correction
> >>>>> p2<- p1 + guides(fill = guide_legend(title="Fertilization
> >>>>> group",keywidth =
> >>>>> 1,keyheight = 1,
> >>>>>                              title.theme = element_text(size=12,
> >colour
> >>>>> =
> >>>>> "black", angle = 0)))+
> >>>>>   theme(legend.text = element_text(size = 12, colour = "black",
> >angle =
> >>>>> 0))
> >>>>>
> >>>>> p2
> >>>>>
> >>>>> ###plot margins
> >>>>> p3<-p2+theme(plot.margin = unit(c(1,1,1.7,1), "lines"))
> >>>>> p3
> >>>>>
> >>>>> #x-axis label
> >>>>> p4<-grid.arrange(
> >>>>>   p3,
> >>>>>   bottom = textGrob(
> >>>>>     "Family and female number",
> >>>>>     gp = gpar(fontsize = 12, cex=1), #fontface = "bold",
> >>>>>     vjust = 0.5, hjust = 0.5,x = 0.52))
> >>>>>
> >>>>> # annotation (NOT WORKING)
> >>>>> p5<-p4+annotate("text", label = "M1", x = 1, y = 25.03, fontface =
> >1,
> >>>>> size=3,angle = 90)
> >>>>> p5
> >>>>> p6<-p5+annotate("text", label = "M2", x = 2, y = 18.37, fontface =
> >1,
> >>>>> size=3,angle = 90)
> >>>>> p6
> >>>>> p7<-p6+annotate("text", label = "M3", x = 3, y = 21.7, fontface =
> >1,
> >>>>> size=3,angle = 90)
> >>>>> p7
> >>>>> p8<-p7+annotate("text", label = "M1-2-3", x = 4, y = 19.1,
> >fontface= 1,
> >>>>> size=3,angle = 90)
> >>>>> p8
> >>>>> Fig1.1<-p8+annotate("segment", size=0.3, x=c(1,1,4),xend=c(1,4,4),
> >>>>>                          y= c(26,28,28), yend=c(28,28,21))+
> >>>>>   annotate("text",x=2.45,y=29.5,fontface = 1, size=3,angle =
> >>>>> 90,label=c("F1"))
> >>>>>
> >>>>> Fig1.1
> >>>>>
> >>>>> Please find attached also my data.
> >>>>>
> >>>>> Any assistance will be highly appreciated.
> >>>>>
> >>>>> Regards,
> >>>>>
> >>>>> Moshi
> >>>>>
> >>>>>
> >>>>> JSPS Postdoctoral Fellow
> >>>>> Laboratory of Population Biology
> >>>>> Department of Marine Biosciences
> >>>>> Graduate School of Marine Science and Technology
> >>>>> Tokyo University of Marine Science and Technology
> >>>>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
> >>>>> Mobile: 050-6874-9072
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>
> >>>> --
> >>>>
> >>>>
> >>>>
> >>>> With regards
> >>>> Rishi Das Roy
> >>>>
> >>>
> >>>
> >>> --
> >>> Md. Moshiur Rahman, PhD
> >>>
> >>> JSPS Postdoctoral Fellow
> >>> Laboratory of Population Biology
> >>> Department of Marine Biosciences
> >>> Graduate School of Marine Science and Technology
> >>> Tokyo University of Marine Science and Technology
> >>> 4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
> >>> Mobile: 050-6874-9072
> >>>
> >>> .........................
> >>>
> >>> Professor
> >>> Fisheries and Marine Resource Technology Discipline
> >>> Khulna University, Khulna - 9208
> >>> BANGLADESH.
> >>> Google scholar:
> >>> https://scholar.google.com.au/citations?user=uElrJSsAAAAJ&hl=en
> >>> ResearchGate:
> >https://www.researchgate.net/profile/Md_Moshiur_Rahman2
> >>> ORCID: https://orcid.org/my-orcid
> >>>
> >>
> >>
> >> --
> >>
> >>
> >>
> >> With regards
> >> Rishi Das Roy
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>
-- 
Md. Moshiur Rahman, PhD

JSPS Postdoctoral Fellow
Laboratory of Population Biology
Department of Marine Biosciences
Graduate School of Marine Science and Technology
Tokyo University of Marine Science and Technology
4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
Mobile: 050-6874-9072

.........................

Professor
Fisheries and Marine Resource Technology Discipline
Khulna University, Khulna - 9208
BANGLADESH.
Google scholar:
https://scholar.google.com.au/citations?user=uElrJSsAAAAJ&hl=en
ResearchGate: https://www.researchgate.net/profile/Md_Moshiur_Rahman2
ORCID: https://orcid.org/my-orcid

	[[alternative HTML version deleted]]


From moh@mm@d|@n02 @end|ng |rom gm@||@com  Sat Sep 21 10:08:21 2019
From: moh@mm@d|@n02 @end|ng |rom gm@||@com (Mohammadian)
Date: Sat, 21 Sep 2019 11:38:21 +0330
Subject: [R] Meta-analysis on microaray data,
 when a sinlge experiment contains diferent tissues
Message-ID: <CALqdc3dHM_VnTw=A3tWOYYMQyf7iBx8g=mE_1w2X3xbOaPZHHw@mail.gmail.com>

Hi!

I dont know whether this is the best place to ask this question, however:

Suppose I want to perform meta-analysis on 10 different microarray studies.

Study	Tissue-source
Study1     Neuron
Study2     Blood
Study3     Neuron and PBMC
......
Study10   ...

How should I treat Study3?
The R package I want to use is among MetaMA, MetaDE, and perhaps crossMeta
Even a reference article/book/tutorial would be appreciated.

Thanks in advance


From moh@mm@d|@n02 @end|ng |rom gm@||@com  Sat Sep 21 10:37:45 2019
From: moh@mm@d|@n02 @end|ng |rom gm@||@com (Mohammadian)
Date: Sat, 21 Sep 2019 12:07:45 +0330
Subject: [R] Meta-analysis on microaray data,
 when a sinlge experiment contains diferent tissues
In-Reply-To: <CAODjwAG_S4qr2BNhbcEzprMWjBCgMMEgT=JNvE0wxfoWN7hLLQ@mail.gmail.com>
References: <CALqdc3dHM_VnTw=A3tWOYYMQyf7iBx8g=mE_1w2X3xbOaPZHHw@mail.gmail.com>
 <CAODjwAG_S4qr2BNhbcEzprMWjBCgMMEgT=JNvE0wxfoWN7hLLQ@mail.gmail.com>
Message-ID: <CALqdc3dH-GLj4+k2agT7-K_BEPNvusWZ0jwC0i3Ygb+fUSK-LQ@mail.gmail.com>

Thank for the prompt response.

On 9/21/19, ???  ( ??? / rIsHi ) <rishi.dasroy at gmail.com> wrote:
> Yes this is not the best place, rather it should be better asked in
> bioinformatics forums like biostar and bioconductor.
>
> On Sat, Sep 21, 2019 at 11:08 AM Mohammadian <mohammadian02 at gmail.com>
> wrote:
>
>> Hi!
>>
>> I dont know whether this is the best place to ask this question, however:
>>
>> Suppose I want to perform meta-analysis on 10 different microarray
>> studies.
>>
>> Study   Tissue-source
>> Study1     Neuron
>> Study2     Blood
>> Study3     Neuron and PBMC
>> ......
>> Study10   ...
>>
>> How should I treat Study3?
>> The R package I want to use is among MetaMA, MetaDE, and perhaps
>> crossMeta
>> Even a reference article/book/tutorial would be appreciated.
>>
>> Thanks in advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
>
>
>
> With regards
> Rishi Das Roy
>


From drj|m|emon @end|ng |rom gm@||@com  Sat Sep 21 12:37:09 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 21 Sep 2019 20:37:09 +1000
Subject: [R] Loop With Dates
In-Reply-To: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
References: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
Message-ID: <CA+8X3fX6B+fzbwRW4di+eLDNGM3FzJrwNFNv4KH6-m7FLVyKVg@mail.gmail.com>

Hi Phillip,
While I really like Ana's solution, this might also help:

phdf<-read.table(text="Date count
  2018-03-29     1
  2018-03-29     1
  2018-03-29     1
  2018-03-30     1
  2018-03-30     1
  2018-03-30     1
  2018-03-31     1
  2018-03-31     1
  2018-03-31     1",
  header=TRUE,stringsAsFactors=FALSE)
phdf$Date<-as.Date(phdf$Date,"%Y-%m-%d")
incflag<-diff(phdf$Date)>0
phdf$count<-c(NA,cumsum(incflag)+1)

Jim

On Sat, Sep 21, 2019 at 3:47 AM Phillip Heinrich <herd_dog at cox.net> wrote:
>
> With the data snippet below I?m trying to increment the ?count? vector by one each time the date changes.
>
>          Date count
> 1   2018-03-29     1
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     1
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     1
> 166 2018-03-31     1
> 167 2018-03-31     1
>
>
>             >
>
>
>
> I can get count to change when the date changes with the following code:
>
> test2 <- transform(test2,
> +                   count = ifelse(Date == lag(Date,1),count,count+1))
> > test2
>           Date count
> 1   2018-03-29    NA
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     2
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     2
> 166 2018-03-31     1
> 167 2018-03-31     1
>
>
>
>
>
>
>
> ...but I want all three March 30 rows to have a count of 2 and the March 31 rows to be equal to 3.  Any suggestions?
>
> Thanks.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep 21 13:38:49 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Sep 2019 04:38:49 -0700
Subject: [R] Creating a simple function
In-Reply-To: <49a5f808-0f87-89b1-11bb-b4ffdae5d250@gmail.com>
References: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
 <49a5f808-0f87-89b1-11bb-b4ffdae5d250@gmail.com>
Message-ID: <90AEDE22-380D-412D-B742-D49B2BF7DCD2@dcn.davis.ca.us>

The dplyr::select function returns a special variety of data.frame called a tibble. The tibble has certain features designed to make it behave consistently when indexing is used. Specifically, the `[` operator always returns a tibble regardless of how many columns are indicated by the column index. This is unlike the conventional data frame which returns a vector when exactly one column is indicated by the column index, or a data.frame if more than one is indicated.

A syntax that consistently yields a column vector with both tibbles and data.frames is

dta[[ 1 ]]

so

ctab <- function(data) {
   CrossTable(data[[1]], data[[2]], prop.chisq = FALSE, prop.c = FALSE,
prop.t = FALSE, format = "SPSS")
}

should work.

On September 20, 2019 10:59:46 AM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 20/09/2019 11:30 a.m., Zachary Lim wrote:
>> Hi,
>> 
>> I'm trying to create a simple function that takes a dataframe as its
>only argument. I've been using gmodels::CrossTable, but it requires a
>lot of arguments, e.g.:
>> 
>> #this runs fine
>> CrossTable(data$col1, data$col2, prop.chisq = FALSE, prop.c = FALSE,
>prop.t = FALSE, format = "SPSS")
>> 
>> Moreover, I wanted to make it compatible with piping, so I decided to
>create the following function:
>> 
>> ctab <- function(data) {
>>    CrossTable(data[,1], data[,2], prop.chisq = FALSE, prop.c = FALSE,
>prop.t = FALSE, format = "SPSS")
>> }
>> 
>> When I try to use this function, however, I get the following error:
>> 
>> #this results in 'Error: Must use a vector in `[`, not an object of
>class matrix.'
>> data %>% select(col1, col2) %>% ctab()
>> 
>> I tried searching online but couldn't find much about that error
>(except for in specific and unrelated cases). Moreover, when I created
>a very simple dataset, it turns out there's no problem:
>> 
>> #this runs fine
>> data.frame(C1 = c('x','y','x','y'), C2 = c('a','a','b','b')) %>%
>ctab()
>> 
>> 
>> Is this a problem with my function or the data? If it's the data, why
>does directly calling CrossTable work?
>
>Presumably  data %>% select(col1, col2)  isn't giving you a dataframe. 
>However, you haven't given us a reproducible example, so I can't tell 
>you what it's doing.  But that's where you should look.
>
>Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep 21 14:22:07 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 21 Sep 2019 08:22:07 -0400
Subject: [R] Creating a simple function
In-Reply-To: <90AEDE22-380D-412D-B742-D49B2BF7DCD2@dcn.davis.ca.us>
References: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
 <49a5f808-0f87-89b1-11bb-b4ffdae5d250@gmail.com>
 <90AEDE22-380D-412D-B742-D49B2BF7DCD2@dcn.davis.ca.us>
Message-ID: <328ce119-7c04-e50c-79a2-6294afe319e8@gmail.com>

On 21/09/2019 7:38 a.m., Jeff Newmiller wrote:
> The dplyr::select function returns a special variety of data.frame called a tibble. 

I don't think that's always true.  The docs say it returns "An object of 
the same class as .data.", and that's what I'm seeing:

 > str(data.frame(a=c(1,1,2,2), b=1:4) %>% subset(a == 1))
'data.frame':	2 obs. of  2 variables:
  $ a: num  1 1
  $ b: int  1 2

But I believe there are other dplyr functions that take dataframes as 
input and return tibbles, I just don't know which ones.

Duncan Murdoch

The tibble has certain features designed to make it behave consistently 
when indexing is used. Specifically, the `[` operator always returns a 
tibble regardless of how many columns are indicated by the column index. 
This is unlike the conventional data frame which returns a vector when 
exactly one column is indicated by the column index, or a data.frame if 
more than one is indicated.
> 
> A syntax that consistently yields a column vector with both tibbles and data.frames is
> 
> dta[[ 1 ]]
> 
> so
> 
> ctab <- function(data) {
>     CrossTable(data[[1]], data[[2]], prop.chisq = FALSE, prop.c = FALSE,
> prop.t = FALSE, format = "SPSS")
> }
> 
> should work.
> 
> On September 20, 2019 10:59:46 AM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 20/09/2019 11:30 a.m., Zachary Lim wrote:
>>> Hi,
>>>
>>> I'm trying to create a simple function that takes a dataframe as its
>> only argument. I've been using gmodels::CrossTable, but it requires a
>> lot of arguments, e.g.:
>>>
>>> #this runs fine
>>> CrossTable(data$col1, data$col2, prop.chisq = FALSE, prop.c = FALSE,
>> prop.t = FALSE, format = "SPSS")
>>>
>>> Moreover, I wanted to make it compatible with piping, so I decided to
>> create the following function:
>>>
>>> ctab <- function(data) {
>>>     CrossTable(data[,1], data[,2], prop.chisq = FALSE, prop.c = FALSE,
>> prop.t = FALSE, format = "SPSS")
>>> }
>>>
>>> When I try to use this function, however, I get the following error:
>>>
>>> #this results in 'Error: Must use a vector in `[`, not an object of
>> class matrix.'
>>> data %>% select(col1, col2) %>% ctab()
>>>
>>> I tried searching online but couldn't find much about that error
>> (except for in specific and unrelated cases). Moreover, when I created
>> a very simple dataset, it turns out there's no problem:
>>>
>>> #this runs fine
>>> data.frame(C1 = c('x','y','x','y'), C2 = c('a','a','b','b')) %>%
>> ctab()
>>>
>>>
>>> Is this a problem with my function or the data? If it's the data, why
>> does directly calling CrossTable work?
>>
>> Presumably  data %>% select(col1, col2)  isn't giving you a dataframe.
>> However, you haven't given us a reproducible example, so I can't tell
>> you what it's doing.  But that's where you should look.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep 21 15:05:12 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Sep 2019 06:05:12 -0700
Subject: [R] Creating a simple function
In-Reply-To: <328ce119-7c04-e50c-79a2-6294afe319e8@gmail.com>
References: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
 <49a5f808-0f87-89b1-11bb-b4ffdae5d250@gmail.com>
 <90AEDE22-380D-412D-B742-D49B2BF7DCD2@dcn.davis.ca.us>
 <328ce119-7c04-e50c-79a2-6294afe319e8@gmail.com>
Message-ID: <1DA8AFEE-9B0B-462F-B20C-787BD7E28D4B@dcn.davis.ca.us>

Your use of subset instead of select does not help, but a corrected example does indeed confirm your point.

library(dplyr)

str(data.frame(a=c(1,1,2,2), b=1:4) %>% select(b,a))
## 'data.frame':	4 obs. of 2 variables: 
## $ b: int 1 2 3 4
## $ a: num 1 1 2 2

However the `[` issue is still worth addressing. If that does not fix the problem then a dput(head(troublesomedata)) from Zachary will be needed to figure out what actually is going on.

On September 21, 2019 5:22:07 AM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 21/09/2019 7:38 a.m., Jeff Newmiller wrote:
>> The dplyr::select function returns a special variety of data.frame
>called a tibble. 
>
>I don't think that's always true.  The docs say it returns "An object
>of 
>the same class as .data.", and that's what I'm seeing:
>
> > str(data.frame(a=c(1,1,2,2), b=1:4) %>% subset(a == 1))
>'data.frame':	2 obs. of  2 variables:
>  $ a: num  1 1
>  $ b: int  1 2
>
>But I believe there are other dplyr functions that take dataframes as 
>input and return tibbles, I just don't know which ones.
>
>Duncan Murdoch
>
>The tibble has certain features designed to make it behave consistently
>
>when indexing is used. Specifically, the `[` operator always returns a 
>tibble regardless of how many columns are indicated by the column
>index. 
>This is unlike the conventional data frame which returns a vector when 
>exactly one column is indicated by the column index, or a data.frame if
>
>more than one is indicated.
>> 
>> A syntax that consistently yields a column vector with both tibbles
>and data.frames is
>> 
>> dta[[ 1 ]]
>> 
>> so
>> 
>> ctab <- function(data) {
>>     CrossTable(data[[1]], data[[2]], prop.chisq = FALSE, prop.c =
>FALSE,
>> prop.t = FALSE, format = "SPSS")
>> }
>> 
>> should work.
>> 
>> On September 20, 2019 10:59:46 AM PDT, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
>>> On 20/09/2019 11:30 a.m., Zachary Lim wrote:
>>>> Hi,
>>>>
>>>> I'm trying to create a simple function that takes a dataframe as
>its
>>> only argument. I've been using gmodels::CrossTable, but it requires
>a
>>> lot of arguments, e.g.:
>>>>
>>>> #this runs fine
>>>> CrossTable(data$col1, data$col2, prop.chisq = FALSE, prop.c =
>FALSE,
>>> prop.t = FALSE, format = "SPSS")
>>>>
>>>> Moreover, I wanted to make it compatible with piping, so I decided
>to
>>> create the following function:
>>>>
>>>> ctab <- function(data) {
>>>>     CrossTable(data[,1], data[,2], prop.chisq = FALSE, prop.c =
>FALSE,
>>> prop.t = FALSE, format = "SPSS")
>>>> }
>>>>
>>>> When I try to use this function, however, I get the following
>error:
>>>>
>>>> #this results in 'Error: Must use a vector in `[`, not an object of
>>> class matrix.'
>>>> data %>% select(col1, col2) %>% ctab()
>>>>
>>>> I tried searching online but couldn't find much about that error
>>> (except for in specific and unrelated cases). Moreover, when I
>created
>>> a very simple dataset, it turns out there's no problem:
>>>>
>>>> #this runs fine
>>>> data.frame(C1 = c('x','y','x','y'), C2 = c('a','a','b','b')) %>%
>>> ctab()
>>>>
>>>>
>>>> Is this a problem with my function or the data? If it's the data,
>why
>>> does directly calling CrossTable work?
>>>
>>> Presumably  data %>% select(col1, col2)  isn't giving you a
>dataframe.
>>> However, you haven't given us a reproducible example, so I can't
>tell
>>> you what it's doing.  But that's where you should look.
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Sep 21 16:25:40 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 21 Sep 2019 10:25:40 -0400
Subject: [R] Creating a simple function
In-Reply-To: <1DA8AFEE-9B0B-462F-B20C-787BD7E28D4B@dcn.davis.ca.us>
References: <DM5PR1101MB2186D3E19143D8C9A40829C6EA880@DM5PR1101MB2186.namprd11.prod.outlook.com>
 <49a5f808-0f87-89b1-11bb-b4ffdae5d250@gmail.com>
 <90AEDE22-380D-412D-B742-D49B2BF7DCD2@dcn.davis.ca.us>
 <328ce119-7c04-e50c-79a2-6294afe319e8@gmail.com>
 <1DA8AFEE-9B0B-462F-B20C-787BD7E28D4B@dcn.davis.ca.us>
Message-ID: <c0271788-f6d6-1119-6318-68d72d795a1b@gmail.com>

On 21/09/2019 9:05 a.m., Jeff Newmiller wrote:
> Your use of subset instead of select does not help, 

Whoops, sorry.  Thanks for doing the real check.

Duncan

but a corrected example does indeed confirm your point.
> 
> library(dplyr)
> 
> str(data.frame(a=c(1,1,2,2), b=1:4) %>% select(b,a))
> ## 'data.frame':	4 obs. of 2 variables:
> ## $ b: int 1 2 3 4
> ## $ a: num 1 1 2 2
> 
> However the `[` issue is still worth addressing. If that does not fix the problem then a dput(head(troublesomedata)) from Zachary will be needed to figure out what actually is going on.
> 
> On September 21, 2019 5:22:07 AM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 21/09/2019 7:38 a.m., Jeff Newmiller wrote:
>>> The dplyr::select function returns a special variety of data.frame
>> called a tibble.
>>
>> I don't think that's always true.  The docs say it returns "An object
>> of
>> the same class as .data.", and that's what I'm seeing:
>>
>>> str(data.frame(a=c(1,1,2,2), b=1:4) %>% subset(a == 1))
>> 'data.frame':	2 obs. of  2 variables:
>>   $ a: num  1 1
>>   $ b: int  1 2
>>
>> But I believe there are other dplyr functions that take dataframes as
>> input and return tibbles, I just don't know which ones.
>>
>> Duncan Murdoch
>>
>> The tibble has certain features designed to make it behave consistently
>>
>> when indexing is used. Specifically, the `[` operator always returns a
>> tibble regardless of how many columns are indicated by the column
>> index.
>> This is unlike the conventional data frame which returns a vector when
>> exactly one column is indicated by the column index, or a data.frame if
>>
>> more than one is indicated.
>>>
>>> A syntax that consistently yields a column vector with both tibbles
>> and data.frames is
>>>
>>> dta[[ 1 ]]
>>>
>>> so
>>>
>>> ctab <- function(data) {
>>>      CrossTable(data[[1]], data[[2]], prop.chisq = FALSE, prop.c =
>> FALSE,
>>> prop.t = FALSE, format = "SPSS")
>>> }
>>>
>>> should work.
>>>
>>> On September 20, 2019 10:59:46 AM PDT, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>>> On 20/09/2019 11:30 a.m., Zachary Lim wrote:
>>>>> Hi,
>>>>>
>>>>> I'm trying to create a simple function that takes a dataframe as
>> its
>>>> only argument. I've been using gmodels::CrossTable, but it requires
>> a
>>>> lot of arguments, e.g.:
>>>>>
>>>>> #this runs fine
>>>>> CrossTable(data$col1, data$col2, prop.chisq = FALSE, prop.c =
>> FALSE,
>>>> prop.t = FALSE, format = "SPSS")
>>>>>
>>>>> Moreover, I wanted to make it compatible with piping, so I decided
>> to
>>>> create the following function:
>>>>>
>>>>> ctab <- function(data) {
>>>>>      CrossTable(data[,1], data[,2], prop.chisq = FALSE, prop.c =
>> FALSE,
>>>> prop.t = FALSE, format = "SPSS")
>>>>> }
>>>>>
>>>>> When I try to use this function, however, I get the following
>> error:
>>>>>
>>>>> #this results in 'Error: Must use a vector in `[`, not an object of
>>>> class matrix.'
>>>>> data %>% select(col1, col2) %>% ctab()
>>>>>
>>>>> I tried searching online but couldn't find much about that error
>>>> (except for in specific and unrelated cases). Moreover, when I
>> created
>>>> a very simple dataset, it turns out there's no problem:
>>>>>
>>>>> #this runs fine
>>>>> data.frame(C1 = c('x','y','x','y'), C2 = c('a','a','b','b')) %>%
>>>> ctab()
>>>>>
>>>>>
>>>>> Is this a problem with my function or the data? If it's the data,
>> why
>>>> does directly calling CrossTable work?
>>>>
>>>> Presumably  data %>% select(col1, col2)  isn't giving you a
>> dataframe.
>>>> However, you haven't given us a reproducible example, so I can't
>> tell
>>>> you what it's doing.  But that's where you should look.
>>>>
>>>> Duncan Murdoch
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>


From herd_dog @end|ng |rom cox@net  Sat Sep 21 21:57:50 2019
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Sat, 21 Sep 2019 12:57:50 -0700
Subject: [R] & statement within an ifelse Loop
Message-ID: <46E9C76212144CCCBC2EA1B01F341EAD@OWNERPC>

Still putzing around trying to increment a count vector when the date changes.  

         Date count
1   2018-03-29     1
2   2018-03-29     1
3   2018-03-29     1
81  2018-03-30     1
82  2018-03-30     1
83  2018-03-30     1
165 2018-03-31     1
166 2018-03-31     1
167 2018-03-31     1
 
I can get count to change when the date changes  - lines 81 and 165 - by comparing the date to the date on the previous line (lag(Date,1)) but then the count returns to 1 on line 82 and line 166.

test2 <- transform(test2,
+                   count = ifelse(Date == lag(Date,1),count,count+1))
> test2
          Date count
1   2018-03-29    NA
2   2018-03-29     1
3   2018-03-29     1
81  2018-03-30     2
82  2018-03-30     1
83  2018-03-30     1
165 2018-03-31     2
166 2018-03-31     1
167 2018-03-31     1

test2 <- transform(test2,
+           count = ifelse(Date == lag(Date,1),(lag(count,1)),(lag(count,1)+1)))



With the code above I get the same results.  It seems to me that line 82 should have count = 2 since the dates on line 81 and 82 are the same so the count from line 82 should be the same as 81 -  (lag(count,1)).  Similarly, if line 83 were count = 2 then line 165 should be equal to 3.

What am I missing here?  Is there a way to add an & clause to either the if or the else clause such as:

((-2:2) >= 0) & ((-2:2) <= 0)I?ve tried this several different ways such as:

(lag(count,1)) &(count = count+1).  

with no success.

Thanks,
Philip

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Sep 21 22:38:22 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 21 Sep 2019 13:38:22 -0700
Subject: [R] & statement within an ifelse Loop
In-Reply-To: <46E9C76212144CCCBC2EA1B01F341EAD@OWNERPC>
References: <46E9C76212144CCCBC2EA1B01F341EAD@OWNERPC>
Message-ID: <e0e51798-89f2-df7e-1692-53104f39a9bc@comcast.net>


On 9/21/19 12:57 PM, Phillip Heinrich wrote:
> Still putzing around trying to increment a count vector when the date changes.
>
>           Date count
> 1   2018-03-29     1
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     1
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     1
> 166 2018-03-31     1
> 167 2018-03-31     1
>   
> I can get count to change when the date changes  - lines 81 and 165 - by comparing the date to the date on the previous line (lag(Date,1)) but then the count returns to 1 on line 82 and line 166.
>
> test2 <- transform(test2,
> +                   count = ifelse(Date == lag(Date,1),count,count+1))


The first thing to do is clarify which package you are expecting lag to 
come from. I suspect it from a package other than the "base" stats which 
gives this.


lag(c(1,2)) == c(1,2)
[1] TRUE TRUE
attr(,"tsp")
[1] 0 1 1


The base lag function only changes the tsp attributes, but not the values.


-- 

David.

>> test2
>            Date count
> 1   2018-03-29    NA
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     2
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     2
> 166 2018-03-31     1
> 167 2018-03-31     1
>
> test2 <- transform(test2,
> +           count = ifelse(Date == lag(Date,1),(lag(count,1)),(lag(count,1)+1)))
>
>
>
> With the code above I get the same results.  It seems to me that line 82 should have count = 2 since the dates on line 81 and 82 are the same so the count from line 82 should be the same as 81 -  (lag(count,1)).  Similarly, if line 83 were count = 2 then line 165 should be equal to 3.
>
> What am I missing here?  Is there a way to add an & clause to either the if or the else clause such as:
>
> ((-2:2) >= 0) & ((-2:2) <= 0)I?ve tried this several different ways such as:
>
> (lag(count,1)) &(count = count+1).
>
> with no success.
>
> Thanks,
> Philip
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep 21 23:15:40 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Sep 2019 14:15:40 -0700
Subject: [R] & statement within an ifelse Loop
In-Reply-To: <46E9C76212144CCCBC2EA1B01F341EAD@OWNERPC>
References: <46E9C76212144CCCBC2EA1B01F341EAD@OWNERPC>
Message-ID: <683DFD08-10B0-4148-84E5-15C14800CB65@dcn.davis.ca.us>

You really need to address the responses to your previous posts on this topic. [1][2] What happened when you tested those methods? In particular, what about them was so ineffective that you are still here asking the same question? And why are you starting new threads of conversation on the same topic?

Failing to respond to help is rude, but ignoring help is really rude. You may 
just be unfamiliar with mailing lists, but now is the time to rectify your behavior. Read the Posting Guide and consider sending reply-all emails at least to the messages I reference below.

[1] https://stat.ethz.ch/pipermail/r-help/2019-September/464183.html
[2] https://stat.ethz.ch/pipermail/r-help/2019-September/464202.html


On September 21, 2019 12:57:50 PM PDT, Phillip Heinrich <herd_dog at cox.net> wrote:
>Still putzing around trying to increment a count vector when the date
>changes.  
>
>         Date count
>1   2018-03-29     1
>2   2018-03-29     1
>3   2018-03-29     1
>81  2018-03-30     1
>82  2018-03-30     1
>83  2018-03-30     1
>165 2018-03-31     1
>166 2018-03-31     1
>167 2018-03-31     1
> 
>I can get count to change when the date changes  - lines 81 and 165 -
>by comparing the date to the date on the previous line (lag(Date,1))
>but then the count returns to 1 on line 82 and line 166.
>
>test2 <- transform(test2,
>+                   count = ifelse(Date == lag(Date,1),count,count+1))
>> test2
>          Date count
>1   2018-03-29    NA
>2   2018-03-29     1
>3   2018-03-29     1
>81  2018-03-30     2
>82  2018-03-30     1
>83  2018-03-30     1
>165 2018-03-31     2
>166 2018-03-31     1
>167 2018-03-31     1
>
>test2 <- transform(test2,
>+           count = ifelse(Date ==
>lag(Date,1),(lag(count,1)),(lag(count,1)+1)))
>
>
>
>With the code above I get the same results.  It seems to me that line
>82 should have count = 2 since the dates on line 81 and 82 are the same
>so the count from line 82 should be the same as 81 -  (lag(count,1)). 
>Similarly, if line 83 were count = 2 then line 165 should be equal to
>3.
>
>What am I missing here?  Is there a way to add an & clause to either
>the if or the else clause such as:
>
>((-2:2) >= 0) & ((-2:2) <= 0)I?ve tried this several different ways
>such as:
>
>(lag(count,1)) &(count = count+1).  
>
>with no success.
>
>Thanks,
>Philip
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Sun Sep 22 00:56:02 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 22 Sep 2019 10:56:02 +1200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
 <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
Message-ID: <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>

(excerpts only)
> slavery being easily justified by the Bible while abolition is not is an experience.
> P.S. Do any R developers actually read this?

I've read one or two verses...

I also found this (by you):
https://www.ncbi.nlm.nih.gov/pubmed/20362542

Which uses embryonic stem cells.
I recognize that they're mouse embryos.
However, your article cites at least five other articles (probably, a
lot more), that use human embryonic stem cells.

You complain about slavery (that doesn't exist), and then prompte
murder (which does exist).
What does that say about you...

And that's ignoring the way you treat animals
We slice and dice data, you slice and dice living creatures.

Here's two songs about freedom, if you have ears to hear:
https://youtu.be/lKw6uqtGFfo
https://youtu.be/HAIdo707Sac


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sun Sep 22 01:29:16 2019
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 21 Sep 2019 16:29:16 -0700
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
 <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
 <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>
Message-ID: <B13CA65A-F0E3-4686-ADCF-F57E30D7E712@noaa.gov>

Please All:

While as I said in my first post I am still not convinced that the OP was in good faith to improve R and not a troll  (yours to decide), I also don't think attacking a person's research to counter a point that has nothing to do with their research is what is wanted on this mail-list.  There is one very simple alternative - don't reply.

Ben - members of R-core do read this mail-list,  and the fact that not a single one has replied probably tells you what you need to know.

-Roy


> On Sep 21, 2019, at 3:56 PM, Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
> (excerpts only)
>> slavery being easily justified by the Bible while abolition is not is an experience.
>> P.S. Do any R developers actually read this?
> 
> I've read one or two verses...
> 
> I also found this (by you):
> https://www.ncbi.nlm.nih.gov/pubmed/20362542
> 
> Which uses embryonic stem cells.
> I recognize that they're mouse embryos.
> However, your article cites at least five other articles (probably, a
> lot more), that use human embryonic stem cells.
> 
> You complain about slavery (that doesn't exist), and then prompte
> murder (which does exist).
> What does that say about you...
> 
> And that's ignoring the way you treat animals
> We slice and dice data, you slice and dice living creatures.
> 
> Here's two songs about freedom, if you have ears to hear:
> https://youtu.be/lKw6uqtGFfo
> https://youtu.be/HAIdo707Sac

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From r|@h|@d@@roy @end|ng |rom gm@||@com  Sat Sep 21 10:16:48 2019
From: r|@h|@d@@roy @end|ng |rom gm@||@com (=?UTF-8?B?4KaL4Ka34Ka/ICAoIOCki+Ckt+CkvyAvIHJJc0hpICk=?=)
Date: Sat, 21 Sep 2019 11:16:48 +0300
Subject: [R] Meta-analysis on microaray data,
 when a sinlge experiment contains diferent tissues
In-Reply-To: <CALqdc3dHM_VnTw=A3tWOYYMQyf7iBx8g=mE_1w2X3xbOaPZHHw@mail.gmail.com>
References: <CALqdc3dHM_VnTw=A3tWOYYMQyf7iBx8g=mE_1w2X3xbOaPZHHw@mail.gmail.com>
Message-ID: <CAODjwAG_S4qr2BNhbcEzprMWjBCgMMEgT=JNvE0wxfoWN7hLLQ@mail.gmail.com>

Yes this is not the best place, rather it should be better asked in
bioinformatics forums like biostar and bioconductor.

On Sat, Sep 21, 2019 at 11:08 AM Mohammadian <mohammadian02 at gmail.com>
wrote:

> Hi!
>
> I dont know whether this is the best place to ask this question, however:
>
> Suppose I want to perform meta-analysis on 10 different microarray studies.
>
> Study   Tissue-source
> Study1     Neuron
> Study2     Blood
> Study3     Neuron and PBMC
> ......
> Study10   ...
>
> How should I treat Study3?
> The R package I want to use is among MetaMA, MetaDE, and perhaps crossMeta
> Even a reference article/book/tutorial would be appreciated.
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 



With regards
Rishi Das Roy

	[[alternative HTML version deleted]]


From beno|t@v@|||@nt @end|ng |rom no-|og@org  Sun Sep 22 08:34:52 2019
From: beno|t@v@|||@nt @end|ng |rom no-|og@org (Benoit Vaillant)
Date: Sun, 22 Sep 2019 08:34:52 +0200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <B13CA65A-F0E3-4686-ADCF-F57E30D7E712@noaa.gov>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
 <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
 <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>
 <B13CA65A-F0E3-4686-ADCF-F57E30D7E712@noaa.gov>
Message-ID: <20190922063452.p6l7mgg67yrlnjmn@auroras.fr>

Hello Roy,

On Sat, Sep 21, 2019 at 04:29:16PM -0700, Roy Mendelssohn - NOAA Federal via R-help wrote:
> don't reply.

While I could refrain from doing it up to now, these single words are
urging me to do so :)

On a personnal side I agree with you that (even public) research
should not be used to address the issue. R-help is far from needing to
kick low. We can do a lot better.

Here are a few of my thoughts I had while reading the thread:
 - the quiet option: already pointed out, won't expand
 - ? Iron Maiden - Powerslave ? (yes I listen to this kind of music):
   well, should the band rename itself, change the album title? :)
 - a more serious one, sometimes I use netstat. definitely not every
   day. So I need a way to remember the options, it's -taupe (in
   french, it means "mole", which does exactly what I want to do:
   dig). Remove the a, switch consonants and it becomes an other
   french word (translation: slut). Should we also ban short options
   that enables one to make such a reminder?
 - a bit of unix "porn":
     $ unzip; strip; touch; finger; grep; mount; fsck; more; yes; fsck; fsck; umount; clean; sleep
   If you see a message here, you are in trouble, these are only unix
   commands.

That's all!

-- 
Beno?t

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190922/a1c4c501/attachment.sig>

From tobby @end|ng |rom htu@@t  Sun Sep 22 12:49:44 2019
From: tobby @end|ng |rom htu@@t (Tobias Fellinger)
Date: Sun, 22 Sep 2019 12:49:44 +0200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
Message-ID: <c9d3955a67cd13eafe19ab718787788c9106cc8c.camel@htu.at>

Hello everyone,

I think Richard's proposal to update the documentation is a good idea. Not
only because it puts the phrasing into context but also because it makes
the documentation clearer.

About the initial mail: I think the awareness for language has increased a
lot in the recent years and I think this is overall a good thing. New code
should consider this from the beginning on and in old code should be
changed where it is possible, particularly the documentation. General
terminology like master/slave is hard to replace but there are alternative
wordings that are less offensive and as clear if not clearer. 

A few thoughts on whether this should be discussed, or if this is the right
place for this discussion. 

To get changes in the code or the documentation done, the help mailing list
is definitely not the best place. But discussing the topic does have some
merit, also if it's only very loosely related to the topic of the mailing-
list. Changing the name of one commandline option will not change society
but having a discussion about phrasing, naming or jokes in documentation
and comments in the code is valuable, even if just to establish a certain
awareness. Whether the original poster is a troll or not does not change
much about this, there are more participants in this conversation than the
op.

I think this discussion could be had much less cynical. Assuming without
reason that anyone acts in bad faith in starting the discussion or arguing
for either side does not help. I also think discussing this separately for
each comment and each commandline option is not the best way to do this.
But the fact, that discussions like this resurface every few years in many
open-source communities shows, that there are concerns here. I think
dismissing completely or belittling these concerns unnecessarily alienates
a (maybe small, maybe larger than it appears) group in the community.

kind regards, Tobias


From r@oknz @end|ng |rom gm@||@com  Sun Sep 22 13:19:55 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 22 Sep 2019 23:19:55 +1200
Subject: [R] Loop With Dates
In-Reply-To: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
References: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
Message-ID: <CABcYAdL-=c6H4qqp+Ni27YUr28f11n6CM2NDco+onbApaGL6Ww@mail.gmail.com>

Is this what you're after?

> df <- data.frame(
+         Date = as.Date(c("2018-03-29", "2018-03-29", "2018-03-29",
+                          "2018-03-30", "2018-03-30", "2018- ..." ...
[TRUNCATED]

> df$count <- cumsum(c(TRUE, diff(df$Date) > 0))
> df
        Date count
1 2018-03-29     1
2 2018-03-29     1
3 2018-03-29     1
4 2018-03-30     2
5 2018-03-30     2
6 2018-03-30     2
7 2018-03-31     3
8 2018-03-31     3
9 2018-03-31     3

No extra libraries needed.  Whenever you want a vector that counts something,
cumsum of a logical vector is a good thing to try.

On Sat, 21 Sep 2019 at 05:47, Phillip Heinrich <herd_dog at cox.net> wrote:
>
> With the data snippet below I?m trying to increment the ?count? vector by one each time the date changes.
>
>          Date count
> 1   2018-03-29     1
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     1
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     1
> 166 2018-03-31     1
> 167 2018-03-31     1
>
>
>             >
>
>
>
> I can get count to change when the date changes with the following code:
>
> test2 <- transform(test2,
> +                   count = ifelse(Date == lag(Date,1),count,count+1))
> > test2
>           Date count
> 1   2018-03-29    NA
> 2   2018-03-29     1
> 3   2018-03-29     1
> 81  2018-03-30     2
> 82  2018-03-30     1
> 83  2018-03-30     1
> 165 2018-03-31     2
> 166 2018-03-31     1
> 167 2018-03-31     1
>
>
>
>
>
>
>
> ...but I want all three March 30 rows to have a count of 2 and the March 31 rows to be equal to 3.  Any suggestions?
>
> Thanks.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k@k@modu05 @end|ng |rom gm@||@com  Sun Sep 22 08:28:14 2019
From: k@k@modu05 @end|ng |rom gm@||@com (kaka modu)
Date: Sun, 22 Sep 2019 09:28:14 +0300
Subject: [R] Academic
Message-ID: <CAPiJDUFE9CYW5K+ZvJap2=W2qNY355ZX8P-+aCXENOFf8aUcQw@mail.gmail.com>

Hi, I'm a postgraduate student from Nigeria, I'm working on Rayleigh and
burr distributions. I tried to fit the two distributions using R through
fitdistrplus and extraDistr packages but I don't have idea on how to set
the start. Please help me on how to fit the distributions. Thank you.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep 22 17:33:13 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 22 Sep 2019 08:33:13 -0700
Subject: [R] Academic
In-Reply-To: <CAPiJDUFE9CYW5K+ZvJap2=W2qNY355ZX8P-+aCXENOFf8aUcQw@mail.gmail.com>
References: <CAPiJDUFE9CYW5K+ZvJap2=W2qNY355ZX8P-+aCXENOFf8aUcQw@mail.gmail.com>
Message-ID: <02FF2AB2-8E38-466D-BA53-CBE96DA89FB8@dcn.davis.ca.us>

Wrong list... this list is about the R language, not about a problem domain in which that language can be used. Read the package description [1] which mentions a dedicated venue.

[1] https://cran.r-project.org/web/packages/fitdistrplus/index.html

On September 21, 2019 11:28:14 PM PDT, kaka modu <kakamodu05 at gmail.com> wrote:
>Hi, I'm a postgraduate student from Nigeria, I'm working on Rayleigh
>and
>burr distributions. I tried to fit the two distributions using R
>through
>fitdistrplus and extraDistr packages but I don't have idea on how to
>set
>the start. Please help me on how to fit the distributions. Thank you.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Sun Sep 22 22:50:12 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 23 Sep 2019 08:50:12 +1200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <B13CA65A-F0E3-4686-ADCF-F57E30D7E712@noaa.gov>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
 <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
 <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>
 <B13CA65A-F0E3-4686-ADCF-F57E30D7E712@noaa.gov>
Message-ID: <CAB8pepwzVk8ez3QALyMLBQLGjjDOoDMsnTT_ktG5qKHgXAVfeQ@mail.gmail.com>

> I also don't think attacking a person's research to counter a point that has nothing to do with their research is what is wanted on this mail-list.

You're right.
I may take a break from these mailing lists, for a while...


From mr@hm@nku|mrt @end|ng |rom gm@||@com  Mon Sep 23 08:00:50 2019
From: mr@hm@nku|mrt @end|ng |rom gm@||@com (Moshiur Rahman)
Date: Mon, 23 Sep 2019 15:00:50 +0900
Subject: [R] dabestr plot color change manually
Message-ID: <CAGNSkSnN4=o1Sp9ZB8raZZ7bUro0om=n+dCzr-zevdOe=GOFgA@mail.gmail.com>

Dear R plot experts,

I'm working on dabestr package for effect size estimation plot (
https://cran.r-project.org/web/packages/dabestr/vignettes/using-dabestr.html)
where I'd like to change the following two issues manually. Does anyone
know-

1) how can I manually change ticks color (I'd like to have black rather
than the default grey one)? and

2) how do I manipulate the point's color distinctly into two different
colors (I'd like to have black and grey colors than the default automatic
gradient color)?

Any suggestion will be highly appreciated.

Thanks in advance.

Regards,

Moshi

JSPS Postdoctoral Fellow
Laboratory of Population Biology
Department of Marine Biosciences
Graduate School of Marine Science and Technology
Tokyo University of Marine Science and Technology
4-5-7 Konan, Minato-ku, Tokyo 108-8477, Japan
Mobile: 050-6874-9072

.

	[[alternative HTML version deleted]]


From |@ngbnj @end|ng |rom gm@||@com  Sun Sep 22 01:10:23 2019
From: |@ngbnj @end|ng |rom gm@||@com (Benjamin Lang)
Date: Sun, 22 Sep 2019 01:10:23 +0200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>
References: <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>
Message-ID: <5BF2A41D-7408-4F05-9AF0-47ED79ABD2A4@gmail.com>

Hi Abby,

I don?t really understand why you?re upset with me, but a) they?re cultured cell lines, not animals, b) they might cure people, c) I don?t do experiments, d) modern slavery, dated today: https://www.theguardian.com/world/2019/sep/21/such-brutality-tricked-into-slavery-in-the-thai-fishing-industry .

I simply don?t like the word, and it doesn?t even describe what the option does.

Best,
Ben

> On 22 Sep 2019, at 00:56, Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
> ?(excerpts only)
>> slavery being easily justified by the Bible while abolition is not is an experience.
>> P.S. Do any R developers actually read this?
> 
> I've read one or two verses...
> 
> I also found this (by you):
> https://www.ncbi.nlm.nih.gov/pubmed/20362542
> 
> Which uses embryonic stem cells.
> I recognize that they're mouse embryos.
> However, your article cites at least five other articles (probably, a
> lot more), that use human embryonic stem cells.
> 
> You complain about slavery (that doesn't exist), and then prompte
> murder (which does exist).
> What does that say about you...
> 
> And that's ignoring the way you treat animals
> We slice and dice data, you slice and dice living creatures.
> 
> Here's two songs about freedom, if you have ears to hear:
> https://youtu.be/lKw6uqtGFfo
> https://youtu.be/HAIdo707Sac

	[[alternative HTML version deleted]]


From |@ngbnj @end|ng |rom gm@||@com  Sun Sep 22 01:30:50 2019
From: |@ngbnj @end|ng |rom gm@||@com (Benjamin Lang)
Date: Sun, 22 Sep 2019 01:30:50 +0200
Subject: [R] [SPAM] Re: The "--slave" option
In-Reply-To: <B13CA65A-F0E3-4686-ADCF-F57E30D7E712@noaa.gov>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <21BC196F-A280-4801-85E1-3C92B25E11D3@noaa.gov>
 <638E8CA7-D293-4424-9D3E-66B2B61B19CF@gmail.com>
 <CAB8pepwOGKHjdSmXE0R9YsR2UEJnW-JzePVxze6fPQK=+J+9kA@mail.gmail.com>
 <B13CA65A-F0E3-4686-ADCF-F57E30D7E712@noaa.gov>
Message-ID: <CA+3jJ-ZD-2-HtUgd3C7HgyfTrv4XCOtFJ1mjoq17gf2w6pf83g@mail.gmail.com>

Hah, fair. I do hope somebody does see it and gives it a thought.

Thanks,
Ben

On Sun, 22 Sep 2019 at 01:29, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Please All:
>
> While as I said in my first post I am still not convinced that the OP was
> in good faith to improve R and not a troll  (yours to decide), I also don't
> think attacking a person's research to counter a point that has nothing to
> do with their research is what is wanted on this mail-list.  There is one
> very simple alternative - don't reply.
>
> Ben - members of R-core do read this mail-list,  and the fact that not a
> single one has replied probably tells you what you need to know.
>
> -Roy
>
>
> > On Sep 21, 2019, at 3:56 PM, Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > (excerpts only)
> >> slavery being easily justified by the Bible while abolition is not is
> an experience.
> >> P.S. Do any R developers actually read this?
> >
> > I've read one or two verses...
> >
> > I also found this (by you):
> > https://www.ncbi.nlm.nih.gov/pubmed/20362542
> >
> > Which uses embryonic stem cells.
> > I recognize that they're mouse embryos.
> > However, your article cites at least five other articles (probably, a
> > lot more), that use human embryonic stem cells.
> >
> > You complain about slavery (that doesn't exist), and then prompte
> > murder (which does exist).
> > What does that say about you...
> >
> > And that's ignoring the way you treat animals
> > We slice and dice data, you slice and dice living creatures.
> >
> > Here's two songs about freedom, if you have ears to hear:
> > https://youtu.be/lKw6uqtGFfo
> > https://youtu.be/HAIdo707Sac
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>

	[[alternative HTML version deleted]]


From de@dd@t@@c|ent|@t@ @end|ng |rom gm@||@com  Mon Sep 23 09:06:50 2019
From: de@dd@t@@c|ent|@t@ @end|ng |rom gm@||@com (=?utf-8?B?TWFsdGUgSMO8Y2tzdMOkZHQ=?=)
Date: Mon, 23 Sep 2019 09:06:50 +0200
Subject: [R] Average distance in kilometers between subsets of points with
 ggmap /geosphere
Message-ID: <3D16E5FC-8878-4D7D-99E8-CC32877B9C4E@gmail.com>

I would like to determine the geographical distances from a number of addresses and determine the mean value (the mean distance) from these.

In case the dataframe has only one row, I have found a solution:

```r
# Pakete laden
library(readxl)
library(openxlsx)
library(googleway)
#library(sf)
library(tidyverse)
library(geosphere)
library("ggmap")

#API Key bestimmen
set_key("")
api_key <- ""
register_google(key=api_key)

#  Data
df <- data.frame(
  V1 = c("80538 M?nchen, Germany", "01328 Dresden, Germany", "80538 M?nchen, Germany",
         "07745 Jena, Germany",    "10117 Berlin, Germany"),
  V2 = c("82152 Planegg, Germany", "01069 Dresden, Germany", "82152 Planegg, Germany",
         "07743 Jena, Germany",    "14195 Berlin, Germany"),
  V3 = c("85748 Garching, Germany", "01069 Dresden, Germany",  "85748 Garching, Germany",
         NA,     "10318 Berlin, Germany"),
  V4 = c("80805 M?nchen, Germany", "01187 Dresden, Germany", "80805 M?nchen, Germany",
         "07745 Jena, Germany", NA), stringsAsFactors=FALSE
)

#replace NA for geocode-funktion
df[is.na(df)] <- ""

#slice it
df1 <- slice(df, 5:5)

#  lon lat Informations
df_2 <- geocode(c(df1$V1, df1$V2,df1$V3, df1$V4)) %>% na.omit()

# to Matrix
mat_df  <- as.matrix(df_2) 

#dist-mat
dist_mat <- distm(mat_df)

#mean-dist of row 5
mean(dist_mat[lower.tri(dist_mat)])/1000  
```

Unfortunately, I fail to implement a function that executes the code for an entire data set. My current problem is, that the function does not calculate the distance-averages rowwise, but calculates the average value from all lines of the data set.

```r
#Funktion

Mean_Dist <- function(df,w,x,y,z) {
  
  # for (row in 1:nrow(df)) {
  #   dist_mat <- geocode(c(w, x, y, z))
  #   
  # }
  
  df <- geocode(c(w, x, y, z)) %>% na.omit() # ziehe lon lat Informationen aus Adressen
  
  mat_df <- as.matrix(df) # schreibe diese in eine Matrix
  
  dist_mat <- distm(mat_df)
  
  dist_mean <- mean(dist_mat[lower.tri(dist_mat)])
  
  return(dist_mean)
}

df %>%  mutate(lon =  Mean_Dist(df,df$V1, df$V2,df$V3, df$V4)/1000)

```
Do you have any idea what mistake I made?

to clarify my question: What I'm trying to create a dataframe like this one (V5):

```r
  V1                     V2                     V3                      V4                      V5                    
  <chr>                  <chr>                  <chr>                   <chr>                   <numeric>                 
1 80538 M?nchen, Germany 82152 Planegg, Germany 85748 Garching, Germany 80805 M?nchen, Germany Mean_Dist_row1
2 01328 Dresden, Germany 01069 Dresden, Germany 01069 Dresden, Germany  01187 Dresden, Germany Mean_Dist_row2
3 80538 M?nchen, Germany 82152 Planegg, Germany 85748 Garching, Germany 80805 M?nchen, Germany Mean_Dist_row3
4 07745 Jena, Germany    07743 Jena, Germany    07745 Jena, Germany     07745 Jena, Germany Mean_Dist_row4   
5 10117 Berlin, Germany  14195 Berlin, Germany  10318 Berlin, Germany   14476 Potsdam, Germany Mean_Dist_row5
```

eg an average of the distance of each row.

From er|cjberger @end|ng |rom gm@||@com  Mon Sep 23 09:32:18 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 23 Sep 2019 10:32:18 +0300
Subject: [R] 
 Average distance in kilometers between subsets of points with
 ggmap /geosphere
In-Reply-To: <3D16E5FC-8878-4D7D-99E8-CC32877B9C4E@gmail.com>
References: <3D16E5FC-8878-4D7D-99E8-CC32877B9C4E@gmail.com>
Message-ID: <CAGgJW74Qk_BzC+A3WwKuQhTMvqyQWvUERJd1FYQyfDJSzJ09wA@mail.gmail.com>

Hi Malte,
I only skimmed your question and looked at the desired output.
I wondered if the apply function could meet your needs.
Here's a small example that might help you:

m <- matrix(1:9,nrow=3)
m <- cbind(m,apply(m,MAR=1,mean))  # MAR=1 says to apply the function
row-wise
m

#         [,1] [,2] [,3] [,4]
# [1,]    1    4    7    4
# [2,]    2    5    8    5
# [3,]    3    6    9    6

HTH,
Eric


On Mon, Sep 23, 2019 at 10:18 AM Malte H?ckst?dt <
deaddatascientists at gmail.com> wrote:

> I would like to determine the geographical distances from a number of
> addresses and determine the mean value (the mean distance) from these.
>
> In case the dataframe has only one row, I have found a solution:
>
> ```r
> # Pakete laden
> library(readxl)
> library(openxlsx)
> library(googleway)
> #library(sf)
> library(tidyverse)
> library(geosphere)
> library("ggmap")
>
> #API Key bestimmen
> set_key("")
> api_key <- ""
> register_google(key=api_key)
>
> #  Data
> df <- data.frame(
>   V1 = c("80538 M?nchen, Germany", "01328 Dresden, Germany", "80538
> M?nchen, Germany",
>          "07745 Jena, Germany",    "10117 Berlin, Germany"),
>   V2 = c("82152 Planegg, Germany", "01069 Dresden, Germany", "82152
> Planegg, Germany",
>          "07743 Jena, Germany",    "14195 Berlin, Germany"),
>   V3 = c("85748 Garching, Germany", "01069 Dresden, Germany",  "85748
> Garching, Germany",
>          NA,     "10318 Berlin, Germany"),
>   V4 = c("80805 M?nchen, Germany", "01187 Dresden, Germany", "80805
> M?nchen, Germany",
>          "07745 Jena, Germany", NA), stringsAsFactors=FALSE
> )
>
> #replace NA for geocode-funktion
> df[is.na(df)] <- ""
>
> #slice it
> df1 <- slice(df, 5:5)
>
> #  lon lat Informations
> df_2 <- geocode(c(df1$V1, df1$V2,df1$V3, df1$V4)) %>% na.omit()
>
> # to Matrix
> mat_df  <- as.matrix(df_2)
>
> #dist-mat
> dist_mat <- distm(mat_df)
>
> #mean-dist of row 5
> mean(dist_mat[lower.tri(dist_mat)])/1000
> ```
>
> Unfortunately, I fail to implement a function that executes the code for
> an entire data set. My current problem is, that the function does not
> calculate the distance-averages rowwise, but calculates the average value
> from all lines of the data set.
>
> ```r
> #Funktion
>
> Mean_Dist <- function(df,w,x,y,z) {
>
>   # for (row in 1:nrow(df)) {
>   #   dist_mat <- geocode(c(w, x, y, z))
>   #
>   # }
>
>   df <- geocode(c(w, x, y, z)) %>% na.omit() # ziehe lon lat Informationen
> aus Adressen
>
>   mat_df <- as.matrix(df) # schreibe diese in eine Matrix
>
>   dist_mat <- distm(mat_df)
>
>   dist_mean <- mean(dist_mat[lower.tri(dist_mat)])
>
>   return(dist_mean)
> }
>
> df %>%  mutate(lon =  Mean_Dist(df,df$V1, df$V2,df$V3, df$V4)/1000)
>
> ```
> Do you have any idea what mistake I made?
>
> to clarify my question: What I'm trying to create a dataframe like this
> one (V5):
>
> ```r
>   V1                     V2                     V3
> V4                      V5
>   <chr>                  <chr>                  <chr>
>  <chr>                   <numeric>
> 1 80538 M?nchen, Germany 82152 Planegg, Germany 85748 Garching, Germany
> 80805 M?nchen, Germany Mean_Dist_row1
> 2 01328 Dresden, Germany 01069 Dresden, Germany 01069 Dresden, Germany
> 01187 Dresden, Germany Mean_Dist_row2
> 3 80538 M?nchen, Germany 82152 Planegg, Germany 85748 Garching, Germany
> 80805 M?nchen, Germany Mean_Dist_row3
> 4 07745 Jena, Germany    07743 Jena, Germany    07745 Jena, Germany
>  07745 Jena, Germany Mean_Dist_row4
> 5 10117 Berlin, Germany  14195 Berlin, Germany  10318 Berlin, Germany
>  14476 Potsdam, Germany Mean_Dist_row5
> ```
>
> eg an average of the distance of each row.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Sep 23 16:14:36 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 23 Sep 2019 16:14:36 +0200
Subject: [R] The "--slave" option
In-Reply-To: <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
Message-ID: <23944.54092.19365.74438@stat.math.ethz.ch>

>>>>> Richard O'Keefe 
>>>>>     on Sat, 21 Sep 2019 09:39:18 +1200 writes:

    > Ah, *now* we're getting somewhere.  There is something
    > that *can* be done that's genuinely helpful.
    >> From the R(1) manual page:
    >        -q, --quiet Don't print startup message

    >        --silent Same as --quiet

    >        --slave Make R run as quietly as possible

    > It might have been better to use --nobanner instead of
    > --quiet.  So perhaps

    >     -q, --quiet Don't print the startup message.  This is
    > the only output that is suppressed.

    >     --silent Same as --quiet.  Suppress the startup
    > message only.

    >     --slave Make R run as quietly as possible.  This is
    > for use when running R as a subordinate process.  See
    > "Introduction to Sub-Processes in R"
    > https://cran.r-project.org/web/packages/subprocess/vignettes/intro.html
    > for an example.

Thank you, Stephen and Richard.

I think we (the R Core Team) *can* make the description a bit
more verbose. However, as practically all "--<foo>" descriptions
are fitting in one short line, (and as the 'subprocess' package is just an
extension pkg, and may disappear (and more reasons)) I'd like to
be less verbose than your proposal.

What about

  -q, --quiet		Don't print startup message

  --silent		Same as --quiet

  --slave		Make R run as quietly as possible.  For use when
  			runnning R as sub(ordinate) process. 

If you look more closely, you'll notice that --slave is not much
quieter than --quiet, the only (?) difference being that the
input is not copied and (only "mostly") the R prompt is also not printed.

And from my experiments (in Linux (Fedora 30)), one might even
notice that in some cases --slave prints the R prompt (to stderr?)
which one might consider bogous (I'm not: not wanting to spend
time fixing this platform-independently) :

    --slave :
------------------------

MM at lynne$ echo '(i <- 1:3)
i*10' | R-3.6.1 --slave --vanilla
> [1] 1 2 3
[1] 10 20 30
MM at lynne$ f=/tmp/Rslave.out$$; echo '(i <- 1:3)
i*10' | R-3.6.1 --slave --vanilla | tee $f
> [1] 1 2 3
[1] 10 20 30
MM at lynne$ cat $f
[1] 1 2 3
[1] 10 20 30

    --quiet :
------------------------

MM at lynne$ f=/tmp/Rquiet.out$$; echo '(i <- 1:3)
i*10' | R-3.6.1 --quiet --vanilla | tee $f
> (i <- 1:3)
[1] 1 2 3
> i*10
[1] 10 20 30
> 
MM at lynne$ cat $f
> (i <- 1:3)
[1] 1 2 3
> i*10
[1] 10 20 30
> 
MM at lynne$ 

------------------------

But there's a bit more to it: In my examples above, both --quiet
and --slave where used together with --vanilla.  In general
--slave *also* never saves, i.e., uses the equivalent of
q('no'), where as --quiet does [ask or ...].

Last but not least, from very simply reading R's source code on
this, it becomes blatant that you can use  '-s'  instead of '--slave',
but we (R Core) have probably not documented that on purpose (so
we could reserve it for something more important, and redefine
the simple use of '-s' some time in the future ?)

So, all those who want to restrict their language could use '-s'
for now.  In addition, we could add  >> one <<  other alias to
--slave, say --subprocess (or --quieter ? or ???)
and one could make that the preferred use some time in the future.

Well, these were another two hours of time *not* spent improving
R technically, but spent reading e-mails, source code, and considering.
Maybe well spent, maybe not ...

Martin Maechler
ETH Zurich and R Core Team




    > On Sat, 21 Sep 2019 at 02:29, Stephen Ellison
    > <S.Ellison at lgcgroup.com> wrote:
    >> 
    >> > Sure, it's a silly example, but it makes about as much
    >> sense as using > "slave" to mean "quiet".  It
    >> doesn't. It's a set of options chosen for when R is
    >> called as a slave process from a controlling process, and
    >> in that it is a reasonable description of the
    >> circumstance.
    >> 
    >> --quiet is a separate command line option with different
    >> effect.
    >> 
    >>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Sep 23 21:42:10 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 23 Sep 2019 19:42:10 +0000 (UTC)
Subject: [R] 95% bootstrap CIs
References: <449979188.15300476.1569267730963.ref@mail.yahoo.com>
Message-ID: <449979188.15300476.1569267730963@mail.yahoo.com>

Dear R-Experts,

Here is my reproducible R code to get the Mean squared error of GAM and MARS after I = 50 iterations/replications.
If I want to get the 95% bootstrap CIs around the MSE of GAM and around the MSE of MARS, how can I complete/modify my R code ?

Many thanks for your precious help.

##################

library(mgcv) 
 library(earth) ? 
my.experiment <- function() { 
n<-500 
x <-runif(n, 0, 5) 
 z <- rnorm(n, 2, 3) 
a <- runif(n, 0, 5) 
y_model <- 0.1*x^3 - 0.5*z^2 - a + x*z + x*a + 3*x*a*z + 10 
 y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) ) 
 gam_model<- gam(y_obs~s(x)+s(z)+s(a)) 
mars_model<-earth(y_obs~x+z+a) 
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
 MSE_MARS<-mean((mars_model$fitted.values - y_model)^2) 
 return( c(MSE_GAM, MSE_MARS) ) 
} ? 
my.data = t(replicate( 50, my.experiment() )) 
colnames(my.data) <- c("MSE_GAM", "MSE_MARS") 
summary(my.data)?

##################


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Sep 23 21:51:26 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 23 Sep 2019 20:51:26 +0100
Subject: [R] 95% bootstrap CIs
In-Reply-To: <449979188.15300476.1569267730963@mail.yahoo.com>
References: <449979188.15300476.1569267730963.ref@mail.yahoo.com>
 <449979188.15300476.1569267730963@mail.yahoo.com>
Message-ID: <8fe63eae-e545-1c08-5612-1cf7ab9b9811@sapo.pt>

Hello,

Is this what you are looking for?


ci95 <- apply(my.data, 2, quantile, probs = c(0.025, 0.975))


Hope this helps,

Rui Barradas

?s 20:42 de 23/09/19, varin sacha via R-help escreveu:
> Dear R-Experts,
> 
> Here is my reproducible R code to get the Mean squared error of GAM and MARS after I = 50 iterations/replications.
> If I want to get the 95% bootstrap CIs around the MSE of GAM and around the MSE of MARS, how can I complete/modify my R code ?
> 
> Many thanks for your precious help.
> 
> ##################
> 
> library(mgcv)
>   library(earth)
> my.experiment <- function() {
> n<-500
> x <-runif(n, 0, 5)
>   z <- rnorm(n, 2, 3)
> a <- runif(n, 0, 5)
> y_model <- 0.1*x^3 - 0.5*z^2 - a + x*z + x*a + 3*x*a*z + 10
>   y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) )
>   gam_model<- gam(y_obs~s(x)+s(z)+s(a))
> mars_model<-earth(y_obs~x+z+a)
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
>   MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
>   return( c(MSE_GAM, MSE_MARS) )
> }
> my.data = t(replicate( 50, my.experiment() ))
> colnames(my.data) <- c("MSE_GAM", "MSE_MARS")
> summary(my.data)
> 
> ##################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Sep 24 03:51:50 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 24 Sep 2019 13:51:50 +1200
Subject: [R] [FORGED] Re:  Loop With Dates
In-Reply-To: <CABcYAdL-=c6H4qqp+Ni27YUr28f11n6CM2NDco+onbApaGL6Ww@mail.gmail.com>
References: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
 <CABcYAdL-=c6H4qqp+Ni27YUr28f11n6CM2NDco+onbApaGL6Ww@mail.gmail.com>
Message-ID: <16a1668f-fb63-228c-e91f-1556020d79a4@auckland.ac.nz>


On 22/09/19 11:19 PM, Richard O'Keefe wrote:

<SNIP>

> Whenever you want a vector that counts something,
> cumsum of a logical vector is a good thing to try.

<SNIP>

Fortune nomination.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From er|cjberger @end|ng |rom gm@||@com  Tue Sep 24 09:50:49 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 24 Sep 2019 10:50:49 +0300
Subject: [R] 
 Average distance in kilometers between subsets of points with
 ggmap /geosphere
In-Reply-To: <A03A0032-4CDB-4ECB-BA57-B4F72801536D@gmail.com>
References: <3D16E5FC-8878-4D7D-99E8-CC32877B9C4E@gmail.com>
 <CAGgJW74Qk_BzC+A3WwKuQhTMvqyQWvUERJd1FYQyfDJSzJ09wA@mail.gmail.com>
 <A03A0032-4CDB-4ECB-BA57-B4F72801536D@gmail.com>
Message-ID: <CAGgJW763NYUpNh1rV_iWcs1iBczd0tXciAqgPSevNm9wRYUm-w@mail.gmail.com>

You are welcome

On Tue, Sep 24, 2019 at 9:10 AM Malte H?ckst?dt <
deaddatascientists at gmail.com> wrote:

> Hello Eric, thanks a lot!In fact, your tip helped me a lot. I have now
> found a solution with lappy and apply. Thank you very much!
>
> regards, malte
>
>
> Am 23.09.2019 um 09:32 schrieb Eric Berger <ericjberger at gmail.com>:
>
> Hi Malte,
> I only skimmed your question and looked at the desired output.
> I wondered if the apply function could meet your needs.
> Here's a small example that might help you:
>
> m <- matrix(1:9,nrow=3)
> m <- cbind(m,apply(m,MAR=1,mean))  # MAR=1 says to apply the function
> row-wise
> m
>
> #         [,1] [,2] [,3] [,4]
> # [1,]    1    4    7    4
> # [2,]    2    5    8    5
> # [3,]    3    6    9    6
>
> HTH,
> Eric
>
>
> On Mon, Sep 23, 2019 at 10:18 AM Malte H?ckst?dt <
> deaddatascientists at gmail.com> wrote:
>
>> I would like to determine the geographical distances from a number of
>> addresses and determine the mean value (the mean distance) from these.
>>
>> In case the dataframe has only one row, I have found a solution:
>>
>> ```r
>> # Pakete laden
>> library(readxl)
>> library(openxlsx)
>> library(googleway)
>> #library(sf)
>> library(tidyverse)
>> library(geosphere)
>> library("ggmap")
>>
>> #API Key bestimmen
>> set_key("")
>> api_key <- ""
>> register_google(key=api_key)
>>
>> #  Data
>> df <- data.frame(
>>   V1 = c("80538 M?nchen, Germany", "01328 Dresden, Germany", "80538
>> M?nchen, Germany",
>>          "07745 Jena, Germany",    "10117 Berlin, Germany"),
>>   V2 = c("82152 Planegg, Germany", "01069 Dresden, Germany", "82152
>> Planegg, Germany",
>>          "07743 Jena, Germany",    "14195 Berlin, Germany"),
>>   V3 = c("85748 Garching, Germany", "01069 Dresden, Germany",  "85748
>> Garching, Germany",
>>          NA,     "10318 Berlin, Germany"),
>>   V4 = c("80805 M?nchen, Germany", "01187 Dresden, Germany", "80805
>> M?nchen, Germany",
>>          "07745 Jena, Germany", NA), stringsAsFactors=FALSE
>> )
>>
>> #replace NA for geocode-funktion
>> df[is.na(df)] <- ""
>>
>> #slice it
>> df1 <- slice(df, 5:5)
>>
>> #  lon lat Informations
>> df_2 <- geocode(c(df1$V1, df1$V2,df1$V3, df1$V4)) %>% na.omit()
>>
>> # to Matrix
>> mat_df  <- as.matrix(df_2)
>>
>> #dist-mat
>> dist_mat <- distm(mat_df)
>>
>> #mean-dist of row 5
>> mean(dist_mat[lower.tri(dist_mat)])/1000
>> ```
>>
>> Unfortunately, I fail to implement a function that executes the code for
>> an entire data set. My current problem is, that the function does not
>> calculate the distance-averages rowwise, but calculates the average value
>> from all lines of the data set.
>>
>> ```r
>> #Funktion
>>
>> Mean_Dist <- function(df,w,x,y,z) {
>>
>>   # for (row in 1:nrow(df)) {
>>   #   dist_mat <- geocode(c(w, x, y, z))
>>   #
>>   # }
>>
>>   df <- geocode(c(w, x, y, z)) %>% na.omit() # ziehe lon lat
>> Informationen aus Adressen
>>
>>   mat_df <- as.matrix(df) # schreibe diese in eine Matrix
>>
>>   dist_mat <- distm(mat_df)
>>
>>   dist_mean <- mean(dist_mat[lower.tri(dist_mat)])
>>
>>   return(dist_mean)
>> }
>>
>> df %>%  mutate(lon =  Mean_Dist(df,df$V1, df$V2,df$V3, df$V4)/1000)
>>
>> ```
>> Do you have any idea what mistake I made?
>>
>> to clarify my question: What I'm trying to create a dataframe like this
>> one (V5):
>>
>> ```r
>>   V1                     V2                     V3
>> V4                      V5
>>   <chr>                  <chr>                  <chr>
>>  <chr>                   <numeric>
>> 1 80538 M?nchen, Germany 82152 Planegg, Germany 85748 Garching, Germany
>> 80805 M?nchen, Germany Mean_Dist_row1
>> 2 01328 Dresden, Germany 01069 Dresden, Germany 01069 Dresden, Germany
>> 01187 Dresden, Germany Mean_Dist_row2
>> 3 80538 M?nchen, Germany 82152 Planegg, Germany 85748 Garching, Germany
>> 80805 M?nchen, Germany Mean_Dist_row3
>> 4 07745 Jena, Germany    07743 Jena, Germany    07745 Jena, Germany
>>  07745 Jena, Germany Mean_Dist_row4
>> 5 10117 Berlin, Germany  14195 Berlin, Germany  10318 Berlin, Germany
>>  14476 Potsdam, Germany Mean_Dist_row5
>> ```
>>
>> eg an average of the distance of each row.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Sep 24 17:47:28 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 24 Sep 2019 10:47:28 -0500
Subject: [R] how to calculate True Positive Rate in R?
Message-ID: <CAF9-5jNOtgd+JyqG6ioLGTfyNVoMM6j=c+3Eu+pbA_RPYAYk_Q@mail.gmail.com>

Hello,

I tried using qvalue function:

    library(qvalue)
    qval_obj=qvalue(pvalR)
    pi1=1-qval_obj$pi0

but after running:

    qval_obj=qvalue(pvalR)
    Error in smooth.spline(lambda, pi0, df = smooth.df) :
      missing or infinite values in inputs are not allowed

or

     qval_obj=qvalue(pvalR,lambda=0.5)
    Error in pi0est(p, ...) :
      ERROR: The estimated pi0 <= 0. Check that you have valid
p-values or use a different range of lambda.

I checked:

    max(pvalR)
    [1] 0.000352731
    min(pvalR)
    [1] 1.84872e-127
    sum(is.na(pvalR))
   [1] 0
   sum(is.infinite(pvalR))
   [1] 0

Please advise,

Thanks
Ana


From er|cjberger @end|ng |rom gm@||@com  Tue Sep 24 17:59:55 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 24 Sep 2019 18:59:55 +0300
Subject: [R] how to calculate True Positive Rate in R?
In-Reply-To: <CAF9-5jNOtgd+JyqG6ioLGTfyNVoMM6j=c+3Eu+pbA_RPYAYk_Q@mail.gmail.com>
References: <CAF9-5jNOtgd+JyqG6ioLGTfyNVoMM6j=c+3Eu+pbA_RPYAYk_Q@mail.gmail.com>
Message-ID: <CAGgJW75hQiF9o4ULEZ=8s4mPqxevqDWsxvWzJ8LNH8+aq5LepQ@mail.gmail.com>

https://cran.r-project.org/web/packages/qvalue/index.html
states
 Package ?qvalue? was removed from the CRAN repository.
Just an FYI

On Tue, Sep 24, 2019 at 6:48 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I tried using qvalue function:
>
>     library(qvalue)
>     qval_obj=qvalue(pvalR)
>     pi1=1-qval_obj$pi0
>
> but after running:
>
>     qval_obj=qvalue(pvalR)
>     Error in smooth.spline(lambda, pi0, df = smooth.df) :
>       missing or infinite values in inputs are not allowed
>
> or
>
>      qval_obj=qvalue(pvalR,lambda=0.5)
>     Error in pi0est(p, ...) :
>       ERROR: The estimated pi0 <= 0. Check that you have valid
> p-values or use a different range of lambda.
>
> I checked:
>
>     max(pvalR)
>     [1] 0.000352731
>     min(pvalR)
>     [1] 1.84872e-127
>     sum(is.na(pvalR))
>    [1] 0
>    sum(is.infinite(pvalR))
>    [1] 0
>
> Please advise,
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 538280 @end|ng |rom gm@||@com  Tue Sep 24 19:55:12 2019
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 24 Sep 2019 11:55:12 -0600
Subject: [R] Loop With Dates
In-Reply-To: <CABcYAdL-=c6H4qqp+Ni27YUr28f11n6CM2NDco+onbApaGL6Ww@mail.gmail.com>
References: <9BE836CA793F47A5BE9CD5091B04BA15@OWNERPC>
 <CABcYAdL-=c6H4qqp+Ni27YUr28f11n6CM2NDco+onbApaGL6Ww@mail.gmail.com>
Message-ID: <CAFEqCdztPNiYFcj8ZjJpjS7S0vEipAeh27kGEAvMDCJiCjm-2g@mail.gmail.com>

Just to add one more option (which is best probably depends on if all
the same dates are together in adjacent rows, if an earlier date can
come later in the data frame, and other things):

df$count <- cumsum(!duplicated(df$Date))

Skill a cumsum of logicals, just a different way of getting the logicals.

On Sun, Sep 22, 2019 at 5:20 AM Richard O'Keefe <raoknz at gmail.com> wrote:
>
> Is this what you're after?
>
> > df <- data.frame(
> +         Date = as.Date(c("2018-03-29", "2018-03-29", "2018-03-29",
> +                          "2018-03-30", "2018-03-30", "2018- ..." ...
> [TRUNCATED]
>
> > df$count <- cumsum(c(TRUE, diff(df$Date) > 0))
> > df
>         Date count
> 1 2018-03-29     1
> 2 2018-03-29     1
> 3 2018-03-29     1
> 4 2018-03-30     2
> 5 2018-03-30     2
> 6 2018-03-30     2
> 7 2018-03-31     3
> 8 2018-03-31     3
> 9 2018-03-31     3
>
> No extra libraries needed.  Whenever you want a vector that counts something,
> cumsum of a logical vector is a good thing to try.
>
> On Sat, 21 Sep 2019 at 05:47, Phillip Heinrich <herd_dog at cox.net> wrote:
> >
> > With the data snippet below I?m trying to increment the ?count? vector by one each time the date changes.
> >
> >          Date count
> > 1   2018-03-29     1
> > 2   2018-03-29     1
> > 3   2018-03-29     1
> > 81  2018-03-30     1
> > 82  2018-03-30     1
> > 83  2018-03-30     1
> > 165 2018-03-31     1
> > 166 2018-03-31     1
> > 167 2018-03-31     1
> >
> >
> >             >
> >
> >
> >
> > I can get count to change when the date changes with the following code:
> >
> > test2 <- transform(test2,
> > +                   count = ifelse(Date == lag(Date,1),count,count+1))
> > > test2
> >           Date count
> > 1   2018-03-29    NA
> > 2   2018-03-29     1
> > 3   2018-03-29     1
> > 81  2018-03-30     2
> > 82  2018-03-30     1
> > 83  2018-03-30     1
> > 165 2018-03-31     2
> > 166 2018-03-31     1
> > 167 2018-03-31     1
> >
> >
> >
> >
> >
> >
> >
> > ...but I want all three March 30 rows to have a count of 2 and the March 31 rows to be equal to 3.  Any suggestions?
> >
> > Thanks.
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 25 00:18:50 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Sep 2019 08:18:50 +1000
Subject: [R] how to calculate True Positive Rate in R?
In-Reply-To: <CAF9-5jNOtgd+JyqG6ioLGTfyNVoMM6j=c+3Eu+pbA_RPYAYk_Q@mail.gmail.com>
References: <CAF9-5jNOtgd+JyqG6ioLGTfyNVoMM6j=c+3Eu+pbA_RPYAYk_Q@mail.gmail.com>
Message-ID: <CA+8X3fV7Ne5JubALR+g2zzTKK3hLHw86w6uUDyOX4vzoGM0iPw@mail.gmail.com>

Hi Ana,
Your minimum value in pvalR is very small and may be causing trouble.
As the qvalue package seems to be in Bioconductor, perhaps posting to
that help list would get an answer.

Jim

On Wed, Sep 25, 2019 at 1:48 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I tried using qvalue function:
>
>     library(qvalue)
>     qval_obj=qvalue(pvalR)
>     pi1=1-qval_obj$pi0
>
> but after running:
>
>     qval_obj=qvalue(pvalR)
>     Error in smooth.spline(lambda, pi0, df = smooth.df) :
>       missing or infinite values in inputs are not allowed
>
> or
>
>      qval_obj=qvalue(pvalR,lambda=0.5)
>     Error in pi0est(p, ...) :
>       ERROR: The estimated pi0 <= 0. Check that you have valid
> p-values or use a different range of lambda.
>
> I checked:
>
>     max(pvalR)
>     [1] 0.000352731
>     min(pvalR)
>     [1] 1.84872e-127
>     sum(is.na(pvalR))
>    [1] 0
>    sum(is.infinite(pvalR))
>    [1] 0
>
> Please advise,
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From herd_dog @end|ng |rom cox@net  Wed Sep 25 01:54:00 2019
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Tue, 24 Sep 2019 16:54:00 -0700
Subject: [R] Creating a Date Field
Message-ID: <6AB72ED7B39A4395BD0429EDEC9D7F83@OWNERPC>

The date is imbedded in the GameID character field so I created a date vector with the following code:

ari18.test3$date <- substring(ari18.test3$GameID,4,11)  And then created a new dataframe with just the Game ID and date vectors.  The date field is a character as shown by the str() command. str(test)
'data.frame':	3 obs. of  2 variables:
 $ GameID: Factor w/ 3 levels "ARI201803290",..: 1 2 3
 $ date  : chr  "20180329" "20180330" "20180331"           GameID     date
1   ARI201803290 20180329
81  ARI201803300 20180330
165 ARI201803310 20180331
> My notes from about a week ago say that the following code will turn ?date? into a date field: test$date <- as.Date(test$date,format="%Y %M %D")  date becomes a date field but the data disappears into NA   str(test)
'data.frame':	3 obs. of  2 variables:
 $ GameID: Factor w/ 3 levels "ARI201803290",..: 1 2 3
 $ date  : Date, format: NA NA NA  What am I missing here?
	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep 25 02:06:06 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 24 Sep 2019 17:06:06 -0700
Subject: [R] Creating a Date Field
In-Reply-To: <6AB72ED7B39A4395BD0429EDEC9D7F83@OWNERPC>
References: <6AB72ED7B39A4395BD0429EDEC9D7F83@OWNERPC>
Message-ID: <BA8A64A0-8CE4-4CB9-A949-692E0D4C356F@dcn.davis.ca.us>

You are not comparing your character date data with the format string. Specifically there are no spaces in your data but there are in your format string. Any characters in the format string that are not part of % date component specifications must be found in your data.

On September 24, 2019 4:54:00 PM PDT, Phillip Heinrich <herd_dog at cox.net> wrote:
>The date is imbedded in the GameID character field so I created a date
>vector with the following code:
>
>ari18.test3$date <- substring(ari18.test3$GameID,4,11)  And then
>created a new dataframe with just the Game ID and date vectors.  The
>date field is a character as shown by the str() command. str(test)
>'data.frame':	3 obs. of  2 variables:
> $ GameID: Factor w/ 3 levels "ARI201803290",..: 1 2 3
>$ date  : chr  "20180329" "20180330" "20180331"           GameID    
>date
>1   ARI201803290 20180329
>81  ARI201803300 20180330
>165 ARI201803310 20180331
>> My notes from about a week ago say that the following code will turn
>?date? into a date field: test$date <- as.Date(test$date,format="%Y %M
>%D")  date becomes a date field but the data disappears into NA  
>str(test)
>'data.frame':	3 obs. of  2 variables:
> $ GameID: Factor w/ 3 levels "ARI201803290",..: 1 2 3
> $ date  : Date, format: NA NA NA  What am I missing here?
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep 25 03:08:06 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 25 Sep 2019 11:08:06 +1000
Subject: [R] Creating a Date Field
In-Reply-To: <6AB72ED7B39A4395BD0429EDEC9D7F83@OWNERPC>
References: <6AB72ED7B39A4395BD0429EDEC9D7F83@OWNERPC>
Message-ID: <CA+8X3fVQzfUTEb1kg5ia4rYPvq6qfWn8FMHDu2J33jjRt6B8Tw@mail.gmail.com>

Hi Phillip,
Try this:

as.Date(c("20180329","20180330","20180331"),"%Y%m%d")
[1] "2018-03-29" "2018-03-30" "2018-03-31"

Note that the format argument has to match the date format exactly.

Jim

On Wed, Sep 25, 2019 at 9:54 AM Phillip Heinrich <herd_dog at cox.net> wrote:
>
> The date is imbedded in the GameID character field so I created a date vector with the following code:
>
> ari18.test3$date <- substring(ari18.test3$GameID,4,11)  And then created a new dataframe with just the Game ID and date vectors.  The date field is a character as shown by the str() command. str(test)
> 'data.frame':   3 obs. of  2 variables:
>  $ GameID: Factor w/ 3 levels "ARI201803290",..: 1 2 3
>  $ date  : chr  "20180329" "20180330" "20180331"           GameID     date
> 1   ARI201803290 20180329
> 81  ARI201803300 20180330
> 165 ARI201803310 20180331
> > My notes from about a week ago say that the following code will turn ?date? into a date field: test$date <- as.Date(test$date,format="%Y %M %D")  date becomes a date field but the data disappears into NA   str(test)
> 'data.frame':   3 obs. of  2 variables:
>  $ GameID: Factor w/ 3 levels "ARI201803290",..: 1 2 3
>  $ date  : Date, format: NA NA NA  What am I missing here?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |@r@@on|ubo @end|ng |rom gm@||@com  Tue Sep 24 21:33:38 2019
From: |@r@@on|ubo @end|ng |rom gm@||@com (Lubo Larsson)
Date: Tue, 24 Sep 2019 14:33:38 -0500
Subject: [R] Multilevel multinomial analysis
Message-ID: <CAF4B2TA3C2v8U_hu62Ju0tmiW1neCoauWSSU7CK65J4AKyAHSg@mail.gmail.com>

Hello,

I am looking for some suggestions as far as packages for doing
multilevel multinomial regression analysis.

Most appreciated.


From vc@ughm@n @end|ng |rom o@th@nyc@gov  Wed Sep 25 00:35:39 2019
From: vc@ughm@n @end|ng |rom o@th@nyc@gov (Caughman, Vanessa (OATH))
Date: Tue, 24 Sep 2019 22:35:39 +0000
Subject: [R] Requesting Assistance with a Backend Question
Message-ID: <432E5D6D01744547A6A11723B8D0DF7FA9BF86E5@MSPWPA-CTWDG2A.cs.nycnet>

Good Evening All,

A unit in my agency - The Office of Administrative Trials and Hearings - is requesting R programming software be made accessible within our network.

Because it is an Open Source application, our Cyber Security group has asked for the following information, about the application, be sought -

Does this application require any access, on the backend, when processing or performing analytics; to any parts of the Cloud environment.

I have read through a lot of the information on the R website and FAQs, but I am not finding any clear answers regarding whether there is any need or ability for the application to access the Cloud.

The unit is working in a Windows, networked environment.

Any assistance in answering these questions will assist in the decision to introduce the application into our networked environment.

Thank you and Kind Regards,

Vanessa

Vanessa J. Caughman-NeSmith
Certified Network Administrator (LAN/WAN)
Office of Administrative Trials and Hearings
100 Church Street, 12th Floor
New York, NY  10007
212.933.3028


	[[alternative HTML version deleted]]


From |@-m| @end|ng |rom @r||@@|t  Wed Sep 25 11:02:42 2019
From: |@-m| @end|ng |rom @r||@@|t (Francesco Ariis)
Date: Wed, 25 Sep 2019 11:02:42 +0200
Subject: [R] static vs. lexical scope
Message-ID: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>

Dear R users/developers,
while ploughing through "An Introduction to R" [1], I found the
expression "static scope" (in contraposition to "lexical scope").

I was a bit puzzled by the difference (since e.g. Wikipedia conflates the
two) until I found this document [2].

Maybe the Introduction should link to it (or similar page) with text
"In case you are interest in the difference between static and lexical
scope, check this explanation"?
Thanks
-F

[1] https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Scope
[2] https://cran.r-project.org/doc/misc/lexical.tex


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Sep 25 12:08:18 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 25 Sep 2019 13:08:18 +0300
Subject: [R] Requesting Assistance with a Backend Question
In-Reply-To: <432E5D6D01744547A6A11723B8D0DF7FA9BF86E5@MSPWPA-CTWDG2A.cs.nycnet>
References: <432E5D6D01744547A6A11723B8D0DF7FA9BF86E5@MSPWPA-CTWDG2A.cs.nycnet>
Message-ID: <20190925130818.4224df13@parabola>

On Tue, 24 Sep 2019 22:35:39 +0000
"Caughman, Vanessa (OATH)" <vcaughman at oath.nyc.gov> wrote:

> Does this application require any access, on the backend, when
> processing or performing analytics; to any parts of the Cloud
> environment.

The answer is: no, but see the fine print.

Core R code (i.e. the one you can get by navigating to
https://cran.r-project.org/ and clicking "Download R for (operating
system)") does *not* use Internet services to perform analytics. A part
of core R is its package system (not used to perform analytics per se),
and its functions like install.packages() function do access CRAN
servers by default (though one could specify the repos = ... argument
to make it access local filesystem or another server of your choice)
to download packages of code provided by other users of R. Packages
installed from CRAN may want to access the Internet or execute
arbitrary code with local user access rights. Though there is a policy
[*] to keep things sane and a review process, mistakes may slip though.

Same goes for any kind of programming environment with a repository of
user-supplied code (Perl and CPAN, Python and PyPI, Rust and
crates.io, JavaScript and NPM...). There are also distributions of R
prepared by third parties, such as Anaconda R, Microsoft R Open, and
third party graphical front-ends for R, such as R-Studio, R commander,
RKWard, JGR, which are also outside of the scope of core R.

But one shouldn't trust the advice of J. Random Hacker from the
Internet to determine whether R is safe (subject to whatever definition
of "safe"). Since R is, indeed, free software, it is possible to
exercise the freedom to study how the program works by looking at the
source code [**] and conducting a security audit.

-- 
Best regards,
Ivan

[*] https://cran.r-project.org/web/packages/policies.html

[**] https://cloud.r-project.org/src/base/R-3/R-3.6.1.tar.gz


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Sep 25 14:43:21 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 25 Sep 2019 12:43:21 +0000 (UTC)
Subject: [R] 95% bootstrap CIs
In-Reply-To: <449979188.15300476.1569267730963@mail.yahoo.com>
References: <449979188.15300476.1569267730963.ref@mail.yahoo.com>
 <449979188.15300476.1569267730963@mail.yahoo.com>
Message-ID: <1439668328.16543550.1569415401776@mail.yahoo.com>

Dear R-experts,

Below the reproducible example. I have tried to write a function that returns the statistic of interest (MSE in my case). I have run boot( ) where the function is included in the statistic argument. I have run boot.ci with the result from boot( ). I guess the error comes from the data : bootResults <- boot(data=?????,statistic=mse, R=1000)
Many thanks for your help.

##################################################
library(mgcv)

library(earth)

library(boot)

?
n<-2000

x <-runif(n, 0, 5)

z <- rnorm(n, 2, 3)

a <- runif(n, 0, 5)


y_model<- 0.1*x^3 - 0.5 * z^2 - a + 10

y_obs<-rnorm(n, y_model, 0.1)

gam_model<- gam(y_obs~s(x)+s(z)+s(a))

mars_model<-earth(y_obs~x+z+a)

?
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)

MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)

?
MSE_GAM

MSE_MARS

?

mse <- function(data,i) {

boot.gam <- gam(y_obs~s(x)+s(z)+s(a),data=data[i,])

return(mean(boot.gam$residuals^2))

}

bootResults <-boot(data=data,statistic=mse,R=1000)

?

mse <- function(data,i) {

boot.earth <- earth((y_obs~x+z+a),data=data[i,])

return(mean(boot.earth$residuals^2))

}

bootResults <-boot(data=data,statistic=mse,R=1000)
##################################################

?









Le lundi 23 septembre 2019 ? 21:42:56 UTC+2, varin sacha via R-help <r-help at r-project.org> a ?crit : 





Dear R-Experts,

Here is my reproducible R code to get the Mean squared error of GAM and MARS after I = 50 iterations/replications.
If I want to get the 95% bootstrap CIs around the MSE of GAM and around the MSE of MARS, how can I complete/modify my R code ?

Many thanks for your precious help.

##################

library(mgcv) 
library(earth) ? 
my.experiment <- function() { 
n<-500 
x <-runif(n, 0, 5) 
z <- rnorm(n, 2, 3) 
a <- runif(n, 0, 5) 
y_model <- 0.1*x^3 - 0.5*z^2 - a + x*z + x*a + 3*x*a*z + 10 
y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) ) 
gam_model<- gam(y_obs~s(x)+s(z)+s(a)) 
mars_model<-earth(y_obs~x+z+a) 
MSE_GAM<-mean((gam_model$fitted.values - y_model)^2) 
MSE_MARS<-mean((mars_model$fitted.values - y_model)^2) 
return( c(MSE_GAM, MSE_MARS) ) 
} ? 
my.data = t(replicate( 50, my.experiment() )) 
colnames(my.data) <- c("MSE_GAM", "MSE_MARS") 
summary(my.data)?

##################

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwu@b @end|ng |rom @|umn|@u@t@hk  Wed Sep 25 13:24:04 2019
From: dwu@b @end|ng |rom @|umn|@u@t@hk (WU Degang)
Date: Wed, 25 Sep 2019 11:24:04 +0000
Subject: [R] curl package new_handle() error on Centos7
Message-ID: <SG2PR01MB3142CDF1F2850B347DE3DA26FC870@SG2PR01MB3142.apcprd01.prod.exchangelabs.com>

Hi everyone,

I am using R-3.6.0 on CentOS 7.7. I got the following error message when I typed ?curl::curl_download(url,tempfile())?:

Error in new_handle() : An unknown option was passed in to libcurl

Because of this error, I cannot use devtools::install_github. The version of curl is the one that comes with CentOS 7.7: curl 7.29.0. My R session info:

R version 3.6.0 (2019-04-26)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS:   /home/opt/software/R-3.6.0/lib64/R/lib/libRblas.so
LAPACK: /home/opt/software/R-3.6.0/lib64/R/lib/libRlapack.so

locale:
[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
[9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] curl_4.1        RCurl_1.95-4.12 bitops_1.0-6

loaded via a namespace (and not attached):
[1] compiler_3.6.0

How can I deal with this error?

Regards,
Degang


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Sep 25 18:50:03 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 25 Sep 2019 17:50:03 +0100
Subject: [R] 95% bootstrap CIs
In-Reply-To: <1439668328.16543550.1569415401776@mail.yahoo.com>
References: <449979188.15300476.1569267730963.ref@mail.yahoo.com>
 <449979188.15300476.1569267730963@mail.yahoo.com>
 <1439668328.16543550.1569415401776@mail.yahoo.com>
Message-ID: <6f71fa02-c1c1-190a-dcaa-34c569c29569@sapo.pt>

Hello,

In your reproducible example you forget to define 'data'.
You should also

set.seed(<some_int_number>)


The following works.


data <- data.frame(a, x, z, y_obs)
boot.ci.type <- c("norm","basic", "perc")

mse_gam <- function(data,i) {
   boot.gam <- gam(y_obs~s(x)+s(z)+s(a),data=data[i,])
   mean(boot.gam$residuals^2)
}

bootResults_gam <-boot(data=data, statistic=mse_gam, R=1000)
boot.ci(bootResults_gam, type = boot.ci.type)


mse <- function(data,i) {
   boot.earth <- earth((y_obs~x+z+a),data=data[i,])
   mean(boot.earth$residuals^2)
}

bootResults <- boot(data=data, statistic=mse, R=1000)
boot.ci(bootResults, type = boot.ci.type)



Hope this helps,

Rui Barradas

?s 13:43 de 25/09/19, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> Below the reproducible example. I have tried to write a function that returns the statistic of interest (MSE in my case). I have run boot( ) where the function is included in the statistic argument. I have run boot.ci with the result from boot( ). I guess the error comes from the data : bootResults <- boot(data=?????,statistic=mse, R=1000)
> Many thanks for your help.
> 
> ##################################################
> library(mgcv)
> 
> library(earth)
> 
> library(boot)
> 
>   
> n<-2000
> 
> x <-runif(n, 0, 5)
> 
> z <- rnorm(n, 2, 3)
> 
> a <- runif(n, 0, 5)
> 
> 
> y_model<- 0.1*x^3 - 0.5 * z^2 - a + 10
> 
> y_obs<-rnorm(n, y_model, 0.1)
> 
> gam_model<- gam(y_obs~s(x)+s(z)+s(a))
> 
> mars_model<-earth(y_obs~x+z+a)
> 
>   
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
> 
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
> 
>   
> MSE_GAM
> 
> MSE_MARS
> 
>   
> 
> mse <- function(data,i) {
> 
> boot.gam <- gam(y_obs~s(x)+s(z)+s(a),data=data[i,])
> 
> return(mean(boot.gam$residuals^2))
> 
> }
> 
> bootResults <-boot(data=data,statistic=mse,R=1000)
> 
>   
> 
> mse <- function(data,i) {
> 
> boot.earth <- earth((y_obs~x+z+a),data=data[i,])
> 
> return(mean(boot.earth$residuals^2))
> 
> }
> 
> bootResults <-boot(data=data,statistic=mse,R=1000)
> ##################################################
> 
>   
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Le lundi 23 septembre 2019 ? 21:42:56 UTC+2, varin sacha via R-help <r-help at r-project.org> a ?crit :
> 
> 
> 
> 
> 
> Dear R-Experts,
> 
> Here is my reproducible R code to get the Mean squared error of GAM and MARS after I = 50 iterations/replications.
> If I want to get the 95% bootstrap CIs around the MSE of GAM and around the MSE of MARS, how can I complete/modify my R code ?
> 
> Many thanks for your precious help.
> 
> ##################
> 
> library(mgcv)
> library(earth)
> my.experiment <- function() {
> n<-500
> x <-runif(n, 0, 5)
> z <- rnorm(n, 2, 3)
> a <- runif(n, 0, 5)
> y_model <- 0.1*x^3 - 0.5*z^2 - a + x*z + x*a + 3*x*a*z + 10
> y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) )
> gam_model<- gam(y_obs~s(x)+s(z)+s(a))
> mars_model<-earth(y_obs~x+z+a)
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
> return( c(MSE_GAM, MSE_MARS) )
> }
> my.data = t(replicate( 50, my.experiment() ))
> colnames(my.data) <- c("MSE_GAM", "MSE_MARS")
> summary(my.data)
> 
> ##################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From me||@@k@@me||me| @end|ng |rom gm@||@com  Wed Sep 25 19:55:18 2019
From: me||@@k@@me||me| @end|ng |rom gm@||@com (melissa schindler)
Date: Wed, 25 Sep 2019 12:55:18 -0500
Subject: [R] Fwd: Vegan Function anova.cca: No Significance Codes Legend in
 Output
In-Reply-To: <CAArv6Zw1Ak_rnA3LoVQV9FL3UMpw29mCq_f7LXA4h29DuUK96w@mail.gmail.com>
References: <CAArv6Zw1Ak_rnA3LoVQV9FL3UMpw29mCq_f7LXA4h29DuUK96w@mail.gmail.com>
Message-ID: <CAArv6Zyi4Jve+N7rm1nv5SP-HXtJLteXjcPqgDZCTNi4o-MpjQ@mail.gmail.com>

Hello all,

I have run a redundancy analysis on Hellinger transformed species abundance
data and environmental variables.

Once I ran the RDA I proceeded to run a permutation on the resulting rda
overall and by "axis" and the outputs did not provide a legend of
significance codes.

Even if none of the axes were significant am I correct in assuming the
legend should still be listed in the results of the permutations?

Is this a glitch in Vegan 2.5-6 or could something be wrong with my
analysis?

*The following is the output of the anova.cca*

anova.cca(rda, by="axis")
'nperm' >= set of all permutations: complete enumeration.
Set of permutations < 'minperm'. Generating entire set.
Permutation test for rda under reduced model
Forward tests for axes
Permutation: free
Number of permutations: 119

Model: rda(formula = spe.hel ~ Conduct + DO + pH, data = Zscore_env_var)
         Df Variance       F Pr(>F)
RDA1      1 0.186195 41.4450 0.2333
RDA2      1 0.002051  0.4564 0.8833
Residual  2 0.008985
*Significance code legend should be listed here with asterisk's denoting
the p-values*

> anova.cca(rda)
'nperm' >= set of all permutations: complete enumeration.
Set of permutations < 'minperm'. Generating entire set.
Permutation test for rda under reduced model
Permutation: free
Number of permutations: 119

Model: rda(formula = spe.hel ~ Conduct + DO + pH, data = Zscore_env_var)
         Df Variance      F Pr(>F)
Model     3 0.188246 6.9836  0.225
Residual  1 0.008985

*Significance code legend should be listed here with asterisk's denoting
the p-values*


Thanks for your time!

Melissa

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Thu Sep 26 13:55:26 2019
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 26 Sep 2019 13:55:26 +0200
Subject: [R] static vs. lexical scope
In-Reply-To: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
References: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
Message-ID: <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>

On Wed, 25 Sep 2019 at 11:03, Francesco Ariis <fa-ml at ariis.it> wrote:
>
> Dear R users/developers,
> while ploughing through "An Introduction to R" [1], I found the
> expression "static scope" (in contraposition to "lexical scope").
>
> I was a bit puzzled by the difference (since e.g. Wikipedia conflates the
> two) until I found this document [2].


I sometimes teach a little R, and they might ask about static/lexical scope.
My short answer is normally that S uses static scoping and R uses
lexical scoping.
And most all modern languages uses lexical scoping.
So if they know Java, C, C# etc. then the scoping rules for R are the same.

I finally says that it is not a full answer but enough for most.

Regards
Martin


From r@oknz @end|ng |rom gm@||@com  Thu Sep 26 15:44:48 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 27 Sep 2019 01:44:48 +1200
Subject: [R] static vs. lexical scope
In-Reply-To: <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>
References: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
 <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>
Message-ID: <CABcYAdLUwD0Q+ngJ8tFd_8fkkbQsiS=L-JVUPCXxQqAjGj6EYg@mail.gmail.com>

Actually, R's scope rules are seriously weird.
I set out to write an R compiler, wow, >20 years ago.
Figured out how to handle optional and keyword parameters efficiently,
figured out a lot of other things, but choked on the scope rules.
Consider

> x <- 1
> f <- function () {
+   a <- x
+   x <- 2
+   b <- x
+   c(a=a, b=b)
+ }
> f()
a b
1 2
> x
[1] 1

It's really not clear what is going on here.
However, ?assign can introduce new variables into an environment,
and from something like
  with(df, x*2-y)
it is impossible for a compiler to tell which, if either, of x and y is to
be obtained from df and which from outside.  And of course ?with
is just a function:

> df <- data.frame(y=24)
> w <- with
> w(df, x*2-y)
[1] -22

So you cannot in general tell *which* function can twist the environment
in which its arguments will be evaluated.

I got very tired of trying to explore a twisty maze of documentation and
trying to infer a specification from examples.  I would come up with an
ingenious mechanism for making the common case tolerable and the
rare cases possible, and then I'd discover a bear trap I hadn't seen.
I love R, but I try really hard not to be clever with it.




So while R's scoping is *like* lexical scoping, it is *dynamic* lexical
scoping, to coin a phrase.

On Thu, 26 Sep 2019 at 23:56, Martin M?ller Skarbiniks Pedersen
<traxplayer at gmail.com> wrote:
>
> On Wed, 25 Sep 2019 at 11:03, Francesco Ariis <fa-ml at ariis.it> wrote:
> >
> > Dear R users/developers,
> > while ploughing through "An Introduction to R" [1], I found the
> > expression "static scope" (in contraposition to "lexical scope").
> >
> > I was a bit puzzled by the difference (since e.g. Wikipedia conflates the
> > two) until I found this document [2].
>
>
> I sometimes teach a little R, and they might ask about static/lexical scope.
> My short answer is normally that S uses static scoping and R uses
> lexical scoping.
> And most all modern languages uses lexical scoping.
> So if they know Java, C, C# etc. then the scoping rules for R are the same.
>
> I finally says that it is not a full answer but enough for most.
>
> Regards
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep 26 16:58:57 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 26 Sep 2019 10:58:57 -0400
Subject: [R] static vs. lexical scope
In-Reply-To: <CABcYAdLUwD0Q+ngJ8tFd_8fkkbQsiS=L-JVUPCXxQqAjGj6EYg@mail.gmail.com>
References: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
 <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>
 <CABcYAdLUwD0Q+ngJ8tFd_8fkkbQsiS=L-JVUPCXxQqAjGj6EYg@mail.gmail.com>
Message-ID: <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>

On 26/09/2019 9:44 a.m., Richard O'Keefe wrote:
> Actually, R's scope rules are seriously weird.
> I set out to write an R compiler, wow, >20 years ago.
> Figured out how to handle optional and keyword parameters efficiently,
> figured out a lot of other things, but choked on the scope rules.
> Consider
> 
>> x <- 1
>> f <- function () {
> +   a <- x
> +   x <- 2
> +   b <- x
> +   c(a=a, b=b)
> + }
>> f()
> a b
> 1 2
>> x
> [1] 1
> 
> It's really not clear what is going on here.

This is all pretty clear:  in the first assignment, x is found in the 
global environment, because it does not exist in the evaluation frame.
In the second assignment, a new variable is created in the evaluation 
frame.  In the third assignment, that new variable is used to set the 
value of b.

> However, ?assign can introduce new variables into an environment,
> and from something like
>    with(df, x*2-y)
> it is impossible for a compiler to tell which, if either, of x and y is to
> be obtained from df and which from outside.  And of course ?with
> is just a function:
> 
>> df <- data.frame(y=24)
>> w <- with
>> w(df, x*2-y)
> [1] -22
> 
> So you cannot in general tell *which* function can twist the environment
> in which its arguments will be evaluated.

It's definitely hard to compile R because of the scoping rules, but that 
doesn't make the scoping rules unclear.

> I got very tired of trying to explore a twisty maze of documentation and
> trying to infer a specification from examples.  I would come up with an
> ingenious mechanism for making the common case tolerable and the
> rare cases possible, and then I'd discover a bear trap I hadn't seen.
> I love R, but I try really hard not to be clever with it.

I think the specification is really pretty simple.  I'm not sure it is 
well documented anywhere, but I think I understand it pretty well, and 
it doesn't seem overly complicated to me.

> So while R's scoping is *like* lexical scoping, it is *dynamic* lexical
> scoping, to coin a phrase.

I'd say it is regular lexical scoping but with dynamic variable 
creation. Call that dynamic lexical scoping if you want, but it's not 
really a mystery.

Duncan Murdoch

> 
> On Thu, 26 Sep 2019 at 23:56, Martin M?ller Skarbiniks Pedersen
> <traxplayer at gmail.com> wrote:
>>
>> On Wed, 25 Sep 2019 at 11:03, Francesco Ariis <fa-ml at ariis.it> wrote:
>>>
>>> Dear R users/developers,
>>> while ploughing through "An Introduction to R" [1], I found the
>>> expression "static scope" (in contraposition to "lexical scope").
>>>
>>> I was a bit puzzled by the difference (since e.g. Wikipedia conflates the
>>> two) until I found this document [2].
>>
>>
>> I sometimes teach a little R, and they might ask about static/lexical scope.
>> My short answer is normally that S uses static scoping and R uses
>> lexical scoping.
>> And most all modern languages uses lexical scoping.
>> So if they know Java, C, C# etc. then the scoping rules for R are the same.
>>
>> I finally says that it is not a full answer but enough for most.
>>
>> Regards
>> Martin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Thu Sep 26 18:14:45 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Thu, 26 Sep 2019 09:14:45 -0700
Subject: [R] static vs. lexical scope
In-Reply-To: <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>
References: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
 <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>
 <CABcYAdLUwD0Q+ngJ8tFd_8fkkbQsiS=L-JVUPCXxQqAjGj6EYg@mail.gmail.com>
 <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>
Message-ID: <CAA99HCwVBE0nvqAOVoA7oDtrJ+UmE7kusr_K5Rp+AgiNYT6TCw@mail.gmail.com>

The best summary I've read on the subject of R's scoping rules (in
particular how they compare to scoping rules in S-PLUS) is Dr. John
Fox's "Frames, Environments, and Scope in R and S-PLUS", written as an
Appendix to the first edition of his book, An R and S-PLUS Companion
to Applied Regression (2002).

In this document Dr. Fox refers to "lexical" scoping primarily,
however where "static" scoping is mentioned, it is defined as
equivalent to "lexical" scoping. The Appendix is available as a PDF
from:

https://socialsciences.mcmaster.ca/jfox/Books/Companion-1E/appendix-scope.pdf

HTH, Bill.

W. Michels, Ph.D.



On Thu, Sep 26, 2019 at 7:59 AM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 26/09/2019 9:44 a.m., Richard O'Keefe wrote:
> > Actually, R's scope rules are seriously weird.
> > I set out to write an R compiler, wow, >20 years ago.
> > Figured out how to handle optional and keyword parameters efficiently,
> > figured out a lot of other things, but choked on the scope rules.
> > Consider
> >
> >> x <- 1
> >> f <- function () {
> > +   a <- x
> > +   x <- 2
> > +   b <- x
> > +   c(a=a, b=b)
> > + }
> >> f()
> > a b
> > 1 2
> >> x
> > [1] 1
> >
> > It's really not clear what is going on here.
>
> This is all pretty clear:  in the first assignment, x is found in the
> global environment, because it does not exist in the evaluation frame.
> In the second assignment, a new variable is created in the evaluation
> frame.  In the third assignment, that new variable is used to set the
> value of b.
>
> > However, ?assign can introduce new variables into an environment,
> > and from something like
> >    with(df, x*2-y)
> > it is impossible for a compiler to tell which, if either, of x and y is to
> > be obtained from df and which from outside.  And of course ?with
> > is just a function:
> >
> >> df <- data.frame(y=24)
> >> w <- with
> >> w(df, x*2-y)
> > [1] -22
> >
> > So you cannot in general tell *which* function can twist the environment
> > in which its arguments will be evaluated.
>
> It's definitely hard to compile R because of the scoping rules, but that
> doesn't make the scoping rules unclear.
>
> > I got very tired of trying to explore a twisty maze of documentation and
> > trying to infer a specification from examples.  I would come up with an
> > ingenious mechanism for making the common case tolerable and the
> > rare cases possible, and then I'd discover a bear trap I hadn't seen.
> > I love R, but I try really hard not to be clever with it.
>
> I think the specification is really pretty simple.  I'm not sure it is
> well documented anywhere, but I think I understand it pretty well, and
> it doesn't seem overly complicated to me.
>
> > So while R's scoping is *like* lexical scoping, it is *dynamic* lexical
> > scoping, to coin a phrase.
>
> I'd say it is regular lexical scoping but with dynamic variable
> creation. Call that dynamic lexical scoping if you want, but it's not
> really a mystery.
>
> Duncan Murdoch
>
> >
> > On Thu, 26 Sep 2019 at 23:56, Martin M?ller Skarbiniks Pedersen
> > <traxplayer at gmail.com> wrote:
> >>
> >> On Wed, 25 Sep 2019 at 11:03, Francesco Ariis <fa-ml at ariis.it> wrote:
> >>>
> >>> Dear R users/developers,
> >>> while ploughing through "An Introduction to R" [1], I found the
> >>> expression "static scope" (in contraposition to "lexical scope").
> >>>
> >>> I was a bit puzzled by the difference (since e.g. Wikipedia conflates the
> >>> two) until I found this document [2].
> >>
> >>
> >> I sometimes teach a little R, and they might ask about static/lexical scope.
> >> My short answer is normally that S uses static scoping and R uses
> >> lexical scoping.
> >> And most all modern languages uses lexical scoping.
> >> So if they know Java, C, C# etc. then the scoping rules for R are the same.
> >>
> >> I finally says that it is not a full answer but enough for most.
> >>
> >> Regards
> >> Martin
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From herd_dog @end|ng |rom cox@net  Thu Sep 26 18:55:00 2019
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Thu, 26 Sep 2019 09:55:00 -0700
Subject: [R] Real Basic Question
Message-ID: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>

Just when I think I?m starting to get the hang of R I run into something that sends me back to Go without collecting $200.

The working directory seems to be correct when I load an .rda file but it is not there and it is not in the Global Environment in the upper right hand window in RStudio.
getwd()
[1] "C:/Users/Owner/Documents/Baseball/RetroSheetDocumentation"
> load("~/Baseball/RetroSheetDocumentation/ari18.test2.rda")
> ari18.test2
Error: object 'ari18.test2' not found
> ls()
 [1] "ari18.test3"       "array1"            "array2"            "BaseballArticles"  "BaseballArticles2"
 [6] "BaseballArticles3" "BBCorpus"          "BBtdm"             "firstfunction"     "folder"           
[11] "h"                 "matrix"            "matrix2"           "matrix3"           "n"                
[16] "seq"               "testvector"        "u"                 "vec"               "x"                
[21] "y"                 "yourname"         
 
     
            >  
     


Somehow ari18.test3 loaded but ari18.test2 will not.

What am I missing here?

Thanks.
	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep 26 18:59:58 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 26 Sep 2019 12:59:58 -0400
Subject: [R] static vs. lexical scope
In-Reply-To: <CAA99HCwVBE0nvqAOVoA7oDtrJ+UmE7kusr_K5Rp+AgiNYT6TCw@mail.gmail.com>
References: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
 <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>
 <CABcYAdLUwD0Q+ngJ8tFd_8fkkbQsiS=L-JVUPCXxQqAjGj6EYg@mail.gmail.com>
 <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>
 <CAA99HCwVBE0nvqAOVoA7oDtrJ+UmE7kusr_K5Rp+AgiNYT6TCw@mail.gmail.com>
Message-ID: <4be5b9a0-127c-c176-50bc-c8c7fb22e1ac@gmail.com>

On 26/09/2019 12:14 p.m., William Michels wrote:
> The best summary I've read on the subject of R's scoping rules (in
> particular how they compare to scoping rules in S-PLUS) is Dr. John
> Fox's "Frames, Environments, and Scope in R and S-PLUS", written as an
> Appendix to the first edition of his book, An R and S-PLUS Companion
> to Applied Regression (2002).

That's a nice comparison of the two systems.  I'm not so sure it's the 
best place to go for people who are only interested in R scoping, 
because some choice of terminology conflicts with standard usage in R 
(I'm thinking "environment" in particular), and this could end up 
confusing users who don't need the more general overview.

I think Hadley's description in Advanced R (online here: 
https://adv-r.hadley.nz/functions.html#lexical-scoping) is a pretty 
clear description of how R works.

Duncan Murdoch
	
> 
> In this document Dr. Fox refers to "lexical" scoping primarily,
> however where "static" scoping is mentioned, it is defined as
> equivalent to "lexical" scoping. The Appendix is available as a PDF
> from:
> 
> https://socialsciences.mcmaster.ca/jfox/Books/Companion-1E/appendix-scope.pdf
> 
> HTH, Bill.
> 
> W. Michels, Ph.D.
> 
> 
> 
> On Thu, Sep 26, 2019 at 7:59 AM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 26/09/2019 9:44 a.m., Richard O'Keefe wrote:
>>> Actually, R's scope rules are seriously weird.
>>> I set out to write an R compiler, wow, >20 years ago.
>>> Figured out how to handle optional and keyword parameters efficiently,
>>> figured out a lot of other things, but choked on the scope rules.
>>> Consider
>>>
>>>> x <- 1
>>>> f <- function () {
>>> +   a <- x
>>> +   x <- 2
>>> +   b <- x
>>> +   c(a=a, b=b)
>>> + }
>>>> f()
>>> a b
>>> 1 2
>>>> x
>>> [1] 1
>>>
>>> It's really not clear what is going on here.
>>
>> This is all pretty clear:  in the first assignment, x is found in the
>> global environment, because it does not exist in the evaluation frame.
>> In the second assignment, a new variable is created in the evaluation
>> frame.  In the third assignment, that new variable is used to set the
>> value of b.
>>
>>> However, ?assign can introduce new variables into an environment,
>>> and from something like
>>>     with(df, x*2-y)
>>> it is impossible for a compiler to tell which, if either, of x and y is to
>>> be obtained from df and which from outside.  And of course ?with
>>> is just a function:
>>>
>>>> df <- data.frame(y=24)
>>>> w <- with
>>>> w(df, x*2-y)
>>> [1] -22
>>>
>>> So you cannot in general tell *which* function can twist the environment
>>> in which its arguments will be evaluated.
>>
>> It's definitely hard to compile R because of the scoping rules, but that
>> doesn't make the scoping rules unclear.
>>
>>> I got very tired of trying to explore a twisty maze of documentation and
>>> trying to infer a specification from examples.  I would come up with an
>>> ingenious mechanism for making the common case tolerable and the
>>> rare cases possible, and then I'd discover a bear trap I hadn't seen.
>>> I love R, but I try really hard not to be clever with it.
>>
>> I think the specification is really pretty simple.  I'm not sure it is
>> well documented anywhere, but I think I understand it pretty well, and
>> it doesn't seem overly complicated to me.
>>
>>> So while R's scoping is *like* lexical scoping, it is *dynamic* lexical
>>> scoping, to coin a phrase.
>>
>> I'd say it is regular lexical scoping but with dynamic variable
>> creation. Call that dynamic lexical scoping if you want, but it's not
>> really a mystery.
>>
>> Duncan Murdoch
>>
>>>
>>> On Thu, 26 Sep 2019 at 23:56, Martin M?ller Skarbiniks Pedersen
>>> <traxplayer at gmail.com> wrote:
>>>>
>>>> On Wed, 25 Sep 2019 at 11:03, Francesco Ariis <fa-ml at ariis.it> wrote:
>>>>>
>>>>> Dear R users/developers,
>>>>> while ploughing through "An Introduction to R" [1], I found the
>>>>> expression "static scope" (in contraposition to "lexical scope").
>>>>>
>>>>> I was a bit puzzled by the difference (since e.g. Wikipedia conflates the
>>>>> two) until I found this document [2].
>>>>
>>>>
>>>> I sometimes teach a little R, and they might ask about static/lexical scope.
>>>> My short answer is normally that S uses static scoping and R uses
>>>> lexical scoping.
>>>> And most all modern languages uses lexical scoping.
>>>> So if they know Java, C, C# etc. then the scoping rules for R are the same.
>>>>
>>>> I finally says that it is not a full answer but enough for most.
>>>>
>>>> Regards
>>>> Martin
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep 26 19:06:48 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 26 Sep 2019 13:06:48 -0400
Subject: [R] Real Basic Question
In-Reply-To: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>
References: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>
Message-ID: <58d97aab-4b3a-5342-743e-0afcaa329ddf@gmail.com>

On 26/09/2019 12:55 p.m., Phillip Heinrich wrote:
> Just when I think I?m starting to get the hang of R I run into something that sends me back to Go without collecting $200.
> 
> The working directory seems to be correct when I load an .rda file but it is not there and it is not in the Global Environment in the upper right hand window in RStudio.
> getwd()
> [1] "C:/Users/Owner/Documents/Baseball/RetroSheetDocumentation"
>> load("~/Baseball/RetroSheetDocumentation/ari18.test2.rda")
>> ari18.test2
> Error: object 'ari18.test2' not found
>> ls()
>   [1] "ari18.test3"       "array1"            "array2"            "BaseballArticles"  "BaseballArticles2"
>   [6] "BaseballArticles3" "BBCorpus"          "BBtdm"             "firstfunction"     "folder"
> [11] "h"                 "matrix"            "matrix2"           "matrix3"           "n"
> [16] "seq"               "testvector"        "u"                 "vec"               "x"
> [21] "y"                 "yourname"
>   
>       
>              >
>       
> 
> 
> Somehow ari18.test3 loaded but ari18.test2 will not.
> 
> What am I missing here?

The filename (~/Baseball/RetroSheetDocumentation/ari18.test2.rda) has no 
connection to the variables that would be created when you load it. 
Finding out what's in that file isn't obvious:  you need to load it into 
an empty location (either your global environment in a clean new 
session, or one created specially for the purpose).  E.g.

  env <- new.env()
  load("~/Baseball/RetroSheetDocumentation/ari18.test2.rda", envir = env)
  ls(envir = env)

This will load the object(s) from that file into the environment env. 
You could copy them from there to somewhere else, use them from there, 
or just load again into the global environment, now you know what you're 
getting.

Duncan Murdoch


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep 26 19:22:05 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 26 Sep 2019 10:22:05 -0700
Subject: [R] static vs. lexical scope
In-Reply-To: <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>
References: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
 <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>
 <CABcYAdLUwD0Q+ngJ8tFd_8fkkbQsiS=L-JVUPCXxQqAjGj6EYg@mail.gmail.com>
 <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>
Message-ID: <731B06A8-C264-47BA-8692-A89E8453A157@dcn.davis.ca.us>

I found this confusing until I learned about environments. The current state of the environment that was active at the time the function was defined is searched, not a frozen copy of the enclosing environment as it existed at the time the function was defined.

x <- 1 # as it was when f was created
f <- function () {
  a <- x # x not yet in current environment
  x <- 2 # always modifies current environment
  b <- x # finds the definition nearest along the enclosing environments list
  c(a=a, b=b)
}
x <- 3 # change after f was created
f()
## a b
## 3 2
x # changes within function don't affect enclosing or calling environments
## [1] 3

Duncan refers to "evaluation frame" (a term described in the R Language Definition) but I tend to think of a "current environment" and two linked lists of supplementary environments: the search path of `parent.env`()s (a.k.a. enclosing environments built from the current environments that were active when functions were defined) and the call chain of `parent.frame`()s (function environments that were active at the point functions were called). You can almost forget about the parent.frame chain unless you are creating your own non-standard evaluation functions (like `with` or `subset`)... 

Environments mutate over time. Specifically, the list of enclosing environments doesn't change but the variables in them do.

(Credit to Hadley Wickham's Advanced R, criticisms to me.)

On September 26, 2019 7:58:57 AM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 26/09/2019 9:44 a.m., Richard O'Keefe wrote:
>> Actually, R's scope rules are seriously weird.
>> I set out to write an R compiler, wow, >20 years ago.
>> Figured out how to handle optional and keyword parameters
>efficiently,
>> figured out a lot of other things, but choked on the scope rules.
>> Consider
>> 
>>> x <- 1
>>> f <- function () {
>> +   a <- x
>> +   x <- 2
>> +   b <- x
>> +   c(a=a, b=b)
>> + }
>>> f()
>> a b
>> 1 2
>>> x
>> [1] 1
>> 
>> It's really not clear what is going on here.
>
>This is all pretty clear:  in the first assignment, x is found in the 
>global environment, because it does not exist in the evaluation frame.
>In the second assignment, a new variable is created in the evaluation 
>frame.  In the third assignment, that new variable is used to set the 
>value of b.
>
>> However, ?assign can introduce new variables into an environment,
>> and from something like
>>    with(df, x*2-y)
>> it is impossible for a compiler to tell which, if either, of x and y
>is to
>> be obtained from df and which from outside.  And of course ?with
>> is just a function:
>> 
>>> df <- data.frame(y=24)
>>> w <- with
>>> w(df, x*2-y)
>> [1] -22
>> 
>> So you cannot in general tell *which* function can twist the
>environment
>> in which its arguments will be evaluated.
>
>It's definitely hard to compile R because of the scoping rules, but
>that 
>doesn't make the scoping rules unclear.
>
>> I got very tired of trying to explore a twisty maze of documentation
>and
>> trying to infer a specification from examples.  I would come up with
>an
>> ingenious mechanism for making the common case tolerable and the
>> rare cases possible, and then I'd discover a bear trap I hadn't seen.
>> I love R, but I try really hard not to be clever with it.
>
>I think the specification is really pretty simple.  I'm not sure it is 
>well documented anywhere, but I think I understand it pretty well, and 
>it doesn't seem overly complicated to me.
>
>> So while R's scoping is *like* lexical scoping, it is *dynamic*
>lexical
>> scoping, to coin a phrase.
>
>I'd say it is regular lexical scoping but with dynamic variable 
>creation. Call that dynamic lexical scoping if you want, but it's not 
>really a mystery.
>
>Duncan Murdoch
>
>> 
>> On Thu, 26 Sep 2019 at 23:56, Martin M?ller Skarbiniks Pedersen
>> <traxplayer at gmail.com> wrote:
>>>
>>> On Wed, 25 Sep 2019 at 11:03, Francesco Ariis <fa-ml at ariis.it>
>wrote:
>>>>
>>>> Dear R users/developers,
>>>> while ploughing through "An Introduction to R" [1], I found the
>>>> expression "static scope" (in contraposition to "lexical scope").
>>>>
>>>> I was a bit puzzled by the difference (since e.g. Wikipedia
>conflates the
>>>> two) until I found this document [2].
>>>
>>>
>>> I sometimes teach a little R, and they might ask about
>static/lexical scope.
>>> My short answer is normally that S uses static scoping and R uses
>>> lexical scoping.
>>> And most all modern languages uses lexical scoping.
>>> So if they know Java, C, C# etc. then the scoping rules for R are
>the same.
>>>
>>> I finally says that it is not a full answer but enough for most.
>>>
>>> Regards
>>> Martin
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From burbr|nk666 @end|ng |rom gm@||@com  Thu Sep 26 02:17:01 2019
From: burbr|nk666 @end|ng |rom gm@||@com (Frank Burbrink)
Date: Wed, 25 Sep 2019 20:17:01 -0400
Subject: [R] capscale/anova.cca issue
Message-ID: <CAAbnQ5g5zNgJ79=8ygH4CKpB0=PTfWZrj0mN7uTO4PXX+TrDng@mail.gmail.com>

Hello,

I have what should be an easy question to answer I hope. I am using
Capscale and anovs.cca in vegan to examine relationship between genetic
distance among individuals to be predicted by several ecological niche
model distance matrices generated from Circuitscape and partialing out
distance in space (from lat/lon). I have done the following:

Converted all of the distances on the RHS using PCNM and used ?scores? to
pull the scores from the PCNM results. My genetic distance is formatted as
a ?dist? object on the LHS. The model looks as follows:



capscale(gendist~scores(cur)+scores(ms)+scores(el)+scores(lgm)+scores(lig)+scores(mis19)+Condition(scores(dist2)),sqrt.dist=T)->try



This works and so does:

anova(try, by=?terms)



However, when I used anova(try, by=?margin) I get this error:

Error in X[, ass != i, drop = FALSE] :

  (subscript) logical subscript too long



If I chose a smaller number of axes, then it will work but seems unstable
(P values change from significant to non-significant and vice versa) given
the number of axes I choose. This model works with anova(try, by=?margin?)
for instance:

capscale(gendist~scores(cur,choices=1:20)+scores(ms,choices=1:20)+scores(el,choices=1:20)+scores(lgm,choices=1:20)+scores(lig,choices=1:20)+scores(mis19,choices=1:20)+Condition(scores(dist2,choices=1:20))->try



If I increase the number axes to 50 then I get the same error as above.



What could be causing this error and is there way to get a stable answer
using anova.cca with margins?



I thank you very much in advance!



Frank



P.S.



Here are some outputs from the reduced to the full axes model:



Call: capscale(formula = gendist ~ scores(cur) + scores(ms) + scores(el) +
scores(lgm) + scores(lig) + scores(mis19) +

Condition(scores(dist2)), sqrt.dist = T)



                 Inertia Proportion Rank

Total         30.3890110  1.0000000

Conditional   20.2125899  0.6651283  115

Constrained    9.9498632  0.3274165  118

Unconstrained  0.2551651  0.0083966    4

Imaginary     -0.0286072 -0.0009414    5

Inertia is Nei distance



Call: capscale(formula = gendist ~ scores(cur, choices = 1:20) + scores(ms,
choices = 1:20) + scores(el, choices = 1:20) +

scores(lgm, choices = 1:20) + scores(lig, choices = 1:20) + scores(mis19,
choices = 1:20) + Condition(scores(dist2, choices

= 1:20)))



              Inertia Proportion Rank

Total         10.1488     1.0000

Conditional    6.9685     0.6866   20

Constrained    3.1599     0.3114  120

Unconstrained  1.9522     0.1924   97

Imaginary     -1.9319    -0.1904   88

Inertia is squared Nei distance

Some constraints were aliased because they were collinear (redundant)



-- 

*__________________________________*
*Frank T. Burbrink, Ph.D.*

*Curator in Charge*
*Department of Herpetology*
*American Museum of Natural History*
*Central Park West at 79th Street*
*New York, NY 10024-5192*

*Website: https://sites.google.com/view/frank-burbrink-website/
<https://sites.google.com/view/frank-burbrink-website/>*

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Thu Sep 26 23:13:56 2019
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Thu, 26 Sep 2019 21:13:56 +0000 (UTC)
Subject: [R] 95% bootstrap CIs
In-Reply-To: <6f71fa02-c1c1-190a-dcaa-34c569c29569@sapo.pt>
References: <449979188.15300476.1569267730963.ref@mail.yahoo.com>
 <449979188.15300476.1569267730963@mail.yahoo.com>
 <1439668328.16543550.1569415401776@mail.yahoo.com>
 <6f71fa02-c1c1-190a-dcaa-34c569c29569@sapo.pt>
Message-ID: <265007516.17641942.1569532436220@mail.yahoo.com>

Dear Rui,

Excellent ! Many thanks.








Le mercredi 25 septembre 2019 ? 18:50:09 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

In your reproducible example you forget to define 'data'.
You should also

set.seed(<some_int_number>)


The following works.


data <- data.frame(a, x, z, y_obs)
boot.ci.type <- c("norm","basic", "perc")

mse_gam <- function(data,i) {
? boot.gam <- gam(y_obs~s(x)+s(z)+s(a),data=data[i,])
? mean(boot.gam$residuals^2)
}

bootResults_gam <-boot(data=data, statistic=mse_gam, R=1000)
boot.ci(bootResults_gam, type = boot.ci.type)


mse <- function(data,i) {
? boot.earth <- earth((y_obs~x+z+a),data=data[i,])
? mean(boot.earth$residuals^2)
}

bootResults <- boot(data=data, statistic=mse, R=1000)
boot.ci(bootResults, type = boot.ci.type)



Hope this helps,

Rui Barradas

?s 13:43 de 25/09/19, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> Below the reproducible example. I have tried to write a function that returns the statistic of interest (MSE in my case). I have run boot( ) where the function is included in the statistic argument. I have run boot.ci with the result from boot( ). I guess the error comes from the data : bootResults <- boot(data=?????,statistic=mse, R=1000)
> Many thanks for your help.
> 
> ##################################################
> library(mgcv)
> 
> library(earth)
> 
> library(boot)
> 
>? 
> n<-2000
> 
> x <-runif(n, 0, 5)
> 
> z <- rnorm(n, 2, 3)
> 
> a <- runif(n, 0, 5)
> 
> 
> y_model<- 0.1*x^3 - 0.5 * z^2 - a + 10
> 
> y_obs<-rnorm(n, y_model, 0.1)
> 
> gam_model<- gam(y_obs~s(x)+s(z)+s(a))
> 
> mars_model<-earth(y_obs~x+z+a)
> 
>? 
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
> 
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
> 
>? 
> MSE_GAM
> 
> MSE_MARS
> 
>? 
> 
> mse <- function(data,i) {
> 
> boot.gam <- gam(y_obs~s(x)+s(z)+s(a),data=data[i,])
> 
> return(mean(boot.gam$residuals^2))
> 
> }
> 
> bootResults <-boot(data=data,statistic=mse,R=1000)
> 
>? 
> 
> mse <- function(data,i) {
> 
> boot.earth <- earth((y_obs~x+z+a),data=data[i,])
> 
> return(mean(boot.earth$residuals^2))
> 
> }
> 
> bootResults <-boot(data=data,statistic=mse,R=1000)
> ##################################################
> 
>? 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Le lundi 23 septembre 2019 ? 21:42:56 UTC+2, varin sacha via R-help <r-help at r-project.org> a ?crit :
> 
> 
> 
> 
> 
> Dear R-Experts,
> 
> Here is my reproducible R code to get the Mean squared error of GAM and MARS after I = 50 iterations/replications.
> If I want to get the 95% bootstrap CIs around the MSE of GAM and around the MSE of MARS, how can I complete/modify my R code ?
> 
> Many thanks for your precious help.
> 
> ##################
> 
> library(mgcv)
> library(earth)
> my.experiment <- function() {
> n<-500
> x <-runif(n, 0, 5)
> z <- rnorm(n, 2, 3)
> a <- runif(n, 0, 5)
> y_model <- 0.1*x^3 - 0.5*z^2 - a + x*z + x*a + 3*x*a*z + 10
> y_obs <- y_model +c( rnorm(n*0.97, 0, 0.1), rnorm(n*0.03, 0, 0.5) )
> gam_model<- gam(y_obs~s(x)+s(z)+s(a))
> mars_model<-earth(y_obs~x+z+a)
> MSE_GAM<-mean((gam_model$fitted.values - y_model)^2)
> MSE_MARS<-mean((mars_model$fitted.values - y_model)^2)
> return( c(MSE_GAM, MSE_MARS) )
> }
> my.data = t(replicate( 50, my.experiment() ))
> colnames(my.data) <- c("MSE_GAM", "MSE_MARS")
> summary(my.data)
> 
> ##################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 27 00:27:49 2019
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 26 Sep 2019 15:27:49 -0700 (PDT)
Subject: [R] Plot two values on same axes
Message-ID: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>

I want to plot maximum and minimum water temperatures on the same axes and
thought I had the correct syntax:

watertemp <- read.table("../../data/hydro/water-temp.dat", header = TRUE, sep =",")
watertemp$sampdate <- as.Date(as.character(watertemp$sampdate))
watertempsum <- summary(watertemp)
print(watertempsum)
maxwatemp <- xyplot(maxtemp ~ sampdate, data=watertemp, col="red", type="h", main="USGS Foss Gauge Water Temperatures, 1974-1981", ylab="Temperature (C)", xlab="Date", scales=list(tck=c(1,0)))
minwatemp <- xyplot(mintemp ~ sampdate, data=watertemp, col="blue", type="h")
plot(maxwatemp)
par(new=TRUE)
plot(minwatemp)

However, R plots only minwatemp and displays this:
Warning message:
In par(new = TRUE) : calling par(new=TRUE) with no plot

Despite my searching for the reason I don't see what syntax error I made.
The two questions I ask of you:

1. Where have I gone wrong in this script?

2. With 2,492 daily observations in the source file (including 242 NAs for
maxtemp and 243 NAs for mintemp), what would be a more appropriate plot to
show both sets of data?

Thanks in advance,

Rich


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 27 01:08:58 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 27 Sep 2019 07:08:58 +0800
Subject: [R] Plot two values on same axes
In-Reply-To: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>
Message-ID: <DBCA087A-935E-4424-AE08-79A1F04B4B41@comcast.net>

Instead of trying to mix lattice and base functions, you might try using the formula:

maxtemp+mintemp ~ sampdate

And then: col= c(?red?, ?blue?)

Sent from my iPhone, so make sure those quotes are ordinary double quotes. 

? 
David


> On Sep 27, 2019, at 6:27 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> I want to plot maximum and minimum water temperatures on the same axes and
> thought I had the correct syntax:
> 
> watertemp <- read.table("../../data/hydro/water-temp.dat", header = TRUE, sep =",")
> watertemp$sampdate <- as.Date(as.character(watertemp$sampdate))
> watertempsum <- summary(watertemp)
> print(watertempsum)
> maxwatemp <- xyplot(maxtemp ~ sampdate, data=watertemp, col="red", type="h", main="USGS Foss Gauge Water Temperatures, 1974-1981", ylab="Temperature (C)", xlab="Date", scales=list(tck=c(1,0)))
> minwatemp <- xyplot(mintemp ~ sampdate, data=watertemp, col="blue", type="h")
> plot(maxwatemp)
> par(new=TRUE)
> plot(minwatemp)
> 
> However, R plots only minwatemp and displays this:
> Warning message:
> In par(new = TRUE) : calling par(new=TRUE) with no plot
> 
> Despite my searching for the reason I don't see what syntax error I made.
> The two questions I ask of you:
> 
> 1. Where have I gone wrong in this script?
> 
> 2. With 2,492 daily observations in the source file (including 242 NAs for
> maxtemp and 243 NAs for mintemp), what would be a more appropriate plot to
> show both sets of data?
> 
> Thanks in advance,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep 27 01:12:18 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 27 Sep 2019 11:12:18 +1200
Subject: [R] Plot two values on same axes
In-Reply-To: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>
Message-ID: <19d360dc-40e9-6dbc-1ce0-72aacea6f761@auckland.ac.nz>


On 27/09/19 10:27 AM, Rich Shepard wrote:

> I want to plot maximum and minimum water temperatures on the same axes and
> thought I had the correct syntax:
> 
> watertemp <- read.table("../../data/hydro/water-temp.dat", header = 
> TRUE, sep =",")
> watertemp$sampdate <- as.Date(as.character(watertemp$sampdate))
> watertempsum <- summary(watertemp)
> print(watertempsum)
> maxwatemp <- xyplot(maxtemp ~ sampdate, data=watertemp, col="red", 
> type="h", main="USGS Foss Gauge Water Temperatures, 1974-1981", 
> ylab="Temperature (C)", xlab="Date", scales=list(tck=c(1,0)))
> minwatemp <- xyplot(mintemp ~ sampdate, data=watertemp, col="blue", 
> type="h")
> plot(maxwatemp)
> par(new=TRUE)
> plot(minwatemp)
> 
> However, R plots only minwatemp and displays this:
> Warning message:
> In par(new = TRUE) : calling par(new=TRUE) with no plot
> 
> Despite my searching for the reason I don't see what syntax error I made.
> The two questions I ask of you:
> 
> 1. Where have I gone wrong in this script?
> 
> 2. With 2,492 daily observations in the source file (including 242 NAs for
> maxtemp and 243 NAs for mintemp), what would be a more appropriate plot to
> show both sets of data?

You are using xyplot() from the lattice package (which you did not 
mention).  Your par(new=TRUE) syntax would probably work with base R 
graphics (although it would be suboptimal; one would normally use 
points() to add a second graph on the same figure).  I would hazard that 
it won't work at all with lattice graphics.

Moreover you seem to be trying to mix lattice graphics and base R 
graphics in a higgledy-piggledy fashion:  first you call xyplot() and 
then you call plot().

To do what you want with lattice graphics I think you need to learn 
about and apply *panels* --- in particular panel.points().  Using panels 
appropriately is a bit tricky, I find, and requires some study.

You may better off using base R graphics, unless there are 
considerations which demand the use of lattice.  Something like this, maybe:

plot(maxtemp ~ sampdate, data=watertemp, type="h", col="red",
                          <annotation arguments>)
points(maxtemp ~ sampdate, data=watertemp, type="h",col="blue")

(Not tested since your example is not reproducible.)

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Sep 27 01:18:57 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 27 Sep 2019 11:18:57 +1200
Subject: [R] [FORGED] Re:  Plot two values on same axes
In-Reply-To: <DBCA087A-935E-4424-AE08-79A1F04B4B41@comcast.net>
References: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>
 <DBCA087A-935E-4424-AE08-79A1F04B4B41@comcast.net>
Message-ID: <7d98934f-65f7-43d0-85fe-965a2b6036bc@auckland.ac.nz>


On 27/09/19 11:08 AM, David Winsemius wrote:

> Instead of trying to mix lattice and base functions, you might try using the formula:
> 
> maxtemp+mintemp ~ sampdate
> 
> And then: col= c(?red?, ?blue?)
> 
> Sent from my iPhone, so make sure those quotes are ordinary double quotes.

Ah-ha!  I've learned something about lattice that I had not previously 
taken on board.  Thanks David!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From c@r|o@ @end|ng |rom tree@com@@r  Wed Sep 25 20:51:59 2019
From: c@r|o@ @end|ng |rom tree@com@@r (Carlos Weiss)
Date: Wed, 25 Sep 2019 15:51:59 -0300
Subject: [R] Error: package 'stats' could not be loaded
Message-ID: <CA+Te=cp3CZ1kxbOFM6uMNjy3FbcMKz98kqfqJ-k72XHDhSe4Gw@mail.gmail.com>

I'm getting an error when using R for the first time. It's a web service
written in C#, .NET 4.5, IIS 10.0 running on Windows Server 2019. The file
called "stats.dll" (which was a result of installing R 3.1.1) is within the
scope of the path variables for all users.

Could anyone tell me if this is a configuration error, or it has to do with
the Windows Server version (it runs in Windows Server 2012 with the same
configuration (I think!)), without looking further into the C# code?

Thanks



Server Error in '/' Application.
------------------------------

*Error: package 'stats' could not be loaded**Description: *An unhandled
exception occurred during the execution of the current web request. Please
review the stack trace for more information about the error and where it
originated in the code.

*Exception Details: *RDotNet.EvaluationException: Error: package 'stats'
could not be loaded


*Source Error:*

An unhandled exception was generated during the execution of the current
web request. Information regarding the origin and location of the exception
can be identified using the exception stack trace below.
*Stack Trace:*

Path variables include the R lib folder.

	[[alternative HTML version deleted]]


From m@rc_grt @end|ng |rom y@hoo@|r  Fri Sep 27 10:08:07 2019
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Fri, 27 Sep 2019 10:08:07 +0200
Subject: [R] Raster package crash with segmentation fault
Message-ID: <3819c46a-fbbc-6f33-13e9-f9cbffa8777c@yahoo.fr>

Dear members,

When I load raster 3.0-7 package installed or from source or from binary 
in r 3.6.1 (macosX 10.14.6), I get a segmentation fault crash:

(see below)

As someone the same problem and a solution ? Thanks

(I have posted this question in R-Sig_GEO list without answer still)

 > library("raster")
Le chargement a n??cessit?? le package : sp

??*** caught segfault ***
address 0x31, cause 'memory not mapped'

Traceback:
??1: Module(module, mustStart = TRUE, where = env)
??2: doTryCatch(return(expr), name, parentenv, handler)
??3: tryCatchOne(expr, names, parentenv, handlers[[1L]])
??4: tryCatchList(expr, classes, parentenv, handlers)
??5: tryCatch(Module(module, mustStart = TRUE, where = env), error = 
function(e) e)
??6: loadModule(module = "spmod", what = TRUE, env = ns, loadNow = TRUE)
??7: (function (ns) loadModule(module = "spmod", what = TRUE, env = ns, 
loadNow = TRUE))(<environment>)
??8: doTryCatch(return(expr), name, parentenv, handler)
??9: tryCatchOne(expr, names, parentenv, handlers[[1L]])
10: tryCatchList(expr, classes, parentenv, handlers)
11: tryCatch((function (ns) loadModule(module = "spmod", what = TRUE, 
env = ns, loadNow = TRUE))(<environment>),???????? error = function(e) e)
12: eval(substitute(tryCatch(FUN(WHERE), error = function(e) e),???????? 
list(FUN = f, WHERE = where)), where)
13: eval(substitute(tryCatch(FUN(WHERE), error = function(e) e),???????? 
list(FUN = f, WHERE = where)), where)
14: .doLoadActions(where, attach)
15: methods::cacheMetaData(ns, TRUE, ns)
16: loadNamespace(package, lib.loc)
17: doTryCatch(return(expr), name, parentenv, handler)
18: tryCatchOne(expr, names, parentenv, handlers[[1L]])
19: tryCatchList(expr, classes, parentenv, handlers)
20: tryCatch({?????? attr(package, "LibPath") <- which.lib.loc ns <- 
loadNamespace(package, lib.loc)?????? env <- attachNamespace(ns, pos = 
pos, deps, exclude, include.only)}, error = function(e) {?????? P <- if 
(!is.null(cc <- conditionCall(e)))???????????????? paste(" in", 
deparse(cc)[1L])?????? else ""?????? msg <- gettextf("package or 
namespace load failed for %s%s:\n %s",???????????????? sQuote(package), 
P, conditionMessage(e)) if (logical.return)???????????????? 
message(paste("Error:", msg), domain = NA)?????? else stop(msg, call. = 
FALSE, domain = NA)})
21: library("raster")

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 27 12:39:38 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 27 Sep 2019 18:39:38 +0800
Subject: [R] Error: package 'stats' could not be loaded
In-Reply-To: <CA+Te=cp3CZ1kxbOFM6uMNjy3FbcMKz98kqfqJ-k72XHDhSe4Gw@mail.gmail.com>
References: <CA+Te=cp3CZ1kxbOFM6uMNjy3FbcMKz98kqfqJ-k72XHDhSe4Gw@mail.gmail.com>
Message-ID: <9A10FA3B-1FF7-48D9-B7B1-279B9FD232DC@comcast.net>

I?m having difficulty understanding why you installed R v 3.1.1. That?s five major versions ago. 

? 
David

Sent from my iPhone

> On Sep 26, 2019, at 2:51 AM, Carlos Weiss <carlos at tree.com.ar> wrote:
> 
> I'm getting an error when using R for the first time. It's a web service
> written in C#, .NET 4.5, IIS 10.0 running on Windows Server 2019. The file
> called "stats.dll" (which was a result of installing R 3.1.1) is within the
> scope of the path variables for all users.
> 
> Could anyone tell me if this is a configuration error, or it has to do with
> the Windows Server version (it runs in Windows Server 2012 with the same
> configuration (I think!)), without looking further into the C# code?
> 
> Thanks
> 
> 
> 
> Server Error in '/' Application.
> ------------------------------
> 
> *Error: package 'stats' could not be loaded**Description: *An unhandled
> exception occurred during the execution of the current web request. Please
> review the stack trace for more information about the error and where it
> originated in the code.
> 
> *Exception Details: *RDotNet.EvaluationException: Error: package 'stats'
> could not be loaded
> 
> 
> *Source Error:*
> 
> An unhandled exception was generated during the execution of the current
> web request. Information regarding the origin and location of the exception
> can be identified using the exception stack trace below.
> *Stack Trace:*
> 
> Path variables include the R lib folder.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Sep 27 12:55:45 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 27 Sep 2019 18:55:45 +0800
Subject: [R] Real Basic Question
In-Reply-To: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>
References: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>
Message-ID: <B9524615-C094-4D7D-88DB-BC3A7DC26CAC@comcast.net>



Sent from my iPhone

> On Sep 27, 2019, at 12:55 AM, Phillip Heinrich <herd_dog at cox.net> wrote:
> 
> Just when I think I?m starting to get the hang of R I run into something that sends me back to Go without collecting $200.
> 
> The working directory seems to be correct when I load an .rda file but it is not there and it is not in the Global Environment in the upper right hand window in RStudio.
> getwd()
> [1] "C:/Users/Owner/Documents/Baseball/RetroSheetDocumentation"
>> load("~/Baseball/RetroSheetDocumentation/ari18.test2.rda")

-/Baseball is NOT the same as your wd. 

Try putting in the ?Documents?


? 
David

>> ari18.test2
> Error: object 'ari18.test2' not found
>> ls()
> [1] "ari18.test3"       "array1"            "array2"            "BaseballArticles"  "BaseballArticles2"
> [6] "BaseballArticles3" "BBCorpus"          "BBtdm"             "firstfunction"     "folder"           
> [11] "h"                 "matrix"            "matrix2"           "matrix3"           "n"                
> [16] "seq"               "testvector"        "u"                 "vec"               "x"                
> [21] "y"                 "yourname"         
> 
> 
>> 
> 
> 
> 
> Somehow ari18.test3 loaded but ari18.test2 will not.
> 
> What am I missing here?
> 
> Thanks.
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep 27 13:45:42 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 27 Sep 2019 12:45:42 +0100
Subject: [R] Real Basic Question
In-Reply-To: <58d97aab-4b3a-5342-743e-0afcaa329ddf@gmail.com>
References: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>
 <58d97aab-4b3a-5342-743e-0afcaa329ddf@gmail.com>
Message-ID: <04ef432f-7aae-3274-a85e-ec897271418e@sapo.pt>

Hello,

1. Try path.expand().

flname <- path.expand("~/Baseball/RetroSheetDocumentation/ari18.test2.rda")

2. To load in the global environment

load(flname, envir = .GlobalEnv)

3. But read the docs. From ?load:

load(<file>) replaces all existing objects with the same names in the 
current environment (typically your workspace, .GlobalEnv) and hence 
potentially overwrites important data. It is considerably safer to use 
envir = to load into a different environment, or to attach(file) which 
load()s into a new entry in the search path.


So Duncan's suggestion to create a new environment and load the data 
there might be sound advice. Check if your data set exists in the 
.GlobalEnv first, then load() it.

ls(pattern = "^ari", envir = .GlobalEnv)


Hope this helps,

Rui Barradas

?s 18:06 de 26/09/19, Duncan Murdoch escreveu:
> On 26/09/2019 12:55 p.m., Phillip Heinrich wrote:
>> Just when I think I?m starting to get the hang of R I run into 
>> something that sends me back to Go without collecting $200.
>>
>> The working directory seems to be correct when I load an .rda file but 
>> it is not there and it is not in the Global Environment in the upper 
>> right hand window in RStudio.
>> getwd()
>> [1] "C:/Users/Owner/Documents/Baseball/RetroSheetDocumentation"
>>> load("~/Baseball/RetroSheetDocumentation/ari18.test2.rda")
>>> ari18.test2
>> Error: object 'ari18.test2' not found
>>> ls()
>> ? [1] "ari18.test3"?????? "array1"??????????? "array2"            
>> "BaseballArticles"? "BaseballArticles2"
>> ? [6] "BaseballArticles3" "BBCorpus"????????? "BBtdm"             
>> "firstfunction"???? "folder"
>> [11] "h"???????????????? "matrix"??????????? "matrix2"           
>> "matrix3"?????????? "n"
>> [16] "seq"?????????????? "testvector"??????? "u"                 
>> "vec"?????????????? "x"
>> [21] "y"???????????????? "yourname"
>> ???????????? >
>>
>>
>> Somehow ari18.test3 loaded but ari18.test2 will not.
>>
>> What am I missing here?
> 
> The filename (~/Baseball/RetroSheetDocumentation/ari18.test2.rda) has no 
> connection to the variables that would be created when you load it. 
> Finding out what's in that file isn't obvious:? you need to load it into 
> an empty location (either your global environment in a clean new 
> session, or one created specially for the purpose).? E.g.
> 
>  ?env <- new.env()
>  ?load("~/Baseball/RetroSheetDocumentation/ari18.test2.rda", envir = env)
>  ?ls(envir = env)
> 
> This will load the object(s) from that file into the environment env. 
> You could copy them from there to somewhere else, use them from there, 
> or just load again into the global environment, now you know what you're 
> getting.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 27 14:29:51 2019
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Sep 2019 05:29:51 -0700 (PDT)
Subject: [R] Plot two values on same axes
In-Reply-To: <DBCA087A-935E-4424-AE08-79A1F04B4B41@comcast.net>
References: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>
 <DBCA087A-935E-4424-AE08-79A1F04B4B41@comcast.net>
Message-ID: <alpine.LNX.2.20.1909270527310.21294@salmo.appl-ecosys.com>

On Fri, 27 Sep 2019, David Winsemius wrote:

> Instead of trying to mix lattice and base functions, you might try using
> the formula:
>
> maxtemp+mintemp ~ sampdate
>
> And then: col= c(?red?, ?blue?)

David,

I certainly will. I've not needed R for projects for many months and when I
looked through previous scripts and the lattice book I failed to find what I
needed. So what I tried was a solution to a different but similar issue on
stackexchange.

Many thanks,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep 27 14:32:53 2019
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Sep 2019 05:32:53 -0700 (PDT)
Subject: [R] Plot two values on same axes
In-Reply-To: <19d360dc-40e9-6dbc-1ce0-72aacea6f761@auckland.ac.nz>
References: <alpine.LNX.2.20.1909261520310.25913@salmo.appl-ecosys.com>
 <19d360dc-40e9-6dbc-1ce0-72aacea6f761@auckland.ac.nz>
Message-ID: <alpine.LNX.2.20.1909270531450.21294@salmo.appl-ecosys.com>

On Fri, 27 Sep 2019, Rolf Turner wrote:

> You may better off using base R graphics, unless there are considerations
> which demand the use of lattice. Something like this, maybe:
>
> plot(maxtemp ~ sampdate, data=watertemp, type="h", col="red",
>                         <annotation arguments>)
> points(maxtemp ~ sampdate, data=watertemp, type="h",col="blue")

Rolf,

Thanks very much.

Regards,

Rich


From pd@|gd @end|ng |rom gm@||@com  Fri Sep 27 15:01:09 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 27 Sep 2019 15:01:09 +0200
Subject: [R] Real Basic Question
In-Reply-To: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>
References: <2FEADD3B2F3A4A7092EA1922F6529ED3@OWNERPC>
Message-ID: <B8568AE6-A9E5-4345-8240-3C47F496CE83@gmail.com>



> On 26 Sep 2019, at 18:55 , Phillip Heinrich <herd_dog at cox.net> wrote:
> 
> Just when I think I?m starting to get the hang of R I run into something that sends me back to Go without collecting $200.
> 
> The working directory seems to be correct when I load an .rda file but it is not there and it is not in the Global Environment in the upper right hand window in RStudio.
> getwd()
> [1] "C:/Users/Owner/Documents/Baseball/RetroSheetDocumentation"
>> load("~/Baseball/RetroSheetDocumentation/ari18.test2.rda")
>> ari18.test2
> Error: object 'ari18.test2' not found
>> ls()
> [1] "ari18.test3"       "array1"            "array2"            "BaseballArticles"  "BaseballArticles2"
> [6] "BaseballArticles3" "BBCorpus"          "BBtdm"             "firstfunction"     "folder"           
> [11] "h"                 "matrix"            "matrix2"           "matrix3"           "n"                
> [16] "seq"               "testvector"        "u"                 "vec"               "x"                
> [21] "y"                 "yourname"         
> 
> 
>> 
> 
> 
> 
> Somehow ari18.test3 loaded but ari18.test2 will not.
> 
> What am I missing here?


(1) getwd() is irrelevant if you load() a fully qualified filename
(2) if the file is actually in the working dir, load("ari18.test2.rda") should do
(3) there is no guarantee that an rda file contains an object of a name related to the file name 
(4) To see what is inside a .rda, try e <- new.env(); load("my.rda", e); ls(e)

-pd

> 
> Thanks.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep 27 18:03:43 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 27 Sep 2019 18:03:43 +0200
Subject: [R] The "--slave" option ==> will become "--no-echo"
In-Reply-To: <23944.54092.19365.74438@stat.math.ethz.ch>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
 <23944.54092.19365.74438@stat.math.ethz.ch>
Message-ID: <23950.13023.376850.661671@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Mon, 23 Sep 2019 16:14:36 +0200 writes:

>>>>> Richard O'Keefe 
>>>>>     on Sat, 21 Sep 2019 09:39:18 +1200 writes:

    >> Ah, *now* we're getting somewhere.  There is something
    >> that *can* be done that's genuinely helpful.
    >>> From the R(1) manual page:
    >> -q, --quiet Don't print startup message

    >> --silent Same as --quiet

    >> --slave Make R run as quietly as possible

    >> It might have been better to use --nobanner instead of
    >> --quiet.  So perhaps

    >> -q, --quiet Don't print the startup message.  This is
    >> the only output that is suppressed.

    >> --silent Same as --quiet.  Suppress the startup
    >> message only.

    >> --slave Make R run as quietly as possible.  This is
    >> for use when running R as a subordinate process.  See
    >> "Introduction to Sub-Processes in R"
    >> https://cran.r-project.org/web/packages/subprocess/vignettes/intro.html
    >> for an example.

    > Thank you, Stephen and Richard.

    > I think we (the R Core Team) *can* make the description a bit
    > more verbose. However, as practically all "--<foo>" descriptions
    > are fitting in one short line, (and as the 'subprocess' package is just an
    > extension pkg, and may disappear (and more reasons)) I'd like to
    > be less verbose than your proposal.

    > What about

    > -q, --quiet		Don't print startup message

    > --silent		Same as --quiet

    > --slave		Make R run as quietly as possible.  For use when
    > runnning R as sub(ordinate) process. 

    > If you look more closely, you'll notice that --slave is not much
    > quieter than --quiet, the only (?) difference being that the
    > input is not copied and (only "mostly") the R prompt is also not printed.

    > And from my experiments (in Linux (Fedora 30)), one might even
    > notice that in some cases --slave prints the R prompt (to stderr?)
    > which one might consider bogous (I'm not: not wanting to spend
    > time fixing this platform-independently) :

    > --slave :
    > ------------------------

    > MM at lynne$ echo '(i <- 1:3)
    > i*10' | R-3.6.1 --slave --vanilla
    >> [1] 1 2 3
    > [1] 10 20 30
    > MM at lynne$ f=/tmp/Rslave.out$$; echo '(i <- 1:3)
    > i*10' | R-3.6.1 --slave --vanilla | tee $f
    >> [1] 1 2 3
    > [1] 10 20 30
    > MM at lynne$ cat $f
    > [1] 1 2 3
    > [1] 10 20 30

    > --quiet :
    > ------------------------

    > MM at lynne$ f=/tmp/Rquiet.out$$; echo '(i <- 1:3)
    > i*10' | R-3.6.1 --quiet --vanilla | tee $f
    >> (i <- 1:3)
    > [1] 1 2 3
    >> i*10
    > [1] 10 20 30
    >> 
    > MM at lynne$ cat $f
    >> (i <- 1:3)
    > [1] 1 2 3
    >> i*10
    > [1] 10 20 30
    >> 
    > MM at lynne$ 

    > ------------------------

    > But there's a bit more to it: In my examples above, both --quiet
    > and --slave where used together with --vanilla.  In general
    > --slave *also* never saves, i.e., uses the equivalent of
    > q('no'), where as --quiet does [ask or ...].

    > Last but not least, from very simply reading R's source code on
    > this, it becomes blatant that you can use  '-s'  instead of '--slave',
    > but we (R Core) have probably not documented that on purpose (so
    > we could reserve it for something more important, and redefine
    > the simple use of '-s' some time in the future ?)

    > So, all those who want to restrict their language could use '-s'
    > for now.  In addition, we could add  >> one <<  other alias to
    > --slave, say --subprocess (or --quieter ? or ???)
    > and one could make that the preferred use some time in the future.

    > Well, these were another two hours of time *not* spent improving
    > R technically, but spent reading e-mails, source code, and considering.
    > Maybe well spent, maybe not ...

    > Martin Maechler
    > ETH Zurich and R Core Team

With in the   R Core Team    we have considered the issue.

As a consequence, I have committed a few minutes ago code changes
that replace '--slave' by '--no-echo' .
[This will be in R-devel versions from svn rev 77229 and of
 course in the "big step" release around April 2020].
 
Among other considerations, we found that  '--no-echo' was
really much more self-explaining, as indeed the command line
option turns off the echo'ing of the R code that is executed,
and on the C level is indeed very much related to R level

    options(echo = "no")

For back compatibility reasons, the old command line option will
continue to work so the many shell and other scripts that use
it, will not stop working.


Best regards,
Martin Maechler
ETH Zurich and R Core Team


From djb|rke @end|ng |rom berke|ey@edu  Fri Sep 27 19:05:09 2019
From: djb|rke @end|ng |rom berke|ey@edu (David J. Birke)
Date: Fri, 27 Sep 2019 10:05:09 -0700
Subject: [R] stats::lm has inconsistent output when adding constant to
 dependent variable
Message-ID: <b4546e64-4105-fced-25f3-6103cfd3d7ee@berkeley.edu>

Dear R community,

I just stumbled upon the following behavior in R version 3.6.0:

set.seed(42)
y <- rep(0, 30)
x <- rbinom(30, 1, prob = 0.91)
# The following will not show any t-statistic or p-value
summary(lm(y~x))
#  The following will show t-statistic and p-value
summary(lm(1+y~x))

My expected output is that the first case should report t-statistic and 
p-value. My intuition might be tricking me, but I think that a constant 
shift of the data should be fully absorbed by the constant and not 
affect inference about the slope.

Is this a bug or is there a reason why there should be a discrepancy 
between the two outputs?

Best,
David


From m@rk|eed@2 @end|ng |rom gm@||@com  Fri Sep 27 20:35:20 2019
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Fri, 27 Sep 2019 14:35:20 -0400
Subject: [R] stats::lm has inconsistent output when adding constant to
 dependent variable
In-Reply-To: <b4546e64-4105-fced-25f3-6103cfd3d7ee@berkeley.edu>
References: <b4546e64-4105-fced-25f3-6103cfd3d7ee@berkeley.edu>
Message-ID: <CAHz+bWZwwkfOdrFVBUEaJiSAfELoGSTLczo_cFNCiiwN=3Z3tA@mail.gmail.com>

Hi: In your example, you made the response zero in every case which
is going to cause problems.  In glm's, I think they call it the donsker
effect. I'm not sure what it's called
in OLS. probably a lack of identifiability. Note that you probably
shouldn't be using zeros
and 1's as the response in a regression anyway.

If you change the response to below, you get what  you'd expect.

y <- c(rep(0, 15), rep(1,15))

On Fri, Sep 27, 2019 at 1:48 PM David J. Birke <djbirke at berkeley.edu> wrote:

> Dear R community,
>
> I just stumbled upon the following behavior in R version 3.6.0:
>
> set.seed(42)
> y <- rep(0, 30)
> x <- rbinom(30, 1, prob = 0.91)
> # The following will not show any t-statistic or p-value
> summary(lm(y~x))
> #  The following will show t-statistic and p-value
> summary(lm(1+y~x))
>
> My expected output is that the first case should report t-statistic and
> p-value. My intuition might be tricking me, but I think that a constant
> shift of the data should be fully absorbed by the constant and not
> affect inference about the slope.
>
> Is this a bug or is there a reason why there should be a discrepancy
> between the two outputs?
>
> Best,
> David
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rk|eed@2 @end|ng |rom gm@||@com  Fri Sep 27 20:43:28 2019
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Fri, 27 Sep 2019 14:43:28 -0400
Subject: [R] stats::lm has inconsistent output when adding constant to
 dependent variable
In-Reply-To: <CAHz+bWZwwkfOdrFVBUEaJiSAfELoGSTLczo_cFNCiiwN=3Z3tA@mail.gmail.com>
References: <b4546e64-4105-fced-25f3-6103cfd3d7ee@berkeley.edu>
 <CAHz+bWZwwkfOdrFVBUEaJiSAfELoGSTLczo_cFNCiiwN=3Z3tA@mail.gmail.com>
Message-ID: <CAHz+bWaXyah=f-6YKeQtLGt4PUtPoiF1Z7y_YAUbBGAV4nknZg@mail.gmail.com>

correction to my previous answer. I looked around and I don't think it's
called the donsker effect. It seems to
jbe referred to as just  a case of "perfect separability.". if you google
for" perfect separation in glms", you'll get a
lot of information.






On Fri, Sep 27, 2019 at 2:35 PM Mark Leeds <markleeds2 at gmail.com> wrote:

> Hi: In your example, you made the response zero in every case which
> is going to cause problems.  In glm's, I think they call it the donsker
> effect. I'm not sure what it's called
> in OLS. probably a lack of identifiability. Note that you probably
> shouldn't be using zeros
> and 1's as the response in a regression anyway.
>
> If you change the response to below, you get what  you'd expect.
>
> y <- c(rep(0, 15), rep(1,15))
>
> On Fri, Sep 27, 2019 at 1:48 PM David J. Birke <djbirke at berkeley.edu>
> wrote:
>
>> Dear R community,
>>
>> I just stumbled upon the following behavior in R version 3.6.0:
>>
>> set.seed(42)
>> y <- rep(0, 30)
>> x <- rbinom(30, 1, prob = 0.91)
>> # The following will not show any t-statistic or p-value
>> summary(lm(y~x))
>> #  The following will show t-statistic and p-value
>> summary(lm(1+y~x))
>>
>> My expected output is that the first case should report t-statistic and
>> p-value. My intuition might be tricking me, but I think that a constant
>> shift of the data should be fully absorbed by the constant and not
>> affect inference about the slope.
>>
>> Is this a bug or is there a reason why there should be a discrepancy
>> between the two outputs?
>>
>> Best,
>> David
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Sep 27 21:01:13 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 27 Sep 2019 20:01:13 +0100
Subject: [R] stats::lm has inconsistent output when adding constant to
 dependent variable
In-Reply-To: <b4546e64-4105-fced-25f3-6103cfd3d7ee@berkeley.edu>
References: <b4546e64-4105-fced-25f3-6103cfd3d7ee@berkeley.edu>
Message-ID: <5b4fcb05-5669-fdd4-618a-0f6b2a9da573@sapo.pt>

Hello,

Maybe FAQ 7.31?

Check the residuals, they are all "zero" in both cases:

fit0 <- lm(y~x)
fit1 <- lm(1+y~x)

# residuals
table(resid(fit0))
#
# 0
#30

table(resid(fit1))
#
#-5.21223595241838e-16 -4.93038065763132e-31  3.12734157145103e-15
#                    6                    23                     1


Hope this helps,

Rui Barradas

?s 18:05 de 27/09/19, David J. Birke escreveu:
> Dear R community,
> 
> I just stumbled upon the following behavior in R version 3.6.0:
> 
> set.seed(42)
> y <- rep(0, 30)
> x <- rbinom(30, 1, prob = 0.91)
> # The following will not show any t-statistic or p-value
> summary(lm(y~x))
> #? The following will show t-statistic and p-value
> summary(lm(1+y~x))
> 
> My expected output is that the first case should report t-statistic and 
> p-value. My intuition might be tricking me, but I think that a constant 
> shift of the data should be fully absorbed by the constant and not 
> affect inference about the slope.
> 
> Is this a bug or is there a reason why there should be a discrepancy 
> between the two outputs?
> 
> Best,
> David
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep 27 23:16:29 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 28 Sep 2019 07:16:29 +1000
Subject: [R] The "--slave" option ==> will become "--no-echo"
In-Reply-To: <23950.13023.376850.661671@stat.math.ethz.ch>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
 <23944.54092.19365.74438@stat.math.ethz.ch>
 <23950.13023.376850.661671@stat.math.ethz.ch>
Message-ID: <CA+8X3fX1+73gdZa5cC0di8G5-UFouK7d-nsoq=mR1snnBqp-LQ@mail.gmail.com>

On Sat, Sep 28, 2019 at 2:04 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> For back compatibility reasons, the old command line option will
> continue to work so the many shell and other scripts that use
> it, will not stop working.
>
That's a relief. I was getting worried that we would become:

The knights who cannot say BS.

Jim


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Fri Sep 27 23:36:17 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Fri, 27 Sep 2019 14:36:17 -0700
Subject: [R] The "--slave" option ==> will become "--no-echo"
In-Reply-To: <23950.13023.376850.661671@stat.math.ethz.ch>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
 <23944.54092.19365.74438@stat.math.ethz.ch>
 <23950.13023.376850.661671@stat.math.ethz.ch>
Message-ID: <CAA99HCwbvfUQBruoB6gt4vD48+7EP-XEyWU5rt_ao0ePDzd_5A@mail.gmail.com>

Hi Martin,

'--no-echo'

....or....

'--no_echo'

Obviously you may prefer the first, but I hope you might consider the second.

Best Regards,

W. Michels, Ph.D.


On Fri, Sep 27, 2019 at 9:04 AM Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>
> >>>>> Martin Maechler
> >>>>>     on Mon, 23 Sep 2019 16:14:36 +0200 writes:
>
> >>>>> Richard O'Keefe
> >>>>>     on Sat, 21 Sep 2019 09:39:18 +1200 writes:
>
>     >> Ah, *now* we're getting somewhere.  There is something
>     >> that *can* be done that's genuinely helpful.
>     >>> From the R(1) manual page:
>     >> -q, --quiet Don't print startup message
>
>     >> --silent Same as --quiet
>
>     >> --slave Make R run as quietly as possible
>
>     >> It might have been better to use --nobanner instead of
>     >> --quiet.  So perhaps
>
>     >> -q, --quiet Don't print the startup message.  This is
>     >> the only output that is suppressed.
>
>     >> --silent Same as --quiet.  Suppress the startup
>     >> message only.
>
>     >> --slave Make R run as quietly as possible.  This is
>     >> for use when running R as a subordinate process.  See
>     >> "Introduction to Sub-Processes in R"
>     >> https://cran.r-project.org/web/packages/subprocess/vignettes/intro.html
>     >> for an example.
>
>     > Thank you, Stephen and Richard.
>
>     > I think we (the R Core Team) *can* make the description a bit
>     > more verbose. However, as practically all "--<foo>" descriptions
>     > are fitting in one short line, (and as the 'subprocess' package is just an
>     > extension pkg, and may disappear (and more reasons)) I'd like to
>     > be less verbose than your proposal.
>
>     > What about
>
>     > -q, --quiet               Don't print startup message
>
>     > --silent          Same as --quiet
>
>     > --slave           Make R run as quietly as possible.  For use when
>     > runnning R as sub(ordinate) process.
>
>     > If you look more closely, you'll notice that --slave is not much
>     > quieter than --quiet, the only (?) difference being that the
>     > input is not copied and (only "mostly") the R prompt is also not printed.
>
>     > And from my experiments (in Linux (Fedora 30)), one might even
>     > notice that in some cases --slave prints the R prompt (to stderr?)
>     > which one might consider bogous (I'm not: not wanting to spend
>     > time fixing this platform-independently) :
>
>     > --slave :
>     > ------------------------
>
>     > MM at lynne$ echo '(i <- 1:3)
>     > i*10' | R-3.6.1 --slave --vanilla
>     >> [1] 1 2 3
>     > [1] 10 20 30
>     > MM at lynne$ f=/tmp/Rslave.out$$; echo '(i <- 1:3)
>     > i*10' | R-3.6.1 --slave --vanilla | tee $f
>     >> [1] 1 2 3
>     > [1] 10 20 30
>     > MM at lynne$ cat $f
>     > [1] 1 2 3
>     > [1] 10 20 30
>
>     > --quiet :
>     > ------------------------
>
>     > MM at lynne$ f=/tmp/Rquiet.out$$; echo '(i <- 1:3)
>     > i*10' | R-3.6.1 --quiet --vanilla | tee $f
>     >> (i <- 1:3)
>     > [1] 1 2 3
>     >> i*10
>     > [1] 10 20 30
>     >>
>     > MM at lynne$ cat $f
>     >> (i <- 1:3)
>     > [1] 1 2 3
>     >> i*10
>     > [1] 10 20 30
>     >>
>     > MM at lynne$
>
>     > ------------------------
>
>     > But there's a bit more to it: In my examples above, both --quiet
>     > and --slave where used together with --vanilla.  In general
>     > --slave *also* never saves, i.e., uses the equivalent of
>     > q('no'), where as --quiet does [ask or ...].
>
>     > Last but not least, from very simply reading R's source code on
>     > this, it becomes blatant that you can use  '-s'  instead of '--slave',
>     > but we (R Core) have probably not documented that on purpose (so
>     > we could reserve it for something more important, and redefine
>     > the simple use of '-s' some time in the future ?)
>
>     > So, all those who want to restrict their language could use '-s'
>     > for now.  In addition, we could add  >> one <<  other alias to
>     > --slave, say --subprocess (or --quieter ? or ???)
>     > and one could make that the preferred use some time in the future.
>
>     > Well, these were another two hours of time *not* spent improving
>     > R technically, but spent reading e-mails, source code, and considering.
>     > Maybe well spent, maybe not ...
>
>     > Martin Maechler
>     > ETH Zurich and R Core Team
>
> With in the   R Core Team    we have considered the issue.
>
> As a consequence, I have committed a few minutes ago code changes
> that replace '--slave' by '--no-echo' .
> [This will be in R-devel versions from svn rev 77229 and of
>  course in the "big step" release around April 2020].
>
> Among other considerations, we found that  '--no-echo' was
> really much more self-explaining, as indeed the command line
> option turns off the echo'ing of the R code that is executed,
> and on the C level is indeed very much related to R level
>
>     options(echo = "no")
>
> For back compatibility reasons, the old command line option will
> continue to work so the many shell and other scripts that use
> it, will not stop working.
>
>
> Best regards,
> Martin Maechler
> ETH Zurich and R Core Team
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 27 23:41:59 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 27 Sep 2019 17:41:59 -0400
Subject: [R] The "--slave" option ==> will become "--no-echo"
In-Reply-To: <CAA99HCwbvfUQBruoB6gt4vD48+7EP-XEyWU5rt_ao0ePDzd_5A@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
 <23944.54092.19365.74438@stat.math.ethz.ch>
 <23950.13023.376850.661671@stat.math.ethz.ch>
 <CAA99HCwbvfUQBruoB6gt4vD48+7EP-XEyWU5rt_ao0ePDzd_5A@mail.gmail.com>
Message-ID: <44f35c7a-f47a-5812-b561-e45744f66a2a@gmail.com>

On 27/09/2019 5:36 p.m., William Michels via R-help wrote:
> Hi Martin,
> 
> '--no-echo'
> 
> ....or....
> 
> '--no_echo'
> 
> Obviously you may prefer the first, but I hope you might consider the second.

Are you serious?  That's a terrible suggestion.  Run "R --help" and 
you'll see *no* options with underscores, and a dozen with embedded hyphens.

Duncan Murdoch

> 
> Best Regards,
> 
> W. Michels, Ph.D.
> 
> 
> On Fri, Sep 27, 2019 at 9:04 AM Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>
>>>>>>> Martin Maechler
>>>>>>>      on Mon, 23 Sep 2019 16:14:36 +0200 writes:
>>
>>>>>>> Richard O'Keefe
>>>>>>>      on Sat, 21 Sep 2019 09:39:18 +1200 writes:
>>
>>      >> Ah, *now* we're getting somewhere.  There is something
>>      >> that *can* be done that's genuinely helpful.
>>      >>> From the R(1) manual page:
>>      >> -q, --quiet Don't print startup message
>>
>>      >> --silent Same as --quiet
>>
>>      >> --slave Make R run as quietly as possible
>>
>>      >> It might have been better to use --nobanner instead of
>>      >> --quiet.  So perhaps
>>
>>      >> -q, --quiet Don't print the startup message.  This is
>>      >> the only output that is suppressed.
>>
>>      >> --silent Same as --quiet.  Suppress the startup
>>      >> message only.
>>
>>      >> --slave Make R run as quietly as possible.  This is
>>      >> for use when running R as a subordinate process.  See
>>      >> "Introduction to Sub-Processes in R"
>>      >> https://cran.r-project.org/web/packages/subprocess/vignettes/intro.html
>>      >> for an example.
>>
>>      > Thank you, Stephen and Richard.
>>
>>      > I think we (the R Core Team) *can* make the description a bit
>>      > more verbose. However, as practically all "--<foo>" descriptions
>>      > are fitting in one short line, (and as the 'subprocess' package is just an
>>      > extension pkg, and may disappear (and more reasons)) I'd like to
>>      > be less verbose than your proposal.
>>
>>      > What about
>>
>>      > -q, --quiet               Don't print startup message
>>
>>      > --silent          Same as --quiet
>>
>>      > --slave           Make R run as quietly as possible.  For use when
>>      > runnning R as sub(ordinate) process.
>>
>>      > If you look more closely, you'll notice that --slave is not much
>>      > quieter than --quiet, the only (?) difference being that the
>>      > input is not copied and (only "mostly") the R prompt is also not printed.
>>
>>      > And from my experiments (in Linux (Fedora 30)), one might even
>>      > notice that in some cases --slave prints the R prompt (to stderr?)
>>      > which one might consider bogous (I'm not: not wanting to spend
>>      > time fixing this platform-independently) :
>>
>>      > --slave :
>>      > ------------------------
>>
>>      > MM at lynne$ echo '(i <- 1:3)
>>      > i*10' | R-3.6.1 --slave --vanilla
>>      >> [1] 1 2 3
>>      > [1] 10 20 30
>>      > MM at lynne$ f=/tmp/Rslave.out$$; echo '(i <- 1:3)
>>      > i*10' | R-3.6.1 --slave --vanilla | tee $f
>>      >> [1] 1 2 3
>>      > [1] 10 20 30
>>      > MM at lynne$ cat $f
>>      > [1] 1 2 3
>>      > [1] 10 20 30
>>
>>      > --quiet :
>>      > ------------------------
>>
>>      > MM at lynne$ f=/tmp/Rquiet.out$$; echo '(i <- 1:3)
>>      > i*10' | R-3.6.1 --quiet --vanilla | tee $f
>>      >> (i <- 1:3)
>>      > [1] 1 2 3
>>      >> i*10
>>      > [1] 10 20 30
>>      >>
>>      > MM at lynne$ cat $f
>>      >> (i <- 1:3)
>>      > [1] 1 2 3
>>      >> i*10
>>      > [1] 10 20 30
>>      >>
>>      > MM at lynne$
>>
>>      > ------------------------
>>
>>      > But there's a bit more to it: In my examples above, both --quiet
>>      > and --slave where used together with --vanilla.  In general
>>      > --slave *also* never saves, i.e., uses the equivalent of
>>      > q('no'), where as --quiet does [ask or ...].
>>
>>      > Last but not least, from very simply reading R's source code on
>>      > this, it becomes blatant that you can use  '-s'  instead of '--slave',
>>      > but we (R Core) have probably not documented that on purpose (so
>>      > we could reserve it for something more important, and redefine
>>      > the simple use of '-s' some time in the future ?)
>>
>>      > So, all those who want to restrict their language could use '-s'
>>      > for now.  In addition, we could add  >> one <<  other alias to
>>      > --slave, say --subprocess (or --quieter ? or ???)
>>      > and one could make that the preferred use some time in the future.
>>
>>      > Well, these were another two hours of time *not* spent improving
>>      > R technically, but spent reading e-mails, source code, and considering.
>>      > Maybe well spent, maybe not ...
>>
>>      > Martin Maechler
>>      > ETH Zurich and R Core Team
>>
>> With in the   R Core Team    we have considered the issue.
>>
>> As a consequence, I have committed a few minutes ago code changes
>> that replace '--slave' by '--no-echo' .
>> [This will be in R-devel versions from svn rev 77229 and of
>>   course in the "big step" release around April 2020].
>>
>> Among other considerations, we found that  '--no-echo' was
>> really much more self-explaining, as indeed the command line
>> option turns off the echo'ing of the R code that is executed,
>> and on the C level is indeed very much related to R level
>>
>>      options(echo = "no")
>>
>> For back compatibility reasons, the old command line option will
>> continue to work so the many shell and other scripts that use
>> it, will not stop working.
>>
>>
>> Best regards,
>> Martin Maechler
>> ETH Zurich and R Core Team
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Sat Sep 28 00:02:22 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Fri, 27 Sep 2019 15:02:22 -0700
Subject: [R] The "--slave" option ==> will become "--no-echo"
In-Reply-To: <44f35c7a-f47a-5812-b561-e45744f66a2a@gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
 <23944.54092.19365.74438@stat.math.ethz.ch>
 <23950.13023.376850.661671@stat.math.ethz.ch>
 <CAA99HCwbvfUQBruoB6gt4vD48+7EP-XEyWU5rt_ao0ePDzd_5A@mail.gmail.com>
 <44f35c7a-f47a-5812-b561-e45744f66a2a@gmail.com>
Message-ID: <CAA99HCyOciJr_rFYrJO5ipMJ8jWDkK2vgt9xxaO7KoxaM7jfGg@mail.gmail.com>

Apologies, Duncan and Martin. I didn't check "R --help" first. You're
quite right, lots of embedded hyphens.

Best Regards, Bill.

W. Michels, Ph.D.

On Fri, Sep 27, 2019 at 2:42 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 27/09/2019 5:36 p.m., William Michels via R-help wrote:
> > Hi Martin,
> >
> > '--no-echo'
> >
> > ....or....
> >
> > '--no_echo'
> >
> > Obviously you may prefer the first, but I hope you might consider the second.
>
> Are you serious?  That's a terrible suggestion.  Run "R --help" and
> you'll see *no* options with underscores, and a dozen with embedded hyphens.
>
> Duncan Murdoch
>
> >
> > Best Regards,
> >
> > W. Michels, Ph.D.
> >
> >
> > On Fri, Sep 27, 2019 at 9:04 AM Martin Maechler
> > <maechler at stat.math.ethz.ch> wrote:
> >>
> >>>>>>> Martin Maechler
> >>>>>>>      on Mon, 23 Sep 2019 16:14:36 +0200 writes:
> >>
> >>>>>>> Richard O'Keefe
> >>>>>>>      on Sat, 21 Sep 2019 09:39:18 +1200 writes:
> >>
> >>      >> Ah, *now* we're getting somewhere.  There is something
> >>      >> that *can* be done that's genuinely helpful.
> >>      >>> From the R(1) manual page:
> >>      >> -q, --quiet Don't print startup message
> >>
> >>      >> --silent Same as --quiet
> >>
> >>      >> --slave Make R run as quietly as possible
> >>
> >>      >> It might have been better to use --nobanner instead of
> >>      >> --quiet.  So perhaps
> >>
> >>      >> -q, --quiet Don't print the startup message.  This is
> >>      >> the only output that is suppressed.
> >>
> >>      >> --silent Same as --quiet.  Suppress the startup
> >>      >> message only.
> >>
> >>      >> --slave Make R run as quietly as possible.  This is
> >>      >> for use when running R as a subordinate process.  See
> >>      >> "Introduction to Sub-Processes in R"
> >>      >> https://cran.r-project.org/web/packages/subprocess/vignettes/intro.html
> >>      >> for an example.
> >>
> >>      > Thank you, Stephen and Richard.
> >>
> >>      > I think we (the R Core Team) *can* make the description a bit
> >>      > more verbose. However, as practically all "--<foo>" descriptions
> >>      > are fitting in one short line, (and as the 'subprocess' package is just an
> >>      > extension pkg, and may disappear (and more reasons)) I'd like to
> >>      > be less verbose than your proposal.
> >>
> >>      > What about
> >>
> >>      > -q, --quiet               Don't print startup message
> >>
> >>      > --silent          Same as --quiet
> >>
> >>      > --slave           Make R run as quietly as possible.  For use when
> >>      > runnning R as sub(ordinate) process.
> >>
> >>      > If you look more closely, you'll notice that --slave is not much
> >>      > quieter than --quiet, the only (?) difference being that the
> >>      > input is not copied and (only "mostly") the R prompt is also not printed.
> >>
> >>      > And from my experiments (in Linux (Fedora 30)), one might even
> >>      > notice that in some cases --slave prints the R prompt (to stderr?)
> >>      > which one might consider bogous (I'm not: not wanting to spend
> >>      > time fixing this platform-independently) :
> >>
> >>      > --slave :
> >>      > ------------------------
> >>
> >>      > MM at lynne$ echo '(i <- 1:3)
> >>      > i*10' | R-3.6.1 --slave --vanilla
> >>      >> [1] 1 2 3
> >>      > [1] 10 20 30
> >>      > MM at lynne$ f=/tmp/Rslave.out$$; echo '(i <- 1:3)
> >>      > i*10' | R-3.6.1 --slave --vanilla | tee $f
> >>      >> [1] 1 2 3
> >>      > [1] 10 20 30
> >>      > MM at lynne$ cat $f
> >>      > [1] 1 2 3
> >>      > [1] 10 20 30
> >>
> >>      > --quiet :
> >>      > ------------------------
> >>
> >>      > MM at lynne$ f=/tmp/Rquiet.out$$; echo '(i <- 1:3)
> >>      > i*10' | R-3.6.1 --quiet --vanilla | tee $f
> >>      >> (i <- 1:3)
> >>      > [1] 1 2 3
> >>      >> i*10
> >>      > [1] 10 20 30
> >>      >>
> >>      > MM at lynne$ cat $f
> >>      >> (i <- 1:3)
> >>      > [1] 1 2 3
> >>      >> i*10
> >>      > [1] 10 20 30
> >>      >>
> >>      > MM at lynne$
> >>
> >>      > ------------------------
> >>
> >>      > But there's a bit more to it: In my examples above, both --quiet
> >>      > and --slave where used together with --vanilla.  In general
> >>      > --slave *also* never saves, i.e., uses the equivalent of
> >>      > q('no'), where as --quiet does [ask or ...].
> >>
> >>      > Last but not least, from very simply reading R's source code on
> >>      > this, it becomes blatant that you can use  '-s'  instead of '--slave',
> >>      > but we (R Core) have probably not documented that on purpose (so
> >>      > we could reserve it for something more important, and redefine
> >>      > the simple use of '-s' some time in the future ?)
> >>
> >>      > So, all those who want to restrict their language could use '-s'
> >>      > for now.  In addition, we could add  >> one <<  other alias to
> >>      > --slave, say --subprocess (or --quieter ? or ???)
> >>      > and one could make that the preferred use some time in the future.
> >>
> >>      > Well, these were another two hours of time *not* spent improving
> >>      > R technically, but spent reading e-mails, source code, and considering.
> >>      > Maybe well spent, maybe not ...
> >>
> >>      > Martin Maechler
> >>      > ETH Zurich and R Core Team
> >>
> >> With in the   R Core Team    we have considered the issue.
> >>
> >> As a consequence, I have committed a few minutes ago code changes
> >> that replace '--slave' by '--no-echo' .
> >> [This will be in R-devel versions from svn rev 77229 and of
> >>   course in the "big step" release around April 2020].
> >>
> >> Among other considerations, we found that  '--no-echo' was
> >> really much more self-explaining, as indeed the command line
> >> option turns off the echo'ing of the R code that is executed,
> >> and on the C level is indeed very much related to R level
> >>
> >>      options(echo = "no")
> >>
> >> For back compatibility reasons, the old command line option will
> >> continue to work so the many shell and other scripts that use
> >> it, will not stop working.
> >>
> >>
> >> Best regards,
> >> Martin Maechler
> >> ETH Zurich and R Core Team
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Sep 28 04:28:58 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 27 Sep 2019 21:28:58 -0500
Subject: [R] how to add p values to bar plot?
Message-ID: <CAF9-5jMAr9nYTTc7mqJAumTUnjiYLKJ4uksmEgNMe-WShz=dBg@mail.gmail.com>

Hi,

I created a bar plot with this code:

library(ggplot2)
df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG Genes"))
p<-ggplot(data=df, aes(x=Name, y=prop,fill=Name)) +
  geom_bar(stat="identity")+ labs(x="", y = "Proportion of cis
EQTLs")+ scale_fill_brewer(palette="Greens") +
theme_minimal()+theme(legend.position = "none")
p

What do I need to change in my plot so that I have plot with p value
shown on the attached figure?

Thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2019-09-27 at 1.30.37 PM.png
Type: image/png
Size: 106834 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190927/2a6eabb9/attachment.png>

From vd4mm|nd @end|ng |rom gm@||@com  Sat Sep 28 06:21:11 2019
From: vd4mm|nd @end|ng |rom gm@||@com (Vivek Das)
Date: Fri, 27 Sep 2019 21:21:11 -0700
Subject: [R] how to add p values to bar plot?
In-Reply-To: <CAF9-5jMAr9nYTTc7mqJAumTUnjiYLKJ4uksmEgNMe-WShz=dBg@mail.gmail.com>
References: <CAF9-5jMAr9nYTTc7mqJAumTUnjiYLKJ4uksmEgNMe-WShz=dBg@mail.gmail.com>
Message-ID: <CAFkF=gEx+TLMUNThT1wfqMb11LzSvpc5E8pNZv7+uhgheK2YGQ@mail.gmail.com>

You will need to add stat_compare_means. Take a look at here.


http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/

library(ggpubr)
p + stat_compare_means()

Should be fine.

Vivek

On Fri, Sep 27, 2019 at 7:29 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi,
>
> I created a bar plot with this code:
>
> library(ggplot2)
> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG
> Genes"))
> p<-ggplot(data=df, aes(x=Name, y=prop,fill=Name)) +
>   geom_bar(stat="identity")+ labs(x="", y = "Proportion of cis
> EQTLs")+ scale_fill_brewer(palette="Greens") +
> theme_minimal()+theme(legend.position = "none")
> p
>
> What do I need to change in my plot so that I have plot with p value
> shown on the attached figure?
>
> Thanks
> Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
----------------------------------------------------------

Vivek Das, PhD

	[[alternative HTML version deleted]]


From vd4mm|nd @end|ng |rom gm@||@com  Sat Sep 28 06:43:04 2019
From: vd4mm|nd @end|ng |rom gm@||@com (Vivek Das)
Date: Fri, 27 Sep 2019 21:43:04 -0700
Subject: [R] how to add p values to bar plot?
In-Reply-To: <CAF9-5jMy0xaRM1UMX79L2q4YcAbg+qm4NHN9PeCjLnvkdYmFBw@mail.gmail.com>
References: <CAF9-5jMAr9nYTTc7mqJAumTUnjiYLKJ4uksmEgNMe-WShz=dBg@mail.gmail.com>
 <CAFkF=gEx+TLMUNThT1wfqMb11LzSvpc5E8pNZv7+uhgheK2YGQ@mail.gmail.com>
 <CAF9-5jMy0xaRM1UMX79L2q4YcAbg+qm4NHN9PeCjLnvkdYmFBw@mail.gmail.com>
Message-ID: <CAFkF=gH4tJcrmzn7T8EocTZgk_MbTLqh7QHdFJqV-xNHrLX4Bw@mail.gmail.com>

Ah, this is a single observation and not pvalue calculation over a
distribution. You don?t seem to have a spread. Here your code seemed like
it was over all genes(more than 1) vs RG genes(also more than one). But it
is basically an observation of difference of 2 values. So it doesn?t need
to calculate any pvalues. Probability calculation is only needed when you
have distribution of data in each arm to make Ho(null hypothesis) thar
ststes condition 1 vs condition 2 have no difference but when you compute
the distribution, you find a difference that rejects your Null and makes
the alternative hypotheses true.

Just observed your ?prop? is between only two values. So no reason for
comparing since there is no distribution.

Just make barplot and compute the Delta that can be difference between
70.42-7.75 or fold change 70.42/7.75. If they are absolute value you can
also scale them in log scale and do the same. Hope this helps. Good luck.

Vivek

On Fri, Sep 27, 2019 at 9:32 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi Vivek,
>
> Thanks for getting back to me and yes that is what I tried:
>
> library(ggpubr)
> library(ggplot2)
> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG
> Genes"))
> my_comparisons <- list(c("All Genes","RG Genes"))
>
> p <-ggbarplot(df, x="Name", y="prop",fill="Name",legend ="",color =
> "white",palette = "jco",xlab = FALSE,ylab="cis eqtl per gene")
>
> p + stat_compare_means(comparisons=my_comparisons)
>
> I got p value 1, I am wondering does putting here p value makes sense
> because I don't have any distribution, I just have these two numbers
> on y axis:
> "prop" = c(7.75,70.42)
>
> Please advise,
>
> Thanks
> Ana
>
>
> On Fri, Sep 27, 2019 at 11:21 PM Vivek Das <vd4mmind at gmail.com> wrote:
> >
> > You will need to add stat_compare_means. Take a look at here.
> >
> >
> >
> http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/
> >
> > library(ggpubr)
> > p + stat_compare_means()
> >
> > Should be fine.
> >
> > Vivek
> >
> > On Fri, Sep 27, 2019 at 7:29 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >>
> >> Hi,
> >>
> >> I created a bar plot with this code:
> >>
> >> library(ggplot2)
> >> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG
> Genes"))
> >> p<-ggplot(data=df, aes(x=Name, y=prop,fill=Name)) +
> >>   geom_bar(stat="identity")+ labs(x="", y = "Proportion of cis
> >> EQTLs")+ scale_fill_brewer(palette="Greens") +
> >> theme_minimal()+theme(legend.position = "none")
> >> p
> >>
> >> What do I need to change in my plot so that I have plot with p value
> >> shown on the attached figure?
> >>
> >> Thanks
> >> Ana
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > ----------------------------------------------------------
> >
> > Vivek Das, PhD
>
-- 
----------------------------------------------------------

Vivek Das, PhD

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Sep 28 06:52:01 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 27 Sep 2019 23:52:01 -0500
Subject: [R] how to add p values to bar plot?
In-Reply-To: <CAFkF=gH4tJcrmzn7T8EocTZgk_MbTLqh7QHdFJqV-xNHrLX4Bw@mail.gmail.com>
References: <CAF9-5jMAr9nYTTc7mqJAumTUnjiYLKJ4uksmEgNMe-WShz=dBg@mail.gmail.com>
 <CAFkF=gEx+TLMUNThT1wfqMb11LzSvpc5E8pNZv7+uhgheK2YGQ@mail.gmail.com>
 <CAF9-5jMy0xaRM1UMX79L2q4YcAbg+qm4NHN9PeCjLnvkdYmFBw@mail.gmail.com>
 <CAFkF=gH4tJcrmzn7T8EocTZgk_MbTLqh7QHdFJqV-xNHrLX4Bw@mail.gmail.com>
Message-ID: <CAF9-5jNu9HvTiw3gOdAtO+u+t6T9jmHNYCOhWejXf+j7N2CnaQ@mail.gmail.com>

Awesome, thanks!

Yes those two numbers on y axis I calculated as (#of EQTLs)/(#of genes) and
the same for the other, RG condition. So implicitly I do have a spread just
that data was not used to plot this, only those ratios. Is in this case
still p value not necessary?

On Fri, 27 Sep 2019 at 23:43, Vivek Das <vd4mmind at gmail.com> wrote:

> Ah, this is a single observation and not pvalue calculation over a
> distribution. You don?t seem to have a spread. Here your code seemed like
> it was over all genes(more than 1) vs RG genes(also more than one). But it
> is basically an observation of difference of 2 values. So it doesn?t need
> to calculate any pvalues. Probability calculation is only needed when you
> have distribution of data in each arm to make Ho(null hypothesis) thar
> ststes condition 1 vs condition 2 have no difference but when you compute
> the distribution, you find a difference that rejects your Null and makes
> the alternative hypotheses true.
>
> Just observed your ?prop? is between only two values. So no reason for
> comparing since there is no distribution.
>
> Just make barplot and compute the Delta that can be difference between
> 70.42-7.75 or fold change 70.42/7.75. If they are absolute value you can
> also scale them in log scale and do the same. Hope this helps. Good luck.
>
> Vivek
>
> On Fri, Sep 27, 2019 at 9:32 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> Hi Vivek,
>>
>> Thanks for getting back to me and yes that is what I tried:
>>
>> library(ggpubr)
>> library(ggplot2)
>> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG
>> Genes"))
>> my_comparisons <- list(c("All Genes","RG Genes"))
>>
>> p <-ggbarplot(df, x="Name", y="prop",fill="Name",legend ="",color =
>> "white",palette = "jco",xlab = FALSE,ylab="cis eqtl per gene")
>>
>> p + stat_compare_means(comparisons=my_comparisons)
>>
>> I got p value 1, I am wondering does putting here p value makes sense
>> because I don't have any distribution, I just have these two numbers
>> on y axis:
>> "prop" = c(7.75,70.42)
>>
>> Please advise,
>>
>> Thanks
>> Ana
>>
>>
>> On Fri, Sep 27, 2019 at 11:21 PM Vivek Das <vd4mmind at gmail.com> wrote:
>> >
>> > You will need to add stat_compare_means. Take a look at here.
>> >
>> >
>> >
>> http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/
>> >
>> > library(ggpubr)
>> > p + stat_compare_means()
>> >
>> > Should be fine.
>> >
>> > Vivek
>> >
>> > On Fri, Sep 27, 2019 at 7:29 PM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>> >>
>> >> Hi,
>> >>
>> >> I created a bar plot with this code:
>> >>
>> >> library(ggplot2)
>> >> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG
>> Genes"))
>> >> p<-ggplot(data=df, aes(x=Name, y=prop,fill=Name)) +
>> >>   geom_bar(stat="identity")+ labs(x="", y = "Proportion of cis
>> >> EQTLs")+ scale_fill_brewer(palette="Greens") +
>> >> theme_minimal()+theme(legend.position = "none")
>> >> p
>> >>
>> >> What do I need to change in my plot so that I have plot with p value
>> >> shown on the attached figure?
>> >>
>> >> Thanks
>> >> Ana
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > ----------------------------------------------------------
>> >
>> > Vivek Das, PhD
>>
> --
> ----------------------------------------------------------
>
> Vivek Das, PhD
>

	[[alternative HTML version deleted]]


From vd4mm|nd @end|ng |rom gm@||@com  Sat Sep 28 07:00:20 2019
From: vd4mm|nd @end|ng |rom gm@||@com (Vivek Das)
Date: Fri, 27 Sep 2019 22:00:20 -0700
Subject: [R] how to add p values to bar plot?
In-Reply-To: <CAF9-5jNu9HvTiw3gOdAtO+u+t6T9jmHNYCOhWejXf+j7N2CnaQ@mail.gmail.com>
References: <CAF9-5jMAr9nYTTc7mqJAumTUnjiYLKJ4uksmEgNMe-WShz=dBg@mail.gmail.com>
 <CAFkF=gEx+TLMUNThT1wfqMb11LzSvpc5E8pNZv7+uhgheK2YGQ@mail.gmail.com>
 <CAF9-5jMy0xaRM1UMX79L2q4YcAbg+qm4NHN9PeCjLnvkdYmFBw@mail.gmail.com>
 <CAFkF=gH4tJcrmzn7T8EocTZgk_MbTLqh7QHdFJqV-xNHrLX4Bw@mail.gmail.com>
 <CAF9-5jNu9HvTiw3gOdAtO+u+t6T9jmHNYCOhWejXf+j7N2CnaQ@mail.gmail.com>
Message-ID: <CAFkF=gFKFUrYYtK9agAg0i6Ks3AqtCR6-1BcDjcHzajxAvNS1A@mail.gmail.com>

Well that means already a ratio. Could you show me how the data frame looks
like? If they are array of values then you compare the distribution of your
ratios like Ratio1 array from ? (#of EQTLs)/(#of genes)? vs Ratio 2 arrays
of the ?same for the other, RG condition?.

ratio1 = c(ratio1Value1, ratio1Value2, ..., ratio1ValueN)
ratio2 = c(ratio2Value1, ratio2Value2, ..., ratio2ValueN)

your code can compare distribution, means & pvalue of these and make
whisker plots and also the pvalues. This is a better way if you can make
your dataframe in that manner to compute and make the plots. Hope this is
clear.

Vivek

On Fri, Sep 27, 2019 at 9:52 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Awesome, thanks!
>
> Yes those two numbers on y axis I calculated as (#of EQTLs)/(#of genes)
> and the same for the other, RG condition. So implicitly I do have a spread
> just that data was not used to plot this, only those ratios. Is in this
> case still p value not necessary?
>
> On Fri, 27 Sep 2019 at 23:43, Vivek Das <vd4mmind at gmail.com> wrote:
>
>> Ah, this is a single observation and not pvalue calculation over a
>> distribution. You don?t seem to have a spread. Here your code seemed like
>> it was over all genes(more than 1) vs RG genes(also more than one). But it
>> is basically an observation of difference of 2 values. So it doesn?t need
>> to calculate any pvalues. Probability calculation is only needed when you
>> have distribution of data in each arm to make Ho(null hypothesis) thar
>> ststes condition 1 vs condition 2 have no difference but when you compute
>> the distribution, you find a difference that rejects your Null and makes
>> the alternative hypotheses true.
>>
>> Just observed your ?prop? is between only two values. So no reason for
>> comparing since there is no distribution.
>>
>> Just make barplot and compute the Delta that can be difference between
>> 70.42-7.75 or fold change 70.42/7.75. If they are absolute value you can
>> also scale them in log scale and do the same. Hope this helps. Good luck.
>>
>> Vivek
>>
>> On Fri, Sep 27, 2019 at 9:32 PM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>>
>>> Hi Vivek,
>>>
>>> Thanks for getting back to me and yes that is what I tried:
>>>
>>> library(ggpubr)
>>> library(ggplot2)
>>> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG
>>> Genes"))
>>> my_comparisons <- list(c("All Genes","RG Genes"))
>>>
>>> p <-ggbarplot(df, x="Name", y="prop",fill="Name",legend ="",color =
>>> "white",palette = "jco",xlab = FALSE,ylab="cis eqtl per gene")
>>>
>>> p + stat_compare_means(comparisons=my_comparisons)
>>>
>>> I got p value 1, I am wondering does putting here p value makes sense
>>> because I don't have any distribution, I just have these two numbers
>>> on y axis:
>>> "prop" = c(7.75,70.42)
>>>
>>> Please advise,
>>>
>>> Thanks
>>> Ana
>>>
>>>
>>> On Fri, Sep 27, 2019 at 11:21 PM Vivek Das <vd4mmind at gmail.com> wrote:
>>> >
>>> > You will need to add stat_compare_means. Take a look at here.
>>> >
>>> >
>>> >
>>> http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/
>>> >
>>> > library(ggpubr)
>>> > p + stat_compare_means()
>>> >
>>> > Should be fine.
>>> >
>>> > Vivek
>>> >
>>> > On Fri, Sep 27, 2019 at 7:29 PM Ana Marija <
>>> sokovic.anamarija at gmail.com> wrote:
>>> >>
>>> >> Hi,
>>> >>
>>> >> I created a bar plot with this code:
>>> >>
>>> >> library(ggplot2)
>>> >> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG
>>> Genes"))
>>> >> p<-ggplot(data=df, aes(x=Name, y=prop,fill=Name)) +
>>> >>   geom_bar(stat="identity")+ labs(x="", y = "Proportion of cis
>>> >> EQTLs")+ scale_fill_brewer(palette="Greens") +
>>> >> theme_minimal()+theme(legend.position = "none")
>>> >> p
>>> >>
>>> >> What do I need to change in my plot so that I have plot with p value
>>> >> shown on the attached figure?
>>> >>
>>> >> Thanks
>>> >> Ana
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > --
>>> > ----------------------------------------------------------
>>> >
>>> > Vivek Das, PhD
>>>
>> --
>> ----------------------------------------------------------
>>
>> Vivek Das, PhD
>>
> --
----------------------------------------------------------

Vivek Das, PhD

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Sep 28 07:25:11 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Sep 2019 17:25:11 +1200
Subject: [R] 
 [FORGED] Re:  The "--slave" option ==> will become "--no-echo"
In-Reply-To: <CA+8X3fX1+73gdZa5cC0di8G5-UFouK7d-nsoq=mR1snnBqp-LQ@mail.gmail.com>
References: <CA+3jJ-bgtpURx0Ej8Wu=AG9Ex4ZtHsZbTq1XSYDQ6+GGsVXXKQ@mail.gmail.com>
 <640ac7dd-fdc1-9f87-ab51-dd3678462090@auckland.ac.nz>
 <CAB8pepz62Wf32PNK-CY8CX=wytABAzMcx9sYPiCM1NroCk3udQ@mail.gmail.com>
 <CABcYAdKKQXm0JGbN2OssCdF9Bqiyat=rUR4-7cw3S3ydt3RDfQ@mail.gmail.com>
 <CCB3E51B-04C8-4F66-8CA8-8E8C5D0C5EDB@gmail.com>
 <CABcYAdKWrOQgjuEMwDdPmtosx639G_1CvqrYdrQs=c9HXpVaZw@mail.gmail.com>
 <CA+3jJ-YfAcJ_htt0ZeyfqAeVVekibpgtrr3bivvo1vEVw9EuUw@mail.gmail.com>
 <d95422eace26473aafc00aff87d3bf5f@GBDCVPEXC08.corp.lgc-group.com>
 <CABcYAdJji6RkVLUx4GY_kaHQ4j2OHmQjpm45a4XV6xNS9mYwvg@mail.gmail.com>
 <23944.54092.19365.74438@stat.math.ethz.ch>
 <23950.13023.376850.661671@stat.math.ethz.ch>
 <CA+8X3fX1+73gdZa5cC0di8G5-UFouK7d-nsoq=mR1snnBqp-LQ@mail.gmail.com>
Message-ID: <bb0b9fce-51d7-2777-7df8-991c0d5b724e@auckland.ac.nz>


On 28/09/19 9:16 AM, Jim Lemon wrote:

> On Sat, Sep 28, 2019 at 2:04 AM Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>
>> For back compatibility reasons, the old command line option will
>> continue to work so the many shell and other scripts that use
>> it, will not stop working.
>>
> That's a relief. I was getting worried that we would become:
> 
> The knights who cannot say BS.

Right on Jim!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Sep 28 04:21:30 2019
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 27 Sep 2019 21:21:30 -0500
Subject: [R] how to add p values to bar plot?
Message-ID: <CAF9-5jMED47wzp3JQj7t1XVr1v4THWW+9vma5XjO_PQBeuGF_w@mail.gmail.com>

Hi,

I have a bar plot (green colors in attach) which I made with this:

library(ggplot2)
df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG Genes"))
p<-ggplot(data=df, aes(x=Name, y=prop,fill=Name)) +
  geom_bar(stat="identity")+ labs(x="", y = "Proportion of cis
EQTLs")+ scale_fill_brewer(palette="Greens") +
theme_minimal()+theme(legend.position = "none")
p

What do I need to change in my plot so that I have plot with p value
shown on the 2nd attached figure (gray and blue)?

Thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2019-09-27 at 9.20.50 PM.png
Type: image/png
Size: 79262 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190927/9b855c0f/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2019-09-27 at 1.30.37 PM.png
Type: image/png
Size: 106834 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190927/9b855c0f/attachment-0001.png>

From m@rk|eed@2 @end|ng |rom gm@||@com  Sat Sep 28 19:32:47 2019
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Sat, 28 Sep 2019 13:32:47 -0400
Subject: [R] stats::lm has inconsistent output when adding constant to
 dependent variable
In-Reply-To: <20190928153632.4a046731@ECM-DTC-716.uniwa.uwa.edu.au>
References: <b4546e64-4105-fced-25f3-6103cfd3d7ee@berkeley.edu>
 <CAHz+bWZwwkfOdrFVBUEaJiSAfELoGSTLczo_cFNCiiwN=3Z3tA@mail.gmail.com>
 <CAHz+bWaXyah=f-6YKeQtLGt4PUtPoiF1Z7y_YAUbBGAV4nknZg@mail.gmail.com>
 <20190928153632.4a046731@ECM-DTC-716.uniwa.uwa.edu.au>
Message-ID: <CAHz+bWbbx_wyAPn2_1A21wy3P7=6SG5ARfgbLRHvq2C7K2gCCA@mail.gmail.com>

Hi Berwin: Yes, that's it. Donsker is famous for a functional CLT so I was
mixing up  statistics
and stochastic processes  I better stick to statistics. It's safer. !!!!!
Thanks for correction.
I'm ccing R-help since it may be useful to someone there. See below for
Berwin's
comment.


Mark

On Sat, Sep 28, 2019 at 3:36 AM Berwin A Turlach <berwin.turlach at gmail.com>
wrote:

> G'day Mark,
>
> On Fri, 27 Sep 2019 14:43:28 -0400
> Mark Leeds <markleeds2 at gmail.com> wrote:
>
> > correction to my previous answer. I looked around and I don't think
> > it's called the donsker effect.
>
> I think you meant the Hauck-Donner effect [1], which refers to the
> problem of separation for binomial GLMs (not all GLMs).
>
> Cheers,
>
>         Berwin
>
> [1] Hauck, Jr., W.W. and Donner, A. (1977) Wald's test as applied to
> hypotheses in logit analysis.  Journal of the American Statistical
> Association 72, 851-853.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Sep 28 23:25:29 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 29 Sep 2019 07:25:29 +1000
Subject: [R] I am a user of the package plotrix,
 and want to ask a question that I can't possibly find the
 answer anywhere
In-Reply-To: <CA+=JkcoTmYoA56e_HRRuxYpvQYEbT++xqF11feaZFROXJm-70A@mail.gmail.com>
References: <CA+=JkcoTmYoA56e_HRRuxYpvQYEbT++xqF11feaZFROXJm-70A@mail.gmail.com>
Message-ID: <CA+8X3fX1c-L_e9yjQBWCxjJR2EVWB1GmUxCMx=teTfR3gvsLeg@mail.gmail.com>

Hi Leo,
The easiest way to do this is:

par(las=1)
# twoord.plot command
par(las=0)

Jim

On Sat, Sep 28, 2019 at 8:56 PM leo wu <leowu.988 at gmail.com> wrote:
>
> Dear Jim Lemon:
>     I am currently using the twoord.plot() function in plotrix package. I want to inquire, how am I supposed to rotate my y-axis label, so it wouldn't display vertically, and would look parrel to the x-axis?
>     If you could answer me, that would be so much help~~
>
> 2019/09/28
> Sincerely and best regards, By Leo


From drj|m|emon @end|ng |rom gm@||@com  Sat Sep 28 23:43:01 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 29 Sep 2019 07:43:01 +1000
Subject: [R] how to add p values to bar plot?
In-Reply-To: <CAF9-5jMED47wzp3JQj7t1XVr1v4THWW+9vma5XjO_PQBeuGF_w@mail.gmail.com>
References: <CAF9-5jMED47wzp3JQj7t1XVr1v4THWW+9vma5XjO_PQBeuGF_w@mail.gmail.com>
Message-ID: <CA+8X3fUSKUBoHAyWTd6dRgx7nyaevzR6GfC=X+gW1PuTEVGc+g@mail.gmail.com>

Hi Ana,
You seem to have a p-value at the top of the second plot. Do you just
want that p-value in a different place?
My first guess would be the "annotate" argument. Say you wanted your
p-value in the middle of the plot.

# your ggplot line
 p+annotate("text",x=1.5,y=0.05,label="p = 1.6x10-16")
p

Note: untested

Jim

On Sat, Sep 28, 2019 at 6:52 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi,
>
> I have a bar plot (green colors in attach) which I made with this:
>
> library(ggplot2)
> df <- data.frame("prop" = c(7.75,70.42), "Name" = c("All Genes","RG Genes"))
> p<-ggplot(data=df, aes(x=Name, y=prop,fill=Name)) +
>   geom_bar(stat="identity")+ labs(x="", y = "Proportion of cis
> EQTLs")+ scale_fill_brewer(palette="Greens") +
> theme_minimal()+theme(legend.position = "none")
> p
>
> What do I need to change in my plot so that I have plot with p value
> shown on the 2nd attached figure (gray and blue)?
>
> Thanks
> Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Mon Sep 30 04:59:44 2019
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 30 Sep 2019 15:59:44 +1300
Subject: [R] static vs. lexical scope
In-Reply-To: <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>
References: <20190925090242.zgua52gcxkbf6ph3@x60s.casa>
 <CAGAA5bfPF9zEHb4XM8N8vsu2byx7Yb0RpfN1wH6_swB5P_BneA@mail.gmail.com>
 <CABcYAdLUwD0Q+ngJ8tFd_8fkkbQsiS=L-JVUPCXxQqAjGj6EYg@mail.gmail.com>
 <15804be7-56a8-cf0e-7c15-98459a4a806e@gmail.com>
Message-ID: <CABcYAdLthXodWWa_otNeVySfc45+rE5ERobBwqV67BM=3cvZDQ@mail.gmail.com>

I didn't say R's rules were "a mystery" or "overly complicated", but
that they are "weird".
When I started trying to compile R, with() did not exist, if I
remember correctly.
Half the point of compiling is to do variable lookups at compile time.
In an example like
  function (...) {
     use x
     x <- ...
     use x
}
it's easy enough to tell one x from the other.  Now change it slightly:
  function (...) {
     use x
     if (...) x <- ...
     use x
}
Now we cannot tell whether the second use refers to an inner x or the outer one.
Consider next
> f <- function () {
+    g <- function () { x }
+    x <- 2
+    g()'
+ }
> x <- 1
> f()
Here's the snag: the x in g does not refer to the x that is visible at
the time when
g is *defined* (as in every other language with lexical scope I've
used) but to the
x that is visible when g is *called*.  In other languages, you can 'trim' the
lexical environment of a closure to just the variables that the
closure mentions.
In R you cannot.

It gets nastier.  A function can *remove* a variable from another
function's frame.
(See ?rm and note the 'envir' argument and then read ?sys.frame.)

The best I was able to come up with was a scheme where each statically visible
variable had a slot for its value and a reserved object.
Mention of x =>
   t := static slot for x
   if t is the reserved object: t := full lookup("x")
Assignment to x =>
  static slot for  := t

That doesn't work with "with", and then of course there are "active
bindings" nowadays,
see ?bindenv.

On Fri, 27 Sep 2019 at 02:59, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 26/09/2019 9:44 a.m., Richard O'Keefe wrote:
> > Actually, R's scope rules are seriously weird.
> > I set out to write an R compiler, wow, >20 years ago.
> > Figured out how to handle optional and keyword parameters efficiently,
> > figured out a lot of other things, but choked on the scope rules.
> > Consider
> >
> >> x <- 1
> >> f <- function () {
> > +   a <- x
> > +   x <- 2
> > +   b <- x
> > +   c(a=a, b=b)
> > + }
> >> f()
> > a b
> > 1 2
> >> x
> > [1] 1
> >
> > It's really not clear what is going on here.
>
> This is all pretty clear:  in the first assignment, x is found in the
> global environment, because it does not exist in the evaluation frame.
> In the second assignment, a new variable is created in the evaluation
> frame.  In the third assignment, that new variable is used to set the
> value of b.
>
> > However, ?assign can introduce new variables into an environment,
> > and from something like
> >    with(df, x*2-y)
> > it is impossible for a compiler to tell which, if either, of x and y is to
> > be obtained from df and which from outside.  And of course ?with
> > is just a function:
> >
> >> df <- data.frame(y=24)
> >> w <- with
> >> w(df, x*2-y)
> > [1] -22
> >
> > So you cannot in general tell *which* function can twist the environment
> > in which its arguments will be evaluated.
>
> It's definitely hard to compile R because of the scoping rules, but that
> doesn't make the scoping rules unclear.
>
> > I got very tired of trying to explore a twisty maze of documentation and
> > trying to infer a specification from examples.  I would come up with an
> > ingenious mechanism for making the common case tolerable and the
> > rare cases possible, and then I'd discover a bear trap I hadn't seen.
> > I love R, but I try really hard not to be clever with it.
>
> I think the specification is really pretty simple.  I'm not sure it is
> well documented anywhere, but I think I understand it pretty well, and
> it doesn't seem overly complicated to me.
>
> > So while R's scoping is *like* lexical scoping, it is *dynamic* lexical
> > scoping, to coin a phrase.
>
> I'd say it is regular lexical scoping but with dynamic variable
> creation. Call that dynamic lexical scoping if you want, but it's not
> really a mystery.
>
> Duncan Murdoch
>
> >
> > On Thu, 26 Sep 2019 at 23:56, Martin M?ller Skarbiniks Pedersen
> > <traxplayer at gmail.com> wrote:
> >>
> >> On Wed, 25 Sep 2019 at 11:03, Francesco Ariis <fa-ml at ariis.it> wrote:
> >>>
> >>> Dear R users/developers,
> >>> while ploughing through "An Introduction to R" [1], I found the
> >>> expression "static scope" (in contraposition to "lexical scope").
> >>>
> >>> I was a bit puzzled by the difference (since e.g. Wikipedia conflates the
> >>> two) until I found this document [2].
> >>
> >>
> >> I sometimes teach a little R, and they might ask about static/lexical scope.
> >> My short answer is normally that S uses static scoping and R uses
> >> lexical scoping.
> >> And most all modern languages uses lexical scoping.
> >> So if they know Java, C, C# etc. then the scoping rules for R are the same.
> >>
> >> I finally says that it is not a full answer but enough for most.
> >>
> >> Regards
> >> Martin
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Mon Sep 30 12:14:19 2019
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Mon, 30 Sep 2019 11:14:19 +0100
Subject: [R] Course: Data exploration, regression,
 GLM & GAM with introduction to R
Message-ID: <220a330d-d3d8-dcd2-345c-e7e5dade3145@highstat.com>

Apologies for cross-posting

We would like to announce the following statistics course in Lisbon, 
Portugal.


Course: Data exploration, regression, GLM & GAM with introduction to R
Where:? PT Meeting Centre, Parque das Na??es, Lisbon, Portugal
When:?? 3 - 7 February 2020

Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2020/Flyer2020_02Lisbon_RGG.pdf


Kind regards,

Alain Zuur



-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com


From dom@g@|9 @end|ng |rom m@u@edu  Mon Sep 30 17:42:03 2019
From: dom@g@|9 @end|ng |rom m@u@edu (Domagalski, Rachel)
Date: Mon, 30 Sep 2019 15:42:03 +0000
Subject: [R] [R-pkgs] New package 'backbone' for extracting significant
 edges from a weighted graph
Message-ID: <DM6PR12MB3452B8D51C55AF591A01335C9F820@DM6PR12MB3452.namprd12.prod.outlook.com>

Hello R users,

I am excited to introduce a new package for R which is now available on CRAN called ?backbone?.
The package can be found here: https://cran.r-project.org/web/packages/backbone/index.html

The backbone package provides methods for extracting from a weighted graph a binary or signed backbone that retains only the significant edges. The user may input a weighted graph, or a bipartite graph from which a weighted graph is first constructed via projection.

Backbone extraction methods include:
the stochastic degree sequence model (Neal, Z. P. (2014). https://doi.org/10.1016/j.socnet.2014.06.001),
hypergeometric model (Neal, Z. (2013). https://doi.org/10.1007/s13278-013-0107-y),
the fixed degree sequence model (Zweig, K. A., and Kaufmann, M. (2011). https://doi.org/10.1007/s13278-011-0021-0),
as well as a universal threshold method.

A vignette which describes the package in greater detail can be found here: https://cran.r-project.org/web/packages/backbone/vignettes/backbone_introduction.html

The package will be constantly updated with new functions and methods.
If you have any backbone extraction methods you would like to see included, please contact the package maintainer Rachel Domagalski at <domagal9 at msu.edu>.

Very best regards,
Rachel Domagalski
Zachary Neal
Bruce Sagan


	[[alternative HTML version deleted]]


-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

