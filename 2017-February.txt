From drjimlemon at gmail.com  Wed Feb  1 00:12:33 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 1 Feb 2017 10:12:33 +1100
Subject: [R] Challenge extracting months
In-Reply-To: <CAGD2cKe-M=v7qpfbnmwV2VOZ1qFGRC2ABv+=CtsqoQ=mFOA43Q@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
	<CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
	<CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>
	<CA+8X3fXKvAhuEGNjbOeHXQJqNXfz-HrcckYzfSiO8MuZNcwchg@mail.gmail.com>
	<CAGD2cKe-M=v7qpfbnmwV2VOZ1qFGRC2ABv+=CtsqoQ=mFOA43Q@mail.gmail.com>
Message-ID: <CA+8X3fVZ5CwgUm-tghU=aNDZ_qBhodh0CAc+GPo4vZJR5pLmkw@mail.gmail.com>

Hi Kwesi,
I worked through your code below, and I think that when you have the
two variables "mon.t1" and "seas.t1" you can select a "rolling
quarter" like this:

# the file name in your example is different from the one you sent
era<-read.table(file="SAfr_700hpa_7x5II.txt",header=FALSE,sep=" ",
 skip=1,dec = ".")
era.nodes<-paste(era[,1],era[,2],sep=".")
era.nodes<-as.numeric(era.nodes)
era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-01"),
 end=as.Date("2016-12-31"))
era.nodes.days.t1<-window(era.nodes.days,start=as.Date("1980-01-01"),
 end=as.Date("2016-12-31"))
mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
addyear<-0
# this loop transforms mon.t1 into an increasing sequence of months
for(i in 2:length(mon.t1)) {
 if(seas.t1[i] > seas.t1[i-1]) addyear<-addyear+12
 mon.t1[i]<-mon.t1[i] + addyear
}
for(i in 1:(max(mon.t1)-2)) {
 # this gives a logical index for the rolling quarter
 rq<-mon.t1 %in% i:(i+2)
}

Each successive "rq" produced by the last loop can be used to extract
whatever values you want from "era" or "era.nodes".

Jim


On Tue, Jan 31, 2017 at 9:04 PM, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
> Hello Jim, thanks for the code. But I come to you once again, I am not
> looking to do a rolling mean, but to select JFM,FMA,MAM etc from the data
> attached. Below is my sample code which actually selects these months. I
> will rather be glad if I can have a function that does the selection for all
> these 3 months selected for each year as shown in my last two lines of code;
> Taking into accounts years with 29 days in February etc.
>
> rm(list = ls())
> library(zoo)
> library(PCICt)
> library(lattice)
> library(RColorBrewer)
>
> setwd('/home/kwesi/Documents/700hpa/soms/')
> # Reading the data
>
> era       <- read.table(file="SAfr_700hpa_5x4II.txt",header = FALSE, sep =
> "",skip=1,dec = ".")
> era.nodes      <- paste(era[,1],era[,2],sep=".")
>
> era.nodes      <-as.numeric(era.nodes)
> era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-01"),end=as.Date("2016-12-31"))
>
> era.nodes.days.t1<-window(era.nodes.days,start=as.Date("1980-01-01"),end=as.Date("2016-12-31"))
>
> mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
> seas.t1 <-as.numeric(format(index(era.nodes.days.t1),"%Y"))
> era.nodes.days.t1<-cbind(era.nodes.days.t1,mon.t1,seas.t1)
> era.nodes.days.t1
> jfm80<-era.nodes.days.t1[1:91,1:3[era.nodes.days.t1[1:91,2]==1|era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3]
> fma80<-era.nodes.days.t1[32:(91+30),1:3
> [era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3|era.nodes.days.t1[1:91,2]==4]
>
> On Tue, Jan 31, 2017 at 5:23 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Kwesi,
>> A mistake in the last email. Don't try to replace the column in
>> era.sta as the result will be a different length. Try this:
>>
>> newera.sta2<-collapse.values(era.sta[,2],3)
>>
>> Jim
>>
>> On Tue, Jan 31, 2017 at 10:32 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> > Hi Kwesi,
>> > The function collapse_values will only work on a vector of numbers
>> > with FUN="mean". era.sta looks like a data frame with at least two
>> > elements. As the second of these elements seems to be numeric, perhaps
>> > this will work:
>> >
>> > era.sta[,2]<-collapse.values(era.sta[,2],3)
>> >
>> > Don't try to apply the names to era.sta, that was just something to
>> > make the example easier to understand. If you want to collapse more
>> > than one column of era.sta do each one at a time and assign them to a
>> > new data frame. In particular, if era[,1] is a vector of month names,
>> > you will have to create a new vector of quarter (three month) names.
>> > If there are very many of these, the collapse_values function can be
>> > modified to do it automatically.
>> >
>> > Jim
>> >
>> >
>> >
>> > On Tue, Jan 31, 2017 at 9:50 AM, Kwesi Quagraine
>> > <starskykwesi at gmail.com> wrote:
>> >> Hello Jim,this is my script now; I am having this error when I called
>> >> the
>> >> function;" In mean.default(list(era...1. = 1:444, Node_freq =
>> >> c(-0.389855332400718,  :  argument is not numeric or logical: returning
>> >> NA"
>> >> Any help will be much appreciated.
>> >>
>> >> Kwesi
>> >>
>> >> rm(list = ls())
>> >> setwd('/home/kwesi/Documents/700hpa/soms/')
>> >> # Reading the data
>> >>
>> >> era       <- read.csv(file="som_freq.csv",header = TRUE, sep = ",",dec
>> >> =
>> >> ".")
>> >> era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
>> >> era.sta<-data.frame(era[,1],era.scaled)
>> >> era.sta
>> >>
>> >> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>> >>   jump<-span-1
>> >>   newx<-rep(NA,length(x)-jump)
>> >>   for(i in 1:length(newx))
>> >>     newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>> >>   return(newx)
>> >> }
>> >>
>> >> #test<-1:12
>> >> names(era.sta)<-month.abb
>> >> collapse_values(era.sta,3)
>> >> era.sta
>> >>
>> >>
>> >> On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon <drjimlemon at gmail.com>
>> >> wrote:
>> >>>
>> >>> Hi Kwesi,
>> >>> Even without the data, it seems clear that you want something like a
>> >>> rolling mean. Here is a simple function that will apply a function
>> >>> like "mean" to successive bits of a vector of numbers:
>> >>>
>> >>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>> >>>  jump<-span-1
>> >>>  newx<-rep(NA,length(x)-jump)
>> >>>  for(i in 1:length(newx))
>> >>>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>> >>>  return(newx)
>> >>> }
>> >>>
>> >>> test<-1:12
>> >>> names(test)<-month.abb
>> >>> test
>> >>> collapse_values(test,3)
>> >>>  [1]  2  3  4  5  6  7  8  9 10 11
>> >>>
>> >>> Jim
>> >>>
>> >>>
>> >>>
>> >>> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
>> >>> <starskykwesi at gmail.com> wrote:
>> >>> > Hello, I have a data with two variables nodes and index, I want to
>> >>> > extract
>> >>> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA
>> >>> > etc to
>> >>> > OND. Was wondering how to go about it. Kindly find attached the data
>> >>> > as
>> >>> > csv.
>> >>> > Any help will be appreciated.
>> >>> >
>> >>> > Regards,
>> >>> > Kwesi
>> >>> >
>> >>> > --
>> >>> > Try not to become a man of success but rather a man of value-Albert
>> >>> > Einstein
>> >>> >
>> >>> > University of Cape Coast|College of Agriculture and Natural
>> >>> > Sciences|Department
>> >>> > of Physics|
>> >>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> >>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> >>> > Mobile: +233266173582
>> >>> > Skype: quagraine_cwasi
>> >>> > Twitter: @Pkdilly
>> >>> > ______________________________________________
>> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> > PLEASE do read the posting guide
>> >>> > http://www.R-project.org/posting-guide.html
>> >>> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >>
>> >>
>> >> --
>> >> Try not to become a man of success but rather a man of value-Albert
>> >> Einstein
>> >>
>> >> University of Cape Coast|College of Agriculture and Natural
>> >> Sciences|Department of Physics|
>> >> Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> >> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> >> Mobile: +233266173582
>> >> Skype: quagraine_cwasi
>> >> Twitter: @Pkdilly
>> >>
>
>
>
>
> --
> Try not to become a man of success but rather a man of value-Albert Einstein
>
> University of Cape Coast|College of Agriculture and Natural
> Sciences|Department of Physics|
> Team Leader|Recycle Up! Ghana|Technology Without Borders|
> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> Mobile: +233266173582
> Skype: quagraine_cwasi
> Twitter: @Pkdilly
>


From msharp at txbiomed.org  Wed Feb  1 00:36:59 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 31 Jan 2017 23:36:59 +0000
Subject: [R] Failure to understand namespaces in XML::getNodeSet
In-Reply-To: <CABdHhvHNcQBE+YLq-V6PP9AYhBAB1Wo8DbcmELpTZovFonsCgw@mail.gmail.com>
References: <C93BCEFF-3EB2-4422-8BDF-9B305E393424@txbiomed.org>
	<CABdHhvHNcQBE+YLq-V6PP9AYhBAB1Wo8DbcmELpTZovFonsCgw@mail.gmail.com>
Message-ID: <BAB7A1DF-1D51-4F3A-8B2C-421E66289545@TxBiomed.org>

Hadley,

Thank you. I am able to get the xml_ns_strip() function to work with my file directly so I will likely be able to reach my immediate goal.

However, I still have had no success with understanding the namespace problem. I am not able to use read_xml() using the object I generated for the reproducible example, which is simply a character vector of length 4 having the contents of the XML file as produce by readLines(). I then used dput() to define the structure. The resulting structure apparently is not to the liking of read_xml(). I have reproduced the necessary code here for your convenience. There error is below.

##
library(xml2)
library(stringr)
with_ns_xml <- c("<?xml version=\"1.0\" ?>",
                 "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
                 "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
                 "</WorkSet>")
## without str_c() collapse it complain of a vector of length > 1 also.
read_xml(str_c(with_ns_xml, collapse = TRUE))
Error in doc_parse_raw(x, encoding = encoding, base_url = base_url, as_html = as_html,  :
  Start tag expected, '<' not found [4]

## produces the following error message.
Error in doc_parse_raw(x, encoding = encoding, base_url = base_url, as_html = as_html,  :
  Start tag expected, '<' not found [4]

I have similar issues with xml2::xml_find_all
xml_find_all(str_c(with_ns_xml, collapse = TRUE), "/WorkSet//Description")

## Produces the following error message.
Error in UseMethod("xml_find_all") :
  no applicable method for 'xml_find_all' applied to an object of class "character"



R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Jan 31, 2017, at 4:27 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>
> See the last example in ?xml2::xml_find_all or use xml2::xml2::xml_ns_strip()
>
> Hadley
>
> On Tue, Jan 31, 2017 at 9:43 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>> I am trying to read a series of XML files that use a namespace and I have failed, thus far, to discover the proper syntax. I have a reproducible example below. I have two XML character strings defined: one without a namespace and one with. I show that I can successfully extract the node using the XML string without the namespace and fail when using the XML string with the namespace.
>>
>> Mark
>> PS I am having the same problem with the xml2 package and am hoping understanding one with help with the other.
>>
>> ##
>> library(XML)
>> ## The first XML text (no_ns_xml) does not have a namespace defined
>> no_ns_xml <- c("<?xml version=\"1.0\" ?>", "<WorkSet>",
>>               "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>>               "</WorkSet>")
>> l_no_ns_xml <-xmlTreeParse(no_ns_xml, asText = TRUE, getDTD = FALSE,
>>                           useInternalNodes = TRUE)
>> ## The node is found
>> getNodeSet(l_no_ns_xml, "/WorkSet//Description")
>>
>> ## The second XML text (with_ns_xml) has a namespace defined
>> with_ns_xml <- c("<?xml version=\"1.0\" ?>",
>>                 "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
>>                 "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>>                 "</WorkSet>")
>>
>> l_with_ns_xml <-xmlTreeParse(with_ns_xml, asText = TRUE, getDTD = FALSE,
>>                               useInternalNodes = TRUE)
>> ## The node is not found
>> getNodeSet(l_with_ns_xml, "/WorkSet//Description")
>> ## I attempt to provide the namespace, but fail.
>> ns <-  "http://labkey.org/etl/xml"
>> names(ns)[1] <- "xmlns"
>> getNodeSet(l_with_ns_xml, "/WorkSet//Description", namespaces = ns)
>>
>> R. Mark Sharp, Ph.D.
>> Director of Data Science Core
>> Southwest National Primate Research Center
>> Texas Biomedical Research Institute
>> P.O. Box 760549
>> San Antonio, TX 78245-0549
>> Telephone: (210)258-9476
>> e-mail: msharp at TxBiomed.org
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> http://hadley.nz

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From h.wickham at gmail.com  Wed Feb  1 00:52:16 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 31 Jan 2017 17:52:16 -0600
Subject: [R] Failure to understand namespaces in XML::getNodeSet
In-Reply-To: <BAB7A1DF-1D51-4F3A-8B2C-421E66289545@TxBiomed.org>
References: <C93BCEFF-3EB2-4422-8BDF-9B305E393424@txbiomed.org>
	<CABdHhvHNcQBE+YLq-V6PP9AYhBAB1Wo8DbcmELpTZovFonsCgw@mail.gmail.com>
	<BAB7A1DF-1D51-4F3A-8B2C-421E66289545@TxBiomed.org>
Message-ID: <CABdHhvFk5-pV0cdEF7mMmZDijNfFw7i9gDAOeY_N4NV0x1Nz2Q@mail.gmail.com>

I think you want

x <- read_xml('<?xml version="1.0" ?>
  <WorkSet xmlns="http://labkey.org/etl/xml">
  <Description>MFIA 9-Plex (CharlesRiver)</Description>
</WorkSet>')

The collapse argument do what you think it does.

Hadley

On Tue, Jan 31, 2017 at 5:36 PM, Mark Sharp <msharp at txbiomed.org> wrote:
> Hadley,
>
> Thank you. I am able to get the xml_ns_strip() function to work with my file directly so I will likely be able to reach my immediate goal.
>
> However, I still have had no success with understanding the namespace problem. I am not able to use read_xml() using the object I generated for the reproducible example, which is simply a character vector of length 4 having the contents of the XML file as produce by readLines(). I then used dput() to define the structure. The resulting structure apparently is not to the liking of read_xml(). I have reproduced the necessary code here for your convenience. There error is below.
>
> ##
> library(xml2)
> library(stringr)
> with_ns_xml <- c("<?xml version=\"1.0\" ?>",
>                  "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
>                  "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>                  "</WorkSet>")
> ## without str_c() collapse it complain of a vector of length > 1 also.
> read_xml(str_c(with_ns_xml, collapse = TRUE))
> Error in doc_parse_raw(x, encoding = encoding, base_url = base_url, as_html = as_html,  :
>   Start tag expected, '<' not found [4]
>
> ## produces the following error message.
> Error in doc_parse_raw(x, encoding = encoding, base_url = base_url, as_html = as_html,  :
>   Start tag expected, '<' not found [4]
>
> I have similar issues with xml2::xml_find_all
> xml_find_all(str_c(with_ns_xml, collapse = TRUE), "/WorkSet//Description")
>
> ## Produces the following error message.
> Error in UseMethod("xml_find_all") :
>   no applicable method for 'xml_find_all' applied to an object of class "character"
>
>
>
> R. Mark Sharp, Ph.D.
> msharp at TxBiomed.org
>
>
>
>
>
>> On Jan 31, 2017, at 4:27 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>
>> See the last example in ?xml2::xml_find_all or use xml2::xml2::xml_ns_strip()
>>
>> Hadley
>>
>> On Tue, Jan 31, 2017 at 9:43 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>>> I am trying to read a series of XML files that use a namespace and I have failed, thus far, to discover the proper syntax. I have a reproducible example below. I have two XML character strings defined: one without a namespace and one with. I show that I can successfully extract the node using the XML string without the namespace and fail when using the XML string with the namespace.
>>>
>>> Mark
>>> PS I am having the same problem with the xml2 package and am hoping understanding one with help with the other.
>>>
>>> ##
>>> library(XML)
>>> ## The first XML text (no_ns_xml) does not have a namespace defined
>>> no_ns_xml <- c("<?xml version=\"1.0\" ?>", "<WorkSet>",
>>>               "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>>>               "</WorkSet>")
>>> l_no_ns_xml <-xmlTreeParse(no_ns_xml, asText = TRUE, getDTD = FALSE,
>>>                           useInternalNodes = TRUE)
>>> ## The node is found
>>> getNodeSet(l_no_ns_xml, "/WorkSet//Description")
>>>
>>> ## The second XML text (with_ns_xml) has a namespace defined
>>> with_ns_xml <- c("<?xml version=\"1.0\" ?>",
>>>                 "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
>>>                 "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>>>                 "</WorkSet>")
>>>
>>> l_with_ns_xml <-xmlTreeParse(with_ns_xml, asText = TRUE, getDTD = FALSE,
>>>                               useInternalNodes = TRUE)
>>> ## The node is not found
>>> getNodeSet(l_with_ns_xml, "/WorkSet//Description")
>>> ## I attempt to provide the namespace, but fail.
>>> ns <-  "http://labkey.org/etl/xml"
>>> names(ns)[1] <- "xmlns"
>>> getNodeSet(l_with_ns_xml, "/WorkSet//Description", namespaces = ns)
>>>
>>> R. Mark Sharp, Ph.D.
>>> Director of Data Science Core
>>> Southwest National Primate Research Center
>>> Texas Biomedical Research Institute
>>> P.O. Box 760549
>>> San Antonio, TX 78245-0549
>>> Telephone: (210)258-9476
>>> e-mail: msharp at TxBiomed.org
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> http://hadley.nz
>
> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.



-- 
http://hadley.nz


From xavier.chiriboga at unine.ch  Wed Feb  1 03:35:38 2017
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Wed, 1 Feb 2017 02:35:38 +0000
Subject: [R] HELP with GLM
Message-ID: <1485916541174.79517@unine.ch>

Dear colleagues,


I am trying to perform GLM ..but I got some objects masked: and an error message below


a <- read.table(file.choose(), h<-T)
> head(a)
  time treatment transinduc
1    1   CHA0+Db     1,0768
2    1   CHA0+Db     1,0706
3    1   CHA0+Db     1,0752
4    1   CHA0+Db     1,0689
5    1   CHA0+Db     1,1829
6    1    PCL+Db     1,1423
> attach(a)
The following objects are masked from a (pos = 12):

    time, transinduc, treatment

The following objects are masked from a (pos = 13):

    time, treatment

The following objects are masked from a (pos = 14):

    time, treatment

> summary(a)
      time         treatment    transinduc
 Min.   :1.000   CHA0   :10   1,0488 : 6
 1st Qu.:1.000   CHA0+Db: 9   1,0724 : 4
 Median :1.000   Db     : 9   1,0752 : 3
 Mean   :1.433   HEALTHY:15   1,0954 : 3
 3rd Qu.:2.000   PCL    :10   1,0001 : 2
 Max.   :2.000   PCL+Db :14   1,0005 : 2
                              (Other):47


m1<-glm(transinduc~time*treatment,data=a,family="poisson")
Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson' family") :
  valor ausente donde TRUE/FALSE es necesario
Adem?s: Warning message:
In Ops.factor(y, 0) : '<' not meaningful for factors


I DO NOT HAVE NEGATIVE VALUES IN MY DATASET, Do you know what is going wrong?


Thank you for you help,


Xavier

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Wed Feb  1 05:42:32 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Wed, 1 Feb 2017 04:42:32 +0000
Subject: [R] Failure to understand namespaces in XML::getNodeSet
In-Reply-To: <CABdHhvFk5-pV0cdEF7mMmZDijNfFw7i9gDAOeY_N4NV0x1Nz2Q@mail.gmail.com>
References: <C93BCEFF-3EB2-4422-8BDF-9B305E393424@txbiomed.org>
	<CABdHhvHNcQBE+YLq-V6PP9AYhBAB1Wo8DbcmELpTZovFonsCgw@mail.gmail.com>
	<BAB7A1DF-1D51-4F3A-8B2C-421E66289545@TxBiomed.org>
	<CABdHhvFk5-pV0cdEF7mMmZDijNfFw7i9gDAOeY_N4NV0x1Nz2Q@mail.gmail.com>
Message-ID: <21BF4313-A61A-4D89-9DE8-BEF08B34B43A@txbiomed.org>

Hadley,

It?s sometimes amazing the mistakes I can make. No, it did not do what I wanted, which was
read_xml(str_c(with_ns_xml, collapse = ?")

Reproducible example follows:
library(stringr)
library(xml2)
## Given the correct argument value for collapse, the next two lines work
no_ns <- read_xml(str_c(no_ns_xml, collapse = ""))
with_ns <- read_xml(str_c(with_ns_xml, collapse = ""))
## The next line finds the node in the XML without a namespace
xml_find_all(no_ns, "//WorkSet//Description")
## With a namespace designated in the XML
## Neither of the next two work, though I thought the second should
xml_find_all(with_ns, "//WorkSet//Description")
xml_find_all(with_ns, "/WorkSet//Description", ns = xml_ns(with_ns))
## Using xml_ns_strip() works as predicted
xml_find_all(xml_ns_strip(with_ns), "//WorkSet//Description")
## I was surprised to find the incorrect namespace value did not matter
xml_find_all(no_ns, "//WorkSet//Description", ns = xml_ns(with_ns))
## This also seems to ignore the namespace argument value
xml_find_all(xml_ns_strip(with_ns), "/WorkSet//Description", ns = xml_ns(with_ns))


Full output follows:
> ## Given the correct argument value for collapse, the next two lines work
> no_ns <- read_xml(str_c(no_ns_xml, collapse = ""))
> with_ns <- read_xml(str_c(with_ns_xml, collapse = ""))
> ## The next line finds the node in the XML without a namespace
> xml_find_all(no_ns, "//WorkSet//Description")
{xml_nodeset (1)}
[1] <Description>MFIA 9-Plex (CharlesRiver)</Description>
> ## With a namespace designated in the XML
> ## Neither of the next two work, though I thought the second should
> xml_find_all(with_ns, "//WorkSet//Description")
{xml_nodeset (0)}
> xml_find_all(with_ns, "/WorkSet//Description", ns = xml_ns(with_ns))
{xml_nodeset (0)}
> ## Using xml_ns_strip() works as predicted
> xml_find_all(xml_ns_strip(with_ns), "//WorkSet//Description")
{xml_nodeset (1)}
[1] <Description>MFIA 9-Plex (CharlesRiver)</Description>
> ## I was surprised to find the incorrect namespace value did not matter
> xml_find_all(no_ns, "//WorkSet//Description", ns = xml_ns(with_ns))
{xml_nodeset (1)}
[1] <Description>MFIA 9-Plex (CharlesRiver)</Description>
> ## This also seems to ignore the namespace argument value
> xml_find_all(xml_ns_strip(with_ns), "/WorkSet//Description", ns = xml_ns(with_ns))
{xml_nodeset (1)}
[1] <Description>MFIA 9-Plex (CharlesRiver)</Description>
R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Jan 31, 2017, at 5:52 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>
> I think you want
>
> x <- read_xml('<?xml version="1.0" ?>
>  <WorkSet xmlns="http://labkey.org/etl/xml">
>  <Description>MFIA 9-Plex (CharlesRiver)</Description>
> </WorkSet>')
>
> The collapse argument do what you think it does.
>
> Hadley
>
> On Tue, Jan 31, 2017 at 5:36 PM, Mark Sharp <msharp at txbiomed.org> wrote:
>> Hadley,
>>
>> Thank you. I am able to get the xml_ns_strip() function to work with my file directly so I will likely be able to reach my immediate goal.
>>
>> However, I still have had no success with understanding the namespace problem. I am not able to use read_xml() using the object I generated for the reproducible example, which is simply a character vector of length 4 having the contents of the XML file as produce by readLines(). I then used dput() to define the structure. The resulting structure apparently is not to the liking of read_xml(). I have reproduced the necessary code here for your convenience. There error is below.
>>
>> ##
>> library(xml2)
>> library(stringr)
>> with_ns_xml <- c("<?xml version=\"1.0\" ?>",
>>                 "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
>>                 "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>>                 "</WorkSet>")
>> ## without str_c() collapse it complain of a vector of length > 1 also.
>> read_xml(str_c(with_ns_xml, collapse = TRUE))
>> Error in doc_parse_raw(x, encoding = encoding, base_url = base_url, as_html = as_html,  :
>>  Start tag expected, '<' not found [4]
>>
>> ## produces the following error message.
>> Error in doc_parse_raw(x, encoding = encoding, base_url = base_url, as_html = as_html,  :
>>  Start tag expected, '<' not found [4]
>>
>> I have similar issues with xml2::xml_find_all
>> xml_find_all(str_c(with_ns_xml, collapse = TRUE), "/WorkSet//Description")
>>
>> ## Produces the following error message.
>> Error in UseMethod("xml_find_all") :
>>  no applicable method for 'xml_find_all' applied to an object of class "character"
>>
>>
>>
>> R. Mark Sharp, Ph.D.
>> msharp at TxBiomed.org
>>
>>
>>
>>
>>
>>> On Jan 31, 2017, at 4:27 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>>
>>> See the last example in ?xml2::xml_find_all or use xml2::xml2::xml_ns_strip()
>>>
>>> Hadley
>>>
>>> On Tue, Jan 31, 2017 at 9:43 AM, Mark Sharp <msharp at txbiomed.org> wrote:
>>>> I am trying to read a series of XML files that use a namespace and I have failed, thus far, to discover the proper syntax. I have a reproducible example below. I have two XML character strings defined: one without a namespace and one with. I show that I can successfully extract the node using the XML string without the namespace and fail when using the XML string with the namespace.
>>>>
>>>> Mark
>>>> PS I am having the same problem with the xml2 package and am hoping understanding one with help with the other.
>>>>
>>>> ##
>>>> library(XML)
>>>> ## The first XML text (no_ns_xml) does not have a namespace defined
>>>> no_ns_xml <- c("<?xml version=\"1.0\" ?>", "<WorkSet>",
>>>>              "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>>>>              "</WorkSet>")
>>>> l_no_ns_xml <-xmlTreeParse(no_ns_xml, asText = TRUE, getDTD = FALSE,
>>>>                          useInternalNodes = TRUE)
>>>> ## The node is found
>>>> getNodeSet(l_no_ns_xml, "/WorkSet//Description")
>>>>
>>>> ## The second XML text (with_ns_xml) has a namespace defined
>>>> with_ns_xml <- c("<?xml version=\"1.0\" ?>",
>>>>                "<WorkSet xmlns=\"http://labkey.org/etl/xml\">",
>>>>                "<Description>MFIA 9-Plex (CharlesRiver)</Description>",
>>>>                "</WorkSet>")
>>>>
>>>> l_with_ns_xml <-xmlTreeParse(with_ns_xml, asText = TRUE, getDTD = FALSE,
>>>>                              useInternalNodes = TRUE)
>>>> ## The node is not found
>>>> getNodeSet(l_with_ns_xml, "/WorkSet//Description")
>>>> ## I attempt to provide the namespace, but fail.
>>>> ns <-  "http://labkey.org/etl/xml"
>>>> names(ns)[1] <- "xmlns"
>>>> getNodeSet(l_with_ns_xml, "/WorkSet//Description", namespaces = ns)
>>>>
>>>> R. Mark Sharp, Ph.D.
>>>> Director of Data Science Core
>>>> Southwest National Primate Research Center
>>>> Texas Biomedical Research Institute
>>>> P.O. Box 760549
>>>> San Antonio, TX 78245-0549
>>>> Telephone: (210)258-9476
>>>> e-mail: msharp at TxBiomed.org
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> http://hadley.nz
>>
>> CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.
>
>
>
> --
> http://hadley.nz

CONFIDENTIALITY NOTICE: This e-mail and any files and/or attachments transmitted, may contain privileged and confidential information and is intended solely for the exclusive use of the individual or entity to whom it is addressed. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or copying of this e-mail and/or attachments is strictly prohibited. If you have received this e-mail in error, please immediately notify the sender stating that this transmission was misdirected; return the e-mail to sender; destroy all paper copies and delete all electronic copies from your system without disclosing its contents.

From drjimlemon at gmail.com  Wed Feb  1 03:00:34 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 1 Feb 2017 13:00:34 +1100
Subject: [R] caculate correlation
In-Reply-To: <365545092.573912.1485862274417@mail.yahoo.com>
References: <379992977.4826084.1485805205593.ref@mail.yahoo.com>
	<379992977.4826084.1485805205593@mail.yahoo.com>
	<CA+8X3fWFVwWYZRpQ-13rBNVRASUATtU4mWde=RrN3n2U8EMv_Q@mail.gmail.com>
	<1908713206.125008.1485812723647@mail.yahoo.com>
	<CA+8X3fWt31bvm=OTOBZvFdcSvb1RWAjMnLpHfvJHH0w5kb=zPw@mail.gmail.com>
	<579290005.175382.1485814667600@mail.yahoo.com>
	<CA+8X3fXsqP=zwHGODvzUujE4v8YsQy7kZ797B_eDq-qXK+qOKA@mail.gmail.com>
	<705924209.578370.1485851300485@mail.yahoo.com>
	<CA+8X3fVV5Q4bbjHjN2SrTdEnyaTyesmNvbUSuTY4nSPHHDpvwA@mail.gmail.com>
	<365545092.573912.1485862274417@mail.yahoo.com>
Message-ID: <CA+8X3fWPbz0-4hpaVfxkqhD2op5AcTGqbumN8x+DQkuwLYER_Q@mail.gmail.com>

Hi Elham,
It looks to me as though you are looking for matches in the name field
and then asking for all columns except the first (-1). If you only
have two columns in "coding.rpkm", and "name" is the first column, you
will get whatever is in the second column that has a match in the
"name" column. I suspect that whatever you are doing to whatever is in
the data frames is just returning names, and without knowing what the
data frames look like, nobody can tell you what is going wrong.

Jim


On Tue, Jan 31, 2017 at 10:31 PM, Elham - <ed_isfahani at yahoo.com> wrote:
> thank you for replay dear Jim,
> actually I`m new in R and I asked the person that teach correlation to
> me,but I have problem in it.
> please guide me, I can not understand why notwithstanding I transpose data,
> I do not have number in coding.rpkm[grep("23.C",coding.rpkm$name),-1]  and
> there is gene name instead of number
>
>
> On Tuesday, January 31, 2017 12:20 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
>
> Hi Elham,
>
> On Tue, Jan 31, 2017 at 7:28 PM, Elham - <ed_isfahani at yahoo.com> wrote:
>> Hi Dear Jim,
>>
>> I did it, both return a vector of name of the genes with different
>> length,as
>> I said before I have list of coding and noncoding so the length are not
>> same.
>>
>> where is number?!
>>
> Not in the values you are extracting from the data frame. As you are
> aware, you can only perform the "cor" operation on numbers. As the
> value returned refers to the correlation of _pairs_ of values, the
> vectors of numbers should be the same length and there should be some
> meaningful relationship between those pairs. Are you just trying to
> correlate any old numbers because they are numbers?
>
>> and at the end of print there is this error :
>>
>> <0 rows> (or 0-length row.names)
>>
> This is probably not an error, just R telling you that something that
> was requested didn't have anything in it. Maybe one day we will find
> out what is in:
>
> coding.rpkm
> ncoding.rpkm
>
> and we can provide more informed advice.
>
>
> Jim
>
>


From karen.castillioni at gmail.com  Wed Feb  1 03:29:39 2017
From: karen.castillioni at gmail.com (Karen Castillioni)
Date: Tue, 31 Jan 2017 20:29:39 -0600
Subject: [R] Error in mcp2matrix(model, linfct = linfct)
Message-ID: <DD177870-9EB9-408B-B6D3-A647C8CF8F03@gmail.com>

Problem: Error in mcp2matrix(model, linfct = linfct)

Post hoc test is not working. Does anyone know what I did wrong?

modmisto<-lme(Cobertura~Tratamento, random=~1|Parcela, data=Cover_BraquiT3) summary(modmisto)

tukey<-glht(modmisto, mcp(Tratamento="Tukey")) Error in mcp2matrix(model, linfct = linfct) : Variable(s) ?Tratamento? of class ?character? is/are not contained as a factor in ?model?.
Some translations if necessary: cobertura=cover, tratamento=treatment, parcela=plot

I have 4 treatments being tested.

Any help with this will be very appreciated!

Thank you
	[[alternative HTML version deleted]]


From Ronald.Taylor at pnnl.gov  Wed Feb  1 01:30:26 2017
From: Ronald.Taylor at pnnl.gov (Taylor, Ronald C)
Date: Wed, 1 Feb 2017 00:30:26 +0000
Subject: [R] need help in trying out sparklyr - spark_connect will not work
Message-ID: <9630E5FD91504140A3479FBFBE1837B51BD30C47@EX10MBOX03.pnnl.gov>

Hello R-help list,

I am a new list member. My first question: I was trying out sparklyr (in R ver 3.3.2) on my Red Hat Linux workstation, following the instructions at spark.rstudio.com as to how to download and use a local copy of Spark. The Spark download appears to work. However, when I try to the do the spark_connect, to get started, I get the error msgs that  you see below.

I cannot find any guidance as to how to fix this. Quite frustrating. Can somebody give me a bit of help? Does something need to be added to my PATH env var in my .mycshrc file, for example? Is there a closed port problem? Has anybody run into this type of error msg? Do I need to do something additional to start up the local copy of Spark that is not mentioned in the RStudio online documentation?


-          Ron


%%%%%%%%%%%%%%%%%%%%

> spark_install(version = "1.6.2")
Installing Spark 1.6.2 for Hadoop 2.6 or later.
Downloading from:
- 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
Installing to:
- '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'
trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
Content type 'application/x-tar' length 278057117 bytes (265.2 MB)
==================================================
downloaded 265.2 MB

Installation complete.
>
> sc <- spark_connect(master = "local")
Error in force(code) :
  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.
    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit
    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689


---- Output Log ----
/home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory

---- Error Log ----
>


%%%%%%%%%%%%%%%%%%

Full screen output of my R session, from the R invocation on:

sidney115% R

R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-redhat-linux-gnu (64-bit)
>
> library(sparklyr)
>
> ls(pos = "package:sparklyr")
  [1] "%>%"
  [2] "compile_package_jars"
  [3] "connection_config"
  [4] "connection_is_open"
  [5] "copy_to"
  [6] "ensure_scalar_boolean"
  [7] "ensure_scalar_character"
  [8] "ensure_scalar_double"
  [9] "ensure_scalar_integer"
 [10] "find_scalac"
 [11] "ft_binarizer"
 [12] "ft_bucketizer"
 [13] "ft_discrete_cosine_transform"
 [14] "ft_elementwise_product"
 [15] "ft_index_to_string"
 [16] "ft_one_hot_encoder"
 [17] "ft_quantile_discretizer"
 [18] "ft_regex_tokenizer"
 [19] "ft_sql_transformer"
 [20] "ft_string_indexer"
 [21] "ft_tokenizer"
 [22] "ft_vector_assembler"
 [23] "hive_context"
 [24] "invoke"
 [25] "invoke_method"
 [26] "invoke_new"
 [27] "invoke_static"
 [28] "java_context"
 [29] "livy_available_versions"
 [30] "livy_config"
 [31] "livy_home_dir"
 [32] "livy_install"
 [33] "livy_install_dir"
 [34] "livy_installed_versions"
 [35] "livy_service_start"
 [36] "livy_service_stop"
 [37] "ml_als_factorization"
 [38] "ml_binary_classification_eval"
 [39] "ml_classification_eval"
 [40] "ml_create_dummy_variables"
 [41] "ml_decision_tree"
 [42] "ml_generalized_linear_regression"
 [43] "ml_gradient_boosted_trees"
 [44] "ml_kmeans"
 [45] "ml_lda"
 [46] "ml_linear_regression"
 [47] "ml_load"
 [48] "ml_logistic_regression"
 [49] "ml_model"
 [50] "ml_multilayer_perceptron"
 [51] "ml_naive_bayes"
 [52] "ml_one_vs_rest"
 [53] "ml_options"
 [54] "ml_pca"
 [55] "ml_prepare_dataframe"
 [56] "ml_prepare_features"
 [57] "ml_prepare_response_features_intercept"
[58] "ml_random_forest"
 [59] "ml_save"
 [60] "ml_survival_regression"
 [61] "ml_tree_feature_importance"
 [62] "na.replace"
 [63] "print_jobj"
 [64] "register_extension"
 [65] "registered_extensions"
 [66] "sdf_copy_to"
 [67] "sdf_import"
 [68] "sdf_load_parquet"
 [69] "sdf_load_table"
 [70] "sdf_mutate"
 [71] "sdf_mutate_"
 [72] "sdf_partition"
 [73] "sdf_persist"
 [74] "sdf_predict"
 [75] "sdf_quantile"
 [76] "sdf_read_column"
 [77] "sdf_register"
 [78] "sdf_sample"
 [79] "sdf_save_parquet"
 [80] "sdf_save_table"
 [81] "sdf_schema"
 [82] "sdf_sort"
 [83] "sdf_with_unique_id"
 [84] "spark_available_versions"
 [85] "spark_compilation_spec"
 [86] "spark_compile"
 [87] "spark_config"
 [88] "spark_connect"
 [89] "spark_connection"
 [90] "spark_connection_is_open"
 [91] "spark_context"
 [92] "spark_dataframe"
 [93] "spark_default_compilation_spec"
 [94] "spark_dependency"
 [95] "spark_disconnect"
 [96] "spark_disconnect_all"
 [97] "spark_home_dir"
 [98] "spark_install"
 [99] "spark_install_dir"
[100] "spark_install_tar"
[101] "spark_installed_versions"
[102] "spark_jobj"
[103] "spark_load_table"
[104] "spark_log"
[105] "spark_read_csv"
[106] "spark_read_json"
[107] "spark_read_parquet"
[108] "spark_save_table"
[109] "spark_session"
[110] "spark_uninstall"
[111] "spark_version"
[112] "spark_version_from_home"
[113] "spark_web"
[114] "spark_write_csv"
[115] "spark_write_json"
[116] "spark_write_parquet"
[117] "tbl_cache"
[118] "tbl_uncache"
>
>
>
> spark_install(version = "1.6.2")
Installing Spark 1.6.2 for Hadoop 2.6 or later.
Downloading from:
- 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
Installing to:
- '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'
trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
Content type 'application/x-tar' length 278057117 bytes (265.2 MB)
==================================================
downloaded 265.2 MB

Installation complete.
>
> sc <- spark_connect(master = "local")
Error in force(code) :
  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.
    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit
    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689


---- Output Log ----
/home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory

---- Error Log ----
>

%%%%%%%%%%%%%%%%%%

Ronald C. Taylor, Ph.D.
Computational Biology & Bioinformatics Group
Pacific Northwest National Laboratory (U.S. Dept of Energy/Battelle)
Richland, WA 99352
phone: (509) 372-6568,  email: ronald.taylor at pnnl.gov
web page:  http://www.pnnl.gov/science/staff/staff_info.asp?staff_num=7048


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Feb  1 06:06:48 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 31 Jan 2017 21:06:48 -0800
Subject: [R] HELP with GLM
In-Reply-To: <1485916541174.79517@unine.ch>
References: <1485916541174.79517@unine.ch>
Message-ID: <147697CC-368A-4993-AB79-F797D6C244F4@comcast.net>


> On Jan 31, 2017, at 6:35 PM, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:
> 
> Dear colleagues,
> 
> 
> I am trying to perform GLM ..but I got some objects masked: and an error message below
> 
> 
> a <- read.table(file.choose(), h<-T)
>> head(a)
>  time treatment transinduc
> 1    1   CHA0+Db     1,0768

Do note htat transinduc came in as a factor variable, not numeric.

> 2    1   CHA0+Db     1,0706
> 3    1   CHA0+Db     1,0752
> 4    1   CHA0+Db     1,0689
> 5    1   CHA0+Db     1,1829
> 6    1    PCL+Db     1,1423
>> attach(a)
> The following objects are masked from a (pos = 12):
> 
>    time, transinduc, treatment
> 
> The following objects are masked from a (pos = 13):
> 
>    time, treatment
> 
> The following objects are masked from a (pos = 14):
> 
>    time, treatment
> 
>> summary(a)
>      time         treatment    transinduc
> Min.   :1.000   CHA0   :10   1,0488 : 6
> 1st Qu.:1.000   CHA0+Db: 9   1,0724 : 4
> Median :1.000   Db     : 9   1,0752 : 3
> Mean   :1.433   HEALTHY:15   1,0954 : 3
> 3rd Qu.:2.000   PCL    :10   1,0001 : 2
> Max.   :2.000   PCL+Db :14   1,0005 : 2
>                              (Other):47
> 
> 
> m1<-glm(transinduc~time*treatment,data=a,family="poisson")
> Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson' family") :
>  valor ausente donde TRUE/FALSE es necesario
> Adem?s: Warning message:
> In Ops.factor(y, 0) : '<' not meaningful for factors
> 
> 
> I DO NOT HAVE NEGATIVE VALUES IN MY DATASET, Do you know what is going wrong?


DO NOT USE `attach`. THAT'S PROBABLY WHAT IS WRONG.
> 
> 
> Thank you for you help,
> 
> 
> Xavier
> 
> 	[[alternative HTML version deleted]]

	And do not post in HTML. Please read the Posting Guide.

____________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Wed Feb  1 06:10:48 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 31 Jan 2017 21:10:48 -0800
Subject: [R] HELP with GLM
In-Reply-To: <1485916541174.79517@unine.ch>
References: <1485916541174.79517@unine.ch>
Message-ID: <CAGxFJbQTkKqrLUZwghiDhKORuwCm79rBesX6B6xVM-Tjga10Bg@mail.gmail.com>

Dear Xavier:

It sounds like you have a right mess! Perhaps others cleverer and more
diligent than I can sort through it and diagnose the problem. However,
it really *does* sound like you need to step back, take a deep breath,
and spend some time with an R tutorial or two (there are many good
ones on teh web) to learn how R works before proceeding further. You
seem to be groping around in the dark.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jan 31, 2017 at 6:35 PM, CHIRIBOGA Xavier
<xavier.chiriboga at unine.ch> wrote:
> Dear colleagues,
>
>
> I am trying to perform GLM ..but I got some objects masked: and an error message below
>
>
> a <- read.table(file.choose(), h<-T)
>> head(a)
>   time treatment transinduc
> 1    1   CHA0+Db     1,0768
> 2    1   CHA0+Db     1,0706
> 3    1   CHA0+Db     1,0752
> 4    1   CHA0+Db     1,0689
> 5    1   CHA0+Db     1,1829
> 6    1    PCL+Db     1,1423
>> attach(a)
> The following objects are masked from a (pos = 12):
>
>     time, transinduc, treatment
>
> The following objects are masked from a (pos = 13):
>
>     time, treatment
>
> The following objects are masked from a (pos = 14):
>
>     time, treatment
>
>> summary(a)
>       time         treatment    transinduc
>  Min.   :1.000   CHA0   :10   1,0488 : 6
>  1st Qu.:1.000   CHA0+Db: 9   1,0724 : 4
>  Median :1.000   Db     : 9   1,0752 : 3
>  Mean   :1.433   HEALTHY:15   1,0954 : 3
>  3rd Qu.:2.000   PCL    :10   1,0001 : 2
>  Max.   :2.000   PCL+Db :14   1,0005 : 2
>                               (Other):47
>
>
> m1<-glm(transinduc~time*treatment,data=a,family="poisson")
> Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson' family") :
>   valor ausente donde TRUE/FALSE es necesario
> Adem?s: Warning message:
> In Ops.factor(y, 0) : '<' not meaningful for factors
>
>
> I DO NOT HAVE NEGATIVE VALUES IN MY DATASET, Do you know what is going wrong?
>
>
> Thank you for you help,
>
>
> Xavier
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Feb  1 08:18:44 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 1 Feb 2017 18:18:44 +1100
Subject: [R] sub-setting rows based on dates in R
In-Reply-To: <KL1PR01MB0999FC07E36B092AFAD82C44B64A0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB0999FC07E36B092AFAD82C44B64A0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fWWO1yMpEqDUx7Xt4Tck1NpymvzaUwACYTGhMn0EqsVOQ@mail.gmail.com>

Hi Md,
This kind of clunky, but it might do what you want.

df1<-read.table(text="Date    Rainfall_Duration
 6/14/2016       10
 6/15/2016       20
 6/17/2016       10
 8/16/2016       30
 8/19/2016       40",
 header=TRUE,stringsAsFactors=FALSE)

df1$Date<-as.Date(df1$Date,"%m/%d/%Y")

df2<-read.table(text="Date    Removal.Rate
 6/17/2016    64.7
 6/30/2016    22.63
 7/14/2016    18.18
 8/19/2016    27.87",
 header=TRUE,stringsAsFactors=FALSE)

df2$Date<-as.Date(df2$Date,"%m/%d/%Y")

df3<-data.frame(Rate.Removal.Date=NULL,Date=NULL,Rainfall_Duration=NULL)

df3row<-0

for(i in 1:dim(df2)[1]) {
 rdrows<-which(df2$Date[i] >= df1$Date & !(df2$Date[i] > df1$Date + 8))
 if(!length(rdrows)) rdrows<-lastrows
 lastrows<-rdrows
 nrows<-length(rdrows)
 for(row in 1:nrows) {
  df3[row+df3row,1]<-format(df2$Date[i],"%m/%d/%Y")
  df3[row+df3row,2]<-format(df1$Date[rdrows[row]],"%m/%d/%Y")
  df3[row+df3row,3]<-df1$Rainfall_Duration[rdrows[row]]
 }
 df3row<-df3row+nrows
}

names(df3)<-c("Rate.Removal.Date","Date","Rainfall_Duration")
df3

Jim

On Wed, Feb 1, 2017 at 3:48 AM, Md Sami Bin Shokrana <samimist at live.com> wrote:
> Hello guys, I am trying to solve a problem in R. I have 2 data frames which look like this:
> df1 <-
>   Date    Rainfall_Duration
> 6/14/2016       10
> 6/15/2016       20
> 6/17/2016       10
> 8/16/2016       30
> 8/19/2016       40
>
> df2 <-
>   Date    Removal.Rate
> 6/17/2016    64.7
> 6/30/2016    22.63
> 7/14/2016    18.18
> 8/19/2016    27.87
>
> I want to look up the dates from df2 in df1 and their corresponding Rainfall_Duration data. For example, I want to look for the 1st date of df2 in df1 and subset rows in df1 for that specific date and 7 days prior to that. additionally, for example: for 6/30/2016 (in df2) there is no dates available in df1 within it's 7 days range. So, in this case I just want to extract the results same as it's previous date (6/17/2016) in df2. Same logic goes for 7/14/2016(df2).
> The output should look like this:
>
> df3<-
>
> Rate.Removal.Date      Date             Rainfall_Duration
> 6/17/2016              6/14/2016              10
> 6/17/2016              6/15/2016              20
> 6/17/2016              6/17/2016              10
> 6/30/2016              6/14/2016              10
> 6/30/2016              6/15/2016              20
> 6/30/2016              6/17/2016              10
> 7/14/2016              6/14/2016              10
> 7/14/2016              6/15/2016              20
> 7/14/2016              6/17/2016              10
> 8/19/2016              8/16/2016              30
> 8/19/2016              8/19/2016              40
>
> I could subset data for the 7 days range. But could not do it when no dates are available in that range. I have the following code:
> library(plyr)
> library (dplyr)
> df1$Date <- as.Date(df1$Date,format = "%m/%d/%Y")
> df2$Date <- as.Date(df2$Date,format = "%m/%d/%Y")
>
> df3 <- lapply(df2$Date, function(x){
>   filter(df1, between(Date, x-7, x))
> })
>
> names(df3) <- as.character(df2$Date)
> bind_rows(df3, .id = "Rate.Removal.Date")
> df3 <- ldply (df3, data.frame, .id = "Rate.Removal.Date")
>
> I hope I could explain my problem properly. I would highly appreciate if someone can help me out with this code or a new one. Thanks in advance.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Feb  1 08:58:29 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 31 Jan 2017 23:58:29 -0800
Subject: [R] Error in mcp2matrix(model, linfct = linfct)
In-Reply-To: <DD177870-9EB9-408B-B6D3-A647C8CF8F03@gmail.com>
References: <DD177870-9EB9-408B-B6D3-A647C8CF8F03@gmail.com>
Message-ID: <1C56FA54-76F2-4A1F-B0E5-56EB2E486A0E@dcn.davis.ca.us>

Looks like your data are not numeric. Examine your data with the str function and troubleshoot your process for reading in data. Step through the code one line at a time and see how the data looks at each step. 

Also, you really need to read the Posting Guide and follow the advice there. If you had done so, we could be more specific about how to fix your problem. 
-- 
Sent from my phone. Please excuse my brevity.

On January 31, 2017 6:29:39 PM PST, Karen Castillioni <karen.castillioni at gmail.com> wrote:
>Problem: Error in mcp2matrix(model, linfct = linfct)
>
>Post hoc test is not working. Does anyone know what I did wrong?
>
>modmisto<-lme(Cobertura~Tratamento, random=~1|Parcela,
>data=Cover_BraquiT3) summary(modmisto)
>
>tukey<-glht(modmisto, mcp(Tratamento="Tukey")) Error in
>mcp2matrix(model, linfct = linfct) : Variable(s) ?Tratamento? of class
>?character? is/are not contained as a factor in ?model?.
>Some translations if necessary: cobertura=cover, tratamento=treatment,
>parcela=plot
>
>I have 4 treatments being tested.
>
>Any help with this will be very appreciated!
>
>Thank you
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Feb  1 09:00:14 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 1 Feb 2017 08:00:14 +0000
Subject: [R] HELP with GLM
In-Reply-To: <CAGxFJbQTkKqrLUZwghiDhKORuwCm79rBesX6B6xVM-Tjga10Bg@mail.gmail.com>
References: <1485916541174.79517@unine.ch>
	<CAGxFJbQTkKqrLUZwghiDhKORuwCm79rBesX6B6xVM-Tjga10Bg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A14004@SRVEXCHCM301.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
> Gunter
> Sent: Wednesday, February 1, 2017 6:11 AM
> To: CHIRIBOGA Xavier <xavier.chiriboga at unine.ch>
> Cc: r-help at r-project.org
> Subject: Re: [R] HELP with GLM
>
> Dear Xavier:
>
> It sounds like you have a right mess! Perhaps others cleverer and more
> diligent than I can sort through it and diagnose the problem. However, it
> really *does* sound like you need to step back, take a deep breath, and
> spend some time with an R tutorial or two (there are many good ones on teh
> web) to learn how R works before proceeding further. You seem to be
> groping around in the dark.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Jan 31, 2017 at 6:35 PM, CHIRIBOGA Xavier
> <xavier.chiriboga at unine.ch> wrote:
> > Dear colleagues,
> >
> >
> > I am trying to perform GLM ..but I got some objects masked: and an
> > error message below
> >
> >
> > a <- read.table(file.choose(), h<-T)
> >> head(a)
> >   time treatment transinduc
> > 1    1   CHA0+Db     1,0768
> > 2    1   CHA0+Db     1,0706
> > 3    1   CHA0+Db     1,0752
> > 4    1   CHA0+Db     1,0689
> > 5    1   CHA0+Db     1,1829
> > 6    1    PCL+Db     1,1423
 >> attach(a)

Attach can be problematic as you have probably objects named time, transinduc, ... etc in your environment. However your glm problem is that you do not have numbers in your data but factors. What you think that are numbers they are not, which is clearly seen from your summary(a)

Your read table should have parameter dec=",".

Cheers
Petr



> > The following objects are masked from a (pos = 12):
> >
> >     time, transinduc, treatment
> >
> > The following objects are masked from a (pos = 13):
> >
> >     time, treatment
> >
> > The following objects are masked from a (pos = 14):
> >
> >     time, treatment
> >
> >> summary(a)
> >       time         treatment    transinduc
> >  Min.   :1.000   CHA0   :10   1,0488 : 6
> >  1st Qu.:1.000   CHA0+Db: 9   1,0724 : 4
> >  Median :1.000   Db     : 9   1,0752 : 3
> >  Mean   :1.433   HEALTHY:15   1,0954 : 3
> >  3rd Qu.:2.000   PCL    :10   1,0001 : 2
> >  Max.   :2.000   PCL+Db :14   1,0005 : 2
> >                               (Other):47
> >
> >
> > m1<-glm(transinduc~time*treatment,data=a,family="poisson")
> > Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson'
> family") :
> >   valor ausente donde TRUE/FALSE es necesario
> > Adem?s: Warning message:
> > In Ops.factor(y, 0) : '<' not meaningful for factors
> >
> >
> > I DO NOT HAVE NEGATIVE VALUES IN MY DATASET, Do you know what is
> going wrong?
> >
> >
> > Thank you for you help,
> >
> >
> > Xavier
> >
> >         [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From xavier.chiriboga at unine.ch  Wed Feb  1 14:28:18 2017
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Wed, 1 Feb 2017 13:28:18 +0000
Subject: [R] GLM HELP NEEDED!
Message-ID: <1485955701753.68218@unine.ch>

Dear colleagues,


I am trying to perform a GLM. I tried again without using attach()...but still is not working.

Do you have any idea to help me?


Thank you again,


Xavier



a <- read.table(file.choose(), h<-T)
> head(a)
  time treatment transinduc
1    1   CHA0+Db     1,0768
2    1   CHA0+Db     1,0706
3    1   CHA0+Db     1,0752
4    1   CHA0+Db     1,0689
5    1   CHA0+Db     1,1829
6    1    PCL+Db     1,1423
> summary(a)
      time         treatment    transinduc
 Min.   :1.000   CHA0   :10   1,0488 : 6
 1st Qu.:1.000   CHA0+Db: 9   1,0724 : 4
 Median :1.000   Db     : 9   1,0752 : 3
 Mean   :1.433   HEALTHY:15   1,0954 : 3
 3rd Qu.:2.000   PCL    :10   1,0001 : 2
 Max.   :2.000   PCL+Db :14   1,0005 : 2
                              (Other):47
> m1<-glm(a$transinduc~a$time*a$treatment,data=a,family="poisson")
Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson' family") :
  valor ausente donde TRUE/FALSE es necesario
Adem?s: Warning message:
In Ops.factor(y, 0) : '<' not meaningful for factors


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Feb  1 15:01:16 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 1 Feb 2017 09:01:16 -0500
Subject: [R] GLM HELP NEEDED!
In-Reply-To: <1485955701753.68218@unine.ch>
References: <1485955701753.68218@unine.ch>
Message-ID: <fe3eccff-bd22-59d0-f7dc-18c9bca44d46@gmail.com>

On 01/02/2017 8:28 AM, CHIRIBOGA Xavier wrote:
> Dear colleagues,
>
>
> I am trying to perform a GLM. I tried again without using attach()...but still is not working.
>
> Do you have any idea to help me?
>
>
> Thank you again,
>
>
> Xavier
>
>
>
> a <- read.table(file.choose(), h<-T)

The "h<-T" argument doesn't make sense.  You are just lucky that it 
worked here. For arguments you almost always use "=".

It's also a bad idea to use "T" as an abbreviation for "TRUE", but that 
won't always cause problems.

>> head(a)
>   time treatment transinduc
> 1    1   CHA0+Db     1,0768
> 2    1   CHA0+Db     1,0706
> 3    1   CHA0+Db     1,0752
> 4    1   CHA0+Db     1,0689
> 5    1   CHA0+Db     1,1829
> 6    1    PCL+Db     1,1423

I assume that transinduc is supposed to be real numbers, with comma as 
the decimal separator.  You need to use dec = "," in read.table to read 
that properly.

>> summary(a)
>       time         treatment    transinduc
>  Min.   :1.000   CHA0   :10   1,0488 : 6
>  1st Qu.:1.000   CHA0+Db: 9   1,0724 : 4
>  Median :1.000   Db     : 9   1,0752 : 3
>  Mean   :1.433   HEALTHY:15   1,0954 : 3
>  3rd Qu.:2.000   PCL    :10   1,0001 : 2
>  Max.   :2.000   PCL+Db :14   1,0005 : 2
>                               (Other):47
>> m1<-glm(a$transinduc~a$time*a$treatment,data=a,family="poisson")
> Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson' family") :
>   valor ausente donde TRUE/FALSE es necesario
> Adem?s: Warning message:
> In Ops.factor(y, 0) : '<' not meaningful for factors

It doesn't make sense to use fractional values like 1.0488 in Poisson 
regression.

Duncan Murdoch


From hannah.lysandrou at laserwarehouse.co.uk  Wed Feb  1 13:09:47 2017
From: hannah.lysandrou at laserwarehouse.co.uk (=?UTF-8?Q?Laser=20Warehouse?=)
Date: Wed, 01 Feb 2017 13:09:47 +0100
Subject: [R] =?utf-8?q?Cost_effective_Laser_and_IPL_servicing=2E_Alma=2C_C?=
	=?utf-8?q?ynosure=2C_Candela=2C_Fotona=2C_Lumenis=E2=80=A6?=
Message-ID: <201702011309.1ux4n6m01xfj@bw.d.mailin.fr>

If you are not able to see this mail, click http://rcwo.r.ca.d.sendibm2.com/9jdkuam01xff.html[  ]( http://rcwo.r.ca.d.sendibm2.com/125ibd65a01xfd.html ) [  ]( http://rcwo.r.ca.d.sendibm2.com/125ibd6xq01xfd.html )


The Laser Warehouse is the UK?s leading independent provider of on site, superior quality, cost-effective laser and IPL services. Our experience and extensive supplier network make The Laser Warehouse your single, trusted source for maintenance and servicing of your medical laser and IPL (Intense Pulsed Light) systems.

We can save you ?1000?s over your main dealer service prices! For many years, the main dealers have charged their customers high prices for the maintenance and servicing of their laser and IPL systems, simply because they could! This is now changing as independent service companies such as ourselves can save you and your clinic many ?1000?s compared to what your main dealer will charge you.

[  ]( http://rcwo.r.ca.d.sendibm2.com/125ibd7q601xfd.html )
?
[  ]( http://rcwo.r.ca.d.sendibm2.com/125ibd8im01xfd.html )

We use either genuine or after-market spares and our service engineers are familiar with all the major makes of laser and IPL systems. Our engineers have over 35 years? laser and IPL servicing experience between them so their experience speaks for itself.

We have hundreds of customers across the UK and we are only too happy to put you in touch with them for testimonials on our service provision.


[  ]( http://rcwo.r.ca.d.sendibm2.com/125ibd9b201xfd.html ) ?If you wish to unsubscribe from our newsletter, click http://rcwo.r.ca.d.sendibm2.com/9jdkuam01xfg.html


	[[alternative HTML version deleted]]


From hannah.lysandrou at laserwarehouse.co.uk  Wed Feb  1 13:09:47 2017
From: hannah.lysandrou at laserwarehouse.co.uk (=?UTF-8?Q?Laser=20Warehouse?=)
Date: Wed, 1 Feb 2017 13:09:47 +0100
Subject: [R] =?utf-8?q?Cost_effective_Laser_and_IPL_servicing=2E_Alma=2C_C?=
	=?utf-8?q?ynosure=2C_Candela=2C_Fotona=2C_Lumenis=E2=80=A6?=
Message-ID: <201702011309.1ux4uam01xfj@bw.d.mailin.fr>

If you are not able to see this mail, click http://rcwo.r.ca.d.sendibm2.com/9jn26am01xff.html[  ]( http://rcwo.r.ca.d.sendibm2.com/126k8p65a01xfd.html ) [  ]( http://rcwo.r.ca.d.sendibm2.com/126k8p6xq01xfd.html )


The Laser Warehouse is the UK?s leading independent provider of on site, superior quality, cost-effective laser and IPL services. Our experience and extensive supplier network make The Laser Warehouse your single, trusted source for maintenance and servicing of your medical laser and IPL (Intense Pulsed Light) systems.

We can save you ?1000?s over your main dealer service prices! For many years, the main dealers have charged their customers high prices for the maintenance and servicing of their laser and IPL systems, simply because they could! This is now changing as independent service companies such as ourselves can save you and your clinic many ?1000?s compared to what your main dealer will charge you.

[  ]( http://rcwo.r.ca.d.sendibm2.com/126k8p7q601xfd.html )
?
[  ]( http://rcwo.r.ca.d.sendibm2.com/126k8p8im01xfd.html )

We use either genuine or after-market spares and our service engineers are familiar with all the major makes of laser and IPL systems. Our engineers have over 35 years? laser and IPL servicing experience between them so their experience speaks for itself.

We have hundreds of customers across the UK and we are only too happy to put you in touch with them for testimonials on our service provision.


[  ]( http://rcwo.r.ca.d.sendibm2.com/126k8p9b201xfd.html ) ?If you wish to unsubscribe from our newsletter, click http://rcwo.r.ca.d.sendibm2.com/9jn26am01xfg.html


	[[alternative HTML version deleted]]


From igomez at zencos.com  Wed Feb  1 15:11:02 2017
From: igomez at zencos.com (Ivan Gomez)
Date: Wed, 1 Feb 2017 14:11:02 +0000
Subject: [R] Help Installing RODBC with custom header locations
Message-ID: <CY4PR08MB2838123262534D7373235637A84D0@CY4PR08MB2838.namprd08.prod.outlook.com>

Hi all,

I'm trying to install.packages("RODBC") , but it is failing because it cannot find certain required header files:

....
"configure: error: "ODBC headers sql.h and sqlext.h not found"

I believe this is because my header files are in a custom location instead of the standard system folder:

comp1:/gpfs/grid/progress/include # ll
total 184
-rw-r--r--. 1 1494 400 4894 Oct 24 2012 odbcinst.h
-rw-r--r--. 1 1494 400 26858 Oct 24 2012 qesqlext.h
-rw-r--r--. 1 1494 400 79606 Oct 24 2012 sqlext.h
-rw-r--r--. 1 1494 400 30106 Oct 24 2012 sql.h
-rw-r--r--. 1 1494 400 8002 Oct 24 2012 sqltypes.h
-rw-r--r--. 1 1494 400 22715 Oct 24 2012 sqlucode.h
-rw-r--r--. 1 1494 400 1354 Oct 24 2012 sqlunx.h



Could you please show me how I can tell the install command to look for the header files in this custom directory or point me towards an example of a similar case?
Thank you very much for your time,
Ivan G.


	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Wed Feb  1 16:31:07 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 01 Feb 2017 09:31:07 -0600
Subject: [R] Help Installing RODBC with custom header locations
In-Reply-To: <CY4PR08MB2838123262534D7373235637A84D0@CY4PR08MB2838.namprd08.prod.outlook.com>
References: <CY4PR08MB2838123262534D7373235637A84D0@CY4PR08MB2838.namprd08.prod.outlook.com>
Message-ID: <F661522A-C61B-4AA0-9CE3-033ED4CC26D2@me.com>

> On Feb 1, 2017, at 8:11 AM, Ivan Gomez <igomez at zencos.com> wrote:
> 
> Hi all,
> 
> I'm trying to install.packages("RODBC") , but it is failing because it cannot find certain required header files:
> 
> ....
> "configure: error: "ODBC headers sql.h and sqlext.h not found"
> 
> I believe this is because my header files are in a custom location instead of the standard system folder:
> 
> comp1:/gpfs/grid/progress/include # ll
> total 184
> -rw-r--r--. 1 1494 400 4894 Oct 24 2012 odbcinst.h
> -rw-r--r--. 1 1494 400 26858 Oct 24 2012 qesqlext.h
> -rw-r--r--. 1 1494 400 79606 Oct 24 2012 sqlext.h
> -rw-r--r--. 1 1494 400 30106 Oct 24 2012 sql.h
> -rw-r--r--. 1 1494 400 8002 Oct 24 2012 sqltypes.h
> -rw-r--r--. 1 1494 400 22715 Oct 24 2012 sqlucode.h
> -rw-r--r--. 1 1494 400 1354 Oct 24 2012 sqlunx.h
> 
> 
> 
> Could you please show me how I can tell the install command to look for the header files in this custom directory or point me towards an example of a similar case?
> Thank you very much for your time,
> Ivan G.
> 


Hi,

For future reference, this subject matter should go to R-SIG-DB:

  https://stat.ethz.ch/mailman/listinfo/r-sig-db


You can use an invocation along the lines of:

install.packages("RODBC",
                 configure.args = "--with-odbc-include=/gpfs/grid/progress/include/")

where the 'configure.args' argument has the FULL path to the header files.

There is detailed installation information in the vignette for the package on CRAN:

  https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf


Regards,

Marc Schwartz


From dwinsemius at comcast.net  Wed Feb  1 17:17:12 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Feb 2017 08:17:12 -0800
Subject: [R] GLM HELP NEEDED!
In-Reply-To: <1485955701753.68218@unine.ch>
References: <1485955701753.68218@unine.ch>
Message-ID: <5BA2D79B-164E-4040-B55C-3DC2132DCFD3@comcast.net>


> On Feb 1, 2017, at 5:28 AM, CHIRIBOGA Xavier <xavier.chiriboga at unine.ch> wrote:
> 
> Dear colleagues,
> 
> 
> I am trying to perform a GLM. I tried again without using attach()...but still is not working.
> 
> Do you have any idea to help me?
> 
> 
> Thank you again,
> 
> 
> Xavier
> 
> 
> 
> a <- read.table(file.choose(), h<-T)
>> head(a)
>  time treatment transinduc
> 1    1   CHA0+Db     1,0768
> 2    1   CHA0+Db     1,0706
> 3    1   CHA0+Db     1,0752
> 4    1   CHA0+Db     1,0689
> 5    1   CHA0+Db     1,1829
> 6    1    PCL+Db     1,1423
>> summary(a)
>      time         treatment    transinduc
> Min.   :1.000   CHA0   :10   1,0488 : 6
> 1st Qu.:1.000   CHA0+Db: 9   1,0724 : 4
> Median :1.000   Db     : 9   1,0752 : 3
> Mean   :1.433   HEALTHY:15   1,0954 : 3
> 3rd Qu.:2.000   PCL    :10   1,0001 : 2
> Max.   :2.000   PCL+Db :14   1,0005 : 2
>                              (Other):47
>> m1<-glm(a$transinduc~a$time*a$treatment,data=a,family="poisson")
> Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson' family") :
>  valor ausente donde TRUE/FALSE es necesario
> Adem?s: Warning message:
> In Ops.factor(y, 0) : '<' not meaningful for factors

Learning to read R error messages carefully and for full meaning is an essential step toward full mastery of this wonderful gift from the R Core.

The business about "negative values" is a complete distraction. That was the consequent of an if statement and was only in there to show you where to look in the function if you were so inclined . The error is actually being thrown much earlier in parsing that statement by the "<" operator inside the `if` statement. The "real" error message that says:

> valor ausente donde TRUE/FALSE es necesario

Or in English:

 missing value where TRUE/FALSE needed


Examine this code:

> x <- factor(1:5)
> y<- 1:5
> glm( x ~ y, family="poisson")
Error in if (any(y < 0)) stop("negative values not allowed for the 'Poisson' family") : 
  missing value where TRUE/FALSE needed
In addition: Warning message:
In Ops.factor(y, 0) : ?<? not meaningful for factors

Because the "<" operator is not defined for factors the result that is passed to `if` is of length 0. Setting the factor variable on the RHS and using the integer values on hte LHS succeeds.


> glm( y ~ x, family="poisson")

Call:  glm(formula = y ~ x, family = "poisson")

Coefficients:
(Intercept)           x2           x3           x4           x5  
  4.676e-11    6.931e-01    1.099e+00    1.386e+00    1.609e+00  

Degrees of Freedom: 4 Total (i.e. Null);  0 Residual
Null Deviance:	    3.591 
Residual Deviance: 6.661e-16 	AIC: 24.35

Duncan Murdoch points out that fractional values in the LHS of a formula for Poisson regression will not be accepted (since the poisson distribution is discrete), and if you do in fact need Poisson regression that you would need to use the quasi-binomial family.

On the other hand ... If those were counts in the thousands and needed to be converted to "whole numbers", you might need to convert the factor values to numeric with:

a$transinduc <- as.numeric( gsub( "[,]", "", a$transinduc) )

-- 
David.
> 
> 	[[alternative HTML version deleted]]

Rhelp is a plain text mailing list.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mak.hholly at gmail.com  Wed Feb  1 18:25:25 2017
From: mak.hholly at gmail.com (greg holly)
Date: Wed, 1 Feb 2017 12:25:25 -0500
Subject: [R] looping problem
Message-ID: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>

Hi all;

I have 22 directories named chr1, chr2,....,chr22. Each directory has a
file named "Z-score.imputed". I would like to combine  Z-score.imputed
files into one. I wrote the following loop but did not get any results.
Your helps are highly appreciated.

regards,

Greg

temp<-c()

for(i in 1:22) {
infile<-paste("chr",i,"/Z-score.imputed",sep="")
psT<-read.table(as.character(infile),header=T,as.is=T,sep="\t")
ps<-psT[psT$Var>0.6,]
ratio=nrow(ps)/nrow(psT)
print(ratio)
}

	[[alternative HTML version deleted]]


From igomez at zencos.com  Wed Feb  1 17:33:02 2017
From: igomez at zencos.com (Ivan Gomez)
Date: Wed, 1 Feb 2017 16:33:02 +0000
Subject: [R] Help Installing RODBC with custom header locations
In-Reply-To: <F661522A-C61B-4AA0-9CE3-033ED4CC26D2@me.com>
References: <CY4PR08MB2838123262534D7373235637A84D0@CY4PR08MB2838.namprd08.prod.outlook.com>
	<F661522A-C61B-4AA0-9CE3-033ED4CC26D2@me.com>
Message-ID: <CY4PR08MB28382E4EAF0E4E6FE98E8FA9A84D0@CY4PR08MB2838.namprd08.prod.outlook.com>

Hi Marc,

Thank you so much for your response. I'll keep in mind R-SIG-DB for future reference.

Just to close this loop, what ultimately did the trick was:

1. Setting the following environment variables
LD_LIBRARY_PATH=/gpfs/grid/progress/lib:$LD_LIBRARY_PATH
ODBCINI=/gpfs/grid/progress/odbc.ini
ODBCINST=/gpfs/grid/progress/odbcinst.ini

2. Running this install command `install.packages("RODBC", configure.args = "--with-odbc-include=/gpfs/grid/progress/include/ --with-odbc-lib=/gpfs/grid/progress/lib/")`

Thank you for your help and have a good day,
Ivan G.


-----Original Message-----
From: Marc Schwartz [mailto:marc_schwartz at me.com] 
Sent: Wednesday, February 01, 2017 10:31 AM
To: Ivan Gomez <igomez at zencos.com>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Help Installing RODBC with custom header locations

> On Feb 1, 2017, at 8:11 AM, Ivan Gomez <igomez at zencos.com> wrote:
> 
> Hi all,
> 
> I'm trying to install.packages("RODBC") , but it is failing because it cannot find certain required header files:
> 
> ....
> "configure: error: "ODBC headers sql.h and sqlext.h not found"
> 
> I believe this is because my header files are in a custom location instead of the standard system folder:
> 
> comp1:/gpfs/grid/progress/include # ll total 184 -rw-r--r--. 1 1494 
> 400 4894 Oct 24 2012 odbcinst.h -rw-r--r--. 1 1494 400 26858 Oct 24 
> 2012 qesqlext.h -rw-r--r--. 1 1494 400 79606 Oct 24 2012 sqlext.h 
> -rw-r--r--. 1 1494 400 30106 Oct 24 2012 sql.h -rw-r--r--. 1 1494 400 
> 8002 Oct 24 2012 sqltypes.h -rw-r--r--. 1 1494 400 22715 Oct 24 2012 
> sqlucode.h -rw-r--r--. 1 1494 400 1354 Oct 24 2012 sqlunx.h
> 
> 
> 
> Could you please show me how I can tell the install command to look for the header files in this custom directory or point me towards an example of a similar case?
> Thank you very much for your time,
> Ivan G.
> 


Hi,

For future reference, this subject matter should go to R-SIG-DB:

  https://stat.ethz.ch/mailman/listinfo/r-sig-db


You can use an invocation along the lines of:

install.packages("RODBC",
                 configure.args = "--with-odbc-include=/gpfs/grid/progress/include/")

where the 'configure.args' argument has the FULL path to the header files.

There is detailed installation information in the vignette for the package on CRAN:

  https://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf


Regards,

Marc Schwartz


From maberg at sfu.ca  Wed Feb  1 17:41:57 2017
From: maberg at sfu.ca (Mary Ann Middleton)
Date: Wed, 1 Feb 2017 08:41:57 -0800 (PST)
Subject: [R] How to create 10 minute time series from hourly data
Message-ID: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>

Hello, 

Apologies if this is a duplicate. I think I sent it to the wrong list yesterday. 

I would appreciate some direction/suggestions with a problem with a time series. 

I have a regular time series dataframe with hourly data. I need to create a time series with a 10 minute interval for $Level_m to compare to another time series. 

I would like to apply an approximation and create a time series with 10 minute intervals from the data series I have. I do not want to smooth the data and so I think a linear approximation would suffice. 

I have also searched xts for possible solutions but haven't had luck. Any input is greatly appreciated. 

~Mary Ann Middleton, PhD 




Here is a sample of the data I have: 

Date Time date.time ms LEVEL TEMPERATURE Level_m 
1 2016-05-31 15:25:00 2016-05-31 15:25:00 0 92.1767 25.171 9.401814 
2 2016-05-31 16:25:00 2016-05-31 16:25:00 0 92.1498 18.023 9.399071 
3 2016-05-31 17:25:00 2016-05-31 17:25:00 0 92.0781 17.951 9.391757 
4 2016-05-31 18:25:00 2016-05-31 18:25:00 0 92.0664 16.312 9.390564 
5 2016-05-31 19:25:00 2016-05-31 19:25:00 0 92.0250 15.043 9.386341 
6 2016-05-31 20:25:00 2016-05-31 20:25:00 0 91.9732 14.015 9.381058 

Here is the str() 

'data.frame': 164 obs. of 7 variables: 
$ Date : chr " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " ... 
$ Time : chr "15:25:00" "16:25:00" "17:25:00" "18:25:00" ... 
$ date.time : POSIXct, format: " 2016-05-31 15:25:00" " 2016-05-31 16:25:00" ... 
$ ms : int 0 0 0 0 0 0 0 0 0 0 ... 
$ LEVEL : num 92.2 92.1 92.1 92.1 92 ... 
$ TEMPERATURE: num 25.2 18 18 16.3 15 ... 
$ Level_m : num 9.4 9.4 9.39 9.39 9.39 ... 

	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Wed Feb  1 19:26:27 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Wed, 1 Feb 2017 20:26:27 +0200
Subject: [R] Challenge extracting months
In-Reply-To: <CA+8X3fVZ5CwgUm-tghU=aNDZ_qBhodh0CAc+GPo4vZJR5pLmkw@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
	<CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
	<CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>
	<CA+8X3fXKvAhuEGNjbOeHXQJqNXfz-HrcckYzfSiO8MuZNcwchg@mail.gmail.com>
	<CAGD2cKe-M=v7qpfbnmwV2VOZ1qFGRC2ABv+=CtsqoQ=mFOA43Q@mail.gmail.com>
	<CA+8X3fVZ5CwgUm-tghU=aNDZ_qBhodh0CAc+GPo4vZJR5pLmkw@mail.gmail.com>
Message-ID: <CAGD2cKdBppoZOe0vohdz4Cw1PEz_svSVFahzSq4-JjTYc93=yA@mail.gmail.com>

Hello Jim, Hello everyone, does anyone know why this is happening? Any
suggestions what might be causing it? I will be grateful for any help.

Kwesi

On Wed, Feb 1, 2017 at 1:12 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kwesi,
> I worked through your code below, and I think that when you have the
> two variables "mon.t1" and "seas.t1" you can select a "rolling
> quarter" like this:
>
> # the file name in your example is different from the one you sent
> era<-read.table(file="SAfr_700hpa_7x5II.txt",header=FALSE,sep=" ",
>  skip=1,dec = ".")
> era.nodes<-paste(era[,1],era[,2],sep=".")
> era.nodes<-as.numeric(era.nodes)
> era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-01"),
>  end=as.Date("2016-12-31"))
> era.nodes.days.t1<-window(era.nodes.days,start=as.Date("1980-01-01"),
>  end=as.Date("2016-12-31"))
> mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
> addyear<-0
> # this loop transforms mon.t1 into an increasing sequence of months
> for(i in 2:length(mon.t1)) {
>  if(seas.t1[i] > seas.t1[i-1]) addyear<-addyear+12
>  mon.t1[i]<-mon.t1[i] + addyear
> }
> for(i in 1:(max(mon.t1)-2)) {
>  # this gives a logical index for the rolling quarter
>  rq<-mon.t1 %in% i:(i+2)
> }
>
> Each successive "rq" produced by the last loop can be used to extract
> whatever values you want from "era" or "era.nodes".
>
> Jim
>
>
> On Tue, Jan 31, 2017 at 9:04 PM, Kwesi Quagraine <starskykwesi at gmail.com>
> wrote:
> > Hello Jim, thanks for the code. But I come to you once again, I am not
> > looking to do a rolling mean, but to select JFM,FMA,MAM etc from the data
> > attached. Below is my sample code which actually selects these months. I
> > will rather be glad if I can have a function that does the selection for
> all
> > these 3 months selected for each year as shown in my last two lines of
> code;
> > Taking into accounts years with 29 days in February etc.
> >
> > rm(list = ls())
> > library(zoo)
> > library(PCICt)
> > library(lattice)
> > library(RColorBrewer)
> >
> > setwd('/home/kwesi/Documents/700hpa/soms/')
> > # Reading the data
> >
> > era       <- read.table(file="SAfr_700hpa_5x4II.txt",header = FALSE,
> sep =
> > "",skip=1,dec = ".")
> > era.nodes      <- paste(era[,1],era[,2],sep=".")
> >
> > era.nodes      <-as.numeric(era.nodes)
> > era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-
> 01"),end=as.Date("2016-12-31"))
> >
> > era.nodes.days.t1<-window(era.nodes.days,start=as.Date("
> 1980-01-01"),end=as.Date("2016-12-31"))
> >
> > mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
> > seas.t1 <-as.numeric(format(index(era.nodes.days.t1),"%Y"))
> > era.nodes.days.t1<-cbind(era.nodes.days.t1,mon.t1,seas.t1)
> > era.nodes.days.t1
> > jfm80<-era.nodes.days.t1[1:91,1:3[era.nodes.days.t1[1:91,2]=
> =1|era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3]
> > fma80<-era.nodes.days.t1[32:(91+30),1:3
> > [era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3|
> era.nodes.days.t1[1:91,2]==4]
> >
> > On Tue, Jan 31, 2017 at 5:23 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Kwesi,
> >> A mistake in the last email. Don't try to replace the column in
> >> era.sta as the result will be a different length. Try this:
> >>
> >> newera.sta2<-collapse.values(era.sta[,2],3)
> >>
> >> Jim
> >>
> >> On Tue, Jan 31, 2017 at 10:32 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >> > Hi Kwesi,
> >> > The function collapse_values will only work on a vector of numbers
> >> > with FUN="mean". era.sta looks like a data frame with at least two
> >> > elements. As the second of these elements seems to be numeric, perhaps
> >> > this will work:
> >> >
> >> > era.sta[,2]<-collapse.values(era.sta[,2],3)
> >> >
> >> > Don't try to apply the names to era.sta, that was just something to
> >> > make the example easier to understand. If you want to collapse more
> >> > than one column of era.sta do each one at a time and assign them to a
> >> > new data frame. In particular, if era[,1] is a vector of month names,
> >> > you will have to create a new vector of quarter (three month) names.
> >> > If there are very many of these, the collapse_values function can be
> >> > modified to do it automatically.
> >> >
> >> > Jim
> >> >
> >> >
> >> >
> >> > On Tue, Jan 31, 2017 at 9:50 AM, Kwesi Quagraine
> >> > <starskykwesi at gmail.com> wrote:
> >> >> Hello Jim,this is my script now; I am having this error when I called
> >> >> the
> >> >> function;" In mean.default(list(era...1. = 1:444, Node_freq =
> >> >> c(-0.389855332400718,  :  argument is not numeric or logical:
> returning
> >> >> NA"
> >> >> Any help will be much appreciated.
> >> >>
> >> >> Kwesi
> >> >>
> >> >> rm(list = ls())
> >> >> setwd('/home/kwesi/Documents/700hpa/soms/')
> >> >> # Reading the data
> >> >>
> >> >> era       <- read.csv(file="som_freq.csv",header = TRUE, sep =
> ",",dec
> >> >> =
> >> >> ".")
> >> >> era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
> >> >> era.sta<-data.frame(era[,1],era.scaled)
> >> >> era.sta
> >> >>
> >> >> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
> >> >>   jump<-span-1
> >> >>   newx<-rep(NA,length(x)-jump)
> >> >>   for(i in 1:length(newx))
> >> >>     newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
> >> >>   return(newx)
> >> >> }
> >> >>
> >> >> #test<-1:12
> >> >> names(era.sta)<-month.abb
> >> >> collapse_values(era.sta,3)
> >> >> era.sta
> >> >>
> >> >>
> >> >> On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon <drjimlemon at gmail.com>
> >> >> wrote:
> >> >>>
> >> >>> Hi Kwesi,
> >> >>> Even without the data, it seems clear that you want something like a
> >> >>> rolling mean. Here is a simple function that will apply a function
> >> >>> like "mean" to successive bits of a vector of numbers:
> >> >>>
> >> >>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
> >> >>>  jump<-span-1
> >> >>>  newx<-rep(NA,length(x)-jump)
> >> >>>  for(i in 1:length(newx))
> >> >>>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
> >> >>>  return(newx)
> >> >>> }
> >> >>>
> >> >>> test<-1:12
> >> >>> names(test)<-month.abb
> >> >>> test
> >> >>> collapse_values(test,3)
> >> >>>  [1]  2  3  4  5  6  7  8  9 10 11
> >> >>>
> >> >>> Jim
> >> >>>
> >> >>>
> >> >>>
> >> >>> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
> >> >>> <starskykwesi at gmail.com> wrote:
> >> >>> > Hello, I have a data with two variables nodes and index, I want to
> >> >>> > extract
> >> >>> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA
> >> >>> > etc to
> >> >>> > OND. Was wondering how to go about it. Kindly find attached the
> data
> >> >>> > as
> >> >>> > csv.
> >> >>> > Any help will be appreciated.
> >> >>> >
> >> >>> > Regards,
> >> >>> > Kwesi
> >> >>> >
> >> >>> > --
> >> >>> > Try not to become a man of success but rather a man of
> value-Albert
> >> >>> > Einstein
> >> >>> >
> >> >>> > University of Cape Coast|College of Agriculture and Natural
> >> >>> > Sciences|Department
> >> >>> > of Physics|
> >> >>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
> >> >>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> >> >>> > Mobile: +233266173582
> >> >>> > Skype: quagraine_cwasi
> >> >>> > Twitter: @Pkdilly
> >> >>> > ______________________________________________
> >> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> > PLEASE do read the posting guide
> >> >>> > http://www.R-project.org/posting-guide.html
> >> >>> > and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Try not to become a man of success but rather a man of value-Albert
> >> >> Einstein
> >> >>
> >> >> University of Cape Coast|College of Agriculture and Natural
> >> >> Sciences|Department of Physics|
> >> >> Team Leader|Recycle Up! Ghana|Technology Without Borders|
> >> >> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> >> >> Mobile: +233266173582
> >> >> Skype: quagraine_cwasi
> >> >> Twitter: @Pkdilly
> >> >>
> >
> >
> >
> >
> > --
> > Try not to become a man of success but rather a man of value-Albert
> Einstein
> >
> > University of Cape Coast|College of Agriculture and Natural
> > Sciences|Department of Physics|
> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> > Mobile: +233266173582
> > Skype: quagraine_cwasi
> > Twitter: @Pkdilly
> >
>



-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly
-------------- next part --------------
A non-text attachment was scrubbed...
Name: freq_nodes_per_year.eps
Type: application/postscript
Size: 56641 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170201/0fa290a8/attachment.eps>

From ruipbarradas at sapo.pt  Wed Feb  1 19:32:53 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 01 Feb 2017 18:32:53 +0000
Subject: [R] looping problem
In-Reply-To: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
References: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
Message-ID: <589229D5.6010306@sapo.pt>

Hello,

If what you want is to combine the files into one data.frame then there 
are 2 things you should see:

1) You create a variable named 'temp' and don't ever use it.
2) You never combine the data.frames you read in.

Try instead the following.

temp <- data.frame()
for(i in 1:22) {
     infile<-paste("chr",i,"/Z-score.imputed",sep="")
     psT<-read.table(infile,header=T,as.is=T,sep="\t")
     temp <- rbind(temp, psT)
}

str(temp)  # to see what you have

Hope this helps,

Rui Barradas



Em 01-02-2017 17:25, greg holly escreveu:
> Hi all;
>
> I have 22 directories named chr1, chr2,....,chr22. Each directory has a
> file named "Z-score.imputed". I would like to combine  Z-score.imputed
> files into one. I wrote the following loop but did not get any results.
> Your helps are highly appreciated.
>
> regards,
>
> Greg
>
> temp<-c()
>
> for(i in 1:22) {
> infile<-paste("chr",i,"/Z-score.imputed",sep="")
> psT<-read.table(as.character(infile),header=T,as.is=T,sep="\t")
> ps<-psT[psT$Var>0.6,]
> ratio=nrow(ps)/nrow(psT)
> print(ratio)
> }
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Wed Feb  1 19:56:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 1 Feb 2017 10:56:19 -0800
Subject: [R] How to create 10 minute time series from hourly data
In-Reply-To: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>
References: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>
Message-ID: <CAGxFJbTRfso2xA5VuJJN08TE9UkMottLvww=s=kEcQKn+T-9CA@mail.gmail.com>

Perhaps:

?approx

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 1, 2017 at 8:41 AM, Mary Ann Middleton <maberg at sfu.ca> wrote:
> Hello,
>
> Apologies if this is a duplicate. I think I sent it to the wrong list yesterday.
>
> I would appreciate some direction/suggestions with a problem with a time series.
>
> I have a regular time series dataframe with hourly data. I need to create a time series with a 10 minute interval for $Level_m to compare to another time series.
>
> I would like to apply an approximation and create a time series with 10 minute intervals from the data series I have. I do not want to smooth the data and so I think a linear approximation would suffice.
>
> I have also searched xts for possible solutions but haven't had luck. Any input is greatly appreciated.
>
> ~Mary Ann Middleton, PhD
>
>
>
>
> Here is a sample of the data I have:
>
> Date Time date.time ms LEVEL TEMPERATURE Level_m
> 1 2016-05-31 15:25:00 2016-05-31 15:25:00 0 92.1767 25.171 9.401814
> 2 2016-05-31 16:25:00 2016-05-31 16:25:00 0 92.1498 18.023 9.399071
> 3 2016-05-31 17:25:00 2016-05-31 17:25:00 0 92.0781 17.951 9.391757
> 4 2016-05-31 18:25:00 2016-05-31 18:25:00 0 92.0664 16.312 9.390564
> 5 2016-05-31 19:25:00 2016-05-31 19:25:00 0 92.0250 15.043 9.386341
> 6 2016-05-31 20:25:00 2016-05-31 20:25:00 0 91.9732 14.015 9.381058
>
> Here is the str()
>
> 'data.frame': 164 obs. of 7 variables:
> $ Date : chr " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " ...
> $ Time : chr "15:25:00" "16:25:00" "17:25:00" "18:25:00" ...
> $ date.time : POSIXct, format: " 2016-05-31 15:25:00" " 2016-05-31 16:25:00" ...
> $ ms : int 0 0 0 0 0 0 0 0 0 0 ...
> $ LEVEL : num 92.2 92.1 92.1 92.1 92 ...
> $ TEMPERATURE: num 25.2 18 18 16.3 15 ...
> $ Level_m : num 9.4 9.4 9.39 9.39 9.39 ...
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lal.prasad at gmail.com  Wed Feb  1 20:03:57 2017
From: lal.prasad at gmail.com (Lal Prasad)
Date: Thu, 2 Feb 2017 00:33:57 +0530
Subject: [R] Export Forecasted output to a table (excel)
Message-ID: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>

Hi All,

Is there any way to

1) Convert the below forecast to a datafram
2) Any way to write it to an excel table?


library(vars)
library(fpp)VARselect(usconsumption, lag.max = 3,
type="const")$selectionvar <- VAR(usconsumption, p=1,type =
"both",lag.max = 3)
serial.test(var, lags.pt = 3,type = "PT.asymptotic")

fcst <- forecast(var)

Regards

Lal

	[[alternative HTML version deleted]]


From ramiro at precisionbioassay.com  Wed Feb  1 20:46:31 2017
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Wed, 1 Feb 2017 19:46:31 +0000
Subject: [R] Using a mock of an S4 class
Message-ID: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>

Hello,

I have a function that applies to an S4 object which contains a slot called @analysis:

function calculation(myObject) {
  tmp <- myObjects at analysis
  result <- ...operations on analysis...
  return result
}

I am writing a unit test for this function.  So I was hoping to create a mock object but I can't figure out how to do it:

test_that("test calculation function", {
  mockMyObject<- mock(?????)  #I am not sure what to put here
  r<-calculation(mockMyObject)
  expect_true(r,0.83625)
})

How can I create a mock S4 object??

Thanks in advance,
Ramiro

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Wed Feb  1 21:31:50 2017
From: mak.hholly at gmail.com (greg holly)
Date: Wed, 1 Feb 2017 15:31:50 -0500
Subject: [R] looping problem
In-Reply-To: <589229D5.6010306@sapo.pt>
References: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
	<589229D5.6010306@sapo.pt>
Message-ID: <CAM9Qe4iiKZ-6cA+NmsPzXvFPC+r88g+iD8ut9wfy2+u+rqrrNQ@mail.gmail.com>

Hi Rui;

I do appreciate for this. Thanks so much. I will try ASAP.

Regards,

Greg

On Wed, Feb 1, 2017 at 1:32 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> If what you want is to combine the files into one data.frame then there
> are 2 things you should see:
>
> 1) You create a variable named 'temp' and don't ever use it.
> 2) You never combine the data.frames you read in.
>
> Try instead the following.
>
> temp <- data.frame()
> for(i in 1:22) {
>     infile<-paste("chr",i,"/Z-score.imputed",sep="")
>     psT<-read.table(infile,header=T,as.is=T,sep="\t")
>     temp <- rbind(temp, psT)
> }
>
> str(temp)  # to see what you have
>
> Hope this helps,
>
> Rui Barradas
>
>
>
>
> Em 01-02-2017 17:25, greg holly escreveu:
>
>> Hi all;
>>
>> I have 22 directories named chr1, chr2,....,chr22. Each directory has a
>> file named "Z-score.imputed". I would like to combine  Z-score.imputed
>> files into one. I wrote the following loop but did not get any results.
>> Your helps are highly appreciated.
>>
>> regards,
>>
>> Greg
>>
>> temp<-c()
>>
>> for(i in 1:22) {
>> infile<-paste("chr",i,"/Z-score.imputed",sep="")
>> psT<-read.table(as.character(infile),header=T,as.is=T,sep="\t")
>> ps<-psT[psT$Var>0.6,]
>> ratio=nrow(ps)/nrow(psT)
>> print(ratio)
>> }
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Feb  1 23:05:15 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 2 Feb 2017 11:05:15 +1300
Subject: [R] [FORGED]  Export Forecasted output to a table (excel)
In-Reply-To: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
Message-ID: <bde89d2c-0081-8e0a-c076-7c2b58c11314@auckland.ac.nz>

On 02/02/17 08:03, Lal Prasad wrote:
> Hi All,
>
> Is there any way to
>
> 1) Convert the below forecast to a datafram
> 2) Any way to write it to an excel table?
>
>
> library(vars)
> library(fpp)VARselect(usconsumption, lag.max = 3,
> type="const")$selectionvar <- VAR(usconsumption, p=1,type =
> "both",lag.max = 3)
> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>
> fcst <- forecast(var)

(1) Read the posting guide.

(2) In particular don't post in HTML.

(3) As it appears, your code makes no sense to me.

(4) DON'T use Excel.  Ever.  See:

     http://www.stat.uiowa.edu/~jcryer/JSMTalk2001.pdf

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From djnordlund at gmail.com  Wed Feb  1 23:25:10 2017
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Wed, 1 Feb 2017 14:25:10 -0800
Subject: [R] [FORGED] Export Forecasted output to a table (excel)
In-Reply-To: <bde89d2c-0081-8e0a-c076-7c2b58c11314@auckland.ac.nz>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
	<bde89d2c-0081-8e0a-c076-7c2b58c11314@auckland.ac.nz>
Message-ID: <d4b2066f-c521-8761-a20b-86bb046a7052@gmail.com>

On 2/1/2017 2:05 PM, Rolf Turner wrote:
> On 02/02/17 08:03, Lal Prasad wrote:
>> Hi All,
>>
>> Is there any way to
>>
>> 1) Convert the below forecast to a datafram
>> 2) Any way to write it to an excel table?
>>
>>
>> library(vars)
>> library(fpp)VARselect(usconsumption, lag.max = 3,
>> type="const")$selectionvar <- VAR(usconsumption, p=1,type =
>> "both",lag.max = 3)
>> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>>
>> fcst <- forecast(var)
> 
> (1) Read the posting guide.
> 
> (2) In particular don't post in HTML.
> 
> (3) As it appears, your code makes no sense to me.
> 
> (4) DON'T use Excel.  Ever.  See:
> 
>      http://www.stat.uiowa.edu/~jcryer/JSMTalk2001.pdf
> 
> cheers,
> 
> Rolf Turner
> 

Unfortunately, that link appears to be broken / does not exist anymore.

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From dwinsemius at comcast.net  Wed Feb  1 23:30:38 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Feb 2017 14:30:38 -0800
Subject: [R] [FORGED] Export Forecasted output to a table (excel)
In-Reply-To: <d4b2066f-c521-8761-a20b-86bb046a7052@gmail.com>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
	<bde89d2c-0081-8e0a-c076-7c2b58c11314@auckland.ac.nz>
	<d4b2066f-c521-8761-a20b-86bb046a7052@gmail.com>
Message-ID: <FBCC6000-AD38-44B8-9DE1-F7ADA889F7C1@comcast.net>


> On Feb 1, 2017, at 2:25 PM, Daniel Nordlund <djnordlund at gmail.com> wrote:
> 
> On 2/1/2017 2:05 PM, Rolf Turner wrote:
>> On 02/02/17 08:03, Lal Prasad wrote:
>>> Hi All,
>>> 
>>> Is there any way to
>>> 
>>> 1) Convert the below forecast to a datafram
>>> 2) Any way to write it to an excel table?
>>> 
>>> 
>>> library(vars)
>>> library(fpp)VARselect(usconsumption, lag.max = 3,
>>> type="const")$selectionvar <- VAR(usconsumption, p=1,type =
>>> "both",lag.max = 3)
>>> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>>> 
>>> fcst <- forecast(var)
>> (1) Read the posting guide.
>> (2) In particular don't post in HTML.
>> (3) As it appears, your code makes no sense to me.
>> (4) DON'T use Excel.  Ever.  See:
>>     http://www.stat.uiowa.edu/~jcryer/JSMTalk2001.pdf
>> cheers,
>> Rolf Turner
> 
> Unfortunately, that link appears to be broken / does not exist anymore.

A google-search quickly turned up this:

http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/Handouts.readings/ExcelPracticalforStat.pdf

> 
> Dan
> 
> -- 
> Daniel Nordlund
> Port Townsend, WA  USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Feb  1 23:44:35 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Feb 2017 14:44:35 -0800
Subject: [R] [FORGED] Export Forecasted output to a table (excel)
In-Reply-To: <FBCC6000-AD38-44B8-9DE1-F7ADA889F7C1@comcast.net>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
	<bde89d2c-0081-8e0a-c076-7c2b58c11314@auckland.ac.nz>
	<d4b2066f-c521-8761-a20b-86bb046a7052@gmail.com>
	<FBCC6000-AD38-44B8-9DE1-F7ADA889F7C1@comcast.net>
Message-ID: <33EDF81B-DE5A-47D8-9DF0-D99942F7D5AA@comcast.net>


> On Feb 1, 2017, at 2:30 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Feb 1, 2017, at 2:25 PM, Daniel Nordlund <djnordlund at gmail.com> wrote:
>> 
>> On 2/1/2017 2:05 PM, Rolf Turner wrote:
>>> On 02/02/17 08:03, Lal Prasad wrote:
>>>> Hi All,
>>>> 
>>>> Is there any way to
>>>> 
>>>> 1) Convert the below forecast to a datafram
>>>> 2) Any way to write it to an excel table?
>>>> 
>>>> 
>>>> library(vars)
>>>> library(fpp)VARselect(usconsumption, lag.max = 3,
>>>> type="const")$selectionvar <- VAR(usconsumption, p=1,type =
>>>> "both",lag.max = 3)
>>>> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>>>> 
>>>> fcst <- forecast(var)
>>> (1) Read the posting guide.
>>> (2) In particular don't post in HTML.
>>> (3) As it appears, your code makes no sense to me.
>>> (4) DON'T use Excel.  Ever.  See:
>>>    http://www.stat.uiowa.edu/~jcryer/JSMTalk2001.pdf
>>> cheers,
>>> Rolf Turner
>> 
>> Unfortunately, that link appears to be broken / does not exist anymore.
> 
> A google-search quickly turned up this:
> 
> http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/Handouts.readings/ExcelPracticalforStat.pdf

That did seem somewhat dated after I read it (being 15 years old) and I think other resources might be more current:

https://web.stanford.edu/group/ssds/cgi-bin/drupal/files/Guides/Using%20Excel%20for%20Data%20Manipulation%20and%20Statistical%20Analysis_1.pdf

http://people.umass.edu/evagold/excel.html

http://www.burns-stat.com/documents/tutorials/spreadsheet-addiction

http://www.phusewiki.org/docs/2009%20PAPERS/SP06.pdf

http://homepages.ulb.ac.be/~gmelard/rech/gmelard_csda23.pdf

-- 
David.


> 
>> 
>> Dan
>> 
>> -- 
>> Daniel Nordlund
>> Port Townsend, WA  USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Wed Feb  1 23:49:59 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 2 Feb 2017 11:49:59 +1300
Subject: [R] [FORGED] Re: [FORGED] Export Forecasted output to a table
 (excel)
In-Reply-To: <d4b2066f-c521-8761-a20b-86bb046a7052@gmail.com>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
	<bde89d2c-0081-8e0a-c076-7c2b58c11314@auckland.ac.nz>
	<d4b2066f-c521-8761-a20b-86bb046a7052@gmail.com>
Message-ID: <1d107d1b-95fc-3fc7-5e72-de1df7edb7e5@auckland.ac.nz>

On 02/02/17 11:25, Daniel Nordlund wrote:
> On 2/1/2017 2:05 PM, Rolf Turner wrote:
>> On 02/02/17 08:03, Lal Prasad wrote:
>>> Hi All,
>>>
>>> Is there any way to
>>>
>>> 1) Convert the below forecast to a datafram
>>> 2) Any way to write it to an excel table?
>>>
>>>
>>> library(vars)
>>> library(fpp)VARselect(usconsumption, lag.max = 3,
>>> type="const")$selectionvar <- VAR(usconsumption, p=1,type =
>>> "both",lag.max = 3)
>>> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>>>
>>> fcst <- forecast(var)
>>
>> (1) Read the posting guide.
>>
>> (2) In particular don't post in HTML.
>>
>> (3) As it appears, your code makes no sense to me.
>>
>> (4) DON'T use Excel.  Ever.  See:
>>
>>      http://www.stat.uiowa.edu/~jcryer/JSMTalk2001.pdf
>>
>> cheers,
>>
>> Rolf Turner
>>
>
> Unfortunately, that link appears to be broken / does not exist anymore.


Thanks for pointing that out Dan.  The following rather messy link does 
seem to work. The line gets wrapped (at least it does in my mailer) so 
you may need to mess around copying and pasting.

https://www.google.co.nz/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwilxsmC_O_RAhVEmJQKHeTKDrkQFggYMAA&url=https%3A%2F%2Foit.utk.edu%2Fresearch%2Fdocumentation%2FDocuments%2FExcelStatProbs.pdf&usg=AFQjCNEocZnHA4b9_9FNxkD2lzHBA9EaNw

cheers,

Rolf

P.S.  See also:

http://www.burns-stat.com/documents/tutorials/spreadsheet-addiction/

R.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From marc_schwartz at me.com  Thu Feb  2 00:06:40 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 01 Feb 2017 17:06:40 -0600
Subject: [R] [FORGED] Export Forecasted output to a table (excel)
In-Reply-To: <FBCC6000-AD38-44B8-9DE1-F7ADA889F7C1@comcast.net>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
	<bde89d2c-0081-8e0a-c076-7c2b58c11314@auckland.ac.nz>
	<d4b2066f-c521-8761-a20b-86bb046a7052@gmail.com>
	<FBCC6000-AD38-44B8-9DE1-F7ADA889F7C1@comcast.net>
Message-ID: <5AA6F978-7C6D-42E2-B527-428714960F31@me.com>


> On Feb 1, 2017, at 4:30 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Feb 1, 2017, at 2:25 PM, Daniel Nordlund <djnordlund at gmail.com> wrote:
>> 
>> On 2/1/2017 2:05 PM, Rolf Turner wrote:
>>> On 02/02/17 08:03, Lal Prasad wrote:
>>>> Hi All,
>>>> 
>>>> Is there any way to
>>>> 
>>>> 1) Convert the below forecast to a datafram
>>>> 2) Any way to write it to an excel table?
>>>> 
>>>> 
>>>> library(vars)
>>>> library(fpp)VARselect(usconsumption, lag.max = 3,
>>>> type="const")$selectionvar <- VAR(usconsumption, p=1,type =
>>>> "both",lag.max = 3)
>>>> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>>>> 
>>>> fcst <- forecast(var)
>>> (1) Read the posting guide.
>>> (2) In particular don't post in HTML.
>>> (3) As it appears, your code makes no sense to me.
>>> (4) DON'T use Excel.  Ever.  See:
>>>    http://www.stat.uiowa.edu/~jcryer/JSMTalk2001.pdf
>>> cheers,
>>> Rolf Turner
>> 
>> Unfortunately, that link appears to be broken / does not exist anymore.
> 
> A google-search quickly turned up this:
> 
> http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/Handouts.readings/ExcelPracticalforStat.pdf


The original 2001 JSM presentation by Jon Cryer is available here:

  https://oit.utk.edu/research/documentation/Documents/ExcelStatProbs.pdf

and here:

  http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.617.4297&rep=rep1&type=pdf

It would appear that he has retired from Iowa and may no longer have an online directory.

Patrick Burns also has a very good presentation and a reference listing here:

  http://www.burns-stat.com/documents/tutorials/spreadsheet-addiction/

as does Frank:

  http://biostat.mc.vanderbilt.edu/wiki/Main/ExcelProblems


FWIW, in the context of a nuanced response and differentiating between using Excel for any actual analyses, which is largely what the above references are warning against and simply for narrowly exporting R results, there are various packages available that can facilitate that, presuming you solve the underlying issue of getting the data into a compatible format (e.g. data frame).

The R Data Import/Export Manual is helpful here:

  https://cran.r-project.org/doc/manuals/r-release/R-data.html

The use of the ?str function can help provide insights into the structure of the returned object and how you might access selected components of the structure to achieve your goal.

An alternative to using Excel would be to use something like the Knitr package, which supports the use of markdown and can facilitate exporting formatted tables, etc. to HTML, PDF and so forth:

  https://yihui.name/knitr/


Regards,

Marc Schwartz

> 
>> 
>> Dan
>> 
>> -- 
>> Daniel Nordlund
>> Port Townsend, WA  USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Feb  2 00:08:49 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 2 Feb 2017 10:08:49 +1100
Subject: [R] Challenge extracting months
In-Reply-To: <CAGD2cKdBppoZOe0vohdz4Cw1PEz_svSVFahzSq4-JjTYc93=yA@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
	<CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
	<CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>
	<CA+8X3fXKvAhuEGNjbOeHXQJqNXfz-HrcckYzfSiO8MuZNcwchg@mail.gmail.com>
	<CAGD2cKe-M=v7qpfbnmwV2VOZ1qFGRC2ABv+=CtsqoQ=mFOA43Q@mail.gmail.com>
	<CA+8X3fVZ5CwgUm-tghU=aNDZ_qBhodh0CAc+GPo4vZJR5pLmkw@mail.gmail.com>
	<CAGD2cKdBppoZOe0vohdz4Cw1PEz_svSVFahzSq4-JjTYc93=yA@mail.gmail.com>
Message-ID: <CA+8X3fXqqQLv82+6hZ9RCM=wfZAmq7Gd8cdJJvXokogPY5Z_QQ@mail.gmail.com>

Hi Kwesi,
It looks to me as though you have plotted the output of your data.
What you have used to plot it is a mystery. Maybe a stacked barplot
with horizontal=TRUE? I don't suppose that the matrix of input values
is available. Let's see, you have 20 rectangles in each bar and 36
bars. Suppose we have a matrix like this:

kqmat<-
 matrix(sin(seq(pi/10,72*pi,pi/10))+rnorm(720,0,0.1),
 ncol=20,byrow=TRUE)
library(plotrix)
color2D.matplot(kqmat,axes=FALSE,xlab="Rolling quarter",ylab="Year",
 cellcolors=matrix(color.scale(kqmat,c(1,0,0),c(0,1,0),c(0,0,1)),nrow=20))
axis(2,at=1:36,labels=2015:1980,las=1)

This is a "plot in the dark", but it may enlighten.

Jim


On Thu, Feb 2, 2017 at 5:26 AM, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
> Hello Jim, Hello everyone, does anyone know why this is happening? Any
> suggestions what might be causing it? I will be grateful for any help.
>
> Kwesi
>
> On Wed, Feb 1, 2017 at 1:12 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Kwesi,
>> I worked through your code below, and I think that when you have the
>> two variables "mon.t1" and "seas.t1" you can select a "rolling
>> quarter" like this:
>>
>> # the file name in your example is different from the one you sent
>> era<-read.table(file="SAfr_700hpa_7x5II.txt",header=FALSE,sep=" ",
>>  skip=1,dec = ".")
>> era.nodes<-paste(era[,1],era[,2],sep=".")
>> era.nodes<-as.numeric(era.nodes)
>> era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-01"),
>>  end=as.Date("2016-12-31"))
>> era.nodes.days.t1<-window(era.nodes.days,start=as.Date("1980-01-01"),
>>  end=as.Date("2016-12-31"))
>> mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
>> addyear<-0
>> # this loop transforms mon.t1 into an increasing sequence of months
>> for(i in 2:length(mon.t1)) {
>>  if(seas.t1[i] > seas.t1[i-1]) addyear<-addyear+12
>>  mon.t1[i]<-mon.t1[i] + addyear
>> }
>> for(i in 1:(max(mon.t1)-2)) {
>>  # this gives a logical index for the rolling quarter
>>  rq<-mon.t1 %in% i:(i+2)
>> }
>>
>> Each successive "rq" produced by the last loop can be used to extract
>> whatever values you want from "era" or "era.nodes".
>>
>> Jim
>>
>>
>> On Tue, Jan 31, 2017 at 9:04 PM, Kwesi Quagraine <starskykwesi at gmail.com>
>> wrote:
>> > Hello Jim, thanks for the code. But I come to you once again, I am not
>> > looking to do a rolling mean, but to select JFM,FMA,MAM etc from the
>> > data
>> > attached. Below is my sample code which actually selects these months. I
>> > will rather be glad if I can have a function that does the selection for
>> > all
>> > these 3 months selected for each year as shown in my last two lines of
>> > code;
>> > Taking into accounts years with 29 days in February etc.
>> >
>> > rm(list = ls())
>> > library(zoo)
>> > library(PCICt)
>> > library(lattice)
>> > library(RColorBrewer)
>> >
>> > setwd('/home/kwesi/Documents/700hpa/soms/')
>> > # Reading the data
>> >
>> > era       <- read.table(file="SAfr_700hpa_5x4II.txt",header = FALSE, sep
>> > =
>> > "",skip=1,dec = ".")
>> > era.nodes      <- paste(era[,1],era[,2],sep=".")
>> >
>> > era.nodes      <-as.numeric(era.nodes)
>> >
>> > era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-01"),end=as.Date("2016-12-31"))
>> >
>> >
>> > era.nodes.days.t1<-window(era.nodes.days,start=as.Date("1980-01-01"),end=as.Date("2016-12-31"))
>> >
>> > mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
>> > seas.t1 <-as.numeric(format(index(era.nodes.days.t1),"%Y"))
>> > era.nodes.days.t1<-cbind(era.nodes.days.t1,mon.t1,seas.t1)
>> > era.nodes.days.t1
>> >
>> > jfm80<-era.nodes.days.t1[1:91,1:3[era.nodes.days.t1[1:91,2]==1|era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3]
>> > fma80<-era.nodes.days.t1[32:(91+30),1:3
>> >
>> > [era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3|era.nodes.days.t1[1:91,2]==4]
>> >
>> > On Tue, Jan 31, 2017 at 5:23 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> >>
>> >> Hi Kwesi,
>> >> A mistake in the last email. Don't try to replace the column in
>> >> era.sta as the result will be a different length. Try this:
>> >>
>> >> newera.sta2<-collapse.values(era.sta[,2],3)
>> >>
>> >> Jim
>> >>
>> >> On Tue, Jan 31, 2017 at 10:32 AM, Jim Lemon <drjimlemon at gmail.com>
>> >> wrote:
>> >> > Hi Kwesi,
>> >> > The function collapse_values will only work on a vector of numbers
>> >> > with FUN="mean". era.sta looks like a data frame with at least two
>> >> > elements. As the second of these elements seems to be numeric,
>> >> > perhaps
>> >> > this will work:
>> >> >
>> >> > era.sta[,2]<-collapse.values(era.sta[,2],3)
>> >> >
>> >> > Don't try to apply the names to era.sta, that was just something to
>> >> > make the example easier to understand. If you want to collapse more
>> >> > than one column of era.sta do each one at a time and assign them to a
>> >> > new data frame. In particular, if era[,1] is a vector of month names,
>> >> > you will have to create a new vector of quarter (three month) names.
>> >> > If there are very many of these, the collapse_values function can be
>> >> > modified to do it automatically.
>> >> >
>> >> > Jim
>> >> >
>> >> >
>> >> >
>> >> > On Tue, Jan 31, 2017 at 9:50 AM, Kwesi Quagraine
>> >> > <starskykwesi at gmail.com> wrote:
>> >> >> Hello Jim,this is my script now; I am having this error when I
>> >> >> called
>> >> >> the
>> >> >> function;" In mean.default(list(era...1. = 1:444, Node_freq =
>> >> >> c(-0.389855332400718,  :  argument is not numeric or logical:
>> >> >> returning
>> >> >> NA"
>> >> >> Any help will be much appreciated.
>> >> >>
>> >> >> Kwesi
>> >> >>
>> >> >> rm(list = ls())
>> >> >> setwd('/home/kwesi/Documents/700hpa/soms/')
>> >> >> # Reading the data
>> >> >>
>> >> >> era       <- read.csv(file="som_freq.csv",header = TRUE, sep =
>> >> >> ",",dec
>> >> >> =
>> >> >> ".")
>> >> >> era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
>> >> >> era.sta<-data.frame(era[,1],era.scaled)
>> >> >> era.sta
>> >> >>
>> >> >> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>> >> >>   jump<-span-1
>> >> >>   newx<-rep(NA,length(x)-jump)
>> >> >>   for(i in 1:length(newx))
>> >> >>     newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>> >> >>   return(newx)
>> >> >> }
>> >> >>
>> >> >> #test<-1:12
>> >> >> names(era.sta)<-month.abb
>> >> >> collapse_values(era.sta,3)
>> >> >> era.sta
>> >> >>
>> >> >>
>> >> >> On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon <drjimlemon at gmail.com>
>> >> >> wrote:
>> >> >>>
>> >> >>> Hi Kwesi,
>> >> >>> Even without the data, it seems clear that you want something like
>> >> >>> a
>> >> >>> rolling mean. Here is a simple function that will apply a function
>> >> >>> like "mean" to successive bits of a vector of numbers:
>> >> >>>
>> >> >>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>> >> >>>  jump<-span-1
>> >> >>>  newx<-rep(NA,length(x)-jump)
>> >> >>>  for(i in 1:length(newx))
>> >> >>>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>> >> >>>  return(newx)
>> >> >>> }
>> >> >>>
>> >> >>> test<-1:12
>> >> >>> names(test)<-month.abb
>> >> >>> test
>> >> >>> collapse_values(test,3)
>> >> >>>  [1]  2  3  4  5  6  7  8  9 10 11
>> >> >>>
>> >> >>> Jim
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
>> >> >>> <starskykwesi at gmail.com> wrote:
>> >> >>> > Hello, I have a data with two variables nodes and index, I want
>> >> >>> > to
>> >> >>> > extract
>> >> >>> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM, FMA
>> >> >>> > etc to
>> >> >>> > OND. Was wondering how to go about it. Kindly find attached the
>> >> >>> > data
>> >> >>> > as
>> >> >>> > csv.
>> >> >>> > Any help will be appreciated.
>> >> >>> >
>> >> >>> > Regards,
>> >> >>> > Kwesi
>> >> >>> >
>> >> >>> > --
>> >> >>> > Try not to become a man of success but rather a man of
>> >> >>> > value-Albert
>> >> >>> > Einstein
>> >> >>> >
>> >> >>> > University of Cape Coast|College of Agriculture and Natural
>> >> >>> > Sciences|Department
>> >> >>> > of Physics|
>> >> >>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> >> >>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> >> >>> > Mobile: +233266173582
>> >> >>> > Skype: quagraine_cwasi
>> >> >>> > Twitter: @Pkdilly
>> >> >>> > ______________________________________________
>> >> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>> > PLEASE do read the posting guide
>> >> >>> > http://www.R-project.org/posting-guide.html
>> >> >>> > and provide commented, minimal, self-contained, reproducible
>> >> >>> > code.
>> >> >>
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Try not to become a man of success but rather a man of value-Albert
>> >> >> Einstein
>> >> >>
>> >> >> University of Cape Coast|College of Agriculture and Natural
>> >> >> Sciences|Department of Physics|
>> >> >> Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> >> >> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> >> >> Mobile: +233266173582
>> >> >> Skype: quagraine_cwasi
>> >> >> Twitter: @Pkdilly
>> >> >>
>> >
>> >
>> >
>> >
>> > --
>> > Try not to become a man of success but rather a man of value-Albert
>> > Einstein
>> >
>> > University of Cape Coast|College of Agriculture and Natural
>> > Sciences|Department of Physics|
>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> > Mobile: +233266173582
>> > Skype: quagraine_cwasi
>> > Twitter: @Pkdilly
>> >
>
>
>
>
> --
> Try not to become a man of success but rather a man of value-Albert Einstein
>
> University of Cape Coast|College of Agriculture and Natural
> Sciences|Department of Physics|
> Team Leader|Recycle Up! Ghana|Technology Without Borders|
> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> Mobile: +233266173582
> Skype: quagraine_cwasi
> Twitter: @Pkdilly
>


From varinsacha at yahoo.fr  Thu Feb  2 00:08:03 2017
From: varinsacha at yahoo.fr (varin sacha)
Date: Wed, 1 Feb 2017 23:08:03 +0000 (UTC)
Subject: [R] Save a generated .txt (or .csv) file on the desktop
In-Reply-To: <26263B1E-9C10-469F-A1FF-FB05E74C7C4F@TxBiomed.org>
References: <368947391.7257542.1485807981734.ref@mail.yahoo.com>
	<368947391.7257542.1485807981734@mail.yahoo.com>
	<26263B1E-9C10-469F-A1FF-FB05E74C7C4F@TxBiomed.org>
Message-ID: <1420639113.1325758.1485990483298@mail.yahoo.com>

Mark,

Many thanks for your response.
Best,
S





________________________________
De : Mark Sharp <msharp at TxBiomed.org>

Cc : R-help Mailing List <r-help at r-project.org>
Envoy? le : Lundi 30 janvier 2017 23h04
Objet : Re: [R] Save a generated .txt (or .csv) file on the desktop


You can define the "file" argument in your call to write.csv()

## This will write out a file named "test_file.csv" to your working directory
write.csv(tableau,file = "test_file.csv", row.names=FALSE)


R. Mark Sharp, Ph.D.
msharp at TxBiomed.org







>
> Dear R-Experts,
>
> I have generated a data.frame. Now I would like to get it (the generated data.frame) saved on my desktop (desktop of my computer) in a .csv or .txt file. How can I proceed ?
>
> Many thanks.
>
> Here is the reproducible example :
>
>
>
> # G?n?ration al?atoire des colonnes
> Individu<-1:50
> Genre<-sample(c("H","F"),50,replace=T)
> Age<-sample(18:45,50,replace=T)
> Pratique<-sample(c("PI","I","TI"),50,replace=T)
> Statut<-sample(c("C","M","D"),50, replace=T)
>
> # G?n?ration du Data.frame "tableau" contenant les colonnes pr?c?dentes
> tableau <- data.frame(Individu,Genre,Age,Pratique,Statut)
>
> # Exportation du data.frame dans un fichier csv
> write.csv(tableau,row.names=FALSE)
>
>
>
> # Sauvegarder...save(tableau, file = "saveddf.txt")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From Ronald.Taylor at pnnl.gov  Thu Feb  2 00:23:17 2017
From: Ronald.Taylor at pnnl.gov (Taylor, Ronald C)
Date: Wed, 1 Feb 2017 23:23:17 +0000
Subject: [R] need help in trying out sparklyr - spark_connect will not work
 on local copy of Spark
Message-ID: <9630E5FD91504140A3479FBFBE1837B51BD313DE@EX10MBOX03.pnnl.gov>

Hello R-help list,

I am a new list member. My first question: I was trying out sparklyr (in R ver 3.3.2) on my Red Hat Linux workstation, following the instructions at spark.rstudio.com as to how to download and use a local copy of Spark. The Spark download appears to work. However, when I try to issue the spark_connect, to get started, I get the error msgs that  you see below.

I cannot find any guidance as to how to fix this. Quite frustrating. Can somebody give me a bit of help? Does something need to be added to my PATH env var in my .mycshrc file, for example? Is there a closed port problem? Has anybody run into this type of error msg? Do I need to do something additional to start up the local copy of Spark that is not mentioned in the RStudio online documentation?

-          Ron

%%%%%%%%%%%%%%%%%%%%

Here is the spark_install (apparently successful) and then the error msg on the spark_connect():

> spark_install(version = "1.6.2")

Installing Spark 1.6.2 for Hadoop 2.6 or later.

Downloading from:

- 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'

Installing to:

- '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'

trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'

Content type 'application/x-tar' length 278057117 bytes (265.2 MB)

==================================================

downloaded 265.2 MB

Installation complete.

>

> sc <- spark_connect(master = "local")

Error in force(code) :

  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.

    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit

    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689

---- Output Log ----

/home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory

---- Error Log ----

>

%%%%%%%%%%%%%%%%%%

And here is the entire screen output of my R session, from the R invocation on:

sidney115% R

R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"

Copyright (C) 2016 The R Foundation for Statistical Computing

Platform: x86_64-redhat-linux-gnu (64-bit)

>

> library(sparklyr)

>

> ls(pos = "package:sparklyr")

  [1] "%>%"

  [2] "compile_package_jars"

  [3] "connection_config"

  [4] "connection_is_open"

  [5] "copy_to"

  [6] "ensure_scalar_boolean"

  [7] "ensure_scalar_character"

  [8] "ensure_scalar_double"

  [9] "ensure_scalar_integer"

[10] "find_scalac"

[11] "ft_binarizer"

[12] "ft_bucketizer"

[13] "ft_discrete_cosine_transform"

[14] "ft_elementwise_product"

[15] "ft_index_to_string"

[16] "ft_one_hot_encoder"

[17] "ft_quantile_discretizer"

[18] "ft_regex_tokenizer"

[19] "ft_sql_transformer"

[20] "ft_string_indexer"

[21] "ft_tokenizer"

[22] "ft_vector_assembler"

[23] "hive_context"

[24] "invoke"

[25] "invoke_method"

[26] "invoke_new"

[27] "invoke_static"

[28] "java_context"

[29] "livy_available_versions"

[30] "livy_config"

[31] "livy_home_dir"

[32] "livy_install"

[33] "livy_install_dir"

[34] "livy_installed_versions"

[35] "livy_service_start"

[36] "livy_service_stop"

[37] "ml_als_factorization"

[38] "ml_binary_classification_eval"

[39] "ml_classification_eval"

[40] "ml_create_dummy_variables"

[41] "ml_decision_tree"

[42] "ml_generalized_linear_regression"

[43] "ml_gradient_boosted_trees"

[44] "ml_kmeans"

[45] "ml_lda"

[46] "ml_linear_regression"

[47] "ml_load"

[48] "ml_logistic_regression"

[49] "ml_model"

[50] "ml_multilayer_perceptron"

[51] "ml_naive_bayes"

[52] "ml_one_vs_rest"

[53] "ml_options"

[54] "ml_pca"

[55] "ml_prepare_dataframe"

[56] "ml_prepare_features"

[57] "ml_prepare_response_features_intercept"

[58] "ml_random_forest"

[59] "ml_save"

[60] "ml_survival_regression"

[61] "ml_tree_feature_importance"

[62] "na.replace"

[63] "print_jobj"

[64] "register_extension"

[65] "registered_extensions"

[66] "sdf_copy_to"

[67] "sdf_import"

[68] "sdf_load_parquet"

[69] "sdf_load_table"

[70] "sdf_mutate"

[71] "sdf_mutate_"

[72] "sdf_partition"

[73] "sdf_persist"

[74] "sdf_predict"

[75] "sdf_quantile"

[76] "sdf_read_column"

[77] "sdf_register"

[78] "sdf_sample"

[79] "sdf_save_parquet"

[80] "sdf_save_table"

[81] "sdf_schema"

[82] "sdf_sort"

[83] "sdf_with_unique_id"

[84] "spark_available_versions"

[85] "spark_compilation_spec"

[86] "spark_compile"

[87] "spark_config"

[88] "spark_connect"

[89] "spark_connection"

[90] "spark_connection_is_open"

[91] "spark_context"

[92] "spark_dataframe"

[93] "spark_default_compilation_spec"

[94] "spark_dependency"

[95] "spark_disconnect"

[96] "spark_disconnect_all"

[97] "spark_home_dir"

[98] "spark_install"

[99] "spark_install_dir"

[100] "spark_install_tar"

[101] "spark_installed_versions"

[102] "spark_jobj"

[103] "spark_load_table"

[104] "spark_log"

[105] "spark_read_csv"

[106] "spark_read_json"

[107] "spark_read_parquet"

[108] "spark_save_table"

[109] "spark_session"

[110] "spark_uninstall"

[111] "spark_version"

[112] "spark_version_from_home"

[113] "spark_web"

[114] "spark_write_csv"

[115] "spark_write_json"

[116] "spark_write_parquet"

[117] "tbl_cache"

[118] "tbl_uncache"

>

>

>

> spark_install(version = "1.6.2")

Installing Spark 1.6.2 for Hadoop 2.6 or later.

Downloading from:

- 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'

Installing to:

- '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'

trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'

Content type 'application/x-tar' length 278057117 bytes (265.2 MB)

==================================================

downloaded 265.2 MB

Installation complete.

>

> sc <- spark_connect(master = "local")

Error in force(code) :

  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.

    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit

    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689


---- Output Log ----

/home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory

---- Error Log ----

>

%%%%%%%%%%%%%%%%%%

Ronald C. Taylor, Ph.D.
Computational Biology & Bioinformatics Group
Pacific Northwest National Laboratory (U.S. Dept of Energy/Battelle)
Richland, WA 99352
phone: (509) 372-6568,  email: ronald.taylor at pnnl.gov
web page:  http://www.pnnl.gov/science/staff/staff_info.asp?staff_num=7048


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Feb  2 00:57:45 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Feb 2017 15:57:45 -0800
Subject: [R] Using a mock of an S4 class
In-Reply-To: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <763D8CCC-9705-492C-BE3C-987775407512@comcast.net>


> On Feb 1, 2017, at 11:46 AM, Ramiro Barrantes <ramiro at precisionbioassay.com> wrote:
> 
> Hello,
> 
> I have a function that applies to an S4 object which contains a slot called @analysis:
> 
> function calculation(myObject) {
>  tmp <- myObjects at analysis
>  result <- ...operations on analysis...
>  return result
> }
> 
> I am writing a unit test for this function.  So I was hoping to create a mock object but I can't figure out how to do it:
> 
> test_that("test calculation function", {
>  mockMyObject<- mock(?????)  #I am not sure what to put here
>  r<-calculation(mockMyObject)
>  expect_true(r,0.83625)
> })
> 
> How can I create a mock S4 object??

I'm not seeing a class definition for any "S4"-classed object. I would expect you to have used `setClass`. I believe that once the class is defined that you should have access to the `new` constructor function.

> 
> Thanks in advance,
> Ramiro
> 
> 	[[alternative HTML version deleted]]

R-help is a plain-text mailing list.

--

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Feb  2 01:07:51 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 2 Feb 2017 11:07:51 +1100
Subject: [R] Challenge extracting months
In-Reply-To: <CAGD2cKexY9FA4jp6CHxLm5ZXCw__LOsA2q6qQc_u-eRj=hBZtg@mail.gmail.com>
References: <CAGD2cKdphYRSa8mQpVQxeZQjwc+pjm8oS6NkZH1qryqkV546pw@mail.gmail.com>
	<CA+8X3fWxyeWtMHr8nvTJEOgDfoxikrhsM-kxROv-f7gRmbr25g@mail.gmail.com>
	<CAGD2cKcwd8F2s6MxEPNDNgi57BRnMR7Dbh_zt41PKKjg9yWh7w@mail.gmail.com>
	<CA+8X3fUA8uTmbTgxhuJXMYeM4tRJz2tGqpf_44O=p2FeZQbJQQ@mail.gmail.com>
	<CA+8X3fXKvAhuEGNjbOeHXQJqNXfz-HrcckYzfSiO8MuZNcwchg@mail.gmail.com>
	<CAGD2cKe-M=v7qpfbnmwV2VOZ1qFGRC2ABv+=CtsqoQ=mFOA43Q@mail.gmail.com>
	<CA+8X3fVZ5CwgUm-tghU=aNDZ_qBhodh0CAc+GPo4vZJR5pLmkw@mail.gmail.com>
	<CAGD2cKdBppoZOe0vohdz4Cw1PEz_svSVFahzSq4-JjTYc93=yA@mail.gmail.com>
	<CA+8X3fXqqQLv82+6hZ9RCM=wfZAmq7Gd8cdJJvXokogPY5Z_QQ@mail.gmail.com>
	<CAGD2cKexY9FA4jp6CHxLm5ZXCw__LOsA2q6qQc_u-eRj=hBZtg@mail.gmail.com>
Message-ID: <CA+8X3fUfUNFFFg0x521k=cuv3Q76vtrVpcJGHdM8a8S7HVL-Kw@mail.gmail.com>

Hi Kwesi,
I can get a plot out of your code without the colors (I don't have
RColorBrewer installed), but it doesn't look like the one you
attached. It is displaying:

prop.table(freqyears,margin=2)*100/365

which contains 20 rows and 37 columns. There are a lot of commands in
the file that don't seem to do anything or even throw errors. I'm
afraid that I can't debug the code you sent, partly because I don't
really know what you are attempting to display.

Jim


On Thu, Feb 2, 2017 at 10:35 AM, Kwesi Quagraine <starskykwesi at gmail.com> wrote:
> Hello Jim, Yes the idea is brilliant. I have been able to manipulate the
> barplot with "margin"  to get the plot in a better shape but now the y-axis
> is out of the plot zone. I have attached my script. Kindly have a look. Its
> with the data I earlier sent.
>
>
>
> On Thu, Feb 2, 2017 at 1:08 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Kwesi,
>> It looks to me as though you have plotted the output of your data.
>> What you have used to plot it is a mystery. Maybe a stacked barplot
>> with horizontal=TRUE? I don't suppose that the matrix of input values
>> is available. Let's see, you have 20 rectangles in each bar and 36
>> bars. Suppose we have a matrix like this:
>>
>> kqmat<-
>>  matrix(sin(seq(pi/10,72*pi,pi/10))+rnorm(720,0,0.1),
>>  ncol=20,byrow=TRUE)
>> library(plotrix)
>> color2D.matplot(kqmat,axes=FALSE,xlab="Rolling quarter",ylab="Year",
>>  cellcolors=matrix(color.scale(kqmat,c(1,0,0),c(0,1,0),c(0,0,1)),nrow=20))
>> axis(2,at=1:36,labels=2015:1980,las=1)
>>
>> This is a "plot in the dark", but it may enlighten.
>>
>> Jim
>>
>>
>> On Thu, Feb 2, 2017 at 5:26 AM, Kwesi Quagraine <starskykwesi at gmail.com>
>> wrote:
>> > Hello Jim, Hello everyone, does anyone know why this is happening? Any
>> > suggestions what might be causing it? I will be grateful for any help.
>> >
>> > Kwesi
>> >
>> > On Wed, Feb 1, 2017 at 1:12 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> >>
>> >> Hi Kwesi,
>> >> I worked through your code below, and I think that when you have the
>> >> two variables "mon.t1" and "seas.t1" you can select a "rolling
>> >> quarter" like this:
>> >>
>> >> # the file name in your example is different from the one you sent
>> >> era<-read.table(file="SAfr_700hpa_7x5II.txt",header=FALSE,sep=" ",
>> >>  skip=1,dec = ".")
>> >> era.nodes<-paste(era[,1],era[,2],sep=".")
>> >> era.nodes<-as.numeric(era.nodes)
>> >> era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-01"),
>> >>  end=as.Date("2016-12-31"))
>> >> era.nodes.days.t1<-window(era.nodes.days,start=as.Date("1980-01-01"),
>> >>  end=as.Date("2016-12-31"))
>> >> mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
>> >> addyear<-0
>> >> # this loop transforms mon.t1 into an increasing sequence of months
>> >> for(i in 2:length(mon.t1)) {
>> >>  if(seas.t1[i] > seas.t1[i-1]) addyear<-addyear+12
>> >>  mon.t1[i]<-mon.t1[i] + addyear
>> >> }
>> >> for(i in 1:(max(mon.t1)-2)) {
>> >>  # this gives a logical index for the rolling quarter
>> >>  rq<-mon.t1 %in% i:(i+2)
>> >> }
>> >>
>> >> Each successive "rq" produced by the last loop can be used to extract
>> >> whatever values you want from "era" or "era.nodes".
>> >>
>> >> Jim
>> >>
>> >>
>> >> On Tue, Jan 31, 2017 at 9:04 PM, Kwesi Quagraine
>> >> <starskykwesi at gmail.com>
>> >> wrote:
>> >> > Hello Jim, thanks for the code. But I come to you once again, I am
>> >> > not
>> >> > looking to do a rolling mean, but to select JFM,FMA,MAM etc from the
>> >> > data
>> >> > attached. Below is my sample code which actually selects these
>> >> > months. I
>> >> > will rather be glad if I can have a function that does the selection
>> >> > for
>> >> > all
>> >> > these 3 months selected for each year as shown in my last two lines
>> >> > of
>> >> > code;
>> >> > Taking into accounts years with 29 days in February etc.
>> >> >
>> >> > rm(list = ls())
>> >> > library(zoo)
>> >> > library(PCICt)
>> >> > library(lattice)
>> >> > library(RColorBrewer)
>> >> >
>> >> > setwd('/home/kwesi/Documents/700hpa/soms/')
>> >> > # Reading the data
>> >> >
>> >> > era       <- read.table(file="SAfr_700hpa_5x4II.txt",header = FALSE,
>> >> > sep
>> >> > =
>> >> > "",skip=1,dec = ".")
>> >> > era.nodes      <- paste(era[,1],era[,2],sep=".")
>> >> >
>> >> > era.nodes      <-as.numeric(era.nodes)
>> >> >
>> >> >
>> >> > era.nodes.days<-zooreg(era.nodes,start=as.Date("1980-01-01"),end=as.Date("2016-12-31"))
>> >> >
>> >> >
>> >> >
>> >> > era.nodes.days.t1<-window(era.nodes.days,start=as.Date("1980-01-01"),end=as.Date("2016-12-31"))
>> >> >
>> >> > mon.t1<-as.numeric(format(index(era.nodes.days.t1),"%m"))
>> >> > seas.t1 <-as.numeric(format(index(era.nodes.days.t1),"%Y"))
>> >> > era.nodes.days.t1<-cbind(era.nodes.days.t1,mon.t1,seas.t1)
>> >> > era.nodes.days.t1
>> >> >
>> >> >
>> >> > jfm80<-era.nodes.days.t1[1:91,1:3[era.nodes.days.t1[1:91,2]==1|era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3]
>> >> > fma80<-era.nodes.days.t1[32:(91+30),1:3
>> >> >
>> >> >
>> >> > [era.nodes.days.t1[1:91,2]==2|era.nodes.days.t1[1:91,2]==3|era.nodes.days.t1[1:91,2]==4]
>> >> >
>> >> > On Tue, Jan 31, 2017 at 5:23 AM, Jim Lemon <drjimlemon at gmail.com>
>> >> > wrote:
>> >> >>
>> >> >> Hi Kwesi,
>> >> >> A mistake in the last email. Don't try to replace the column in
>> >> >> era.sta as the result will be a different length. Try this:
>> >> >>
>> >> >> newera.sta2<-collapse.values(era.sta[,2],3)
>> >> >>
>> >> >> Jim
>> >> >>
>> >> >> On Tue, Jan 31, 2017 at 10:32 AM, Jim Lemon <drjimlemon at gmail.com>
>> >> >> wrote:
>> >> >> > Hi Kwesi,
>> >> >> > The function collapse_values will only work on a vector of numbers
>> >> >> > with FUN="mean". era.sta looks like a data frame with at least two
>> >> >> > elements. As the second of these elements seems to be numeric,
>> >> >> > perhaps
>> >> >> > this will work:
>> >> >> >
>> >> >> > era.sta[,2]<-collapse.values(era.sta[,2],3)
>> >> >> >
>> >> >> > Don't try to apply the names to era.sta, that was just something
>> >> >> > to
>> >> >> > make the example easier to understand. If you want to collapse
>> >> >> > more
>> >> >> > than one column of era.sta do each one at a time and assign them
>> >> >> > to a
>> >> >> > new data frame. In particular, if era[,1] is a vector of month
>> >> >> > names,
>> >> >> > you will have to create a new vector of quarter (three month)
>> >> >> > names.
>> >> >> > If there are very many of these, the collapse_values function can
>> >> >> > be
>> >> >> > modified to do it automatically.
>> >> >> >
>> >> >> > Jim
>> >> >> >
>> >> >> >
>> >> >> >
>> >> >> > On Tue, Jan 31, 2017 at 9:50 AM, Kwesi Quagraine
>> >> >> > <starskykwesi at gmail.com> wrote:
>> >> >> >> Hello Jim,this is my script now; I am having this error when I
>> >> >> >> called
>> >> >> >> the
>> >> >> >> function;" In mean.default(list(era...1. = 1:444, Node_freq =
>> >> >> >> c(-0.389855332400718,  :  argument is not numeric or logical:
>> >> >> >> returning
>> >> >> >> NA"
>> >> >> >> Any help will be much appreciated.
>> >> >> >>
>> >> >> >> Kwesi
>> >> >> >>
>> >> >> >> rm(list = ls())
>> >> >> >> setwd('/home/kwesi/Documents/700hpa/soms/')
>> >> >> >> # Reading the data
>> >> >> >>
>> >> >> >> era       <- read.csv(file="som_freq.csv",header = TRUE, sep =
>> >> >> >> ",",dec
>> >> >> >> =
>> >> >> >> ".")
>> >> >> >> era.scaled <- scale(era[,2:3], center = TRUE, scale = TRUE)
>> >> >> >> era.sta<-data.frame(era[,1],era.scaled)
>> >> >> >> era.sta
>> >> >> >>
>> >> >> >> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>> >> >> >>   jump<-span-1
>> >> >> >>   newx<-rep(NA,length(x)-jump)
>> >> >> >>   for(i in 1:length(newx))
>> >> >> >>     newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>> >> >> >>   return(newx)
>> >> >> >> }
>> >> >> >>
>> >> >> >> #test<-1:12
>> >> >> >> names(era.sta)<-month.abb
>> >> >> >> collapse_values(era.sta,3)
>> >> >> >> era.sta
>> >> >> >>
>> >> >> >>
>> >> >> >> On Mon, Jan 30, 2017 at 11:53 PM, Jim Lemon
>> >> >> >> <drjimlemon at gmail.com>
>> >> >> >> wrote:
>> >> >> >>>
>> >> >> >>> Hi Kwesi,
>> >> >> >>> Even without the data, it seems clear that you want something
>> >> >> >>> like
>> >> >> >>> a
>> >> >> >>> rolling mean. Here is a simple function that will apply a
>> >> >> >>> function
>> >> >> >>> like "mean" to successive bits of a vector of numbers:
>> >> >> >>>
>> >> >> >>> collapse_values<-function(x,span,FUN="mean",na.rm=FALSE) {
>> >> >> >>>  jump<-span-1
>> >> >> >>>  newx<-rep(NA,length(x)-jump)
>> >> >> >>>  for(i in 1:length(newx))
>> >> >> >>>   newx[i]<-do.call(FUN,list(x[i:(i+jump)],na.rm=na.rm))
>> >> >> >>>  return(newx)
>> >> >> >>> }
>> >> >> >>>
>> >> >> >>> test<-1:12
>> >> >> >>> names(test)<-month.abb
>> >> >> >>> test
>> >> >> >>> collapse_values(test,3)
>> >> >> >>>  [1]  2  3  4  5  6  7  8  9 10 11
>> >> >> >>>
>> >> >> >>> Jim
>> >> >> >>>
>> >> >> >>>
>> >> >> >>>
>> >> >> >>> On Mon, Jan 30, 2017 at 11:53 PM, Kwesi Quagraine
>> >> >> >>> <starskykwesi at gmail.com> wrote:
>> >> >> >>> > Hello, I have a data with two variables nodes and index, I
>> >> >> >>> > want
>> >> >> >>> > to
>> >> >> >>> > extract
>> >> >> >>> > 3 months seasons, with a shift of 1 month, that is, DJF, JFM,
>> >> >> >>> > FMA
>> >> >> >>> > etc to
>> >> >> >>> > OND. Was wondering how to go about it. Kindly find attached
>> >> >> >>> > the
>> >> >> >>> > data
>> >> >> >>> > as
>> >> >> >>> > csv.
>> >> >> >>> > Any help will be appreciated.
>> >> >> >>> >
>> >> >> >>> > Regards,
>> >> >> >>> > Kwesi
>> >> >> >>> >
>> >> >> >>> > --
>> >> >> >>> > Try not to become a man of success but rather a man of
>> >> >> >>> > value-Albert
>> >> >> >>> > Einstein
>> >> >> >>> >
>> >> >> >>> > University of Cape Coast|College of Agriculture and Natural
>> >> >> >>> > Sciences|Department
>> >> >> >>> > of Physics|
>> >> >> >>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> >> >> >>> > Other emails:
>> >> >> >>> > kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> >> >> >>> > Mobile: +233266173582
>> >> >> >>> > Skype: quagraine_cwasi
>> >> >> >>> > Twitter: @Pkdilly
>> >> >> >>> > ______________________________________________
>> >> >> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >> >>> > see
>> >> >> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >>> > PLEASE do read the posting guide
>> >> >> >>> > http://www.R-project.org/posting-guide.html
>> >> >> >>> > and provide commented, minimal, self-contained, reproducible
>> >> >> >>> > code.
>> >> >> >>
>> >> >> >>
>> >> >> >>
>> >> >> >>
>> >> >> >> --
>> >> >> >> Try not to become a man of success but rather a man of
>> >> >> >> value-Albert
>> >> >> >> Einstein
>> >> >> >>
>> >> >> >> University of Cape Coast|College of Agriculture and Natural
>> >> >> >> Sciences|Department of Physics|
>> >> >> >> Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> >> >> >> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> >> >> >> Mobile: +233266173582
>> >> >> >> Skype: quagraine_cwasi
>> >> >> >> Twitter: @Pkdilly
>> >> >> >>
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> > Try not to become a man of success but rather a man of value-Albert
>> >> > Einstein
>> >> >
>> >> > University of Cape Coast|College of Agriculture and Natural
>> >> > Sciences|Department of Physics|
>> >> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> >> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> >> > Mobile: +233266173582
>> >> > Skype: quagraine_cwasi
>> >> > Twitter: @Pkdilly
>> >> >
>> >
>> >
>> >
>> >
>> > --
>> > Try not to become a man of success but rather a man of value-Albert
>> > Einstein
>> >
>> > University of Cape Coast|College of Agriculture and Natural
>> > Sciences|Department of Physics|
>> > Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> > Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> > Mobile: +233266173582
>> > Skype: quagraine_cwasi
>> > Twitter: @Pkdilly
>> >
>
>
>
>
> --
> Try not to become a man of success but rather a man of value-Albert Einstein
>
> University of Cape Coast|College of Agriculture and Natural
> Sciences|Department of Physics|
> Team Leader|Recycle Up! Ghana|Technology Without Borders|
> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
> Mobile: +233266173582
> Skype: quagraine_cwasi
> Twitter: @Pkdilly
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: kq.png
Type: image/png
Size: 4191 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170202/126711dd/attachment.png>

From dwinsemius at comcast.net  Thu Feb  2 01:39:55 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 1 Feb 2017 16:39:55 -0800
Subject: [R] need help in trying out sparklyr - spark_connect will not
	work on local copy of Spark
In-Reply-To: <9630E5FD91504140A3479FBFBE1837B51BD313DE@EX10MBOX03.pnnl.gov>
References: <9630E5FD91504140A3479FBFBE1837B51BD313DE@EX10MBOX03.pnnl.gov>
Message-ID: <2215E62B-A775-45B0-B039-2A13448DF0D9@comcast.net>


> On Feb 1, 2017, at 3:23 PM, Taylor, Ronald C <Ronald.Taylor at pnnl.gov> wrote:
> 
> Hello R-help list,
> 
> I am a new list member. My first question: I was trying out sparklyr (in R ver 3.3.2) on my Red Hat Linux workstation, following the instructions at spark.rstudio.com as to how to download and use a local copy of Spark. The Spark download appears to work. However, when I try to issue the spark_connect, to get started, I get the error msgs that  you see below.
> 
> I cannot find any guidance as to how to fix this. Quite frustrating. Can somebody give me a bit of help? Does something need to be added to my PATH env var in my .mycshrc file, for example? Is there a closed port problem? Has anybody run into this type of error msg? Do I need to do something additional to start up the local copy of Spark that is not mentioned in the RStudio online documentation?
> 
> -          Ron
> 
> %%%%%%%%%%%%%%%%%%%%
> 
> Here is the spark_install (apparently successful) and then the error msg on the spark_connect():
> 
>> spark_install(version = "1.6.2")
> 
> Installing Spark 1.6.2 for Hadoop 2.6 or later.
> 
> Downloading from:
> 
> - 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Installing to:
> 
> - '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'
> 
> trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Content type 'application/x-tar' length 278057117 bytes (265.2 MB)
> 
> ==================================================
> 
> downloaded 265.2 MB
> 
> Installation complete.
> 
>> 
> 
>> sc <- spark_connect(master = "local")
> 
> Error in force(code) :
> 
>  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.
> 
>    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit
> 
>    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689
> 
> ---- Output Log ----
> 
> /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory


So this makes me wonder if you do not have a proper installation of java for one of those other packages. This seems off-topic for r-help, although possibly on-topic for the R-SIG-DBI list :

 https://stat.ethz.ch/mailman/listinfo/r-sig-db


There's also a "Report a bug" link:

	? Report a bug at 
https://?github.com/?rstudio/?sparklyr/?issues


-- 
David.
> 
> ---- Error Log ----
> 
>> 
> 
> %%%%%%%%%%%%%%%%%%
> 
> And here is the entire screen output of my R session, from the R invocation on:
> 
> sidney115% R
> 
> R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
> 
> Copyright (C) 2016 The R Foundation for Statistical Computing
> 
> Platform: x86_64-redhat-linux-gnu (64-bit)
> 
>> 
> 
>> library(sparklyr)
> 
>> 
> 
>> ls(pos = "package:sparklyr")
> 
>  [1] "%>%"
> 
>  [2] "compile_package_jars"
> 
>  [3] "connection_config"
> 
>  [4] "connection_is_open"
> 
>  [5] "copy_to"
> 
>  [6] "ensure_scalar_boolean"
> 
>  [7] "ensure_scalar_character"
> 
>  [8] "ensure_scalar_double"
> 
>  [9] "ensure_scalar_integer"
> 
> [10] "find_scalac"
> 
> [11] "ft_binarizer"
> 
> [12] "ft_bucketizer"
> 
> [13] "ft_discrete_cosine_transform"
> 
> [14] "ft_elementwise_product"
> 
> [15] "ft_index_to_string"
> 
> [16] "ft_one_hot_encoder"
> 
> [17] "ft_quantile_discretizer"
> 
> [18] "ft_regex_tokenizer"
> 
> [19] "ft_sql_transformer"
> 
> [20] "ft_string_indexer"
> 
> [21] "ft_tokenizer"
> 
> [22] "ft_vector_assembler"
> 
> [23] "hive_context"
> 
> [24] "invoke"
> 
> [25] "invoke_method"
> 
> [26] "invoke_new"
> 
> [27] "invoke_static"
> 
> [28] "java_context"
> 
> [29] "livy_available_versions"
> 
> [30] "livy_config"
> 
> [31] "livy_home_dir"
> 
> [32] "livy_install"
> 
> [33] "livy_install_dir"
> 
> [34] "livy_installed_versions"
> 
> [35] "livy_service_start"
> 
> [36] "livy_service_stop"
> 
> [37] "ml_als_factorization"
> 
> [38] "ml_binary_classification_eval"
> 
> [39] "ml_classification_eval"
> 
> [40] "ml_create_dummy_variables"
> 
> [41] "ml_decision_tree"
> 
> [42] "ml_generalized_linear_regression"
> 
> [43] "ml_gradient_boosted_trees"
> 
> [44] "ml_kmeans"
> 
> [45] "ml_lda"
> 
> [46] "ml_linear_regression"
> 
> [47] "ml_load"
> 
> [48] "ml_logistic_regression"
> 
> [49] "ml_model"
> 
> [50] "ml_multilayer_perceptron"
> 
> [51] "ml_naive_bayes"
> 
> [52] "ml_one_vs_rest"
> 
> [53] "ml_options"
> 
> [54] "ml_pca"
> 
> [55] "ml_prepare_dataframe"
> 
> [56] "ml_prepare_features"
> 
> [57] "ml_prepare_response_features_intercept"
> 
> [58] "ml_random_forest"
> 
> [59] "ml_save"
> 
> [60] "ml_survival_regression"
> 
> [61] "ml_tree_feature_importance"
> 
> [62] "na.replace"
> 
> [63] "print_jobj"
> 
> [64] "register_extension"
> 
> [65] "registered_extensions"
> 
> [66] "sdf_copy_to"
> 
> [67] "sdf_import"
> 
> [68] "sdf_load_parquet"
> 
> [69] "sdf_load_table"
> 
> [70] "sdf_mutate"
> 
> [71] "sdf_mutate_"
> 
> [72] "sdf_partition"
> 
> [73] "sdf_persist"
> 
> [74] "sdf_predict"
> 
> [75] "sdf_quantile"
> 
> [76] "sdf_read_column"
> 
> [77] "sdf_register"
> 
> [78] "sdf_sample"
> 
> [79] "sdf_save_parquet"
> 
> [80] "sdf_save_table"
> 
> [81] "sdf_schema"
> 
> [82] "sdf_sort"
> 
> [83] "sdf_with_unique_id"
> 
> [84] "spark_available_versions"
> 
> [85] "spark_compilation_spec"
> 
> [86] "spark_compile"
> 
> [87] "spark_config"
> 
> [88] "spark_connect"
> 
> [89] "spark_connection"
> 
> [90] "spark_connection_is_open"
> 
> [91] "spark_context"
> 
> [92] "spark_dataframe"
> 
> [93] "spark_default_compilation_spec"
> 
> [94] "spark_dependency"
> 
> [95] "spark_disconnect"
> 
> [96] "spark_disconnect_all"
> 
> [97] "spark_home_dir"
> 
> [98] "spark_install"
> 
> [99] "spark_install_dir"
> 
> [100] "spark_install_tar"
> 
> [101] "spark_installed_versions"
> 
> [102] "spark_jobj"
> 
> [103] "spark_load_table"
> 
> [104] "spark_log"
> 
> [105] "spark_read_csv"
> 
> [106] "spark_read_json"
> 
> [107] "spark_read_parquet"
> 
> [108] "spark_save_table"
> 
> [109] "spark_session"
> 
> [110] "spark_uninstall"
> 
> [111] "spark_version"
> 
> [112] "spark_version_from_home"
> 
> [113] "spark_web"
> 
> [114] "spark_write_csv"
> 
> [115] "spark_write_json"
> 
> [116] "spark_write_parquet"
> 
> [117] "tbl_cache"
> 
> [118] "tbl_uncache"
> 
>> 
> 
>> 
> 
>> 
> 
>> spark_install(version = "1.6.2")
> 
> Installing Spark 1.6.2 for Hadoop 2.6 or later.
> 
> Downloading from:
> 
> - 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Installing to:
> 
> - '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'
> 
> trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Content type 'application/x-tar' length 278057117 bytes (265.2 MB)
> 
> ==================================================
> 
> downloaded 265.2 MB
> 
> Installation complete.
> 
>> 
> 
>> sc <- spark_connect(master = "local")
> 
> Error in force(code) :
> 
>  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.
> 
>    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit
> 
>    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689
> 
> 
> ---- Output Log ----
> 
> /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory



> ---- Error Log ----
> 
>> 
> 
> %%%%%%%%%%%%%%%%%%
> 
> Ronald C. Taylor, Ph.D.
> Computational Biology & Bioinformatics Group
> Pacific Northwest National Laboratory (U.S. Dept of Energy/Battelle)
> Richland, WA 99352
> phone: (509) 372-6568,  email: ronald.taylor at pnnl.gov
> web page:  http://www.pnnl.gov/science/staff/staff_info.asp?staff_num=7048
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From lal.prasad at gmail.com  Thu Feb  2 02:55:59 2017
From: lal.prasad at gmail.com (Lal Prasad)
Date: Thu, 2 Feb 2017 07:25:59 +0530
Subject: [R] Export Forecasted output to a table (excel)
In-Reply-To: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
Message-ID: <CACuGqaKzesHH2LtYJFHmY2nnotS7A97NXgHA-a=jsYH9OTasQA@mail.gmail.com>

Thanks all for the information provided.
Is there any way I could convert an object of type mforecast (output of
forecast()) to dataframe?

On Thu, Feb 2, 2017 at 12:33 AM, Lal Prasad <lal.prasad at gmail.com> wrote:

> Hi All,
>
> Is there any way to
>
> 1) Convert the below forecast to a datafram
> 2) Any way to write it to an excel table?
>
>
> library(vars)
> library(fpp)VARselect(usconsumption, lag.max = 3, type="const")$selectionvar <- VAR(usconsumption, p=1,type = "both",lag.max = 3)
> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>
> fcst <- forecast(var)
>
> Regards
>
> Lal
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Feb  2 05:42:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 1 Feb 2017 20:42:29 -0800
Subject: [R] How to create 10 minute time series from hourly data
In-Reply-To: <69079561.25955359.1485977128537.JavaMail.zimbra@sfu.ca>
References: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>
	<CAGxFJbTRfso2xA5VuJJN08TE9UkMottLvww=s=kEcQKn+T-9CA@mail.gmail.com>
	<69079561.25955359.1485977128537.JavaMail.zimbra@sfu.ca>
Message-ID: <CAGxFJbQ1bv=uX_NmgzWjXu-mp06QJXGE938kTJ5N06aa0HMZ6A@mail.gmail.com>

1. Always cc the list.

2. Assuming all you want to to do is produce a regular sequence 6
times as long, ?seq

Please go through an R tutorial or two to learn basic R functionality like this.
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 1, 2017 at 11:25 AM, Mary Ann Middleton <maberg at sfu.ca> wrote:
> Thank you.  I will try that for interpolating the values between hours.
>
> But before I can do that, do you have any suggestions how I can expand the
> time series from hourly to 10-minute intervals?
>
> I think I will need to create an time series and then merge it with the
> existing data frame, at which point I could apply 'approx' to fill the
> remaining values, but this is where I'm really stuck.
>
> ~Mary Ann
> ________________________________
> From: "Bert Gunter" <bgunter.4567 at gmail.com>
> To: "Mary Ann Middleton" <maberg at sfu.ca>
> Cc: "R-help" <r-help at r-project.org>
> Sent: Wednesday, February 1, 2017 10:56:19 AM
> Subject: Re: [R] How to create 10 minute time series from hourly data
>
> Perhaps:
>
> ?approx
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Feb 1, 2017 at 8:41 AM, Mary Ann Middleton <maberg at sfu.ca> wrote:
>> Hello,
>>
>> Apologies if this is a duplicate. I think I sent it to the wrong list
>> yesterday.
>>
>> I would appreciate some direction/suggestions with a problem with a time
>> series.
>>
>> I have a regular time series dataframe with hourly data. I need to create
>> a time series with a 10 minute interval for $Level_m to compare to another
>> time series.
>>
>> I would like to apply an approximation and create a time series with 10
>> minute intervals from the data series I have. I do not want to smooth the
>> data and so I think a linear approximation would suffice.
>>
>> I have also searched xts for possible solutions but haven't had luck. Any
>> input is greatly appreciated.
>>
>> ~Mary Ann Middleton, PhD
>>
>>
>>
>>
>> Here is a sample of the data I have:
>>
>> Date Time date.time ms LEVEL TEMPERATURE Level_m
>> 1 2016-05-31 15:25:00 2016-05-31 15:25:00 0 92.1767 25.171 9.401814
>> 2 2016-05-31 16:25:00 2016-05-31 16:25:00 0 92.1498 18.023 9.399071
>> 3 2016-05-31 17:25:00 2016-05-31 17:25:00 0 92.0781 17.951 9.391757
>> 4 2016-05-31 18:25:00 2016-05-31 18:25:00 0 92.0664 16.312 9.390564
>> 5 2016-05-31 19:25:00 2016-05-31 19:25:00 0 92.0250 15.043 9.386341
>> 6 2016-05-31 20:25:00 2016-05-31 20:25:00 0 91.9732 14.015 9.381058
>>
>> Here is the str()
>>
>> 'data.frame': 164 obs. of 7 variables:
>> $ Date : chr " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " " 2016-05-31 "
>> ...
>> $ Time : chr "15:25:00" "16:25:00" "17:25:00" "18:25:00" ...
>> $ date.time : POSIXct, format: " 2016-05-31 15:25:00" " 2016-05-31
>> 16:25:00" ...
>> $ ms : int 0 0 0 0 0 0 0 0 0 0 ...
>> $ LEVEL : num 92.2 92.1 92.1 92.1 92 ...
>> $ TEMPERATURE: num 25.2 18 18 16.3 15 ...
>> $ Level_m : num 9.4 9.4 9.39 9.39 9.39 ...
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Feb  2 07:50:48 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Feb 2017 06:50:48 +0000
Subject: [R] How to create 10 minute time series from hourly data
In-Reply-To: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>
References: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A142A2@SRVEXCHCM301.precheza.cz>

Hi

You maybe could try

?splinefun or ?approxfun

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mary Ann
> Middleton
> Sent: Wednesday, February 1, 2017 5:42 PM
> To: r-help at r-project.org
> Subject: [R] How to create 10 minute time series from hourly data
>
> Hello,
>
> Apologies if this is a duplicate. I think I sent it to the wrong list yesterday.
>
> I would appreciate some direction/suggestions with a problem with a time
> series.
>
> I have a regular time series dataframe with hourly data. I need to create a
> time series with a 10 minute interval for $Level_m to compare to another
> time series.
>
> I would like to apply an approximation and create a time series with 10
> minute intervals from the data series I have. I do not want to smooth the
> data and so I think a linear approximation would suffice.
>
> I have also searched xts for possible solutions but haven't had luck. Any input
> is greatly appreciated.
>
> ~Mary Ann Middleton, PhD
>
>
>
>
> Here is a sample of the data I have:
>
> Date Time date.time ms LEVEL TEMPERATURE Level_m
> 1 2016-05-31 15:25:00 2016-05-31 15:25:00 0 92.1767 25.171 9.401814
> 2 2016-05-31 16:25:00 2016-05-31 16:25:00 0 92.1498 18.023 9.399071
> 3 2016-05-31 17:25:00 2016-05-31 17:25:00 0 92.0781 17.951 9.391757
> 4 2016-05-31 18:25:00 2016-05-31 18:25:00 0 92.0664 16.312 9.390564
> 5 2016-05-31 19:25:00 2016-05-31 19:25:00 0 92.0250 15.043 9.386341
> 6 2016-05-31 20:25:00 2016-05-31 20:25:00 0 91.9732 14.015 9.381058
>
> Here is the str()
>
> 'data.frame': 164 obs. of 7 variables:
> $ Date : chr " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " ...
> $ Time : chr "15:25:00" "16:25:00" "17:25:00" "18:25:00" ...
> $ date.time : POSIXct, format: " 2016-05-31 15:25:00" " 2016-05-31 16:25:00" ...
> $ ms : int 0 0 0 0 0 0 0 0 0 0 ...
> $ LEVEL : num 92.2 92.1 92.1 92.1 92 ...
> $ TEMPERATURE: num 25.2 18 18 16.3 15 ...
> $ Level_m : num 9.4 9.4 9.39 9.39 9.39 ...
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Thu Feb  2 09:07:11 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 2 Feb 2017 19:07:11 +1100
Subject: [R] sub-setting rows based on dates in R
In-Reply-To: <KL1PR01MB0999572A7CC95503DBE8F0FBB64D0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB0999FC07E36B092AFAD82C44B64A0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
	<CA+8X3fWWO1yMpEqDUx7Xt4Tck1NpymvzaUwACYTGhMn0EqsVOQ@mail.gmail.com>
	<KL1PR01MB0999572A7CC95503DBE8F0FBB64D0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fUhKxHysrc37jVSGjrfFjzTNTFmj5XBfO81KeCs6XCy0A@mail.gmail.com>

Hi Md,
What I have done is to use the most recent intervening date between the
last set of dates if any are there, otherwise the last set of dates. That
is what I understand from your description.

Remember that this is a very clunky way to do something like this by adding
rows to a data frame, and it is likely to scale up to large data sets badly.

df1<-read.table(text="Date    Rainfall_Duration
 6/14/2016       10
 6/15/2016       20
 6/17/2016       10
 8/16/2016       30
 8/19/2016       40
 8/21/2016       20
 9/4/2016        10",
 header=TRUE,stringsAsFactors=FALSE)
# change the character strings in df2$Date to Date values
df1$Date<-as.Date(df1$Date,"%m/%d/%Y")

df2<-read.table(text="Date    Removal.Rate
 6/17/2016    64.7
 6/30/2016    22.63
 7/14/2016    18.18
 8/19/2016    27.87
 8/30/2016    23.45
 9/2/2016     17.2",
 header=TRUE,stringsAsFactors=FALSE)
# change the character strings in df2$Date to Date values
df2$Date<-as.Date(df2$Date,"%m/%d/%Y")

df3<-data.frame(Rate.Removal.Date=NULL,Date=NULL,Rainfall_Duration=NULL)

df3row<-0

for(i in 1:dim(df2)[1]) {
 rdrows<-which(df2$Date[i] >= df1$Date & !(df2$Date[i] > df1$Date + 8))
 # if there are no dates in df1 within the prior 7 days
 if(!length(rdrows)) {
  # first check if at least one date in df1 is less than the df2
  # date and is not included in the last set of df1 dates
  checkrows<-which(df2$Date[i] >= df1$Date)
  # use the last date greater than the maximum in lastrows
  if(any(checkrows > lastrows))
   rdrows<-max(checkrows[checkrows > lastrows])
  # otherwise use the last set
  else rdrows<-lastrows
 }
 # save the current set of dates
 lastrows<-rdrows
 # get the number of new rows
 nrows<-length(rdrows)
 for(row in 1:nrows) {
  # set the values in each row
  df3[row+df3row,1]<-format(df2$Date[i],"%m/%d/%Y")
  df3[row+df3row,2]<-format(df1$Date[rdrows[row]],"%m/%d/%Y")
  df3[row+df3row,3]<-df1$Rainfall_Duration[rdrows[row]]
 }
 # keep count of the current number of rows
 df3row<-df3row+nrows
}

names(df3)<-c("Rate.Removal.Date","Date","Rainfall_Duration")
df3

Jim


On Thu, Feb 2, 2017 at 4:58 AM, Md Sami Bin Shokrana <samimist at live.com>
wrote:

> Hi Jim,
>
> Thank you so much for your help. Your code works great. Could you please
> explain your code a bit? One more thing, I am so sorry that I forgot to
> mention one more criteria in my post. If it is not much trouble, could you
> please help me out with that? I have added a couple more observations
> (the bold ones) to each of my data frames which are shown below:
>
>
> The main concept is,
>
> (i) For a specific date in df2, if no matching dates are available in df1
> within the 7 days range, the code will keep on looking for the latest
> available date in df1 with a "Rainfall_Duration" data. For example, in df2,
> for *8/30/2016*, there is no "Rainfall_Duration" data available in
> df1 within the prior 7 days range. So, I want the code to keep on looking
> for dates in df1 until there is an available data for "Rainfall_Duration"
> in df1 (in this case which is * 8/21/2016)* .
>
>
> (ii) Additionally, for* 9/2/2016 *(df2), there is no date available in
> df1 with a "Rainfall_Duration" data within prior 7 days range. The latest
> available data for "Rainfall_Duration" is *8/21/2016*. So, the code will
> extract the same result we had for *8/30/2016* in df2.
>
>  In simpler words, i just want the code to keep on looking for data with
> "Rainfall_Duraiton" in df1 if there is none available within the prior 7
> days range. Sorry for not mentioning it before.
>
>
>
> df1 <-
>
> Date Rainfall_Duration
> 6/14/2016 10
> 6/15/2016 20
> 6/17/2016 10
> 8/16/2016 30
> 8/19/2016 40
> *8/21/2016* *20* *9/4/2016                 10*
>
>
> df2 <-
>
> Date Removal.Rate
> 6/17/2016 64.7
> 6/30/2016 22.63
> 7/14/2016 18.18
> 8/19/2016 27.87
> *8/30/2016* *23.45* *9/2/2016         17.2*
>
>
> Expected output:
>
>
> df3 <-
>
> Rate.Removal.Date     Date Rainfall_Duration
> 6/17/2016 6/14/2016 10
> 6/17/2016 6/15/2016 20
> 6/17/2016 6/17/2016 10
> 6/30/2016 6/14/2016 10
> 6/30/2016 6/15/2016 20
> 6/30/2016 6/17/2016 10
> 7/14/2016 6/14/2016 10
> 7/14/2016 6/15/2016 20
> 7/14/2016 6/17/2016 10
> 8/19/2016 8/16/2016 30
> 8/19/2016 8/19/2016 40
> *8/30/2016* *8/21/2016* *20* *9/2/2016                 8/21/2016       20*
>
>
> Thanks in advance.
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* Wednesday, February 1, 2017 1:18 PM
> *To:* Md Sami Bin Shokrana; r-help mailing list
> *Subject:* Re: [R] sub-setting rows based on dates in R
>
> Hi Md,
> This kind of clunky, but it might do what you want.
>
> df1<-read.table(text="Date    Rainfall_Duration
>  6/14/2016       10
>  6/15/2016       20
>  6/17/2016       10
>  8/16/2016       30
>  8/19/2016       40",
>  header=TRUE,stringsAsFactors=FALSE)
>
> df1$Date<-as.Date(df1$Date,"%m/%d/%Y")
>
> df2<-read.table(text="Date    Removal.Rate
>  6/17/2016    64.7
>  6/30/2016    22.63
>  7/14/2016    18.18
>  8/19/2016    27.87",
>  header=TRUE,stringsAsFactors=FALSE)
>
> df2$Date<-as.Date(df2$Date,"%m/%d/%Y")
>
> df3<-data.frame(Rate.Removal.Date=NULL,Date=NULL,Rainfall_Duration=NULL)
>
> df3row<-0
>
> for(i in 1:dim(df2)[1]) {
>  rdrows<-which(df2$Date[i] >= df1$Date & !(df2$Date[i] > df1$Date + 8))
>  if(!length(rdrows)) rdrows<-lastrows
>  lastrows<-rdrows
>  nrows<-length(rdrows)
>  for(row in 1:nrows) {
>   df3[row+df3row,1]<-format(df2$Date[i],"%m/%d/%Y")
>   df3[row+df3row,2]<-format(df1$Date[rdrows[row]],"%m/%d/%Y")
>   df3[row+df3row,3]<-df1$Rainfall_Duration[rdrows[row]]
>  }
>  df3row<-df3row+nrows
> }
>
> names(df3)<-c("Rate.Removal.Date","Date","Rainfall_Duration")
> df3
>
> Jim
>
> On Wed, Feb 1, 2017 at 3:48 AM, Md Sami Bin Shokrana <samimist at live.com>
> wrote:
> > Hello guys, I am trying to solve a problem in R. I have 2 data frames
> which look like this:
> > df1 <-
> >   Date    Rainfall_Duration
> > 6/14/2016       10
> > 6/15/2016       20
> > 6/17/2016       10
> > 8/16/2016       30
> > 8/19/2016       40
> >
> > df2 <-
> >   Date    Removal.Rate
> > 6/17/2016    64.7
> > 6/30/2016    22.63
> > 7/14/2016    18.18
> > 8/19/2016    27.87
> >
> > I want to look up the dates from df2 in df1 and their corresponding
> Rainfall_Duration data. For example, I want to look for the 1st date of df2
> in df1 and subset rows in df1 for that specific date and 7 days prior to
> that. additionally, for example: for 6/30/2016 (in df2) there is no dates
> available in df1 within it's 7 days range. So, in this case I just want to
> extract the results same as it's previous date (6/17/2016) in df2. Same
> logic goes for 7/14/2016(df2).
> > The output should look like this:
> >
> > df3<-
> >
> > Rate.Removal.Date      Date             Rainfall_Duration
> > 6/17/2016              6/14/2016              10
> > 6/17/2016              6/15/2016              20
> > 6/17/2016              6/17/2016              10
> > 6/30/2016              6/14/2016              10
> > 6/30/2016              6/15/2016              20
> > 6/30/2016              6/17/2016              10
> > 7/14/2016              6/14/2016              10
> > 7/14/2016              6/15/2016              20
> > 7/14/2016              6/17/2016              10
> > 8/19/2016              8/16/2016              30
> > 8/19/2016              8/19/2016              40
> >
> > I could subset data for the 7 days range. But could not do it when no
> dates are available in that range. I have the following code:
> > library(plyr)
> > library (dplyr)
> > df1$Date <- as.Date(df1$Date,format = "%m/%d/%Y")
> > df2$Date <- as.Date(df2$Date,format = "%m/%d/%Y")
> >
> > df3 <- lapply(df2$Date, function(x){
> >   filter(df1, between(Date, x-7, x))
> > })
> >
> > names(df3) <- as.character(df2$Date)
> > bind_rows(df3, .id = "Rate.Removal.Date")
> > df3 <- ldply (df3, data.frame, .id = "Rate.Removal.Date")
> >
> > I hope I could explain my problem properly. I would highly appreciate if
> someone can help me out with this code or a new one. Thanks in advance.
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> R-help Info Page - Homepage - SfS ? Seminar for Statistics
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> stat.ethz.ch
> The main R mailing list, for announcements about the development of R and
> the availability of new code, questions and answers about problems and
> solutions using R ...
>
>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Feb  2 12:54:20 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 02 Feb 2017 11:54:20 +0000
Subject: [R] Export Forecasted output to a table (excel)
In-Reply-To: <CACuGqaKzesHH2LtYJFHmY2nnotS7A97NXgHA-a=jsYH9OTasQA@mail.gmail.com>
References: <CACuGqa+zRfWmaNsfMvzLNbcwwcSbXxsE1RfCYp-94qAHBWHN=g@mail.gmail.com>
	<CACuGqaKzesHH2LtYJFHmY2nnotS7A97NXgHA-a=jsYH9OTasQA@mail.gmail.com>
Message-ID: <58931DEC.1000605@sapo.pt>

Hello,

Objects of type mforecast are list with many members. In order to have a 
data.frame you need to tell us which members you want. Do not mistake 
the output of the print method with the object, to see what mforecast 
objects are try

str(fcst)

Rui Barradas

Em 02-02-2017 01:55, Lal Prasad escreveu:
> Thanks all for the information provided.
> Is there any way I could convert an object of type mforecast (output of
> forecast()) to dataframe?
>
> On Thu, Feb 2, 2017 at 12:33 AM, Lal Prasad <lal.prasad at gmail.com> wrote:
>
>> Hi All,
>>
>> Is there any way to
>>
>> 1) Convert the below forecast to a datafram
>> 2) Any way to write it to an excel table?
>>
>>
>> library(vars)
>> library(fpp)VARselect(usconsumption, lag.max = 3, type="const")$selectionvar <- VAR(usconsumption, p=1,type = "both",lag.max = 3)
>> serial.test(var, lags.pt = 3,type = "PT.asymptotic")
>>
>> fcst <- forecast(var)
>>
>> Regards
>>
>> Lal
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From josh.m.ulrich at gmail.com  Thu Feb  2 13:38:14 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 2 Feb 2017 06:38:14 -0600
Subject: [R] How to create 10 minute time series from hourly data
In-Reply-To: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>
References: <779140718.25434668.1485967317240.JavaMail.zimbra@sfu.ca>
Message-ID: <CAPPM_gRpOqAnHY3ErPevUPW28wpEXVmqv_kk7bDkzAhC_mouTA@mail.gmail.com>

On Wed, Feb 1, 2017 at 10:41 AM, Mary Ann Middleton <maberg at sfu.ca> wrote:
> Hello,
>
> Apologies if this is a duplicate. I think I sent it to the wrong list yesterday.
>
> I would appreciate some direction/suggestions with a problem with a time series.
>
> I have a regular time series dataframe with hourly data. I need to create a time series with a 10 minute interval for $Level_m to compare to another time series.
>
> I would like to apply an approximation and create a time series with 10 minute intervals from the data series I have. I do not want to smooth the data and so I think a linear approximation would suffice.
>
> I have also searched xts for possible solutions but haven't had luck. Any input is greatly appreciated.
>
Here's an xts solution:

# Create xts object from data.frame
x <- xts(Data[,c("ms", "LEVEL", "TEMPERATURE", "Level_m")], Data$date.time)
# Create regular, 10-minute, "zero-width" (i.e. no columns) xts object
# that spans all the times in 'x'
x10min <- xts(, order.by = seq(start(x), end(x), by = "10 min"))
# Merge regular xts object with original data, filling via zoo::na.approx
y <- merge(x, x10min, fill = na.approx)


> ~Mary Ann Middleton, PhD
>
>
>
>
> Here is a sample of the data I have:
>
> Date Time date.time ms LEVEL TEMPERATURE Level_m
> 1 2016-05-31 15:25:00 2016-05-31 15:25:00 0 92.1767 25.171 9.401814
> 2 2016-05-31 16:25:00 2016-05-31 16:25:00 0 92.1498 18.023 9.399071
> 3 2016-05-31 17:25:00 2016-05-31 17:25:00 0 92.0781 17.951 9.391757
> 4 2016-05-31 18:25:00 2016-05-31 18:25:00 0 92.0664 16.312 9.390564
> 5 2016-05-31 19:25:00 2016-05-31 19:25:00 0 92.0250 15.043 9.386341
> 6 2016-05-31 20:25:00 2016-05-31 20:25:00 0 91.9732 14.015 9.381058
>
> Here is the str()
>
> 'data.frame': 164 obs. of 7 variables:
> $ Date : chr " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " " 2016-05-31 " ...
> $ Time : chr "15:25:00" "16:25:00" "17:25:00" "18:25:00" ...
> $ date.time : POSIXct, format: " 2016-05-31 15:25:00" " 2016-05-31 16:25:00" ...
> $ ms : int 0 0 0 0 0 0 0 0 0 0 ...
> $ LEVEL : num 92.2 92.1 92.1 92.1 92 ...
> $ TEMPERATURE: num 25.2 18 18 16.3 15 ...
> $ Level_m : num 9.4 9.4 9.39 9.39 9.39 ...
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From mak.hholly at gmail.com  Thu Feb  2 14:33:30 2017
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 2 Feb 2017 08:33:30 -0500
Subject: [R] looping problem
In-Reply-To: <589229D5.6010306@sapo.pt>
References: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
	<589229D5.6010306@sapo.pt>
Message-ID: <CAM9Qe4innBJoFbfgkSRTJddUWxq_y9saz0h8E+XOOV5=qtAzaQ@mail.gmail.com>

Hi Rui;

Is there any way to insert the chr ids in numeric as 1,2......,22 in the
final output. Here is output from str(temp). So I need also chr ids in a
column.
1          rs58108140 10583 G A -0.070438 0.059903
2         rs189107123 10611 C G -0.044916 0.085853

Regards,
Greg


On Wed, Feb 1, 2017 at 1:32 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> If what you want is to combine the files into one data.frame then there
> are 2 things you should see:
>
> 1) You create a variable named 'temp' and don't ever use it.
> 2) You never combine the data.frames you read in.
>
> Try instead the following.
>
> temp <- data.frame()
> for(i in 1:22) {
>     infile<-paste("chr",i,"/Z-score.imputed",sep="")
>     psT<-read.table(infile,header=T,as.is=T,sep="\t")
>     temp <- rbind(temp, psT)
> }
>
> str(temp)  # to see what you have
>
> Hope this helps,
>
> Rui Barradas
>
>
>
>
> Em 01-02-2017 17:25, greg holly escreveu:
>
>> Hi all;
>>
>> I have 22 directories named chr1, chr2,....,chr22. Each directory has a
>> file named "Z-score.imputed". I would like to combine  Z-score.imputed
>> files into one. I wrote the following loop but did not get any results.
>> Your helps are highly appreciated.
>>
>> regards,
>>
>> Greg
>>
>> temp<-c()
>>
>> for(i in 1:22) {
>> infile<-paste("chr",i,"/Z-score.imputed",sep="")
>> psT<-read.table(as.character(infile),header=T,as.is=T,sep="\t")
>> ps<-psT[psT$Var>0.6,]
>> ratio=nrow(ps)/nrow(psT)
>> print(ratio)
>> }
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From calandra at rgzm.de  Thu Feb  2 14:59:05 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Thu, 2 Feb 2017 14:59:05 +0100
Subject: [R] legend in ggplot2
Message-ID: <9a15a02c-79c7-edba-6395-3202fd1898b7@rgzm.de>

Dear useRs,

I have been using base graphics since a long time and I'm currently 
trying to switch to ggplot2. I'm struggling with the legend (which 
probably means that my graphic commands are not optimal).
I have copied the output from dput(mydata) at the end of the email.

Here is what I have tried:
library(ggplot2)
library(cowplot)
colo <- c("#F8766D", "#00BFC4")
p1 <- ggplot(data=mydata[mydata$Equipment=="Shore",], 
aes(x=Spot,y=Value)) + 
geom_boxplot(outlier.size=2,fill=colo[1],outlier.color=colo[1]) + 
geom_jitter()
p2 <- ggplot(data=mydata[mydata$Equipment=="Leeb",], 
aes(x=Spot,y=Value)) + 
geom_boxplot(outlier.size=2,fill=colo[2],outlier.color=colo[2]) + 
geom_jitter()
plot_grid(p1, p2, nrow=2, ncol=1)

The plot is fine, but there is no legend at all. I know this has to do 
with 'color' and 'fill' arguments to aes(), but I got lost with all of 
this...
Ideally, I am looking for this kind of structure in the legend:
Equipment
     [red box] Shore
     [blue box] Leeb
Points
     [black dot] Measurements
     [red/blue dot] Outliers

Thank you in advance for your help!
Bests,
Ivan


mydata <- structure(list(Equipment = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Leeb", "Shore"), class = "factor"), Spot = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("1", "2", "3"), class = "factor"), Measurement = structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L), .Label = c("1","2", "3", "4", "5", "6", "7", "8", "9", "10"), class = "factor"), Value = c(540, 640, 587, 593, 677, 675, 626, 625, 635, 645, 492, 538, 560, 565, 560, 543, 560, 555, 580, 577, 645, 645, 667, 658, 652, 667, 652, 659, 669, 671, 89, 90.5, 93, 91, 91.5, 94, 94, 91.5, 92.5, 91.5, 82, 82, 78.5, 84.5, 83.5, 87, 88, 88.5, 83.5, 88, 89, 87, 87, 88, 92, 90.5, 88, 90.5, 93, 92.5)), .Names = c("Equipment", "Spot", "Measurement", "Value"), row.names = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L), class = "data.frame")


-- 


--
Ivan Calandra, PhD
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
calandra at rgzm.de
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra
https://rgzm.academia.edu/IvanCalandra
https://publons.com/author/705639/


From thierry.onkelinx at inbo.be  Thu Feb  2 15:12:26 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 2 Feb 2017 15:12:26 +0100
Subject: [R] legend in ggplot2
In-Reply-To: <9a15a02c-79c7-edba-6395-3202fd1898b7@rgzm.de>
References: <9a15a02c-79c7-edba-6395-3202fd1898b7@rgzm.de>
Message-ID: <CAJuCY5yAR5o+gZEN7aJjjFhX7cMnRDtN3R09Z388giB=2N_ksQ@mail.gmail.com>

Dear Ivan,

You're making things too complicated.

ggplot(mydata, aes(x = Spot, y = Value)) +
  geom_boxplot(aes(colour = Equipment), outlier.colour = "red") +
  geom_jitter() +
  facet_wrap(~Equipment, scales = "free_y") +
  scale_colour_manual(values = c(Leeb = "blue", Shore = "red"))

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-02-02 14:59 GMT+01:00 Ivan Calandra <calandra at rgzm.de>:

> Dear useRs,
>
> I have been using base graphics since a long time and I'm currently trying
> to switch to ggplot2. I'm struggling with the legend (which probably means
> that my graphic commands are not optimal).
> I have copied the output from dput(mydata) at the end of the email.
>
> Here is what I have tried:
> library(ggplot2)
> library(cowplot)
> colo <- c("#F8766D", "#00BFC4")
> p1 <- ggplot(data=mydata[mydata$Equipment=="Shore",],
> aes(x=Spot,y=Value)) + geom_boxplot(outlier.size=2,fi
> ll=colo[1],outlier.color=colo[1]) + geom_jitter()
> p2 <- ggplot(data=mydata[mydata$Equipment=="Leeb",], aes(x=Spot,y=Value))
> + geom_boxplot(outlier.size=2,fill=colo[2],outlier.color=colo[2]) +
> geom_jitter()
> plot_grid(p1, p2, nrow=2, ncol=1)
>
> The plot is fine, but there is no legend at all. I know this has to do
> with 'color' and 'fill' arguments to aes(), but I got lost with all of
> this...
> Ideally, I am looking for this kind of structure in the legend:
> Equipment
>     [red box] Shore
>     [blue box] Leeb
> Points
>     [black dot] Measurements
>     [red/blue dot] Outliers
>
> Thank you in advance for your help!
> Bests,
> Ivan
>
>
> mydata <- structure(list(Equipment = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L), .Label = c("Leeb", "Shore"), class = "factor"), Spot = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L), .Label = c("1", "2", "3"), class = "factor"), Measurement =
> structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L), .Label = c("1","2", "3", "4", "5",
> "6", "7", "8", "9", "10"), class = "factor"), Value = c(540, 640, 587, 593,
> 677, 675, 626, 625, 635, 645, 492, 538, 560, 565, 560, 543, 560, 555, 580,
> 577, 645, 645, 667, 658!
> , 652, 667, 652, 659, 669, 671, 89, 90.5, 93, 91, 91.5, 94, 94, 91.5,
> 92.5, 91.5, 82, 82, 78.5, 84.5, 83.5, 87, 88, 88.5, 83.5, 88, 89, 87, 87,
> 88, 92, 90.5, 88, 90.5, 93, 92.5)), .Names = c("Equipment", "Spot",
> "Measurement", "Value"), row.names = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 101L, 102L, 103L, 104L, 105L, 106L, 107L,
> 108L, 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L,
> 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L), class =
> "data.frame")
>
>
> --
>
>
> --
> Ivan Calandra, PhD
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> calandra at rgzm.de
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> https://rgzm.academia.edu/IvanCalandra
> https://publons.com/author/705639/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From calandra at rgzm.de  Thu Feb  2 15:24:14 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Thu, 2 Feb 2017 15:24:14 +0100
Subject: [R] legend in ggplot2
In-Reply-To: <CAJuCY5yAR5o+gZEN7aJjjFhX7cMnRDtN3R09Z388giB=2N_ksQ@mail.gmail.com>
References: <9a15a02c-79c7-edba-6395-3202fd1898b7@rgzm.de>
	<CAJuCY5yAR5o+gZEN7aJjjFhX7cMnRDtN3R09Z388giB=2N_ksQ@mail.gmail.com>
Message-ID: <73c64103-aa6b-1202-9905-127cd941032d@rgzm.de>

Thanks Thierry,

I knew there had to be a simpler way, but just could not find it 
(facet_wrap() does the trick!).

Just 2 other questions:
- How do I remove the plot titles? I don't find any argument in 
facet_wrap() on that...
- How can I add the legend for the outliers?

Thanks again,
Ivan

--
Ivan Calandra, PhD
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
calandra at rgzm.de
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra
https://rgzm.academia.edu/IvanCalandra
https://publons.com/author/705639/

On 02/02/2017 15:12, Thierry Onkelinx wrote:
> Dear Ivan,
>
> You're making things too complicated.
>
> ggplot(mydata, aes(x = Spot, y = Value)) +
>   geom_boxplot(aes(colour = Equipment), outlier.colour = "red") +
>   geom_jitter() +
>   facet_wrap(~Equipment, scales = "free_y") +
>   scale_colour_manual(values = c(Leeb = "blue", Shore = "red"))
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2017-02-02 14:59 GMT+01:00 Ivan Calandra <calandra at rgzm.de 
> <mailto:calandra at rgzm.de>>:
>
>     Dear useRs,
>
>     I have been using base graphics since a long time and I'm
>     currently trying to switch to ggplot2. I'm struggling with the
>     legend (which probably means that my graphic commands are not
>     optimal).
>     I have copied the output from dput(mydata) at the end of the email.
>
>     Here is what I have tried:
>     library(ggplot2)
>     library(cowplot)
>     colo <- c("#F8766D", "#00BFC4")
>     p1 <- ggplot(data=mydata[mydata$Equipment=="Shore",],
>     aes(x=Spot,y=Value)) +
>     geom_boxplot(outlier.size=2,fill=colo[1],outlier.color=colo[1]) +
>     geom_jitter()
>     p2 <- ggplot(data=mydata[mydata$Equipment=="Leeb",],
>     aes(x=Spot,y=Value)) +
>     geom_boxplot(outlier.size=2,fill=colo[2],outlier.color=colo[2]) +
>     geom_jitter()
>     plot_grid(p1, p2, nrow=2, ncol=1)
>
>     The plot is fine, but there is no legend at all. I know this has
>     to do with 'color' and 'fill' arguments to aes(), but I got lost
>     with all of this...
>     Ideally, I am looking for this kind of structure in the legend:
>     Equipment
>         [red box] Shore
>         [blue box] Leeb
>     Points
>         [black dot] Measurements
>         [red/blue dot] Outliers
>
>     Thank you in advance for your help!
>     Bests,
>     Ivan
>
>
>     mydata <- structure(list(Equipment = structure(c(1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Leeb", "Shore"), class =
>     "factor"), Spot = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L), .Label = c("1", "2", "3"), class = "factor"),
>     Measurement = structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
>     1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L,
>     7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L,
>     3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
>     9L, 10L), .Label = c("1","2", "3", "4", "5", "6", "7", "8", "9",
>     "10"), class = "factor"), Value = c(540, 640, 587, 593, 677, 675,
>     626, 625, 635, 645, 492, 538, 560, 565, 560, 543, 560, 555, 580,
>     577, 645, 645, 667, 658!
>     , 652, 667, 652, 659, 669, 671, 89, 90.5, 93, 91, 91.5, 94, 94,
>     91.5, 92.5, 91.5, 82, 82, 78.5, 84.5, 83.5, 87, 88, 88.5, 83.5,
>     88, 89, 87, 87, 88, 92, 90.5, 88, 90.5, 93, 92.5)), .Names =
>     c("Equipment", "Spot", "Measurement", "Value"), row.names = c(1L,
>     2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
>     17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
>     30L, 101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 109L, 110L,
>     111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L, 120L, 121L,
>     122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L), class =
>     "data.frame")
>
>
>     -- 
>
>
>     --
>     Ivan Calandra, PhD
>     MONREPOS Archaeological Research Centre and
>     Museum for Human Behavioural Evolution
>     Schloss Monrepos
>     56567 Neuwied, Germany
>     calandra at rgzm.de <mailto:calandra at rgzm.de>
>     +49 (0) 2631 9772-243 <tel:%2B49%20%280%29%202631%209772-243>
>     https://www.researchgate.net/profile/Ivan_Calandra
>     <https://www.researchgate.net/profile/Ivan_Calandra>
>     https://rgzm.academia.edu/IvanCalandra
>     <https://rgzm.academia.edu/IvanCalandra>
>     https://publons.com/author/705639/
>     <https://publons.com/author/705639/>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From ruipbarradas at sapo.pt  Thu Feb  2 15:39:32 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 02 Feb 2017 14:39:32 +0000
Subject: [R] looping problem
In-Reply-To: <CAM9Qe4innBJoFbfgkSRTJddUWxq_y9saz0h8E+XOOV5=qtAzaQ@mail.gmail.com>
References: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
	<589229D5.6010306@sapo.pt>
	<CAM9Qe4innBJoFbfgkSRTJddUWxq_y9saz0h8E+XOOV5=qtAzaQ@mail.gmail.com>
Message-ID: <589344A4.90109@sapo.pt>

Hello,

If I understand correctly, just use ?cbind.

Rui Barradas

Em 02-02-2017 13:33, greg holly escreveu:
> Hi Rui;
>
> Is there any way to insert the chr ids in numeric as 1,2......,22 in the
> final output. Here is output from str(temp). So I need also chr ids in a
> column.
> 1          rs58108140 10583 G A -0.070438 0.059903
> 2         rs189107123 10611 C G -0.044916 0.085853
>
> Regards,
> Greg
>
>
> On Wed, Feb 1, 2017 at 1:32 PM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     If what you want is to combine the files into one data.frame then
>     there are 2 things you should see:
>
>     1) You create a variable named 'temp' and don't ever use it.
>     2) You never combine the data.frames you read in.
>
>     Try instead the following.
>
>     temp <- data.frame()
>     for(i in 1:22) {
>          infile<-paste("chr",i,"/Z-score.imputed",sep="")
>          psT<-read.table(infile,header=T,as.is <http://as.is>=T,sep="\t")
>          temp <- rbind(temp, psT)
>     }
>
>     str(temp)  # to see what you have
>
>     Hope this helps,
>
>     Rui Barradas
>
>
>
>
>     Em 01-02-2017 17:25, greg holly escreveu:
>
>         Hi all;
>
>         I have 22 directories named chr1, chr2,....,chr22. Each
>         directory has a
>         file named "Z-score.imputed". I would like to combine
>         Z-score.imputed
>         files into one. I wrote the following loop but did not get any
>         results.
>         Your helps are highly appreciated.
>
>         regards,
>
>         Greg
>
>         temp<-c()
>
>         for(i in 1:22) {
>         infile<-paste("chr",i,"/Z-score.imputed",sep="")
>         psT<-read.table(as.character(infile),header=T,as.is
>         <http://as.is>=T,sep="\t")
>         ps<-psT[psT$Var>0.6,]
>         ratio=nrow(ps)/nrow(psT)
>         print(ratio)
>         }
>
>                  [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>


From marc_grt at yahoo.fr  Thu Feb  2 15:30:57 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 2 Feb 2017 15:30:57 +0100
Subject: [R] Function that works within a package and not when copied in
 global environment. Why?
Message-ID: <82f987ca-f11d-c6e1-db39-71a8415195e2@yahoo.fr>

Dear experts,

In the package nlWaldTest, there is an hidden function : .smartsub

I can use it, for example:

 > getFromNamespace(".smartsub", ns="nlWaldTest")(pat="x", repl="b" ,
x="essai(b[1], b[2], x[1])")
[1] "essai(b[1], b[2], b[1])"

Now I try to create this function in my global environment:
smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")

It works also:
 > smartsub(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
[1] "essai(b[1], b[2], b[1])"

But if I create the function manually:
 > smartsub2 <- function (pat, repl, x)
  {
      args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
      names <- if (is.null(names(args)))
          character(length(args))
      else names(args)
      dovec <- names %in% vectorize.args
      do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs = 
list(args[!dovec]),
                          SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
  }
 > smartsub2(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
Error in names %in% vectorize.args : objet 'vectorize.args' introuvable

It fails because vectorize.args is unknown

Indeed smartsub2 is different from smartsub.
 > identical(smartsub, smartsub2)
[1] FALSE

1/ Why are they different? They are just a copy of each other.

2/ Second question, vectorize.args is indeed not defined before to be 
used in the function. Why no error is produced in original function?

Thanks a lot

Marc


-- 

__________________________________________________________
Marc Girondot, Pr

Laboratoire Ecologie, Syst?matique et Evolution
Equipe de Conservation des Populations et des Communaut?s
CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
B?timent 362
91405 Orsay Cedex, France

Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
e-mail: marc.girondot at u-psud.fr
Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
Skype: girondot


From mak.hholly at gmail.com  Thu Feb  2 16:13:08 2017
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 2 Feb 2017 10:13:08 -0500
Subject: [R] looping problem
In-Reply-To: <589344A4.90109@sapo.pt>
References: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
	<589229D5.6010306@sapo.pt>
	<CAM9Qe4innBJoFbfgkSRTJddUWxq_y9saz0h8E+XOOV5=qtAzaQ@mail.gmail.com>
	<589344A4.90109@sapo.pt>
Message-ID: <CAM9Qe4j-hZ+WxxR0NmLk6bGMMRrOBnVVrwNRvzFRS2e3kmasvA@mail.gmail.com>

Thanks so much for this. Unfortunately, cbind did not work. Basically, I
like to put an extra column named "chr" in the combined file from 22 chr.
So chr colum will be "1" for the portion of chr1 in the combined file, 2
for the portion of chr2 in the combined file and so on.

Regards,

Greg

On Thu, Feb 2, 2017 at 9:39 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> If I understand correctly, just use ?cbind.
>
> Rui Barradas
>
> Em 02-02-2017 13:33, greg holly escreveu:
>
>> Hi Rui;
>>
>> Is there any way to insert the chr ids in numeric as 1,2......,22 in the
>> final output. Here is output from str(temp). So I need also chr ids in a
>> column.
>> 1          rs58108140 10583 G A -0.070438 0.059903
>> 2         rs189107123 10611 C G -0.044916 0.085853
>>
>> Regards,
>> Greg
>>
>>
>> On Wed, Feb 1, 2017 at 1:32 PM, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>
>>     Hello,
>>
>>     If what you want is to combine the files into one data.frame then
>>     there are 2 things you should see:
>>
>>     1) You create a variable named 'temp' and don't ever use it.
>>     2) You never combine the data.frames you read in.
>>
>>     Try instead the following.
>>
>>     temp <- data.frame()
>>     for(i in 1:22) {
>>          infile<-paste("chr",i,"/Z-score.imputed",sep="")
>>          psT<-read.table(infile,header=T,as.is <http://as.is>=T,sep="\t")
>>          temp <- rbind(temp, psT)
>>     }
>>
>>     str(temp)  # to see what you have
>>
>>     Hope this helps,
>>
>>     Rui Barradas
>>
>>
>>
>>
>>     Em 01-02-2017 17:25, greg holly escreveu:
>>
>>         Hi all;
>>
>>         I have 22 directories named chr1, chr2,....,chr22. Each
>>         directory has a
>>         file named "Z-score.imputed". I would like to combine
>>         Z-score.imputed
>>         files into one. I wrote the following loop but did not get any
>>         results.
>>         Your helps are highly appreciated.
>>
>>         regards,
>>
>>         Greg
>>
>>         temp<-c()
>>
>>         for(i in 1:22) {
>>         infile<-paste("chr",i,"/Z-score.imputed",sep="")
>>         psT<-read.table(as.character(infile),header=T,as.is
>>         <http://as.is>=T,sep="\t")
>>         ps<-psT[psT$Var>0.6,]
>>         ratio=nrow(ps)/nrow(psT)
>>         print(ratio)
>>         }
>>
>>                  [[alternative HTML version deleted]]
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Feb  2 16:28:58 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Feb 2017 15:28:58 +0000
Subject: [R] looping problem
In-Reply-To: <CAM9Qe4j-hZ+WxxR0NmLk6bGMMRrOBnVVrwNRvzFRS2e3kmasvA@mail.gmail.com>
References: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
	<589229D5.6010306@sapo.pt>
	<CAM9Qe4innBJoFbfgkSRTJddUWxq_y9saz0h8E+XOOV5=qtAzaQ@mail.gmail.com>
	<589344A4.90109@sapo.pt>
	<CAM9Qe4j-hZ+WxxR0NmLk6bGMMRrOBnVVrwNRvzFRS2e3kmasvA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A14500@SRVEXCHCM301.precheza.cz>

Hi.

Your messages are rather confusing. Well, if you could get correct final data.frame in loop why not just add inside of loop new column(s) by

psT$chr <- i

Maybe it is time to read R intro as good source for starting with R. It has about 100 pages, but you can pick as start only pages 2-40 which are basic for data input and manipulation.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg holly
> Sent: Thursday, February 2, 2017 4:13 PM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] looping problem
>
> Thanks so much for this. Unfortunately, cbind did not work. Basically, I like to
> put an extra column named "chr" in the combined file from 22 chr.
> So chr colum will be "1" for the portion of chr1 in the combined file, 2 for the
> portion of chr2 in the combined file and so on.
>
> Regards,
>
> Greg
>
> On Thu, Feb 2, 2017 at 9:39 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> > Hello,
> >
> > If I understand correctly, just use ?cbind.
> >
> > Rui Barradas
> >
> > Em 02-02-2017 13:33, greg holly escreveu:
> >
> >> Hi Rui;
> >>
> >> Is there any way to insert the chr ids in numeric as 1,2......,22 in
> >> the final output. Here is output from str(temp). So I need also chr
> >> ids in a column.
> >> 1          rs58108140 10583 G A -0.070438 0.059903
> >> 2         rs189107123 10611 C G -0.044916 0.085853
> >>
> >> Regards,
> >> Greg
> >>
> >>
> >> On Wed, Feb 1, 2017 at 1:32 PM, Rui Barradas <ruipbarradas at sapo.pt
> >> <mailto:ruipbarradas at sapo.pt>> wrote:
> >>
> >>     Hello,
> >>
> >>     If what you want is to combine the files into one data.frame then
> >>     there are 2 things you should see:
> >>
> >>     1) You create a variable named 'temp' and don't ever use it.
> >>     2) You never combine the data.frames you read in.
> >>
> >>     Try instead the following.
> >>
> >>     temp <- data.frame()
> >>     for(i in 1:22) {
> >>          infile<-paste("chr",i,"/Z-score.imputed",sep="")
> >>          psT<-read.table(infile,header=T,as.is <http://as.is>=T,sep="\t")
> >>          temp <- rbind(temp, psT)
> >>     }
> >>
> >>     str(temp)  # to see what you have
> >>
> >>     Hope this helps,
> >>
> >>     Rui Barradas
> >>
> >>
> >>
> >>
> >>     Em 01-02-2017 17:25, greg holly escreveu:
> >>
> >>         Hi all;
> >>
> >>         I have 22 directories named chr1, chr2,....,chr22. Each
> >>         directory has a
> >>         file named "Z-score.imputed". I would like to combine
> >>         Z-score.imputed
> >>         files into one. I wrote the following loop but did not get any
> >>         results.
> >>         Your helps are highly appreciated.
> >>
> >>         regards,
> >>
> >>         Greg
> >>
> >>         temp<-c()
> >>
> >>         for(i in 1:22) {
> >>         infile<-paste("chr",i,"/Z-score.imputed",sep="")
> >>         psT<-read.table(as.character(infile),header=T,as.is
> >>         <http://as.is>=T,sep="\t")
> >>         ps<-psT[psT$Var>0.6,]
> >>         ratio=nrow(ps)/nrow(psT)
> >>         print(ratio)
> >>         }
> >>
> >>                  [[alternative HTML version deleted]]
> >>
> >>         ______________________________________________
> >>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >>         -- To UNSUBSCRIBE and more, see
> >>         https://stat.ethz.ch/mailman/listinfo/r-help
> >>         <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>         PLEASE do read the posting guide
> >>         http://www.R-project.org/posting-guide.html
> >>         <http://www.R-project.org/posting-guide.html>
> >>         and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From percival_bueser at cocolife.com  Thu Feb  2 03:44:54 2017
From: percival_bueser at cocolife.com (Percival Bueser)
Date: Thu, 2 Feb 2017 10:44:54 +0800
Subject: [R] Help with implementing Whittaker-Henderson graduation for
	raw-data
Message-ID: <000001d27cfe$55494bd0$ffdbe370$@com>

Good day everyone!

I would appreciate if anyone can help me regarding the following: I would
like to implement the Whittaker-Henderson smoothing to the raw data on the
attached .txt file, based on the description on this link:

https://artax.karlin.mff.cuni.cz/r-help/library/pracma/html/whittaker.html

On the attached .txt file, The x's are the independent variables and the y's
are the dependent variables. The signal to be smoothed is y, lambda = 1600
and d = 2.

Can anyone please send me a sample R script, or a link to an R script which
I can adapt, where I can get both the (1) smoothed graph and the (2)
smoothed values of y for each x given, and then import both the smoothed
graph and the smoothed values of y to Microsoft Excel?

Thank you very much.

Regards,

Percy


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Sample_data.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170202/cf7d34a2/attachment.txt>

From art.tem.us at gmail.com  Thu Feb  2 08:08:15 2017
From: art.tem.us at gmail.com (Art U)
Date: Thu, 2 Feb 2017 02:08:15 -0500
Subject: [R] How to do double (nested) parSapply in R?
Message-ID: <CAKY_brHrWXDTRZ9zCdA3BdKG3_JsoGW3fqGBZq350X_8XFLSLw@mail.gmail.com>

Hello,

I have a data orig.raw that contains 8 predictors and 1 outcome variable.
I'm trying to run simulation (bootstrap) and create, let's say, 10
confidence intervals for coefficients estimated by LASSO. I did it with
regular function replicate, but now I want to do it by using parallel
programming. Here is my code:

cl <- makeCluster(detectCores())
clusterEvalQ(cl,library(glmnet))
clusterEvalQ(cl,library(MASS))
clusterExport(cl,c("orig.raw"))

pp=parSapply(cl,1:10,function(i,data=orig.raw,...){
  library(parallel)
  cl <- makeCluster(detectCores())
  clusterEvalQ(cl,library(glmnet))
  clusterEvalQ(cl,library(MASS))
  clusterExport(cl,c("orig.raw"))

  repl=parSapply(cl=cl,1:10,function(i,data=orig.raw,...){
    s1=data[sample(nrow(data),size=500,replace=TRUE),]
    cross=cv.glmnet(s1[,1:8],s1[,9])
    penalty <- cross$lambda.min
    fit=glmnet(s1[,1:8],s1[,9],alpha=1,lambda=penalty)
    coe=coef(fit)
    m=as(coe, "matrix")
    return(m)
  })

stopCluster(cl)

  mr=t(matrix(repl,nrow = 9,ncol=10))
  means=colMeans(mr)
  std=apply(mr, 2, sd)
  lb=means-1.96*std;
  ub=means+1.96*std;
  ind=t(as.numeric({beta>lb & beta<ub}))
  return(ind)})
stopCluster(cl)

And here is the error I'm getting

Error in checkForRemoteErrors(val) : 8 nodes produced errors; first
error: comparison (6) is possible only for atomic and list types

If I run only function repl - it works and I get the matrix that contains
coefficients from 10 runs.

Can you please help me to solve the problem?
Regards,
Ariel

	[[alternative HTML version deleted]]


From yeroslaviz at biochem.mpg.de  Thu Feb  2 12:10:22 2017
From: yeroslaviz at biochem.mpg.de (Yeroslaviz, Assa)
Date: Thu, 2 Feb 2017 11:10:22 +0000
Subject: [R] installing Contfrac package gives a gcc error
Message-ID: <3D1E6208-B602-4D0E-91A2-F91EA5FC7C36@biochem.mpg.de>

Hi everyone,

I am trying to install the contra package on my Ubuntu server.

Ich bekomme aber die folgende Fehlermeldung:

But I keep getting this error:

Installing contfrac
'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet  \
  CMD INSTALL '/tmp/Rtmp0ZStmN/devtools84a45d407429/contfrac'  \
  --library='/home/yeroslaviz/R/x86_64-pc-linux-gnu-library/3.3'  \
  --install-tests

* installing *source* package ?contfrac? ...
** package ?contfrac? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c contfrac.c -o contfrac.o
gcc: error: unrecognized command line option ?-fstack-protector-strong?
gcc: error: unrecognized command line option ?-Wdate-time?
/usr/lib/R/etc/Makeconf:132: recipe for target 'contfrac.o' failed
make: *** [contfrac.o] Error 1
ERROR: compilation failed for package ?contfrac?
* removing ?/home/yeroslaviz/R/x86_64-pc-linux-gnu-library/3.3/contfrac?
Error: Command failed (1)


is this a known problem?

my server has the following gcc version installed- 5.4.0.

BUT when typing which gcc I get the following path - /home/yeroslaviz/anaconda_ete/bin/gcc
the version of this gcc is though -  4.8.5.

the gcc version of  /usr/bin/gcc -v  is

Using built-in specs.
COLLECT_GCC=/usr/bin/gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/5/lto-wrapper
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.4' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)

I will appreciate any help.

danke
Assa


> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.2 tcltk_3.3.2


??

Assa Yeroslaviz, PhD
Application service, Bioinformatics group
Max Planck Institute for Biochemistry
Am Klopferspitz 18, 82152 Martinsried
Germany
Tel:     +49 89 8578 2427
Email: yeroslaviz at biochem.mpg.de<mailto:yeroslaviz at biochem.mpg.de>


	[[alternative HTML version deleted]]


From yeroslaviz at biochem.mpg.de  Thu Feb  2 12:10:22 2017
From: yeroslaviz at biochem.mpg.de (Yeroslaviz, Assa)
Date: Thu, 2 Feb 2017 11:10:22 +0000
Subject: [R] installing Contfrac package gives a gcc error
Message-ID: <3D1E6208-B602-4D0E-91A2-F91EA5FC7C36@biochem.mpg.de>

Hi everyone,

I am trying to install the contra package on my Ubuntu server.

Ich bekomme aber die folgende Fehlermeldung:

But I keep getting this error:

Installing contfrac
'/usr/lib/R/bin/R' --no-site-file --no-environ --no-save --no-restore --quiet  \
  CMD INSTALL '/tmp/Rtmp0ZStmN/devtools84a45d407429/contfrac'  \
  --library='/home/yeroslaviz/R/x86_64-pc-linux-gnu-library/3.3'  \
  --install-tests

* installing *source* package ?contfrac? ...
** package ?contfrac? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -g  -c contfrac.c -o contfrac.o
gcc: error: unrecognized command line option ?-fstack-protector-strong?
gcc: error: unrecognized command line option ?-Wdate-time?
/usr/lib/R/etc/Makeconf:132: recipe for target 'contfrac.o' failed
make: *** [contfrac.o] Error 1
ERROR: compilation failed for package ?contfrac?
* removing ?/home/yeroslaviz/R/x86_64-pc-linux-gnu-library/3.3/contfrac?
Error: Command failed (1)


is this a known problem?

my server has the following gcc version installed- 5.4.0.

BUT when typing which gcc I get the following path - /home/yeroslaviz/anaconda_ete/bin/gcc
the version of this gcc is though -  4.8.5.

the gcc version of  /usr/bin/gcc -v  is

Using built-in specs.
COLLECT_GCC=/usr/bin/gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/5/lto-wrapper
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.4' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)

I will appreciate any help.

danke
Assa


> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.1 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.3.2 tcltk_3.3.2


??

Assa Yeroslaviz, PhD
Application service, Bioinformatics group
Max Planck Institute for Biochemistry
Am Klopferspitz 18, 82152 Martinsried
Germany
Tel:     +49 89 8578 2427
Email: yeroslaviz at biochem.mpg.de<mailto:yeroslaviz at biochem.mpg.de>


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Feb  2 17:01:12 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Feb 2017 08:01:12 -0800
Subject: [R] Function that works within a package and not when copied in
 global environment. Why?
In-Reply-To: <82f987ca-f11d-c6e1-db39-71a8415195e2@yahoo.fr>
References: <82f987ca-f11d-c6e1-db39-71a8415195e2@yahoo.fr>
Message-ID: <CAGxFJbQZyT98iOctc2JsXnrr61T9JPZDt2-b2jX16ZEyUOujQg@mail.gmail.com>

1. No they're not. e.g.

> f <- function() NULL
> g <- function()NULL

> identical(f,g)
[1] FALSE

> str(f)
function ()
 - attr(*, "srcref")=Class 'srcref'  atomic [1:8] 1 6 1 20 6 20 1 1
  .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
<environment: 0x1026578d0>

> str(g)
function ()
 - attr(*, "srcref")=Class 'srcref'  atomic [1:8] 1 6 1 19 6 19 1 1
  .. ..- attr(*, "srcfile")=Classes 'srcfilecopy', 'srcfile'
<environment: 0x102613028>

> h <- f
> identical(f,h)
[1] TRUE

identical() is very fussy about whether t=2 objects are the same; they
must be identical in all respects, including attributes, classes, etc.
attached to them. The namespace object has different attributes
attached to it than the one you created.

2. You need to review how namespaces work. From the "Writing R
extensions" manual:

"The namespace controls the search strategy for variables used by
**functions in the package**. If not found locally, R searches the
package namespace first, then the imports, then the base namespace and
then the normal search path."

So if vectorize.args() is among the package functions, it will be
found by package functions but not by those you write unless
specifically qualified by :: or ::: depending on whether it is
exported.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 2, 2017 at 6:30 AM, Marc Girondot via R-help
<r-help at r-project.org> wrote:
> Dear experts,
>
> In the package nlWaldTest, there is an hidden function : .smartsub
>
> I can use it, for example:
>
>> getFromNamespace(".smartsub", ns="nlWaldTest")(pat="x", repl="b" ,
> x="essai(b[1], b[2], x[1])")
> [1] "essai(b[1], b[2], b[1])"
>
> Now I try to create this function in my global environment:
> smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")
>
> It works also:
>> smartsub(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
> [1] "essai(b[1], b[2], b[1])"
>
> But if I create the function manually:
>> smartsub2 <- function (pat, repl, x)
>  {
>      args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
>      names <- if (is.null(names(args)))
>          character(length(args))
>      else names(args)
>      dovec <- names %in% vectorize.args
>      do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs =
> list(args[!dovec]),
>                          SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
>  }
>> smartsub2(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
> Error in names %in% vectorize.args : objet 'vectorize.args' introuvable
>
> It fails because vectorize.args is unknown
>
> Indeed smartsub2 is different from smartsub.
>> identical(smartsub, smartsub2)
> [1] FALSE
>
> 1/ Why are they different? They are just a copy of each other.
>
> 2/ Second question, vectorize.args is indeed not defined before to be used
> in the function. Why no error is produced in original function?
>
> Thanks a lot
>
> Marc
>
>
> --
>
> __________________________________________________________
> Marc Girondot, Pr
>
> Laboratoire Ecologie, Syst?matique et Evolution
> Equipe de Conservation des Populations et des Communaut?s
> CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
> B?timent 362
> 91405 Orsay Cedex, France
>
> Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
> e-mail: marc.girondot at u-psud.fr
> Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
> Skype: girondot
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Feb  2 17:21:07 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Feb 2017 08:21:07 -0800
Subject: [R] Help with implementing Whittaker-Henderson graduation for
	raw-data
In-Reply-To: <000001d27cfe$55494bd0$ffdbe370$@com>
References: <000001d27cfe$55494bd0$ffdbe370$@com>
Message-ID: <CAGxFJbQotUQs3wtge3oRdtWrq5BEoXLDHnxev5MfuYpi3Q1JiA@mail.gmail.com>

Percival:

Please make at least a minimal effort to search before posting.

 A google search on "Whittaker-Henderson smoothing R" brought up what
appeared to me to be several relevant links. If I am wrong about this,
you should probably explain why in a further query.

Of course, in general, we do not write your code for you. This is just
"r-help" not a free r programming service. You need to show us your
code and the errors you got when you attempted to run it.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 1, 2017 at 6:44 PM, Percival Bueser
<percival_bueser at cocolife.com> wrote:
> Good day everyone!
>
> I would appreciate if anyone can help me regarding the following: I would
> like to implement the Whittaker-Henderson smoothing to the raw data on the
> attached .txt file, based on the description on this link:
>
> https://artax.karlin.mff.cuni.cz/r-help/library/pracma/html/whittaker.html
>
> On the attached .txt file, The x's are the independent variables and the y's
> are the dependent variables. The signal to be smoothed is y, lambda = 1600
> and d = 2.
>
> Can anyone please send me a sample R script, or a link to an R script which
> I can adapt, where I can get both the (1) smoothed graph and the (2)
> smoothed values of y for each x given, and then import both the smoothed
> graph and the smoothed values of y to Microsoft Excel?
>
> Thank you very much.
>
> Regards,
>
> Percy
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mak.hholly at gmail.com  Thu Feb  2 17:32:24 2017
From: mak.hholly at gmail.com (greg holly)
Date: Thu, 2 Feb 2017 11:32:24 -0500
Subject: [R] looping problem
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A14500@SRVEXCHCM301.precheza.cz>
References: <CAM9Qe4hPJnx74SJZSEY7H9wCeNV=vRt6fqU6+R+ocA+HSQWFvw@mail.gmail.com>
	<589229D5.6010306@sapo.pt>
	<CAM9Qe4innBJoFbfgkSRTJddUWxq_y9saz0h8E+XOOV5=qtAzaQ@mail.gmail.com>
	<589344A4.90109@sapo.pt>
	<CAM9Qe4j-hZ+WxxR0NmLk6bGMMRrOBnVVrwNRvzFRS2e3kmasvA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A14500@SRVEXCHCM301.precheza.cz>
Message-ID: <CAM9Qe4jP+GfH5v1k2nASCjjsK6W7vWKwrgsOr3pPcAfgQebT6g@mail.gmail.com>

Thanks so much Peter. I do appreciate for this.

Greg

On Thu, Feb 2, 2017 at 10:28 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi.
>
> Your messages are rather confusing. Well, if you could get correct final
> data.frame in loop why not just add inside of loop new column(s) by
>
> psT$chr <- i
>
> Maybe it is time to read R intro as good source for starting with R. It
> has about 100 pages, but you can pick as start only pages 2-40 which are
> basic for data input and manipulation.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg
> holly
> > Sent: Thursday, February 2, 2017 4:13 PM
> > To: Rui Barradas <ruipbarradas at sapo.pt>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] looping problem
> >
> > Thanks so much for this. Unfortunately, cbind did not work. Basically, I
> like to
> > put an extra column named "chr" in the combined file from 22 chr.
> > So chr colum will be "1" for the portion of chr1 in the combined file, 2
> for the
> > portion of chr2 in the combined file and so on.
> >
> > Regards,
> >
> > Greg
> >
> > On Thu, Feb 2, 2017 at 9:39 AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >
> > > Hello,
> > >
> > > If I understand correctly, just use ?cbind.
> > >
> > > Rui Barradas
> > >
> > > Em 02-02-2017 13:33, greg holly escreveu:
> > >
> > >> Hi Rui;
> > >>
> > >> Is there any way to insert the chr ids in numeric as 1,2......,22 in
> > >> the final output. Here is output from str(temp). So I need also chr
> > >> ids in a column.
> > >> 1          rs58108140 10583 G A -0.070438 0.059903
> > >> 2         rs189107123 10611 C G -0.044916 0.085853
> > >>
> > >> Regards,
> > >> Greg
> > >>
> > >>
> > >> On Wed, Feb 1, 2017 at 1:32 PM, Rui Barradas <ruipbarradas at sapo.pt
> > >> <mailto:ruipbarradas at sapo.pt>> wrote:
> > >>
> > >>     Hello,
> > >>
> > >>     If what you want is to combine the files into one data.frame then
> > >>     there are 2 things you should see:
> > >>
> > >>     1) You create a variable named 'temp' and don't ever use it.
> > >>     2) You never combine the data.frames you read in.
> > >>
> > >>     Try instead the following.
> > >>
> > >>     temp <- data.frame()
> > >>     for(i in 1:22) {
> > >>          infile<-paste("chr",i,"/Z-score.imputed",sep="")
> > >>          psT<-read.table(infile,header=T,as.is <http://as.is
> >=T,sep="\t")
> > >>          temp <- rbind(temp, psT)
> > >>     }
> > >>
> > >>     str(temp)  # to see what you have
> > >>
> > >>     Hope this helps,
> > >>
> > >>     Rui Barradas
> > >>
> > >>
> > >>
> > >>
> > >>     Em 01-02-2017 17:25, greg holly escreveu:
> > >>
> > >>         Hi all;
> > >>
> > >>         I have 22 directories named chr1, chr2,....,chr22. Each
> > >>         directory has a
> > >>         file named "Z-score.imputed". I would like to combine
> > >>         Z-score.imputed
> > >>         files into one. I wrote the following loop but did not get any
> > >>         results.
> > >>         Your helps are highly appreciated.
> > >>
> > >>         regards,
> > >>
> > >>         Greg
> > >>
> > >>         temp<-c()
> > >>
> > >>         for(i in 1:22) {
> > >>         infile<-paste("chr",i,"/Z-score.imputed",sep="")
> > >>         psT<-read.table(as.character(infile),header=T,as.is
> > >>         <http://as.is>=T,sep="\t")
> > >>         ps<-psT[psT$Var>0.6,]
> > >>         ratio=nrow(ps)/nrow(psT)
> > >>         print(ratio)
> > >>         }
> > >>
> > >>                  [[alternative HTML version deleted]]
> > >>
> > >>         ______________________________________________
> > >>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
> list
> > >>         -- To UNSUBSCRIBE and more, see
> > >>         https://stat.ethz.ch/mailman/listinfo/r-help
> > >>         <https://stat.ethz.ch/mailman/listinfo/r-help>
> > >>         PLEASE do read the posting guide
> > >>         http://www.R-project.org/posting-guide.html
> > >>         <http://www.R-project.org/posting-guide.html>
> > >>         and provide commented, minimal, self-contained, reproducible
> code.
> > >>
> > >>
> > >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Thu Feb  2 17:34:08 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 2 Feb 2017 17:34:08 +0100
Subject: [R] Function that works within a package and not when copied in
 global environment. Why?
In-Reply-To: <CAGxFJbQZyT98iOctc2JsXnrr61T9JPZDt2-b2jX16ZEyUOujQg@mail.gmail.com>
References: <82f987ca-f11d-c6e1-db39-71a8415195e2@yahoo.fr>
	<CAGxFJbQZyT98iOctc2JsXnrr61T9JPZDt2-b2jX16ZEyUOujQg@mail.gmail.com>
Message-ID: <7ba5e948-e04d-e536-5586-6407bc7e447f@yahoo.fr>

Thanks Bert for the explanation about identical.

For the vectorize.args, note that vectorize.args is not a function but 
an variable that is unknown in the namespace nlWaldTest.

 > nlWaldTest::vectorize.args
Erreur : 'vectorize.args' n'est pas un objet export? depuis 
'namespace:nlWaldTest'


Furthermore, if the function is created from a copy of the original one:

smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")

or if it is created manually: by copy-paste of the code:

smartsub2 <- function (pat, repl, x)
  {
      args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
      names <- if (is.null(names(args)))
          character(length(args))
      else names(args)
      dovec <- names %in% vectorize.args
      do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs = 
list(args[!dovec]),
                          SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
  }

Both are defined in the global env, but the first one works and not the 
second one.

I am surprised and don't understand how it is possible.

Sincerely

Marc Girondot

> 2. You need to review how namespaces work. From the "Writing R
> extensions" manual:
>
> "The namespace controls the search strategy for variables used by
> **functions in the package**. If not found locally, R searches the
> package namespace first, then the imports, then the base namespace and
> then the normal search path."
>
> So if vectorize.args() is among the package functions, it will be
> found by package functions but not by those you write unless
> specifically qualified by :: or ::: depending on whether it is
> exported.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Feb 2, 2017 at 6:30 AM, Marc Girondot via R-help
> <r-help at r-project.org> wrote:
>> Dear experts,
>>
>> In the package nlWaldTest, there is an hidden function : .smartsub
>>
>> I can use it, for example:
>>
>>> getFromNamespace(".smartsub", ns="nlWaldTest")(pat="x", repl="b" ,
>> x="essai(b[1], b[2], x[1])")
>> [1] "essai(b[1], b[2], b[1])"
>>
>> Now I try to create this function in my global environment:
>> smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")
>>
>> It works also:
>>> smartsub(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
>> [1] "essai(b[1], b[2], b[1])"
>>
>> But if I create the function manually:
>>> smartsub2 <- function (pat, repl, x)
>>   {
>>       args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
>>       names <- if (is.null(names(args)))
>>           character(length(args))
>>       else names(args)
>>       dovec <- names %in% vectorize.args
>>       do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs =
>> list(args[!dovec]),
>>                           SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
>>   }
>>> smartsub2(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
>> Error in names %in% vectorize.args : objet 'vectorize.args' introuvable
>>
>> It fails because vectorize.args is unknown
>>
>> Indeed smartsub2 is different from smartsub.
>>> identical(smartsub, smartsub2)
>> [1] FALSE
>>
>> 1/ Why are they different? They are just a copy of each other.
>>
>> 2/ Second question, vectorize.args is indeed not defined before to be used
>> in the function. Why no error is produced in original function?
>>
>> Thanks a lot
>>
>> Marc
>>
>>
>> --
>>
>> __________________________________________________________
>> Marc Girondot, Pr
>>
>> Laboratoire Ecologie, Syst?matique et Evolution
>> Equipe de Conservation des Populations et des Communaut?s
>> CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
>> B?timent 362
>> 91405 Orsay Cedex, France
>>
>> Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
>> e-mail: marc.girondot at u-psud.fr
>> Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
>> Skype: girondot
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Feb  2 17:48:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Feb 2017 08:48:52 -0800
Subject: [R] Function that works within a package and not when copied in
 global environment. Why?
In-Reply-To: <7ba5e948-e04d-e536-5586-6407bc7e447f@yahoo.fr>
References: <82f987ca-f11d-c6e1-db39-71a8415195e2@yahoo.fr>
	<CAGxFJbQZyT98iOctc2JsXnrr61T9JPZDt2-b2jX16ZEyUOujQg@mail.gmail.com>
	<7ba5e948-e04d-e536-5586-6407bc7e447f@yahoo.fr>
Message-ID: <CAGxFJbR1vRtncZTz=dfXjWnMt_HdQBsW8Bhc6dzajF2312bs3g@mail.gmail.com>

OK.

Try:  nlWaldTest:::vectorize.args  (3 colons)

Your error message said it was *not* exported, so you need 3 colons
(which, in general, is a bad idea.It's usually not exported for a
reason).

I presume vectorize.args is is in the environment of the function
copied from the name space, because functions are actually closures
that include (pointers to) their environments; whereas it is certainly
not part of the (global) environment, the environment of the manually
created function by copy-paste of the code.

If I am wrong about this, I would appreciate a correction by someone
with better understanding of such subtleties than I.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 2, 2017 at 8:34 AM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> Thanks Bert for the explanation about identical.
>
> For the vectorize.args, note that vectorize.args is not a function but an
> variable that is unknown in the namespace nlWaldTest.
>
>> nlWaldTest::vectorize.args
> Erreur : 'vectorize.args' n'est pas un objet export? depuis
> 'namespace:nlWaldTest'
>
>
> Furthermore, if the function is created from a copy of the original one:
>
> smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")
>
> or if it is created manually: by copy-paste of the code:
>
> smartsub2 <- function (pat, repl, x)
>  {
>      args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
>      names <- if (is.null(names(args)))
>          character(length(args))
>      else names(args)
>      dovec <- names %in% vectorize.args
>      do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs =
> list(args[!dovec]),
>                          SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
>  }
>
> Both are defined in the global env, but the first one works and not the
> second one.
>
> I am surprised and don't understand how it is possible.
>
> Sincerely
>
> Marc Girondot
>
>> 2. You need to review how namespaces work. From the "Writing R
>> extensions" manual:
>>
>> "The namespace controls the search strategy for variables used by
>> **functions in the package**. If not found locally, R searches the
>> package namespace first, then the imports, then the base namespace and
>> then the normal search path."
>>
>> So if vectorize.args() is among the package functions, it will be
>> found by package functions but not by those you write unless
>> specifically qualified by :: or ::: depending on whether it is
>> exported.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Feb 2, 2017 at 6:30 AM, Marc Girondot via R-help
>> <r-help at r-project.org> wrote:
>>>
>>> Dear experts,
>>>
>>> In the package nlWaldTest, there is an hidden function : .smartsub
>>>
>>> I can use it, for example:
>>>
>>>> getFromNamespace(".smartsub", ns="nlWaldTest")(pat="x", repl="b" ,
>>>
>>> x="essai(b[1], b[2], x[1])")
>>> [1] "essai(b[1], b[2], b[1])"
>>>
>>> Now I try to create this function in my global environment:
>>> smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")
>>>
>>> It works also:
>>>>
>>>> smartsub(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
>>>
>>> [1] "essai(b[1], b[2], b[1])"
>>>
>>> But if I create the function manually:
>>>>
>>>> smartsub2 <- function (pat, repl, x)
>>>
>>>   {
>>>       args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
>>>       names <- if (is.null(names(args)))
>>>           character(length(args))
>>>       else names(args)
>>>       dovec <- names %in% vectorize.args
>>>       do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs =
>>> list(args[!dovec]),
>>>                           SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
>>>   }
>>>>
>>>> smartsub2(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
>>>
>>> Error in names %in% vectorize.args : objet 'vectorize.args' introuvable
>>>
>>> It fails because vectorize.args is unknown
>>>
>>> Indeed smartsub2 is different from smartsub.
>>>>
>>>> identical(smartsub, smartsub2)
>>>
>>> [1] FALSE
>>>
>>> 1/ Why are they different? They are just a copy of each other.
>>>
>>> 2/ Second question, vectorize.args is indeed not defined before to be
>>> used
>>> in the function. Why no error is produced in original function?
>>>
>>> Thanks a lot
>>>
>>> Marc
>>>
>>>
>>> --
>>>
>>> __________________________________________________________
>>> Marc Girondot, Pr
>>>
>>> Laboratoire Ecologie, Syst?matique et Evolution
>>> Equipe de Conservation des Populations et des Communaut?s
>>> CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
>>> B?timent 362
>>> 91405 Orsay Cedex, France
>>>
>>> Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
>>> e-mail: marc.girondot at u-psud.fr
>>> Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
>>> Skype: girondot
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From wdunlap at tibco.com  Thu Feb  2 18:32:21 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 2 Feb 2017 09:32:21 -0800
Subject: [R] Function that works within a package and not when copied in
 global environment. Why?
In-Reply-To: <7ba5e948-e04d-e536-5586-6407bc7e447f@yahoo.fr>
References: <82f987ca-f11d-c6e1-db39-71a8415195e2@yahoo.fr>
	<CAGxFJbQZyT98iOctc2JsXnrr61T9JPZDt2-b2jX16ZEyUOujQg@mail.gmail.com>
	<7ba5e948-e04d-e536-5586-6407bc7e447f@yahoo.fr>
Message-ID: <CAF8bMcZ0+14efdr1ergjm4r8jGHg-sYpGKOuQjfCMy-55CycQw@mail.gmail.com>

When searching for the object referred to by a name, R looks first in
the current environment, then in the environment's parent environment,
then in that environment's parent environment, etc.  It stops looking
either when the name is found or when it hits .EmptyEnv, the ultimate
ancestor of all environments.

When a function,f,  is being evaluated, the current environment is a
child of environment(f), which is typically the environment in which
the function was created.  When a function is in a package, the
function's environment is generally the package's namespace. When a
function is made on the command line, its namespace is .GlobalEnv.
.GlobalEnv is not a descendant of any package namespace so when the
function is evaluated it will not look in any package namespace when
looking up names.

You can change the environment of a function with
   environment(f) <- someEnvironment
as in
    environment(revisedLmFunc) <- environment(lm)
or
    environment(revisedLmFunc) <- getNamespace(lm)
I do this when debugging functions in environments, but I don't
recommend it for general use (e.g., for code other people will be
using).

Here is some code that displays the ancestral environments of an
environment to help you look at various situations.

myFormatEnvironment <- function(envir) {
    if (is.null(n <- attr(envir, "name"))) {
        n <- format(envir)
    }
    n
}
ancestralEnvironments <- function (envir) {
    if (identical(envir, emptyenv())) {
        list(envir)
    }
    else {
        c(list(envir), ancestralEnvironments(parent.env(envir)))
    }
}

Here are some examples showing the ancestral environments of a (a)
function in a pacakge, (b) a function in .GlobalEnv, and (c) a
function created by a function in a package.

> vapply(ancestralEnvironments(environment(stats::lm)), myFormatEnvironment, "")
 [1] "<environment: namespace:stats>" "imports:stats"
 [3] "<environment: namespace:base>"  "<environment: R_GlobalEnv>"
 [5] "package:stats"                  "package:graphics"
 [7] "package:grDevices"              "package:utils"
 [9] "package:datasets"               "package:methods"
[11] "Autoloads"                      "<environment: base>"
[13] "<environment: R_EmptyEnv>"
> myFunc <- function(x) x
> vapply(ancestralEnvironments(environment(myFunc)), myFormatEnvironment, "")
 [1] "<environment: R_GlobalEnv>" "package:stats"
 [3] "package:graphics"           "package:grDevices"
 [5] "package:utils"              "package:datasets"
 [7] "package:methods"            "Autoloads"
 [9] "<environment: base>"        "<environment: R_EmptyEnv>"
> vapply(ancestralEnvironments(environment(approxfun(1:3,log(1:3)))), myFormatEnvironment, "")
 [1] "<environment: 0x0000000015d33f28>"
 [2] "<environment: namespace:stats>"
 [3] "imports:stats"
 [4] "<environment: namespace:base>"
 [5] "<environment: R_GlobalEnv>"
 [6] "package:stats"
 [7] "package:graphics"
 [8] "package:grDevices"
 [9] "package:utils"
[10] "package:datasets"
[11] "package:methods"
[12] "Autoloads"
[13] "<environment: base>"
[14] "<environment: R_EmptyEnv>"
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Feb 2, 2017 at 8:34 AM, Marc Girondot via R-help
<r-help at r-project.org> wrote:
> Thanks Bert for the explanation about identical.
>
> For the vectorize.args, note that vectorize.args is not a function but an
> variable that is unknown in the namespace nlWaldTest.
>
>> nlWaldTest::vectorize.args
> Erreur : 'vectorize.args' n'est pas un objet export? depuis
> 'namespace:nlWaldTest'
>
>
> Furthermore, if the function is created from a copy of the original one:
>
> smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")
>
> or if it is created manually: by copy-paste of the code:
>
> smartsub2 <- function (pat, repl, x)
>  {
>      args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
>      names <- if (is.null(names(args)))
>          character(length(args))
>      else names(args)
>      dovec <- names %in% vectorize.args
>      do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs =
> list(args[!dovec]),
>                          SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
>  }
>
> Both are defined in the global env, but the first one works and not the
> second one.
>
> I am surprised and don't understand how it is possible.
>
> Sincerely
>
> Marc Girondot
>
>> 2. You need to review how namespaces work. From the "Writing R
>> extensions" manual:
>>
>> "The namespace controls the search strategy for variables used by
>> **functions in the package**. If not found locally, R searches the
>> package namespace first, then the imports, then the base namespace and
>> then the normal search path."
>>
>> So if vectorize.args() is among the package functions, it will be
>> found by package functions but not by those you write unless
>> specifically qualified by :: or ::: depending on whether it is
>> exported.
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Feb 2, 2017 at 6:30 AM, Marc Girondot via R-help
>> <r-help at r-project.org> wrote:
>>>
>>> Dear experts,
>>>
>>> In the package nlWaldTest, there is an hidden function : .smartsub
>>>
>>> I can use it, for example:
>>>
>>>> getFromNamespace(".smartsub", ns="nlWaldTest")(pat="x", repl="b" ,
>>>
>>> x="essai(b[1], b[2], x[1])")
>>> [1] "essai(b[1], b[2], b[1])"
>>>
>>> Now I try to create this function in my global environment:
>>> smartsub <- getFromNamespace(".smartsub", ns="nlWaldTest")
>>>
>>> It works also:
>>>>
>>>> smartsub(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
>>>
>>> [1] "essai(b[1], b[2], b[1])"
>>>
>>> But if I create the function manually:
>>>>
>>>> smartsub2 <- function (pat, repl, x)
>>>
>>>   {
>>>       args <- lapply(as.list(match.call())[-1L], eval, parent.frame())
>>>       names <- if (is.null(names(args)))
>>>           character(length(args))
>>>       else names(args)
>>>       dovec <- names %in% vectorize.args
>>>       do.call("mapply", c(FUN = FUN, args[dovec], MoreArgs =
>>> list(args[!dovec]),
>>>                           SIMPLIFY = SIMPLIFY, USE.NAMES = USE.NAMES))
>>>   }
>>>>
>>>> smartsub2(pat="x", repl="b" , x="essai(b[1], b[2], x[1])")
>>>
>>> Error in names %in% vectorize.args : objet 'vectorize.args' introuvable
>>>
>>> It fails because vectorize.args is unknown
>>>
>>> Indeed smartsub2 is different from smartsub.
>>>>
>>>> identical(smartsub, smartsub2)
>>>
>>> [1] FALSE
>>>
>>> 1/ Why are they different? They are just a copy of each other.
>>>
>>> 2/ Second question, vectorize.args is indeed not defined before to be
>>> used
>>> in the function. Why no error is produced in original function?
>>>
>>> Thanks a lot
>>>
>>> Marc
>>>
>>>
>>> --
>>>
>>> __________________________________________________________
>>> Marc Girondot, Pr
>>>
>>> Laboratoire Ecologie, Syst?matique et Evolution
>>> Equipe de Conservation des Populations et des Communaut?s
>>> CNRS, AgroParisTech et Universit? Paris-Sud 11 , UMR 8079
>>> B?timent 362
>>> 91405 Orsay Cedex, France
>>>
>>> Tel:  33 1 (0)1.69.15.72.30   Fax: 33 1 (0)1.69.15.73.53
>>> e-mail: marc.girondot at u-psud.fr
>>> Web: http://www.ese.u-psud.fr/epc/conservation/Marc.html
>>> Skype: girondot
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Thu Feb  2 19:08:16 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 2 Feb 2017 19:08:16 +0100
Subject: [R] Help with implementing Whittaker-Henderson graduation for
	raw-data
In-Reply-To: <000001d27cfe$55494bd0$ffdbe370$@com>
References: <000001d27cfe$55494bd0$ffdbe370$@com>
Message-ID: <396A20EA-E8AA-406F-B7D5-E6E81D6A227C@xs4all.nl>


Why don't you just try the function whittaker from the pracma R package?
There is an example which should be adequate for finding out what to do.

Berend Hasselman

> On 2 Feb 2017, at 03:44, Percival Bueser <percival_bueser at cocolife.com> wrote:
> 
> Good day everyone!
> 
> I would appreciate if anyone can help me regarding the following: I would
> like to implement the Whittaker-Henderson smoothing to the raw data on the
> attached .txt file, based on the description on this link:
> 
> https://artax.karlin.mff.cuni.cz/r-help/library/pracma/html/whittaker.html
> 
> On the attached .txt file, The x's are the independent variables and the y's
> are the dependent variables. The signal to be smoothed is y, lambda = 1600
> and d = 2.
> 
> Can anyone please send me a sample R script, or a link to an R script which
> I can adapt, where I can get both the (1) smoothed graph and the (2)
> smoothed values of y for each x given, and then import both the smoothed
> graph and the smoothed values of y to Microsoft Excel?
> 
> Thank you very much.
> 
> Regards,
> 
> Percy
> 
> 
> <Sample_data.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Thu Feb  2 19:16:46 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 2 Feb 2017 10:16:46 -0800
Subject: [R] How to do double (nested) parSapply in R?
In-Reply-To: <CAKY_brHrWXDTRZ9zCdA3BdKG3_JsoGW3fqGBZq350X_8XFLSLw@mail.gmail.com>
References: <CAKY_brHrWXDTRZ9zCdA3BdKG3_JsoGW3fqGBZq350X_8XFLSLw@mail.gmail.com>
Message-ID: <CAFDcVCRt-FMh6DLc7xCgZ4GcBPE4LDPA4eP3q4vzGjewZbaj2w@mail.gmail.com>

Quick comment: sapply() / parSapply() can behaves "unexpectedly". To
troubleshoot this, use parLapply() instead to see if you at least get the
individual results you think you should get.

Henrik

On Feb 2, 2017 08:03, "Art U" <art.tem.us at gmail.com> wrote:

> Hello,
>
> I have a data orig.raw that contains 8 predictors and 1 outcome variable.
> I'm trying to run simulation (bootstrap) and create, let's say, 10
> confidence intervals for coefficients estimated by LASSO. I did it with
> regular function replicate, but now I want to do it by using parallel
> programming. Here is my code:
>
> cl <- makeCluster(detectCores())
> clusterEvalQ(cl,library(glmnet))
> clusterEvalQ(cl,library(MASS))
> clusterExport(cl,c("orig.raw"))
>
> pp=parSapply(cl,1:10,function(i,data=orig.raw,...){
>   library(parallel)
>   cl <- makeCluster(detectCores())
>   clusterEvalQ(cl,library(glmnet))
>   clusterEvalQ(cl,library(MASS))
>   clusterExport(cl,c("orig.raw"))
>
>   repl=parSapply(cl=cl,1:10,function(i,data=orig.raw,...){
>     s1=data[sample(nrow(data),size=500,replace=TRUE),]
>     cross=cv.glmnet(s1[,1:8],s1[,9])
>     penalty <- cross$lambda.min
>     fit=glmnet(s1[,1:8],s1[,9],alpha=1,lambda=penalty)
>     coe=coef(fit)
>     m=as(coe, "matrix")
>     return(m)
>   })
>
> stopCluster(cl)
>
>   mr=t(matrix(repl,nrow = 9,ncol=10))
>   means=colMeans(mr)
>   std=apply(mr, 2, sd)
>   lb=means-1.96*std;
>   ub=means+1.96*std;
>   ind=t(as.numeric({beta>lb & beta<ub}))
>   return(ind)})
> stopCluster(cl)
>
> And here is the error I'm getting
>
> Error in checkForRemoteErrors(val) : 8 nodes produced errors; first
> error: comparison (6) is possible only for atomic and list types
>
> If I run only function repl - it works and I get the matrix that contains
> coefficients from 10 runs.
>
> Can you please help me to solve the problem?
> Regards,
> Ariel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ramiro at precisionbioassay.com  Thu Feb  2 20:58:52 2017
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Thu, 2 Feb 2017 19:58:52 +0000
Subject: [R] Using a mock of an S4 class
In-Reply-To: <763D8CCC-9705-492C-BE3C-987775407512@comcast.net>
References: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>
	<763D8CCC-9705-492C-BE3C-987775407512@comcast.net>
Message-ID: <C7338A7EFF31BB4D831BB06C00887789B9C0166A@MBX023-W1-CA-2.exch023.domain.local>

Yes, so are you suggesting that I create an instance of my S4 class in order to test my function.

My understanding is that ideally the test should not depend on any code besides the one that I am testing.

I just thought that you could perhaps define a mock class so that I would not need to invoke my external constructor function, hence making this test focus exclusively on the function that I am trying to test.  Is it possible to do this in R?

On 2/1/17, 6:57 PM, "David Winsemius" <dwinsemius at comcast.net> wrote:

>
>> On Feb 1, 2017, at 11:46 AM, Ramiro Barrantes
>><ramiro at precisionbioassay.com> wrote:
>> 
>> Hello,
>> 
>> I have a function that applies to an S4 object which contains a slot
>>called @analysis:
>> 
>> function calculation(myObject) {
>>  tmp <- myObjects at analysis
>>  result <- ...operations on analysis...
>>  return result
>> }
>> 
>> I am writing a unit test for this function.  So I was hoping to create
>>a mock object but I can't figure out how to do it:
>> 
>> test_that("test calculation function", {
>>  mockMyObject<- mock(?????)  #I am not sure what to put here
>>  r<-calculation(mockMyObject)
>>  expect_true(r,0.83625)
>> })
>> 
>> How can I create a mock S4 object??
>
>I'm not seeing a class definition for any "S4"-classed object. I would
>expect you to have used `setClass`. I believe that once the class is
>defined that you should have access to the `new` constructor function.
>
>> 
>> Thanks in advance,
>> Ramiro
>> 
>> 	[[alternative HTML version deleted]]
>
>R-help is a plain-text mailing list.
>
>--
>
>David Winsemius
>Alameda, CA, USA
>



From Ramgad82 at gmx.net  Thu Feb  2 22:04:28 2017
From: Ramgad82 at gmx.net (Dagmar)
Date: Thu, 2 Feb 2017 22:04:28 +0100
Subject: [R] beginner question: subset first entry (row) per week
Message-ID: <c813159b-b100-48ca-5fba-2862cc94c7db@gmx.net>

Dear knowing people,

I have a data frame like this.

exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie", 
"CookieMonster","CookieMonster","CookieMonster"),
recordedTime=as.POSIXct(strptime(as.character("01.01.2017","02.01.2011","03.01.2011",
"01.01.2011","02.01.2011","03.01.2011"),"%d.%m.%Y")),
                          week =c(1,2,2,
                                 1,2,2),
                          eatencookies=c(1,0.5,0.001,
                                        50,51,200))
exdatframe

#Now I want a new dataframe with only the first row per week (i.e. I 
want to know how many cookies were eaten at the first recorded day of 
each week). Something like that:

exdatframe2 <- data.frame(Name=c("Ernie","Ernie", 
"CookieMonster","CookieMonster"),
                          recordedTime=c("01.01.2017","02.01.2011",
"01.01.2011","02.01.2011"),
                          week =c(1,2,
                                  1,2),
                          eatencookies=c(1,0.5,
                                         50,51))
exdatframe2

# How do I do that? I thought it must be something with tapply or subset 
- but I just don't get it....

# would be great if someone helps.

# Dagmar


From bgunter.4567 at gmail.com  Thu Feb  2 22:15:20 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 2 Feb 2017 13:15:20 -0800
Subject: [R] beginner question: subset first entry (row) per week
In-Reply-To: <c813159b-b100-48ca-5fba-2862cc94c7db@gmx.net>
References: <c813159b-b100-48ca-5fba-2862cc94c7db@gmx.net>
Message-ID: <CAGxFJbR8ASxVg1HSvrgmA6boKr5uUQteqecY3j2GhAB7iOmVVw@mail.gmail.com>

new.df <- orig.df[!duplicated(df[["week"]]), ]

See ?duplicated

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 2, 2017 at 1:04 PM, Dagmar <Ramgad82 at gmx.net> wrote:
> Dear knowing people,
>
> I have a data frame like this.
>
> exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie",
> "CookieMonster","CookieMonster","CookieMonster"),
> recordedTime=as.POSIXct(strptime(as.character("01.01.2017","02.01.2011","03.01.2011",
> "01.01.2011","02.01.2011","03.01.2011"),"%d.%m.%Y")),
>                          week =c(1,2,2,
>                                 1,2,2),
>                          eatencookies=c(1,0.5,0.001,
>                                        50,51,200))
> exdatframe
>
> #Now I want a new dataframe with only the first row per week (i.e. I want to
> know how many cookies were eaten at the first recorded day of each week).
> Something like that:
>
> exdatframe2 <- data.frame(Name=c("Ernie","Ernie",
> "CookieMonster","CookieMonster"),
>                          recordedTime=c("01.01.2017","02.01.2011",
> "01.01.2011","02.01.2011"),
>                          week =c(1,2,
>                                  1,2),
>                          eatencookies=c(1,0.5,
>                                         50,51))
> exdatframe2
>
> # How do I do that? I thought it must be something with tapply or subset -
> but I just don't get it....
>
> # would be great if someone helps.
>
> # Dagmar
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ronald.Taylor at pnnl.gov  Thu Feb  2 22:26:19 2017
From: Ronald.Taylor at pnnl.gov (Taylor, Ronald C)
Date: Thu, 2 Feb 2017 21:26:19 +0000
Subject: [R] need help in trying out sparklyr - spark_connect will not
 work on local copy of Spark
In-Reply-To: <2215E62B-A775-45B0-B039-2A13448DF0D9@comcast.net>
References: <9630E5FD91504140A3479FBFBE1837B51BD313DE@EX10MBOX03.pnnl.gov>
	<2215E62B-A775-45B0-B039-2A13448DF0D9@comcast.net>
Message-ID: <9630E5FD91504140A3479FBFBE1837B51BD31A65@EX10MBOX03.pnnl.gov>


> So this makes me wonder if you do not have a proper installation of java for one of those other packages. 

David,

You were right. I was using Java 1.6 instead of Java 1.7 or later.  Mea culpa. I am now up and running, and looking to do many things  with R and Spark. Thank you.

Ron

Ronald C. Taylor, Ph.D.
Computational Biology & Bioinformatics Group
Pacific Northwest National Laboratory (U.S. Dept of Energy/Battelle)
Richland, WA 99352
phone: (509) 372-6568,  email: ronald.taylor at pnnl.gov
web page: ?http://www.pnnl.gov/science/staff/staff_info.asp?staff_num=7048

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Wednesday, February 01, 2017 4:40 PM
To: Taylor, Ronald C
Cc: r-help at r-project.org; ronald.taylor24 (ronald.taylor24 at gmail.com)
Subject: Re: [R] need help in trying out sparklyr - spark_connect will not work on local copy of Spark


> On Feb 1, 2017, at 3:23 PM, Taylor, Ronald C <Ronald.Taylor at pnnl.gov> wrote:
> 
> Hello R-help list,
> 
> I am a new list member. My first question: I was trying out sparklyr (in R ver 3.3.2) on my Red Hat Linux workstation, following the instructions at spark.rstudio.com as to how to download and use a local copy of Spark. The Spark download appears to work. However, when I try to issue the spark_connect, to get started, I get the error msgs that  you see below.
> 
> I cannot find any guidance as to how to fix this. Quite frustrating. Can somebody give me a bit of help? Does something need to be added to my PATH env var in my .mycshrc file, for example? Is there a closed port problem? Has anybody run into this type of error msg? Do I need to do something additional to start up the local copy of Spark that is not mentioned in the RStudio online documentation?
> 
> -          Ron
> 
> %%%%%%%%%%%%%%%%%%%%
> 
> Here is the spark_install (apparently successful) and then the error msg on the spark_connect():
> 
>> spark_install(version = "1.6.2")
> 
> Installing Spark 1.6.2 for Hadoop 2.6 or later.
> 
> Downloading from:
> 
> - 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Installing to:
> 
> - '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'
> 
> trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Content type 'application/x-tar' length 278057117 bytes (265.2 MB)
> 
> ==================================================
> 
> downloaded 265.2 MB
> 
> Installation complete.
> 
>> 
> 
>> sc <- spark_connect(master = "local")
> 
> Error in force(code) :
> 
>  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.
> 
>    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit
> 
>    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689
> 
> ---- Output Log ----
> 
> /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory


So this makes me wonder if you do not have a proper installation of java for one of those other packages. This seems off-topic for r-help, although possibly on-topic for the R-SIG-DBI list :

 https://stat.ethz.ch/mailman/listinfo/r-sig-db


There's also a "Report a bug" link:

	? Report a bug at 
https://?github.com/?rstudio/?sparklyr/?issues


-- 
David.
> 
> ---- Error Log ----
> 
>> 
> 
> %%%%%%%%%%%%%%%%%%
> 
> And here is the entire screen output of my R session, from the R invocation on:
> 
> sidney115% R
> 
> R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
> 
> Copyright (C) 2016 The R Foundation for Statistical Computing
> 
> Platform: x86_64-redhat-linux-gnu (64-bit)
> 
>> 
> 
>> library(sparklyr)
> 
>> 
> 
>> ls(pos = "package:sparklyr")
> 
>  [1] "%>%"
> 
>  [2] "compile_package_jars"
> 
>  [3] "connection_config"
> 
>  [4] "connection_is_open"
> 
>  [5] "copy_to"
> 
>  [6] "ensure_scalar_boolean"
> 
>  [7] "ensure_scalar_character"
> 
>  [8] "ensure_scalar_double"
> 
>  [9] "ensure_scalar_integer"
> 
> [10] "find_scalac"
> 
> [11] "ft_binarizer"
> 
> [12] "ft_bucketizer"
> 
> [13] "ft_discrete_cosine_transform"
> 
> [14] "ft_elementwise_product"
> 
> [15] "ft_index_to_string"
> 
> [16] "ft_one_hot_encoder"
> 
> [17] "ft_quantile_discretizer"
> 
> [18] "ft_regex_tokenizer"
> 
> [19] "ft_sql_transformer"
> 
> [20] "ft_string_indexer"
> 
> [21] "ft_tokenizer"
> 
> [22] "ft_vector_assembler"
> 
> [23] "hive_context"
> 
> [24] "invoke"
> 
> [25] "invoke_method"
> 
> [26] "invoke_new"
> 
> [27] "invoke_static"
> 
> [28] "java_context"
> 
> [29] "livy_available_versions"
> 
> [30] "livy_config"
> 
> [31] "livy_home_dir"
> 
> [32] "livy_install"
> 
> [33] "livy_install_dir"
> 
> [34] "livy_installed_versions"
> 
> [35] "livy_service_start"
> 
> [36] "livy_service_stop"
> 
> [37] "ml_als_factorization"
> 
> [38] "ml_binary_classification_eval"
> 
> [39] "ml_classification_eval"
> 
> [40] "ml_create_dummy_variables"
> 
> [41] "ml_decision_tree"
> 
> [42] "ml_generalized_linear_regression"
> 
> [43] "ml_gradient_boosted_trees"
> 
> [44] "ml_kmeans"
> 
> [45] "ml_lda"
> 
> [46] "ml_linear_regression"
> 
> [47] "ml_load"
> 
> [48] "ml_logistic_regression"
> 
> [49] "ml_model"
> 
> [50] "ml_multilayer_perceptron"
> 
> [51] "ml_naive_bayes"
> 
> [52] "ml_one_vs_rest"
> 
> [53] "ml_options"
> 
> [54] "ml_pca"
> 
> [55] "ml_prepare_dataframe"
> 
> [56] "ml_prepare_features"
> 
> [57] "ml_prepare_response_features_intercept"
> 
> [58] "ml_random_forest"
> 
> [59] "ml_save"
> 
> [60] "ml_survival_regression"
> 
> [61] "ml_tree_feature_importance"
> 
> [62] "na.replace"
> 
> [63] "print_jobj"
> 
> [64] "register_extension"
> 
> [65] "registered_extensions"
> 
> [66] "sdf_copy_to"
> 
> [67] "sdf_import"
> 
> [68] "sdf_load_parquet"
> 
> [69] "sdf_load_table"
> 
> [70] "sdf_mutate"
> 
> [71] "sdf_mutate_"
> 
> [72] "sdf_partition"
> 
> [73] "sdf_persist"
> 
> [74] "sdf_predict"
> 
> [75] "sdf_quantile"
> 
> [76] "sdf_read_column"
> 
> [77] "sdf_register"
> 
> [78] "sdf_sample"
> 
> [79] "sdf_save_parquet"
> 
> [80] "sdf_save_table"
> 
> [81] "sdf_schema"
> 
> [82] "sdf_sort"
> 
> [83] "sdf_with_unique_id"
> 
> [84] "spark_available_versions"
> 
> [85] "spark_compilation_spec"
> 
> [86] "spark_compile"
> 
> [87] "spark_config"
> 
> [88] "spark_connect"
> 
> [89] "spark_connection"
> 
> [90] "spark_connection_is_open"
> 
> [91] "spark_context"
> 
> [92] "spark_dataframe"
> 
> [93] "spark_default_compilation_spec"
> 
> [94] "spark_dependency"
> 
> [95] "spark_disconnect"
> 
> [96] "spark_disconnect_all"
> 
> [97] "spark_home_dir"
> 
> [98] "spark_install"
> 
> [99] "spark_install_dir"
> 
> [100] "spark_install_tar"
> 
> [101] "spark_installed_versions"
> 
> [102] "spark_jobj"
> 
> [103] "spark_load_table"
> 
> [104] "spark_log"
> 
> [105] "spark_read_csv"
> 
> [106] "spark_read_json"
> 
> [107] "spark_read_parquet"
> 
> [108] "spark_save_table"
> 
> [109] "spark_session"
> 
> [110] "spark_uninstall"
> 
> [111] "spark_version"
> 
> [112] "spark_version_from_home"
> 
> [113] "spark_web"
> 
> [114] "spark_write_csv"
> 
> [115] "spark_write_json"
> 
> [116] "spark_write_parquet"
> 
> [117] "tbl_cache"
> 
> [118] "tbl_uncache"
> 
>> 
> 
>> 
> 
>> 
> 
>> spark_install(version = "1.6.2")
> 
> Installing Spark 1.6.2 for Hadoop 2.6 or later.
> 
> Downloading from:
> 
> - 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Installing to:
> 
> - '~/.cache/spark/spark-1.6.2-bin-hadoop2.6'
> 
> trying URL 'https://d3kbcqa49mib13.cloudfront.net/spark-1.6.2-bin-hadoop2.6.tgz'
> 
> Content type 'application/x-tar' length 278057117 bytes (265.2 MB)
> 
> ==================================================
> 
> downloaded 265.2 MB
> 
> Installation complete.
> 
>> 
> 
>> sc <- spark_connect(master = "local")
> 
> Error in force(code) :
> 
>  Failed while connecting to sparklyr to port (8880) for sessionid (3689): Gateway in port (8880) did not respond.
> 
>    Path: /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-submit
> 
>    Parameters: --class, sparklyr.Backend, --jars, '/usr/lib64/R/library/sparklyr/java/spark-csv_2.11-1.3.0.jar','/usr/lib64/R/library/sparklyr/java/commons-csv-1.1.jar','/usr/lib64/R/library/sparklyr/java/univocity-parsers-1.5.1.jar', '/usr/lib64/R/library/sparklyr/java/sparklyr-1.6-2.10.jar', 8880, 3689
> 
> 
> ---- Output Log ----
> 
> /home/rtaylor/.cache/spark/spark-1.6.2-bin-hadoop2.6/bin/spark-class: line 86: /usr/local/bin/bin/java: No such file or directory



> ---- Error Log ----
> 
>> 
> 
> %%%%%%%%%%%%%%%%%%
> 
> Ronald C. Taylor, Ph.D.
> Computational Biology & Bioinformatics Group
> Pacific Northwest National Laboratory (U.S. Dept of Energy/Battelle)
> Richland, WA 99352
> phone: (509) 372-6568,  email: ronald.taylor at pnnl.gov
> web page:  http://www.pnnl.gov/science/staff/staff_info.asp?staff_num=7048
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Feb  2 23:04:30 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Feb 2017 09:04:30 +1100
Subject: [R] sub-setting rows based on dates in R
In-Reply-To: <KL1PR01MB0999CC6F954A99BD65121503B64C0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
References: <KL1PR01MB0999FC07E36B092AFAD82C44B64A0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
	<CA+8X3fWWO1yMpEqDUx7Xt4Tck1NpymvzaUwACYTGhMn0EqsVOQ@mail.gmail.com>
	<KL1PR01MB0999572A7CC95503DBE8F0FBB64D0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
	<CA+8X3fUhKxHysrc37jVSGjrfFjzTNTFmj5XBfO81KeCs6XCy0A@mail.gmail.com>
	<KL1PR01MB0999CC6F954A99BD65121503B64C0@KL1PR01MB0999.apcprd01.prod.exchangelabs.com>
Message-ID: <CA+8X3fWMH2e4dNgPfsjZCi6ZxrNoBruKxJ79G=WpP4xqd6fLnQ@mail.gmail.com>

It looks to me as though the problem is in your input data. The following
example works for me:

df1<-data.frame(Date=paste(rep(6:8,each=20),
 c(sort(sample(1:30,20)),sort(sample(1:30,20)),sort(sample(1:30,20))),
 2016,sep="/"),
 Rainfall_Duration=sample(c(10,20,30,40),60,TRUE))
df1$Date<-as.Date(df1$Date,"%m/%d/%Y")
df2<-data.frame(Date=paste(rep(6:8,each=10),
 c(sort(sample(10:30,10)),sort(sample(10:30,10)),sort(sample(10:30,10))),
 2016,sep="/"),
 Removal.Rate=runif(30,10,60))
df2$Date<-as.Date(df2$Date,"%m/%d/%Y")

df3<-data.frame(Rate.Removal.Date=NULL,Date=NULL,Rainfall_Duration=NULL)

df3row<-0

for(i in 1:dim(df2)[1]) {
 rdrows<-which(df2$Date[i] >= df1$Date & !(df2$Date[i] > df1$Date + 8))
 # if there are no dates in df1 within the prior 7 days
 if(!length(rdrows)) {
  # first check if at least one date in df1 is less than the df2
  # date and is not included in the last set of df1 dates
  checkrows<-which(df2$Date[i] >= df1$Date)
  # use the last date greater than the maximum in lastrows
  if(any(checkrows > lastrows))
   rdrows<-max(checkrows[checkrows > lastrows])
  # otherwise use the last set
  else rdrows<-lastrows
 }
 # save the current set of dates
 lastrows<-rdrows
 # get the number of new rows
 nrows<-length(rdrows)
 for(row in 1:nrows) {
  # set the values in each row
  df3[row+df3row,1]<-format(df2$Date[i],"%m/%d/%Y")
  df3[row+df3row,2]<-format(df1$Date[rdrows[row]],"%m/%d/%Y")
  df3[row+df3row,3]<-df1$Rainfall_Duration[rdrows[row]]
 }
 df3row<-df3row+nrows
}

names(df3)<-c("Rate.Removal.Date","Date","Rainfall_Duration")
df3

Jim

On Fri, Feb 3, 2017 at 4:05 AM, Md Sami Bin Shokrana <samimist at live.com>
wrote:

>
> Hi Jim,
>
> Thanks a lot. As you already mentioned, this is a clunky method. This code
> runs fine with the sample data I provided here. But my real data is much
> larger (more than 50 observations for df1) and this code does not work. I
> am getting this error:
> Error in `*tmp*`[[j]] : subscript out of bounds
> Do you have any solution for that? You have already done a lot. So, I
> really appreciate your effort. Thanks
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* Thursday, February 2, 2017 2:07 PM
>
> *To:* Md Sami Bin Shokrana; r-help mailing list
> *Subject:* Re: [R] sub-setting rows based on dates in R
>
> Hi Md,
> What I have done is to use the most recent intervening date between the
> last set of dates if any are there, otherwise the last set of dates. That
> is what I understand from your description.
>
> Remember that this is a very clunky way to do something like this by
> adding rows to a data frame, and it is likely to scale up to large data
> sets badly.
>
> df1<-read.table(text="Date    Rainfall_Duration
>  6/14/2016       10
>  6/15/2016       20
>  6/17/2016       10
>  8/16/2016       30
>  8/19/2016       40
>  8/21/2016       20
>  9/4/2016        10",
>  header=TRUE,stringsAsFactors=FALSE)
> # change the character strings in df2$Date to Date values
> df1$Date<-as.Date(df1$Date,"%m/%d/%Y")
>
> df2<-read.table(text="Date    Removal.Rate
>  6/17/2016    64.7
>  6/30/2016    22.63
>  7/14/2016    18.18
>  8/19/2016    27.87
>  8/30/2016    23.45
>  9/2/2016     17.2",
>  header=TRUE,stringsAsFactors=FALSE)
> # change the character strings in df2$Date to Date values
> df2$Date<-as.Date(df2$Date,"%m/%d/%Y")
>
> df3<-data.frame(Rate.Removal.Date=NULL,Date=NULL,Rainfall_Duration=NULL)
>
> df3row<-0
>
> for(i in 1:dim(df2)[1]) {
>  rdrows<-which(df2$Date[i] >= df1$Date & !(df2$Date[i] > df1$Date + 8))
>  # if there are no dates in df1 within the prior 7 days
>  if(!length(rdrows)) {
>   # first check if at least one date in df1 is less than the df2
>   # date and is not included in the last set of df1 dates
>   checkrows<-which(df2$Date[i] >= df1$Date)
>   # use the last date greater than the maximum in lastrows
>   if(any(checkrows > lastrows))
>    rdrows<-max(checkrows[checkrows > lastrows])
>   # otherwise use the last set
>   else rdrows<-lastrows
>  }
>  # save the current set of dates
>  lastrows<-rdrows
>  # get the number of new rows
>  nrows<-length(rdrows)
>  for(row in 1:nrows) {
>   # set the values in each row
>   df3[row+df3row,1]<-format(df2$Date[i],"%m/%d/%Y")
>   df3[row+df3row,2]<-format(df1$Date[rdrows[row]],"%m/%d/%Y")
>   df3[row+df3row,3]<-df1$Rainfall_Duration[rdrows[row]]
>  }
>  # keep count of the current number of rows
>  df3row<-df3row+nrows
> }
>
> names(df3)<-c("Rate.Removal.Date","Date","Rainfall_Duration")
> df3
>
> Jim
>
>
> On Thu, Feb 2, 2017 at 4:58 AM, Md Sami Bin Shokrana <samimist at live.com>
> wrote:
>
>> Hi Jim,
>>
>> Thank you so much for your help. Your code works great. Could you please
>> explain your code a bit? One more thing, I am so sorry that I forgot to
>> mention one more criteria in my post. If it is not much trouble, could you
>> please help me out with that? I have added a couple more observations
>> (the bold ones) to each of my data frames which are shown below:
>>
>>
>> The main concept is,
>>
>> (i) For a specific date in df2, if no matching dates are available in df1
>> within the 7 days range, the code will keep on looking for the latest
>> available date in df1 with a "Rainfall_Duration" data. For example, in df2,
>> for *8/30/2016*, there is no "Rainfall_Duration" data available in
>> df1 within the prior 7 days range. So, I want the code to keep on looking
>> for dates in df1 until there is an available data for "Rainfall_Duration"
>> in df1 (in this case which is * 8/21/2016)* .
>>
>>
>> (ii) Additionally, for* 9/2/2016 *(df2), there is no date available in
>> df1 with a "Rainfall_Duration" data within prior 7 days range. The latest
>> available data for "Rainfall_Duration" is *8/21/2016*. So, the code will
>> extract the same result we had for *8/30/2016* in df2.
>>
>>  In simpler words, i just want the code to keep on looking for data with
>> "Rainfall_Duraiton" in df1 if there is none available within the prior 7
>> days range. Sorry for not mentioning it before.
>>
>>
>>
>> df1 <-
>>
>> Date Rainfall_Duration
>> 6/14/2016 10
>> 6/15/2016 20
>> 6/17/2016 10
>> 8/16/2016 30
>> 8/19/2016 40
>> *8/21/2016* *20* *9/4/2016                 10*
>>
>>
>> df2 <-
>>
>> Date Removal.Rate
>> 6/17/2016 64.7
>> 6/30/2016 22.63
>> 7/14/2016 18.18
>> 8/19/2016 27.87
>> *8/30/2016* *23.45* *9/2/2016         17.2*
>>
>>
>> Expected output:
>>
>>
>> df3 <-
>>
>> Rate.Removal.Date     Date Rainfall_Duration
>> 6/17/2016 6/14/2016 10
>> 6/17/2016 6/15/2016 20
>> 6/17/2016 6/17/2016 10
>> 6/30/2016 6/14/2016 10
>> 6/30/2016 6/15/2016 20
>> 6/30/2016 6/17/2016 10
>> 7/14/2016 6/14/2016 10
>> 7/14/2016 6/15/2016 20
>> 7/14/2016 6/17/2016 10
>> 8/19/2016 8/16/2016 30
>> 8/19/2016 8/19/2016 40
>> *8/30/2016* *8/21/2016* *20* *9/2/2016                 8/21/2016
>> 20*
>>
>>
>> Thanks in advance.
>>
>>
>> ------------------------------
>> *From:* Jim Lemon <drjimlemon at gmail.com>
>> *Sent:* Wednesday, February 1, 2017 1:18 PM
>> *To:* Md Sami Bin Shokrana; r-help mailing list
>> *Subject:* Re: [R] sub-setting rows based on dates in R
>>
>> Hi Md,
>> This kind of clunky, but it might do what you want.
>>
>> df1<-read.table(text="Date    Rainfall_Duration
>>  6/14/2016       10
>>  6/15/2016       20
>>  6/17/2016       10
>>  8/16/2016       30
>>  8/19/2016       40",
>>  header=TRUE,stringsAsFactors=FALSE)
>>
>> df1$Date<-as.Date(df1$Date,"%m/%d/%Y")
>>
>> df2<-read.table(text="Date    Removal.Rate
>>  6/17/2016    64.7
>>  6/30/2016    22.63
>>  7/14/2016    18.18
>>  8/19/2016    27.87",
>>  header=TRUE,stringsAsFactors=FALSE)
>>
>> df2$Date<-as.Date(df2$Date,"%m/%d/%Y")
>>
>> df3<-data.frame(Rate.Removal.Date=NULL,Date=NULL,Rainfall_Duration=NULL)
>>
>> df3row<-0
>>
>> for(i in 1:dim(df2)[1]) {
>>  rdrows<-which(df2$Date[i] >= df1$Date & !(df2$Date[i] > df1$Date + 8))
>>  if(!length(rdrows)) rdrows<-lastrows
>>  lastrows<-rdrows
>>  nrows<-length(rdrows)
>>  for(row in 1:nrows) {
>>   df3[row+df3row,1]<-format(df2$Date[i],"%m/%d/%Y")
>>   df3[row+df3row,2]<-format(df1$Date[rdrows[row]],"%m/%d/%Y")
>>   df3[row+df3row,3]<-df1$Rainfall_Duration[rdrows[row]]
>>  }
>>  df3row<-df3row+nrows
>> }
>>
>> names(df3)<-c("Rate.Removal.Date","Date","Rainfall_Duration")
>> df3
>>
>> Jim
>>
>> On Wed, Feb 1, 2017 at 3:48 AM, Md Sami Bin Shokrana <samimist at live.com>
>> wrote:
>> > Hello guys, I am trying to solve a problem in R. I have 2 data frames
>> which look like this:
>> > df1 <-
>> >   Date    Rainfall_Duration
>> > 6/14/2016       10
>> > 6/15/2016       20
>> > 6/17/2016       10
>> > 8/16/2016       30
>> > 8/19/2016       40
>> >
>> > df2 <-
>> >   Date    Removal.Rate
>> > 6/17/2016    64.7
>> > 6/30/2016    22.63
>> > 7/14/2016    18.18
>> > 8/19/2016    27.87
>> >
>> > I want to look up the dates from df2 in df1 and their corresponding
>> Rainfall_Duration data. For example, I want to look for the 1st date of df2
>> in df1 and subset rows in df1 for that specific date and 7 days prior to
>> that. additionally, for example: for 6/30/2016 (in df2) there is no dates
>> available in df1 within it's 7 days range. So, in this case I just want to
>> extract the results same as it's previous date (6/17/2016) in df2. Same
>> logic goes for 7/14/2016(df2).
>> > The output should look like this:
>> >
>> > df3<-
>> >
>> > Rate.Removal.Date      Date             Rainfall_Duration
>> > 6/17/2016              6/14/2016              10
>> > 6/17/2016              6/15/2016              20
>> > 6/17/2016              6/17/2016              10
>> > 6/30/2016              6/14/2016              10
>> > 6/30/2016              6/15/2016              20
>> > 6/30/2016              6/17/2016              10
>> > 7/14/2016              6/14/2016              10
>> > 7/14/2016              6/15/2016              20
>> > 7/14/2016              6/17/2016              10
>> > 8/19/2016              8/16/2016              30
>> > 8/19/2016              8/19/2016              40
>> >
>> > I could subset data for the 7 days range. But could not do it when no
>> dates are available in that range. I have the following code:
>> > library(plyr)
>> > library (dplyr)
>> > df1$Date <- as.Date(df1$Date,format = "%m/%d/%Y")
>> > df2$Date <- as.Date(df2$Date,format = "%m/%d/%Y")
>> >
>> > df3 <- lapply(df2$Date, function(x){
>> >   filter(df1, between(Date, x-7, x))
>> > })
>> >
>> > names(df3) <- as.character(df2$Date)
>> > bind_rows(df3, .id = "Rate.Removal.Date")
>> > df3 <- ldply (df3, data.frame, .id = "Rate.Removal.Date")
>> >
>> > I hope I could explain my problem properly. I would highly appreciate
>> if someone can help me out with this code or a new one. Thanks in advance.
>> >
>> >
>> >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> R-help Info Page - Homepage - SfS ? Seminar for Statistics
>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>> stat.ethz.ch
>> The main R mailing list, for announcements about the development of R and
>> the availability of new code, questions and answers about problems and
>> solutions using R ...
>>
>>
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb  2 23:14:48 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 02 Feb 2017 14:14:48 -0800
Subject: [R] Using a mock of an S4 class
In-Reply-To: <C7338A7EFF31BB4D831BB06C00887789B9C0166A@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>
	<763D8CCC-9705-492C-BE3C-987775407512@comcast.net>
	<C7338A7EFF31BB4D831BB06C00887789B9C0166A@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <E31B7466-23B9-43C2-B01E-4723AD40AC7E@dcn.davis.ca.us>

You seem like you have painted yourself into a corner... you want to access slots in an S4 object yet you don't want to create one. Are you going to do this test without the benefit of an operating system either? 

Beware of getting too meta... David didn't say you had to use an S4 object defined elsewhere... you invented that. But you do have to use the setClass function to create an S4 class with which you can create an object. No class, no object, mock or otherwise.

Me, I like S3.
-- 
Sent from my phone. Please excuse my brevity.

On February 2, 2017 11:58:52 AM PST, Ramiro Barrantes <ramiro at precisionbioassay.com> wrote:
>Yes, so are you suggesting that I create an instance of my S4 class in
>order to test my function.
>
>My understanding is that ideally the test should not depend on any code
>besides the one that I am testing.
>
>I just thought that you could perhaps define a mock class so that I
>would not need to invoke my external constructor function, hence making
>this test focus exclusively on the function that I am trying to test. 
>Is it possible to do this in R?
>
>On 2/1/17, 6:57 PM, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>>
>>> On Feb 1, 2017, at 11:46 AM, Ramiro Barrantes
>>><ramiro at precisionbioassay.com> wrote:
>>> 
>>> Hello,
>>> 
>>> I have a function that applies to an S4 object which contains a slot
>>>called @analysis:
>>> 
>>> function calculation(myObject) {
>>>  tmp <- myObjects at analysis
>>>  result <- ...operations on analysis...
>>>  return result
>>> }
>>> 
>>> I am writing a unit test for this function.  So I was hoping to
>create
>>>a mock object but I can't figure out how to do it:
>>> 
>>> test_that("test calculation function", {
>>>  mockMyObject<- mock(?????)  #I am not sure what to put here
>>>  r<-calculation(mockMyObject)
>>>  expect_true(r,0.83625)
>>> })
>>> 
>>> How can I create a mock S4 object??
>>
>>I'm not seeing a class definition for any "S4"-classed object. I would
>>expect you to have used `setClass`. I believe that once the class is
>>defined that you should have access to the `new` constructor function.
>>
>>> 
>>> Thanks in advance,
>>> Ramiro
>>> 
>>> 	[[alternative HTML version deleted]]
>>
>>R-help is a plain-text mailing list.
>>
>>--
>>
>>David Winsemius
>>Alameda, CA, USA
>>
>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Feb  2 23:19:37 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Thu, 2 Feb 2017 22:19:37 +0000
Subject: [R] metafor rma.mv weights questions
In-Reply-To: <31A98C8B8E62D84982441B63A46937D76CEDCF95@FHSDB2D11-1.csu.mcmaster.ca>
References: <31A98C8B8E62D84982441B63A46937D76CEDCF95@FHSDB2D11-1.csu.mcmaster.ca>
Message-ID: <e4832c7892d042a7bdf5371313596a29@UM-MAIL3216.unimaas.nl>

Hi Laura,

As far as I am concerned, you account for multiple effects sizes from the same study by setting up and fitting an appropriate model, not by fiddling with the weights. Several examples are described here:

http://www.metafor-project.org/doku.php/analyses#multivariate_multilevel_meta-analysis_models

The model implies the structure of the variance-covariance matrix of the estimates. The inverse of this var-cov matrix then implies the weights (and for multilevel/multivariate data, this is no longer a diagonal matrix, so there are not just weights, but an entire weight matrix). See also help(rma.mv) in metafor.

So, if you fit an appropriate model to the data at hand, the 'default weights' used by rma.mv() will be just fine.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan,
>Laura
>Sent: Monday, January 30, 2017 18:18
>To: r-help at r-project.org
>Subject: [R] metafor rma.mv weights questions
>
>Hi there,
>
>Question:
>Does the rma.mv command in metafor automically adjust the weights to
>account for multiple effect sizes within study or do these weights need to
>manually calculated and applied?
>
>Details:
>In setting up a multilevel meta-analysis and meta-regression with multiple
>effect sizes within studies, I have seen the suggestion to adjust the
>weights according to Hedges, Tipton, & Johnson (suggestion made at
>24.33mins in this tutorial https://www.youtube.com/watch?v=rJjeRRf23L8)
>using:
> Wij=1/Kj*mean V.j
>I am wondering if the data is structured hierarchically and the random
>effects for each level specified correctly, does the rma.mv command
>automatically adjust the weights in this way? Another way to ask this
>question is - what are the default weights used by rma.mv when there are
>multiple estimates within studies?
>
>Thanks
>Laura
>
>Laura Duncan, M.A.
>Research Coordinator
>Offord Centre for Child Studies
>McMaster University
>
>Tel: 905 525 9140 x21504
>Fax: 905 574 6665
>duncanlj at mcmaster.ca
>ontariochildhealthstudy.ca
>offordcentre.com
>
>Mailing Address ????????????????????????????????????????????? Courier
>Address
>1280 Main St. W. MIP 201A?????????????????????????? 175 Longwood Rd. S.
>MIP 201A
>Hamilton, Ontario L8S 4K1 ??????????????????????????? Hamilton, Ontario
>L8P 0A1


From martin.morgan at roswellpark.org  Fri Feb  3 00:24:11 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Thu, 2 Feb 2017 18:24:11 -0500
Subject: [R] Using a mock of an S4 class
In-Reply-To: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <9120e3e2-8f8c-2a14-acb3-d6ecf27573b8@roswellpark.org>

On 02/01/2017 02:46 PM, Ramiro Barrantes wrote:
> Hello,
>
> I have a function that applies to an S4 object which contains a slot called @analysis:
>
> function calculation(myObject) {
>   tmp <- myObjects at analysis
>   result <- ...operations on analysis...
>   return result
> }
>
> I am writing a unit test for this function.  So I was hoping to create a mock object but I can't figure out how to do it:
>
> test_that("test calculation function", {
>   mockMyObject<- mock(?????)  #I am not sure what to put here
>   r<-calculation(mockMyObject)
>   expect_true(r,0.83625)
> })
>
> How can I create a mock S4 object??

I don't know of a convenient way to create a mock with functionality 
like mocks in other languages. But here's a class

   .A = setClass("A", contains="integer")

This creates an instance that might be used as a mock

    mock = .A()  # same as new("A")

but maybe you have an initialize method (initialize methods are very 
tricky to get correct, and many people avoid them, using 
plain-old-functions to form an API around object creation; the 
plain-old-function finishes by calling the constructor .A() or new("A")) 
that has side effects that are inappropriate for your test, mimicked 
here with stop()

   setMethod("initialize", "A", function(.Object, ...) stop("oops"))

our initial attempts are thwarted

 > .A()
Error in initialize(value, ...) : oops

but we could reach into our bag of hacks and try

   mock = .Call(methods:::C_new_object, getClassDef("A"))

You would still need to populate slots / data used in your test, e.g.,

   slot(mock, ".Data") = 1:4

This is robust to any validity method, since the validity method is not 
invoked on direct slot assignment

   setValidity("A", function(object) {
       if (all(object > 0)) TRUE else "oops2"
   })

   slot(mock, ".Data") = 0:4  # still works

So something like

   mockS4object = function(class, ..., where=topenv(parent.frame())) {
       obj <- .Call(
           methods:::C_new_object,
           getClassDef(class, where=where)
       )

       args = list(...)
       for (nm in names(args))
           slot(obj, nm) = args[[nm]]

       obj
   }
   mockS4object("A", .Data=1:4)

Mock objects typically have useful testing properties, like returning 
the number of times a slot (field) is accessed. Unfortunately, I don't 
have anything to offer for that.

Martin


>
> Thanks in advance,
> Ramiro
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From acefix at rocketmail.com  Thu Feb  2 20:43:44 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Thu, 2 Feb 2017 19:43:44 +0000 (UTC)
Subject: [R] princomp() output loadings component missing
In-Reply-To: <DA148A68-253E-4975-9337-8EF3AD42C531@bigelow.org>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
	<DA148A68-253E-4975-9337-8EF3AD42C531@bigelow.org>
Message-ID: <1846956587.486412.1486064624390@mail.yahoo.com>

Thank you very much!
Ace 

    On Sunday, January 29, 2017 4:13 PM, Ben Tupper <btupper at bigelow.org> wrote:
 

 Hi,

Check out the detailed explanation in the 'Value' section of ?princomp - in particular for 'loadings'.? It will send you to ?loadings where it explains why that one element appears to be missing.

If you really want to see the missing value try...

p3$loadings['Rape', 'Comp.4']

... or even ...

unclass(p3$loadings)

Don't forget that this email list works best when messages are send in plain text, and it works poorly for html or rich text.? Check the settings in your email client.? In case others are interested here is what the loadings print to...

Loadings:
? ? ? ? Comp.1 Comp.2 Comp.3 Comp.4
Murder? -0.536? 0.418 -0.341? 0.649
Assault? -0.583? 0.188 -0.268 -0.743
UrbanPop -0.278 -0.873 -0.378? 0.134
Rape? ? -0.543 -0.167? 0.818? ? ? 

? ? ? ? ? ? ? Comp.1 Comp.2 Comp.3 Comp.4
SS loadings? ? ? 1.00? 1.00? 1.00? 1.00
Proportion Var? 0.25? 0.25? 0.25? 0.25
Cumulative Var? 0.25? 0.50? 0.75? 1.00 

Cheers,
Ben

> On Jan 29, 2017, at 4:31 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> 
> Hello, there,
> I did a test run for this princomp() function using USArrests data. The R document says that the output loadings contain the eigenvector matrix. When I looked at this matrix, I found that a missing item for Comp.4 
> 
>> p3=princomp(USArrests, cor=TRUE )> p3$loadings
> Loadings:? ? ? ? Comp.1 Comp.2 Comp.3 Comp.4Murder? -0.536? 0.418 -0.341? 0.649Assault? -0.583? 0.188 -0.268 -0.743UrbanPop -0.278 -0.873 -0.378? 0.134Rape? ? -0.543 -0.167? 0.818? ? ? 
>? ? ? ? ? ? ? ? Comp.1 Comp.2 Comp.3 Comp.4SS loadings? ? ? 1.00? 1.00? 1.00? 1.00Proportion Var? 0.25? 0.25? 0.25? 0.25Cumulative Var? 0.25? 0.50? 0.75? 1.00
> How should I explain this?
> Thanks.
> Ace
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org




   
	[[alternative HTML version deleted]]


From liai at mail.nih.gov  Thu Feb  2 20:54:43 2017
From: liai at mail.nih.gov (Li, Aiguo (NIH/NCI) [E])
Date: Thu, 2 Feb 2017 19:54:43 +0000
Subject: [R] need help to generate an intersection matrix
Message-ID: <7C8E2481-E941-4481-924F-E4936C2CD81D@contoso.com>

Dear all,

I am new to r script and run into some difficulty with this simple task.
Here is my data: I need to find out the number of mutual intersected elements as shown below
data
pathway1             A             B             C              D             E
pathway2             A             C              F
pathway3             B             D             E

output
                                pathway1             pathway2             pathway3
pathway1             5                                              2                                              3
pathway2             2                                              3                                              0
pathway3             3                                              0                                              3

here is my script
tb = matrix(data =NA, nrow = 3, ncol = 3)
for(i in 1:3){
  for(j in 1:3){

  tb[i,j]=length(intersect(data[i,][!is.na(data[i,])], data[j,][!is.na(data[j,])]))
  }
}

Ana

	[[alternative HTML version deleted]]


From lgherar1 at asu.edu  Thu Feb  2 21:53:08 2017
From: lgherar1 at asu.edu (Laureano Gherardi)
Date: Thu, 2 Feb 2017 13:53:08 -0700
Subject: [R]  nlsList (nlme) error
Message-ID: <a1cc5ec43ccaaf28f389a7432ee94def@mail.gmail.com>

Hello Rick,

This may be way to late but I had the same error and solved it just
removing the ?na.action=? argument. Since I had removed the NAs beforehand
it did not affect my results.

Best,

Lau

Laureano A. Gherardi PhD

Sala Lab <http://sala.lab.asu.edu/people/> LSA 217A

School of Life Sciences <https://sols.asu.edu/>

Arizona State University

PO Box 874501

Tempe, AZ, 85287-4501

1+(480) 727-3726

My Research Gate
<https://www.researchgate.net/profile/Laureano_Gherardi/?ev=hdr_xprf>

My Google Scholar
<https://scholar.google.com/citations?user=GH72YJ8AAAAJ&hl=en>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Feb  3 01:08:37 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 3 Feb 2017 11:08:37 +1100
Subject: [R] need help to generate an intersection matrix
In-Reply-To: <7C8E2481-E941-4481-924F-E4936C2CD81D@contoso.com>
References: <7C8E2481-E941-4481-924F-E4936C2CD81D@contoso.com>
Message-ID: <CA+8X3fU4EhiMB9SQ=PU4k3S-cN8SyMN2tA5-DMsAiN24f=eJsQ@mail.gmail.com>

Hi Ana,
Here is one way:

pathway1<-LETTERS[1:5]
pathway2<-c("A","C","F")
pathway3<-c("B","D","E")
intersect.mat<-matrix(0,nrow=3,ncol=3)
rownames(intersect.mat)<-paste("pathway",1:3,sep="")
colnames(intersect.mat)<-paste("pathway",1:3,sep="")
for(row in 1:3) {
 for(col in 1:3)
  intersect.mat[row,col]<-
   sum(get(rownames(intersect.mat)[row])%in%
   get(colnames(intersect.mat)[col]))
}

Jim


On Fri, Feb 3, 2017 at 6:54 AM, Li, Aiguo (NIH/NCI) [E]
<liai at mail.nih.gov> wrote:
> Dear all,
>
> I am new to r script and run into some difficulty with this simple task.
> Here is my data: I need to find out the number of mutual intersected elements as shown below
> data
> pathway1             A             B             C              D             E
> pathway2             A             C              F
> pathway3             B             D             E
>
> output
>                                 pathway1             pathway2             pathway3
> pathway1             5                                              2                                              3
> pathway2             2                                              3                                              0
> pathway3             3                                              0                                              3
>
> here is my script
> tb = matrix(data =NA, nrow = 3, ncol = 3)
> for(i in 1:3){
>   for(j in 1:3){
>
>   tb[i,j]=length(intersect(data[i,][!is.na(data[i,])], data[j,][!is.na(data[j,])]))
>   }
> }
>
> Ana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ramgad82 at gmx.net  Fri Feb  3 09:05:58 2017
From: Ramgad82 at gmx.net (Dagmar)
Date: Fri, 3 Feb 2017 09:05:58 +0100
Subject: [R] beginner question: subset first entry (row) per week -
 found the answer myself :-)
In-Reply-To: <c813159b-b100-48ca-5fba-2862cc94c7db@gmx.net>
References: <c813159b-b100-48ca-5fba-2862cc94c7db@gmx.net>
Message-ID: <269cf324-110d-d2cf-8535-264df9614932@gmx.net>

Dear all,

Now, all the sudden I found the answer myself :-)

I did it by:

ddply(exdatframe,.(week),function(x) head(x,1))

I'll simply do it for Ernie and Cookiemonster seperate - that is not a 
big problem.

Thanks anyway for your engagement in this group!

Dagmar


Am 02.02.2017 um 22:04 schrieb Dagmar:
> Dear knowing people,
>
> I have a data frame like this.
>
> exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie", 
> "CookieMonster","CookieMonster","CookieMonster"),
> recordedTime=as.POSIXct(strptime(as.character("01.01.2017","02.01.2011","03.01.2011", 
>
> "01.01.2011","02.01.2011","03.01.2011"),"%d.%m.%Y")),
>                          week =c(1,2,2,
>                                 1,2,2),
>                          eatencookies=c(1,0.5,0.001,
>                                        50,51,200))
> exdatframe
>
> #Now I want a new dataframe with only the first row per week (i.e. I 
> want to know how many cookies were eaten at the first recorded day of 
> each week). Something like that:
>
> exdatframe2 <- data.frame(Name=c("Ernie","Ernie", 
> "CookieMonster","CookieMonster"),
>                          recordedTime=c("01.01.2017","02.01.2011",
> "01.01.2011","02.01.2011"),
>                          week =c(1,2,
>                                  1,2),
>                          eatencookies=c(1,0.5,
>                                         50,51))
> exdatframe2
>
> # How do I do that? I thought it must be something with tapply or 
> subset - but I just don't get it....
>
> # would be great if someone helps.
>
> # Dagmar
>
>


From percival_bueser at cocolife.com  Fri Feb  3 01:28:14 2017
From: percival_bueser at cocolife.com (Percival Bueser)
Date: Fri, 3 Feb 2017 08:28:14 +0800
Subject: [R] Help with implementing Whittaker-Henderson graduation for
	raw-data
In-Reply-To: <CAGxFJbQotUQs3wtge3oRdtWrq5BEoXLDHnxev5MfuYpi3Q1JiA@mail.gmail.com>
References: <000001d27cfe$55494bd0$ffdbe370$@com>
	<CAGxFJbQotUQs3wtge3oRdtWrq5BEoXLDHnxev5MfuYpi3Q1JiA@mail.gmail.com>
Message-ID: <000001d27db4$6865e820$3931b860$@com>

Good day!

I eventually was able to make the code anyway. Here it is:

getwd()
setwd("C:/R")
datafile <- read.table("test_file.txt", header = TRUE)
library(SparseM)
var2 = datafile$y
d = 2
lambda = 1600
    require(SparseM, warn.conflicts = FALSE)
    m <- length(var2)
    E <- as(m, "matrix.diag.csr")
    class(E) <- "matrix.csr"
    Dmat <- diff(E, differences = d)
    B <- E + (lambda * t(Dmat) %*% Dmat)
    z <- solve(B, var2)
    z
write.table(z, "C:/R/test.txt", sep="\t")  

(then transfer the results to Excel and that's it)

Regards,

Percy



-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Friday, February 3, 2017 12:21 AM
To: Percival Bueser
Cc: R-help
Subject: Re: [R] Help with implementing Whittaker-Henderson graduation for raw-data

Percival:

Please make at least a minimal effort to search before posting.

 A google search on "Whittaker-Henderson smoothing R" brought up what
appeared to me to be several relevant links. If I am wrong about this,
you should probably explain why in a further query.

Of course, in general, we do not write your code for you. This is just
"r-help" not a free r programming service. You need to show us your
code and the errors you got when you attempted to run it.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 1, 2017 at 6:44 PM, Percival Bueser
<percival_bueser at cocolife.com> wrote:
> Good day everyone!
>
> I would appreciate if anyone can help me regarding the following: I would
> like to implement the Whittaker-Henderson smoothing to the raw data on the
> attached .txt file, based on the description on this link:
>
> https://artax.karlin.mff.cuni.cz/r-help/library/pracma/html/whittaker.html
>
> On the attached .txt file, The x's are the independent variables and the y's
> are the dependent variables. The signal to be smoothed is y, lambda = 1600
> and d = 2.
>
> Can anyone please send me a sample R script, or a link to an R script which
> I can adapt, where I can get both the (1) smoothed graph and the (2)
> smoothed values of y for each x given, and then import both the smoothed
> graph and the smoothed values of y to Microsoft Excel?
>
> Thank you very much.
>
> Regards,
>
> Percy
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From percival_bueser at cocolife.com  Fri Feb  3 01:42:19 2017
From: percival_bueser at cocolife.com (Percival Bueser)
Date: Fri, 3 Feb 2017 08:42:19 +0800
Subject: [R] Help with implementing Whittaker-Henderson graduation for
	raw-data
In-Reply-To: <396A20EA-E8AA-406F-B7D5-E6E81D6A227C@xs4all.nl>
References: <000001d27cfe$55494bd0$ffdbe370$@com>
	<396A20EA-E8AA-406F-B7D5-E6E81D6A227C@xs4all.nl>
Message-ID: <000101d27db6$5fca50a0$1f5ef1e0$@com>

Good day!

I eventually was able to make the code anyway. Here it is:

getwd()
setwd("C:/R")
datafile <- read.table("test_file.txt", header = TRUE)
library(SparseM)
var2 = datafile$y
d = 2
lambda = 1600
    require(SparseM, warn.conflicts = FALSE)
    m <- length(var2)
    E <- as(m, "matrix.diag.csr")
    class(E) <- "matrix.csr"
    Dmat <- diff(E, differences = d)
    B <- E + (lambda * t(Dmat) %*% Dmat)
    z <- solve(B, var2)
    z
write.table(z, "C:/R/test.txt", sep="\t")  

(then transfer the results to Excel and that's it)

Now, my problem is: 

I'd like to use the following command:
    z2 <- whittaker(var2, lambda, d)
    z2
which will reveal the results using the whittaker function itself. 

However, when I use this command
    library(pracma)
I get the following error:

> library(pracma)
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck =
vI[[j]]) : 
  there is no package called 'quadprog'
Error: package or namespace load failed for 'pracma'

So this must mean that I should have quadprog, but when I tried
    library(quadprog)
before library(pracma), I get the following error:

> library(quadprog)
Error in library(quadprog) : there is no package called 'quadprog'

I'd like to get around these so I can use the whittaker function itself. How
can I do this? Thank you very much.

Regards,

Percy

-----Original Message-----
From: Berend Hasselman [mailto:bhh at xs4all.nl] 
Sent: Friday, February 3, 2017 2:08 AM
To: Percival Bueser
Cc: r-help at r-project.org
Subject: Re: [R] Help with implementing Whittaker-Henderson graduation for
raw-data


Why don't you just try the function whittaker from the pracma R package?
There is an example which should be adequate for finding out what to do.

Berend Hasselman

> On 2 Feb 2017, at 03:44, Percival Bueser <percival_bueser at cocolife.com>
wrote:
> 
> Good day everyone!
> 
> I would appreciate if anyone can help me regarding the following: I would
> like to implement the Whittaker-Henderson smoothing to the raw data on the
> attached .txt file, based on the description on this link:
> 
> https://artax.karlin.mff.cuni.cz/r-help/library/pracma/html/whittaker.html
> 
> On the attached .txt file, The x's are the independent variables and the
y's
> are the dependent variables. The signal to be smoothed is y, lambda = 1600
> and d = 2.
> 
> Can anyone please send me a sample R script, or a link to an R script
which
> I can adapt, where I can get both the (1) smoothed graph and the (2)
> smoothed values of y for each x given, and then import both the smoothed
> graph and the smoothed values of y to Microsoft Excel?
> 
> Thank you very much.
> 
> Regards,
> 
> Percy
> 
> 
> <Sample_data.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From percival_bueser at cocolife.com  Fri Feb  3 01:53:14 2017
From: percival_bueser at cocolife.com (Percival Bueser)
Date: Fri, 3 Feb 2017 08:53:14 +0800
Subject: [R] Help with implementing Whittaker-Henderson graduation for
	raw-data
In-Reply-To: <396A20EA-E8AA-406F-B7D5-E6E81D6A227C@xs4all.nl>
References: <000001d27cfe$55494bd0$ffdbe370$@com>
	<396A20EA-E8AA-406F-B7D5-E6E81D6A227C@xs4all.nl>
Message-ID: <000201d27db7$e68b1f10$b3a15d30$@com>

Good day! 

Problems fixed. Resolutions:

Added 
require(pracma, warn.conflicts = FALSE) after library(pracma).

The code is now working. (The examples in the link
https://artax.karlin.mff.cuni.cz/r-help/library/pracma/html/whittaker
show the sample code for the function, but not the prerequisites. I've found
the prerequisites, so thank you very much!)

Regards,

Percy




-----Original Message-----
From: Berend Hasselman [mailto:bhh at xs4all.nl] 
Sent: Friday, February 3, 2017 2:08 AM
To: Percival Bueser
Cc: r-help at r-project.org
Subject: Re: [R] Help with implementing Whittaker-Henderson graduation for
raw-data


Why don't you just try the function whittaker from the pracma R package?
There is an example which should be adequate for finding out what to do.

Berend Hasselman

> On 2 Feb 2017, at 03:44, Percival Bueser <percival_bueser at cocolife.com>
wrote:
> 
> Good day everyone!
> 
> I would appreciate if anyone can help me regarding the following: I would
> like to implement the Whittaker-Henderson smoothing to the raw data on the
> attached .txt file, based on the description on this link:
> 
> https://artax.karlin.mff.cuni.cz/r-help/library/pracma/html/whittaker.html
> 
> On the attached .txt file, The x's are the independent variables and the
y's
> are the dependent variables. The signal to be smoothed is y, lambda = 1600
> and d = 2.
> 
> Can anyone please send me a sample R script, or a link to an R script
which
> I can adapt, where I can get both the (1) smoothed graph and the (2)
> smoothed values of y for each x given, and then import both the smoothed
> graph and the smoothed values of y to Microsoft Excel?
> 
> Thank you very much.
> 
> Regards,
> 
> Percy
> 
> 
> <Sample_data.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ankush.sak at gmail.com  Fri Feb  3 12:19:12 2017
From: ankush.sak at gmail.com (Ankush Sharma)
Date: Fri, 3 Feb 2017 16:49:12 +0530
Subject: [R] Error: long vectors (argument 1) are not supported in .Fortran
Message-ID: <CAALWEk3NVdWrOVyP1dC82wj4_N5VQwG3Z7riUVCc4ses4xs=rQ@mail.gmail.com>

Hi all ,

I'm working on WGCNA on  R-3.3.1 version to reconstruct gene -gene
coexpression networks of 54000 probes in 230 samples on Load Sharing
facility (Remote computing cluster). Despite memory at dispose, I'm
encountering a error of allocation of memory at soft thresholding step or
 at TOM Similarity step.  The problem of memory allocation at soft
thresholding step  was corrected by allocating the required memory using [bsub
-R "rusage[mem=40000]".

Error Message
 > # Turn adjacency into topological overlap

> TOM = TOMsimilarity(adjacency);

Error in TOMsimilarity(adjacency) :

  long vectors (argument 1) are not supported in .Fortran

Calls: TOMsimilarity -> .C

Execution halted

Warning message:

system call failed: Cannot allocate memory


?Is there a way to run build this TOMsimilarity matrix.


?Thanks
?





Best Regards,
?Ankush Sharma,PhD
Visiting CASyM Postdoctoral Research fellow (CASyM Consortium, EU-FP7)
LISM, Institute of Clinical Physiology, Siena (Italy)
?Experimental Oncology Unit (UOS),
?I?
?nstitute of Clinical Physiology
?- National Research Council, ?
 Siena (IT)

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Feb  3 16:31:33 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 3 Feb 2017 07:31:33 -0800
Subject: [R] Error: long vectors (argument 1) are not supported in
	.Fortran
In-Reply-To: <CAALWEk3NVdWrOVyP1dC82wj4_N5VQwG3Z7riUVCc4ses4xs=rQ@mail.gmail.com>
References: <CAALWEk3NVdWrOVyP1dC82wj4_N5VQwG3Z7riUVCc4ses4xs=rQ@mail.gmail.com>
Message-ID: <CAGxFJbRURyCPxsfKn=6ZQ2phjQ8usB4BpN06AoiAMzvpCZQp=A@mail.gmail.com>

Probably wrong list. Try the Bioconductor list instead.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 3, 2017 at 3:19 AM, Ankush Sharma <ankush.sak at gmail.com> wrote:
> Hi all ,
>
> I'm working on WGCNA on  R-3.3.1 version to reconstruct gene -gene
> coexpression networks of 54000 probes in 230 samples on Load Sharing
> facility (Remote computing cluster). Despite memory at dispose, I'm
> encountering a error of allocation of memory at soft thresholding step or
>  at TOM Similarity step.  The problem of memory allocation at soft
> thresholding step  was corrected by allocating the required memory using [bsub
> -R "rusage[mem=40000]".
>
> Error Message
>  > # Turn adjacency into topological overlap
>
>> TOM = TOMsimilarity(adjacency);
>
> Error in TOMsimilarity(adjacency) :
>
>   long vectors (argument 1) are not supported in .Fortran
>
> Calls: TOMsimilarity -> .C
>
> Execution halted
>
> Warning message:
>
> system call failed: Cannot allocate memory
>
>
> Is there a way to run build this TOMsimilarity matrix.
>
>
> Thanks
>
>
>
>
>
>
> Best Regards,
> Ankush Sharma,PhD
> Visiting CASyM Postdoctoral Research fellow (CASyM Consortium, EU-FP7)
> LISM, Institute of Clinical Physiology, Siena (Italy)
> Experimental Oncology Unit (UOS),
> I
> nstitute of Clinical Physiology
> - National Research Council,
>  Siena (IT)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ramiro at precisionbioassay.com  Fri Feb  3 16:51:51 2017
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Fri, 3 Feb 2017 15:51:51 +0000
Subject: [R] Using a mock of an S4 class
In-Reply-To: <9120e3e2-8f8c-2a14-acb3-d6ecf27573b8@roswellpark.org>
References: <C7338A7EFF31BB4D831BB06C00887789B9C015A8@MBX023-W1-CA-2.exch023.domain.local>,
	<9120e3e2-8f8c-2a14-acb3-d6ecf27573b8@roswellpark.org>
Message-ID: <C7338A7EFF31BB4D831BB06C00887789B9C0171A@MBX023-W1-CA-2.exch023.domain.local>

Thank you so much!!  This is very helpful.

On 02/01/2017 02:46 PM, Ramiro Barrantes wrote:
> Hello,
>
> I have a function that applies to an S4 object which contains a slot called @analysis:
>
> function calculation(myObject) {
>   tmp <- myObjects at analysis
>   result <- ...operations on analysis...
>   return result
> }
>
> I am writing a unit test for this function.  So I was hoping to create a mock object but I can't figure out how to do it:
>
> test_that("test calculation function", {
>   mockMyObject<- mock(?????)  #I am not sure what to put here
>   r<-calculation(mockMyObject)
>   expect_true(r,0.83625)
> })
>
> How can I create a mock S4 object??

I don't know of a convenient way to create a mock with functionality
like mocks in other languages. But here's a class

   .A = setClass("A", contains="integer")

This creates an instance that might be used as a mock

    mock = .A()  # same as new("A")

but maybe you have an initialize method (initialize methods are very
tricky to get correct, and many people avoid them, using
plain-old-functions to form an API around object creation; the
plain-old-function finishes by calling the constructor .A() or new("A"))
that has side effects that are inappropriate for your test, mimicked
here with stop()

   setMethod("initialize", "A", function(.Object, ...) stop("oops"))

our initial attempts are thwarted

 > .A()
Error in initialize(value, ...) : oops

but we could reach into our bag of hacks and try

   mock = .Call(methods:::C_new_object, getClassDef("A"))

You would still need to populate slots / data used in your test, e.g.,

   slot(mock, ".Data") = 1:4

This is robust to any validity method, since the validity method is not
invoked on direct slot assignment

   setValidity("A", function(object) {
       if (all(object > 0)) TRUE else "oops2"
   })

   slot(mock, ".Data") = 0:4  # still works

So something like

   mockS4object = function(class, ..., where=topenv(parent.frame())) {
       obj <- .Call(
           methods:::C_new_object,
           getClassDef(class, where=where)
       )

       args = list(...)
       for (nm in names(args))
           slot(obj, nm) = args[[nm]]

       obj
   }
   mockS4object("A", .Data=1:4)

Mock objects typically have useful testing properties, like returning
the number of times a slot (field) is accessed. Unfortunately, I don't
have anything to offer for that.

Martin


>
> Thanks in advance,
> Ramiro
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From Tilmann_Faul at t-online.de  Fri Feb  3 17:29:20 2017
From: Tilmann_Faul at t-online.de (Tilmann Faul)
Date: Fri, 3 Feb 2017 17:29:20 +0100
Subject: [R] use of Encoding()?
Message-ID: <54eeb713-efe4-6946-a7b4-eb790794357d@t-online.de>

Hey,

this is my first question here, so forgive me if i my be clumsy.

I want  to use Encoding to set the encoding of a character vector, but
it doese not seem to work. See example.

> x <- "16-03-02"
> Encoding(x)
[1] "unknown"
> Encoding(x) <- "latin1"
> Encoding(x)
[1] "unknown"

Is this intended?
Actually i want to change encoding of a character vector generated by
list.file on a linux computerwith UTF-8 file encoding, rstudio encoding
is iso8859-15.
Any hints?

best Tilmann


From peter.langfelder at gmail.com  Fri Feb  3 18:32:21 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 3 Feb 2017 09:32:21 -0800
Subject: [R] Error: long vectors (argument 1) are not supported in
	.Fortran
In-Reply-To: <CAGxFJbRURyCPxsfKn=6ZQ2phjQ8usB4BpN06AoiAMzvpCZQp=A@mail.gmail.com>
References: <CAALWEk3NVdWrOVyP1dC82wj4_N5VQwG3Z7riUVCc4ses4xs=rQ@mail.gmail.com>
	<CAGxFJbRURyCPxsfKn=6ZQ2phjQ8usB4BpN06AoiAMzvpCZQp=A@mail.gmail.com>
Message-ID: <CA+hbrhUaa2CEEva+ThAzdpA3CmdKXFtB_u_O5Z2W48BDthwGbg@mail.gmail.com>

Just to set the record straight, WGCNA is a CRAN package.

As to Ankush's question - the current WGCNA version does not support
analysis of more than about 46300 nodes (probes) in one block. You
have two options: 1. filter out some of the least-informative probes
(e.g., probes with lowest mean expression or lowest variance); 2. use
the "blockwise" approach as implemented in blockwiseModules. Set the
maxBlockSize argument to say 40000, and the function will
automatically split your data into 2 blocks and run the analysis in
each block separately.

The third option is to wait a few weeks (possibly months), I do have a
WGCNA update in the works that __should__ work on blocks larger than
46300.

Best,

Peter

On Fri, Feb 3, 2017 at 7:31 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Probably wrong list. Try the Bioconductor list instead.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Feb 3, 2017 at 3:19 AM, Ankush Sharma <ankush.sak at gmail.com> wrote:
>> Hi all ,
>>
>> I'm working on WGCNA on  R-3.3.1 version to reconstruct gene -gene
>> coexpression networks of 54000 probes in 230 samples on Load Sharing
>> facility (Remote computing cluster). Despite memory at dispose, I'm
>> encountering a error of allocation of memory at soft thresholding step or
>>  at TOM Similarity step.  The problem of memory allocation at soft
>> thresholding step  was corrected by allocating the required memory using [bsub
>> -R "rusage[mem=40000]".
>>
>> Error Message
>>  > # Turn adjacency into topological overlap
>>
>>> TOM = TOMsimilarity(adjacency);
>>
>> Error in TOMsimilarity(adjacency) :
>>
>>   long vectors (argument 1) are not supported in .Fortran
>>
>> Calls: TOMsimilarity -> .C
>>
>> Execution halted
>>
>> Warning message:
>>
>> system call failed: Cannot allocate memory
>>
>>
>> Is there a way to run build this TOMsimilarity matrix.
>>
>>
>> Thanks
>>
>>
>>
>>
>>
>>
>> Best Regards,
>> Ankush Sharma,PhD
>> Visiting CASyM Postdoctoral Research fellow (CASyM Consortium, EU-FP7)
>> LISM, Institute of Clinical Physiology, Siena (Italy)
>> Experimental Oncology Unit (UOS),
>> I
>> nstitute of Clinical Physiology
>> - National Research Council,
>>  Siena (IT)
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From olivier.crouzet at univ-nantes.fr  Fri Feb  3 19:12:08 2017
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Fri, 3 Feb 2017 19:12:08 +0100
Subject: [R] use of Encoding()?
In-Reply-To: <54eeb713-efe4-6946-a7b4-eb790794357d@t-online.de>
References: <54eeb713-efe4-6946-a7b4-eb790794357d@t-online.de>
Message-ID: <20170203191208.370d1daf5e335deb13a2f5df@univ-nantes.fr>

Hi,

using R version 3.3.2 under Linux, these work perfectly (but I receive
a correct encoding ("UTF-8"), not "unknown"). 

What is your system (windows, mac, linux)? Your R version? Which
interface (RStudio, Windows R interface)? There are often issues with
character encoding using Windows (in many different programming
languages) but it may not be the case concerning R.

If these operations are meant to read data from a file, you may
alternatively consider the option fileEncoding= from read.table /
read.csv (to change encoding) or, perhaps but I would
suggets first trying the preceding option, encoding= (to specifically
declare the file encoding if you know it but R does not detect it).

Olivier.


On Fri, 3 Feb 2017 17:29:20 +0100 Tilmann Faul
<Tilmann_Faul at t-online.de> wrote:

> Hey,
> 
> this is my first question here, so forgive me if i my be clumsy.
> 
> I want  to use Encoding to set the encoding of a character vector, but
> it doese not seem to work. See example.
> 
> > x <- "16-03-02"
> > Encoding(x)
> [1] "unknown"
> > Encoding(x) <- "latin1"
> > Encoding(x)
> [1] "unknown"
> 
> Is this intended?
> Actually i want to change encoding of a character vector generated by
> list.file on a linux computerwith UTF-8 file encoding, rstudio
> encoding is iso8859-15.
> Any hints?
> 
> best Tilmann
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique de Nantes -- UMR6310
  CNRS / Universit? de Nantes
  Chemin de la Censive du Tertre -- BP 81227
  44312 Nantes cedex 3
  France

  http://www.lling.univ-nantes.fr/


From dwinsemius at comcast.net  Fri Feb  3 20:23:02 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 3 Feb 2017 11:23:02 -0800
Subject: [R] use of Encoding()?
In-Reply-To: <20170203191208.370d1daf5e335deb13a2f5df@univ-nantes.fr>
References: <54eeb713-efe4-6946-a7b4-eb790794357d@t-online.de>
	<20170203191208.370d1daf5e335deb13a2f5df@univ-nantes.fr>
Message-ID: <81639044-E15F-4BE5-9E7F-75997C758A57@comcast.net>


> On Feb 3, 2017, at 10:12 AM, Olivier Crouzet <olivier.crouzet at univ-nantes.fr> wrote:
> 
> Hi,
> 
> using R version 3.3.2 under Linux, these work perfectly (but I receive
> a correct encoding ("UTF-8"), not "unknown"). 
> 
> What is your system (windows, mac, linux)? Your R version? Which
> interface (RStudio, Windows R interface)? There are often issues with
> character encoding using Windows (in many different programming
> languages) but it may not be the case concerning R.

I'm wondering if it's being done on a Mac, since I see the same behavior at my console (the "standard" R.app GUI). If the issue is with reading a Windows file while using one of the `read.*` functions, then setting the `fileEncoding` parameter to one of 'iso-8859-1' or 'cp1252' may be attempted.

The ?Encodings page says: "ASCII strings will never be marked with a declared encoding, since their representation is the same in all supported encodings."

Running the example in the help page (on a Mac):

> x <- "fa\xE7ile"
> Encoding(x)
[1] "unknown"
> Encoding(x) <- "latin1"
> x
[1] "fa?ile"
> Encoding(x)
[1] "latin1"


-- 
David.
> 
> If these operations are meant to read data from a file, you may
> alternatively consider the option fileEncoding= from read.table /
> read.csv (to change encoding) or, perhaps but I would
> suggets first trying the preceding option, encoding= (to specifically
> declare the file encoding if you know it but R does not detect it).
> 
> Olivier.
> 
> 
> On Fri, 3 Feb 2017 17:29:20 +0100 Tilmann Faul
> <Tilmann_Faul at t-online.de> wrote:
> 
>> Hey,
>> 
>> this is my first question here, so forgive me if i my be clumsy.
>> 
>> I want  to use Encoding to set the encoding of a character vector, but
>> it doese not seem to work. See example.
>> 
>>> x <- "16-03-02"
>>> Encoding(x)
>> [1] "unknown"
>>> Encoding(x) <- "latin1"
>>> Encoding(x)
>> [1] "unknown"
>> 
>> Is this intended?
>> Actually i want to change encoding of a character vector generated by
>> list.file on a linux computerwith UTF-8 file encoding, rstudio
>> encoding is iso8859-15.
>> Any hints?
>> 
>> best Tilmann
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
> 
> 
> -- 
>  Olivier Crouzet, PhD
>  Laboratoire de Linguistique de Nantes -- UMR6310
>  CNRS / Universit? de Nantes
>  Chemin de la Censive du Tertre -- BP 81227
>  44312 Nantes cedex 3
>  France
> 
>  http://www.lling.univ-nantes.fr/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From olivier.crouzet at univ-nantes.fr  Fri Feb  3 20:51:39 2017
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Fri, 3 Feb 2017 20:51:39 +0100
Subject: [R] use of Encoding()?
In-Reply-To: <81639044-E15F-4BE5-9E7F-75997C758A57@comcast.net>
References: <54eeb713-efe4-6946-a7b4-eb790794357d@t-online.de>
	<20170203191208.370d1daf5e335deb13a2f5df@univ-nantes.fr>
	<81639044-E15F-4BE5-9E7F-75997C758A57@comcast.net>
Message-ID: <20170203205139.10f219398aa4d2e432bf769a@univ-nantes.fr>

On Fri, 3 Feb 2017 11:23:02 -0800
David Winsemius <dwinsemius at comcast.net> wrote:

Oups, I (erroneously) tried with accented characters, which explains my
answer. Actually, I (correctly) get "unknown" if using characters from
the ASCII set, so my understanding is that there's actually no problem
with the OP's request as there's no reason why "16-03-02" should be
represented as anything else than "unknown" according to this
information (all characters are in the ASCII set).

Olivier.

> 
> > On Feb 3, 2017, at 10:12 AM, Olivier Crouzet
> > <olivier.crouzet at univ-nantes.fr> wrote:
> > 
> > Hi,
> > 
> > using R version 3.3.2 under Linux, these work perfectly (but I
> > receive a correct encoding ("UTF-8"), not "unknown"). 
> > 
> > What is your system (windows, mac, linux)? Your R version? Which
> > interface (RStudio, Windows R interface)? There are often issues
> > with character encoding using Windows (in many different programming
> > languages) but it may not be the case concerning R.
> 
> I'm wondering if it's being done on a Mac, since I see the same
> behavior at my console (the "standard" R.app GUI). If the issue is
> with reading a Windows file while using one of the `read.*`
> functions, then setting the `fileEncoding` parameter to one of
> 'iso-8859-1' or 'cp1252' may be attempted.
> 
> The ?Encodings page says: "ASCII strings will never be marked with a
> declared encoding, since their representation is the same in all
> supported encodings."
> 
> Running the example in the help page (on a Mac):
> 
> > x <- "fa\xE7ile"
> > Encoding(x)
> [1] "unknown"
> > Encoding(x) <- "latin1"
> > x
> [1] "fa?ile"
> > Encoding(x)
> [1] "latin1"
> 
> 
> -- 
> David.
> > 
> > If these operations are meant to read data from a file, you may
> > alternatively consider the option fileEncoding= from read.table /
> > read.csv (to change encoding) or, perhaps but I would
> > suggets first trying the preceding option, encoding= (to
> > specifically declare the file encoding if you know it but R does
> > not detect it).
> > 
> > Olivier.
> > 
> > 
> > On Fri, 3 Feb 2017 17:29:20 +0100 Tilmann Faul
> > <Tilmann_Faul at t-online.de> wrote:
> > 
> >> Hey,
> >> 
> >> this is my first question here, so forgive me if i my be clumsy.
> >> 
> >> I want  to use Encoding to set the encoding of a character vector,
> >> but it doese not seem to work. See example.
> >> 
> >>> x <- "16-03-02"
> >>> Encoding(x)
> >> [1] "unknown"
> >>> Encoding(x) <- "latin1"
> >>> Encoding(x)
> >> [1] "unknown"
> >> 
> >> Is this intended?
> >> Actually i want to change encoding of a character vector generated
> >> by list.file on a linux computerwith UTF-8 file encoding, rstudio
> >> encoding is iso8859-15.
> >> Any hints?
> >> 
> >> best Tilmann
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html and provide commented,
> >> minimal, self-contained, reproducible code.
> > 
> > 
> > -- 
> >  Olivier Crouzet, PhD
> >  Laboratoire de Linguistique de Nantes -- UMR6310
> >  CNRS / Universit? de Nantes
> >  Chemin de la Censive du Tertre -- BP 81227
> >  44312 Nantes cedex 3
> >  France
> > 
> >  http://www.lling.univ-nantes.fr/
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 


-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique de Nantes -- UMR6310
  CNRS / Universit? de Nantes
  Chemin de la Censive du Tertre -- BP 81227
  44312 Nantes cedex 3
  France

  http://www.lling.univ-nantes.fr/


From roy.mendelssohn at noaa.gov  Fri Feb  3 23:10:40 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 3 Feb 2017 14:10:40 -0800
Subject: [R] testers  sought for xtractomatic-like package
Message-ID: <28B24DC4-3876-4F9E-8457-8E24DFC248C4@noaa.gov>

rerddapXtracto is an R package developed to subset and extract satellite and other oceanographic related data from a remote ERDDAP server. The program can extract data for a moving point in time along a user-supplied set of longitude, latitude and time points; in a 3D bounding box; or within a polygon (through time). 

These functions differ from those in the xtractomatic package in that they use the rerddap package to access gridded data on any ERDDAP server, but they require the user to provide initial information about the data to be extracted. 

I am looking for people to test the package.  Right now it is only available on github at https://github.com/rmendels/rerddapXtracto.  A number of people have successful used the package,  but for now consider it test quality only.  The vignette can be seen at https://rmendels.github.io/UsingrerddapXtracto.nb.html  and an RNotebook downloaded from there.

Thanks in advance for any help.

-Roy




**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From tal.galili at gmail.com  Sat Feb  4 13:17:01 2017
From: tal.galili at gmail.com (Tal Galili)
Date: Sat, 4 Feb 2017 14:17:01 +0200
Subject: [R] Is a list an atomic object? (or is there an issue with the help
 page of ?tapply ?)
Message-ID: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>

In the help page of ?tapply it says that the first argument (X) is "an
atomic object, typically a vector."

However, tapply seems to be able to handle list objects. For example:

###################

l <- as.list(1:10)
is.atomic(l) # FALSE
index <- c(rep(1,5),rep(2,5))
tapply(l,index,unlist)

> tapply(l,index,unlist)
$`1`
[1] 1 2 3 4 5

$`2`
[1]  6  7  8  9 10


###################

Hence, does it mean a list an atomic object? (which I thought it wasn't) or
is the help for tapply needs updating?
(or some third option I'm missing?)

Thanks.





----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From aurelie.siberchicot at univ-lyon1.fr  Fri Feb  3 18:02:00 2017
From: aurelie.siberchicot at univ-lyon1.fr (=?UTF-8?Q?Aur=c3=a9lie_Siberchicot?=)
Date: Fri, 3 Feb 2017 18:02:00 +0100
Subject: [R] [R-pkgs] Announcing fitdistrplus 1.0-8
Message-ID: <fbcf66e2-3899-9b09-e09b-44453a296af9@univ-lyon1.fr>

Dear useRs,

We are pleased to announce you a new version of "fitdistrplus" on CRAN :
https://cran.r-project.org/web/packages/fitdistrplus/index.html

"fitdistrplus" is a package dedicated to help the fit of a parametric 
distribution to non-censored or censored data.

The main new features in this release are few new topics in the FAQ 
vignette 
(https://cran.r-project.org/web/packages/fitdistrplus/vignettes/FAQ.html) 
and the now possible use of "ggplot2" in functions "cdfcomp", 
"denscomp", "qqcomp" and "ppcomp".
We also created a new mailing list 
fitdist-users at listes.univ-lyon1.fr*//*at which you can send any question 
or comment regarding "fitdistrplus".

Best regards,

Marie Laure Delignette-Muller, Christophe Dutang and Aur?lie Siberchicot

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From chuck.snell.email at gmail.com  Fri Feb  3 20:57:24 2017
From: chuck.snell.email at gmail.com (Chuck Snell)
Date: Fri, 3 Feb 2017 13:57:24 -0600
Subject: [R] using extremes - extreme value analysis for low (minimum)
	temperature
Message-ID: <CAB7MhXjxFAuJXAuS6tU-_Kt_fx8XND6TfgkOcVgfZ9YyimAxZw@mail.gmail.com>

Hello,

I am trying to answer the question:

"What is the probability of a certain day's low forecast (of 21) being the
month's overall low?"

I decided to attempt it in R

Searching pointed me to extreme value analysis.

I created a csv file of the last 8 years lows for the month:
year       month's low

2009 10.04

2010 18.493

2011 7.547

2012 15.008

2013 19.283

2014 9.508

2015 2.55

2016 20.1


I loaded "extremes"


install.packages("extRemes")
library(extRemes)

I successfully loaded the csv file.
I initially started with fitting to a Gumbel

fit2 <- fevd(PeakingLowTemp,FebruaryEVA,type="Gumbel")

Now for my question - unfortunately the examples I am finding all deal with
maximums -
meaning maximum high temps and probability of exceeding and maximum
rainfall and probability of exceeding

I need to fit the lows (minimums) and calculate the probability of being
less than a temp.

Can you help guide me with the remainder of my setup

Thanks!!

	[[alternative HTML version deleted]]


From art.tem.us at gmail.com  Fri Feb  3 21:07:13 2017
From: art.tem.us at gmail.com (Art U)
Date: Fri, 3 Feb 2017 15:07:13 -0500
Subject: [R] Change (merge) vector by row names.
Message-ID: <CAKY_brEbJcey__MpJ9jjyUPLt6_yG25poRVbQC9mdfjr-S22Yw@mail.gmail.com>

Hello,

I have a vector of coefficients from backward selection model that looks
like:

             [,1]
(Intercept) -0.15
s1[, 1]      2.65
s1[, 2]      1.81
s1[, 5]      2.35


I'd like to get a new vector that contains zeroes for variables that were
not included in the final model. For example here it suppose to be:

             [,1]
(Intercept) -0.15
s1[, 1]      2.65
s1[, 2]      1.81
s1[, 3]      0
s1[, 4]      0
s1[, 5]      2.35

s1[, 6]      0

s1[, 7]      0

s1[, 8]      0


Is there simple function I can use to get such result?
Regards,
Ariel


-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]


From ankush.sak at gmail.com  Sat Feb  4 04:34:44 2017
From: ankush.sak at gmail.com (Ankush Sharma)
Date: Sat, 4 Feb 2017 09:04:44 +0530
Subject: [R] Error: long vectors (argument 1) are not supported in
	.Fortran
In-Reply-To: <CA+hbrhUaa2CEEva+ThAzdpA3CmdKXFtB_u_O5Z2W48BDthwGbg@mail.gmail.com>
References: <CAALWEk3NVdWrOVyP1dC82wj4_N5VQwG3Z7riUVCc4ses4xs=rQ@mail.gmail.com>
	<CAGxFJbRURyCPxsfKn=6ZQ2phjQ8usB4BpN06AoiAMzvpCZQp=A@mail.gmail.com>
	<CA+hbrhUaa2CEEva+ThAzdpA3CmdKXFtB_u_O5Z2W48BDthwGbg@mail.gmail.com>
Message-ID: <CAALWEk3A8X9dYFE9Hj22=rbcVW8fue4DsH-KQ3iY74+SWsaFzw@mail.gmail.com>

Many thanks for the prompt response.

Best Regards,
?Ankush Sharma,PhD
Visiting CASyM Postdoctoral Research fellow (CASyM Consortium, EU-FP7)
LISM, Institute of Clinical Physiology, Siena (Italy)
?Experimental Oncology Unit (UOS),
?I?
?nstitute of Clinical Physiology
?- National Research Council, ?
 Siena (IT)

On Fri, Feb 3, 2017 at 11:02 PM, Peter Langfelder <
peter.langfelder at gmail.com> wrote:

> Just to set the record straight, WGCNA is a CRAN package.
>
> As to Ankush's question - the current WGCNA version does not support
> analysis of more than about 46300 nodes (probes) in one block. You
> have two options: 1. filter out some of the least-informative probes
> (e.g., probes with lowest mean expression or lowest variance); 2. use
> the "blockwise" approach as implemented in blockwiseModules. Set the
> maxBlockSize argument to say 40000, and the function will
> automatically split your data into 2 blocks and run the analysis in
> each block separately.
>
> The third option is to wait a few weeks (possibly months), I do have a
> WGCNA update in the works that __should__ work on blocks larger than
> 46300.
>
> Best,
>
> Peter
>
> On Fri, Feb 3, 2017 at 7:31 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> > Probably wrong list. Try the Bioconductor list instead.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Fri, Feb 3, 2017 at 3:19 AM, Ankush Sharma <ankush.sak at gmail.com>
> wrote:
> >> Hi all ,
> >>
> >> I'm working on WGCNA on  R-3.3.1 version to reconstruct gene -gene
> >> coexpression networks of 54000 probes in 230 samples on Load Sharing
> >> facility (Remote computing cluster). Despite memory at dispose, I'm
> >> encountering a error of allocation of memory at soft thresholding step
> or
> >>  at TOM Similarity step.  The problem of memory allocation at soft
> >> thresholding step  was corrected by allocating the required memory
> using [bsub
> >> -R "rusage[mem=40000]".
> >>
> >> Error Message
> >>  > # Turn adjacency into topological overlap
> >>
> >>> TOM = TOMsimilarity(adjacency);
> >>
> >> Error in TOMsimilarity(adjacency) :
> >>
> >>   long vectors (argument 1) are not supported in .Fortran
> >>
> >> Calls: TOMsimilarity -> .C
> >>
> >> Execution halted
> >>
> >> Warning message:
> >>
> >> system call failed: Cannot allocate memory
> >>
> >>
> >> Is there a way to run build this TOMsimilarity matrix.
> >>
> >>
> >> Thanks
> >>
> >>
> >>
> >>
> >>
> >>
> >> Best Regards,
> >> Ankush Sharma,PhD
> >> Visiting CASyM Postdoctoral Research fellow (CASyM Consortium, EU-FP7)
> >> LISM, Institute of Clinical Physiology, Siena (Italy)
> >> Experimental Oncology Unit (UOS),
> >> I
> >> nstitute of Clinical Physiology
> >> - National Research Council,
> >>  Siena (IT)
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Feb  4 17:43:11 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 4 Feb 2017 17:43:11 +0100
Subject: [R] Change (merge) vector by row names.
In-Reply-To: <CAKY_brEbJcey__MpJ9jjyUPLt6_yG25poRVbQC9mdfjr-S22Yw@mail.gmail.com>
References: <CAKY_brEbJcey__MpJ9jjyUPLt6_yG25poRVbQC9mdfjr-S22Yw@mail.gmail.com>
Message-ID: <4D09C198-87D8-4F5B-8E32-CECA35C15F37@gmail.com>


> On 03 Feb 2017, at 21:07 , Art U <art.tem.us at gmail.com> wrote:
> 
> Hello,
> 
> I have a vector of coefficients from backward selection model that looks
> like:
> 
>             [,1]
> (Intercept) -0.15
> s1[, 1]      2.65
> s1[, 2]      1.81
> s1[, 5]      2.35
> 
> 
> I'd like to get a new vector that contains zeroes for variables that were
> not included in the final model. For example here it suppose to be:
> 
>             [,1]
> (Intercept) -0.15
> s1[, 1]      2.65
> s1[, 2]      1.81
> s1[, 3]      0
> s1[, 4]      0
> s1[, 5]      2.35
> 
> s1[, 6]      0
> 
> s1[, 7]      0
> 
> s1[, 8]      0
> 
> 
> Is there simple function I can use to get such result?

I wouldn't waste time looking for it... It goes something like

fullnames <- ...
extended <- matrix(0,length(fullnames),1)
rownames(extended) <- fullnames
extended[rownames(reduced),] <- reduced

where, presumably, you can find fullnames fromm the fit of a full model.

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From riyasmjgeo at gmail.com  Sat Feb  4 18:14:01 2017
From: riyasmjgeo at gmail.com (Riyas MJ)
Date: Sat, 4 Feb 2017 22:44:01 +0530
Subject: [R] Gradient color to a line graph
Message-ID: <CAEPexpw-MQ5DWnn6cqBE4Qu+ytGg0u9WcFAy-yr1FMbW2HS5Cw@mail.gmail.com>

Hi all,

I am a new user of R. I just did my first real program.
I would like to know how to put a gradient (like rainbow() or topo.colors,
etc) to a* line* graph.

Example:
ar1=array(data=1:10,dim=9)
ar2=array(data=11:20,dim=9)
plot(ar1,ar2,type="l",col="red",lwd=3)

Instead of a red color, I would like to make it in rainbow colors.
Tried to do my own and tried searching but everywhere its about giving
gradient to point graph, not to a line graph. Please help, it is needed for
my work.

Thanks in advance
-- 
Riyas MJ
Project assistant (PA -II)
Physical Oceanography Department (POD)
CSIR- National Institute of Oceanography (NIO)
Dona Paula, Goa - 403 004, India
Ph: +91 9037553320, +91 7083030397

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Feb  4 21:19:14 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 4 Feb 2017 12:19:14 -0800
Subject: [R] Gradient color to a line graph
In-Reply-To: <CAEPexpw-MQ5DWnn6cqBE4Qu+ytGg0u9WcFAy-yr1FMbW2HS5Cw@mail.gmail.com>
References: <CAEPexpw-MQ5DWnn6cqBE4Qu+ytGg0u9WcFAy-yr1FMbW2HS5Cw@mail.gmail.com>
Message-ID: <5144217C-5FFD-4862-A712-175FBFC4971F@comcast.net>


> On Feb 4, 2017, at 9:14 AM, Riyas MJ <riyasmjgeo at gmail.com> wrote:
> 
> Hi all,
> 
> I am a new user of R. I just did my first real program.
> I would like to know how to put a gradient (like rainbow() or topo.colors,
> etc) to a* line* graph.
> 
> Example:
> ar1=array(data=1:10,dim=9)
> ar2=array(data=11:20,dim=9)
> plot(ar1,ar2,type="l",col="red",lwd=3)
> 
> Instead of a red color, I would like to make it in rainbow colors.
> Tried to do my own and tried searching but everywhere its about giving
> gradient to point graph, not to a line graph. Please help, it is needed for

Install the plotrix package and look in its Index page for a function name that has both `color` and `line` in its name.

-- 
David.
> my work.
> 
> Thanks in advance
> -- 
> Riyas MJ
> Project assistant (PA -II)
> Physical Oceanography Department (POD)
> CSIR- National Institute of Oceanography (NIO)
> Dona Paula, Goa - 403 004, India
> Ph: +91 9037553320, +91 7083030397
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sat Feb  4 21:57:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 04 Feb 2017 12:57:18 -0800
Subject: [R] Gradient color to a line graph
In-Reply-To: <5144217C-5FFD-4862-A712-175FBFC4971F@comcast.net>
References: <CAEPexpw-MQ5DWnn6cqBE4Qu+ytGg0u9WcFAy-yr1FMbW2HS5Cw@mail.gmail.com>
	<5144217C-5FFD-4862-A712-175FBFC4971F@comcast.net>
Message-ID: <CB2B6BEB-FFF3-447C-945B-B11C0388EE5E@dcn.davis.ca.us>

You haven't indicated what information you want to convey with this gradient. 

You also are using arrays where you should be using vectors, usually stored in a data frame.

Here is one way using the contributed package ggplot2:

library(ggplot2)
DF <- data.frame( V1=1:10, V2=11:20, C=21:30 )
p <- ggplot( DF, aes( x=V1, y=V2, colour=C ) ) +
    geom_line( size=2 ) +
    scale_colour_gradient( low="red", high="blue" )
print( p )


-- 
Sent from my phone. Please excuse my brevity.

On February 4, 2017 12:19:14 PM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Feb 4, 2017, at 9:14 AM, Riyas MJ <riyasmjgeo at gmail.com> wrote:
>> 
>> Hi all,
>> 
>> I am a new user of R. I just did my first real program.
>> I would like to know how to put a gradient (like rainbow() or
>topo.colors,
>> etc) to a* line* graph.
>> 
>> Example:
>> ar1=array(data=1:10,dim=9)
>> ar2=array(data=11:20,dim=9)
>> plot(ar1,ar2,type="l",col="red",lwd=3)
>> 
>> Instead of a red color, I would like to make it in rainbow colors.
>> Tried to do my own and tried searching but everywhere its about
>giving
>> gradient to point graph, not to a line graph. Please help, it is
>needed for
>
>Install the plotrix package and look in its Index page for a function
>name that has both `color` and `line` in its name.


From payneb at post.bgu.ac.il  Sun Feb  5 13:01:07 2017
From: payneb at post.bgu.ac.il (Brandon Payne)
Date: Sun, 5 Feb 2017 14:01:07 +0200
Subject: [R] mean of a column in a list of data frames
Message-ID: <CAN4m+BJC9iUZwfG4_Ar6xn3nACVpWREr+Av6MPhp6++bnfRybQ@mail.gmail.com>

I have a list of data frames,

    ownersList <- list(exp2004owners,exp2005owners,
                   exp2006owners,exp2007owners,
                   exp2008owners,exp2009owners,
                   exp2010owners,exp2011owners,
                   exp2012owners,exp2013owners,
                   exp2014owners)

 I want to take the mean of the first column $grossIncome.
 I can access the first column with

lapply(ownersList, "[[", 1)                      ##works

But I can't take the mean of that.
mean(lapply(ownersList, "[[", 1))          ##not working

There must be a more idiomatic way to write this with map or apply.

ownersIncome<- c(mean(ownersList[[1]]$grossIncome),
                 mean(ownersList[[2]]$grossIncome),
                 mean(ownersList[[3]]$grossIncome),
                 mean(ownersList[[4]]$grossIncome),
                 mean(ownersList[[5]]$grossIncome),
                 mean(ownersList[[6]]$grossIncome),
                 mean(ownersList[[7]]$grossIncome),
                 mean(ownersList[[8]]$grossIncome),
                 mean(ownersList[[9]]$grossIncome),
                 mean(ownersList[[10]]$grossIncome),
                 mean(ownersList[[11]]$grossIncome))

I tried a for loop, which also didn't work.

aList<-
    for(i in 1:3){
    mean(ownersList[[i]]$grossIncome)
}
aList

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Feb  5 13:15:46 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 5 Feb 2017 07:15:46 -0500
Subject: [R] mean of a column in a list of data frames
In-Reply-To: <CAN4m+BJC9iUZwfG4_Ar6xn3nACVpWREr+Av6MPhp6++bnfRybQ@mail.gmail.com>
References: <CAN4m+BJC9iUZwfG4_Ar6xn3nACVpWREr+Av6MPhp6++bnfRybQ@mail.gmail.com>
Message-ID: <c81d2e5d-5d40-fd1c-0b21-1af9bd52e5a5@gmail.com>

On 05/02/2017 7:01 AM, Brandon Payne wrote:
> I have a list of data frames,
>
>     ownersList <- list(exp2004owners,exp2005owners,
>                    exp2006owners,exp2007owners,
>                    exp2008owners,exp2009owners,
>                    exp2010owners,exp2011owners,
>                    exp2012owners,exp2013owners,
>                    exp2014owners)
>
>  I want to take the mean of the first column $grossIncome.
>  I can access the first column with
>
> lapply(ownersList, "[[", 1)                      ##works
>
> But I can't take the mean of that.
> mean(lapply(ownersList, "[[", 1))          ##not working

lapply returns a list of the first columns, and mean() doesn't know what 
to do with that.
>
> There must be a more idiomatic way to write this with map or apply.

Yes, take the mean inside lapply:

lapply(ownersList, function(x) mean(x[[1]]))

Not tested.

Duncan Murdoch

>
> ownersIncome<- c(mean(ownersList[[1]]$grossIncome),
>                  mean(ownersList[[2]]$grossIncome),
>                  mean(ownersList[[3]]$grossIncome),
>                  mean(ownersList[[4]]$grossIncome),
>                  mean(ownersList[[5]]$grossIncome),
>                  mean(ownersList[[6]]$grossIncome),
>                  mean(ownersList[[7]]$grossIncome),
>                  mean(ownersList[[8]]$grossIncome),
>                  mean(ownersList[[9]]$grossIncome),
>                  mean(ownersList[[10]]$grossIncome),
>                  mean(ownersList[[11]]$grossIncome))
>
> I tried a for loop, which also didn't work.
>
> aList<-
>     for(i in 1:3){
>     mean(ownersList[[i]]$grossIncome)
> }

for loops don't have a useful value:  it's always NULL.  This would have 
worked as

aList <- list()
for(i in 1:3){
     aList[[i]] <- mean(ownersList[[i]]$grossIncome)
}


Duncan Murdoch


From ruipbarradas at sapo.pt  Sun Feb  5 13:20:13 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 05 Feb 2017 12:20:13 +0000
Subject: [R] mean of a column in a list of data frames
In-Reply-To: <CAN4m+BJC9iUZwfG4_Ar6xn3nACVpWREr+Av6MPhp6++bnfRybQ@mail.gmail.com>
References: <CAN4m+BJC9iUZwfG4_Ar6xn3nACVpWREr+Av6MPhp6++bnfRybQ@mail.gmail.com>
Message-ID: <5897187D.4040404@sapo.pt>

Hello,

Try instead the following.

aList<- numeric(3)
for(i in 1:3){
       aList[i] <- mean(ownersList[[i]]$grossIncome)
}
aList

Hope this helps,

Rui Barradas


Em 05-02-2017 12:01, Brandon Payne escreveu:
> I have a list of data frames,
>
>      ownersList <- list(exp2004owners,exp2005owners,
>                     exp2006owners,exp2007owners,
>                     exp2008owners,exp2009owners,
>                     exp2010owners,exp2011owners,
>                     exp2012owners,exp2013owners,
>                     exp2014owners)
>
>   I want to take the mean of the first column $grossIncome.
>   I can access the first column with
>
> lapply(ownersList, "[[", 1)                      ##works
>
> But I can't take the mean of that.
> mean(lapply(ownersList, "[[", 1))          ##not working
>
> There must be a more idiomatic way to write this with map or apply.
>
> ownersIncome<- c(mean(ownersList[[1]]$grossIncome),
>                   mean(ownersList[[2]]$grossIncome),
>                   mean(ownersList[[3]]$grossIncome),
>                   mean(ownersList[[4]]$grossIncome),
>                   mean(ownersList[[5]]$grossIncome),
>                   mean(ownersList[[6]]$grossIncome),
>                   mean(ownersList[[7]]$grossIncome),
>                   mean(ownersList[[8]]$grossIncome),
>                   mean(ownersList[[9]]$grossIncome),
>                   mean(ownersList[[10]]$grossIncome),
>                   mean(ownersList[[11]]$grossIncome))
>
> I tried a for loop, which also didn't work.
>
> aList<-
>      for(i in 1:3){
>      mean(ownersList[[i]]$grossIncome)
> }
> aList
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfhenson1 at gmail.com  Sun Feb  5 20:44:40 2017
From: jfhenson1 at gmail.com (James Henson)
Date: Sun, 5 Feb 2017 13:44:40 -0600
Subject: [R] Marg.fct function
Message-ID: <CABPq8JPYNbH-=YPevKJ-gLK3fnKEd-L3LRzc=6N6JrFMRZZSwQ@mail.gmail.com>

Greetings R Community,

An attempt to reproduce the results from code in the source below
fails.  R cannot find the function ?Marg.fct?. An Internet search for
the ?Marg.fct? function was not fruitful.  I appreciate your help.
Best regards, James F. Henson.

R (and S-PLUS) Manual to Accompany Agresti?s Categorical Data Analysis
(2002) 2nd edition Laura A. Thompson, 2009?

http://www.stat.ufl.edu/~aa/cda/Thompson_manual.pdf  page 181

The code is:

# Code from Manual to Accompany Agresti?s Categorical Data Analysis
(2002) 2nd edition Laura A. Thompson, 2009

y <- c(144, 33, 84, 126, 2, 4, 14, 29, 0, 2, 6, 25, 0, 0, 1, 5)

ZF <- Z <- matrix(1,16,1)

#

M1 <- Marg.fct(1,rep(4,2)) # used to get m1+, etc

Error: could not find function "Marg.fct"



M2 <- Marg.fct(2,rep(4,2)) # used to get m+1, etc

#

C.matrix <- matrix(c(

  1, 0, 0, 0, -1, 0, 0, 0, # y1+ = y+1

  0, 1, 0, 0, 0, -1, 0, 0, # y2+ = y+2

  0, 0, 1, 0, 0, 0, -1, 0), # y3+ = y+3

  3,8,byrow=T)

h.fct <- function(m) { # constraint function

  marg <- rbind(M1%*%m, M2%*%m) # y1+, y2+, y3+, y4+, y+1, y+2, y+3, y+4

  C.matrix%*%marg # y1+ = y+1, y2+ = y+2, etc

}

#

a <- mph.fit(y=y,Z=Z,ZF=ZF,h.fct=h.fct)

mph.summary(a)


From pdalgd at gmail.com  Sun Feb  5 22:10:13 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 5 Feb 2017 22:10:13 +0100
Subject: [R] Marg.fct function
In-Reply-To: <CABPq8JPYNbH-=YPevKJ-gLK3fnKEd-L3LRzc=6N6JrFMRZZSwQ@mail.gmail.com>
References: <CABPq8JPYNbH-=YPevKJ-gLK3fnKEd-L3LRzc=6N6JrFMRZZSwQ@mail.gmail.com>
Message-ID: <B5B8C20B-FEA4-456E-9A95-349CB58C4414@gmail.com>


> On 05 Feb 2017, at 20:44 , James Henson <jfhenson1 at gmail.com> wrote:
> 
> Greetings R Community,
> 
> An attempt to reproduce the results from code in the source below
> fails.  R cannot find the function ?Marg.fct?. An Internet search for
> the ?Marg.fct? function was not fruitful.  I appreciate your help.
> Best regards, James F. Henson.

I have no specific knowledge of this, but Thompson's document refers to MPH.FIT, and if you google that, you get to 

http://homepage.stat.uiowa.edu/~jblang/mph.fitting/mph.fit.documentation.2.0.htm

which tells you that to get the software, you should contact the author. And "please do not distribute", etc.

You could try that, but the document is from 2007, so there is some risk that you will experience an example of the "bitrot" that CRAN was designed to avoid...

-pd

> 
> R (and S-PLUS) Manual to Accompany Agresti?s Categorical Data Analysis
> (2002) 2nd edition Laura A. Thompson, 2009?
> 
> http://www.stat.ufl.edu/~aa/cda/Thompson_manual.pdf  page 181
> 
> The code is:
> 
> # Code from Manual to Accompany Agresti?s Categorical Data Analysis
> (2002) 2nd edition Laura A. Thompson, 2009
> 
> y <- c(144, 33, 84, 126, 2, 4, 14, 29, 0, 2, 6, 25, 0, 0, 1, 5)
> 
> ZF <- Z <- matrix(1,16,1)
> 
> #
> 
> M1 <- Marg.fct(1,rep(4,2)) # used to get m1+, etc
> 
> Error: could not find function "Marg.fct"
> 
> 
> 
> M2 <- Marg.fct(2,rep(4,2)) # used to get m+1, etc
> 
> #
> 
> C.matrix <- matrix(c(
> 
>  1, 0, 0, 0, -1, 0, 0, 0, # y1+ = y+1
> 
>  0, 1, 0, 0, 0, -1, 0, 0, # y2+ = y+2
> 
>  0, 0, 1, 0, 0, 0, -1, 0), # y3+ = y+3
> 
>  3,8,byrow=T)
> 
> h.fct <- function(m) { # constraint function
> 
>  marg <- rbind(M1%*%m, M2%*%m) # y1+, y2+, y3+, y4+, y+1, y+2, y+3, y+4
> 
>  C.matrix%*%marg # y1+ = y+1, y2+ = y+2, etc
> 
> }
> 
> #
> 
> a <- mph.fit(y=y,Z=Z,ZF=ZF,h.fct=h.fct)
> 
> mph.summary(a)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.ca.us  Sun Feb  5 22:47:07 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 05 Feb 2017 13:47:07 -0800
Subject: [R] Marg.fct function
In-Reply-To: <CABPq8JPYNbH-=YPevKJ-gLK3fnKEd-L3LRzc=6N6JrFMRZZSwQ@mail.gmail.com>
References: <CABPq8JPYNbH-=YPevKJ-gLK3fnKEd-L3LRzc=6N6JrFMRZZSwQ@mail.gmail.com>
Message-ID: <5B13CE3B-8F28-4A35-9053-1717E25C19C7@dcn.davis.ca.us>

It is not part of "R". You can dig through all of the packages that the author mentions,  or send an email to the author. 
-- 
Sent from my phone. Please excuse my brevity.

On February 5, 2017 11:44:40 AM PST, James Henson <jfhenson1 at gmail.com> wrote:
>Greetings R Community,
>
>An attempt to reproduce the results from code in the source below
>fails.  R cannot find the function ?Marg.fct?. An Internet search for
>the ?Marg.fct? function was not fruitful.  I appreciate your help.
>Best regards, James F. Henson.
>
>R (and S-PLUS) Manual to Accompany Agresti?s Categorical Data Analysis
>(2002) 2nd edition Laura A. Thompson, 2009?
>
>http://www.stat.ufl.edu/~aa/cda/Thompson_manual.pdf  page 181
>
>The code is:
>
># Code from Manual to Accompany Agresti?s Categorical Data Analysis
>(2002) 2nd edition Laura A. Thompson, 2009
>
>y <- c(144, 33, 84, 126, 2, 4, 14, 29, 0, 2, 6, 25, 0, 0, 1, 5)
>
>ZF <- Z <- matrix(1,16,1)
>
>#
>
>M1 <- Marg.fct(1,rep(4,2)) # used to get m1+, etc
>
>Error: could not find function "Marg.fct"
>
>
>
>M2 <- Marg.fct(2,rep(4,2)) # used to get m+1, etc
>
>#
>
>C.matrix <- matrix(c(
>
>  1, 0, 0, 0, -1, 0, 0, 0, # y1+ = y+1
>
>  0, 1, 0, 0, 0, -1, 0, 0, # y2+ = y+2
>
>  0, 0, 1, 0, 0, 0, -1, 0), # y3+ = y+3
>
>  3,8,byrow=T)
>
>h.fct <- function(m) { # constraint function
>
> marg <- rbind(M1%*%m, M2%*%m) # y1+, y2+, y3+, y4+, y+1, y+2, y+3, y+4
>
>  C.matrix%*%marg # y1+ = y+1, y2+ = y+2, etc
>
>}
>
>#
>
>a <- mph.fit(y=y,Z=Z,ZF=ZF,h.fct=h.fct)
>
>mph.summary(a)
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From riyasmjgeo at gmail.com  Mon Feb  6 06:15:23 2017
From: riyasmjgeo at gmail.com (Riyas MJ)
Date: Mon, 6 Feb 2017 10:45:23 +0530
Subject: [R] Gradient color to a line graph
In-Reply-To: <CB2B6BEB-FFF3-447C-945B-B11C0388EE5E@dcn.davis.ca.us>
References: <CAEPexpw-MQ5DWnn6cqBE4Qu+ytGg0u9WcFAy-yr1FMbW2HS5Cw@mail.gmail.com>
	<5144217C-5FFD-4862-A712-175FBFC4971F@comcast.net>
	<CB2B6BEB-FFF3-447C-945B-B11C0388EE5E@dcn.davis.ca.us>
Message-ID: <CAEPexpz5oKi57rU+Nc7bvPRUETBswO8QaGN0AEJZV5298Y76OA@mail.gmail.com>

Thank you so much. Both worked well. Thanks

On Sun, Feb 5, 2017 at 2:27 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You haven't indicated what information you want to convey with this
> gradient.
>
> You also are using arrays where you should be using vectors, usually
> stored in a data frame.
>
> Here is one way using the contributed package ggplot2:
>
> library(ggplot2)
> DF <- data.frame( V1=1:10, V2=11:20, C=21:30 )
> p <- ggplot( DF, aes( x=V1, y=V2, colour=C ) ) +
>     geom_line( size=2 ) +
>     scale_colour_gradient( low="red", high="blue" )
> print( p )
>
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 4, 2017 12:19:14 PM PST, David Winsemius <
> dwinsemius at comcast.net> wrote:
> >
> >> On Feb 4, 2017, at 9:14 AM, Riyas MJ <riyasmjgeo at gmail.com> wrote:
> >>
> >> Hi all,
> >>
> >> I am a new user of R. I just did my first real program.
> >> I would like to know how to put a gradient (like rainbow() or
> >topo.colors,
> >> etc) to a* line* graph.
> >>
> >> Example:
> >> ar1=array(data=1:10,dim=9)
> >> ar2=array(data=11:20,dim=9)
> >> plot(ar1,ar2,type="l",col="red",lwd=3)
> >>
> >> Instead of a red color, I would like to make it in rainbow colors.
> >> Tried to do my own and tried searching but everywhere its about
> >giving
> >> gradient to point graph, not to a line graph. Please help, it is
> >needed for
> >
> >Install the plotrix package and look in its Index page for a function
> >name that has both `color` and `line` in its name.
>



-- 
Riyas MJ
Project assistant (PA -II)
Physical Oceanography Department (POD)
CSIR- National Institute of Oceanography (NIO)
Dona Paula, Goa - 403 004, India
Ph: +91 9037553320, +91 7083030397

	[[alternative HTML version deleted]]


From dilorenzopl at gmail.com  Sat Feb  4 21:59:22 2017
From: dilorenzopl at gmail.com (Paolo Di Lorenzo)
Date: Sat, 4 Feb 2017 15:59:22 -0500
Subject: [R] [R-pkgs] usmap v 0.1.0 released
Message-ID: <CAHujmRZV-ePVGzQ-uUCM862BKzMiBj2rTsRfYVkrEpGL319Duw@mail.gmail.com>

Hello useRs,

I am announcing the release of my first package, usmap (
http://cran.r-project.org/package=usmap).

"usmap" is a package to aid in the creation of US choropleths that include
Alaska and Hawaii. It is still in its early stages (v 0.1.0) but I hope to
improve it with added functionality over time.

Features can be seen in the vignettes here:
https://cran.r-project.org/web/packages/usmap/vignettes/introduction.html
https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html

Feel free to contribute ideas and code: http://github.com/pdil/usmap

If you have any questions please email me at paolo at dilorenzo.pl or message
me on Twitter @dilorenzopl <http://www.twitter.com/dilorenzopl>.

Thank you,

Paolo Di Lorenzo
http://dilorenzo.pl
paolo at dilorenzo.pl // dilorenzopl at gmail.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jeshyb at dtu.dk  Mon Feb  6 09:29:16 2017
From: jeshyb at dtu.dk (Jesper Hybel Pedersen)
Date: Mon, 6 Feb 2017 08:29:16 +0000
Subject: [R] What does ksmooth() do that  NadarayaWatsonkernel() does not?
Message-ID: <773BFF189410B249B52626B7486D3856DC500B@ait-pex02mbx05.win.dtu.dk>



What does the function ksmooth() to correct bias? Reading articles gives me the formula:

\frac{$B-t(B^n_{i=1}K_h(x-x_i)y_i}{$B-t(B^n_{j=1}K_h(x-x_j)}

For the Nadaray-Watson estimator. The same formula is stated in the documentation for the function:

NadarayaWatsonkernel(x, y, h, gridpoint)

>From the bbemkr-package (see ?NadarayaWatsonkernel). However this is not what the ksmooth()
function does as shown by the incompatibility of the followingly methods of calculation:


if (!require(bbemkr)) {install.packages("bbemkr")}

N = 100
x = rnorm(N)
y = 2 * x + rnorm(N)


# Manual implementation of Nadaray-Watson
y_fitted = rep(0,N)
w = y_fitted
lambda = 1
for (h in 1:N)
                           {
                                                      for (i in 1:N)
                                                                                  {
                                                                                                             w[i] = dnorm((x[i]-x[h]),sd=lambda)
                                                              y_fitted[h] = y_fitted[h] + y[i] * w[i]
                                                                                  }
                                                      y_fitted[h] = y_fitted[h]/sum(w)
                           }

nw.bbemkr = NadarayaWatsonkernel(x, y, lambda, x)
ks.stats = ksmooth(x,y,kernel="normal",bandwidth=lambda,x.points=x)

plot( x, y)
points( x , y_fitted , col="blue")  # From the manual implementation
points( nw.bbemkr$gridpoint+rnorm(N,sd=0.02), nw.bbemkr$mh,col="green") # From package bbemkr
points( ks.stats$x,ks.stats$y ,col="red")


The manual implementation is the same as the bbemkr package function NadarayaWatsonkernel()
But these are not the same as ksmooth() $B!D(B but still ksmooth() seems to result in better fit so I would like
To know what it does to achieve this better fit?


Best regards
Jesper Hybel Pedersen

	[[alternative HTML version deleted]]


From nabilaelarbi1912 at gmail.com  Mon Feb  6 02:50:30 2017
From: nabilaelarbi1912 at gmail.com (Nabila Arbi)
Date: Mon, 6 Feb 2017 02:50:30 +0100
Subject: [R] Beginner needs help with R
Message-ID: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>

Dear R-Help Team!

I have some trouble with R. It's probably nothing big, but I can't find a
solution.
My problem is the following:
I am trying to download some sequences from ncbi using the ape package.

seq1 <- paste("DQ", seq(060054, 060060), sep = "")

sequences <- read.GenBank(seq1,
seq.names = seq1,
species.names = TRUE,
gene.names = FALSE,
as.character = TRUE)

write.dna(sequences, "mysequences.fas", format = "fasta")

My problem is, that R doesn't take the whole sequence number as "060054"
but it puts it as DQ60054 (missing the zero in the beginning, which is
essential).

Could please tell me, how I can get R to accepting the zero in the
beginning of the accession number?

Thank you very much in advance and all the best!

Nabila

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Mon Feb  6 14:37:18 2017
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 6 Feb 2017 07:37:18 -0600
Subject: [R] Beginner needs help with R
In-Reply-To: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
References: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
Message-ID: <CAN5YmCFo4ZvnR4WV8+XR+5y5vfT0raUBcHbvROqpq5kZcrtk2Q@mail.gmail.com>

Try this:

seq1 <- paste("DQ0", seq(60054, 60060), sep = "")

Jean

On Sun, Feb 5, 2017 at 7:50 PM, Nabila Arbi <nabilaelarbi1912 at gmail.com>
wrote:

> Dear R-Help Team!
>
> I have some trouble with R. It's probably nothing big, but I can't find a
> solution.
> My problem is the following:
> I am trying to download some sequences from ncbi using the ape package.
>
> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>
> sequences <- read.GenBank(seq1,
> seq.names = seq1,
> species.names = TRUE,
> gene.names = FALSE,
> as.character = TRUE)
>
> write.dna(sequences, "mysequences.fas", format = "fasta")
>
> My problem is, that R doesn't take the whole sequence number as "060054"
> but it puts it as DQ60054 (missing the zero in the beginning, which is
> essential).
>
> Could please tell me, how I can get R to accepting the zero in the
> beginning of the accession number?
>
> Thank you very much in advance and all the best!
>
> Nabila
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From calandra at rgzm.de  Mon Feb  6 14:42:23 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Mon, 6 Feb 2017 14:42:23 +0100
Subject: [R] Beginner needs help with R
In-Reply-To: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
References: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
Message-ID: <2654a56f-36ea-eaab-362e-2bc41ccd8887@rgzm.de>

Hi Nabila,

This is because you ask to create a sequence with seq(), which does not 
make much sense with non numeric data. That's why R trims the 0.

One alternative would be:
seq2 <- paste("DQ0", seq(60054, 60060), sep = "")

Would that work for you?

HTH,
Ivan

--
Ivan Calandra, PhD
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
calandra at rgzm.de
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra
https://rgzm.academia.edu/IvanCalandra
https://publons.com/author/705639/

On 06/02/2017 02:50, Nabila Arbi wrote:
> Dear R-Help Team!
>
> I have some trouble with R. It's probably nothing big, but I can't find a
> solution.
> My problem is the following:
> I am trying to download some sequences from ncbi using the ape package.
>
> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>
> sequences <- read.GenBank(seq1,
> seq.names = seq1,
> species.names = TRUE,
> gene.names = FALSE,
> as.character = TRUE)
>
> write.dna(sequences, "mysequences.fas", format = "fasta")
>
> My problem is, that R doesn't take the whole sequence number as "060054"
> but it puts it as DQ60054 (missing the zero in the beginning, which is
> essential).
>
> Could please tell me, how I can get R to accepting the zero in the
> beginning of the accession number?
>
> Thank you very much in advance and all the best!
>
> Nabila
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Mon Feb  6 14:45:43 2017
From: jholtman at gmail.com (jim holtman)
Date: Mon, 6 Feb 2017 08:45:43 -0500
Subject: [R] Beginner needs help with R
In-Reply-To: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
References: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
Message-ID: <CAAxdm-4bq4pPu3j=8HJecQ_i2uUdreoq3WMm+AKzJADrxrepjQ@mail.gmail.com>

You need the leading zeros, and 'numerics' just give the number without
leading zeros.  You can use 'sprintf' for create a character string with
the leading zeros:

> # this is using 'numeric' and drops leading zeros
>
> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
> seq1
[1] "DQ60054" "DQ60055" "DQ60056" "DQ60057" "DQ60058" "DQ60059" "DQ60060"
>
> # use 'sprintf' to create leading zeros
> seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))
> seq2
[1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
"DQ060060"
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Feb 5, 2017 at 8:50 PM, Nabila Arbi <nabilaelarbi1912 at gmail.com>
wrote:

> Dear R-Help Team!
>
> I have some trouble with R. It's probably nothing big, but I can't find a
> solution.
> My problem is the following:
> I am trying to download some sequences from ncbi using the ape package.
>
> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>
> sequences <- read.GenBank(seq1,
> seq.names = seq1,
> species.names = TRUE,
> gene.names = FALSE,
> as.character = TRUE)
>
> write.dna(sequences, "mysequences.fas", format = "fasta")
>
> My problem is, that R doesn't take the whole sequence number as "060054"
> but it puts it as DQ60054 (missing the zero in the beginning, which is
> essential).
>
> Could please tell me, how I can get R to accepting the zero in the
> beginning of the accession number?
>
> Thank you very much in advance and all the best!
>
> Nabila
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Mon Feb  6 15:42:53 2017
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 6 Feb 2017 16:42:53 +0200
Subject: [R] Beginner needs help with R
In-Reply-To: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
References: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
Message-ID: <CAJ=0CtBJoUke5-tfkBD=tREBLCpKor=ctTdE6ro8dWgw7J17QQ@mail.gmail.com>

Two methods, among others:

seq1 <- paste("DQ", sprintf("%0*d", 6, seq(060054, 060060)), sep = "")

or

seq1 <- paste("DQ", formatC(seq(060054, 060060), dig = 5, flag = 0), sep =
"")

Hth,
Adrian


On Mon, Feb 6, 2017 at 3:50 AM, Nabila Arbi <nabilaelarbi1912 at gmail.com>
wrote:

> Dear R-Help Team!
>
> I have some trouble with R. It's probably nothing big, but I can't find a
> solution.
> My problem is the following:
> I am trying to download some sequences from ncbi using the ape package.
>
> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>
> sequences <- read.GenBank(seq1,
> seq.names = seq1,
> species.names = TRUE,
> gene.names = FALSE,
> as.character = TRUE)
>
> write.dna(sequences, "mysequences.fas", format = "fasta")
>
> My problem is, that R doesn't take the whole sequence number as "060054"
> but it puts it as DQ60054 (missing the zero in the beginning, which is
> essential).
>
> Could please tell me, how I can get R to accepting the zero in the
> beginning of the accession number?
>
> Thank you very much in advance and all the best!
>
> Nabila
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr. 90-92
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From Somayya.Gardee at ggc.scot.nhs.uk  Mon Feb  6 15:46:54 2017
From: Somayya.Gardee at ggc.scot.nhs.uk (Gardee, Somayya)
Date: Mon, 6 Feb 2017 14:46:54 +0000
Subject: [R] how to interpret t.test output
Message-ID: <57658195CF796048AA3FDA2C90A0F6418D03702E94@LAPPWGGCPMB04.ggc.scot.nhs.uk>

Hello for my project I am trying to write up my results from the paired t-test I conducted.
Please could someone help.

Thank you,
Somayya Gardee
****************************************************************************
NHSGG&C Disclaimer

The information contained within this e-mail and in any attachment is
confidential and may be privileged. If you are not the intended
recipient, please destroy this message, delete any copies held on your
systems and notify the sender immediately; you should not retain, copy
or use this e-mail for any purpose, nor disclose all or any part of its
content to any other person.

All messages passing through this gateway are checked for viruses, but
we strongly recommend that you check for viruses using your own virus
scanner as NHS Greater Glasgow & Clyde will not take responsibility for
any damage caused as a result of virus infection.

**************************************************************************

From marc_grt at yahoo.fr  Mon Feb  6 16:46:59 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 6 Feb 2017 16:46:59 +0100
Subject: [R] roxygen2 v6.0.0
Message-ID: <d17a92d1-e69a-bd22-2f27-4da1f4fefc84@yahoo.fr>

Hi,

I used roxygen2 v5.0.1 to document my package, and all was ok. I have 
just updated to roxygen2 v6.0.0 and my script is broken and I can't find 
why.

I have done a simple version of a package folder as a test with 3 files: 
chr.R, essai-package.R and DESCRIPTION.

Previously, I did:

package.skeleton("essai",code_files=c('chr.R',"essai-package.R"))
roxygenize("essai")
system(paste0("R CMD build '", getwd(), "/essai'"))
install.packages(file.path(getwd(), "essai_1.0.tar.gz"), repos = NULL, 
type="source")

And it worked well.

Now I get an error at the second line: roxygenize("essai")

 > roxygenize("essai")
First time using roxygen2. Upgrading automatically...
Updating roxygen version in 
/Users/marcgirondot/Documents/Espace_de_travail_R/Package_Essai/essai/DESCRIPTION
Warning: The existing 'NAMESPACE' file was not generated by roxygen2, 
and will not be overwritten.
Warning: The existing 'chr.Rd' file was not generated by roxygen2, and 
will not be overwritten.
Warning: The existing 'essai-package.Rd' file was not generated by 
roxygen2, and will not be overwritten.

And of course it fails after.

Are you aware of this situation ? And do you have a solution ?

Thanks a lot

Marc


A file DESCRIPTION:

Package: essai
Type: Package
Title: Package Used For Try
Version: 1.0
Date: 2017-02-06
Author: Marc Girondot <marc.girondot at u-psud.fr>
Maintainer: Marc Girondot <marc.girondot at u-psud.fr>
Description: Trying package.
Depends: R (>= 2.14.2)
License: GPL-2
LazyData: yes
LazyLoad: yes
Encoding: UTF-8
RoxygenNote: 6.0.0

A file essai-package.R (essai=try in French):

#' Trying package
#'
#' \tabular{ll}{
#'  Package: \tab essai\cr
#'  Type: \tab Package\cr
#'  Version: \tab 1.0 - build 1\cr
#'  Date: \tab 2017-02-06\cr
#'  License: \tab GPL (>= 2)\cr
#'  LazyLoad: \tab yes\cr
#'  }
#' @title The package essai
#' @author Marc Girondot \email{marc.girondot@@u-psud.fr}
#' @docType package
#' @name essai-package

NULL

A file chr.R:

#' chr returns the characters defined by the codes
#' @title Return the characters defined by the codes
#' @author Based on this blog: 
http://datadebrief.blogspot.com/2011/03/ascii-code-table-in-r.html
#' @return A string with characters defined by the codes
#' @param n The vector with codes
#' @description Return a string with characters defined by the codes. 
J'essaye avec un code utf-8: ?.
#' @examples
#' chr(65:75)
#' chr(unlist(tapply(144:175, 144:175, function(x) {c(208, x)})))
#' @encoding UTF-8
#' @export


chr <- function(n) {
     rawToChar(as.raw(n))
     }


From xie at yihui.name  Mon Feb  6 17:14:47 2017
From: xie at yihui.name (Yihui Xie)
Date: Mon, 6 Feb 2017 10:14:47 -0600
Subject: [R] roxygen2 v6.0.0
In-Reply-To: <d17a92d1-e69a-bd22-2f27-4da1f4fefc84@yahoo.fr>
References: <d17a92d1-e69a-bd22-2f27-4da1f4fefc84@yahoo.fr>
Message-ID: <CANROs4e4Giwh6Pj1=D7z-pUjEFsfi1XAMNH3XRK+Kuu3woYUOw@mail.gmail.com>

If your package source is version controlled (meaning you are free to
regret any time), I'd recommend you to delete the three files
NAMESPACE, chr.Rd, and essai-package.Rd. Then try to roxygenize again.
Basically the warnings you saw indicates that roxygen2 failed to find
the line

% Generated by roxygen2: do not edit by hand

in your NAMESPACE and .Rd files, so it thinks these files were
probably not previously generated by roxygen2. I think the cause is
package.skeleton(), which generated the Rd files. Seriously, friends
don't let friends use package.skeleton()... (it is 2017 now)

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Mon, Feb 6, 2017 at 9:46 AM, Marc Girondot via R-help
<r-help at r-project.org> wrote:
> Hi,
>
> I used roxygen2 v5.0.1 to document my package, and all was ok. I have just
> updated to roxygen2 v6.0.0 and my script is broken and I can't find why.
>
> I have done a simple version of a package folder as a test with 3 files:
> chr.R, essai-package.R and DESCRIPTION.
>
> Previously, I did:
>
> package.skeleton("essai",code_files=c('chr.R',"essai-package.R"))
> roxygenize("essai")
> system(paste0("R CMD build '", getwd(), "/essai'"))
> install.packages(file.path(getwd(), "essai_1.0.tar.gz"), repos = NULL,
> type="source")
>
> And it worked well.
>
> Now I get an error at the second line: roxygenize("essai")
>
>> roxygenize("essai")
> First time using roxygen2. Upgrading automatically...
> Updating roxygen version in
> /Users/marcgirondot/Documents/Espace_de_travail_R/Package_Essai/essai/DESCRIPTION
> Warning: The existing 'NAMESPACE' file was not generated by roxygen2, and
> will not be overwritten.
> Warning: The existing 'chr.Rd' file was not generated by roxygen2, and will
> not be overwritten.
> Warning: The existing 'essai-package.Rd' file was not generated by roxygen2,
> and will not be overwritten.
>
> And of course it fails after.
>
> Are you aware of this situation ? And do you have a solution ?
>
> Thanks a lot
>
> Marc
>
>
> A file DESCRIPTION:
>
> Package: essai
> Type: Package
> Title: Package Used For Try
> Version: 1.0
> Date: 2017-02-06
> Author: Marc Girondot <marc.girondot at u-psud.fr>
> Maintainer: Marc Girondot <marc.girondot at u-psud.fr>
> Description: Trying package.
> Depends: R (>= 2.14.2)
> License: GPL-2
> LazyData: yes
> LazyLoad: yes
> Encoding: UTF-8
> RoxygenNote: 6.0.0
>
> A file essai-package.R (essai=try in French):
>
> #' Trying package
> #'
> #' \tabular{ll}{
> #'  Package: \tab essai\cr
> #'  Type: \tab Package\cr
> #'  Version: \tab 1.0 - build 1\cr
> #'  Date: \tab 2017-02-06\cr
> #'  License: \tab GPL (>= 2)\cr
> #'  LazyLoad: \tab yes\cr
> #'  }
> #' @title The package essai
> #' @author Marc Girondot \email{marc.girondot@@u-psud.fr}
> #' @docType package
> #' @name essai-package
>
> NULL
>
> A file chr.R:
>
> #' chr returns the characters defined by the codes
> #' @title Return the characters defined by the codes
> #' @author Based on this blog:
> http://datadebrief.blogspot.com/2011/03/ascii-code-table-in-r.html
> #' @return A string with characters defined by the codes
> #' @param n The vector with codes
> #' @description Return a string with characters defined by the codes.
> J'essaye avec un code utf-8: ?.
> #' @examples
> #' chr(65:75)
> #' chr(unlist(tapply(144:175, 144:175, function(x) {c(208, x)})))
> #' @encoding UTF-8
> #' @export
>
>
> chr <- function(n) {
>     rawToChar(as.raw(n))
>     }
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Feb  6 18:08:06 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 06 Feb 2017 09:08:06 -0800
Subject: [R] Beginner needs help with R
In-Reply-To: <CAAxdm-4bq4pPu3j=8HJecQ_i2uUdreoq3WMm+AKzJADrxrepjQ@mail.gmail.com>
References: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
	<CAAxdm-4bq4pPu3j=8HJecQ_i2uUdreoq3WMm+AKzJADrxrepjQ@mail.gmail.com>
Message-ID: <E0148C73-F1DA-4CF5-BCA0-6D89C2127030@dcn.davis.ca.us>

I think it is important to point out that whenever R treats a number as a numeric (integer or double) it loses any base 10 concept of "leading zero" in that internal representation, so in this expression

seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))

the arguments to seq have leading zeros that are ignored by R and have nothing to do with getting the desired output. That is,  the same result can be obtained using

seq2 <- paste0("DQ", sprintf("%06d", seq(60054, 60060)))

or

seq2 <- paste0("DQ", sprintf("%06d", seq(0060054, 00060060)))

since only the zero inside the format string is key to success. (If it makes you more comfortable to put the zero there for readability that is your choice, but R ignores therm.)

Also note that the paste0 function is not needed when you use sprintf:

seq2 <- sprintf("DQ%06d", seq(60054, 60060))

or

myprefix <- "DQ"
seq2 <- sprintf("%s%06d", myprefix,seq(60054, 60060))

-- 
Sent from my phone. Please excuse my brevity.

On February 6, 2017 5:45:43 AM PST, jim holtman <jholtman at gmail.com> wrote:
>You need the leading zeros, and 'numerics' just give the number without
>leading zeros.  You can use 'sprintf' for create a character string
>with
>the leading zeros:
>
>> # this is using 'numeric' and drops leading zeros
>>
>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>> seq1
>[1] "DQ60054" "DQ60055" "DQ60056" "DQ60057" "DQ60058" "DQ60059"
>"DQ60060"
>>
>> # use 'sprintf' to create leading zeros
>> seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))
>> seq2
>[1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
>"DQ060060"
>>
>
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>On Sun, Feb 5, 2017 at 8:50 PM, Nabila Arbi
><nabilaelarbi1912 at gmail.com>
>wrote:
>
>> Dear R-Help Team!
>>
>> I have some trouble with R. It's probably nothing big, but I can't
>find a
>> solution.
>> My problem is the following:
>> I am trying to download some sequences from ncbi using the ape
>package.
>>
>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>
>> sequences <- read.GenBank(seq1,
>> seq.names = seq1,
>> species.names = TRUE,
>> gene.names = FALSE,
>> as.character = TRUE)
>>
>> write.dna(sequences, "mysequences.fas", format = "fasta")
>>
>> My problem is, that R doesn't take the whole sequence number as
>"060054"
>> but it puts it as DQ60054 (missing the zero in the beginning, which
>is
>> essential).
>>
>> Could please tell me, how I can get R to accepting the zero in the
>> beginning of the accession number?
>>
>> Thank you very much in advance and all the best!
>>
>> Nabila
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Feb  6 18:20:27 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 06 Feb 2017 09:20:27 -0800
Subject: [R] how to interpret t.test output
In-Reply-To: <57658195CF796048AA3FDA2C90A0F6418D03702E94@LAPPWGGCPMB04.ggc.scot.nhs.uk>
References: <57658195CF796048AA3FDA2C90A0F6418D03702E94@LAPPWGGCPMB04.ggc.scot.nhs.uk>
Message-ID: <24BD1489-C7A4-4A22-9327-19FAEFFA216F@dcn.davis.ca.us>

Perhaps someone could, but:

1) It is normal on public Internet mailing lists and forums to simply ask the actual question and let people respond if they know the answer, rather than asking for permission to ask.

2) You should read the Posting Guide for this mailing list... your question does not appear to fit the subject area for this mailing list, as it is about interpreting statistical computation results (statistics) rather than using R to obtain them (R). Perhaps try stats.stackexchange.com?
-- 
Sent from my phone. Please excuse my brevity.

On February 6, 2017 6:46:54 AM PST, "Gardee, Somayya" <Somayya.Gardee at ggc.scot.nhs.uk> wrote:
>Hello for my project I am trying to write up my results from the paired
>t-test I conducted.
>Please could someone help.
>
>Thank you,
>Somayya Gardee
>****************************************************************************
>NHSGG&C Disclaimer
>
>The information contained within this e-mail and in any attachment is
>confidential and may be privileged. If you are not the intended
>recipient, please destroy this message, delete any copies held on your
>systems and notify the sender immediately; you should not retain, copy
>or use this e-mail for any purpose, nor disclose all or any part of its
>content to any other person.
>
>All messages passing through this gateway are checked for viruses, but
>we strongly recommend that you check for viruses using your own virus
>scanner as NHS Greater Glasgow & Clyde will not take responsibility for
>any damage caused as a result of virus infection.
>
>**************************************************************************
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Mon Feb  6 18:38:23 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 6 Feb 2017 18:38:23 +0100
Subject: [R] roxygen2 v6.0.0
In-Reply-To: <CANROs4e4Giwh6Pj1=D7z-pUjEFsfi1XAMNH3XRK+Kuu3woYUOw@mail.gmail.com>
References: <d17a92d1-e69a-bd22-2f27-4da1f4fefc84@yahoo.fr>
	<CANROs4e4Giwh6Pj1=D7z-pUjEFsfi1XAMNH3XRK+Kuu3woYUOw@mail.gmail.com>
Message-ID: <568e6d3c-b900-0c2c-a15e-d39858e48ffb@yahoo.fr>

Le 06/02/2017 ? 17:14, Yihui Xie a ?crit :
> If your package source is version controlled (meaning you are free to
> regret any time), I'd recommend you to delete the three files
> NAMESPACE, chr.Rd, and essai-package.Rd. Then try to roxygenize again.
> Basically the warnings you saw indicates that roxygen2 failed to find
> the line
>
> % Generated by roxygen2: do not edit by hand
>
> in your NAMESPACE and .Rd files, so it thinks these files were
> probably not previously generated by roxygen2. I think the cause is
> package.skeleton(), which generated the Rd files. Seriously, friends
> don't let friends use package.skeleton()... (it is 2017 now)
Thanks ! It works perfectly after removing the /man/ folder and the 
NAMESPACE file.
I didn't know that package.skeleton() was out-of-age !
That's true that it is easy to generate the skeleton manually.

Marc
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
>
>
> On Mon, Feb 6, 2017 at 9:46 AM, Marc Girondot via R-help
> <r-help at r-project.org> wrote:
>> Hi,
>>
>> I used roxygen2 v5.0.1 to document my package, and all was ok. I have just
>> updated to roxygen2 v6.0.0 and my script is broken and I can't find why.
>>
>> I have done a simple version of a package folder as a test with 3 files:
>> chr.R, essai-package.R and DESCRIPTION.
>>
>> Previously, I did:
>>
>> package.skeleton("essai",code_files=c('chr.R',"essai-package.R"))
>> roxygenize("essai")
>> system(paste0("R CMD build '", getwd(), "/essai'"))
>> install.packages(file.path(getwd(), "essai_1.0.tar.gz"), repos = NULL,
>> type="source")
>>
>> And it worked well.
>>
>> Now I get an error at the second line: roxygenize("essai")
>>
>>> roxygenize("essai")
>> First time using roxygen2. Upgrading automatically...
>> Updating roxygen version in
>> /Users/marcgirondot/Documents/Espace_de_travail_R/Package_Essai/essai/DESCRIPTION
>> Warning: The existing 'NAMESPACE' file was not generated by roxygen2, and
>> will not be overwritten.
>> Warning: The existing 'chr.Rd' file was not generated by roxygen2, and will
>> not be overwritten.
>> Warning: The existing 'essai-package.Rd' file was not generated by roxygen2,
>> and will not be overwritten.
>>
>> And of course it fails after.
>>
>> Are you aware of this situation ? And do you have a solution ?
>>
>> Thanks a lot
>>
>> Marc
>>
>>
>> A file DESCRIPTION:
>>
>> Package: essai
>> Type: Package
>> Title: Package Used For Try
>> Version: 1.0
>> Date: 2017-02-06
>> Author: Marc Girondot <marc.girondot at u-psud.fr>
>> Maintainer: Marc Girondot <marc.girondot at u-psud.fr>
>> Description: Trying package.
>> Depends: R (>= 2.14.2)
>> License: GPL-2
>> LazyData: yes
>> LazyLoad: yes
>> Encoding: UTF-8
>> RoxygenNote: 6.0.0
>>
>> A file essai-package.R (essai=try in French):
>>
>> #' Trying package
>> #'
>> #' \tabular{ll}{
>> #'  Package: \tab essai\cr
>> #'  Type: \tab Package\cr
>> #'  Version: \tab 1.0 - build 1\cr
>> #'  Date: \tab 2017-02-06\cr
>> #'  License: \tab GPL (>= 2)\cr
>> #'  LazyLoad: \tab yes\cr
>> #'  }
>> #' @title The package essai
>> #' @author Marc Girondot \email{marc.girondot@@u-psud.fr}
>> #' @docType package
>> #' @name essai-package
>>
>> NULL
>>
>> A file chr.R:
>>
>> #' chr returns the characters defined by the codes
>> #' @title Return the characters defined by the codes
>> #' @author Based on this blog:
>> http://datadebrief.blogspot.com/2011/03/ascii-code-table-in-r.html
>> #' @return A string with characters defined by the codes
>> #' @param n The vector with codes
>> #' @description Return a string with characters defined by the codes.
>> J'essaye avec un code utf-8: ?.
>> #' @examples
>> #' chr(65:75)
>> #' chr(unlist(tapply(144:175, 144:175, function(x) {c(208, x)})))
>> #' @encoding UTF-8
>> #' @export
>>
>>
>> chr <- function(n) {
>>      rawToChar(as.raw(n))
>>      }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Tilmann_Faul at t-online.de  Mon Feb  6 19:36:53 2017
From: Tilmann_Faul at t-online.de (Tilmann Faul)
Date: Mon, 6 Feb 2017 19:36:53 +0100
Subject: [R] regex [:digit:] gives diffrent result
Message-ID: <f908b96c-e844-5211-24f4-0571d10b6cec@t-online.de>

Using R is a grate advantage, thanks for your work.

Using regex under R 3.1.1, Debian 8.6 jessy works fine.

str_detect("16-03-08", "[:digit:]{2}")
[1] TRUE
str_detect("16-03-08", "[0-9]{2}")
[1] TRUE

runing the same code under R 3.3.2 backport, Debian 8.6 jessy gives a
different result. This is also a different computer.

str_detect("16-03-08", "[:digit:]{2}")
[1] FALSE
str_detect("16-03-08", "[0-9]{2}")
[1] TRUE

Is this intended?
My workaround is using [0-9] instead of [:digit:].

Thanks
Tilmann


From wdunlap at tibco.com  Mon Feb  6 19:51:23 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 6 Feb 2017 10:51:23 -0800
Subject: [R] regex [:digit:] gives diffrent result
In-Reply-To: <f908b96c-e844-5211-24f4-0571d10b6cec@t-online.de>
References: <f908b96c-e844-5211-24f4-0571d10b6cec@t-online.de>
Message-ID: <CAF8bMcZ+vQZQ=t-Np3nS_rp+e313qCp+ZkWR+E5+xvQHgcjwZg@mail.gmail.com>

Shouldn't your "[:digit:]" be "[[:digit:]]"?
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Feb 6, 2017 at 10:36 AM, Tilmann Faul <Tilmann_Faul at t-online.de> wrote:
> Using R is a grate advantage, thanks for your work.
>
> Using regex under R 3.1.1, Debian 8.6 jessy works fine.
>
> str_detect("16-03-08", "[:digit:]{2}")
> [1] TRUE
> str_detect("16-03-08", "[0-9]{2}")
> [1] TRUE
>
> runing the same code under R 3.3.2 backport, Debian 8.6 jessy gives a
> different result. This is also a different computer.
>
> str_detect("16-03-08", "[:digit:]{2}")
> [1] FALSE
> str_detect("16-03-08", "[0-9]{2}")
> [1] TRUE
>
> Is this intended?
> My workaround is using [0-9] instead of [:digit:].
>
> Thanks
> Tilmann
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfhenson1 at gmail.com  Mon Feb  6 20:07:52 2017
From: jfhenson1 at gmail.com (James Henson)
Date: Mon, 6 Feb 2017 13:07:52 -0600
Subject: [R] Marg.fct function
In-Reply-To: <5B13CE3B-8F28-4A35-9053-1717E25C19C7@dcn.davis.ca.us>
References: <CABPq8JPYNbH-=YPevKJ-gLK3fnKEd-L3LRzc=6N6JrFMRZZSwQ@mail.gmail.com>
	<5B13CE3B-8F28-4A35-9053-1717E25C19C7@dcn.davis.ca.us>
Message-ID: <CABPq8JNu7WWkVny2=2pF2UZdMHcHHeJyDkGfX=UQa6RQnE6KPQ@mail.gmail.com>

Greetings Peter and Jeff,

Thanks for this information.  Will try these type of analyses in SAS.
Sure they are doable in R, but developing a procedure is difficult.
Alan Agresti gives a cookbook SAS method in An Introduction to
Categorical Analysis.

Thanks,
James

On Sun, Feb 5, 2017 at 3:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> It is not part of "R". You can dig through all of the packages that the author mentions,  or send an email to the author.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 5, 2017 11:44:40 AM PST, James Henson <jfhenson1 at gmail.com> wrote:
>>Greetings R Community,
>>
>>An attempt to reproduce the results from code in the source below
>>fails.  R cannot find the function ?Marg.fct?. An Internet search for
>>the ?Marg.fct? function was not fruitful.  I appreciate your help.
>>Best regards, James F. Henson.
>>
>>R (and S-PLUS) Manual to Accompany Agresti?s Categorical Data Analysis
>>(2002) 2nd edition Laura A. Thompson, 2009?
>>
>>http://www.stat.ufl.edu/~aa/cda/Thompson_manual.pdf  page 181
>>
>>The code is:
>>
>># Code from Manual to Accompany Agresti?s Categorical Data Analysis
>>(2002) 2nd edition Laura A. Thompson, 2009
>>
>>y <- c(144, 33, 84, 126, 2, 4, 14, 29, 0, 2, 6, 25, 0, 0, 1, 5)
>>
>>ZF <- Z <- matrix(1,16,1)
>>
>>#
>>
>>M1 <- Marg.fct(1,rep(4,2)) # used to get m1+, etc
>>
>>Error: could not find function "Marg.fct"
>>
>>
>>
>>M2 <- Marg.fct(2,rep(4,2)) # used to get m+1, etc
>>
>>#
>>
>>C.matrix <- matrix(c(
>>
>>  1, 0, 0, 0, -1, 0, 0, 0, # y1+ = y+1
>>
>>  0, 1, 0, 0, 0, -1, 0, 0, # y2+ = y+2
>>
>>  0, 0, 1, 0, 0, 0, -1, 0), # y3+ = y+3
>>
>>  3,8,byrow=T)
>>
>>h.fct <- function(m) { # constraint function
>>
>> marg <- rbind(M1%*%m, M2%*%m) # y1+, y2+, y3+, y4+, y+1, y+2, y+3, y+4
>>
>>  C.matrix%*%marg # y1+ = y+1, y2+ = y+2, etc
>>
>>}
>>
>>#
>>
>>a <- mph.fit(y=y,Z=Z,ZF=ZF,h.fct=h.fct)
>>
>>mph.summary(a)
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Feb  6 20:30:18 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Feb 2017 11:30:18 -0800
Subject: [R] Beginner needs help with R
In-Reply-To: <E0148C73-F1DA-4CF5-BCA0-6D89C2127030@dcn.davis.ca.us>
References: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
	<CAAxdm-4bq4pPu3j=8HJecQ_i2uUdreoq3WMm+AKzJADrxrepjQ@mail.gmail.com>
	<E0148C73-F1DA-4CF5-BCA0-6D89C2127030@dcn.davis.ca.us>
Message-ID: <BE6B87F7-548D-41E4-83B8-D6E5BF0BC0C6@comcast.net>


> On Feb 6, 2017, at 9:08 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I think it is important to point out that whenever R treats a number as a numeric (integer or double) it loses any base 10 concept of "leading zero" in that internal representation, so in this expression
> 
> seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))

You can do it just with sprintf (and presumably with formatC as well) if you add a leading "DQ" to the format string.:

> sprintf( "DQ%06s", seq(060054, 060060))
[1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059" "DQ060060"

-- 
David.



> the arguments to seq have leading zeros that are ignored by R and have nothing to do with getting the desired output. That is,  the same result can be obtained using
> 
> seq2 <- paste0("DQ", sprintf("%06d", seq(60054, 60060)))
> 
> or
> 
> seq2 <- paste0("DQ", sprintf("%06d", seq(0060054, 00060060)))
> 
> since only the zero inside the format string is key to success. (If it makes you more comfortable to put the zero there for readability that is your choice, but R ignores therm.)
> 
> Also note that the paste0 function is not needed when you use sprintf:
> 
> seq2 <- sprintf("DQ%06d", seq(60054, 60060))
> 
> or
> 
> myprefix <- "DQ"
> seq2 <- sprintf("%s%06d", myprefix,seq(60054, 60060))
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 6, 2017 5:45:43 AM PST, jim holtman <jholtman at gmail.com> wrote:
>> You need the leading zeros, and 'numerics' just give the number without
>> leading zeros.  You can use 'sprintf' for create a character string
>> with
>> the leading zeros:
>> 
>>> # this is using 'numeric' and drops leading zeros
>>> 
>>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>> seq1
>> [1] "DQ60054" "DQ60055" "DQ60056" "DQ60057" "DQ60058" "DQ60059"
>> "DQ60060"
>>> 
>>> # use 'sprintf' to create leading zeros
>>> seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))
>>> seq2
>> [1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
>> "DQ060060"
>>> 
>> 
>> 
>> Jim Holtman
>> Data Munger Guru
>> 
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>> On Sun, Feb 5, 2017 at 8:50 PM, Nabila Arbi
>> <nabilaelarbi1912 at gmail.com>
>> wrote:
>> 
>>> Dear R-Help Team!
>>> 
>>> I have some trouble with R. It's probably nothing big, but I can't
>> find a
>>> solution.
>>> My problem is the following:
>>> I am trying to download some sequences from ncbi using the ape
>> package.
>>> 
>>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>> 
>>> sequences <- read.GenBank(seq1,
>>> seq.names = seq1,
>>> species.names = TRUE,
>>> gene.names = FALSE,
>>> as.character = TRUE)
>>> 
>>> write.dna(sequences, "mysequences.fas", format = "fasta")
>>> 
>>> My problem is, that R doesn't take the whole sequence number as
>> "060054"
>>> but it puts it as DQ60054 (missing the zero in the beginning, which
>> is
>>> essential).
>>> 
>>> Could please tell me, how I can get R to accepting the zero in the
>>> beginning of the accession number?
>>> 
>>> Thank you very much in advance and all the best!
>>> 
>>> Nabila
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Mon Feb  6 22:43:05 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 7 Feb 2017 08:43:05 +1100
Subject: [R] how to interpret t.test output
In-Reply-To: <57658195CF796048AA3FDA2C90A0F6418D03702E94@LAPPWGGCPMB04.ggc.scot.nhs.uk>
References: <57658195CF796048AA3FDA2C90A0F6418D03702E94@LAPPWGGCPMB04.ggc.scot.nhs.uk>
Message-ID: <CA+8X3fWO_admoNNPJgJmr9R-G_QneCAHaKV_76piLLWTmZeTTQ@mail.gmail.com>

Hi Somayya,
When you perform a t-test on two sets of numeric values, the answer
you get tells you how likely it is that those two sets of numbers came
from the same distribution. What most people are interested in is
whether the means of those two distributions are different. Let's see,
you seem to be with NHS in Scotland, so you are probably interested in
something like whether the mean reported severity of hangover is the
same for whisky as vodka in a sample of drinkers, controlling for
number of standard drinks of course. About all you can say from a
t-test is that those drinking one drink felt worse the next day _if_
the p value is small enough. Beware of doing lots of t-tests and
looking for <0.05.

Jim


On Tue, Feb 7, 2017 at 1:46 AM, Gardee, Somayya
<Somayya.Gardee at ggc.scot.nhs.uk> wrote:
> Hello for my project I am trying to write up my results from the paired t-test I conducted.
> Please could someone help.
>
> Thank you,
> Somayya Gardee
> ****************************************************************************
> NHSGG&C Disclaimer
>
> The information contained within this e-mail and in any attachment is
> confidential and may be privileged. If you are not the intended
> recipient, please destroy this message, delete any copies held on your
> systems and notify the sender immediately; you should not retain, copy
> or use this e-mail for any purpose, nor disclose all or any part of its
> content to any other person.
>
> All messages passing through this gateway are checked for viruses, but
> we strongly recommend that you check for viruses using your own virus
> scanner as NHS Greater Glasgow & Clyde will not take responsibility for
> any damage caused as a result of virus infection.
>
> **************************************************************************
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From davidsmi at microsoft.com  Mon Feb  6 23:20:26 2017
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 6 Feb 2017 22:20:26 +0000
Subject: [R] Revolutions blog: January 2017 roundup
Message-ID: <CY1PR0301MB21058F369A5A2BAFBE6B91E7C8400@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of January:

The Data Science Virtual Machine on Azure has been updated with the latest Microsoft R Server, and adds RStudio and
JuliaPro: http://blog.revolutionanalytics.com/2017/01/dsvm-updated-now-includes-rstudio.html

A crowdsourced list of local R user groups and community events, maintained by Colin Gillespie:
http://blog.revolutionanalytics.com/2017/01/list-of-r-conferences-and-user-groups.html

Resources for searching R packages, now that CRAN has more than 10,000 of them:
http://blog.revolutionanalytics.com/2017/01/cran-10000.html

An analysis of 2 decades of Kung Fu movies (with R code) by Jim Vallandingham:
http://blog.revolutionanalytics.com/2017/01/kung-fu-r.html

New Zealand's Heartland Bank replaced SAS with Microsoft R Server:
http://blog.revolutionanalytics.com/2017/01/nz-bank-replaces-sas-with-r.html

A tutorial on creating a predictive model for the NYC Taxi dataset using the MicrosoftML package in Microsoft R Server:
http://blog.revolutionanalytics.com/2017/01/microsoftml-taxi-trips.html

A list of upcoming R conference and meetings: http://blog.revolutionanalytics.com/2017/01/upcoming-r-conferences.html

The new book "Text Mining with R" by Julia Silge and David Robinson, also available free online:
http://blog.revolutionanalytics.com/2017/01/free-guide-to-text-mining-with-r.html

A comprehensive guide to using Git and Github for R projects with RStudio, by Jenny Bryan:
http://blog.revolutionanalytics.com/2017/01/git-gud-with-git-and-r.html

Media reactions to the release of Microsoft R Server 9:
http://blog.revolutionanalytics.com/2017/01/microsoft-r-server-in-the-news.html

A survey by Forwards, the R Foundation taskforce, quantifies diversity in the R community:
http://blog.revolutionanalytics.com/2017/01/diversity-in-the-r-community.html

A new R package distributes data (and some R code) behind many data journalism features at fivethirtyeight.com:
http://blog.revolutionanalytics.com/2017/01/the-fivethirtyeight-r-package.html

A collection of Microsoft R Server tips from the customer support team:
http://blog.revolutionanalytics.com/2017/01/tiger-team-tips.html

R is being used to predict student performance in Australia and India:
http://blog.revolutionanalytics.com/2017/01/education-analytics.html

A case study in data visualization design: NOAA's flood prediction chart:
http://blog.revolutionanalytics.com/2017/01/the-anatomy-of-a-useful-chart.html

StackOverflow has released a dataset of question-and-answer data, which several people have analyzed using R:
http://blog.revolutionanalytics.com/2017/01/stackoverflow-insights.html

Several arguments for why R is the best data science language to learn today:
http://blog.revolutionanalytics.com/2017/01/three-reasons-to-learn-r-today.html

A tutorial on analyzing emotions in video, using R and the Microsoft Emotion API:
http://blog.revolutionanalytics.com/2017/01/analyzing-emotions-in-video-with-r.html

An introduction to the new remote R workspaces feature of Microsoft R Server 9:
http://blog.revolutionanalytics.com/2017/01/remote-and-local-r-workspaces.html

A roundup of the major news about R in 2016:
http://blog.revolutionanalytics.com/2017/01/the-biggest-r-stories-from-2016.html

General interest stories (not related to R) in the past month included: rearranged continents
(http://blog.revolutionanalytics.com/2017/01/because-its-friday-tangram-earth.html), a collapsing bridge
(http://blog.revolutionanalytics.com/2017/01/because-its-friday-infrastructure-collapses.html), satire for coders
(http://blog.revolutionanalytics.com/2017/01/because-its-friday-code-burn.html), and crafty photographer tricks
(http://blog.revolutionanalytics.com/2017/01/because-its-friday-photography-tricks.html).

If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From george.brida at gmail.com  Mon Feb  6 23:21:49 2017
From: george.brida at gmail.com (george brida)
Date: Mon, 6 Feb 2017 23:21:49 +0100
Subject: [R] diff doesnot work
Message-ID: <CAGsroM1s6FEDUzFD0MSaYL297hgXJ=u4Mdx1XJz7h_51CUjyUQ@mail.gmail.com>

Dear R users,

I have a txt file entitled coc composed by one column of numeric values
without header and having 50 rows. This file is under the following path:

C:\\Users\\intel\\Documents\\TR

I have written the following lines:

xcx=read.table("C:\\Users\\intel\\Documents\\TR\\coc.txt",header=F)
xc=log(xcx)

I have obtained the series xc but when I wrote
x=diff(xc)

I obtained the following message:

data frame with 0 columns and 50 rows

I don't know where is the problem. Can you help me please

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Feb  6 23:28:25 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 6 Feb 2017 14:28:25 -0800
Subject: [R] diff doesnot work
In-Reply-To: <CAGsroM1s6FEDUzFD0MSaYL297hgXJ=u4Mdx1XJz7h_51CUjyUQ@mail.gmail.com>
References: <CAGsroM1s6FEDUzFD0MSaYL297hgXJ=u4Mdx1XJz7h_51CUjyUQ@mail.gmail.com>
Message-ID: <CAF8bMcYUN0HfFnMDB97arQAns-R3cJAvYC90UDQvc50vb0Kc7w@mail.gmail.com>

diff() does not work on data.frames so you need to give it a column
from the data.frame, as a vector.
  diff(data.frame(P=c(1,2,3,5,7,11,13,17))$P)
  [1] 1 1 2 2 4 2 4

You get different errors for multi- and single-column data.frames
  > diff(data.frame(P=c(1,2,3,5,7,11,13,17), F=c(1,1,2,3,5,8,13,21)))
  Error in r[i1] - r[-length(r):-(length(r) - lag + 1L)] :
    non-numeric argument to binary operator
  > diff(data.frame(P=c(1,2,3,5,7,11,13,17)))
  data frame with 0 columns and 8 rows
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Feb 6, 2017 at 2:21 PM, george brida <george.brida at gmail.com> wrote:
> Dear R users,
>
> I have a txt file entitled coc composed by one column of numeric values
> without header and having 50 rows. This file is under the following path:
>
> C:\\Users\\intel\\Documents\\TR
>
> I have written the following lines:
>
> xcx=read.table("C:\\Users\\intel\\Documents\\TR\\coc.txt",header=F)
> xc=log(xcx)
>
> I have obtained the series xc but when I wrote
> x=diff(xc)
>
> I obtained the following message:
>
> data frame with 0 columns and 50 rows
>
> I don't know where is the problem. Can you help me please
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb  7 01:11:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 6 Feb 2017 16:11:08 -0800
Subject: [R] roxygen2 v6.0.0
In-Reply-To: <568e6d3c-b900-0c2c-a15e-d39858e48ffb@yahoo.fr>
References: <d17a92d1-e69a-bd22-2f27-4da1f4fefc84@yahoo.fr>
	<CANROs4e4Giwh6Pj1=D7z-pUjEFsfi1XAMNH3XRK+Kuu3woYUOw@mail.gmail.com>
	<568e6d3c-b900-0c2c-a15e-d39858e48ffb@yahoo.fr>
Message-ID: <CAGxFJbRshtpAW6YWtwe9+CiFUKv_m3D1wihAc_8UObjMytSj+w@mail.gmail.com>

Marc:

You miss Yihui's point I think: roxygen2 will generate the (Namespace
and other) files for you. See its documentation for how (the
directives to put in your comments).

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 6, 2017 at 9:38 AM, Marc Girondot via R-help
<r-help at r-project.org> wrote:
> Le 06/02/2017 ? 17:14, Yihui Xie a ?crit :
>>
>> If your package source is version controlled (meaning you are free to
>> regret any time), I'd recommend you to delete the three files
>> NAMESPACE, chr.Rd, and essai-package.Rd. Then try to roxygenize again.
>> Basically the warnings you saw indicates that roxygen2 failed to find
>> the line
>>
>> % Generated by roxygen2: do not edit by hand
>>
>> in your NAMESPACE and .Rd files, so it thinks these files were
>> probably not previously generated by roxygen2. I think the cause is
>> package.skeleton(), which generated the Rd files. Seriously, friends
>> don't let friends use package.skeleton()... (it is 2017 now)
>
> Thanks ! It works perfectly after removing the /man/ folder and the
> NAMESPACE file.
> I didn't know that package.skeleton() was out-of-age !
> That's true that it is easy to generate the skeleton manually.
>
> Marc
>>
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>>
>>
>> On Mon, Feb 6, 2017 at 9:46 AM, Marc Girondot via R-help
>> <r-help at r-project.org> wrote:
>>>
>>> Hi,
>>>
>>> I used roxygen2 v5.0.1 to document my package, and all was ok. I have
>>> just
>>> updated to roxygen2 v6.0.0 and my script is broken and I can't find why.
>>>
>>> I have done a simple version of a package folder as a test with 3 files:
>>> chr.R, essai-package.R and DESCRIPTION.
>>>
>>> Previously, I did:
>>>
>>> package.skeleton("essai",code_files=c('chr.R',"essai-package.R"))
>>> roxygenize("essai")
>>> system(paste0("R CMD build '", getwd(), "/essai'"))
>>> install.packages(file.path(getwd(), "essai_1.0.tar.gz"), repos = NULL,
>>> type="source")
>>>
>>> And it worked well.
>>>
>>> Now I get an error at the second line: roxygenize("essai")
>>>
>>>> roxygenize("essai")
>>>
>>> First time using roxygen2. Upgrading automatically...
>>> Updating roxygen version in
>>>
>>> /Users/marcgirondot/Documents/Espace_de_travail_R/Package_Essai/essai/DESCRIPTION
>>> Warning: The existing 'NAMESPACE' file was not generated by roxygen2, and
>>> will not be overwritten.
>>> Warning: The existing 'chr.Rd' file was not generated by roxygen2, and
>>> will
>>> not be overwritten.
>>> Warning: The existing 'essai-package.Rd' file was not generated by
>>> roxygen2,
>>> and will not be overwritten.
>>>
>>> And of course it fails after.
>>>
>>> Are you aware of this situation ? And do you have a solution ?
>>>
>>> Thanks a lot
>>>
>>> Marc
>>>
>>>
>>> A file DESCRIPTION:
>>>
>>> Package: essai
>>> Type: Package
>>> Title: Package Used For Try
>>> Version: 1.0
>>> Date: 2017-02-06
>>> Author: Marc Girondot <marc.girondot at u-psud.fr>
>>> Maintainer: Marc Girondot <marc.girondot at u-psud.fr>
>>> Description: Trying package.
>>> Depends: R (>= 2.14.2)
>>> License: GPL-2
>>> LazyData: yes
>>> LazyLoad: yes
>>> Encoding: UTF-8
>>> RoxygenNote: 6.0.0
>>>
>>> A file essai-package.R (essai=try in French):
>>>
>>> #' Trying package
>>> #'
>>> #' \tabular{ll}{
>>> #'  Package: \tab essai\cr
>>> #'  Type: \tab Package\cr
>>> #'  Version: \tab 1.0 - build 1\cr
>>> #'  Date: \tab 2017-02-06\cr
>>> #'  License: \tab GPL (>= 2)\cr
>>> #'  LazyLoad: \tab yes\cr
>>> #'  }
>>> #' @title The package essai
>>> #' @author Marc Girondot \email{marc.girondot@@u-psud.fr}
>>> #' @docType package
>>> #' @name essai-package
>>>
>>> NULL
>>>
>>> A file chr.R:
>>>
>>> #' chr returns the characters defined by the codes
>>> #' @title Return the characters defined by the codes
>>> #' @author Based on this blog:
>>> http://datadebrief.blogspot.com/2011/03/ascii-code-table-in-r.html
>>> #' @return A string with characters defined by the codes
>>> #' @param n The vector with codes
>>> #' @description Return a string with characters defined by the codes.
>>> J'essaye avec un code utf-8: ?.
>>> #' @examples
>>> #' chr(65:75)
>>> #' chr(unlist(tapply(144:175, 144:175, function(x) {c(208, x)})))
>>> #' @encoding UTF-8
>>> #' @export
>>>
>>>
>>> chr <- function(n) {
>>>      rawToChar(as.raw(n))
>>>      }
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From John.Szumiloski at bms.com  Tue Feb  7 14:52:22 2017
From: John.Szumiloski at bms.com (Szumiloski, John)
Date: Tue, 7 Feb 2017 13:52:22 +0000
Subject: [R] ggplot: restricting legend with multiple geoms and nested groups
Message-ID: <7c03955fbebd4d0ba0f8c1c0d5f3d670@DM5PR2601MB0042.067d.mgd.msft.net>

Dear useRs:

I am having difficulty understanding how to make a legend in ggplot when I only want certain geoms to be indicated, in the presence of nested groups.  An example:

require(tidyverse)

  dat <- tibble(X=rep(seq(4),3),
                # fake data
                Y=c(-1.11, -0.46, 0.02, 0.81,
                    -0.51,  0.43, 0.73, 1.39,
                    -0.12,  0.62, 1.19, 1.99
                    ),
                G1=rep(seq(3), each=4) %>% factor)

  dat <- dat %>% mutate(lin=predict(lm(Y~X*G1, dat)),
                        quad=predict(lm(Y~poly(X,2)*G1, dat)))


Now dat contains one grouping variable, G1,  the X and Y data, and two columns of fitted values.  I want to consolidate the fitted value columns for plotting:


  # stack model fits: make wide -> long
  dat <- dat %>% gather(lin:quad, key="Model", value="fit", factor_key=TRUE)

Thus the model variable acts as another grouping variable.

I want to plot the two fits over the raw data, with the raw data grouped and annotated by G1, and the fits grouped by model*G1 but annotated by only model.  Thus each G1 will have separately annotated model fits plotted, but the same model annotations will be the same for all levels of G1.  Here is the code that I thought would do this.


  # init plot
  pl <- ggplot(data=dat, mapping=aes(x=X, y=Y, group=interaction(Model,G1))) +  theme_bw()

    # add raw data in background
  pl <- pl +
    geom_path(data=dat %>% filter(Model=='lin'),  # filter probably not necessary but prevents redundant overplotting
              mapping=aes(x=X, y=Y, group=G1, color=G1), linetype=2, show.legend=FALSE) +
    geom_point(data=dat %>% filter(Model=='lin'),
               mapping=aes(x=X, y=Y, group=G1, color=G1, shape=G1), show.legend=FALSE)

    # add fits
    pl <- pl + geom_path(aes(x=X, y=fit, group=interaction(Model,G1), color=Model) )
    pl


The plot looks as I want it.  But the legend is titled G1, and has the levels of G1 in the legend (as well as the desired Model levels).  But I thought turning off the show.legend argument in the raw data geoms would prevent this.  What I desire in the legend is only the two levels of Model (and titled as such).

Any assistance greatly appreciated.
John
John Szumiloski, Ph.D.
Principal Scientist, Statistician
Pharmaceutical Development / Analytical and Bioanalytical Operations<http://teams.bms.com/sites/ARD/>
NBR105-1-1411

Bristol-Myers Squibb
P.O. Box 191
1 Squibb Drive
New Brunswick, NJ
08903-0191

(732) 227-7167


________________________________
This message (including any attachments) may contain con...{{dropped:19}}


From bgunter.4567 at gmail.com  Tue Feb  7 17:02:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Feb 2017 08:02:18 -0800
Subject: [R] Beginner needs help with R
In-Reply-To: <CAAxdm-4bq4pPu3j=8HJecQ_i2uUdreoq3WMm+AKzJADrxrepjQ@mail.gmail.com>
References: <CAEv7pgVO6EM8hx2hCJmPF9Rezb4fiCMyHd8VCTYR2E87m9RJTg@mail.gmail.com>
	<CAAxdm-4bq4pPu3j=8HJecQ_i2uUdreoq3WMm+AKzJADrxrepjQ@mail.gmail.com>
Message-ID: <CAGxFJbRudVQh0AVrS=yBwpoVDhaREqaQGYNPodOt7YfK1=3qvw@mail.gmail.com>

No need for sprintf(). Simply:

> paste0("DQ0",seq.int(60054,60060))

[1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
[7] "DQ060060"


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 6, 2017 at 5:45 AM, jim holtman <jholtman at gmail.com> wrote:
> You need the leading zeros, and 'numerics' just give the number without
> leading zeros.  You can use 'sprintf' for create a character string with
> the leading zeros:
>
>> # this is using 'numeric' and drops leading zeros
>>
>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>> seq1
> [1] "DQ60054" "DQ60055" "DQ60056" "DQ60057" "DQ60058" "DQ60059" "DQ60060"
>>
>> # use 'sprintf' to create leading zeros
>> seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))
>> seq2
> [1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
> "DQ060060"
>>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sun, Feb 5, 2017 at 8:50 PM, Nabila Arbi <nabilaelarbi1912 at gmail.com>
> wrote:
>
>> Dear R-Help Team!
>>
>> I have some trouble with R. It's probably nothing big, but I can't find a
>> solution.
>> My problem is the following:
>> I am trying to download some sequences from ncbi using the ape package.
>>
>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>
>> sequences <- read.GenBank(seq1,
>> seq.names = seq1,
>> species.names = TRUE,
>> gene.names = FALSE,
>> as.character = TRUE)
>>
>> write.dna(sequences, "mysequences.fas", format = "fasta")
>>
>> My problem is, that R doesn't take the whole sequence number as "060054"
>> but it puts it as DQ60054 (missing the zero in the beginning, which is
>> essential).
>>
>> Could please tell me, how I can get R to accepting the zero in the
>> beginning of the accession number?
>>
>> Thank you very much in advance and all the best!
>>
>> Nabila
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ted.Harding at wlandres.net  Tue Feb  7 17:48:47 2017
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Tue, 07 Feb 2017 16:48:47 -0000 (GMT)
Subject: [R] Beginner needs help with R
In-Reply-To: <CAGxFJbRudVQh0AVrS=yBwpoVDhaREqaQGYNPodOt7YfK1=3qvw@mail.gmail.com>
Message-ID: <XFMail.20170207164847.Ted.Harding@wlandres.net>

Bert, your solution seems to presuppose that the programmer
knows beforehand that the leading digit in the number is "0"
(which in fact is clearly the case in Nabila Arbi's original
query). However, the sequence might arise from some process
outside of the progammer's contgrol, and may then either have
a leading 0 or not.In that case, I think Jim's solution is safer!
Best wishes,
Ted.


On 07-Feb-2017 16:02:18 Bert Gunter wrote:
> No need for sprintf(). Simply:
> 
>> paste0("DQ0",seq.int(60054,60060))
> 
> [1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
> [7] "DQ060060"
> 
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Feb 6, 2017 at 5:45 AM, jim holtman <jholtman at gmail.com> wrote:
>> You need the leading zeros, and 'numerics' just give the number without
>> leading zeros.  You can use 'sprintf' for create a character string with
>> the leading zeros:
>>
>>> # this is using 'numeric' and drops leading zeros
>>>
>>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>> seq1
>> [1] "DQ60054" "DQ60055" "DQ60056" "DQ60057" "DQ60058" "DQ60059" "DQ60060"
>>>
>>> # use 'sprintf' to create leading zeros
>>> seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))
>>> seq2
>> [1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
>> "DQ060060"
>>>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Sun, Feb 5, 2017 at 8:50 PM, Nabila Arbi <nabilaelarbi1912 at gmail.com>
>> wrote:
>>
>>> Dear R-Help Team!
>>>
>>> I have some trouble with R. It's probably nothing big, but I can't find a
>>> solution.
>>> My problem is the following:
>>> I am trying to download some sequences from ncbi using the ape package.
>>>
>>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>>
>>> sequences <- read.GenBank(seq1,
>>> seq.names = seq1,
>>> species.names = TRUE,
>>> gene.names = FALSE,
>>> as.character = TRUE)
>>>
>>> write.dna(sequences, "mysequences.fas", format = "fasta")
>>>
>>> My problem is, that R doesn't take the whole sequence number as "060054"
>>> but it puts it as DQ60054 (missing the zero in the beginning, which is
>>> essential).
>>>
>>> Could please tell me, how I can get R to accepting the zero in the
>>> beginning of the accession number?
>>>
>>> Thank you very much in advance and all the best!
>>>
>>> Nabila
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 07-Feb-2017  Time: 16:48:41
This message was sent by XFMail


From bgunter.4567 at gmail.com  Tue Feb  7 18:50:56 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Feb 2017 09:50:56 -0800
Subject: [R] Beginner needs help with R
In-Reply-To: <XFMail.20170207164847.Ted.Harding@wlandres.net>
References: <CAGxFJbRudVQh0AVrS=yBwpoVDhaREqaQGYNPodOt7YfK1=3qvw@mail.gmail.com>
	<XFMail.20170207164847.Ted.Harding@wlandres.net>
Message-ID: <CAGxFJbREkrA8soPgD4jFUP2qF9rXD1VmuEsRf_d4LqvcdmaaxA@mail.gmail.com>

Yes, I was replying to the OP's query **as stated.** I try to avoid
guessing what the OP really *meant*, although I grant that sometimes
this may be necessary.

But do note that the leading 0's in seq() *are* unnecessary:

> sprintf("%02d",1:3)
[1] "01" "02" "03"


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 7, 2017 at 8:48 AM, Ted Harding <Ted.Harding at wlandres.net> wrote:
> Bert, your solution seems to presuppose that the programmer
> knows beforehand that the leading digit in the number is "0"
> (which in fact is clearly the case in Nabila Arbi's original
> query). However, the sequence might arise from some process
> outside of the progammer's contgrol, and may then either have
> a leading 0 or not.In that case, I think Jim's solution is safer!
> Best wishes,
> Ted.
>
>
> On 07-Feb-2017 16:02:18 Bert Gunter wrote:
>> No need for sprintf(). Simply:
>>
>>> paste0("DQ0",seq.int(60054,60060))
>>
>> [1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
>> [7] "DQ060060"
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Feb 6, 2017 at 5:45 AM, jim holtman <jholtman at gmail.com> wrote:
>>> You need the leading zeros, and 'numerics' just give the number without
>>> leading zeros.  You can use 'sprintf' for create a character string with
>>> the leading zeros:
>>>
>>>> # this is using 'numeric' and drops leading zeros
>>>>
>>>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>>> seq1
>>> [1] "DQ60054" "DQ60055" "DQ60056" "DQ60057" "DQ60058" "DQ60059" "DQ60060"
>>>>
>>>> # use 'sprintf' to create leading zeros
>>>> seq2 <- paste0("DQ", sprintf("%06d", seq(060054, 060060)))
>>>> seq2
>>> [1] "DQ060054" "DQ060055" "DQ060056" "DQ060057" "DQ060058" "DQ060059"
>>> "DQ060060"
>>>>
>>>
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>> On Sun, Feb 5, 2017 at 8:50 PM, Nabila Arbi <nabilaelarbi1912 at gmail.com>
>>> wrote:
>>>
>>>> Dear R-Help Team!
>>>>
>>>> I have some trouble with R. It's probably nothing big, but I can't find a
>>>> solution.
>>>> My problem is the following:
>>>> I am trying to download some sequences from ncbi using the ape package.
>>>>
>>>> seq1 <- paste("DQ", seq(060054, 060060), sep = "")
>>>>
>>>> sequences <- read.GenBank(seq1,
>>>> seq.names = seq1,
>>>> species.names = TRUE,
>>>> gene.names = FALSE,
>>>> as.character = TRUE)
>>>>
>>>> write.dna(sequences, "mysequences.fas", format = "fasta")
>>>>
>>>> My problem is, that R doesn't take the whole sequence number as "060054"
>>>> but it puts it as DQ60054 (missing the zero in the beginning, which is
>>>> essential).
>>>>
>>>> Could please tell me, how I can get R to accepting the zero in the
>>>> beginning of the accession number?
>>>>
>>>> Thank you very much in advance and all the best!
>>>>
>>>> Nabila
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 07-Feb-2017  Time: 16:48:41
> This message was sent by XFMail
> -------------------------------------------------


From catalinroibu at gmail.com  Tue Feb  7 18:51:21 2017
From: catalinroibu at gmail.com (catalin roibu)
Date: Tue, 7 Feb 2017 19:51:21 +0200
Subject: [R] Gaussian Filter
Message-ID: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>

Dear all!

Please help me with a script or package to compute a Gaussian filter. I
have a time series (like average mean temperature from 1901-2014) and I
want to extract low, high and band pass frequencies using a Gaussian filter
with 32 years window.

Thank you very much!

Best regards!

Catalin

	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Tue Feb  7 20:23:46 2017
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 7 Feb 2017 14:23:46 -0500
Subject: [R] rms::latex.anova broken?
Message-ID: <64f380a6-5a2f-9fd7-9534-67b3dd8ef382@utoronto.ca>

I am re-running some logistic regression analyses using lrm from the rms 
package but latex(anova(...)) appears to be broken on my system.

Here is some anova() output followed by the latex() error for two models 
since the error changes. My sessionInfo() follows the other output. I 
have updated all my packages and re-installed Hmisc and rms plus 
dependencies. The only thing I haven't done yet is update R completely. 
Has anyone else encountered this and know how to solve it?

 > anova(full)
                 Wald Statistics          Response: id14

  Factor              Chi-Square d.f. P
  birthweight_kilo     0.87       1   0.3517
  ageinmonth           4.12       1   0.0423
  zbmi                 6.49       1   0.0108
  maxtbf              15.16       1   0.0001
  cowsmilk             6.54       1   0.0106
  Male                 1.96       1   0.1611
  multivitamin         0.76       1   0.3819
  bottleuse            0.13       1   0.7194
  preterm              0.50       1   0.4811
  AGEINTRO_cowsmilk    0.06       1   0.8032
  AGEINTRO_complefood  0.61       1   0.4356
  TOTAL               30.49      11   0.0013
 > latex(anova(full),file="",table.env=FALSE,booktabs=TRUE)
Error in ifelse(sn %nin% c("d.f.", "MS", "Partial SS"), math(sn), sn) :
   could not find function "math"
 > anova(full.nl)
                 Wald Statistics          Response: id14

  Factor              Chi-Square d.f. P
  birthweight_kilo     3.68       2   0.1588
   Nonlinear           2.65       1   0.1037
  ageinmonth          16.25       2   0.0003
   Nonlinear          13.45       1   0.0002
  zbmi                 4.07       2   0.1310
   Nonlinear           0.23       1   0.6323
  maxtbf              15.81       2   0.0004
   Nonlinear           2.57       1   0.1092
  cowsmilk             3.34       2   0.1880
   Nonlinear           1.16       1   0.2821
  Male                 1.21       1   0.2711
  multivitamin         0.57       1   0.4494
  bottleuse            0.06       1   0.8100
  preterm              0.01       1   0.9418
  AGEINTRO_cowsmilk    3.65       2   0.1612
   Nonlinear           3.28       1   0.0700
  AGEINTRO_complefood  5.40       2   0.0671
   Nonlinear           4.00       1   0.0455
  TOTAL NONLINEAR     25.41       7   0.0006
  TOTAL               52.13      18   <.0001
 > latex(anova(full.nl),file="",table.env=FALSE,booktabs=TRUE)
Error in paste0(specs$lspace, specs$italics(substring(rowl, 2)), sep = 
"") :
   attempt to apply non-function

 > sessionInfo()
R version 3.2.3 Patched (2016-01-31 r70055)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Slackware 14.2

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rms_5.1-0       SparseM_1.74    Hmisc_4.0-2     ggplot2_2.2.1
[5] Formula_1.2-1   survival_2.40-1 lattice_0.20-34 knitr_1.15.1

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.9         RColorBrewer_1.1-2  plyr_1.8.4
  [4] base64enc_0.1-3     tools_3.2.3         rpart_4.1-10
  [7] digest_0.6.12       polspline_1.1.12    tibble_1.2
[10] gtable_0.2.0        htmlTable_1.9       checkmate_1.8.2
[13] nlme_3.1-131        Matrix_1.2-8        mvtnorm_1.0-5
[16] gridExtra_2.2.1     stringr_1.1.0       cluster_2.0.5
[19] htmlwidgets_0.8     MatrixModels_0.4-1  grid_3.2.3
[22] nnet_7.3-12         data.table_1.10.4   foreign_0.8-67
[25] multcomp_1.4-6      TH.data_1.0-8       latticeExtra_0.6-28
[28] magrittr_1.5        codetools_0.2-15    MASS_7.3-45
[31] scales_0.4.1        backports_1.0.5     htmltools_0.3.5
[34] splines_3.2.3       assertthat_0.1      colorspace_1.3-2
[37] quantreg_5.29       sandwich_2.3-4      stringi_1.1.2
[40] acepack_1.4.1       lazyeval_0.2.0      munsell_0.4.3
[43] zoo_1.7-14


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From bgunter.4567 at gmail.com  Tue Feb  7 20:30:48 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Feb 2017 11:30:48 -0800
Subject: [R] Gaussian Filter
In-Reply-To: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>
References: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>
Message-ID: <CAGxFJbRLNRFJGPj00dJAXO9Yc4d8ODfs-K5NReQODKzTS18c9w@mail.gmail.com>

Please do your "homework" before posting!

Either:

https://cran.r-project.org/web/views/TimeSeries.html

or search: e.g. "bandpass filter" on rseek.org



Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 7, 2017 at 9:51 AM, catalin roibu <catalinroibu at gmail.com> wrote:
> Dear all!
>
> Please help me with a script or package to compute a Gaussian filter. I
> have a time series (like average mean temperature from 1901-2014) and I
> want to extract low, high and band pass frequencies using a Gaussian filter
> with 32 years window.
>
> Thank you very much!
>
> Best regards!
>
> Catalin
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From starskykwesi at gmail.com  Tue Feb  7 20:43:01 2017
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Tue, 7 Feb 2017 21:43:01 +0200
Subject: [R] Gaussian Filter
In-Reply-To: <CAGxFJbRLNRFJGPj00dJAXO9Yc4d8ODfs-K5NReQODKzTS18c9w@mail.gmail.com>
References: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>
	<CAGxFJbRLNRFJGPj00dJAXO9Yc4d8ODfs-K5NReQODKzTS18c9w@mail.gmail.com>
Message-ID: <CAGD2cKeAkgmX2mpm3ffAKiQ7L1WCbG9H1rXB5Lbnts+LUv=xyg@mail.gmail.com>

Hello Catalin, you could have a look on this link first for ideas in
constructing your own script.

http://stackoverflow.com/questions/7105962/how-do-i-run-a-high-pass-or-low-pass-filter-on-data-points-in-r

Cheers!
Kwesi

On Tue, Feb 7, 2017 at 9:30 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Please do your "homework" before posting!
>
> Either:
>
> https://cran.r-project.org/web/views/TimeSeries.html
>
> or search: e.g. "bandpass filter" on rseek.org
>
>
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 7, 2017 at 9:51 AM, catalin roibu <catalinroibu at gmail.com>
> wrote:
> > Dear all!
> >
> > Please help me with a script or package to compute a Gaussian filter. I
> > have a time series (like average mean temperature from 1901-2014) and I
> > want to extract low, high and band pass frequencies using a Gaussian
> filter
> > with 32 years window.
> >
> > Thank you very much!
> >
> > Best regards!
> >
> > Catalin
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast|College of Agriculture and Natural Sciences|Department
of Physics|
Team Leader|Recycle Up! Ghana|Technology Without Borders|
Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From ladarozkosny at seznam.cz  Wed Feb  8 01:49:10 2017
From: ladarozkosny at seznam.cz (=?utf-8?q?Ladislav_Rozko=C5=A1n=C3=BD?=)
Date: Wed, 08 Feb 2017 01:49:10 +0100 (CET)
Subject: [R] pls package - validation
Message-ID: <McV.wonQ.1n}dZmj{BYq.1Occi6@seznam.cz>




Hi,




I'm trying to fit PLSR model in R with 'pls' package with 22 samples (16 
train, 6 test). I know that basic for considering of number of component is 
cross-validation (in my case 'LOO') and then I should choose number of 
component with minimum of RMSEP (or first minimum). But problem is that 
values of RMSEP is increasing (not the opposite). Should I choose only 1 
component?




And then I tried compute R2 with my test-dataset (6 samples) and I received 
nonsensical values (below 0, bigger then 1).

Do you have any idea what may be caused? If it's my problem with fitting or 
problem with datasets.




Below, you can see my results:




>pH.spec<-plsr(pH ~ spec, data=soil.train, validation="LOO")

>summary(pH.spec)

Data: ??? X dimension: 16 501 
??? Y dimension: 16 1
Fit method: kernelpls
Number of components considered: 14

VALIDATION: RMSEP
Cross-validated using 16 leave-one-out segments.
?????? (Intercept)? 1 comps? 2 comps? 3 comps? 4 comps? 5 comps? 6 comps? 7 
comps? 8 comps? 9 comps? 10 comps? 11 comps
CV????????? 0.5343?? 0.5435?? 0.5506??? 1.629??? 1.617??? 1.742??? 1.921??? 
1.979??? 1.977??? 1.971???? 1.972???? 1.972
adjCV?????? 0.5343?? 0.5419?? 0.5486??? 1.587??? 1.570??? 1.688??? 1.860??? 
1.916??? 1.914??? 1.908???? 1.910???? 1.909
?????? 12 comps? 13 comps? 14 comps
CV??????? 1.972???? 1.972???? 1.972
adjCV???? 1.909???? 1.909???? 1.909

TRAINING: % variance explained
??? 1 comps? 2 comps? 3 comps? 4 comps? 5 comps? 6 comps? 7 comps? 8 comps? 
9 comps? 10 comps? 11 comps? 12 comps
X??? 96.410?? 99.655??? 99.87??? 99.90??? 99.93??? 99.94??? 99.95??? 99.96??
? 99.96???? 99.97???? 99.98???? 99.99
pH??? 3.649??? 8.342??? 19.41??? 67.48??? 88.96??? 97.19??? 99.69??? 99.94??
? 99.99??? 100.00??? 100.00??? 100.00
??? 13 comps? 14 comps
X????? 99.99?????? 100
pH??? 100.00?????? 100




> R2(pH.spec, newdata = soil.test)
(Intercept)????? 1 comps????? 2 comps????? 3 comps????? 4 comps????? 5 comps
????? 6 comps????? 7 comps????? 8 comps? 
?? -1.65763???? -0.60849???? -0.05253???? -0.72870???? -2.84718???? -2.34102
???? -3.28201???? -3.68611???? -3.69817? 
??? 9 comps???? 10 comps???? 11 comps???? 12 comps???? 13 comps???? 14 comps
? 
?? -3.77271???? -3.74585???? -3.76342???? -3.76074???? -3.76110???? -3.76115
? 





Thank you in advance for your help






=
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Feb  8 06:56:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 7 Feb 2017 21:56:19 -0800
Subject: [R] pls package - validation
In-Reply-To: <McV.wonQ.1n}dZmj{BYq.1Occi6@seznam.cz>
References: <McV.wonQ.1n}dZmj{BYq.1Occi6@seznam.cz>
Message-ID: <CAGxFJbSG=DsMum3gneVkLjDx_a88uJmEL888tn=TfewZ6WuobA@mail.gmail.com>

I think this wants a statistical discussion, which is OT here.
stats.stackexchange.com would be a better place to post for that.

However, if I understand correctly, using pls or anything else to try
to fit (some combination of) 501 variables to 16 data points -- and
then crossvalidate with 6 data points -- is utter nonsense. You just
have a fancy random number generator!

As I said, I think it better to follow up or complain about me on
stackexchange rather than here.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 7, 2017 at 4:49 PM, Ladislav Rozko?n?
<ladarozkosny at seznam.cz> wrote:
>
>
>
> Hi,
>
>
>
>
> I'm trying to fit PLSR model in R with 'pls' package with 22 samples (16
> train, 6 test). I know that basic for considering of number of component is
> cross-validation (in my case 'LOO') and then I should choose number of
> component with minimum of RMSEP (or first minimum). But problem is that
> values of RMSEP is increasing (not the opposite). Should I choose only 1
> component?
>
>
>
>
> And then I tried compute R2 with my test-dataset (6 samples) and I received
> nonsensical values (below 0, bigger then 1).
>
> Do you have any idea what may be caused? If it's my problem with fitting or
> problem with datasets.
>
>
>
>
> Below, you can see my results:
>
>
>
>
>>pH.spec<-plsr(pH ~ spec, data=soil.train, validation="LOO")
>
>>summary(pH.spec)
>
> Data:     X dimension: 16 501
>     Y dimension: 16 1
> Fit method: kernelpls
> Number of components considered: 14
>
> VALIDATION: RMSEP
> Cross-validated using 16 leave-one-out segments.
>        (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7
> comps  8 comps  9 comps  10 comps  11 comps
> CV          0.5343   0.5435   0.5506    1.629    1.617    1.742    1.921
> 1.979    1.977    1.971     1.972     1.972
> adjCV       0.5343   0.5419   0.5486    1.587    1.570    1.688    1.860
> 1.916    1.914    1.908     1.910     1.909
>        12 comps  13 comps  14 comps
> CV        1.972     1.972     1.972
> adjCV     1.909     1.909     1.909
>
> TRAINING: % variance explained
>     1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps
> 9 comps  10 comps  11 comps  12 comps
> X    96.410   99.655    99.87    99.90    99.93    99.94    99.95    99.96
>   99.96     99.97     99.98     99.99
> pH    3.649    8.342    19.41    67.48    88.96    97.19    99.69    99.94
>   99.99    100.00    100.00    100.00
>     13 comps  14 comps
> X      99.99       100
> pH    100.00       100
>
>
>
>
>> R2(pH.spec, newdata = soil.test)
> (Intercept)      1 comps      2 comps      3 comps      4 comps      5 comps
>       6 comps      7 comps      8 comps
>    -1.65763     -0.60849     -0.05253     -0.72870     -2.84718     -2.34102
>      -3.28201     -3.68611     -3.69817
>     9 comps     10 comps     11 comps     12 comps     13 comps     14 comps
>
>    -3.77271     -3.74585     -3.76342     -3.76074     -3.76110     -3.76115
>
>
>
>
>
>
> Thank you in advance for your help
>
>
>
>
>
>
> =
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Wed Feb  8 10:27:33 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Wed, 8 Feb 2017 09:27:33 +0000
Subject: [R] fine tune changepoint
Message-ID: <CAMk+s2S3Y_mt0rQNN=rfB0Eor5QiOb3iQiS3=VamvrmSr_+p9Q@mail.gmail.com>

Dear all,
I am using the package changepoint to identify a cut-off between positive
and negative values for an assay. I followed the vignette of the package
and the results are replicated, so I tried with a dataset of my choice. In
the assay, the positive have a value above 0.8 and the negative below 0.6,
so i did:

set.seed(10)

my.data <- c(rnorm(100, 0.8, 0.1), rnorm(100, 0.6, 0.1))

plot(my.data)


cp <- cpt.mean(my.data, method='PELT')

cpts(cp)

plot(cp, type='l', cpt.col='blue', xlab="Index", cpt.width=4)

It is visible that the data is clearly separated in two clusters, but the
algorithm did not find any change point. I tried also the other methods of
the function but no change point was found.

How can I fine tune the analysis to identify a change point to use as
cut-off? such fine-tuning should also be generic because should be applied
to any dataset.

thank you

L.

	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Wed Feb  8 10:27:54 2017
From: lucam1968 at gmail.com (Luca Meyer)
Date: Wed, 8 Feb 2017 10:27:54 +0100
Subject: [R] How do I best create a R procedure from a R file?
Message-ID: <CABQyo84onPdGV-Kyb8mNKZodY8meb4GsCNveE0eckNMS6G6ZCA@mail.gmail.com>

Hi,

I am working on the following file:

> str(elencositi)
'data.frame':    641 obs. of  2 variables:
 $ indirizzo.sito: chr  "10ahora.com.ar" "abceconomia.co" "accmag.com" "
actu.orange.fr" ...
 $ nome.sito     : chr  "10ahora" "ABC economia" "Acc Magazine" "Orange
Actu" ...

> head(elencositi)
          indirizzo.sito    nome.sito
1         10ahora.com.ar      10ahora
2         abceconomia.co ABC economia
3             accmag.com Acc Magazine
4         actu.orange.fr  Orange Actu
5   affaires.lapresse.ca    La Presse
6 agipapress.blogspot.it   Agigapress

Which is regularly updated and I consequently need to update a procedure
that takes elencositi data to update dati$FONTE as indicated below:

dati$FONTE <- ifelse(dati$FONTE=='10ahora.com.ar','10ahora',dati$FONTE)
dati$FONTE <- ifelse(dati$FONTE=='abceconomia.co','ABC economia',dati$FONTE)
dati$FONTE <- ifelse(dati$FONTE=='accmag.com','Acc Magazine',dati$FONTE)

Currently I am using a time consuming procedure involving Excel to update
that, but how can I make that automatic?

Thank you in advance,

Luca

	[[alternative HTML version deleted]]


From b.h.mevik at usit.uio.no  Wed Feb  8 10:45:32 2017
From: b.h.mevik at usit.uio.no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Wed, 08 Feb 2017 10:45:32 +0100
Subject: [R] pls package - validation
In-Reply-To: <CAGxFJbSG=DsMum3gneVkLjDx_a88uJmEL888tn=TfewZ6WuobA@mail.gmail.com>
	(Bert Gunter's message of "Tue, 7 Feb 2017 21:56:19 -0800")
References: <McV.wonQ.1n}dZmj{BYq.1Occi6@seznam.cz>
	<CAGxFJbSG=DsMum3gneVkLjDx_a88uJmEL888tn=TfewZ6WuobA@mail.gmail.com>
Message-ID: <s3sa89x3tj7.fsf@varelg.uio.no>

Bert Gunter <bgunter.4567 at gmail.com> writes:

> However, if I understand correctly, using pls or anything else to try
> to fit (some combination of) 501 variables to 16 data points -- and
> then crossvalidate with 6 data points -- is utter nonsense. You just
> have a fancy random number generator!

That is incorrect.  PLSR and other dimension reducing regression methods
can handle more prediction variables than samples perfectly fine -- many
of them were created for that purpose.

As for the original question: typically this happens when there is no
(or very little) correlation between the response and the prediction
variables.  (Or as they tend to say in chemometrics: You don't have a
model.)

> As I said, I think it better to follow up or complain about me on
> stackexchange rather than here.

Sorry, I read this too late. :)

-- 
Regards,
Bj?rn-Helge Mevik
-------------- neste del --------------
A non-text attachment was scrubbed...
Name: ikke tilgjengelig
Type: application/pgp-signature
Size: 800 bytes
Desc: ikke tilgjengelig
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170208/2c61e1ad/attachment.bin>

From b.h.mevik at usit.uio.no  Wed Feb  8 10:45:32 2017
From: b.h.mevik at usit.uio.no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Wed, 08 Feb 2017 10:45:32 +0100
Subject: [R] pls package - validation
In-Reply-To: <CAGxFJbSG=DsMum3gneVkLjDx_a88uJmEL888tn=TfewZ6WuobA@mail.gmail.com>
	(Bert Gunter's message of "Tue, 7 Feb 2017 21:56:19 -0800")
References: <McV.wonQ.1n}dZmj{BYq.1Occi6@seznam.cz>
	<CAGxFJbSG=DsMum3gneVkLjDx_a88uJmEL888tn=TfewZ6WuobA@mail.gmail.com>
Message-ID: <s3sa89x3tj7.fsf@varelg.uio.no>

Bert Gunter <bgunter.4567 at gmail.com> writes:

> However, if I understand correctly, using pls or anything else to try
> to fit (some combination of) 501 variables to 16 data points -- and
> then crossvalidate with 6 data points -- is utter nonsense. You just
> have a fancy random number generator!

That is incorrect.  PLSR and other dimension reducing regression methods
can handle more prediction variables than samples perfectly fine -- many
of them were created for that purpose.

As for the original question: typically this happens when there is no
(or very little) correlation between the response and the prediction
variables.  (Or as they tend to say in chemometrics: You don't have a
model.)

> As I said, I think it better to follow up or complain about me on
> stackexchange rather than here.

Sorry, I read this too late. :)

-- 
Regards,
Bj?rn-Helge Mevik
-------------- neste del --------------
A non-text attachment was scrubbed...
Name: ikke tilgjengelig
Type: application/pgp-signature
Size: 800 bytes
Desc: ikke tilgjengelig
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170208/2c61e1ad/attachment-0001.bin>

From petr.pikal at precheza.cz  Wed Feb  8 13:43:04 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 8 Feb 2017 12:43:04 +0000
Subject: [R] How do I best create a R procedure from a R file?
In-Reply-To: <CABQyo84onPdGV-Kyb8mNKZodY8meb4GsCNveE0eckNMS6G6ZCA@mail.gmail.com>
References: <CABQyo84onPdGV-Kyb8mNKZodY8meb4GsCNveE0eckNMS6G6ZCA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A15086@SRVEXCHCM301.precheza.cz>

Hi

one possibility is to use merge but it generates new data. Match can result in required data, but maybe there are also other options.

First some toy data
edat<-data.frame(letters, LETTERS)
set.seed(111)
dati<-data.frame(FFF=sample(letters[8:15], 35, replace=T))
dati$FFF<-as.character(dati$FFF)
dati$FFF[c(5,12, 23, 31)]<-2

> head(dati$FFF, 10)
 [1] "l" "m" "j" "l" "2" "k" "h" "l" "k" "h"

names(edat)<-c("let", "LET")

merge(dati, edat, by.x="FFF", by.y="let", all.x=TRUE)
> merge(dati, edat, by.x="FFF", by.y="let", all.x=TRUE)
   FFF  LET
1    2 <NA>
2    2 <NA>
3    2 <NA>
4    2 <NA>
5    h    H
6    h    H
7    h    H

....
32   m    M
33   n    N
34   o    O
35   o    O
>
Now with match

ind<-edat$LET[match(dati$FFF, edat$let)]

ind<-as.character(ind)
dati$FFF <- ifelse(is.na(ind), dati$FFF, ind)

> head(dati$FFF, 10)
 [1] "L" "M" "J" "L" "2" "K" "H" "L" "K" "H"

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luca
> Meyer
> Sent: Wednesday, February 8, 2017 10:28 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] How do I best create a R procedure from a R file?
>
> Hi,
>
> I am working on the following file:
>
> > str(elencositi)
> 'data.frame':    641 obs. of  2 variables:
>  $ indirizzo.sito: chr  "10ahora.com.ar" "abceconomia.co" "accmag.com" "
> actu.orange.fr" ...
>  $ nome.sito     : chr  "10ahora" "ABC economia" "Acc Magazine" "Orange
> Actu" ...
>
> > head(elencositi)
>           indirizzo.sito    nome.sito
> 1         10ahora.com.ar      10ahora
> 2         abceconomia.co ABC economia
> 3             accmag.com Acc Magazine
> 4         actu.orange.fr  Orange Actu
> 5   affaires.lapresse.ca    La Presse
> 6 agipapress.blogspot.it   Agigapress
>
> Which is regularly updated and I consequently need to update a procedure
> that takes elencositi data to update dati$FONTE as indicated below:
>
> dati$FONTE <- ifelse(dati$FONTE=='10ahora.com.ar','10ahora',dati$FONTE)
> dati$FONTE <- ifelse(dati$FONTE=='abceconomia.co','ABC
> economia',dati$FONTE) dati$FONTE <- ifelse(dati$FONTE=='accmag.com','Acc
> Magazine',dati$FONTE)
>
> Currently I am using a time consuming procedure involving Excel to update
> that, but how can I make that automatic?
>
> Thank you in advance,
>
> Luca
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From gallais.fanny at gmail.com  Wed Feb  8 11:10:48 2017
From: gallais.fanny at gmail.com (Fanny Gallais)
Date: Wed, 8 Feb 2017 11:10:48 +0100
Subject: [R] Differential equations
Message-ID: <CANSOPkWbR5rzOs_+-pMZPz7QAmbdhjH2bkahRBrOXvds9e-4ow@mail.gmail.com>

Hi,

I'm working on a system of 2 differential equations. My initial condition
(t=0) is c(100,0) and i'm using lsoda function (from package deSolve) to
solve it.
My system reprensents the evoution of drug concentration in two
compartments throug time. Problem is I would like to model a repeated drug
administration. That is to say, not only 100 at t=0 but also at t=20,40,...
I can't find a solution to do so. I tried adding "100" to the first
differential equation at the times of interest but it doesn't work. Do you
have any idea?

Thank you
F.G.

	[[alternative HTML version deleted]]


From peter.mills at strath.ac.uk  Wed Feb  8 11:41:22 2017
From: peter.mills at strath.ac.uk (Peter Mills)
Date: Wed, 8 Feb 2017 10:41:22 +0000
Subject: [R] calculating the cumulative distribution function for a Von
 Mises Mixture model?
In-Reply-To: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86A734@EX2010-MBX2.ds.strath.ac.uk>
References: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86A734@EX2010-MBX2.ds.strath.ac.uk>
Message-ID: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86B05D@EX2010-MBX2.ds.strath.ac.uk>

Hello

Is there a package for calculating the cumulative distribution function for a Von Mises Mixture model? I am using vonMF to calculate kappa, mu and the weighting parameter for Von Mises Mixtures; I now need to calculate the cumulative distribution function (CDF) for these mixtures.

I would be grateful for any suggestions, please? How is the direction for the lower limit for the CDF of a Von Mises Mixture model determined?

Kind Regards
Peter Mills

University of Strathclyde
Level 4, Technology and Innovation Centre (TIC),
99 George Street,
Glasgow,
G1 1RD


From bgunter.4567 at gmail.com  Wed Feb  8 16:14:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 8 Feb 2017 07:14:32 -0800
Subject: [R] Gaussian Filter
In-Reply-To: <CAEW+BD+0F6CWR1f=PbdFm9z5WKrRJbp2VSjqEhhiDdcGkSbm0A@mail.gmail.com>
References: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>
	<CAGxFJbRLNRFJGPj00dJAXO9Yc4d8ODfs-K5NReQODKzTS18c9w@mail.gmail.com>
	<CAEW+BD+0F6CWR1f=PbdFm9z5WKrRJbp2VSjqEhhiDdcGkSbm0A@mail.gmail.com>
Message-ID: <CAGxFJbQUKgcMmxEEpFbybRnCSErkq+2s5yC1UbkVYcbVerpLwQ@mail.gmail.com>

Always cc the list.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Feb 7, 2017 at 11:14 PM, catalin roibu <catalinroibu at gmail.com>
wrote:

> Dear Bert,
>
> I tried all packages and I need a package or script to compute a Gaussian
> filter with different windows (eg, 10 years, 21 years, 32 years, etc).
>
> Thank you!
>
>
> Best regards!
>
>
>
>
>
>
>   <https://mailtrack.io/>Sent with Mailtrack
> <https://mailtrack.io/install?source=signature&lang=en&referral=catalinroibu at gmail.com&idSignature=22>
>
> On 7 February 2017 at 21:30, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> Please do your "homework" before posting!
>>
>> Either:
>>
>> https://cran.r-project.org/web/views/TimeSeries.html
>>
>> or search: e.g. "bandpass filter" on rseek.org
>>
>>
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Feb 7, 2017 at 9:51 AM, catalin roibu <catalinroibu at gmail.com>
>> wrote:
>> > Dear all!
>> >
>> > Please help me with a script or package to compute a Gaussian filter. I
>> > have a time series (like average mean temperature from 1901-2014) and I
>> > want to extract low, high and band pass frequencies using a Gaussian
>> filter
>> > with 32 years window.
>> >
>> > Thank you very much!
>> >
>> > Best regards!
>> >
>> > Catalin
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Feb  8 16:19:39 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 8 Feb 2017 16:19:39 +0100
Subject: [R] Differential equations
In-Reply-To: <CANSOPkWbR5rzOs_+-pMZPz7QAmbdhjH2bkahRBrOXvds9e-4ow@mail.gmail.com>
References: <CANSOPkWbR5rzOs_+-pMZPz7QAmbdhjH2bkahRBrOXvds9e-4ow@mail.gmail.com>
Message-ID: <ABCDAEC0-39D6-49D1-A522-5F0F13DEB4E3@gmail.com>

It's been a while, but I think I have gotten through this sort of situation by splitting the integration into intervals, i.e., you run from t=0 to t=20 witn initial condition c(100,0), yielding a value c(y1,y2), then you run from 20 to 40 with initial condition c(y1+100, y2), etc.

-pd

On 08 Feb 2017, at 11:10 , Fanny Gallais <gallais.fanny at gmail.com> wrote:

> Hi,
> 
> I'm working on a system of 2 differential equations. My initial condition
> (t=0) is c(100,0) and i'm using lsoda function (from package deSolve) to
> solve it.
> My system reprensents the evoution of drug concentration in two
> compartments throug time. Problem is I would like to model a repeated drug
> administration. That is to say, not only 100 at t=0 but also at t=20,40,...
> I can't find a solution to do so. I tried adding "100" to the first
> differential equation at the times of interest but it doesn't work. Do you
> have any idea?
> 
> Thank you
> F.G.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From catalinroibu at gmail.com  Wed Feb  8 17:26:12 2017
From: catalinroibu at gmail.com (catalin roibu)
Date: Wed, 8 Feb 2017 18:26:12 +0200
Subject: [R] Gaussian Filter
In-Reply-To: <CAEW+BD+HJopco8k9DRERtJoDQtUTVGWOuQRwRTsRf274EX6Sgw@mail.gmail.com>
References: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>
	<CAGxFJbRLNRFJGPj00dJAXO9Yc4d8ODfs-K5NReQODKzTS18c9w@mail.gmail.com>
	<CAGD2cKeAkgmX2mpm3ffAKiQ7L1WCbG9H1rXB5Lbnts+LUv=xyg@mail.gmail.com>
	<CAEW+BD+HJopco8k9DRERtJoDQtUTVGWOuQRwRTsRf274EX6Sgw@mail.gmail.com>
Message-ID: <CAEW+BD+xPkh1ADMF-Wv+aWSRm_P2jWybu+JxVhMnz60ZUfA2ow@mail.gmail.com>

Dear all!

?I know that! I need only the Gaussian filter, as for the rest is simple.



  <https://mailtrack.io/>Sent with Mailtrack
<https://mailtrack.io/install?source=signature&lang=en&referral=catalinroibu at gmail.com&idSignature=22>

On 8 February 2017 at 09:58, catalin roibu <catalinroibu at gmail.com> wrote:

> Dear Kwesi,
>
> ?I know that! I need only the Gaussian filter, as for the rest is simple.
>
> ?
>
>
>
>   <https://mailtrack.io/>Sent with Mailtrack
> <https://mailtrack.io/install?source=signature&lang=en&referral=catalinroibu at gmail.com&idSignature=22>
>
> On 7 February 2017 at 21:43, Kwesi Quagraine <starskykwesi at gmail.com>
> wrote:
>
>> Hello Catalin, you could have a look on this link first for ideas in
>> constructing your own script.
>>
>> http://stackoverflow.com/questions/7105962/how-do-i-run-a-
>> high-pass-or-low-pass-filter-on-data-points-in-r
>>
>> Cheers!
>> Kwesi
>>
>> On Tue, Feb 7, 2017 at 9:30 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> Please do your "homework" before posting!
>>>
>>> Either:
>>>
>>> https://cran.r-project.org/web/views/TimeSeries.html
>>>
>>> or search: e.g. "bandpass filter" on rseek.org
>>>
>>>
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Tue, Feb 7, 2017 at 9:51 AM, catalin roibu <catalinroibu at gmail.com>
>>> wrote:
>>> > Dear all!
>>> >
>>> > Please help me with a script or package to compute a Gaussian filter. I
>>> > have a time series (like average mean temperature from 1901-2014) and I
>>> > want to extract low, high and band pass frequencies using a Gaussian
>>> filter
>>> > with 32 years window.
>>> >
>>> > Thank you very much!
>>> >
>>> > Best regards!
>>> >
>>> > Catalin
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Try not to become a man of success but rather a man of value-Albert
>> Einstein
>>
>> University of Cape Coast|College of Agriculture and Natural Sciences|Department
>> of Physics|
>> Team Leader|Recycle Up! Ghana|Technology Without Borders|
>> Other emails: kwesi.quagraine at ucc.edu.gh|kwesi.quagraine at teog.de|
>> Mobile: +233266173582 <+233%2026%20617%203582>
>> Skype: quagraine_cwasi
>> Twitter: @Pkdilly
>>
>>
>
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>



-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From erich.subs at neuwirth.priv.at  Wed Feb  8 19:23:51 2017
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Wed, 8 Feb 2017 19:23:51 +0100
Subject: [R] How do I best create a R procedure from a R file?
In-Reply-To: <CABQyo84onPdGV-Kyb8mNKZodY8meb4GsCNveE0eckNMS6G6ZCA@mail.gmail.com>
References: <CABQyo84onPdGV-Kyb8mNKZodY8meb4GsCNveE0eckNMS6G6ZCA@mail.gmail.com>
Message-ID: <9388BA7C-E4BA-4B6D-AF4A-E457F0009CBB@neuwirth.priv.at>

Rough sketch:
lookup.vec <-  elencositi$nome.sito
names(ookup.vec) <-  elencositi$indirezzo.sito

dati$FONTE <- lookup.vec(dati$FONTE)

This, however, assumes that elencositi has all the values that con occur.



> On 8 Feb 2017, at 10:27, Luca Meyer <lucam1968 at gmail.com> wrote:
> 
> Hi,
> 
> I am working on the following file:
> 
>> str(elencositi)
> 'data.frame':    641 obs. of  2 variables:
> $ indirizzo.sito: chr  "10ahora.com.ar" "abceconomia.co" "accmag.com" "
> actu.orange.fr" ...
> $ nome.sito     : chr  "10ahora" "ABC economia" "Acc Magazine" "Orange
> Actu" ...
> 
>> head(elencositi)
>          indirizzo.sito    nome.sito
> 1         10ahora.com.ar      10ahora
> 2         abceconomia.co ABC economia
> 3             accmag.com Acc Magazine
> 4         actu.orange.fr  Orange Actu
> 5   affaires.lapresse.ca    La Presse
> 6 agipapress.blogspot.it   Agigapress
> 
> Which is regularly updated and I consequently need to update a procedure
> that takes elencositi data to update dati$FONTE as indicated below:
> 
> dati$FONTE <- ifelse(dati$FONTE=='10ahora.com.ar','10ahora',dati$FONTE)
> dati$FONTE <- ifelse(dati$FONTE=='abceconomia.co','ABC economia',dati$FONTE)
> dati$FONTE <- ifelse(dati$FONTE=='accmag.com','Acc Magazine',dati$FONTE)
> 
> Currently I am using a time consuming procedure involving Excel to update
> that, but how can I make that automatic?
> 
> Thank you in advance,
> 
> Luca
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Wed Feb  8 19:57:17 2017
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Wed, 8 Feb 2017 12:57:17 -0600
Subject: [R] rms::latex.anova broken?
In-Reply-To: <273527dd-e0c5-471f-eaa7-c2c784d2d209@utoronto.ca>
References: <64f380a6-5a2f-9fd7-9534-67b3dd8ef382@utoronto.ca>
	<273527dd-e0c5-471f-eaa7-c2c784d2d209@utoronto.ca>
Message-ID: <CAMO-wTZ=f9Ce=X52o-ftUZi7+6B+cedv=ou7c+WY8PJRBBnQwg@mail.gmail.com>

In recent versions of rms on CRAN there was a non-downward compatible
change.  To get latex output for summary, anova, and print on fit objects
you leave off file="" (because we're usually using knitr anyway) and use

options(prType='latex')
anova(f)     # LaTeX output

You can use options(prType='html') to get special html output for RMarkdown
html reports and html notebooks.

There are small changes in Hmisc, e.g., leave off file="" for
latex(describe()).

Frank

------------------------------
Frank E Harrell Jr      Professor and Chairman      School of Medicine

Department of *Biostatistics*      *Vanderbilt University*

On Wed, Feb 8, 2017 at 12:19 PM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Hi Frank.
>
> I sent this to r-help yesterday but have not received any answers from the
> list readers. I thought I'd send to you directly to see if you had any
> insight. Since I posted this yesterday I have updated my R installation to
> the latest patched version and still get the errors.
>
> I use latex(anova(...)) quite a bit so a fix or workaround would by most
> appreciated.
>
> All the best,
>
> Kevin
>
>
> -------- Forwarded Message --------
> Subject: rms::latex.anova broken?
> Date: Tue, 7 Feb 2017 14:23:46 -0500
> From: Kevin E. Thorpe <kevin.thorpe at utoronto.ca>
> To: R Help Mailing List <r-help at stat.math.ethz.ch>
>
> I am re-running some logistic regression analyses using lrm from the rms
> package but latex(anova(...)) appears to be broken on my system.
>
> Here is some anova() output followed by the latex() error for two models
> since the error changes. My sessionInfo() follows the other output. I have
> updated all my packages and re-installed Hmisc and rms plus dependencies.
> The only thing I haven't done yet is update R completely. Has anyone else
> encountered this and know how to solve it?
>
> anova(full)
>>
>                 Wald Statistics          Response: id14
>
>  Factor              Chi-Square d.f. P
>  birthweight_kilo     0.87       1   0.3517
>  ageinmonth           4.12       1   0.0423
>  zbmi                 6.49       1   0.0108
>  maxtbf              15.16       1   0.0001
>  cowsmilk             6.54       1   0.0106
>  Male                 1.96       1   0.1611
>  multivitamin         0.76       1   0.3819
>  bottleuse            0.13       1   0.7194
>  preterm              0.50       1   0.4811
>  AGEINTRO_cowsmilk    0.06       1   0.8032
>  AGEINTRO_complefood  0.61       1   0.4356
>  TOTAL               30.49      11   0.0013
>
>> latex(anova(full),file="",table.env=FALSE,booktabs=TRUE)
>>
> Error in ifelse(sn %nin% c("d.f.", "MS", "Partial SS"), math(sn), sn) :
>   could not find function "math"
>
>> anova(full.nl)
>>
>                 Wald Statistics          Response: id14
>
>  Factor              Chi-Square d.f. P
>  birthweight_kilo     3.68       2   0.1588
>   Nonlinear           2.65       1   0.1037
>  ageinmonth          16.25       2   0.0003
>   Nonlinear          13.45       1   0.0002
>  zbmi                 4.07       2   0.1310
>   Nonlinear           0.23       1   0.6323
>  maxtbf              15.81       2   0.0004
>   Nonlinear           2.57       1   0.1092
>  cowsmilk             3.34       2   0.1880
>   Nonlinear           1.16       1   0.2821
>  Male                 1.21       1   0.2711
>  multivitamin         0.57       1   0.4494
>  bottleuse            0.06       1   0.8100
>  preterm              0.01       1   0.9418
>  AGEINTRO_cowsmilk    3.65       2   0.1612
>   Nonlinear           3.28       1   0.0700
>  AGEINTRO_complefood  5.40       2   0.0671
>   Nonlinear           4.00       1   0.0455
>  TOTAL NONLINEAR     25.41       7   0.0006
>  TOTAL               52.13      18   <.0001
>
>> latex(anova(full.nl),file="",table.env=FALSE,booktabs=TRUE)
>>
> Error in paste0(specs$lspace, specs$italics(substring(rowl, 2)), sep = "")
> :
>   attempt to apply non-function
>
> sessionInfo()
>>
> R version 3.2.3 Patched (2016-01-31 r70055)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Slackware 14.2
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rms_5.1-0       SparseM_1.74    Hmisc_4.0-2     ggplot2_2.2.1
> [5] Formula_1.2-1   survival_2.40-1 lattice_0.20-34 knitr_1.15.1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.9         RColorBrewer_1.1-2  plyr_1.8.4
>  [4] base64enc_0.1-3     tools_3.2.3         rpart_4.1-10
>  [7] digest_0.6.12       polspline_1.1.12    tibble_1.2
> [10] gtable_0.2.0        htmlTable_1.9       checkmate_1.8.2
> [13] nlme_3.1-131        Matrix_1.2-8        mvtnorm_1.0-5
> [16] gridExtra_2.2.1     stringr_1.1.0       cluster_2.0.5
> [19] htmlwidgets_0.8     MatrixModels_0.4-1  grid_3.2.3
> [22] nnet_7.3-12         data.table_1.10.4   foreign_0.8-67
> [25] multcomp_1.4-6      TH.data_1.0-8       latticeExtra_0.6-28
> [28] magrittr_1.5        codetools_0.2-15    MASS_7.3-45
> [31] scales_0.4.1        backports_1.0.5     htmltools_0.3.5
> [34] splines_3.2.3       assertthat_0.1      colorspace_1.3-2
> [37] quantreg_5.29       sandwich_2.3-4      stringi_1.1.2
> [40] acepack_1.4.1       lazyeval_0.2.0      munsell_0.4.3
> [43] zoo_1.7-14
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>

	[[alternative HTML version deleted]]


From jwd at surewest.net  Wed Feb  8 22:15:44 2017
From: jwd at surewest.net (John Dougherty)
Date: Wed, 8 Feb 2017 13:15:44 -0800
Subject: [R] Gaussian Filter
In-Reply-To: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>
References: <CAEW+BDJ2-hnOG1EbeD+FmCdFA1aW7RcyCrSqxTv2RpNwifyq=A@mail.gmail.com>
Message-ID: <20170208131544.2dd5e3c4@draco.site>

On Tue, 7 Feb 2017 19:51:21 +0200
catalin roibu <catalinroibu at gmail.com> wrote:

The simplest way to get answers to such questions is run an internet
search on your terms: "R Gaussian filter."  Google reports 6,600,000
hits.  The hits you are interested in are near the top.  It wastes
less time that way.  

BTW, is the data mean average temperature date, or
just "like" mean average temperature data.  

-- 

John


From grow.andre at gmail.com  Wed Feb  8 20:43:29 2017
From: grow.andre at gmail.com (=?iso-8859-1?Q?Andr=E9_Grow?=)
Date: Wed, 8 Feb 2017 20:43:29 +0100
Subject: [R] =?iso-8859-1?q?Does_=22coeftest=22_correctly_use_weights_from?=
	=?iso-8859-1?q?_=22svydesign=22_in_=22svyglm=22_object=3F?=
Message-ID: <002101d28243$9fbed870$df3c8950$@gmail.com>

Dear all,

 

I am using data from the European Social Survey (ESS) and I would like to
calculate country-level cluster-robust standard errors for a regression
model in R that includes country fixed effects and employs the design
weights that come with the ESS.

 

To correctly use the weights, I use the 'survey' package and the functions
'svydesign' and 'svyglm'. This step looks like this:

 

design_1 <- svydesign(id=~1, weights=~dweight, data=ESS)

 

m1 <- svyglm(y ~ cntry + x, design = design_1)

 

My question is: when I now apply the functions 'cluster.vcov' and 'coeftest'
from the packages 'lmtest' and 'multiwayvcov' to the model m1, do the
resulting standard errors correctly account for the design weights? This
step looks like this:

 

vcov_m1 <- cluster.vcov(m1, ESS$cntry)

 

coeftest(m1, vcov_m1)

 

Note that I do not use 'cntry' as an id variable in the svydesign function,
because then I cannot include country dummies in the regression model.

 

Thanks in advance for your feedback!


	[[alternative HTML version deleted]]


From jeremyeadler at gmail.com  Wed Feb  8 22:28:57 2017
From: jeremyeadler at gmail.com (jeremy adler)
Date: Wed, 8 Feb 2017 16:28:57 -0500
Subject: [R] simplifying output of mapply
Message-ID: <CACxLA8DbEgs2S8k77-zBrZHYE1YVLTb+GNsGDJuJDeGapF9Uug@mail.gmail.com>

Hi

I'm trying to use mapply to generate graphs but I cant figure out how to
get the program to only save the graph to the array and not the other
output.

plt<-function (x,y) {
  p<-dfs[dfs$region==x,c("region",y)]
  colnames(p)<-c("v1","v2")

g<-ggplot(p,aes(v2))+geom_density(aes(x=v2,fill=v1))+geom_histogram(aes(y=..density..),alpha=.5)+
theme(legend.position="none")
  g<-g+xlab(x)
  return(g)

}
m<-mapply(FUN=plt,x=c("spot_001"),y=c("Cell.Median.CD3"))

So I just want the graphs (g) to be stored in m and none of the other
extraneous output. Thanks for your help!

Jeremy

	[[alternative HTML version deleted]]


From xavier.chiriboga at unine.ch  Thu Feb  9 01:08:39 2017
From: xavier.chiriboga at unine.ch (CHIRIBOGA Xavier)
Date: Thu, 9 Feb 2017 00:08:39 +0000
Subject: [R] GLM and POST HOC test INTERPRETATION
Message-ID: <1486598924190.59589@unine.ch>

Dear colleagues,


I am analyzing a data set of 68 values (integers). In some treatments (exactly 6) the values are "zero". Because I record 0 in my measurement (or really a small value below zero)

My experiment is designed in such a way that I record values for 6 treatments at 2 times. Replicates are different in each combination time-treatment.

I am running a GLM , poisson distribution, for ANOVA I used Chisq, and for the POST HOC test I used Tukey.

I try to detect if interaction is significant, so I build the script:    expresion~time*treatment

Effects of time, treatment are interaction are significant. However, when I run the script for Tukey comparisons, I only get 15 comparisons. Of course I cannot interpret that:

these comparisons are the same for Time 1 and Time 2, since there is a significant effect of time. Moreover, I got a warning message : covariate interactions found. I dont know if I am doing right? I dont know what to do?


Thank you for your help,


Xavier

PhD Student

University of Neuchatel


lm3=glm(expresion~time*treatment,family="poisson")
> summary(lm3)

Call:
glm(formula = expresion ~ time * treatment, family = "poisson")

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-5.3796  -1.4523  -0.6642   1.2277   6.3909

Coefficients:
                      Estimate Std. Error z value Pr(>|z|)
(Intercept)            2.09964    0.29508   7.115 1.12e-12 ***
time                   0.20294    0.19255   1.054 0.291895
treatmentCHA0+Db      -0.17004    0.36180  -0.470 0.638356
treatmentDb            1.68952    0.37624   4.490 7.11e-06 ***
treatmentHEALTHY       0.84035    0.50340   1.669 0.095049 .
treatmentPCL           0.32072    0.37950   0.845 0.398041
treatmentPCL+Db        0.54365    0.34047   1.597 0.110320
time:treatmentCHA0+Db  0.87314    0.22626   3.859 0.000114 ***
time:treatmentDb      -0.82803    0.26539  -3.120 0.001808 **
time:treatmentHEALTHY -1.36987    0.38318  -3.575 0.000350 ***
time:treatmentPCL      0.08474    0.24635   0.344 0.730851
time:treatmentPCL+Db   0.39244    0.21521   1.824 0.068217 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 1173.05  on 66  degrees of freedom
Residual deviance:  403.07  on 55  degrees of freedom
AIC: 707.95

Number of Fisher Scoring iterations: 5


> anova(lm3,test="Chisq")
Analysis of Deviance Table

Model: poisson, link: log

Response: expresion

Terms added sequentially (first to last)


               Df Deviance Resid. Df Resid. Dev  Pr(>Chi)
NULL                              66    1173.05
time            1   100.55        65    1072.50 < 2.2e-16 ***
treatment       5   561.69        60     510.81 < 2.2e-16 ***
time:treatment  5   107.75        55     403.07 < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


> summary(glht(lm3, mcp(treatment="Tukey")))

         Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: glm(formula = expresion ~ time * treatment, family = "poisson")

Linear Hypotheses:
                       Estimate Std. Error z value Pr(>|z|)
CHA0+Db - CHA0 == 0     -0.1700     0.3618  -0.470   0.9970
Db - CHA0 == 0           1.6895     0.3762   4.490   <0.001 ***
HEALTHY - CHA0 == 0      0.8404     0.5034   1.669   0.5402
PCL - CHA0 == 0          0.3207     0.3795   0.845   0.9568
PCL+Db - CHA0 == 0       0.5437     0.3405   1.597   0.5892
Db - CHA0+Db == 0        1.8596     0.3135   5.931   <0.001 ***
HEALTHY - CHA0+Db == 0   1.0104     0.4584   2.204   0.2266
PCL - CHA0+Db == 0       0.4908     0.3174   1.546   0.6231
PCL+Db - CHA0+Db == 0    0.7137     0.2696   2.648   0.0817 .
HEALTHY - Db == 0       -0.8492     0.4699  -1.807   0.4491
PCL - Db == 0           -1.3688     0.3338  -4.101   <0.001 ***
PCL+Db - Db == 0        -1.1459     0.2887  -3.969   <0.001 ***
PCL - HEALTHY == 0      -0.5196     0.4725  -1.100   0.8764
PCL+Db - HEALTHY == 0   -0.2967     0.4418  -0.672   0.9842
PCL+Db - PCL == 0        0.2229     0.2929   0.761   0.9725
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- single-step method)

Warning message:
In mcp2matrix(model, linfct = linfct) :
  covariate interactions found -- default contrast might be inappropriate


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Feb  9 01:45:26 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 8 Feb 2017 16:45:26 -0800
Subject: [R] GLM and POST HOC test INTERPRETATION
In-Reply-To: <1486598924190.59589@unine.ch>
References: <1486598924190.59589@unine.ch>
Message-ID: <CAGxFJbRg7qPqDY=h77SEt1UECDvt=fbm8D8xRj0f+qaJYQktxA@mail.gmail.com>

Your questions are basically statistical and therefore OT here,
although some kind soul may respond. I would strongly suggest that you
consult with a local statistical expert, as you seem to be out of your
depth statistically.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Feb 8, 2017 at 4:08 PM, CHIRIBOGA Xavier
<xavier.chiriboga at unine.ch> wrote:
> Dear colleagues,
>
>
> I am analyzing a data set of 68 values (integers). In some treatments (exactly 6) the values are "zero". Because I record 0 in my measurement (or really a small value below zero)
>
> My experiment is designed in such a way that I record values for 6 treatments at 2 times. Replicates are different in each combination time-treatment.
>
> I am running a GLM , poisson distribution, for ANOVA I used Chisq, and for the POST HOC test I used Tukey.
>
> I try to detect if interaction is significant, so I build the script:    expresion~time*treatment
>
> Effects of time, treatment are interaction are significant. However, when I run the script for Tukey comparisons, I only get 15 comparisons. Of course I cannot interpret that:
>
> these comparisons are the same for Time 1 and Time 2, since there is a significant effect of time. Moreover, I got a warning message : covariate interactions found. I dont know if I am doing right? I dont know what to do?
>
>
> Thank you for your help,
>
>
> Xavier
>
> PhD Student
>
> University of Neuchatel
>
>
> lm3=glm(expresion~time*treatment,family="poisson")
>> summary(lm3)
>
> Call:
> glm(formula = expresion ~ time * treatment, family = "poisson")
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -5.3796  -1.4523  -0.6642   1.2277   6.3909
>
> Coefficients:
>                       Estimate Std. Error z value Pr(>|z|)
> (Intercept)            2.09964    0.29508   7.115 1.12e-12 ***
> time                   0.20294    0.19255   1.054 0.291895
> treatmentCHA0+Db      -0.17004    0.36180  -0.470 0.638356
> treatmentDb            1.68952    0.37624   4.490 7.11e-06 ***
> treatmentHEALTHY       0.84035    0.50340   1.669 0.095049 .
> treatmentPCL           0.32072    0.37950   0.845 0.398041
> treatmentPCL+Db        0.54365    0.34047   1.597 0.110320
> time:treatmentCHA0+Db  0.87314    0.22626   3.859 0.000114 ***
> time:treatmentDb      -0.82803    0.26539  -3.120 0.001808 **
> time:treatmentHEALTHY -1.36987    0.38318  -3.575 0.000350 ***
> time:treatmentPCL      0.08474    0.24635   0.344 0.730851
> time:treatmentPCL+Db   0.39244    0.21521   1.824 0.068217 .
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> (Dispersion parameter for poisson family taken to be 1)
>
>     Null deviance: 1173.05  on 66  degrees of freedom
> Residual deviance:  403.07  on 55  degrees of freedom
> AIC: 707.95
>
> Number of Fisher Scoring iterations: 5
>
>
>> anova(lm3,test="Chisq")
> Analysis of Deviance Table
>
> Model: poisson, link: log
>
> Response: expresion
>
> Terms added sequentially (first to last)
>
>
>                Df Deviance Resid. Df Resid. Dev  Pr(>Chi)
> NULL                              66    1173.05
> time            1   100.55        65    1072.50 < 2.2e-16 ***
> treatment       5   561.69        60     510.81 < 2.2e-16 ***
> time:treatment  5   107.75        55     403.07 < 2.2e-16 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
>> summary(glht(lm3, mcp(treatment="Tukey")))
>
>          Simultaneous Tests for General Linear Hypotheses
>
> Multiple Comparisons of Means: Tukey Contrasts
>
>
> Fit: glm(formula = expresion ~ time * treatment, family = "poisson")
>
> Linear Hypotheses:
>                        Estimate Std. Error z value Pr(>|z|)
> CHA0+Db - CHA0 == 0     -0.1700     0.3618  -0.470   0.9970
> Db - CHA0 == 0           1.6895     0.3762   4.490   <0.001 ***
> HEALTHY - CHA0 == 0      0.8404     0.5034   1.669   0.5402
> PCL - CHA0 == 0          0.3207     0.3795   0.845   0.9568
> PCL+Db - CHA0 == 0       0.5437     0.3405   1.597   0.5892
> Db - CHA0+Db == 0        1.8596     0.3135   5.931   <0.001 ***
> HEALTHY - CHA0+Db == 0   1.0104     0.4584   2.204   0.2266
> PCL - CHA0+Db == 0       0.4908     0.3174   1.546   0.6231
> PCL+Db - CHA0+Db == 0    0.7137     0.2696   2.648   0.0817 .
> HEALTHY - Db == 0       -0.8492     0.4699  -1.807   0.4491
> PCL - Db == 0           -1.3688     0.3338  -4.101   <0.001 ***
> PCL+Db - Db == 0        -1.1459     0.2887  -3.969   <0.001 ***
> PCL - HEALTHY == 0      -0.5196     0.4725  -1.100   0.8764
> PCL+Db - HEALTHY == 0   -0.2967     0.4418  -0.672   0.9842
> PCL+Db - PCL == 0        0.2229     0.2929   0.761   0.9725
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> (Adjusted p values reported -- single-step method)
>
> Warning message:
> In mcp2matrix(model, linfct = linfct) :
>   covariate interactions found -- default contrast might be inappropriate
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Thu Feb  9 08:36:59 2017
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 9 Feb 2017 02:36:59 -0500
Subject: [R] Does "coeftest" correctly use weights from "svydesign" in
 "svyglm" object?
In-Reply-To: <002101d28243$9fbed870$df3c8950$@gmail.com>
References: <002101d28243$9fbed870$df3c8950$@gmail.com>
Message-ID: <CAOwvMDxgJ4yiC9rjmHQ-htB97OwDtU3Hm7JKGtPPZ=JJi7f_rw@mail.gmail.com>

hi, that setup is not correct.  see examples in

https://github.com/ajdamico/asdfree/tree/master/European%20Social%20Survey

On Feb 8, 2017 11:54 PM, "Andr? Grow" <grow.andre at gmail.com> wrote:

> Dear all,
>
>
>
> I am using data from the European Social Survey (ESS) and I would like to
> calculate country-level cluster-robust standard errors for a regression
> model in R that includes country fixed effects and employs the design
> weights that come with the ESS.
>
>
>
> To correctly use the weights, I use the 'survey' package and the functions
> 'svydesign' and 'svyglm'. This step looks like this:
>
>
>
> design_1 <- svydesign(id=~1, weights=~dweight, data=ESS)
>
>
>
> m1 <- svyglm(y ~ cntry + x, design = design_1)
>
>
>
> My question is: when I now apply the functions 'cluster.vcov' and
> 'coeftest'
> from the packages 'lmtest' and 'multiwayvcov' to the model m1, do the
> resulting standard errors correctly account for the design weights? This
> step looks like this:
>
>
>
> vcov_m1 <- cluster.vcov(m1, ESS$cntry)
>
>
>
> coeftest(m1, vcov_m1)
>
>
>
> Note that I do not use 'cntry' as an id variable in the svydesign function,
> because then I cannot include country dummies in the regression model.
>
>
>
> Thanks in advance for your feedback!
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lpfgarcia at gmail.com  Wed Feb  8 19:30:07 2017
From: lpfgarcia at gmail.com (=?UTF-8?Q?Lu=C3=ADs_Paulo_F=2E_Garcia?=)
Date: Wed, 8 Feb 2017 16:30:07 -0200
Subject: [R] [R-pkgs]  Announcing mfe 0.1.0
Message-ID: <CAPK6mFpn7qUdi3O2L37MkVHMmiveXGp3AQ19uNdhJoVp5AE--Q@mail.gmail.com>

Dear R users,

I am pleased to announce that the package mfe (Meta-Feature Extractor) is
now
available on CRAN (https://cran.r-project.org/package=mfe).

The mfe package extracts meta-features from datasets to support the design
of
recommendation systems based on Meta-Learning. The meta-features, also
called
characterization measures, are able to characterize the complexity of
datasets
and to provide estimates of algorithm performance. The package contains not
only the standard characterization measures, but also more recent
characterization measures.

Please, visit the repository on GitHub (https://github.com/rivolli/mfe) or
the
Vignette (
https://cran.r-project.org/web/packages/mfe/vignettes/mfe-vignette.html)
for more information.

Kind Regards,
Luis

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From G.Maubach at weinwolf.de  Thu Feb  9 12:31:17 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 9 Feb 2017 12:31:17 +0100
Subject: [R] RStudio: Place for Storing Options
Message-ID: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>

Hi All,

I would like to make a backup of my RStudio IDE options I configure using 
"Tools/Global Options" from the menu bar. Searching the web did not reveal 
anything.

Can you tell me where RStudio IDE does store its configuration?

Kind regards

Georg


	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Thu Feb  9 14:08:50 2017
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 9 Feb 2017 08:08:50 -0500
Subject: [R] rms::latex.anova broken?
In-Reply-To: <64f380a6-5a2f-9fd7-9534-67b3dd8ef382@utoronto.ca>
References: <64f380a6-5a2f-9fd7-9534-67b3dd8ef382@utoronto.ca>
Message-ID: <09ead555-8251-5ef3-5df6-f55d4ebbe959@utoronto.ca>

I figured I should follow-up to say the function is not broken, rather 
it was me not paying close attention to recent release notes.

Frank Harrell kindly informed me (thanks Frank) that with recent 
versions of Hmisc/rms I should use options(prType="latex") for LaTeX 
output to behave correctly.

Kevin

On 02/07/2017 02:23 PM, Kevin E. Thorpe wrote:
> I am re-running some logistic regression analyses using lrm from the rms
> package but latex(anova(...)) appears to be broken on my system.
>
> Here is some anova() output followed by the latex() error for two models
> since the error changes. My sessionInfo() follows the other output. I
> have updated all my packages and re-installed Hmisc and rms plus
> dependencies. The only thing I haven't done yet is update R completely.
> Has anyone else encountered this and know how to solve it?
>
>> anova(full)
>                 Wald Statistics          Response: id14
>
>  Factor              Chi-Square d.f. P
>  birthweight_kilo     0.87       1   0.3517
>  ageinmonth           4.12       1   0.0423
>  zbmi                 6.49       1   0.0108
>  maxtbf              15.16       1   0.0001
>  cowsmilk             6.54       1   0.0106
>  Male                 1.96       1   0.1611
>  multivitamin         0.76       1   0.3819
>  bottleuse            0.13       1   0.7194
>  preterm              0.50       1   0.4811
>  AGEINTRO_cowsmilk    0.06       1   0.8032
>  AGEINTRO_complefood  0.61       1   0.4356
>  TOTAL               30.49      11   0.0013
>> latex(anova(full),file="",table.env=FALSE,booktabs=TRUE)
> Error in ifelse(sn %nin% c("d.f.", "MS", "Partial SS"), math(sn), sn) :
>   could not find function "math"
>> anova(full.nl)
>                 Wald Statistics          Response: id14
>
>  Factor              Chi-Square d.f. P
>  birthweight_kilo     3.68       2   0.1588
>   Nonlinear           2.65       1   0.1037
>  ageinmonth          16.25       2   0.0003
>   Nonlinear          13.45       1   0.0002
>  zbmi                 4.07       2   0.1310
>   Nonlinear           0.23       1   0.6323
>  maxtbf              15.81       2   0.0004
>   Nonlinear           2.57       1   0.1092
>  cowsmilk             3.34       2   0.1880
>   Nonlinear           1.16       1   0.2821
>  Male                 1.21       1   0.2711
>  multivitamin         0.57       1   0.4494
>  bottleuse            0.06       1   0.8100
>  preterm              0.01       1   0.9418
>  AGEINTRO_cowsmilk    3.65       2   0.1612
>   Nonlinear           3.28       1   0.0700
>  AGEINTRO_complefood  5.40       2   0.0671
>   Nonlinear           4.00       1   0.0455
>  TOTAL NONLINEAR     25.41       7   0.0006
>  TOTAL               52.13      18   <.0001
>> latex(anova(full.nl),file="",table.env=FALSE,booktabs=TRUE)
> Error in paste0(specs$lspace, specs$italics(substring(rowl, 2)), sep =
> "") :
>   attempt to apply non-function
>
>> sessionInfo()
> R version 3.2.3 Patched (2016-01-31 r70055)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Slackware 14.2
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rms_5.1-0       SparseM_1.74    Hmisc_4.0-2     ggplot2_2.2.1
> [5] Formula_1.2-1   survival_2.40-1 lattice_0.20-34 knitr_1.15.1
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.9         RColorBrewer_1.1-2  plyr_1.8.4
>  [4] base64enc_0.1-3     tools_3.2.3         rpart_4.1-10
>  [7] digest_0.6.12       polspline_1.1.12    tibble_1.2
> [10] gtable_0.2.0        htmlTable_1.9       checkmate_1.8.2
> [13] nlme_3.1-131        Matrix_1.2-8        mvtnorm_1.0-5
> [16] gridExtra_2.2.1     stringr_1.1.0       cluster_2.0.5
> [19] htmlwidgets_0.8     MatrixModels_0.4-1  grid_3.2.3
> [22] nnet_7.3-12         data.table_1.10.4   foreign_0.8-67
> [25] multcomp_1.4-6      TH.data_1.0-8       latticeExtra_0.6-28
> [28] magrittr_1.5        codetools_0.2-15    MASS_7.3-45
> [31] scales_0.4.1        backports_1.0.5     htmltools_0.3.5
> [34] splines_3.2.3       assertthat_0.1      colorspace_1.3-2
> [37] quantreg_5.29       sandwich_2.3-4      stringi_1.1.2
> [40] acepack_1.4.1       lazyeval_0.2.0      munsell_0.4.3
> [43] zoo_1.7-14
>
>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From ulrik.stervbo at gmail.com  Thu Feb  9 15:37:57 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 09 Feb 2017 14:37:57 +0000
Subject: [R] RStudio: Place for Storing Options
In-Reply-To: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
Message-ID: <CAKVAULMscdFRfEiZr01RB6Tv6u07pJHY0-hotXSuq4anvoSbmA@mail.gmail.com>

Hi Georg,

maybe someone here knows, but I think you are more likely to get answers to
Rstudio related questions with RStudio support:
https://support.rstudio.com/hc/en-us

Best,
Ulrik

On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de> wrote:

> Hi All,
>
> I would like to make a backup of my RStudio IDE options I configure using
> "Tools/Global Options" from the menu bar. Searching the web did not reveal
> anything.
>
> Can you tell me where RStudio IDE does store its configuration?
>
> Kind regards
>
> Georg
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Feb  9 16:06:13 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 9 Feb 2017 16:06:13 +0100
Subject: [R] RStudio: Place for Storing Options
In-Reply-To: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
Message-ID: <22684.34149.431821.945334@stat.math.ethz.ch>


>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>>>>     on Thu, 9 Feb 2017 14:37:57 +0000 writes:

    > Hi Georg,
    > maybe someone here knows, but I think you are more likely to get answers to
    > Rstudio related questions with RStudio support:
    > https://support.rstudio.com/hc/en-us

    > Best,
    > Ulrik

Indeed, thank you, Ulrik.

In this special case, however, I'm quite sure many readers of
R-help would be interested in the answer; so once you receive an
answer, please post it (or a link to a public URL with it) here
on R-help, thank you in advance.

We would like to be able to *save*, or sometimes *set* / *reset*
such options  "in a scripted manner", e.g. for
controlled exam sessions.

Martin Maechler,
ETH Zurich

    > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de> wrote:

    >> Hi All,
    >> I would like to make a backup of my RStudio IDE options I configure using 
    >> "Tools/Global Options" from the menu bar. Searching the
    >> web did not reveal anything.

    >> Can you tell me where RStudio IDE does store its configuration?

    >> Kind regards
    >> Georg


From ed_isfahani at yahoo.com  Fri Feb 10 00:51:43 2017
From: ed_isfahani at yahoo.com (Elham -)
Date: Thu, 9 Feb 2017 23:51:43 +0000 (UTC)
Subject: [R] How to prepare a input data for Cytoscape
References: <203666941.2299767.1486684303639.ref@mail.yahoo.com>
Message-ID: <203666941.2299767.1486684303639@mail.yahoo.com>

Hello,I want to use "Cytoscape" ?to construct co-expression network for coding-lncoding (control/tretment situation).I calculated correlation by R for control and treatment and now I want to prepare input data for cytoscape,?
I want?molecules (genes and lncRNA) as nodes andcorrelation weighting the edges connecting them,also?use value of correlation as an?Edge weights?too.should?I??prepare input table with 6 column? 1-coding genes 2-lncoding 3-pairs?of treatment 4-pairs?of control 5-value of treatment correlation 6-value of control correlationthat first and second are nodes and others are edges?
	[[alternative HTML version deleted]]


From a.gonzalezvoyer at gmail.com  Thu Feb  9 20:30:23 2017
From: a.gonzalezvoyer at gmail.com (Alejandro)
Date: Thu, 9 Feb 2017 13:30:23 -0600
Subject: [R] How to include custom na.action in function
Message-ID: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>

Hello,

I?ve tried googling for an answer to this but I simply can?t find something that fixes my problem. I have a long numerical vector with positive, negative and null values. I want to revert the sign of the positive and negative values and for zero to remain zero. I?ve written a function that works, except that my vector has missing values (NA) and I need to keep those as missing values. How could I add that to this function:

revertsign<-function(x){
 if (x > 0) {x <- x*-1}
   else 
if (x < 0) {x <- abs(x)}
 else
   if (x == 0) {x <- 0}
 }

I?ve tried if(is.na(x)) {x <- NA} but I get the following error message: Error in if (x > 0) { : missing value where TRUE/FALSE needed. Which I guess is the first NA in the vector which fails the first if of the function.

I use supply() to run the function on a vector.

Thanks for any assistance.

Cheers

Alejandro

From jfox at mcmaster.ca  Fri Feb 10 01:14:49 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Fri, 10 Feb 2017 00:14:49 +0000
Subject: [R] How to include custom na.action in function
In-Reply-To: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
References: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
Message-ID: <D4C26FDA.495A%jfox@mcmaster.ca>

Dear Alejandro,

If I follow what you want to do, you can just negate the vector:

> x <- c(-10, 0, 10, NA)
> (x <- -x)
[1]  10   0 -10  NA


I hope this helps,
 John

-------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
Web: http://socserv.mcmaster.ca/jfox/




On 2017-02-09, 2:30 PM, "R-help on behalf of Alejandro"
<r-help-bounces at r-project.org on behalf of a.gonzalezvoyer at gmail.com>
wrote:

>Hello,
>
>I?ve tried googling for an answer to this but I simply can?t find
>something that fixes my problem. I have a long numerical vector with
>positive, negative and null values. I want to revert the sign of the
>positive and negative values and for zero to remain zero. I?ve written a
>function that works, except that my vector has missing values (NA) and I
>need to keep those as missing values. How could I add that to this
>function:
>
>revertsign<-function(x){
> if (x > 0) {x <- x*-1}
>   else 
>if (x < 0) {x <- abs(x)}
> else
>   if (x == 0) {x <- 0}
> }
>
>I?ve tried if(is.na(x)) {x <- NA} but I get the following error message:
>Error in if (x > 0) { : missing value where TRUE/FALSE needed. Which I
>guess is the first NA in the vector which fails the first if of the
>function.
>
>I use supply() to run the function on a vector.
>
>Thanks for any assistance.
>
>Cheers
>
>Alejandro
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Feb 10 01:16:19 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 10 Feb 2017 11:16:19 +1100
Subject: [R] How to include custom na.action in function
In-Reply-To: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
References: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
Message-ID: <CA+8X3fVJhhVL2EKM6JffRf9ucAHi5n0m3sf9P8QR2_qdsa7gfw@mail.gmail.com>

Hi Alejandro,
How about:

-sign(x) * sign(x) * x

Jim


On Fri, Feb 10, 2017 at 6:30 AM, Alejandro <a.gonzalezvoyer at gmail.com> wrote:
> Hello,
>
> I?ve tried googling for an answer to this but I simply can?t find something that fixes my problem. I have a long numerical vector with positive, negative and null values. I want to revert the sign of the positive and negative values and for zero to remain zero. I?ve written a function that works, except that my vector has missing values (NA) and I need to keep those as missing values. How could I add that to this function:
>
> revertsign<-function(x){
>  if (x > 0) {x <- x*-1}
>    else
> if (x < 0) {x <- abs(x)}
>  else
>    if (x == 0) {x <- 0}
>  }
>
> I?ve tried if(is.na(x)) {x <- NA} but I get the following error message: Error in if (x > 0) { : missing value where TRUE/FALSE needed. Which I guess is the first NA in the vector which fails the first if of the function.
>
> I use supply() to run the function on a vector.
>
> Thanks for any assistance.
>
> Cheers
>
> Alejandro
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Feb 10 01:18:21 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 9 Feb 2017 16:18:21 -0800
Subject: [R] How to include custom na.action in function
In-Reply-To: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
References: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
Message-ID: <CAGxFJbTdfLMn0z5sKF2+QHY-=DNaivyYtfu=7uyN081_xNnnwg@mail.gmail.com>

Do Not do this!

?ifelse  ## (is vectorized; or use subscripting)


> x <- c(NA,5,0,-3)

> ifelse(x>0,x-1, abs(x))
[1] NA  4  0  3


Please spend some time with an R tutorial or two -- there are many
good ones on the web. This is basic stuff covered in them.


Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 9, 2017 at 11:30 AM, Alejandro <a.gonzalezvoyer at gmail.com> wrote:
> Hello,
>
> I?ve tried googling for an answer to this but I simply can?t find something that fixes my problem. I have a long numerical vector with positive, negative and null values. I want to revert the sign of the positive and negative values and for zero to remain zero. I?ve written a function that works, except that my vector has missing values (NA) and I need to keep those as missing values. How could I add that to this function:
>
> revertsign<-function(x){
>  if (x > 0) {x <- x*-1}
>    else
> if (x < 0) {x <- abs(x)}
>  else
>    if (x == 0) {x <- 0}
>  }
>
> I?ve tried if(is.na(x)) {x <- NA} but I get the following error message: Error in if (x > 0) { : missing value where TRUE/FALSE needed. Which I guess is the first NA in the vector which fails the first if of the function.
>
> I use supply() to run the function on a vector.
>
> Thanks for any assistance.
>
> Cheers
>
> Alejandro
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Feb 10 01:25:07 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 9 Feb 2017 16:25:07 -0800
Subject: [R] How to include custom na.action in function
In-Reply-To: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
References: <BEAB18E7-851C-4D1B-8AEC-67D4FF438B79@gmail.com>
Message-ID: <CAGxFJbTFCyba4ohR-zbQhCmTrx4xPDBTcaX_pAJNWARn27+=JQ@mail.gmail.com>

Oh, after seeing John's answer, I realized I misread your x*(-1) bit
as x-1. His reply is how it should be done.

The sillier ifelse() solution is:

ifelse(x>0,-x,abs(x) )

My remark about going through a tutorial are still germane, however.

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 9, 2017 at 11:30 AM, Alejandro <a.gonzalezvoyer at gmail.com> wrote:
> Hello,
>
> I?ve tried googling for an answer to this but I simply can?t find something that fixes my problem. I have a long numerical vector with positive, negative and null values. I want to revert the sign of the positive and negative values and for zero to remain zero. I?ve written a function that works, except that my vector has missing values (NA) and I need to keep those as missing values. How could I add that to this function:
>
> revertsign<-function(x){
>  if (x > 0) {x <- x*-1}
>    else
> if (x < 0) {x <- abs(x)}
>  else
>    if (x == 0) {x <- 0}
>  }
>
> I?ve tried if(is.na(x)) {x <- NA} but I get the following error message: Error in if (x > 0) { : missing value where TRUE/FALSE needed. Which I guess is the first NA in the vector which fails the first if of the function.
>
> I use supply() to run the function on a vector.
>
> Thanks for any assistance.
>
> Cheers
>
> Alejandro
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From utz.ryan at gmail.com  Fri Feb 10 02:56:07 2017
From: utz.ryan at gmail.com (Ryan Utz)
Date: Thu, 9 Feb 2017 20:56:07 -0500
Subject: [R] Inconsistent error opening connection on URL
Message-ID: <CAKJ8KVjgTbyzWF=_Y_BBjGBc4ghaK06b4W4efPjwBSOnZQ2EuA@mail.gmail.com>

Hello,

I'm trying to automatically download online data using a URL. Half the time
the code works, the other time I get this error:

Error in file(con, "r") : cannot open the connection

But I cannot for the life of me figure out why it works sometimes and not
others. Reading online data is relatively new for me. Snooping around on
this error shows that folk use this

setInternet2(TRUE)

but that doesn't work in my case, as I just end up with this error:

Error in setInternet2(TRUE) : use != NA is defunct

Any tips on resetting a connection when such errors occur? Here's an
example of one of the specific URLs I'm trying to read:

URL.1=paste('
http://pick18.discoverlife.org/mp/20m?plot=2&kind=Hypoprepia+fucosa&site=33.9+-83.3&date1=2011,2012,2013,2014,2015&flags=build_txt:
',sep='')
readLines(URL.1)

URL.2=paste('
http://pick18.discoverlife.org/tmp/Hypoprepia_fucosa_33.9_-83.3_2011,2012,2013,2014,2015.txt
',sep='')
X=read.delim(URL.2)

Thanks,
Ryan

-- 

Ryan Utz, Ph.D.
Assistant professor of water resources
*chatham**UNIVERSITY*
Home/Cell: (724) 272-7769

	[[alternative HTML version deleted]]


From mamushbukana at gmail.com  Fri Feb 10 09:12:15 2017
From: mamushbukana at gmail.com (mamuash bukana)
Date: Fri, 10 Feb 2017 10:12:15 +0200
Subject: [R] Equality of two probabilities (proportions?)
Message-ID: <CAFxDEqJjMCgqyQ94c9rjZQ+X+znYjUfbEa4=81_iXRGk0bQmnQ@mail.gmail.com>

Dear R users,
I wanted to test if there is significant difference between
probabilities of the same event calculated in different ways. I am
aware about the prop.test() which does the comparison between two
proportions given the number of successes and sample sizes. But in my
case the only values I do have are the probabilities the event.

Your kind suggestions will be very appreciated.

Mamuash


From r.turner at auckland.ac.nz  Fri Feb 10 09:42:33 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 10 Feb 2017 21:42:33 +1300
Subject: [R] [FORGED]  Equality of two probabilities (proportions?)
In-Reply-To: <CAFxDEqJjMCgqyQ94c9rjZQ+X+znYjUfbEa4=81_iXRGk0bQmnQ@mail.gmail.com>
References: <CAFxDEqJjMCgqyQ94c9rjZQ+X+znYjUfbEa4=81_iXRGk0bQmnQ@mail.gmail.com>
Message-ID: <ccf57dc3-c388-3148-9427-1a78d18832b6@auckland.ac.nz>


On 10/02/17 21:12, mamuash bukana wrote:

> Dear R users,
> I wanted to test if there is significant difference between
> probabilities of the same event calculated in different ways. I am
> aware about the prop.test() which does the comparison between two
> proportions given the number of successes and sample sizes. But in my
> case the only values I do have are the probabilities the event.
>
> Your kind suggestions will be very appreciated.

I think that it is pretty clear from your question that you are way out 
of your depth and that you do not understand the concept of "significant 
difference".

You should therefore seek help from a competent local statistician.

Although I could be wrong about my estimate of your depth of 
understanding, it is at the very least true that you need to read the 
posting guide carefully and learn how to ask a question that actually 
makes sense, includes necessary details, and gives list members a 
fighting chance of providing a meaningful answer.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From mamushbukana at gmail.com  Fri Feb 10 12:27:31 2017
From: mamushbukana at gmail.com (mamuash bukana)
Date: Fri, 10 Feb 2017 13:27:31 +0200
Subject: [R] [FORGED]  Equality of two probabilities (proportions?)
In-Reply-To: <ccf57dc3-c388-3148-9427-1a78d18832b6@auckland.ac.nz>
References: <CAFxDEqJjMCgqyQ94c9rjZQ+X+znYjUfbEa4=81_iXRGk0bQmnQ@mail.gmail.com>
	<ccf57dc3-c388-3148-9427-1a78d18832b6@auckland.ac.nz>
Message-ID: <CAFxDEqJPSBh1LAkcx6Ko2pA9DBcRxFkuq3+0EK9PnX+J6dv8GA@mail.gmail.com>

Suppose we calculate probability of an event using Binomial
distribution and got p1. Then probability of that same event is
calculated using the Normal approximation to Binomial and got p2.
Can't we evaluate the goodness of our approximation by comparing the
difference between p1&p2? If yes, how to implement this in R?

I wouldn't have been here seeking for help if I had that "deep"
understanding of the issue under question Rolf!


M

On Fri, Feb 10, 2017 at 10:42 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 10/02/17 21:12, mamuash bukana wrote:
>
>> Dear R users,
>> I wanted to test if there is significant difference between
>> probabilities of the same event calculated in different ways. I am
>> aware about the prop.test() which does the comparison between two
>> proportions given the number of successes and sample sizes. But in my
>> case the only values I do have are the probabilities the event.
>>
>> Your kind suggestions will be very appreciated.
>
>
> I think that it is pretty clear from your question that you are way out of
> your depth and that you do not understand the concept of "significant
> difference".
>
> You should therefore seek help from a competent local statistician.
>
> Although I could be wrong about my estimate of your depth of understanding,
> it is at the very least true that you need to read the posting guide
> carefully and learn how to ask a question that actually makes sense,
> includes necessary details, and gives list members a fighting chance of
> providing a meaningful answer.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From lists at dewey.myzen.co.uk  Fri Feb 10 13:14:35 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 10 Feb 2017 12:14:35 +0000
Subject: [R] [FORGED] Equality of two probabilities (proportions?)
In-Reply-To: <CAFxDEqJPSBh1LAkcx6Ko2pA9DBcRxFkuq3+0EK9PnX+J6dv8GA@mail.gmail.com>
References: <CAFxDEqJjMCgqyQ94c9rjZQ+X+znYjUfbEa4=81_iXRGk0bQmnQ@mail.gmail.com>
	<ccf57dc3-c388-3148-9427-1a78d18832b6@auckland.ac.nz>
	<CAFxDEqJPSBh1LAkcx6Ko2pA9DBcRxFkuq3+0EK9PnX+J6dv8GA@mail.gmail.com>
Message-ID: <6387069f-bb1b-8373-4922-b5bccdd724fc@dewey.myzen.co.uk>

Dear Mamuash

I expect you will shortly get an email telling you that this is 
off-topic as it is about statistics not R but in the mean time you might 
search for "scoring rules" or even "Brier score". I am afraid I am not 
an expert in this area and they possibly do not answer your question but 
worth a try.

On 10/02/2017 11:27, mamuash bukana wrote:
> Suppose we calculate probability of an event using Binomial
> distribution and got p1. Then probability of that same event is
> calculated using the Normal approximation to Binomial and got p2.
> Can't we evaluate the goodness of our approximation by comparing the
> difference between p1&p2? If yes, how to implement this in R?
>
> I wouldn't have been here seeking for help if I had that "deep"
> understanding of the issue under question Rolf!
>
>
> M
>
> On Fri, Feb 10, 2017 at 10:42 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> On 10/02/17 21:12, mamuash bukana wrote:
>>
>>> Dear R users,
>>> I wanted to test if there is significant difference between
>>> probabilities of the same event calculated in different ways. I am
>>> aware about the prop.test() which does the comparison between two
>>> proportions given the number of successes and sample sizes. But in my
>>> case the only values I do have are the probabilities the event.
>>>
>>> Your kind suggestions will be very appreciated.
>>
>>
>> I think that it is pretty clear from your question that you are way out of
>> your depth and that you do not understand the concept of "significant
>> difference".
>>
>> You should therefore seek help from a competent local statistician.
>>
>> Although I could be wrong about my estimate of your depth of understanding,
>> it is at the very least true that you need to read the posting guide
>> carefully and learn how to ask a question that actually makes sense,
>> includes necessary details, and gives list members a fighting chance of
>> providing a meaningful answer.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter.4567 at gmail.com  Fri Feb 10 17:03:34 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 10 Feb 2017 08:03:34 -0800
Subject: [R] [FORGED] Equality of two probabilities (proportions?)
In-Reply-To: <CAFxDEqJPSBh1LAkcx6Ko2pA9DBcRxFkuq3+0EK9PnX+J6dv8GA@mail.gmail.com>
References: <CAFxDEqJjMCgqyQ94c9rjZQ+X+znYjUfbEa4=81_iXRGk0bQmnQ@mail.gmail.com>
	<ccf57dc3-c388-3148-9427-1a78d18832b6@auckland.ac.nz>
	<CAFxDEqJPSBh1LAkcx6Ko2pA9DBcRxFkuq3+0EK9PnX+J6dv8GA@mail.gmail.com>
Message-ID: <CAGxFJbQM4GcfxaccptJw6dc_qjtBONREqhTPKV3Muti9_-B64g@mail.gmail.com>

IMHO, You were given an appropriate answer. Please follow its advice.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 10, 2017 at 3:27 AM, mamuash bukana <mamushbukana at gmail.com> wrote:
> Suppose we calculate probability of an event using Binomial
> distribution and got p1. Then probability of that same event is
> calculated using the Normal approximation to Binomial and got p2.
> Can't we evaluate the goodness of our approximation by comparing the
> difference between p1&p2? If yes, how to implement this in R?
>
> I wouldn't have been here seeking for help if I had that "deep"
> understanding of the issue under question Rolf!
>
>
> M
>
> On Fri, Feb 10, 2017 at 10:42 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> On 10/02/17 21:12, mamuash bukana wrote:
>>
>>> Dear R users,
>>> I wanted to test if there is significant difference between
>>> probabilities of the same event calculated in different ways. I am
>>> aware about the prop.test() which does the comparison between two
>>> proportions given the number of successes and sample sizes. But in my
>>> case the only values I do have are the probabilities the event.
>>>
>>> Your kind suggestions will be very appreciated.
>>
>>
>> I think that it is pretty clear from your question that you are way out of
>> your depth and that you do not understand the concept of "significant
>> difference".
>>
>> You should therefore seek help from a competent local statistician.
>>
>> Although I could be wrong about my estimate of your depth of understanding,
>> it is at the very least true that you need to read the posting guide
>> carefully and learn how to ask a question that actually makes sense,
>> includes necessary details, and gives list members a fighting chance of
>> providing a meaningful answer.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From simon.urbanek at r-project.org  Fri Feb 10 22:08:55 2017
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 10 Feb 2017 16:08:55 -0500
Subject: [R] R under OS X El Capitan 10.11.2
In-Reply-To: <CAG8VtR1=QnLeBmu8dtN+sHEX88NT-izbQvmZC5Pvh+V765T0=A@mail.gmail.com>
References: <CAG8VtR1=QnLeBmu8dtN+sHEX88NT-izbQvmZC5Pvh+V765T0=A@mail.gmail.com>
Message-ID: <8B5C7CDE-506D-4180-BA2D-0AD0FC46BE4E@r-project.org>

Please use R-SIG-Mac and include important details such as your sessionInfo() as well as how you installed the packages. Also make sure you have re-installed Rcpp and that you don't have an older version on your library path.

Cheers,
Simon



> On Jan 1, 2016, at 9:54 PM, Paul Schlesinger <phschlesinger at gmail.com> wrote:
> 
> Since Apple upgrade to 10.11.2 and the new version ggplot2 running
> library(ggplot2) gives the following
> 
> Error in library.dynam(lib, package, package.lib) :
>  shared object ?Rcpp.so? not found
> Error: package or namespace load failed for ?ggplot2?
> 
> Updating all packages went without errors but did not correct this error.
> Re-installing R did not correct the situation and similar errors occur in
> Studio.  This same R version and ggplot2 on Windows 7 did not produce these
> error and is why I do not suspect ggplot2.
> 
> Thank you
> -- 
> Paul H. Schlesinger MD, PhD
> Washington University School of Medicine
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Feb 10 22:53:40 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 11 Feb 2017 10:53:40 +1300
Subject: [R] [FORGED]  Equality of two probabilities (proportions?)
In-Reply-To: <CAFxDEqJPSBh1LAkcx6Ko2pA9DBcRxFkuq3+0EK9PnX+J6dv8GA@mail.gmail.com>
References: <CAFxDEqJjMCgqyQ94c9rjZQ+X+znYjUfbEa4=81_iXRGk0bQmnQ@mail.gmail.com>
	<ccf57dc3-c388-3148-9427-1a78d18832b6@auckland.ac.nz>
	<CAFxDEqJPSBh1LAkcx6Ko2pA9DBcRxFkuq3+0EK9PnX+J6dv8GA@mail.gmail.com>
Message-ID: <e043de4b-38a6-5c2a-4f11-9b180daa1e04@auckland.ac.nz>


On 11/02/17 00:27, mamuash bukana wrote:

> Suppose we calculate probability of an event using Binomial
> distribution and got p1. Then probability of that same event is
> calculated using the Normal approximation to Binomial and got p2.
> Can't we evaluate the goodness of our approximation by comparing the
> difference between p1&p2? If yes, how to implement this in R?
>
> I wouldn't have been here seeking for help if I had that "deep"
> understanding of the issue under question Rolf!

In your original post you asked about whether the difference was 
"statistically significant".  As I suspected, the question is totally 
inappropriate.  The concept of "statistical significance" does not apply 
in this context.  There are no statistics; there are only calculations 
of probabilities.

As I said, you are out of your depth and need to learn the basics of the 
subject that you are trying to deal with.  Learn to walk before you try 
to run.  There are no short cuts to an understanding of probability and 
statistics.  A lot of hard graft is required.

Michael Dewey's suggestion of studying "scoring rules" or the "Brier 
score" might be useful to you, but you need to get the basic principles 
of the subject (probability and statistics) straight in your mind before 
you dive into these ideas.

As others have said, this issue is off topic for this list.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From tdehdari at gmail.com  Sat Feb 11 12:55:40 2017
From: tdehdari at gmail.com (Tahereh Dehdarirad)
Date: Sat, 11 Feb 2017 15:25:40 +0330
Subject: [R] Independent samples bootstrapped T-test : question
Message-ID: <CAJGnSAMSU0Pr6M4REy39HYDM0Nx-LxktjZXjw2oiJHtKAW0xTA@mail.gmail.com>

Dear R group,

I have some question regarding bootstrapping in R. I wish to use
independent samples bootstrapped T-test. I would like to know: 1 how  I can
 calculate p and t values.2. for means and CI of each sample, should I
report the bootstrapped mean and CI of each group? and not the ones
obtained from t-test?

I used the following code with regard to t-test (t value and p value), So,
I wonder if it is correct with regard to t and p values?

AVGMR=Names_first_last$`Avg_ Readars-Mendeley`

B      <- 1000
t.star = numeric(B)
 t.vect <- vector(length=B)
p.vect <- vector(length=B)
for(i in 1:B){ boot.c <- sample(subset(AVGMR, Gender==1), replace=T)
boot.c <- sample(subset(AVGMR, Gender==2), replace=T)
ttest  <- t.test(boot.c, boot.p)
   t.vect[i] <- ttest$statistic
   p.vect[i] <- ttest$p.value
 }

I would be really grateful if you could please help me with regard to my
both questions.

Kind regards,

Tahereh Dehdarirad, PhD
Department of Library and Information Science
University of Barcelona, Spain

	[[alternative HTML version deleted]]


From vodvos at zoho.com  Sat Feb 11 12:15:10 2017
From: vodvos at zoho.com (vod vos)
Date: Sat, 11 Feb 2017 03:15:10 -0800
Subject: [R] How to disable verbose grob results in pdf when using knitr
 with gridExtra?
Message-ID: <15a2ce2429f.c2789ed0280.8497138545484174752@zoho.com>

Hi every one,



I am using Knitr, R and Latex to produce pdf file. When using gridExtra to set up a gtable layout to place multiple grobs on a page,

 

grid.arrange(facetpoint1,pright1,pright2,pright3,pright4,pright5,pright6,pright7, ncol=2, layout_matrix=cbind(c(1,1,1,1,1,1,1),c(2,3,4,5,6,7,8)), widths=c(2,1))



the verbose of the infomation shows before the one figure in the pdf file:



## TableGrob (7 x 2) "arrange": 8 grobs ## z cells name grob ## 1 1 (1-7,1-1) arrange gtable[layout] ## 2 2 (1-1,2-2) arrange gtable[layout] ## 3 3 (2-2,2-2) arrange gtable[layout] ## 4 4 (3-3,2-2) arrange gtable[layout] ## 5 5 (4-4,2-2) arrange gtable[layout] ## 6 6 (5-5,2-2) arrange gtable[layout] ## 7 7 (6-6,2-2) arrange gtable[layout] ## 8 8 (7-7,2-2) arrange gtable[layout] 






When I ?grid.arrange, no ways were found to disable the verbose in the pdf file. Any ideas? 



Thanks.


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Feb 11 16:45:54 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Feb 2017 07:45:54 -0800 (PST)
Subject: [R] How to disable verbose grob results in pdf when using knitr
 with gridExtra?
In-Reply-To: <15a2ce2429f.c2789ed0280.8497138545484174752@zoho.com>
References: <15a2ce2429f.c2789ed0280.8497138545484174752@zoho.com>
Message-ID: <alpine.BSF.2.00.1702110719050.71951@pedal.dcn.davis.ca.us>

On Sat, 11 Feb 2017, vod vos wrote:

> Hi every one,
>
> I am using Knitr,

Keep in mind that this list is about R first and foremost. There is a 
mailing list for Knitr, and also the maintainer of the knitr package 
recommends asking questions on stackoverflow.com.

> R and Latex to produce pdf file. When using gridExtra to set up a
> gtable layout to place multiple grobs on a page,
>
> grid.arrange(facetpoint1,pright1,pright2,pright3,pright4,pright5,pright6,pright7, ncol=2, layout_matrix=cbind(c(1,1,1,1,1,1,1),c(2,3,4,5,6,7,8)), widths=c(2,1))

This is not a reproducible example. No matter where you ask this question 
you need to supply a complete short script that exhibits the problem. That 
also means including enough data IN THE SCRIPT to allow the script to 
run. There are multiple guides online that describe how to do this in 
detail.

> the verbose of the infomation shows before the one figure in the pdf file:
>
> ## TableGrob (7 x 2) "arrange": 8 grobs ## z cells name grob ## 1 1 (1-7,1-1) arrange gtable[layout] ## 2 2 (1-1,2-2) arrange gtable[layout] ## 3 3 (2-2,2-2) arrange gtable[layout] ## 4 4 (3-3,2-2) arrange gtable[layout] ## 5 5 (4-4,2-2) arrange gtable[layout] ## 6 6 (5-5,2-2) arrange gtable[layout] ## 7 7 (6-6,2-2) arrange gtable[layout] ## 8 8 (7-7,2-2) arrange gtable[layout]

None of this appears when I created my own reproducible R example:

#### begin code
library(grid)
library(gridExtra)

facetpoint1 <- pright1 <- pright2 <- pright3 <- pright4 <- pright5 <- 
pright6 <- pright7  <- textGrob("X")
grid.arrange( facetpoint1, pright1, pright2, pright3, pright4, pright5
             , pright6, pright7
             , ncol=2
             , layout_matrix = cbind( c( 1, 1, 1, 1, 1, 1, 1 )
                                    , c( 2, 3, 4, 5, 6, 7, 8 ) )
             , widths = c( 2, 1 )
             )
#### end code

If the above example produces output for you in R or in a knitted PDF then 
something is different about your setup than mine.

> When I ?grid.arrange, no ways were found to disable the verbose in the pdf file. Any ideas?

Does this happen at the R console? If it does, please post a reproducible 
example, and the invocation and output of sessionInfo() (mine is below). 
If it doesn't, there could be some interaction with knitr going on, and 
using the echo=FALSE or warnings=FALSE chunk options could help, or you 
may need more specialized help than we can offer here (e.g. via one of 
the knitr support areas mentioned above).

> Thanks.
>
> 	[[alternative HTML version deleted]]

When you don't set your email to plain text, the automatic conversion of 
HTML to text is very likely to cause us to see something quite different 
than you were looking at. It is in your best interest to figure out how to 
set your email program to send plain text. Please read the Posting Guide:

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.5 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C 
LC_TIME=en_US.UTF-8
  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8 
LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 
LC_IDENTIFICATION=C

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods 
base

other attached packages:
[1] gridExtra_2.2.1

loaded via a namespace (and not attached):
  [1] backports_1.0.4 magrittr_1.5    rprojroot_1.1   htmltools_0.3.5 
tools_3.3.2
  [6] gtable_0.2.0    yaml_2.1.14     Rcpp_0.12.8     stringi_1.1.2 
rmarkdown_1.3
[11] knitr_1.15.1    stringr_1.1.0   digest_0.6.11   evaluate_0.10


From bgunter.4567 at gmail.com  Sat Feb 11 16:46:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 11 Feb 2017 07:46:14 -0800
Subject: [R] Independent samples bootstrapped T-test : question
In-Reply-To: <CAJGnSAMSU0Pr6M4REy39HYDM0Nx-LxktjZXjw2oiJHtKAW0xTA@mail.gmail.com>
References: <CAJGnSAMSU0Pr6M4REy39HYDM0Nx-LxktjZXjw2oiJHtKAW0xTA@mail.gmail.com>
Message-ID: <CAGxFJbQQ1n3iMZSpRFw=BhJUP2+nnZj5zxbKk2_ma2pHZq2vzw@mail.gmail.com>

This is really a statistical question and not about R, and purely
statistical questions are typically off topic here. I note that there
is a "boot" package that you may wish to consider, and searching on
"bootstrapping" on rseek.org -- which you should always do before
posting here -- produced what looked like a number of relevant hits.
Otherwise, try posting your question on stats.stackexchange.com, which
*is* concerned with statistical issues.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 11, 2017 at 3:55 AM, Tahereh Dehdarirad <tdehdari at gmail.com> wrote:
> Dear R group,
>
> I have some question regarding bootstrapping in R. I wish to use
> independent samples bootstrapped T-test. I would like to know: 1 how  I can
>  calculate p and t values.2. for means and CI of each sample, should I
> report the bootstrapped mean and CI of each group? and not the ones
> obtained from t-test?
>
> I used the following code with regard to t-test (t value and p value), So,
> I wonder if it is correct with regard to t and p values?
>
> AVGMR=Names_first_last$`Avg_ Readars-Mendeley`
>
> B      <- 1000
> t.star = numeric(B)
>  t.vect <- vector(length=B)
> p.vect <- vector(length=B)
> for(i in 1:B){ boot.c <- sample(subset(AVGMR, Gender==1), replace=T)
> boot.c <- sample(subset(AVGMR, Gender==2), replace=T)
> ttest  <- t.test(boot.c, boot.p)
>    t.vect[i] <- ttest$statistic
>    p.vect[i] <- ttest$p.value
>  }
>
> I would be really grateful if you could please help me with regard to my
> both questions.
>
> Kind regards,
>
> Tahereh Dehdarirad, PhD
> Department of Library and Information Science
> University of Barcelona, Spain
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Feb 11 17:09:36 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Feb 2017 08:09:36 -0800 (PST)
Subject: [R] RStudio: Place for Storing Options
In-Reply-To: <22684.34149.431821.945334@stat.math.ethz.ch>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
	<22684.34149.431821.945334@stat.math.ethz.ch>
Message-ID: <alpine.BSF.2.00.1702110801470.71951@pedal.dcn.davis.ca.us>

For the record, then, Google listened to my incantation of "rstudio 
configuration file" and the second result was:

https://support.rstudio.com/hc/en-us/articles/200534577-Resetting-RStudio-Desktop-s-State

RStudio Desktop is also open source, so you can download the source 
code and look at the operating-system-specific bits (for "where") if the 
above link goes out of date or disappears.

On Thu, 9 Feb 2017, Martin Maechler wrote:

>
>>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>>>>>     on Thu, 9 Feb 2017 14:37:57 +0000 writes:
>
>    > Hi Georg,
>    > maybe someone here knows, but I think you are more likely to get answers to
>    > Rstudio related questions with RStudio support:
>    > https://support.rstudio.com/hc/en-us
>
>    > Best,
>    > Ulrik
>
> Indeed, thank you, Ulrik.
>
> In this special case, however, I'm quite sure many readers of
> R-help would be interested in the answer; so once you receive an
> answer, please post it (or a link to a public URL with it) here
> on R-help, thank you in advance.
>
> We would like to be able to *save*, or sometimes *set* / *reset*
> such options  "in a scripted manner", e.g. for
> controlled exam sessions.
>
> Martin Maechler,
> ETH Zurich
>
>    > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de> wrote:
>
>    >> Hi All,
>    >> I would like to make a backup of my RStudio IDE options I configure using
>    >> "Tools/Global Options" from the menu bar. Searching the
>    >> web did not reveal anything.
>
>    >> Can you tell me where RStudio IDE does store its configuration?
>
>    >> Kind regards
>    >> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From reichmanj at sbcglobal.net  Sat Feb 11 17:26:33 2017
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Sat, 11 Feb 2017 10:26:33 -0600
Subject: [R] Plotting Landscape in R-Studio
Message-ID: <000601d28483$9c6f7ca0$d54e75e0$@sbcglobal.net>

R-Help

 

How can I format a plot within R-Studio  (Plot Windows) to conform to an 8.5
x 11-  landscape.  Such that when I Export - Copy to Clip board I can past
plot into word.

 

Jeff


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Feb 11 18:01:47 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 11 Feb 2017 09:01:47 -0800
Subject: [R] Plotting Landscape in R-Studio
In-Reply-To: <000601d28483$9c6f7ca0$d54e75e0$@sbcglobal.net>
References: <000601d28483$9c6f7ca0$d54e75e0$@sbcglobal.net>
Message-ID: <0AEE48AA-DBE7-4F46-BAB1-C948AE76ECEA@comcast.net>


> On Feb 11, 2017, at 8:26 AM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> 
> R-Help
> 
> 
> 
> How can I format a plot within R-Studio  (Plot Windows) to conform to an 8.5
> x 11-  landscape.  Such that when I Export - Copy to Clip board I can past
> plot into word.
> 

This is really the wrong venue for asking questions about transferring graphics from RStudio to Word. Two other options: RStudio has its own help forum and this would probably be an OK question if you constructed a minimal verifiable example to submit to StackOverflow.


> 
> 
> Jeff
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sat Feb 11 20:13:21 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Feb 2017 11:13:21 -0800
Subject: [R] Plotting Landscape in R-Studio
In-Reply-To: <0AEE48AA-DBE7-4F46-BAB1-C948AE76ECEA@comcast.net>
References: <000601d28483$9c6f7ca0$d54e75e0$@sbcglobal.net>
	<0AEE48AA-DBE7-4F46-BAB1-C948AE76ECEA@comcast.net>
Message-ID: <8978F7E5-8EB0-4EC6-9746-8BECF60A3614@dcn.davis.ca.us>

While the question AS POSED is off base here (and in fact unlikely to have any satisfactory answer due to the unavoidable squishiness of pasted graphics in Word), the OP could investigate the ReporteRs package which can export graphics directly to word files in a fairly predictable manner, including creating landscape oriented sections. 
-- 
Sent from my phone. Please excuse my brevity.

On February 11, 2017 9:01:47 AM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Feb 11, 2017, at 8:26 AM, Jeff Reichman <reichmanj at sbcglobal.net>
>wrote:
>> 
>> R-Help
>> 
>> 
>> 
>> How can I format a plot within R-Studio  (Plot Windows) to conform to
>an 8.5
>> x 11-  landscape.  Such that when I Export - Copy to Clip board I can
>past
>> plot into word.
>> 
>
>This is really the wrong venue for asking questions about transferring
>graphics from RStudio to Word. Two other options: RStudio has its own
>help forum and this would probably be an OK question if you constructed
>a minimal verifiable example to submit to StackOverflow.
>
>
>> 
>> 
>> Jeff
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sat Feb 11 23:08:19 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 11 Feb 2017 23:08:19 +0100
Subject: [R] Plotting Landscape in R-Studio
In-Reply-To: <8978F7E5-8EB0-4EC6-9746-8BECF60A3614@dcn.davis.ca.us>
References: <000601d28483$9c6f7ca0$d54e75e0$@sbcglobal.net>
	<0AEE48AA-DBE7-4F46-BAB1-C948AE76ECEA@comcast.net>
	<8978F7E5-8EB0-4EC6-9746-8BECF60A3614@dcn.davis.ca.us>
Message-ID: <DD3F514E-7E20-45F2-93D3-A0FAB90B8DAF@gmail.com>


> On 11 Feb 2017, at 20:13 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> While the question AS POSED is off base here (and in fact unlikely to have any satisfactory answer due to the unavoidable squishiness of pasted graphics in Word),

I did wonder whether it wouldn't be easier just to export to a (PDF? WMF?) file and import that in Word. That looks like a no-brainer from the RStudio side. Or write directly to the appropriate device.

-pd


> the OP could investigate the ReporteRs package which can export graphics directly to word files in a fairly predictable manner, including creating landscape oriented sections. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 11, 2017 9:01:47 AM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Feb 11, 2017, at 8:26 AM, Jeff Reichman <reichmanj at sbcglobal.net>
>> wrote:
>>> 
>>> R-Help
>>> 
>>> 
>>> 
>>> How can I format a plot within R-Studio  (Plot Windows) to conform to
>> an 8.5
>>> x 11-  landscape.  Such that when I Export - Copy to Clip board I can
>> past
>>> plot into word.
>>> 
>> 
>> This is really the wrong venue for asking questions about transferring
>> graphics from RStudio to Word. Two other options: RStudio has its own
>> help forum and this would probably be an OK question if you constructed
>> a minimal verifiable example to submit to StackOverflow.
>> 
>> 
>>> 
>>> 
>>> Jeff
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From acefix at rocketmail.com  Sat Feb 11 19:33:04 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Sat, 11 Feb 2017 18:33:04 +0000 (UTC)
Subject: [R] get() return nothing
In-Reply-To: <1718993451.2837139.1485682314808@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
Message-ID: <1020994841.500566.1486837984563@mail.yahoo.com>

Hello, there,
I wrote a loop to check the dimension of all the .txt dataframes:> ls()
?[1] "actualpca.table" "b4galnt2"??????? "b4galnt2.txt"??? "data"
?[5] "galnt4"????????? "galnt4.txt"????? "galnt5"????????? "galnt5.txt"
?[9] "galnt6"????????? "galnt6.txt"????? "glyco"?????????? "glyco.txt"
[13] "i"?????????????? "mtscaled"??????? "newsig.table"??? "nicepca"
[17] "pca"???????????? "sig.txt"???????? "st3gal3"???????? "st3gal3.txt"
[21] "st3gal5"???????? "st3gal5.txt"???? "st6gal1"???????? "st6gal1.txt"
> for(i in ls(pattern="txt")){dim(get(i))}
>
If I check individual ones, they are ok:
> dim(get("galnt4.txt"))
[1] 8 3
>
could anyone help me to figure out why it did not work with a loop?
Thanks a lot!

Ace






 

  
  
	[[alternative HTML version deleted]]


From bhaskar.kolkata at gmail.com  Sun Feb 12 01:13:43 2017
From: bhaskar.kolkata at gmail.com (Bhaskar Mitra)
Date: Sat, 11 Feb 2017 19:13:43 -0500
Subject: [R] Query - Merging and conditional replacement of values in a data
	frame
Message-ID: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>

Hello Everyone,

I have two data frames df1 and df2 as shown below. They
are of different length. However, they have one common column - time.

df1 <-
time v1  v2 v3
1     2   3  4
2     5   6  4
3     1   3  4
4     1   3  4
5     2   3  4
6     2   3  4


df2 <-
time v11  v12 v13
3     112   3  4
4     112   3  4

By matching the 'time' column in df1 and df2, I am trying to modify column
'v1' in df1 by replacing it
with values in column 'v11' in df2. The modified df1 should look something
like this:

df1 <-
time v1   v2 v3
1     2   3  4
2     5   6  4
3     112 3  4
4     112 3  4
5     2   3  4
6     2   3  4

I tried to use the 'merge' function to combine df1 and df2 followed by
the conditional 'ifelse' statement. However, that doesn't seem to work.

Can I replace the values in df1 by not merging the two data frames?

Thanks for your help,

Regards,
Bhaskar

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Feb 12 01:53:38 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 11 Feb 2017 19:53:38 -0500
Subject: [R] get() return nothing
In-Reply-To: <1020994841.500566.1486837984563@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
	<1020994841.500566.1486837984563@mail.yahoo.com>
Message-ID: <8f6e9c10-be6b-c6de-6120-ae9c0d385d38@gmail.com>

On 11/02/2017 1:33 PM, Fix Ace via R-help wrote:
> Hello, there,
> I wrote a loop to check the dimension of all the .txt dataframes:> ls()
>  [1] "actualpca.table" "b4galnt2"        "b4galnt2.txt"    "data"
>  [5] "galnt4"          "galnt4.txt"      "galnt5"          "galnt5.txt"
>  [9] "galnt6"          "galnt6.txt"      "glyco"           "glyco.txt"
> [13] "i"               "mtscaled"        "newsig.table"    "nicepca"
> [17] "pca"             "sig.txt"         "st3gal3"         "st3gal3.txt"
> [21] "st3gal5"         "st3gal5.txt"     "st6gal1"         "st6gal1.txt"
>> for(i in ls(pattern="txt")){dim(get(i))}
>>
> If I check individual ones, they are ok:
>> dim(get("galnt4.txt"))
> [1] 8 3
>>
> could anyone help me to figure out why it did not work with a loop?
> Thanks a lot!

It's the difference between

for (i in 1:10) i

(which prints nothing) and

for (i in 1:10) print(i)

Duncan Murdoch


From bgunter.4567 at gmail.com  Sun Feb 12 03:43:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 11 Feb 2017 18:43:39 -0800
Subject: [R] Query - Merging and conditional replacement of values in a
 data frame
In-Reply-To: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
References: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
Message-ID: <CAGxFJbRAftXFozskjT4vRuL6SefUfL+1K+qtPUpCnPf=jwvHTQ@mail.gmail.com>

Your "assignments" (<-) are not legitimate R code that can be cut and
pasted. Learn to use dput() to provide examples that we can use.

You fail to say whether the time column of df2 is a proper subset of
df1 or may contain times not in df1. I shall assume the latter. You
also did not say whether the time values occur in order in both data
frames. I shall assume they do not.

If I understand correctly,then,  match and subscripting will do it,
something like


> df1 <-data.frame(time = 1:6, v1 = c(2,5,1,1,2,2))
> df2 <- data.frame(time = 4:3,v11 = c(112,113))

> wm <- match(df1$time,df2$time)
> df1[!is.na(wm),"v1"] <- df2[na.omit(wm),"v11"]

> df1

  time  v1
1    1   2
2    2   5
3    3 113
4    4 112
5    5   2
6    6   2

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 11, 2017 at 4:13 PM, Bhaskar Mitra
<bhaskar.kolkata at gmail.com> wrote:
> Hello Everyone,
>
> I have two data frames df1 and df2 as shown below. They
> are of different length. However, they have one common column - time.
>
> df1 <-
> time v1  v2 v3
> 1     2   3  4
> 2     5   6  4
> 3     1   3  4
> 4     1   3  4
> 5     2   3  4
> 6     2   3  4
>
>
> df2 <-
> time v11  v12 v13
> 3     112   3  4
> 4     112   3  4
>
> By matching the 'time' column in df1 and df2, I am trying to modify column
> 'v1' in df1 by replacing it
> with values in column 'v11' in df2. The modified df1 should look something
> like this:
>
> df1 <-
> time v1   v2 v3
> 1     2   3  4
> 2     5   6  4
> 3     112 3  4
> 4     112 3  4
> 5     2   3  4
> 6     2   3  4
>
> I tried to use the 'merge' function to combine df1 and df2 followed by
> the conditional 'ifelse' statement. However, that doesn't seem to work.
>
> Can I replace the values in df1 by not merging the two data frames?
>
> Thanks for your help,
>
> Regards,
> Bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Sun Feb 12 06:02:33 2017
From: valkremk at gmail.com (Val)
Date: Sat, 11 Feb 2017 23:02:33 -0600
Subject: [R] remove
Message-ID: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>

Hi all,
I have a big data set and want to  remove rows conditionally.
In my data file  each person were recorded  for several weeks. Somehow
during the recording periods, their last name was misreported.   For
each person,   the last name should be the same. Otherwise remove from
the data. Example, in the following data set, Alex was found to have
two last names .

Alex   West
Alex   Joseph

Alex should be removed  from the data.  if this happens then I want
remove  all rows with Alex. Here is my data set

df <- read.table(header=TRUE, text='first  week last
Alex    1  West
Bob     1  John
Cory    1  Jack
Cory    2  Jack
Bob     2  John
Bob     3  John
Alex    2  Joseph
Alex    3  West
Alex    4  West ')

Desired output

      first  week last
1     Bob     1   John
2     Bob     2   John
3     Bob     3   John
4     Cory     1   Jack
5     Cory     2   Jack

Thank you in advance


From syen04 at gmail.com  Sun Feb 12 06:14:54 2017
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 12 Feb 2017 13:14:54 +0800
Subject: [R] Echos for comment line (with #)
Message-ID: <e396abb8-3f02-d515-301c-dfaa33484c7c@gmail.com>

I need help with what may be a simple option in R (or Rstudio)--to 
receive an echo of a comment line.

Running the following two-line script in plain R,

# adding
1+2

I did get the echo:

 > # adding
 > 1+2
[1] 3
 >

However, running the same lines in RStudio, the comment line does not 
appear in output:

 > 1+2
[1] 3
 >

Please help. Thanks.



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Feb 12 06:36:21 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 11 Feb 2017 21:36:21 -0800
Subject: [R] remove
In-Reply-To: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
Message-ID: <CAGxFJbSh-CZoXLyXts8XSi_7t9wD-dp+AkniQeOfGFtXFniecw@mail.gmail.com>

Basic stuff!

Either subscripting or ?subset.

There are many good R tutorials on the web. You should spend some
(more?) time with some.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 11, 2017 at 9:02 PM, Val <valkremk at gmail.com> wrote:
> Hi all,
> I have a big data set and want to  remove rows conditionally.
> In my data file  each person were recorded  for several weeks. Somehow
> during the recording periods, their last name was misreported.   For
> each person,   the last name should be the same. Otherwise remove from
> the data. Example, in the following data set, Alex was found to have
> two last names .
>
> Alex   West
> Alex   Joseph
>
> Alex should be removed  from the data.  if this happens then I want
> remove  all rows with Alex. Here is my data set
>
> df <- read.table(header=TRUE, text='first  week last
> Alex    1  West
> Bob     1  John
> Cory    1  Jack
> Cory    2  Jack
> Bob     2  John
> Bob     3  John
> Alex    2  Joseph
> Alex    3  West
> Alex    4  West ')
>
> Desired output
>
>       first  week last
> 1     Bob     1   John
> 2     Bob     2   John
> 3     Bob     3   John
> 4     Cory     1   Jack
> 5     Cory     2   Jack
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From philipt900 at iinet.net.au  Sun Feb 12 06:39:26 2017
From: philipt900 at iinet.net.au (P Tennant)
Date: Sun, 12 Feb 2017 16:39:26 +1100
Subject: [R] remove
In-Reply-To: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
Message-ID: <589FF50E.8040009@iinet.net.au>

Hi Val,

The by() function could be used here. With the dataframe dfr:

# split the data by first name and check for more than one last name for 
each first name
res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
# make the result more easily manipulated
res <- as.table(res)
res
# first
  # Alex   Bob  Cory
  # TRUE FALSE FALSE

# then use this result to subset the data
nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
# sort if needed
nw.dfr[order(nw.dfr$first) , ]

   first week last
2   Bob    1 John
5   Bob    2 John
6   Bob    3 John
3  Cory    1 Jack
4  Cory    2 Jack


Philip

On 12/02/2017 4:02 PM, Val wrote:
> Hi all,
> I have a big data set and want to  remove rows conditionally.
> In my data file  each person were recorded  for several weeks. Somehow
> during the recording periods, their last name was misreported.   For
> each person,   the last name should be the same. Otherwise remove from
> the data. Example, in the following data set, Alex was found to have
> two last names .
>
> Alex   West
> Alex   Joseph
>
> Alex should be removed  from the data.  if this happens then I want
> remove  all rows with Alex. Here is my data set
>
> df<- read.table(header=TRUE, text='first  week last
> Alex    1  West
> Bob     1  John
> Cory    1  Jack
> Cory    2  Jack
> Bob     2  John
> Bob     3  John
> Alex    2  Joseph
> Alex    3  West
> Alex    4  West ')
>
> Desired output
>
>        first  week last
> 1     Bob     1   John
> 2     Bob     2   John
> 3     Bob     3   John
> 4     Cory     1   Jack
> 5     Cory     2   Jack
>
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Feb 12 06:49:36 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Feb 2017 21:49:36 -0800 (PST)
Subject: [R] Query - Merging and conditional replacement of values in a
 data frame
In-Reply-To: <CAGxFJbRAftXFozskjT4vRuL6SefUfL+1K+qtPUpCnPf=jwvHTQ@mail.gmail.com>
References: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
	<CAGxFJbRAftXFozskjT4vRuL6SefUfL+1K+qtPUpCnPf=jwvHTQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1702112147350.98426@pedal.dcn.davis.ca.us>

Or use rownames and subscripting?

df1 <- read.table( text=
"time v1  v2 v3
1     2   3  4
2     5   6  4
3     1   3  4
4     1   3  4
5     2   3  4
6     2   3  4
",header=TRUE)

df2 <- read.table( text=
"time v11  v12 v13
3     112   3  4
4     112   3  4
",header=TRUE)

df3 <- df1
rownames( df3 ) <- df3$time
df3[ as.character( df2$time ), "v1" ] <- df2[ , "v11" ]
df3
df3[ "7", c( "time", "v1" ) ] <- data.frame( time=7, v1=2 )
df3
df2b <- data.frame( time=c(7,8), v2=c(4,5), v3=c(6,7) )
df2b
df3[ df2b$time, c( "time", "v2", "v3" ) ] <- df2b
df3

On Sat, 11 Feb 2017, Bert Gunter wrote:

> Your "assignments" (<-) are not legitimate R code that can be cut and
> pasted. Learn to use dput() to provide examples that we can use.
>
> You fail to say whether the time column of df2 is a proper subset of
> df1 or may contain times not in df1. I shall assume the latter. You
> also did not say whether the time values occur in order in both data
> frames. I shall assume they do not.
>
> If I understand correctly,then,  match and subscripting will do it,
> something like
>
>
>> df1 <-data.frame(time = 1:6, v1 = c(2,5,1,1,2,2))
>> df2 <- data.frame(time = 4:3,v11 = c(112,113))
>
>> wm <- match(df1$time,df2$time)
>> df1[!is.na(wm),"v1"] <- df2[na.omit(wm),"v11"]
>
>> df1
>
>  time  v1
> 1    1   2
> 2    2   5
> 3    3 113
> 4    4 112
> 5    5   2
> 6    6   2
>
> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Feb 11, 2017 at 4:13 PM, Bhaskar Mitra
> <bhaskar.kolkata at gmail.com> wrote:
>> Hello Everyone,
>>
>> I have two data frames df1 and df2 as shown below. They
>> are of different length. However, they have one common column - time.
>>
>> df1 <-
>> time v1  v2 v3
>> 1     2   3  4
>> 2     5   6  4
>> 3     1   3  4
>> 4     1   3  4
>> 5     2   3  4
>> 6     2   3  4
>>
>>
>> df2 <-
>> time v11  v12 v13
>> 3     112   3  4
>> 4     112   3  4
>>
>> By matching the 'time' column in df1 and df2, I am trying to modify column
>> 'v1' in df1 by replacing it
>> with values in column 'v11' in df2. The modified df1 should look something
>> like this:
>>
>> df1 <-
>> time v1   v2 v3
>> 1     2   3  4
>> 2     5   6  4
>> 3     112 3  4
>> 4     112 3  4
>> 5     2   3  4
>> 6     2   3  4
>>
>> I tried to use the 'merge' function to combine df1 and df2 followed by
>> the conditional 'ifelse' statement. However, that doesn't seem to work.
>>
>> Can I replace the values in df1 by not merging the two data frames?
>>
>> Thanks for your help,
>>
>> Regards,
>> Bhaskar
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r.turner at auckland.ac.nz  Sun Feb 12 07:04:19 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 12 Feb 2017 19:04:19 +1300
Subject: [R] [FORGED] Re:  remove
In-Reply-To: <CAGxFJbSh-CZoXLyXts8XSi_7t9wD-dp+AkniQeOfGFtXFniecw@mail.gmail.com>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<CAGxFJbSh-CZoXLyXts8XSi_7t9wD-dp+AkniQeOfGFtXFniecw@mail.gmail.com>
Message-ID: <27f3081f-e1c2-0391-9fc5-741f6586a199@auckland.ac.nz>


On 12/02/17 18:36, Bert Gunter wrote:
> Basic stuff!
>
> Either subscripting or ?subset.
>
> There are many good R tutorials on the web. You should spend some
> (more?) time with some.

Uh, Bert, perhaps I'm being obtuse (a common occurrence) but it doesn't 
seem basic to me.  The only way that I can see how to go at it is via
a for loop:

rdln <- function(X) {
# Remove discordant last names.
     ok <- logical(nrow(X))
     for(nm in unique(X$first)) {
         xxx <- unique(X$last[X$first==nm])
         if(length(xxx)==1) ok[X$first==nm] <- TRUE
     }
     Y <- X[ok,]
     Y <- Y[order(Y$first),]
     rownames(Y) <- 1:nrow(Y)
     Y
}

Calling the toy data frame "melvin" rather than "df" (since "df" is the 
name of the built in F density function, it is bad form to use it as the 
name of another object) I get:

 > rdln(melvin)
   first week last
1   Bob    1 John
2   Bob    2 John
3   Bob    3 John
4  Cory    1 Jack
5  Cory    2 Jack

which is the desired output.  If there is a "basic stuff" way to do this
I'd like to see it.  Perhaps I will then be toadally embarrassed, but 
they say that this is good for one.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> On Sat, Feb 11, 2017 at 9:02 PM, Val <valkremk at gmail.com> wrote:
>> Hi all,
>> I have a big data set and want to  remove rows conditionally.
>> In my data file  each person were recorded  for several weeks. Somehow
>> during the recording periods, their last name was misreported.   For
>> each person,   the last name should be the same. Otherwise remove from
>> the data. Example, in the following data set, Alex was found to have
>> two last names .
>>
>> Alex   West
>> Alex   Joseph
>>
>> Alex should be removed  from the data.  if this happens then I want
>> remove  all rows with Alex. Here is my data set
>>
>> df <- read.table(header=TRUE, text='first  week last
>> Alex    1  West
>> Bob     1  John
>> Cory    1  Jack
>> Cory    2  Jack
>> Bob     2  John
>> Bob     3  John
>> Alex    2  Joseph
>> Alex    3  West
>> Alex    4  West ')
>>
>> Desired output
>>
>>       first  week last
>> 1     Bob     1   John
>> 2     Bob     2   John
>> 3     Bob     3   John
>> 4     Cory     1   Jack
>> 5     Cory     2   Jack


From jdnewmil at dcn.davis.ca.us  Sun Feb 12 07:42:05 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Feb 2017 22:42:05 -0800 (PST)
Subject: [R] remove
In-Reply-To: <589FF50E.8040009@iinet.net.au>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
Message-ID: <alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>

The "by" function aggregates and returns a result with generally fewer 
rows than the original data. Since you are looking to index the rows in 
the original data set, the "ave" function is better suited because it 
always returns a vector that is just as long as the input vector:

# I usually work with character data rather than factors if I plan
# to modify the data (e.g. removing rows)
DF <- read.table( text=
'first  week last
Alex    1  West
Bob     1  John
Cory    1  Jack
Cory    2  Jack
Bob     2  John
Bob     3  John
Alex    2  Joseph
Alex    3  West
Alex    4  West
', header = TRUE, as.is = TRUE )

err <- ave( DF$last
           , DF[ , "first", drop = FALSE]
           , FUN = function( lst ) {
               length( unique( lst ) )
             }
           )
result <- DF[ "1" == err, ]
result

Notice that the ave function returns a vector of the same type as was 
given to it, so even though the function returns a numeric the err
vector is character.

If you wanted to be able to examine more than one other column in 
determining the keep/reject decision, you could do:

err2 <- ave( seq_along( DF$first )
            , DF[ , "first", drop = FALSE]
            , FUN = function( n ) {
               length( unique( DF[ n, "last" ] ) )
              }
            )
result2 <- DF[ 1 == err2, ]
result2

and then you would have the option to re-use the "n" index to look at 
other columns as well.

Finally, here is a dplyr solution:

library(dplyr)
result3 <- (   DF
            %>% group_by( first ) # like a prep for ave or by
            %>% mutate( err = length( unique( last ) ) ) # similar to ave
            %>% filter( 1 == err ) # drop the rows with too many last names
            %>% select( -err ) # drop the temporary column
            %>% as.data.frame # convert back to a plain-jane data frame
            )
result3

which uses a small set of verbs in a pipeline of functions to go from 
input to result in one pass.

If your data set is really big (running out of memory big) then you might 
want to investigate the data.table or sqlite packages, either of which can 
be combined with dplyr to get a standardized syntax for managing larger 
amounts of data. However, most people actually aren't running out of 
memory so in most cases the extra horsepower isn't actually needed.

On Sun, 12 Feb 2017, P Tennant wrote:

> Hi Val,
>
> The by() function could be used here. With the dataframe dfr:
>
> # split the data by first name and check for more than one last name for each 
> first name
> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
> # make the result more easily manipulated
> res <- as.table(res)
> res
> # first
> # Alex   Bob  Cory
> # TRUE FALSE FALSE
>
> # then use this result to subset the data
> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
> # sort if needed
> nw.dfr[order(nw.dfr$first) , ]
>
>  first week last
> 2   Bob    1 John
> 5   Bob    2 John
> 6   Bob    3 John
> 3  Cory    1 Jack
> 4  Cory    2 Jack
>
>
> Philip
>
> On 12/02/2017 4:02 PM, Val wrote:
>> Hi all,
>> I have a big data set and want to  remove rows conditionally.
>> In my data file  each person were recorded  for several weeks. Somehow
>> during the recording periods, their last name was misreported.   For
>> each person,   the last name should be the same. Otherwise remove from
>> the data. Example, in the following data set, Alex was found to have
>> two last names .
>> 
>> Alex   West
>> Alex   Joseph
>> 
>> Alex should be removed  from the data.  if this happens then I want
>> remove  all rows with Alex. Here is my data set
>> 
>> df<- read.table(header=TRUE, text='first  week last
>> Alex    1  West
>> Bob     1  John
>> Cory    1  Jack
>> Cory    2  Jack
>> Bob     2  John
>> Bob     3  John
>> Alex    2  Joseph
>> Alex    3  West
>> Alex    4  West ')
>> 
>> Desired output
>>
>>        first  week last
>> 1     Bob     1   John
>> 2     Bob     2   John
>> 3     Bob     3   John
>> 4     Cory     1   Jack
>> 5     Cory     2   Jack
>> 
>> Thank you in advance
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Sun Feb 12 07:56:23 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 11 Feb 2017 22:56:23 -0800 (PST)
Subject: [R] Echos for comment line (with #)
In-Reply-To: <e396abb8-3f02-d515-301c-dfaa33484c7c@gmail.com>
References: <e396abb8-3f02-d515-301c-dfaa33484c7c@gmail.com>
Message-ID: <alpine.BSF.2.00.1702112244530.98426@pedal.dcn.davis.ca.us>

On Sun, 12 Feb 2017, Steven Yen wrote:

> I need help with what may be a simple option in R (or Rstudio)--to
> receive an echo of a comment line.
>
> Running the following two-line script in plain R,
>
> # adding
> 1+2
>
> I did get the echo:
>
> > # adding
> > 1+2
> [1] 3
> >
>
> However, running the same lines in RStudio, the comment line does not
> appear in output:
>
> > 1+2
> [1] 3
> >
>
> Please help. Thanks.

This email list is about R... a language, and the computation engine 
usually used by RStudio. This is not the appropriate place to ask a 
question about the RStudio user interface... see 
https://support.rstudio.com for that.

However, I think you have omitted key information from your question, 
because there are many ways to run R code in RStudio and you did not say 
exactly what you DID. When you ask your question there be sure to be 
more precise about your button clicks and keypresses and menu selections.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From philipt900 at iinet.net.au  Sun Feb 12 08:19:11 2017
From: philipt900 at iinet.net.au (P Tennant)
Date: Sun, 12 Feb 2017 18:19:11 +1100
Subject: [R] remove
In-Reply-To: <alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
Message-ID: <58A00C6F.3090605@iinet.net.au>

Hi Jeff,

Why do you say ave() is better suited *because* it always returns a 
vector that is just as long as the input vector? Is it because that 
feature (of equal length), allows match() to be avoided, and as a 
result, the subsequent subsetting is faster with very large datasets?

Thanks, Philip


On 12/02/2017 5:42 PM, Jeff Newmiller wrote:
> The "by" function aggregates and returns a result with generally fewer 
> rows than the original data. Since you are looking to index the rows 
> in the original data set, the "ave" function is better suited because 
> it always returns a vector that is just as long as the input vector:
>
> # I usually work with character data rather than factors if I plan
> # to modify the data (e.g. removing rows)
> DF <- read.table( text=
> 'first  week last
> Alex    1  West
> Bob     1  John
> Cory    1  Jack
> Cory    2  Jack
> Bob     2  John
> Bob     3  John
> Alex    2  Joseph
> Alex    3  West
> Alex    4  West
> ', header = TRUE, as.is = TRUE )
>
> err <- ave( DF$last
>           , DF[ , "first", drop = FALSE]
>           , FUN = function( lst ) {
>               length( unique( lst ) )
>             }
>           )
> result <- DF[ "1" == err, ]
> result
>
> Notice that the ave function returns a vector of the same type as was 
> given to it, so even though the function returns a numeric the err
> vector is character.
>
> If you wanted to be able to examine more than one other column in 
> determining the keep/reject decision, you could do:
>
> err2 <- ave( seq_along( DF$first )
>            , DF[ , "first", drop = FALSE]
>            , FUN = function( n ) {
>               length( unique( DF[ n, "last" ] ) )
>              }
>            )
> result2 <- DF[ 1 == err2, ]
> result2
>
> and then you would have the option to re-use the "n" index to look at 
> other columns as well.
>
> Finally, here is a dplyr solution:
>
> library(dplyr)
> result3 <- (   DF
>            %>% group_by( first ) # like a prep for ave or by
>            %>% mutate( err = length( unique( last ) ) ) # similar to ave
>            %>% filter( 1 == err ) # drop the rows with too many last 
> names
>            %>% select( -err ) # drop the temporary column
>            %>% as.data.frame # convert back to a plain-jane data frame
>            )
> result3
>
> which uses a small set of verbs in a pipeline of functions to go from 
> input to result in one pass.
>
> If your data set is really big (running out of memory big) then you 
> might want to investigate the data.table or sqlite packages, either of 
> which can be combined with dplyr to get a standardized syntax for 
> managing larger amounts of data. However, most people actually aren't 
> running out of memory so in most cases the extra horsepower isn't 
> actually needed.
>
> On Sun, 12 Feb 2017, P Tennant wrote:
>
>> Hi Val,
>>
>> The by() function could be used here. With the dataframe dfr:
>>
>> # split the data by first name and check for more than one last name 
>> for each first name
>> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
>> # make the result more easily manipulated
>> res <- as.table(res)
>> res
>> # first
>> # Alex   Bob  Cory
>> # TRUE FALSE FALSE
>>
>> # then use this result to subset the data
>> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
>> # sort if needed
>> nw.dfr[order(nw.dfr$first) , ]
>>
>>  first week last
>> 2   Bob    1 John
>> 5   Bob    2 John
>> 6   Bob    3 John
>> 3  Cory    1 Jack
>> 4  Cory    2 Jack
>>
>>
>> Philip
>>
>> On 12/02/2017 4:02 PM, Val wrote:
>>> Hi all,
>>> I have a big data set and want to  remove rows conditionally.
>>> In my data file  each person were recorded  for several weeks. Somehow
>>> during the recording periods, their last name was misreported.   For
>>> each person,   the last name should be the same. Otherwise remove from
>>> the data. Example, in the following data set, Alex was found to have
>>> two last names .
>>>
>>> Alex   West
>>> Alex   Joseph
>>>
>>> Alex should be removed  from the data.  if this happens then I want
>>> remove  all rows with Alex. Here is my data set
>>>
>>> df<- read.table(header=TRUE, text='first  week last
>>> Alex    1  West
>>> Bob     1  John
>>> Cory    1  Jack
>>> Cory    2  Jack
>>> Bob     2  John
>>> Bob     3  John
>>> Alex    2  Joseph
>>> Alex    3  West
>>> Alex    4  West ')
>>>
>>> Desired output
>>>
>>>        first  week last
>>> 1     Bob     1   John
>>> 2     Bob     2   John
>>> 3     Bob     3   John
>>> 4     Cory     1   Jack
>>> 5     Cory     2   Jack
>>>
>>> Thank you in advance
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --------------------------------------------------------------------------- 
>
> Jeff Newmiller                        The     .....       .....  Go 
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live 
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  
> rocks...1k
> --------------------------------------------------------------------------- 
>


From drjimlemon at gmail.com  Sun Feb 12 08:20:28 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 12 Feb 2017 18:20:28 +1100
Subject: [R] Independent samples bootstrapped T-test : question
In-Reply-To: <CAJGnSAMSU0Pr6M4REy39HYDM0Nx-LxktjZXjw2oiJHtKAW0xTA@mail.gmail.com>
References: <CAJGnSAMSU0Pr6M4REy39HYDM0Nx-LxktjZXjw2oiJHtKAW0xTA@mail.gmail.com>
Message-ID: <CA+8X3fUN51mOe0PVvx+xRqsBKwW=e_JB0qhzCMFDS=6vCNHkOw@mail.gmail.com>

Hi Tahereh,
In the code you provided, there seems to be a mistake in the calls to
"sample" in that you haven't specified the "size" argument. You should
have gotten an error there. Also, you have assigned both samples to
the same variable name, so there will be no "boot.p" when the call to
t-test is made, leading to another error message. As Bert said, have a
look at the "boot" function in the "boot" package. This is probably
what you are attempting.

Jim


On Sat, Feb 11, 2017 at 10:55 PM, Tahereh Dehdarirad <tdehdari at gmail.com> wrote:
> Dear R group,
>
> I have some question regarding bootstrapping in R. I wish to use
> independent samples bootstrapped T-test. I would like to know: 1 how  I can
>  calculate p and t values.2. for means and CI of each sample, should I
> report the bootstrapped mean and CI of each group? and not the ones
> obtained from t-test?
>
> I used the following code with regard to t-test (t value and p value), So,
> I wonder if it is correct with regard to t and p values?
>
> AVGMR=Names_first_last$`Avg_ Readars-Mendeley`
>
> B      <- 1000
> t.star = numeric(B)
>  t.vect <- vector(length=B)
> p.vect <- vector(length=B)
> for(i in 1:B){ boot.c <- sample(subset(AVGMR, Gender==1), replace=T)
> boot.c <- sample(subset(AVGMR, Gender==2), replace=T)
> ttest  <- t.test(boot.c, boot.p)
>    t.vect[i] <- ttest$statistic
>    p.vect[i] <- ttest$p.value
>  }
>
> I would be really grateful if you could please help me with regard to my
> both questions.
>
> Kind regards,
>
> Tahereh Dehdarirad, PhD
> Department of Library and Information Science
> University of Barcelona, Spain
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From inctpat at gmail.com  Sun Feb 12 04:40:00 2017
From: inctpat at gmail.com (=?UTF-8?B?6LKd5Y6f5bez5qi56ZuE?=)
Date: Sun, 12 Feb 2017 03:40:00 +0000
Subject: [R] =?utf-8?q?How_to_create_HyCa=24NIR_and_octane=E3=80=80like_th?=
	=?utf-8?b?ZSAieWFybiIgb2YgInBscyIu?=
Message-ID: <CAHtrptmLXpriC2=GBkX+-FS+FT=_0P5RSSO8w9wB31i4osF2vQ@mail.gmail.com>

I am a user of package, "pls".  I am going to draw the NIR spectra of my
own measured data using matplot.

Question
   For example, I have such a csv data, "HyCa.csv", below.
  Would you please tell me how to create a data like the "yarn".
  yarn has the structure of "NIR" and "density".
  That is to say,how to create HyCa$NIR and octane for drawing and
analyzing the obtained data.

        X1540    X1560    X1580    X1600 Octane
S001 0.240016 0.232166 0.239428 0.255710   87.3
S002 0.246177 0.237545 0.243874 0.259296   87.0
S003 0.242777 0.234150 0.240941 0.256484   87.1
S004 0.244098 0.237214 0.244729 0.261580   89.7
S005 0.241922 0.231888 0.237418 0.252461   84.9
S006 0.242209 0.232352 0.238188 0.253036   84.7
S007 0.244148 0.237362 0.244701 0.261598   89.3
S008 0.242019 0.234185 0.241428 0.257564   87.6
S009 0.242408 0.232431 0.238130 0.253083   84.5
S010 0.244512 0.238601 0.246392 0.263583   91.7

Detaied explanation of "yarn"
--------------------
yarn NIR spectra and density measurements of PET yarns
Description
A training set consisting of 21 NIR spectra of PET yarns, measured at 268
wavelengths, and 21
corresponding densities. A test set of 7 samples is also provided. Many
thanks to Erik Swierenga.
56 yarn
Usage
yarn
Format
A data frame with components
NIR Numeric matrix of NIR measurements
density Numeric vector of densities
train Logical vector with TRUE for the training samples and FALSE for the
test samples
Source
Swierenga H., de Weijer A. P., van Wijk R. J., Buydens L. M. C. (1999)
Strategy for constructing
robust multivariate calibration models Chemometrics and Intelligent
Laboratoryy Systems, 49(1),1?17.

	[[alternative HTML version deleted]]


From vodvos at zoho.com  Sun Feb 12 08:27:15 2017
From: vodvos at zoho.com (vod vos)
Date: Sat, 11 Feb 2017 23:27:15 -0800
Subject: [R] How to disable verbose grob results in pdf when using knitr
 with gridExtra?
In-Reply-To: <alpine.BSF.2.00.1702110719050.71951@pedal.dcn.davis.ca.us>
References: <15a2ce2429f.c2789ed0280.8497138545484174752@zoho.com>
	<alpine.BSF.2.00.1702110719050.71951@pedal.dcn.davis.ca.us>
Message-ID: <15a3137f49b.f8765ba22615.4671787512632555903@zoho.com>

Sorry for no reproducible example.



using warnings=FALSE chunk options in knitr does not help. I found it is not the knitr's business.  I used 



resultpdf&lt;- grid.arrange(facetpoint1,pright1,pright2,pright3,pright4,pright5,pright6,pright7, ncol=2, layout_matrix=cbind(c(1,1,1,1,1,1,1),c(2,3,4,5,6,7,8)), widths=c(2,1)) 



then 



print(resultpdf)



in my chunk.



I removed object resultpdf, just used code below to produce figure



grid.arrange(facetpoint1,pright1,pright2,pright3,pright4,pright5,pright6,pright7, ncol=2, layout_matrix=cbind(c(1,1,1,1,1,1,1),c(2,3,4,5,6,7,8)), widths=c(2,1)) 



then no verbose appeared.



The problem is using print() with ggplot2.




---- On ???, 11 ?? 2017 07:45:54 -0800 Jeff Newmiller &lt;jdnewmil at dcn.davis.ca.us&gt; wrote ----




On Sat, 11 Feb 2017, vod vos wrote: 

 

&gt; Hi every one, 

&gt; 

&gt; I am using Knitr, 

 

Keep in mind that this list is about R first and foremost. There is a 

mailing list for Knitr, and also the maintainer of the knitr package 

recommends asking questions on stackoverflow.com. 

 

&gt; R and Latex to produce pdf file. When using gridExtra to set up a 

&gt; gtable layout to place multiple grobs on a page, 

&gt; 

&gt; grid.arrange(facetpoint1,pright1,pright2,pright3,pright4,pright5,pright6,pright7, ncol=2, layout_matrix=cbind(c(1,1,1,1,1,1,1),c(2,3,4,5,6,7,8)), widths=c(2,1)) 

 

This is not a reproducible example. No matter where you ask this question 

you need to supply a complete short script that exhibits the problem. That 

also means including enough data IN THE SCRIPT to allow the script to 

run. There are multiple guides online that describe how to do this in 

detail. 

 

&gt; the verbose of the infomation shows before the one figure in the pdf file: 

&gt; 

&gt; ## TableGrob (7 x 2) "arrange": 8 grobs ## z cells name grob ## 1 1 (1-7,1-1) arrange gtable[layout] ## 2 2 (1-1,2-2) arrange gtable[layout] ## 3 3 (2-2,2-2) arrange gtable[layout] ## 4 4 (3-3,2-2) arrange gtable[layout] ## 5 5 (4-4,2-2) arrange gtable[layout] ## 6 6 (5-5,2-2) arrange gtable[layout] ## 7 7 (6-6,2-2) arrange gtable[layout] ## 8 8 (7-7,2-2) arrange gtable[layout] 

 

None of this appears when I created my own reproducible R example: 

 

#### begin code 

library(grid) 

library(gridExtra) 

 

facetpoint1 &lt;- pright1 &lt;- pright2 &lt;- pright3 &lt;- pright4 &lt;- pright5 &lt;- 

pright6 &lt;- pright7 &lt;- textGrob("X") 

grid.arrange( facetpoint1, pright1, pright2, pright3, pright4, pright5 

 , pright6, pright7 

 , ncol=2 

 , layout_matrix = cbind( c( 1, 1, 1, 1, 1, 1, 1 ) 

 , c( 2, 3, 4, 5, 6, 7, 8 ) ) 

 , widths = c( 2, 1 ) 

 ) 

#### end code 

 

If the above example produces output for you in R or in a knitted PDF then 

something is different about your setup than mine. 

 

&gt; When I ?grid.arrange, no ways were found to disable the verbose in the pdf file. Any ideas? 

 

Does this happen at the R console? If it does, please post a reproducible 

example, and the invocation and output of sessionInfo() (mine is below). 

If it doesn't, there could be some interaction with knitr going on, and 

using the echo=FALSE or warnings=FALSE chunk options could help, or you 

may need more specialized help than we can offer here (e.g. via one of 

the knitr support areas mentioned above). 

 

&gt; Thanks. 

&gt; 

&gt;     [[alternative HTML version deleted]] 

 

When you don't set your email to plain text, the automatic conversion of 

HTML to text is very likely to cause us to see something quite different 

than you were looking at. It is in your best interest to figure out how to 

set your email program to send plain text. Please read the Posting Guide: 

 

&gt; ______________________________________________ 

&gt; R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 

&gt; https://stat.ethz.ch/mailman/listinfo/r-help 

&gt; PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 

&gt; and provide commented, minimal, self-contained, reproducible code. 

 

---------------------------------------------------------------------------

Jeff Newmiller The ..... ..... Go Live... 

DCN:&lt;jdnewmil at dcn.davis.ca.us&gt; Basics: ##.#. ##.#. Live Go... 

 Live: OO#.. Dead: OO#.. Playing 

Research Engineer (Solar/Batteries O.O#. #.O#. with 

/Software/Embedded Controllers) .OO#. .OO#. rocks...1k 

---------------------------------------------------------------------------



&gt; sessionInfo() 

R version 3.3.2 (2016-10-31) 

Platform: x86_64-pc-linux-gnu (64-bit) 

Running under: Ubuntu 14.04.5 LTS 



locale: 

 [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C 

LC_TIME=en_US.UTF-8 

 [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 

LC_MESSAGES=en_US.UTF-8 

 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C 

[10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 

LC_IDENTIFICATION=C 



attached base packages: 

[1] grid stats graphics grDevices utils datasets methods 

base 



other attached packages: 

[1] gridExtra_2.2.1 



loaded via a namespace (and not attached): 

 [1] backports_1.0.4 magrittr_1.5 rprojroot_1.1 htmltools_0.3.5 

tools_3.3.2 

 [6] gtable_0.2.0 yaml_2.1.14 Rcpp_0.12.8 stringi_1.1.2 

rmarkdown_1.3 

[11] knitr_1.15.1 stringr_1.1.0 digest_0.6.11 evaluate_0.10 









	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Feb 12 10:35:26 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 12 Feb 2017 20:35:26 +1100
Subject: [R] Query - Merging and conditional replacement of values in a
 data frame
In-Reply-To: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
References: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
Message-ID: <CA+8X3fV2emucJZQnUkd274giLqUabiccDYkuJhTghDux6ZKMBA@mail.gmail.com>

Hi Bhaskar,
Maybe:

df1 <-read.table(text="time v1  v2 v3
1     2   3  4
2     5   6  4
3     1   3  4
4     1   3  4
5     2   3  4
6     2   3  4",
header=TRUE)


df2 <-read.table(text="time v11  v12 v13
3     112   3  4
4     112   3  4",
header=TRUE)

for(time1 in df1$time) {
 time2<-which(df2$time==time1)
 if(length(time2)) df1[df1$time==time1,]<-df2[time2,]
}

Jim


On Sun, Feb 12, 2017 at 11:13 AM, Bhaskar Mitra
<bhaskar.kolkata at gmail.com> wrote:
> Hello Everyone,
>
> I have two data frames df1 and df2 as shown below. They
> are of different length. However, they have one common column - time.
>
> df1 <-
> time v1  v2 v3
> 1     2   3  4
> 2     5   6  4
> 3     1   3  4
> 4     1   3  4
> 5     2   3  4
> 6     2   3  4
>
>
> df2 <-
> time v11  v12 v13
> 3     112   3  4
> 4     112   3  4
>
> By matching the 'time' column in df1 and df2, I am trying to modify column
> 'v1' in df1 by replacing it
> with values in column 'v11' in df2. The modified df1 should look something
> like this:
>
> df1 <-
> time v1   v2 v3
> 1     2   3  4
> 2     5   6  4
> 3     112 3  4
> 4     112 3  4
> 5     2   3  4
> 6     2   3  4
>
> I tried to use the 'merge' function to combine df1 and df2 followed by
> the conditional 'ifelse' statement. However, that doesn't seem to work.
>
> Can I replace the values in df1 by not merging the two data frames?
>
> Thanks for your help,
>
> Regards,
> Bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Sun Feb 12 11:22:05 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 12 Feb 2017 10:22:05 +0000
Subject: [R] Plotting Landscape in R-Studio
In-Reply-To: <DD3F514E-7E20-45F2-93D3-A0FAB90B8DAF@gmail.com>
References: <000601d28483$9c6f7ca0$d54e75e0$@sbcglobal.net>
	<0AEE48AA-DBE7-4F46-BAB1-C948AE76ECEA@comcast.net>
	<8978F7E5-8EB0-4EC6-9746-8BECF60A3614@dcn.davis.ca.us>
	<DD3F514E-7E20-45F2-93D3-A0FAB90B8DAF@gmail.com>
Message-ID: <660b2d0d-cfda-c3d0-ea27-39c9acde897e@dewey.myzen.co.uk>

Colleagues who use Word seem to find no problem with .wmf files.

On 11/02/2017 22:08, peter dalgaard wrote:
>
>> On 11 Feb 2017, at 20:13 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> While the question AS POSED is off base here (and in fact unlikely to have any satisfactory answer due to the unavoidable squishiness of pasted graphics in Word),
>
> I did wonder whether it wouldn't be easier just to export to a (PDF? WMF?) file and import that in Word. That looks like a no-brainer from the RStudio side. Or write directly to the appropriate device.
>
> -pd
>
>
>> the OP could investigate the ReporteRs package which can export graphics directly to word files in a fairly predictable manner, including creating landscape oriented sections.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 11, 2017 9:01:47 AM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>>> On Feb 11, 2017, at 8:26 AM, Jeff Reichman <reichmanj at sbcglobal.net>
>>> wrote:
>>>>
>>>> R-Help
>>>>
>>>>
>>>>
>>>> How can I format a plot within R-Studio  (Plot Windows) to conform to
>>> an 8.5
>>>> x 11-  landscape.  Such that when I Export - Copy to Clip board I can
>>> past
>>>> plot into word.
>>>>
>>>
>>> This is really the wrong venue for asking questions about transferring
>>> graphics from RStudio to Word. Two other options: RStudio has its own
>>> help forum and this would probably be an OK question if you constructed
>>> a minimal verifiable example to submit to StackOverflow.
>>>
>>>
>>>>
>>>>
>>>> Jeff
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From allantanaka11 at yahoo.com  Sun Feb 12 13:34:20 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Sun, 12 Feb 2017 12:34:20 +0000 (UTC)
Subject: [R] object of type 'closure' is not subsettable
References: <78845307.2701201.1486902860381.ref@mail.yahoo.com>
Message-ID: <78845307.2701201.1486902860381@mail.yahoo.com>

Hi.
I tried to run this R-code but still completely no idea why it still gives error message: Error in forecast[[d + 1]] = paste(index(lEJReturnsOffset[windowLength]), ?: object of type 'closure' is not subsettable
Here is the R-code:
library(rugarch); library(sos); library(forecast);library(lattice)library(quantmod); require(stochvol); require(fBasics);data = read.table("EURJPY.m1440.csv", header=F)names(data)data=ts(data)lEJ=log(data)lret.EJ = 100*diff(lEJ)lret.EJ = ts(lret.EJ)lret.EJ[as.character(head(index(lret.EJ)))]=0windowLength=500foreLength=length(lret.EJ)-windowLengthforecasts<-vector(mode="character", length=foreLength)for (d in 0:foreLength) {? lEJReturnsOffset=lret.EJ[(1+d):(windowLength+d)]? final.aic<-Inf? final.order<-c(0,0,0)? for (p in 0:5) for (q in 0:5) {? ? if(p == 0 && q == 0) {? ? ? next? ? }? ??? ? arimaFit=tryCatch(arima(lEJReturnsOffset, order=c(p,0,q)),? ? ? ? ? ? ? ? ? ? ? error=function(err)FALSE,? ? ? ? ? ? ? ? ? ? ? warning=function(err)FALSE)? ? if(!is.logical(arimaFit)) {? ? ? current.aic<-AIC(arimaFit)? ? ? if(current.aic<final.aic) {? ? ? ? final.aic<-current.aic? ? ? ? final.order<-c(p,0,q)? ? ? ? final.arima<-arima(lEJReturnsOffset, order=final.order)? ? ? }? ? } else {? ? ? next? ? }? }
spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1,1)),? ? ? ? ? ? ? ? ? ? ?mean.model = list(armaOrder = c(final.order[1], final.order[3]), arfima = FALSE, include.mean = TRUE),? ? ? ? ? ? ? ? ? ? ?distribution.model = "sged")fit <- tryCatch(ugarchfit(spec, lEJReturnsOffset, solver='gosolnp'),? error=function(e) e, warning=function(w) w)if(is(fit, "warning")) {? forecast[d+1]=paste(index(lEJReturnsOffset[windowLength]), 1, sep=",")? print(paste(index(lEJReturnsOffset[windowLength]), 1, sep=","))} else {? fore = ugarchforecast(fit, n.ahead=1)? ind = fore at forecast$seriesFor? forecasts[d+1] = paste(colnames(ind), ifelse(ind[1] < 0, -1, 1), sep=",")? print(paste(colnames(ind), ifelse(ind[1] < 0, -1, 1), sep=","))?}}write.csv(forecasts, file="forecasts.csv", row.names=FALSE)
??
	[[alternative HTML version deleted]]


From valkremk at gmail.com  Sun Feb 12 16:12:47 2017
From: valkremk at gmail.com (Val)
Date: Sun, 12 Feb 2017 09:12:47 -0600
Subject: [R] remove
In-Reply-To: <alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
Message-ID: <CAJOiR6ZZJRHbv4EyoZksJwwuJ8mMFDyjRAv25qqkRpeiFUO=Dw@mail.gmail.com>

 Jeff, Rolf and Philip.
Thank you very much for your suggestion.

Jeff, you suggested if your data is big then consider data.table ....
My data is "big"  it is more than 200M  records and I will see if this
function works.

Thank you again.


On Sun, Feb 12, 2017 at 12:42 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The "by" function aggregates and returns a result with generally fewer rows
> than the original data. Since you are looking to index the rows in the
> original data set, the "ave" function is better suited because it always
> returns a vector that is just as long as the input vector:
>
> # I usually work with character data rather than factors if I plan
> # to modify the data (e.g. removing rows)
> DF <- read.table( text=
> 'first  week last
> Alex    1  West
> Bob     1  John
> Cory    1  Jack
> Cory    2  Jack
> Bob     2  John
> Bob     3  John
> Alex    2  Joseph
> Alex    3  West
> Alex    4  West
> ', header = TRUE, as.is = TRUE )
>
> err <- ave( DF$last
>           , DF[ , "first", drop = FALSE]
>           , FUN = function( lst ) {
>               length( unique( lst ) )
>             }
>           )
> result <- DF[ "1" == err, ]
> result
>
> Notice that the ave function returns a vector of the same type as was given
> to it, so even though the function returns a numeric the err
> vector is character.
>
> If you wanted to be able to examine more than one other column in
> determining the keep/reject decision, you could do:
>
> err2 <- ave( seq_along( DF$first )
>            , DF[ , "first", drop = FALSE]
>            , FUN = function( n ) {
>               length( unique( DF[ n, "last" ] ) )
>              }
>            )
> result2 <- DF[ 1 == err2, ]
> result2
>
> and then you would have the option to re-use the "n" index to look at other
> columns as well.
>
> Finally, here is a dplyr solution:
>
> library(dplyr)
> result3 <- (   DF
>            %>% group_by( first ) # like a prep for ave or by
>            %>% mutate( err = length( unique( last ) ) ) # similar to ave
>            %>% filter( 1 == err ) # drop the rows with too many last names
>            %>% select( -err ) # drop the temporary column
>            %>% as.data.frame # convert back to a plain-jane data frame
>            )
> result3
>
> which uses a small set of verbs in a pipeline of functions to go from input
> to result in one pass.
>
> If your data set is really big (running out of memory big) then you might
> want to investigate the data.table or sqlite packages, either of which can
> be combined with dplyr to get a standardized syntax for managing larger
> amounts of data. However, most people actually aren't running out of memory
> so in most cases the extra horsepower isn't actually needed.
>
>
> On Sun, 12 Feb 2017, P Tennant wrote:
>
>> Hi Val,
>>
>> The by() function could be used here. With the dataframe dfr:
>>
>> # split the data by first name and check for more than one last name for
>> each first name
>> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
>> # make the result more easily manipulated
>> res <- as.table(res)
>> res
>> # first
>> # Alex   Bob  Cory
>> # TRUE FALSE FALSE
>>
>> # then use this result to subset the data
>> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
>> # sort if needed
>> nw.dfr[order(nw.dfr$first) , ]
>>
>>  first week last
>> 2   Bob    1 John
>> 5   Bob    2 John
>> 6   Bob    3 John
>> 3  Cory    1 Jack
>> 4  Cory    2 Jack
>>
>>
>> Philip
>>
>> On 12/02/2017 4:02 PM, Val wrote:
>>>
>>> Hi all,
>>> I have a big data set and want to  remove rows conditionally.
>>> In my data file  each person were recorded  for several weeks. Somehow
>>> during the recording periods, their last name was misreported.   For
>>> each person,   the last name should be the same. Otherwise remove from
>>> the data. Example, in the following data set, Alex was found to have
>>> two last names .
>>>
>>> Alex   West
>>> Alex   Joseph
>>>
>>> Alex should be removed  from the data.  if this happens then I want
>>> remove  all rows with Alex. Here is my data set
>>>
>>> df<- read.table(header=TRUE, text='first  week last
>>> Alex    1  West
>>> Bob     1  John
>>> Cory    1  Jack
>>> Cory    2  Jack
>>> Bob     2  John
>>> Bob     3  John
>>> Alex    2  Joseph
>>> Alex    3  West
>>> Alex    4  West ')
>>>
>>> Desired output
>>>
>>>        first  week last
>>> 1     Bob     1   John
>>> 2     Bob     2   John
>>> 3     Bob     3   John
>>> 4     Cory     1   Jack
>>> 5     Cory     2   Jack
>>>
>>> Thank you in advance
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From jdnewmil at dcn.davis.ca.us  Sun Feb 12 16:18:26 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 12 Feb 2017 07:18:26 -0800
Subject: [R] remove
In-Reply-To: <58A00C6F.3090605@iinet.net.au>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
	<58A00C6F.3090605@iinet.net.au>
Message-ID: <81C6B41A-B136-464B-82F5-08093A7CFE39@dcn.davis.ca.us>

Exactly. Sort of like the optimisation of using which.max instead of max followed by which, though ideally the only intermediate vector would be the logical vector that says keep or don't keep.
-- 
Sent from my phone. Please excuse my brevity.

On February 11, 2017 11:19:11 PM PST, P Tennant <philipt900 at iinet.net.au> wrote:
>Hi Jeff,
>
>Why do you say ave() is better suited *because* it always returns a 
>vector that is just as long as the input vector? Is it because that 
>feature (of equal length), allows match() to be avoided, and as a 
>result, the subsequent subsetting is faster with very large datasets?
>
>Thanks, Philip
>
>
>On 12/02/2017 5:42 PM, Jeff Newmiller wrote:
>> The "by" function aggregates and returns a result with generally
>fewer 
>> rows than the original data. Since you are looking to index the rows 
>> in the original data set, the "ave" function is better suited because
>
>> it always returns a vector that is just as long as the input vector:
>>
>> # I usually work with character data rather than factors if I plan
>> # to modify the data (e.g. removing rows)
>> DF <- read.table( text=
>> 'first  week last
>> Alex    1  West
>> Bob     1  John
>> Cory    1  Jack
>> Cory    2  Jack
>> Bob     2  John
>> Bob     3  John
>> Alex    2  Joseph
>> Alex    3  West
>> Alex    4  West
>> ', header = TRUE, as.is = TRUE )
>>
>> err <- ave( DF$last
>>           , DF[ , "first", drop = FALSE]
>>           , FUN = function( lst ) {
>>               length( unique( lst ) )
>>             }
>>           )
>> result <- DF[ "1" == err, ]
>> result
>>
>> Notice that the ave function returns a vector of the same type as was
>
>> given to it, so even though the function returns a numeric the err
>> vector is character.
>>
>> If you wanted to be able to examine more than one other column in 
>> determining the keep/reject decision, you could do:
>>
>> err2 <- ave( seq_along( DF$first )
>>            , DF[ , "first", drop = FALSE]
>>            , FUN = function( n ) {
>>               length( unique( DF[ n, "last" ] ) )
>>              }
>>            )
>> result2 <- DF[ 1 == err2, ]
>> result2
>>
>> and then you would have the option to re-use the "n" index to look at
>
>> other columns as well.
>>
>> Finally, here is a dplyr solution:
>>
>> library(dplyr)
>> result3 <- (   DF
>>            %>% group_by( first ) # like a prep for ave or by
>>            %>% mutate( err = length( unique( last ) ) ) # similar to
>ave
>>            %>% filter( 1 == err ) # drop the rows with too many last 
>> names
>>            %>% select( -err ) # drop the temporary column
>>            %>% as.data.frame # convert back to a plain-jane data
>frame
>>            )
>> result3
>>
>> which uses a small set of verbs in a pipeline of functions to go from
>
>> input to result in one pass.
>>
>> If your data set is really big (running out of memory big) then you 
>> might want to investigate the data.table or sqlite packages, either
>of 
>> which can be combined with dplyr to get a standardized syntax for 
>> managing larger amounts of data. However, most people actually aren't
>
>> running out of memory so in most cases the extra horsepower isn't 
>> actually needed.
>>
>> On Sun, 12 Feb 2017, P Tennant wrote:
>>
>>> Hi Val,
>>>
>>> The by() function could be used here. With the dataframe dfr:
>>>
>>> # split the data by first name and check for more than one last name
>
>>> for each first name
>>> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
>>> # make the result more easily manipulated
>>> res <- as.table(res)
>>> res
>>> # first
>>> # Alex   Bob  Cory
>>> # TRUE FALSE FALSE
>>>
>>> # then use this result to subset the data
>>> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
>>> # sort if needed
>>> nw.dfr[order(nw.dfr$first) , ]
>>>
>>>  first week last
>>> 2   Bob    1 John
>>> 5   Bob    2 John
>>> 6   Bob    3 John
>>> 3  Cory    1 Jack
>>> 4  Cory    2 Jack
>>>
>>>
>>> Philip
>>>
>>> On 12/02/2017 4:02 PM, Val wrote:
>>>> Hi all,
>>>> I have a big data set and want to  remove rows conditionally.
>>>> In my data file  each person were recorded  for several weeks.
>Somehow
>>>> during the recording periods, their last name was misreported.  
>For
>>>> each person,   the last name should be the same. Otherwise remove
>from
>>>> the data. Example, in the following data set, Alex was found to
>have
>>>> two last names .
>>>>
>>>> Alex   West
>>>> Alex   Joseph
>>>>
>>>> Alex should be removed  from the data.  if this happens then I want
>>>> remove  all rows with Alex. Here is my data set
>>>>
>>>> df<- read.table(header=TRUE, text='first  week last
>>>> Alex    1  West
>>>> Bob     1  John
>>>> Cory    1  Jack
>>>> Cory    2  Jack
>>>> Bob     2  John
>>>> Bob     3  John
>>>> Alex    2  Joseph
>>>> Alex    3  West
>>>> Alex    4  West ')
>>>>
>>>> Desired output
>>>>
>>>>        first  week last
>>>> 1     Bob     1   John
>>>> 2     Bob     2   John
>>>> 3     Bob     3   John
>>>> 4     Cory     1   Jack
>>>> 5     Cory     2   Jack
>>>>
>>>> Thank you in advance
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>---------------------------------------------------------------------------
>
>>
>> Jeff Newmiller                        The     .....       .....  Go 
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  
>> rocks...1k
>>
>---------------------------------------------------------------------------
>
>>


From jdnewmil at dcn.davis.ca.us  Sun Feb 12 17:06:36 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 12 Feb 2017 08:06:36 -0800
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <78845307.2701201.1486902860381@mail.yahoo.com>
References: <78845307.2701201.1486902860381.ref@mail.yahoo.com>
	<78845307.2701201.1486902860381@mail.yahoo.com>
Message-ID: <7275BB0C-97E0-48B3-8A63-CD2FEEF50CB2@dcn.davis.ca.us>

By failing to send your email in plain text format on this mailing list, we see a damaged version of what you saw when you sent it. 

Also, we would need some some data to test the code with. Google "r reproducible example" to find discussions of how to ask questions online. 

From the error message alone I suspect forecast is the function from the forecast package, and you are trying to create and modify a data object with that same name. At the very least re-using names is unwise, but I think your whole concept of how to create forecasts is deviating from the normal way this is done. But the scrambling of the code isn't helping. 

-- 
Sent from my phone. Please excuse my brevity.

On February 12, 2017 4:34:20 AM PST, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
>Hi.
>I tried to run this R-code but still completely no idea why it still
>gives error message: Error in forecast[[d + 1]] =
>paste(index(lEJReturnsOffset[windowLength]), ?: object of type
>'closure' is not subsettable
>Here is the R-code:
>library(rugarch); library(sos);
>library(forecast);library(lattice)library(quantmod); require(stochvol);
>require(fBasics);data = read.table("EURJPY.m1440.csv",
>header=F)names(data)data=ts(data)lEJ=log(data)lret.EJ =
>100*diff(lEJ)lret.EJ =
>ts(lret.EJ)lret.EJ[as.character(head(index(lret.EJ)))]=0windowLength=500foreLength=length(lret.EJ)-windowLengthforecasts<-vector(mode="character",
>length=foreLength)for (d in 0:foreLength) {?
>lEJReturnsOffset=lret.EJ[(1+d):(windowLength+d)]? final.aic<-Inf?
>final.order<-c(0,0,0)? for (p in 0:5) for (q in 0:5) {? ? if(p == 0 &&
>q == 0) {? ? ? next? ? }? ??? ?
>arimaFit=tryCatch(arima(lEJReturnsOffset, order=c(p,0,q)),? ? ? ? ? ? ?
>? ? ? ? error=function(err)FALSE,? ? ? ? ? ? ? ? ? ? ?
>warning=function(err)FALSE)? ? if(!is.logical(arimaFit)) {? ? ?
>current.aic<-AIC(arimaFit)? ? ? if(current.aic<final.aic) {? ? ? ?
>final.aic<-current.aic? ? ? ? final.order<-c(p,0,q)? ? ? ?
>final.arima<-arima(lEJReturnsOffset, order=final.order)? ? ? }? ? }
>else {? ? ? next? ? }? }
>spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder =
>c(1,1)),? ? ? ? ? ? ? ? ? ? ?mean.model = list(armaOrder =
>c(final.order[1], final.order[3]), arfima = FALSE, include.mean =
>TRUE),? ? ? ? ? ? ? ? ? ? ?distribution.model = "sged")fit <-
>tryCatch(ugarchfit(spec, lEJReturnsOffset, solver='gosolnp'),?
>error=function(e) e, warning=function(w) w)if(is(fit, "warning")) {?
>forecast[d+1]=paste(index(lEJReturnsOffset[windowLength]), 1, sep=",")?
>print(paste(index(lEJReturnsOffset[windowLength]), 1, sep=","))} else
>{? fore = ugarchforecast(fit, n.ahead=1)? ind =
>fore at forecast$seriesFor? forecasts[d+1] = paste(colnames(ind),
>ifelse(ind[1] < 0, -1, 1), sep=",")? print(paste(colnames(ind),
>ifelse(ind[1] < 0, -1, 1), sep=","))?}}write.csv(forecasts,
>file="forecasts.csv", row.names=FALSE)
>??
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Feb 12 17:19:25 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Feb 2017 08:19:25 -0800
Subject: [R] [FORGED] Re:  remove
In-Reply-To: <27f3081f-e1c2-0391-9fc5-741f6586a199@auckland.ac.nz>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<CAGxFJbSh-CZoXLyXts8XSi_7t9wD-dp+AkniQeOfGFtXFniecw@mail.gmail.com>
	<27f3081f-e1c2-0391-9fc5-741f6586a199@auckland.ac.nz>
Message-ID: <CAGxFJbT+ktTPY1t5Qgud_bBSNn9cC80_Wrnx3RODjX2jR=TSJQ@mail.gmail.com>

My understanding was that the discordant names has been identified. So
in the example the OP gave, removing rows with first = "Alex" is done
by:

df[df$first !="Alex",]

If that is not the case, as others have pointed out, various forms of
tapply() (by, ave, etc.) can be used. I agree that that is not so
"basic," so I apologize if my understanding was incorrect.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 11, 2017 at 10:04 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 12/02/17 18:36, Bert Gunter wrote:
>>
>> Basic stuff!
>>
>> Either subscripting or ?subset.
>>
>> There are many good R tutorials on the web. You should spend some
>> (more?) time with some.
>
>
> Uh, Bert, perhaps I'm being obtuse (a common occurrence) but it doesn't seem
> basic to me.  The only way that I can see how to go at it is via
> a for loop:
>
> rdln <- function(X) {
> # Remove discordant last names.
>     ok <- logical(nrow(X))
>     for(nm in unique(X$first)) {
>         xxx <- unique(X$last[X$first==nm])
>         if(length(xxx)==1) ok[X$first==nm] <- TRUE
>     }
>     Y <- X[ok,]
>     Y <- Y[order(Y$first),]
>     rownames(Y) <- 1:nrow(Y)
>     Y
> }
>
> Calling the toy data frame "melvin" rather than "df" (since "df" is the name
> of the built in F density function, it is bad form to use it as the name of
> another object) I get:
>
>> rdln(melvin)
>   first week last
> 1   Bob    1 John
> 2   Bob    2 John
> 3   Bob    3 John
> 4  Cory    1 Jack
> 5  Cory    2 Jack
>
> which is the desired output.  If there is a "basic stuff" way to do this
> I'd like to see it.  Perhaps I will then be toadally embarrassed, but they
> say that this is good for one.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>> On Sat, Feb 11, 2017 at 9:02 PM, Val <valkremk at gmail.com> wrote:
>>>
>>> Hi all,
>>> I have a big data set and want to  remove rows conditionally.
>>> In my data file  each person were recorded  for several weeks. Somehow
>>> during the recording periods, their last name was misreported.   For
>>> each person,   the last name should be the same. Otherwise remove from
>>> the data. Example, in the following data set, Alex was found to have
>>> two last names .
>>>
>>> Alex   West
>>> Alex   Joseph
>>>
>>> Alex should be removed  from the data.  if this happens then I want
>>> remove  all rows with Alex. Here is my data set
>>>
>>> df <- read.table(header=TRUE, text='first  week last
>>> Alex    1  West
>>> Bob     1  John
>>> Cory    1  Jack
>>> Cory    2  Jack
>>> Bob     2  John
>>> Bob     3  John
>>> Alex    2  Joseph
>>> Alex    3  West
>>> Alex    4  West ')
>>>
>>> Desired output
>>>
>>>       first  week last
>>> 1     Bob     1   John
>>> 2     Bob     2   John
>>> 3     Bob     3   John
>>> 4     Cory     1   Jack
>>> 5     Cory     2   Jack


From Rainer.Schuermann at gmx.net  Sun Feb 12 18:17:05 2017
From: Rainer.Schuermann at gmx.net (Rainer Schuermann)
Date: Sun, 12 Feb 2017 18:17:05 +0100
Subject: [R] [FORGED] Re:  remove
In-Reply-To: <27f3081f-e1c2-0391-9fc5-741f6586a199@auckland.ac.nz>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<CAGxFJbSh-CZoXLyXts8XSi_7t9wD-dp+AkniQeOfGFtXFniecw@mail.gmail.com>
	<27f3081f-e1c2-0391-9fc5-741f6586a199@auckland.ac.nz>
Message-ID: <3483707.pxfQFYcgtY@nizza>

I may not be understanding the question well enough but for me

df[ df[ , "first"]  != "Alex", ]

seems to do the job:

  first week last 

Rainer




On Sonntag, 12. Februar 2017 19:04:19 CET Rolf Turner wrote:
> 
> On 12/02/17 18:36, Bert Gunter wrote:
> > Basic stuff!
> >
> > Either subscripting or ?subset.
> >
> > There are many good R tutorials on the web. You should spend some
> > (more?) time with some.
> 
> Uh, Bert, perhaps I'm being obtuse (a common occurrence) but it doesn't 
> seem basic to me.  The only way that I can see how to go at it is via
> a for loop:
> 
> rdln <- function(X) {
> # Remove discordant last names.
>      ok <- logical(nrow(X))
>      for(nm in unique(X$first)) {
>          xxx <- unique(X$last[X$first==nm])
>          if(length(xxx)==1) ok[X$first==nm] <- TRUE
>      }
>      Y <- X[ok,]
>      Y <- Y[order(Y$first),]
>      rownames(Y) <- 1:nrow(Y)
>      Y
> }
> 
> Calling the toy data frame "melvin" rather than "df" (since "df" is the 
> name of the built in F density function, it is bad form to use it as the 
> name of another object) I get:
> 
>  > rdln(melvin)
>    first week last
> 1   Bob    1 John
> 2   Bob    2 John
> 3   Bob    3 John
> 4  Cory    1 Jack
> 5  Cory    2 Jack
> 
> which is the desired output.  If there is a "basic stuff" way to do this
> I'd like to see it.  Perhaps I will then be toadally embarrassed, but 
> they say that this is good for one.
> 
> cheers,
> 
> Rolf
> 
> > On Sat, Feb 11, 2017 at 9:02 PM, Val <valkremk at gmail.com> wrote:
> >> Hi all,
> >> I have a big data set and want to  remove rows conditionally.
> >> In my data file  each person were recorded  for several weeks. Somehow
> >> during the recording periods, their last name was misreported.   For
> >> each person,   the last name should be the same. Otherwise remove from
> >> the data. Example, in the following data set, Alex was found to have
> >> two last names .
> >>
> >> Alex   West
> >> Alex   Joseph
> >>
> >> Alex should be removed  from the data.  if this happens then I want
> >> remove  all rows with Alex. Here is my data set
> >>
> >> df <- read.table(header=TRUE, text='first  week last
> >> Alex    1  West
> >> Bob     1  John
> >> Cory    1  Jack
> >> Cory    2  Jack
> >> Bob     2  John
> >> Bob     3  John
> >> Alex    2  Joseph
> >> Alex    3  West
> >> Alex    4  West ')
> >>
> >> Desired output
> >>
> >>       first  week last
> >> 1     Bob     1   John
> >> 2     Bob     2   John
> >> 3     Bob     3   John
> >> 4     Cory     1   Jack
> >> 5     Cory     2   Jack
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



	[[alternative HTML version deleted]]


From valkremk at gmail.com  Sun Feb 12 19:51:59 2017
From: valkremk at gmail.com (Val)
Date: Sun, 12 Feb 2017 12:51:59 -0600
Subject: [R] [FORGED] Re: remove
In-Reply-To: <3483707.pxfQFYcgtY@nizza>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<CAGxFJbSh-CZoXLyXts8XSi_7t9wD-dp+AkniQeOfGFtXFniecw@mail.gmail.com>
	<27f3081f-e1c2-0391-9fc5-741f6586a199@auckland.ac.nz>
	<3483707.pxfQFYcgtY@nizza>
Message-ID: <CAJOiR6ZnBfRzezK4Hv1UeFD1cvJm+3ojOkbv_O=yFZYO5dK94Q@mail.gmail.com>

Thank you Rainer,

The question was :-
1. Identify those first names with different last names or more than
one last names.
2. Once identified (like Alex)  then exclude them.  This is because
not reliable record.

On Sun, Feb 12, 2017 at 11:17 AM, Rainer Schuermann
<Rainer.Schuermann at gmx.net> wrote:
> I may not be understanding the question well enough but for me
>
> df[ df[ , "first"]  != "Alex", ]
>
> seems to do the job:
>
>   first week last
>
> Rainer
>
>
>
>
> On Sonntag, 12. Februar 2017 19:04:19 CET Rolf Turner wrote:
>>
>> On 12/02/17 18:36, Bert Gunter wrote:
>> > Basic stuff!
>> >
>> > Either subscripting or ?subset.
>> >
>> > There are many good R tutorials on the web. You should spend some
>> > (more?) time with some.
>>
>> Uh, Bert, perhaps I'm being obtuse (a common occurrence) but it doesn't
>> seem basic to me.  The only way that I can see how to go at it is via
>> a for loop:
>>
>> rdln <- function(X) {
>> # Remove discordant last names.
>>      ok <- logical(nrow(X))
>>      for(nm in unique(X$first)) {
>>          xxx <- unique(X$last[X$first==nm])
>>          if(length(xxx)==1) ok[X$first==nm] <- TRUE
>>      }
>>      Y <- X[ok,]
>>      Y <- Y[order(Y$first),]
>>      rownames(Y) <- 1:nrow(Y)
>>      Y
>> }
>>
>> Calling the toy data frame "melvin" rather than "df" (since "df" is the
>> name of the built in F density function, it is bad form to use it as the
>> name of another object) I get:
>>
>>  > rdln(melvin)
>>    first week last
>> 1   Bob    1 John
>> 2   Bob    2 John
>> 3   Bob    3 John
>> 4  Cory    1 Jack
>> 5  Cory    2 Jack
>>
>> which is the desired output.  If there is a "basic stuff" way to do this
>> I'd like to see it.  Perhaps I will then be toadally embarrassed, but
>> they say that this is good for one.
>>
>> cheers,
>>
>> Rolf
>>
>> > On Sat, Feb 11, 2017 at 9:02 PM, Val <valkremk at gmail.com> wrote:
>> >> Hi all,
>> >> I have a big data set and want to  remove rows conditionally.
>> >> In my data file  each person were recorded  for several weeks. Somehow
>> >> during the recording periods, their last name was misreported.   For
>> >> each person,   the last name should be the same. Otherwise remove from
>> >> the data. Example, in the following data set, Alex was found to have
>> >> two last names .
>> >>
>> >> Alex   West
>> >> Alex   Joseph
>> >>
>> >> Alex should be removed  from the data.  if this happens then I want
>> >> remove  all rows with Alex. Here is my data set
>> >>
>> >> df <- read.table(header=TRUE, text='first  week last
>> >> Alex    1  West
>> >> Bob     1  John
>> >> Cory    1  Jack
>> >> Cory    2  Jack
>> >> Bob     2  John
>> >> Bob     3  John
>> >> Alex    2  Joseph
>> >> Alex    3  West
>> >> Alex    4  West ')
>> >>
>> >> Desired output
>> >>
>> >>       first  week last
>> >> 1     Bob     1   John
>> >> 2     Bob     2   John
>> >> 3     Bob     3   John
>> >> 4     Cory     1   Jack
>> >> 5     Cory     2   Jack
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhaskar.kolkata at gmail.com  Sun Feb 12 20:02:38 2017
From: bhaskar.kolkata at gmail.com (Bhaskar Mitra)
Date: Sun, 12 Feb 2017 14:02:38 -0500
Subject: [R] Query - Merging and conditional replacement of values in a
 data frame
In-Reply-To: <CA+8X3fV2emucJZQnUkd274giLqUabiccDYkuJhTghDux6ZKMBA@mail.gmail.com>
References: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
	<CA+8X3fV2emucJZQnUkd274giLqUabiccDYkuJhTghDux6ZKMBA@mail.gmail.com>
Message-ID: <CAEGXkYXOoYdvi6rpo2739+SAnjBc4B_kbvxgKxSFYEJTHK937A@mail.gmail.com>

Thanks for all your help. This is helpful.

Best,
Bhaskar

On Sun, Feb 12, 2017 at 4:35 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Bhaskar,
> Maybe:
>
> df1 <-read.table(text="time v1  v2 v3
> 1     2   3  4
> 2     5   6  4
> 3     1   3  4
> 4     1   3  4
> 5     2   3  4
> 6     2   3  4",
> header=TRUE)
>
>
> df2 <-read.table(text="time v11  v12 v13
> 3     112   3  4
> 4     112   3  4",
> header=TRUE)
>
> for(time1 in df1$time) {
>  time2<-which(df2$time==time1)
>  if(length(time2)) df1[df1$time==time1,]<-df2[time2,]
> }
>
> Jim
>
>
> On Sun, Feb 12, 2017 at 11:13 AM, Bhaskar Mitra
> <bhaskar.kolkata at gmail.com> wrote:
> > Hello Everyone,
> >
> > I have two data frames df1 and df2 as shown below. They
> > are of different length. However, they have one common column - time.
> >
> > df1 <-
> > time v1  v2 v3
> > 1     2   3  4
> > 2     5   6  4
> > 3     1   3  4
> > 4     1   3  4
> > 5     2   3  4
> > 6     2   3  4
> >
> >
> > df2 <-
> > time v11  v12 v13
> > 3     112   3  4
> > 4     112   3  4
> >
> > By matching the 'time' column in df1 and df2, I am trying to modify
> column
> > 'v1' in df1 by replacing it
> > with values in column 'v11' in df2. The modified df1 should look
> something
> > like this:
> >
> > df1 <-
> > time v1   v2 v3
> > 1     2   3  4
> > 2     5   6  4
> > 3     112 3  4
> > 4     112 3  4
> > 5     2   3  4
> > 6     2   3  4
> >
> > I tried to use the 'merge' function to combine df1 and df2 followed by
> > the conditional 'ifelse' statement. However, that doesn't seem to work.
> >
> > Can I replace the values in df1 by not merging the two data frames?
> >
> > Thanks for your help,
> >
> > Regards,
> > Bhaskar
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Feb 12 21:55:56 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 12 Feb 2017 12:55:56 -0800
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <78845307.2701201.1486902860381@mail.yahoo.com>
References: <78845307.2701201.1486902860381.ref@mail.yahoo.com>
	<78845307.2701201.1486902860381@mail.yahoo.com>
Message-ID: <CAF8bMcYO4gEJLgjdESsbF_Djr3CS5SH47Fj8RsfjKdFBB9ub0w@mail.gmail.com>

> Error in forecast[[d + 1]] = paste(index(lEJReturnsOffset[windowLength]),  : object of type 'closure' is not subsettable

A 'closure' is a function and you cannot use '[' or '[[' to make a
subset of a function.

You used
   forecast[d+1] <- ...
in one branch of the 'if' statement and
   forecasts[d+1] <- ...
in the other.  Do you see the problem now?

By the way, the code snippet in the error message says '[[d+1]]' but
the code you supplied has '[d+1]'.  Does the html mangling selectively
double brackets or did you not show us the code that generated that
message?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Feb 12, 2017 at 4:34 AM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> Hi.
> I tried to run this R-code but still completely no idea why it still gives error message: Error in forecast[[d + 1]] = paste(index(lEJReturnsOffset[windowLength]),  : object of type 'closure' is not subsettable
> Here is the R-code:
> library(rugarch); library(sos); library(forecast);library(lattice)library(quantmod); require(stochvol); require(fBasics);data = read.table("EURJPY.m1440.csv", header=F)names(data)data=ts(data)lEJ=log(data)lret.EJ = 100*diff(lEJ)lret.EJ = ts(lret.EJ)lret.EJ[as.character(head(index(lret.EJ)))]=0windowLength=500foreLength=length(lret.EJ)-windowLengthforecasts<-vector(mode="character", length=foreLength)for (d in 0:foreLength) {  lEJReturnsOffset=lret.EJ[(1+d):(windowLength+d)]  final.aic<-Inf  final.order<-c(0,0,0)  for (p in 0:5) for (q in 0:5) {    if(p == 0 && q == 0) {      next    }        arimaFit=tryCatch(arima(lEJReturnsOffset, order=c(p,0,q)),                      error=function(err)FALSE,                      warning=function(err)FALSE)    if(!is.logical(arimaFit)) {      current.aic<-AIC(arimaFit)      if(current.aic<final.aic) {        final.aic<-current.aic        final.order<-c(p,0,q)        final.arima<-arima(lEJReturnsOffset, order=final.order)      }    } else {      next    }  }
> spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1,1)),                     mean.model = list(armaOrder = c(final.order[1], final.order[3]), arfima = FALSE, include.mean = TRUE),                     distribution.model = "sged")fit <- tryCatch(ugarchfit(spec, lEJReturnsOffset, solver='gosolnp'),  error=function(e) e, warning=function(w) w)if(is(fit, "warning")) {  forecast[d+1]=paste(index(lEJReturnsOffset[windowLength]), 1, sep=",")  print(paste(index(lEJReturnsOffset[windowLength]), 1, sep=","))} else {  fore = ugarchforecast(fit, n.ahead=1)  ind = fore at forecast$seriesFor  forecasts[d+1] = paste(colnames(ind), ifelse(ind[1] < 0, -1, 1), sep=",")  print(paste(colnames(ind), ifelse(ind[1] < 0, -1, 1), sep=",")) }}write.csv(forecasts, file="forecasts.csv", row.names=FALSE)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From george.trojan at noaa.gov  Sun Feb 12 23:11:08 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Sun, 12 Feb 2017 22:11:08 +0000
Subject: [R] Help with saving user defined functions
Message-ID: <CABie7_rg7uOBCG43Q8eqAJ8x6SCeg6BLi_aA1TBNwJARSXNsow@mail.gmail.com>

I can't figure out how to save functions to RDS file. Here is an example
what I am trying to achieve:

> t <- rnorm(100)
> cdf <- ecdf(t)
> cdf(0)
[1] 0.59
> saveRDS(cdf, "/tmp/foo")
>
Save workspace image? [y/n/c]: n
[gtrojan at asok petproject]$ R
> cdf <- readRDS("/tmp/foo")
> cdf
Empirical CDF
Call: ecdf(t)
x[1:100] = -2.8881, -2.2054, -2.0026,  ..., 2.0367, 2.0414

This works. However when instead of saving cdf() I try to save function

> trans <- function(x) qnorm(cdf(x) * 0.99)

after restoring object from file I get an error:

> trans <- readRDS("/tmp/foo")
> trans(0)
Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"

I tried to define and call cdf within the definition of trans, without
success:

> tmp <- rnorm(100)
> trans <- function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
> saveRDS(trans, "/tmp/foo")
Save workspace image? [y/n/c]: n

> trans <- readRDS("/tmp/foo")
> trans
function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
> trans(0)
Error in sort(x) : object 'tmp' not found

So, here the call cdf(0) did not force evaluation of my random sample. What
am I missing?

George

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Mon Feb 13 00:30:49 2017
From: valkremk at gmail.com (Val)
Date: Sun, 12 Feb 2017 17:30:49 -0600
Subject: [R] remove
In-Reply-To: <alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
Message-ID: <CAJOiR6bDtpSGH_fb0yzZ2km01NW5fg+9GsbtsBAf5Hnp+UCrhA@mail.gmail.com>

Hi Jeff and all,
 How do I get the  number of unique first names   in the two data sets?

for the first one,
result2 <- DF[ 1 == err2, ]
length(unique(result2$first))




On Sun, Feb 12, 2017 at 12:42 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> The "by" function aggregates and returns a result with generally fewer rows
> than the original data. Since you are looking to index the rows in the
> original data set, the "ave" function is better suited because it always
> returns a vector that is just as long as the input vector:
>
> # I usually work with character data rather than factors if I plan
> # to modify the data (e.g. removing rows)
> DF <- read.table( text=
> 'first  week last
> Alex    1  West
> Bob     1  John
> Cory    1  Jack
> Cory    2  Jack
> Bob     2  John
> Bob     3  John
> Alex    2  Joseph
> Alex    3  West
> Alex    4  West
> ', header = TRUE, as.is = TRUE )
>
> err <- ave( DF$last
>           , DF[ , "first", drop = FALSE]
>           , FUN = function( lst ) {
>               length( unique( lst ) )
>             }
>           )
> result <- DF[ "1" == err, ]
> result
>
> Notice that the ave function returns a vector of the same type as was given
> to it, so even though the function returns a numeric the err
> vector is character.
>
> If you wanted to be able to examine more than one other column in
> determining the keep/reject decision, you could do:
>
> err2 <- ave( seq_along( DF$first )
>            , DF[ , "first", drop = FALSE]
>            , FUN = function( n ) {
>               length( unique( DF[ n, "last" ] ) )
>              }
>            )
> result2 <- DF[ 1 == err2, ]
> result2
>
> and then you would have the option to re-use the "n" index to look at other
> columns as well.
>
> Finally, here is a dplyr solution:
>
> library(dplyr)
> result3 <- (   DF
>            %>% group_by( first ) # like a prep for ave or by
>            %>% mutate( err = length( unique( last ) ) ) # similar to ave
>            %>% filter( 1 == err ) # drop the rows with too many last names
>            %>% select( -err ) # drop the temporary column
>            %>% as.data.frame # convert back to a plain-jane data frame
>            )
> result3
>
> which uses a small set of verbs in a pipeline of functions to go from input
> to result in one pass.
>
> If your data set is really big (running out of memory big) then you might
> want to investigate the data.table or sqlite packages, either of which can
> be combined with dplyr to get a standardized syntax for managing larger
> amounts of data. However, most people actually aren't running out of memory
> so in most cases the extra horsepower isn't actually needed.
>
>
> On Sun, 12 Feb 2017, P Tennant wrote:
>
>> Hi Val,
>>
>> The by() function could be used here. With the dataframe dfr:
>>
>> # split the data by first name and check for more than one last name for
>> each first name
>> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
>> # make the result more easily manipulated
>> res <- as.table(res)
>> res
>> # first
>> # Alex   Bob  Cory
>> # TRUE FALSE FALSE
>>
>> # then use this result to subset the data
>> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
>> # sort if needed
>> nw.dfr[order(nw.dfr$first) , ]
>>
>>  first week last
>> 2   Bob    1 John
>> 5   Bob    2 John
>> 6   Bob    3 John
>> 3  Cory    1 Jack
>> 4  Cory    2 Jack
>>
>>
>> Philip
>>
>> On 12/02/2017 4:02 PM, Val wrote:
>>>
>>> Hi all,
>>> I have a big data set and want to  remove rows conditionally.
>>> In my data file  each person were recorded  for several weeks. Somehow
>>> during the recording periods, their last name was misreported.   For
>>> each person,   the last name should be the same. Otherwise remove from
>>> the data. Example, in the following data set, Alex was found to have
>>> two last names .
>>>
>>> Alex   West
>>> Alex   Joseph
>>>
>>> Alex should be removed  from the data.  if this happens then I want
>>> remove  all rows with Alex. Here is my data set
>>>
>>> df<- read.table(header=TRUE, text='first  week last
>>> Alex    1  West
>>> Bob     1  John
>>> Cory    1  Jack
>>> Cory    2  Jack
>>> Bob     2  John
>>> Bob     3  John
>>> Alex    2  Joseph
>>> Alex    3  West
>>> Alex    4  West ')
>>>
>>> Desired output
>>>
>>>        first  week last
>>> 1     Bob     1   John
>>> 2     Bob     2   John
>>> 3     Bob     3   John
>>> 4     Cory     1   Jack
>>> 5     Cory     2   Jack
>>>
>>> Thank you in advance
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From bgunter.4567 at gmail.com  Mon Feb 13 01:05:31 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Feb 2017 16:05:31 -0800
Subject: [R] Help with saving user defined functions
In-Reply-To: <CABie7_rg7uOBCG43Q8eqAJ8x6SCeg6BLi_aA1TBNwJARSXNsow@mail.gmail.com>
References: <CABie7_rg7uOBCG43Q8eqAJ8x6SCeg6BLi_aA1TBNwJARSXNsow@mail.gmail.com>
Message-ID: <CAGxFJbQ7gEOO=Ajs4i-G_QzC4xssjqcgD8=YyBv_T4ric-CaZA@mail.gmail.com>

It worked fine for me:

> t <- rnorm(100)
> cdf <- ecdf(t)
>
> trans <- function(x) qnorm(cdf(x) * 0.99)
> saveRDS(trans, "/tmp/foo")
> trans(1.2)
[1] 1.042457
> trans1 <- readRDS("/tmp/foo")
> trans1(0)
[1] 0.1117773


Of course, if I remove cdf() from the global environment, it will fail:

> rm(cdf)
> trans1(0)
Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"

So it looks like you're clearing you global workspace in between
saving and loading?

You may need to read up on function closures/lexical scoping : A
user-defined function in R includes not only code but also a pointer
to the environment in which it was defined, in your case, the global
environment from which you apparently removed cdf(). Note that
functions are not evauated until called, so free variables in the
functions that do not or will not exist in the function's lexical
scope when called will not trigger any errors until the function *is*
called.

Same comments for your second version -- if tmp is removed the
function will fail.



Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Feb 12, 2017 at 2:11 PM, George Trojan - NOAA Federal
<george.trojan at noaa.gov> wrote:
> I can't figure out how to save functions to RDS file. Here is an example
> what I am trying to achieve:
>
>> t <- rnorm(100)
>> cdf <- ecdf(t)
>> cdf(0)
> [1] 0.59
>> saveRDS(cdf, "/tmp/foo")
>>
> Save workspace image? [y/n/c]: n
> [gtrojan at asok petproject]$ R
>> cdf <- readRDS("/tmp/foo")
>> cdf
> Empirical CDF
> Call: ecdf(t)
> x[1:100] = -2.8881, -2.2054, -2.0026,  ..., 2.0367, 2.0414
>
> This works. However when instead of saving cdf() I try to save function
>
>> trans <- function(x) qnorm(cdf(x) * 0.99)
>
> after restoring object from file I get an error:
>
>> trans <- readRDS("/tmp/foo")
>> trans(0)
> Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>
> I tried to define and call cdf within the definition of trans, without
> success:
>
>> tmp <- rnorm(100)
>> trans <- function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
>> saveRDS(trans, "/tmp/foo")
> Save workspace image? [y/n/c]: n
>
>> trans <- readRDS("/tmp/foo")
>> trans
> function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
>> trans(0)
> Error in sort(x) : object 'tmp' not found
>
> So, here the call cdf(0) did not force evaluation of my random sample. What
> am I missing?
>
> George
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reichmanj at sbcglobal.net  Mon Feb 13 01:23:10 2017
From: reichmanj at sbcglobal.net (Jeff Reichman)
Date: Sun, 12 Feb 2017 18:23:10 -0600
Subject: [R] Converting Excel Date format into R-Date formats
Message-ID: <000001d2858f$5bcf5e60$136e1b20$@sbcglobal.net>

R-Help Group

 

What is the proper way to convert excel date formats to R-Date format.

 


Event ID

Event Date

Event Type


250013

1-Jan-09

NSAG Attack


250015

1-Jan-09

NSAG Attack


250016

1-Jan-09

NSAG Attack

 

Obviously this is wrong 

 

        df$Event.Date <- as.Date(df$Event.Date, "%d-%b-%y")

 

as it return "NA"

 

Jeff

 


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Feb 13 01:26:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 12 Feb 2017 16:26:16 -0800
Subject: [R] Help with saving user defined functions
In-Reply-To: <CAGxFJbQ7gEOO=Ajs4i-G_QzC4xssjqcgD8=YyBv_T4ric-CaZA@mail.gmail.com>
References: <CABie7_rg7uOBCG43Q8eqAJ8x6SCeg6BLi_aA1TBNwJARSXNsow@mail.gmail.com>
	<CAGxFJbQ7gEOO=Ajs4i-G_QzC4xssjqcgD8=YyBv_T4ric-CaZA@mail.gmail.com>
Message-ID: <ADD690DA-3246-4A99-BABE-7D0007B2C501@dcn.davis.ca.us>

So doesn't the fact that a function contains a reference to an environment suggest that this whole exercise is a really bad idea?
-- 
Sent from my phone. Please excuse my brevity.

On February 12, 2017 4:05:31 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>It worked fine for me:
>
>> t <- rnorm(100)
>> cdf <- ecdf(t)
>>
>> trans <- function(x) qnorm(cdf(x) * 0.99)
>> saveRDS(trans, "/tmp/foo")
>> trans(1.2)
>[1] 1.042457
>> trans1 <- readRDS("/tmp/foo")
>> trans1(0)
>[1] 0.1117773
>
>
>Of course, if I remove cdf() from the global environment, it will fail:
>
>> rm(cdf)
>> trans1(0)
>Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>
>So it looks like you're clearing you global workspace in between
>saving and loading?
>
>You may need to read up on function closures/lexical scoping : A
>user-defined function in R includes not only code but also a pointer
>to the environment in which it was defined, in your case, the global
>environment from which you apparently removed cdf(). Note that
>functions are not evauated until called, so free variables in the
>functions that do not or will not exist in the function's lexical
>scope when called will not trigger any errors until the function *is*
>called.
>
>Same comments for your second version -- if tmp is removed the
>function will fail.
>
>
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Feb 12, 2017 at 2:11 PM, George Trojan - NOAA Federal
><george.trojan at noaa.gov> wrote:
>> I can't figure out how to save functions to RDS file. Here is an
>example
>> what I am trying to achieve:
>>
>>> t <- rnorm(100)
>>> cdf <- ecdf(t)
>>> cdf(0)
>> [1] 0.59
>>> saveRDS(cdf, "/tmp/foo")
>>>
>> Save workspace image? [y/n/c]: n
>> [gtrojan at asok petproject]$ R
>>> cdf <- readRDS("/tmp/foo")
>>> cdf
>> Empirical CDF
>> Call: ecdf(t)
>> x[1:100] = -2.8881, -2.2054, -2.0026,  ..., 2.0367, 2.0414
>>
>> This works. However when instead of saving cdf() I try to save
>function
>>
>>> trans <- function(x) qnorm(cdf(x) * 0.99)
>>
>> after restoring object from file I get an error:
>>
>>> trans <- readRDS("/tmp/foo")
>>> trans(0)
>> Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>>
>> I tried to define and call cdf within the definition of trans,
>without
>> success:
>>
>>> tmp <- rnorm(100)
>>> trans <- function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) *
>0.99 }
>>> saveRDS(trans, "/tmp/foo")
>> Save workspace image? [y/n/c]: n
>>
>>> trans <- readRDS("/tmp/foo")
>>> trans
>> function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
>>> trans(0)
>> Error in sort(x) : object 'tmp' not found
>>
>> So, here the call cdf(0) did not force evaluation of my random
>sample. What
>> am I missing?
>>
>> George
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Feb 13 01:31:23 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 12 Feb 2017 16:31:23 -0800
Subject: [R] remove
In-Reply-To: <CAJOiR6bDtpSGH_fb0yzZ2km01NW5fg+9GsbtsBAf5Hnp+UCrhA@mail.gmail.com>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
	<CAJOiR6bDtpSGH_fb0yzZ2km01NW5fg+9GsbtsBAf5Hnp+UCrhA@mail.gmail.com>
Message-ID: <EDE98E7C-0602-46E5-8C6B-28C3C6A200D2@dcn.davis.ca.us>

Your question mystifies me, since it looks to me like you already know the answer. 
-- 
Sent from my phone. Please excuse my brevity.

On February 12, 2017 3:30:49 PM PST, Val <valkremk at gmail.com> wrote:
>Hi Jeff and all,
> How do I get the  number of unique first names   in the two data sets?
>
>for the first one,
>result2 <- DF[ 1 == err2, ]
>length(unique(result2$first))
>
>
>
>
>On Sun, Feb 12, 2017 at 12:42 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> The "by" function aggregates and returns a result with generally
>fewer rows
>> than the original data. Since you are looking to index the rows in
>the
>> original data set, the "ave" function is better suited because it
>always
>> returns a vector that is just as long as the input vector:
>>
>> # I usually work with character data rather than factors if I plan
>> # to modify the data (e.g. removing rows)
>> DF <- read.table( text=
>> 'first  week last
>> Alex    1  West
>> Bob     1  John
>> Cory    1  Jack
>> Cory    2  Jack
>> Bob     2  John
>> Bob     3  John
>> Alex    2  Joseph
>> Alex    3  West
>> Alex    4  West
>> ', header = TRUE, as.is = TRUE )
>>
>> err <- ave( DF$last
>>           , DF[ , "first", drop = FALSE]
>>           , FUN = function( lst ) {
>>               length( unique( lst ) )
>>             }
>>           )
>> result <- DF[ "1" == err, ]
>> result
>>
>> Notice that the ave function returns a vector of the same type as was
>given
>> to it, so even though the function returns a numeric the err
>> vector is character.
>>
>> If you wanted to be able to examine more than one other column in
>> determining the keep/reject decision, you could do:
>>
>> err2 <- ave( seq_along( DF$first )
>>            , DF[ , "first", drop = FALSE]
>>            , FUN = function( n ) {
>>               length( unique( DF[ n, "last" ] ) )
>>              }
>>            )
>> result2 <- DF[ 1 == err2, ]
>> result2
>>
>> and then you would have the option to re-use the "n" index to look at
>other
>> columns as well.
>>
>> Finally, here is a dplyr solution:
>>
>> library(dplyr)
>> result3 <- (   DF
>>            %>% group_by( first ) # like a prep for ave or by
>>            %>% mutate( err = length( unique( last ) ) ) # similar to
>ave
>>            %>% filter( 1 == err ) # drop the rows with too many last
>names
>>            %>% select( -err ) # drop the temporary column
>>            %>% as.data.frame # convert back to a plain-jane data
>frame
>>            )
>> result3
>>
>> which uses a small set of verbs in a pipeline of functions to go from
>input
>> to result in one pass.
>>
>> If your data set is really big (running out of memory big) then you
>might
>> want to investigate the data.table or sqlite packages, either of
>which can
>> be combined with dplyr to get a standardized syntax for managing
>larger
>> amounts of data. However, most people actually aren't running out of
>memory
>> so in most cases the extra horsepower isn't actually needed.
>>
>>
>> On Sun, 12 Feb 2017, P Tennant wrote:
>>
>>> Hi Val,
>>>
>>> The by() function could be used here. With the dataframe dfr:
>>>
>>> # split the data by first name and check for more than one last name
>for
>>> each first name
>>> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
>>> # make the result more easily manipulated
>>> res <- as.table(res)
>>> res
>>> # first
>>> # Alex   Bob  Cory
>>> # TRUE FALSE FALSE
>>>
>>> # then use this result to subset the data
>>> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
>>> # sort if needed
>>> nw.dfr[order(nw.dfr$first) , ]
>>>
>>>  first week last
>>> 2   Bob    1 John
>>> 5   Bob    2 John
>>> 6   Bob    3 John
>>> 3  Cory    1 Jack
>>> 4  Cory    2 Jack
>>>
>>>
>>> Philip
>>>
>>> On 12/02/2017 4:02 PM, Val wrote:
>>>>
>>>> Hi all,
>>>> I have a big data set and want to  remove rows conditionally.
>>>> In my data file  each person were recorded  for several weeks.
>Somehow
>>>> during the recording periods, their last name was misreported.  
>For
>>>> each person,   the last name should be the same. Otherwise remove
>from
>>>> the data. Example, in the following data set, Alex was found to
>have
>>>> two last names .
>>>>
>>>> Alex   West
>>>> Alex   Joseph
>>>>
>>>> Alex should be removed  from the data.  if this happens then I want
>>>> remove  all rows with Alex. Here is my data set
>>>>
>>>> df<- read.table(header=TRUE, text='first  week last
>>>> Alex    1  West
>>>> Bob     1  John
>>>> Cory    1  Jack
>>>> Cory    2  Jack
>>>> Bob     2  John
>>>> Bob     3  John
>>>> Alex    2  Joseph
>>>> Alex    3  West
>>>> Alex    4  West ')
>>>>
>>>> Desired output
>>>>
>>>>        first  week last
>>>> 1     Bob     1   John
>>>> 2     Bob     2   John
>>>> 3     Bob     3   John
>>>> 4     Cory     1   Jack
>>>> 5     Cory     2   Jack
>>>>
>>>> Thank you in advance
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------


From bgunter.4567 at gmail.com  Mon Feb 13 02:12:27 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Feb 2017 17:12:27 -0800
Subject: [R] Help with saving user defined functions
In-Reply-To: <ADD690DA-3246-4A99-BABE-7D0007B2C501@dcn.davis.ca.us>
References: <CABie7_rg7uOBCG43Q8eqAJ8x6SCeg6BLi_aA1TBNwJARSXNsow@mail.gmail.com>
	<CAGxFJbQ7gEOO=Ajs4i-G_QzC4xssjqcgD8=YyBv_T4ric-CaZA@mail.gmail.com>
	<ADD690DA-3246-4A99-BABE-7D0007B2C501@dcn.davis.ca.us>
Message-ID: <CAGxFJbTdXMryG6zVzhPyG+4o4eCVAsoU2_fQChC+13NW_+D_8Q@mail.gmail.com>

Jeff:

Oh yes!-- and I meant to say so and forgot, so I'm glad you did. Not
only might the free variable in the function not be there; worse yet,
it might be there but something else. So it seems like a disaster
waiting to happen. The solution, I would presume, is to have no free
variables (make them arguments). Or save and read the function *and*
its environment.  Namespaces in packages I think would also take care
of this, right?

Note: If my understanding on any of this is incorrect, I would greatly
appreciate someone settting me straight. In particular, as Jeff noted,
my understanding is that saving a function (closure)  with a free
variable in the function depends on the function finding its enclosing
environment when it is read back into R via readRDS() .  Correct?  The
man page is silent on this point.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Feb 12, 2017 at 4:26 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> So doesn't the fact that a function contains a reference to an environment suggest that this whole exercise is a really bad idea?
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 12, 2017 4:05:31 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>It worked fine for me:
>>
>>> t <- rnorm(100)
>>> cdf <- ecdf(t)
>>>
>>> trans <- function(x) qnorm(cdf(x) * 0.99)
>>> saveRDS(trans, "/tmp/foo")
>>> trans(1.2)
>>[1] 1.042457
>>> trans1 <- readRDS("/tmp/foo")
>>> trans1(0)
>>[1] 0.1117773
>>
>>
>>Of course, if I remove cdf() from the global environment, it will fail:
>>
>>> rm(cdf)
>>> trans1(0)
>>Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>>
>>So it looks like you're clearing you global workspace in between
>>saving and loading?
>>
>>You may need to read up on function closures/lexical scoping : A
>>user-defined function in R includes not only code but also a pointer
>>to the environment in which it was defined, in your case, the global
>>environment from which you apparently removed cdf(). Note that
>>functions are not evauated until called, so free variables in the
>>functions that do not or will not exist in the function's lexical
>>scope when called will not trigger any errors until the function *is*
>>called.
>>
>>Same comments for your second version -- if tmp is removed the
>>function will fail.
>>
>>
>>
>>Cheers,
>>Bert
>>
>>
>>Bert Gunter
>>
>>"The trouble with having an open mind is that people keep coming along
>>and sticking things into it."
>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>On Sun, Feb 12, 2017 at 2:11 PM, George Trojan - NOAA Federal
>><george.trojan at noaa.gov> wrote:
>>> I can't figure out how to save functions to RDS file. Here is an
>>example
>>> what I am trying to achieve:
>>>
>>>> t <- rnorm(100)
>>>> cdf <- ecdf(t)
>>>> cdf(0)
>>> [1] 0.59
>>>> saveRDS(cdf, "/tmp/foo")
>>>>
>>> Save workspace image? [y/n/c]: n
>>> [gtrojan at asok petproject]$ R
>>>> cdf <- readRDS("/tmp/foo")
>>>> cdf
>>> Empirical CDF
>>> Call: ecdf(t)
>>> x[1:100] = -2.8881, -2.2054, -2.0026,  ..., 2.0367, 2.0414
>>>
>>> This works. However when instead of saving cdf() I try to save
>>function
>>>
>>>> trans <- function(x) qnorm(cdf(x) * 0.99)
>>>
>>> after restoring object from file I get an error:
>>>
>>>> trans <- readRDS("/tmp/foo")
>>>> trans(0)
>>> Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>>>
>>> I tried to define and call cdf within the definition of trans,
>>without
>>> success:
>>>
>>>> tmp <- rnorm(100)
>>>> trans <- function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) *
>>0.99 }
>>>> saveRDS(trans, "/tmp/foo")
>>> Save workspace image? [y/n/c]: n
>>>
>>>> trans <- readRDS("/tmp/foo")
>>>> trans
>>> function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
>>>> trans(0)
>>> Error in sort(x) : object 'tmp' not found
>>>
>>> So, here the call cdf(0) did not force evaluation of my random
>>sample. What
>>> am I missing?
>>>
>>> George
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Mon Feb 13 02:28:53 2017
From: valkremk at gmail.com (Val)
Date: Sun, 12 Feb 2017 19:28:53 -0600
Subject: [R] remove
In-Reply-To: <EDE98E7C-0602-46E5-8C6B-28C3C6A200D2@dcn.davis.ca.us>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
	<CAJOiR6bDtpSGH_fb0yzZ2km01NW5fg+9GsbtsBAf5Hnp+UCrhA@mail.gmail.com>
	<EDE98E7C-0602-46E5-8C6B-28C3C6A200D2@dcn.davis.ca.us>
Message-ID: <CAJOiR6b6-hF+HvsjdidPDcuwJ0tU58J18=sjk2A8EMxediSHbw@mail.gmail.com>

Sorry  Jeff, I did not finish my email. I accidentally touched the send button.
My question was the
when I used this one
length(unique(result2$first))
     vs
dim(result2[!duplicated(result2[,c('first')]),]) [1]

I did get different results but now I found out the problem.

Thank you!.








On Sun, Feb 12, 2017 at 6:31 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Your question mystifies me, since it looks to me like you already know the answer.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 12, 2017 3:30:49 PM PST, Val <valkremk at gmail.com> wrote:
>>Hi Jeff and all,
>> How do I get the  number of unique first names   in the two data sets?
>>
>>for the first one,
>>result2 <- DF[ 1 == err2, ]
>>length(unique(result2$first))
>>
>>
>>
>>
>>On Sun, Feb 12, 2017 at 12:42 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>> The "by" function aggregates and returns a result with generally
>>fewer rows
>>> than the original data. Since you are looking to index the rows in
>>the
>>> original data set, the "ave" function is better suited because it
>>always
>>> returns a vector that is just as long as the input vector:
>>>
>>> # I usually work with character data rather than factors if I plan
>>> # to modify the data (e.g. removing rows)
>>> DF <- read.table( text=
>>> 'first  week last
>>> Alex    1  West
>>> Bob     1  John
>>> Cory    1  Jack
>>> Cory    2  Jack
>>> Bob     2  John
>>> Bob     3  John
>>> Alex    2  Joseph
>>> Alex    3  West
>>> Alex    4  West
>>> ', header = TRUE, as.is = TRUE )
>>>
>>> err <- ave( DF$last
>>>           , DF[ , "first", drop = FALSE]
>>>           , FUN = function( lst ) {
>>>               length( unique( lst ) )
>>>             }
>>>           )
>>> result <- DF[ "1" == err, ]
>>> result
>>>
>>> Notice that the ave function returns a vector of the same type as was
>>given
>>> to it, so even though the function returns a numeric the err
>>> vector is character.
>>>
>>> If you wanted to be able to examine more than one other column in
>>> determining the keep/reject decision, you could do:
>>>
>>> err2 <- ave( seq_along( DF$first )
>>>            , DF[ , "first", drop = FALSE]
>>>            , FUN = function( n ) {
>>>               length( unique( DF[ n, "last" ] ) )
>>>              }
>>>            )
>>> result2 <- DF[ 1 == err2, ]
>>> result2
>>>
>>> and then you would have the option to re-use the "n" index to look at
>>other
>>> columns as well.
>>>
>>> Finally, here is a dplyr solution:
>>>
>>> library(dplyr)
>>> result3 <- (   DF
>>>            %>% group_by( first ) # like a prep for ave or by
>>>            %>% mutate( err = length( unique( last ) ) ) # similar to
>>ave
>>>            %>% filter( 1 == err ) # drop the rows with too many last
>>names
>>>            %>% select( -err ) # drop the temporary column
>>>            %>% as.data.frame # convert back to a plain-jane data
>>frame
>>>            )
>>> result3
>>>
>>> which uses a small set of verbs in a pipeline of functions to go from
>>input
>>> to result in one pass.
>>>
>>> If your data set is really big (running out of memory big) then you
>>might
>>> want to investigate the data.table or sqlite packages, either of
>>which can
>>> be combined with dplyr to get a standardized syntax for managing
>>larger
>>> amounts of data. However, most people actually aren't running out of
>>memory
>>> so in most cases the extra horsepower isn't actually needed.
>>>
>>>
>>> On Sun, 12 Feb 2017, P Tennant wrote:
>>>
>>>> Hi Val,
>>>>
>>>> The by() function could be used here. With the dataframe dfr:
>>>>
>>>> # split the data by first name and check for more than one last name
>>for
>>>> each first name
>>>> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
>>>> # make the result more easily manipulated
>>>> res <- as.table(res)
>>>> res
>>>> # first
>>>> # Alex   Bob  Cory
>>>> # TRUE FALSE FALSE
>>>>
>>>> # then use this result to subset the data
>>>> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
>>>> # sort if needed
>>>> nw.dfr[order(nw.dfr$first) , ]
>>>>
>>>>  first week last
>>>> 2   Bob    1 John
>>>> 5   Bob    2 John
>>>> 6   Bob    3 John
>>>> 3  Cory    1 Jack
>>>> 4  Cory    2 Jack
>>>>
>>>>
>>>> Philip
>>>>
>>>> On 12/02/2017 4:02 PM, Val wrote:
>>>>>
>>>>> Hi all,
>>>>> I have a big data set and want to  remove rows conditionally.
>>>>> In my data file  each person were recorded  for several weeks.
>>Somehow
>>>>> during the recording periods, their last name was misreported.
>>For
>>>>> each person,   the last name should be the same. Otherwise remove
>>from
>>>>> the data. Example, in the following data set, Alex was found to
>>have
>>>>> two last names .
>>>>>
>>>>> Alex   West
>>>>> Alex   Joseph
>>>>>
>>>>> Alex should be removed  from the data.  if this happens then I want
>>>>> remove  all rows with Alex. Here is my data set
>>>>>
>>>>> df<- read.table(header=TRUE, text='first  week last
>>>>> Alex    1  West
>>>>> Bob     1  John
>>>>> Cory    1  Jack
>>>>> Cory    2  Jack
>>>>> Bob     2  John
>>>>> Bob     3  John
>>>>> Alex    2  Joseph
>>>>> Alex    3  West
>>>>> Alex    4  West ')
>>>>>
>>>>> Desired output
>>>>>
>>>>>        first  week last
>>>>> 1     Bob     1   John
>>>>> 2     Bob     2   John
>>>>> 3     Bob     3   John
>>>>> 4     Cory     1   Jack
>>>>> 5     Cory     2   Jack
>>>>>
>>>>> Thank you in advance
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------


From george.trojan at noaa.gov  Mon Feb 13 02:31:40 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Mon, 13 Feb 2017 01:31:40 +0000
Subject: [R] Help with saving user defined functions
In-Reply-To: <CAGxFJbQ7gEOO=Ajs4i-G_QzC4xssjqcgD8=YyBv_T4ric-CaZA@mail.gmail.com>
References: <CABie7_rg7uOBCG43Q8eqAJ8x6SCeg6BLi_aA1TBNwJARSXNsow@mail.gmail.com>
	<CAGxFJbQ7gEOO=Ajs4i-G_QzC4xssjqcgD8=YyBv_T4ric-CaZA@mail.gmail.com>
Message-ID: <CABie7_raOnKVEqaLK+t-znLU0Q7jO2HK=xpu9LWfQo=+vc2YxA@mail.gmail.com>

I want to split my computation into parts. The first script processes the
data, the second does the graphics. I want to save  results of
time-consuming calculations. My example tried to simulate this by terminate
the session without saving it, so the environment was lost on purpose. What
confuses me that ecdf can be saved and restored, but not my own derived
function.
Of course I can save parameters and redefine the function in the second
script.

Reading Chapter 8 of Advanced R, hopefully the book will clear my mind.

On Mon, Feb 13, 2017 at 12:05 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> It worked fine for me:
>
> > t <- rnorm(100)
> > cdf <- ecdf(t)
> >
> > trans <- function(x) qnorm(cdf(x) * 0.99)
> > saveRDS(trans, "/tmp/foo")
> > trans(1.2)
> [1] 1.042457
> > trans1 <- readRDS("/tmp/foo")
> > trans1(0)
> [1] 0.1117773
>
>
> Of course, if I remove cdf() from the global environment, it will fail:
>
> > rm(cdf)
> > trans1(0)
> Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>
> So it looks like you're clearing you global workspace in between
> saving and loading?
>
> You may need to read up on function closures/lexical scoping : A
> user-defined function in R includes not only code but also a pointer
> to the environment in which it was defined, in your case, the global
> environment from which you apparently removed cdf(). Note that
> functions are not evauated until called, so free variables in the
> functions that do not or will not exist in the function's lexical
> scope when called will not trigger any errors until the function *is*
> called.
>
> Same comments for your second version -- if tmp is removed the
> function will fail.
>
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Feb 12, 2017 at 2:11 PM, George Trojan - NOAA Federal
> <george.trojan at noaa.gov> wrote:
> > I can't figure out how to save functions to RDS file. Here is an example
> > what I am trying to achieve:
> >
> >> t <- rnorm(100)
> >> cdf <- ecdf(t)
> >> cdf(0)
> > [1] 0.59
> >> saveRDS(cdf, "/tmp/foo")
> >>
> > Save workspace image? [y/n/c]: n
> > [gtrojan at asok petproject]$ R
> >> cdf <- readRDS("/tmp/foo")
> >> cdf
> > Empirical CDF
> > Call: ecdf(t)
> > x[1:100] = -2.8881, -2.2054, -2.0026,  ..., 2.0367, 2.0414
> >
> > This works. However when instead of saving cdf() I try to save function
> >
> >> trans <- function(x) qnorm(cdf(x) * 0.99)
> >
> > after restoring object from file I get an error:
> >
> >> trans <- readRDS("/tmp/foo")
> >> trans(0)
> > Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
> >
> > I tried to define and call cdf within the definition of trans, without
> > success:
> >
> >> tmp <- rnorm(100)
> >> trans <- function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
> >> saveRDS(trans, "/tmp/foo")
> > Save workspace image? [y/n/c]: n
> >
> >> trans <- readRDS("/tmp/foo")
> >> trans
> > function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
> >> trans(0)
> > Error in sort(x) : object 'tmp' not found
> >
> > So, here the call cdf(0) did not force evaluation of my random sample.
> What
> > am I missing?
> >
> > George
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Feb 13 04:00:55 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 13 Feb 2017 14:00:55 +1100
Subject: [R] Converting Excel Date format into R-Date formats
In-Reply-To: <000001d2858f$5bcf5e60$136e1b20$@sbcglobal.net>
References: <000001d2858f$5bcf5e60$136e1b20$@sbcglobal.net>
Message-ID: <CA+8X3fWbJ+3LPOLP_Mb-tHuaRYrKp9Zt2APBBxaJX5BOPjA4FQ@mail.gmail.com>

Hi Jeff,
Most likely the "Event Date" field is a factor. Try this:

df$Event.Date <- as.Date(as.character(df$Event.Date),
 "%d-%b-%y")

Also beware of Excel's habit of silently converting mixed date formats
(i.e. dd/mm/yyyy and mm/dd/yyyy) to one or the other format. The only
way I know to prevent this is to stick to international (yyyy-mm-dd)
format in Excel.

Jim


On Mon, Feb 13, 2017 at 11:23 AM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> R-Help Group
>
>
>
> What is the proper way to convert excel date formats to R-Date format.
>
>
>
>
> Event ID
>
> Event Date
>
> Event Type
>
>
> 250013
>
> 1-Jan-09
>
> NSAG Attack
>
>
> 250015
>
> 1-Jan-09
>
> NSAG Attack
>
>
> 250016
>
> 1-Jan-09
>
> NSAG Attack
>
>
>
> Obviously this is wrong
>
>
>
>         df$Event.Date <- as.Date(df$Event.Date, "%d-%b-%y")
>
>
>
> as it return "NA"
>
>
>
> Jeff
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Mon Feb 13 05:18:37 2017
From: valkremk at gmail.com (Val)
Date: Sun, 12 Feb 2017 22:18:37 -0600
Subject: [R] remove
In-Reply-To: <CAJOiR6b6-hF+HvsjdidPDcuwJ0tU58J18=sjk2A8EMxediSHbw@mail.gmail.com>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
	<CAJOiR6bDtpSGH_fb0yzZ2km01NW5fg+9GsbtsBAf5Hnp+UCrhA@mail.gmail.com>
	<EDE98E7C-0602-46E5-8C6B-28C3C6A200D2@dcn.davis.ca.us>
	<CAJOiR6b6-hF+HvsjdidPDcuwJ0tU58J18=sjk2A8EMxediSHbw@mail.gmail.com>
Message-ID: <CAJOiR6Z18SK1Wx12RSu2jvt=v4UfxCJJCXZKA7Uo1MgdDjh=Zw@mail.gmail.com>

Hi Jeff and All,

When I examined the excluded  data,  ie.,  first name with  with
different last names, I noticed that  some last names were  not
recorded
or instance, I modified the data as follows
DF <- read.table( text=
'first  week last
Alex    1  West
Bob     1  John
Cory    1  Jack
Cory    2     -
Bob     2  John
Bob     3  John
Alex    2  Joseph
Alex    3  West
Alex    4  West
', header = TRUE, as.is = TRUE )


err2 <- ave( seq_along( DF$first )
           , DF[ , "first", drop = FALSE]
           , FUN = function( n ) {
              length( unique( DF[ n, "last" ] ) )
             }
           )
result2 <- DF[ 1 == err2, ]
result2

first week last
2   Bob    1 John
5   Bob    2 John
6   Bob    3 John

However, I want keep Cory's record. It is assumed that not recorded
should have the same last name.

Final out put should be

first week last
   Bob    1 John
   Bob    2 John
   Bob    3 John
  Cory    1  Jack
  Cory    2   -

Thank you again!

On Sun, Feb 12, 2017 at 7:28 PM, Val <valkremk at gmail.com> wrote:
> Sorry  Jeff, I did not finish my email. I accidentally touched the send button.
> My question was the
> when I used this one
> length(unique(result2$first))
>      vs
> dim(result2[!duplicated(result2[,c('first')]),]) [1]
>
> I did get different results but now I found out the problem.
>
> Thank you!.
>
>
>
>
>
>
>
>
> On Sun, Feb 12, 2017 at 6:31 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> Your question mystifies me, since it looks to me like you already know the answer.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 12, 2017 3:30:49 PM PST, Val <valkremk at gmail.com> wrote:
>>>Hi Jeff and all,
>>> How do I get the  number of unique first names   in the two data sets?
>>>
>>>for the first one,
>>>result2 <- DF[ 1 == err2, ]
>>>length(unique(result2$first))
>>>
>>>
>>>
>>>
>>>On Sun, Feb 12, 2017 at 12:42 AM, Jeff Newmiller
>>><jdnewmil at dcn.davis.ca.us> wrote:
>>>> The "by" function aggregates and returns a result with generally
>>>fewer rows
>>>> than the original data. Since you are looking to index the rows in
>>>the
>>>> original data set, the "ave" function is better suited because it
>>>always
>>>> returns a vector that is just as long as the input vector:
>>>>
>>>> # I usually work with character data rather than factors if I plan
>>>> # to modify the data (e.g. removing rows)
>>>> DF <- read.table( text=
>>>> 'first  week last
>>>> Alex    1  West
>>>> Bob     1  John
>>>> Cory    1  Jack
>>>> Cory    2  Jack
>>>> Bob     2  John
>>>> Bob     3  John
>>>> Alex    2  Joseph
>>>> Alex    3  West
>>>> Alex    4  West
>>>> ', header = TRUE, as.is = TRUE )
>>>>
>>>> err <- ave( DF$last
>>>>           , DF[ , "first", drop = FALSE]
>>>>           , FUN = function( lst ) {
>>>>               length( unique( lst ) )
>>>>             }
>>>>           )
>>>> result <- DF[ "1" == err, ]
>>>> result
>>>>
>>>> Notice that the ave function returns a vector of the same type as was
>>>given
>>>> to it, so even though the function returns a numeric the err
>>>> vector is character.
>>>>
>>>> If you wanted to be able to examine more than one other column in
>>>> determining the keep/reject decision, you could do:
>>>>
>>>> err2 <- ave( seq_along( DF$first )
>>>>            , DF[ , "first", drop = FALSE]
>>>>            , FUN = function( n ) {
>>>>               length( unique( DF[ n, "last" ] ) )
>>>>              }
>>>>            )
>>>> result2 <- DF[ 1 == err2, ]
>>>> result2
>>>>
>>>> and then you would have the option to re-use the "n" index to look at
>>>other
>>>> columns as well.
>>>>
>>>> Finally, here is a dplyr solution:
>>>>
>>>> library(dplyr)
>>>> result3 <- (   DF
>>>>            %>% group_by( first ) # like a prep for ave or by
>>>>            %>% mutate( err = length( unique( last ) ) ) # similar to
>>>ave
>>>>            %>% filter( 1 == err ) # drop the rows with too many last
>>>names
>>>>            %>% select( -err ) # drop the temporary column
>>>>            %>% as.data.frame # convert back to a plain-jane data
>>>frame
>>>>            )
>>>> result3
>>>>
>>>> which uses a small set of verbs in a pipeline of functions to go from
>>>input
>>>> to result in one pass.
>>>>
>>>> If your data set is really big (running out of memory big) then you
>>>might
>>>> want to investigate the data.table or sqlite packages, either of
>>>which can
>>>> be combined with dplyr to get a standardized syntax for managing
>>>larger
>>>> amounts of data. However, most people actually aren't running out of
>>>memory
>>>> so in most cases the extra horsepower isn't actually needed.
>>>>
>>>>
>>>> On Sun, 12 Feb 2017, P Tennant wrote:
>>>>
>>>>> Hi Val,
>>>>>
>>>>> The by() function could be used here. With the dataframe dfr:
>>>>>
>>>>> # split the data by first name and check for more than one last name
>>>for
>>>>> each first name
>>>>> res <- by(dfr, dfr['first'], function(x) length(unique(x$last)) > 1)
>>>>> # make the result more easily manipulated
>>>>> res <- as.table(res)
>>>>> res
>>>>> # first
>>>>> # Alex   Bob  Cory
>>>>> # TRUE FALSE FALSE
>>>>>
>>>>> # then use this result to subset the data
>>>>> nw.dfr <- dfr[!dfr$first %in% names(res[res]) , ]
>>>>> # sort if needed
>>>>> nw.dfr[order(nw.dfr$first) , ]
>>>>>
>>>>>  first week last
>>>>> 2   Bob    1 John
>>>>> 5   Bob    2 John
>>>>> 6   Bob    3 John
>>>>> 3  Cory    1 Jack
>>>>> 4  Cory    2 Jack
>>>>>
>>>>>
>>>>> Philip
>>>>>
>>>>> On 12/02/2017 4:02 PM, Val wrote:
>>>>>>
>>>>>> Hi all,
>>>>>> I have a big data set and want to  remove rows conditionally.
>>>>>> In my data file  each person were recorded  for several weeks.
>>>Somehow
>>>>>> during the recording periods, their last name was misreported.
>>>For
>>>>>> each person,   the last name should be the same. Otherwise remove
>>>from
>>>>>> the data. Example, in the following data set, Alex was found to
>>>have
>>>>>> two last names .
>>>>>>
>>>>>> Alex   West
>>>>>> Alex   Joseph
>>>>>>
>>>>>> Alex should be removed  from the data.  if this happens then I want
>>>>>> remove  all rows with Alex. Here is my data set
>>>>>>
>>>>>> df<- read.table(header=TRUE, text='first  week last
>>>>>> Alex    1  West
>>>>>> Bob     1  John
>>>>>> Cory    1  Jack
>>>>>> Cory    2  Jack
>>>>>> Bob     2  John
>>>>>> Bob     3  John
>>>>>> Alex    2  Joseph
>>>>>> Alex    3  West
>>>>>> Alex    4  West ')
>>>>>>
>>>>>> Desired output
>>>>>>
>>>>>>        first  week last
>>>>>> 1     Bob     1   John
>>>>>> 2     Bob     2   John
>>>>>> 3     Bob     3   John
>>>>>> 4     Cory     1   Jack
>>>>>> 5     Cory     2   Jack
>>>>>>
>>>>>> Thank you in advance
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>Go...
>>>>                                       Live:   OO#.. Dead: OO#..
>>>Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>rocks...1k
>>>>
>>>---------------------------------------------------------------------------


From bgunter.4567 at gmail.com  Mon Feb 13 05:28:22 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 12 Feb 2017 20:28:22 -0800
Subject: [R] Help with saving user defined functions
In-Reply-To: <CABie7_raOnKVEqaLK+t-znLU0Q7jO2HK=xpu9LWfQo=+vc2YxA@mail.gmail.com>
References: <CABie7_rg7uOBCG43Q8eqAJ8x6SCeg6BLi_aA1TBNwJARSXNsow@mail.gmail.com>
	<CAGxFJbQ7gEOO=Ajs4i-G_QzC4xssjqcgD8=YyBv_T4ric-CaZA@mail.gmail.com>
	<CABie7_raOnKVEqaLK+t-znLU0Q7jO2HK=xpu9LWfQo=+vc2YxA@mail.gmail.com>
Message-ID: <CAGxFJbQ_QbTCR7fu74_0dc=tw3T0OdWEo_TOPOyvSneippLJRA@mail.gmail.com>

ecdf() is part of the stats package, which is (typically)
automatically attached on startup.

I have no idea what you mean by "splitting" and "saving." This is
basically how all of R works -- e.g. see the value of lm() and the
(S3) plot method, plot.lm, for "lm"  objects. This has nothing to do
with free variables and lexical scoping. Perhaps you need to review
how functions and S3 methods work?

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Feb 12, 2017 at 5:31 PM, George Trojan - NOAA Federal
<george.trojan at noaa.gov> wrote:
> I want to split my computation into parts. The first script processes the
> data, the second does the graphics. I want to save  results of
> time-consuming calculations. My example tried to simulate this by terminate
> the session without saving it, so the environment was lost on purpose. What
> confuses me that ecdf can be saved and restored, but not my own derived
> function.
> Of course I can save parameters and redefine the function in the second
> script.
>
> Reading Chapter 8 of Advanced R, hopefully the book will clear my mind.
>
> On Mon, Feb 13, 2017 at 12:05 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>
>> It worked fine for me:
>>
>> > t <- rnorm(100)
>> > cdf <- ecdf(t)
>> >
>> > trans <- function(x) qnorm(cdf(x) * 0.99)
>> > saveRDS(trans, "/tmp/foo")
>> > trans(1.2)
>> [1] 1.042457
>> > trans1 <- readRDS("/tmp/foo")
>> > trans1(0)
>> [1] 0.1117773
>>
>>
>> Of course, if I remove cdf() from the global environment, it will fail:
>>
>> > rm(cdf)
>> > trans1(0)
>> Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>>
>> So it looks like you're clearing you global workspace in between
>> saving and loading?
>>
>> You may need to read up on function closures/lexical scoping : A
>> user-defined function in R includes not only code but also a pointer
>> to the environment in which it was defined, in your case, the global
>> environment from which you apparently removed cdf(). Note that
>> functions are not evauated until called, so free variables in the
>> functions that do not or will not exist in the function's lexical
>> scope when called will not trigger any errors until the function *is*
>> called.
>>
>> Same comments for your second version -- if tmp is removed the
>> function will fail.
>>
>>
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Feb 12, 2017 at 2:11 PM, George Trojan - NOAA Federal
>> <george.trojan at noaa.gov> wrote:
>> > I can't figure out how to save functions to RDS file. Here is an example
>> > what I am trying to achieve:
>> >
>> >> t <- rnorm(100)
>> >> cdf <- ecdf(t)
>> >> cdf(0)
>> > [1] 0.59
>> >> saveRDS(cdf, "/tmp/foo")
>> >>
>> > Save workspace image? [y/n/c]: n
>> > [gtrojan at asok petproject]$ R
>> >> cdf <- readRDS("/tmp/foo")
>> >> cdf
>> > Empirical CDF
>> > Call: ecdf(t)
>> > x[1:100] = -2.8881, -2.2054, -2.0026,  ..., 2.0367, 2.0414
>> >
>> > This works. However when instead of saving cdf() I try to save function
>> >
>> >> trans <- function(x) qnorm(cdf(x) * 0.99)
>> >
>> > after restoring object from file I get an error:
>> >
>> >> trans <- readRDS("/tmp/foo")
>> >> trans(0)
>> > Error in qnorm(cdf(x) * 0.99) : could not find function "cdf"
>> >
>> > I tried to define and call cdf within the definition of trans, without
>> > success:
>> >
>> >> tmp <- rnorm(100)
>> >> trans <- function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
>> >> saveRDS(trans, "/tmp/foo")
>> > Save workspace image? [y/n/c]: n
>> >
>> >> trans <- readRDS("/tmp/foo")
>> >> trans
>> > function(x) { cdf <- ecdf(tmp); cdf(0); qnorm(cdf(x)) * 0.99 }
>> >> trans(0)
>> > Error in sort(x) : object 'tmp' not found
>> >
>> > So, here the call cdf(0) did not force evaluation of my random sample.
>> > What
>> > am I missing?
>> >
>> > George
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From philipt900 at iinet.net.au  Mon Feb 13 08:26:53 2017
From: philipt900 at iinet.net.au (P Tennant)
Date: Mon, 13 Feb 2017 18:26:53 +1100
Subject: [R] remove
In-Reply-To: <CAJOiR6Z18SK1Wx12RSu2jvt=v4UfxCJJCXZKA7Uo1MgdDjh=Zw@mail.gmail.com>
References: <CAJOiR6ZYhfQwXpcWhFyfyhWLMNP3jwNvvkEJg+O1Tb23VoVybg@mail.gmail.com>
	<589FF50E.8040009@iinet.net.au>
	<alpine.BSF.2.00.1702112208050.98426@pedal.dcn.davis.ca.us>
	<CAJOiR6bDtpSGH_fb0yzZ2km01NW5fg+9GsbtsBAf5Hnp+UCrhA@mail.gmail.com>
	<EDE98E7C-0602-46E5-8C6B-28C3C6A200D2@dcn.davis.ca.us>
	<CAJOiR6b6-hF+HvsjdidPDcuwJ0tU58J18=sjk2A8EMxediSHbw@mail.gmail.com>
	<CAJOiR6Z18SK1Wx12RSu2jvt=v4UfxCJJCXZKA7Uo1MgdDjh=Zw@mail.gmail.com>
Message-ID: <58A15FBD.9000506@iinet.net.au>

Val,

Working with R's special missing value indicator (NA) would be useful 
here. You could use the na.strings arg in read.table() to recognise "-" 
as a missing value:

dfr <- read.table( text=
'first  week last
Alex    1  West
Bob     1  John
Cory    1  Jack
Cory    2  -
Bob     2  John
Bob     3  John
Alex    2  Joseph
Alex    3  West
Alex    4  West
', header = TRUE, as.is = TRUE, na.strings = c("NA", "-"))

and then modify the function used by ave() or by() to exclude missing 
values from the count of unique last names. Here's one approach adapting 
code from earlier in this thread:

err <- ave(dfr$last, dfr$first, FUN = function(x) 
length(unique(x[!is.na(x)])))
res <- dfr[err == 1 , ]
res <- res[order(res$first) , ]
res

   first week last
2   Bob    1 John
5   Bob    2 John
6   Bob    3 John
3  Cory    1 Jack
4  Cory    2 <NA>


Alternatively, if not using na.strings, change "-" to NA after first 
reading the data in: identify last names recorded as "-" using an index, 
and assign NA to these elements, before proceeding as above.

Philip

On 13/02/2017 3:18 PM, Val wrote:
> Hi Jeff and All,
>
> When I examined the excluded  data,  ie.,  first name with  with
> different last names, I noticed that  some last names were  not
> recorded
> or instance, I modified the data as follows
> DF<- read.table( text=
> 'first  week last
> Alex    1  West
> Bob     1  John
> Cory    1  Jack
> Cory    2     -
> Bob     2  John
> Bob     3  John
> Alex    2  Joseph
> Alex    3  West
> Alex    4  West
> ', header = TRUE, as.is = TRUE )
>
>
> err2<- ave( seq_along( DF$first )
>             , DF[ , "first", drop = FALSE]
>             , FUN = function( n ) {
>                length( unique( DF[ n, "last" ] ) )
>               }
>             )
> result2<- DF[ 1 == err2, ]
> result2
>
> first week last
> 2   Bob    1 John
> 5   Bob    2 John
> 6   Bob    3 John
>
> However, I want keep Cory's record. It is assumed that not recorded
> should have the same last name.
>
> Final out put should be
>
> first week last
>     Bob    1 John
>     Bob    2 John
>     Bob    3 John
>    Cory    1  Jack
>    Cory    2   -
>
> Thank you again!
>
> On Sun, Feb 12, 2017 at 7:28 PM, Val<valkremk at gmail.com>  wrote:
>> Sorry  Jeff, I did not finish my email. I accidentally touched the send button.
>> My question was the
>> when I used this one
>> length(unique(result2$first))
>>       vs
>> dim(result2[!duplicated(result2[,c('first')]),]) [1]
>>
>> I did get different results but now I found out the problem.
>>
>> Thank you!.
>>
>>
>>
>>
>>
>>
>>
>>
>> On Sun, Feb 12, 2017 at 6:31 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us>  wrote:
>>> Your question mystifies me, since it looks to me like you already know the answer.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On February 12, 2017 3:30:49 PM PST, Val<valkremk at gmail.com>  wrote:
>>>> Hi Jeff and all,
>>>> How do I get the  number of unique first names   in the two data sets?
>>>>
>>>> for the first one,
>>>> result2<- DF[ 1 == err2, ]
>>>> length(unique(result2$first))
>>>>
>>>>
>>>>
>>>>
>>>> On Sun, Feb 12, 2017 at 12:42 AM, Jeff Newmiller
>>>> <jdnewmil at dcn.davis.ca.us>  wrote:
>>>>> The "by" function aggregates and returns a result with generally
>>>> fewer rows
>>>>> than the original data. Since you are looking to index the rows in
>>>> the
>>>>> original data set, the "ave" function is better suited because it
>>>> always
>>>>> returns a vector that is just as long as the input vector:
>>>>>
>>>>> # I usually work with character data rather than factors if I plan
>>>>> # to modify the data (e.g. removing rows)
>>>>> DF<- read.table( text=
>>>>> 'first  week last
>>>>> Alex    1  West
>>>>> Bob     1  John
>>>>> Cory    1  Jack
>>>>> Cory    2  Jack
>>>>> Bob     2  John
>>>>> Bob     3  John
>>>>> Alex    2  Joseph
>>>>> Alex    3  West
>>>>> Alex    4  West
>>>>> ', header = TRUE, as.is = TRUE )
>>>>>
>>>>> err<- ave( DF$last
>>>>>            , DF[ , "first", drop = FALSE]
>>>>>            , FUN = function( lst ) {
>>>>>                length( unique( lst ) )
>>>>>              }
>>>>>            )
>>>>> result<- DF[ "1" == err, ]
>>>>> result
>>>>>
>>>>> Notice that the ave function returns a vector of the same type as was
>>>> given
>>>>> to it, so even though the function returns a numeric the err
>>>>> vector is character.
>>>>>
>>>>> If you wanted to be able to examine more than one other column in
>>>>> determining the keep/reject decision, you could do:
>>>>>
>>>>> err2<- ave( seq_along( DF$first )
>>>>>             , DF[ , "first", drop = FALSE]
>>>>>             , FUN = function( n ) {
>>>>>                length( unique( DF[ n, "last" ] ) )
>>>>>               }
>>>>>             )
>>>>> result2<- DF[ 1 == err2, ]
>>>>> result2
>>>>>
>>>>> and then you would have the option to re-use the "n" index to look at
>>>> other
>>>>> columns as well.
>>>>>
>>>>> Finally, here is a dplyr solution:
>>>>>
>>>>> library(dplyr)
>>>>> result3<- (   DF
>>>>>             %>% group_by( first ) # like a prep for ave or by
>>>>>             %>% mutate( err = length( unique( last ) ) ) # similar to
>>>> ave
>>>>>             %>% filter( 1 == err ) # drop the rows with too many last
>>>> names
>>>>>             %>% select( -err ) # drop the temporary column
>>>>>             %>% as.data.frame # convert back to a plain-jane data
>>>> frame
>>>>>             )
>>>>> result3
>>>>>
>>>>> which uses a small set of verbs in a pipeline of functions to go from
>>>> input
>>>>> to result in one pass.
>>>>>
>>>>> If your data set is really big (running out of memory big) then you
>>>> might
>>>>> want to investigate the data.table or sqlite packages, either of
>>>> which can
>>>>> be combined with dplyr to get a standardized syntax for managing
>>>> larger
>>>>> amounts of data. However, most people actually aren't running out of
>>>> memory
>>>>> so in most cases the extra horsepower isn't actually needed.
>>>>>
>>>>>
>>>>> On Sun, 12 Feb 2017, P Tennant wrote:
>>>>>
>>>>>> Hi Val,
>>>>>>
>>>>>> The by() function could be used here. With the dataframe dfr:
>>>>>>
>>>>>> # split the data by first name and check for more than one last name
>>>> for
>>>>>> each first name
>>>>>> res<- by(dfr, dfr['first'], function(x) length(unique(x$last))>  1)
>>>>>> # make the result more easily manipulated
>>>>>> res<- as.table(res)
>>>>>> res
>>>>>> # first
>>>>>> # Alex   Bob  Cory
>>>>>> # TRUE FALSE FALSE
>>>>>>
>>>>>> # then use this result to subset the data
>>>>>> nw.dfr<- dfr[!dfr$first %in% names(res[res]) , ]
>>>>>> # sort if needed
>>>>>> nw.dfr[order(nw.dfr$first) , ]
>>>>>>
>>>>>>   first week last
>>>>>> 2   Bob    1 John
>>>>>> 5   Bob    2 John
>>>>>> 6   Bob    3 John
>>>>>> 3  Cory    1 Jack
>>>>>> 4  Cory    2 Jack
>>>>>>
>>>>>>
>>>>>> Philip
>>>>>>
>>>>>> On 12/02/2017 4:02 PM, Val wrote:
>>>>>>> Hi all,
>>>>>>> I have a big data set and want to  remove rows conditionally.
>>>>>>> In my data file  each person were recorded  for several weeks.
>>>> Somehow
>>>>>>> during the recording periods, their last name was misreported.
>>>> For
>>>>>>> each person,   the last name should be the same. Otherwise remove
>>>> from
>>>>>>> the data. Example, in the following data set, Alex was found to
>>>> have
>>>>>>> two last names .
>>>>>>>
>>>>>>> Alex   West
>>>>>>> Alex   Joseph
>>>>>>>
>>>>>>> Alex should be removed  from the data.  if this happens then I want
>>>>>>> remove  all rows with Alex. Here is my data set
>>>>>>>
>>>>>>> df<- read.table(header=TRUE, text='first  week last
>>>>>>> Alex    1  West
>>>>>>> Bob     1  John
>>>>>>> Cory    1  Jack
>>>>>>> Cory    2  Jack
>>>>>>> Bob     2  John
>>>>>>> Bob     3  John
>>>>>>> Alex    2  Joseph
>>>>>>> Alex    3  West
>>>>>>> Alex    4  West ')
>>>>>>>
>>>>>>> Desired output
>>>>>>>
>>>>>>>         first  week last
>>>>>>> 1     Bob     1   John
>>>>>>> 2     Bob     2   John
>>>>>>> 3     Bob     3   John
>>>>>>> 4     Cory     1   Jack
>>>>>>> 5     Cory     2   Jack
>>>>>>>
>>>>>>> Thank you in advance
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>> ---------------------------------------------------------------------------
>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>         Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>>                                        Live:   OO#.. Dead: OO#..
>>>> Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>> rocks...1k
>>>> ---------------------------------------------------------------------------


From s.algeri14 at imperial.ac.uk  Mon Feb 13 16:54:10 2017
From: s.algeri14 at imperial.ac.uk (Algeri, Sara)
Date: Mon, 13 Feb 2017 15:54:10 +0000
Subject: [R] Error loading largeVis
Message-ID: <HE1PR06MB10192906BD5ACC68A1A0EF12AD590@HE1PR06MB1019.eurprd06.prod.outlook.com>

Dear all,

I have been trying to load the package 'largeVis' but despite I do not receive any error message when installing it, I keep getting  the following error when loading it in my working directory:

> require("largeVis")
Loading required package: largeVis
Loading required package: Matrix
Error : object ?opticsXi? is not exported by 'namespace:dbscan'

As suggested in other posts with a similar error message (but for different packages), I have already tried to uninstall R, restart my machine and install the newest version of R available, however this does not seem to help solving the issue.
Also, after loading 'dbscan', when typing 'dbscan:::opticsXi', I get:

> dbscan:::opticsXi
Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
  object 'opticsXi' not found

Does anybody have any suggestion on how to solve this issue?

Thank you in advance,
Sara

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Mon Feb 13 17:13:23 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 13 Feb 2017 17:13:23 +0100
Subject: [R] Error loading largeVis
In-Reply-To: <HE1PR06MB10192906BD5ACC68A1A0EF12AD590@HE1PR06MB1019.eurprd06.prod.outlook.com>
References: <HE1PR06MB10192906BD5ACC68A1A0EF12AD590@HE1PR06MB1019.eurprd06.prod.outlook.com>
Message-ID: <9BB146A0-5B38-4B5F-BB24-C6C678917445@xs4all.nl>


> On 13 Feb 2017, at 16:54, Algeri, Sara <s.algeri14 at imperial.ac.uk> wrote:
> 
> Dear all,
> 
> I have been trying to load the package 'largeVis' but despite I do not receive any error message when installing it, I keep getting  the following error when loading it in my working directory:
> 
>> require("largeVis")
> Loading required package: largeVis
> Loading required package: Matrix
> Error : object ?opticsXi? is not exported by 'namespace:dbscan'
> 
> As suggested in other posts with a similar error message (but for different packages), I have already tried to uninstall R, restart my machine and install the newest version of R available, however this does not seem to help solving the issue.
> Also, after loading 'dbscan', when typing 'dbscan:::opticsXi', I get:
> 
>> dbscan:::opticsXi
> Error in get(name, envir = asNamespace(pkg), inherits = FALSE) :
>  object 'opticsXi' not found
> 
> Does anybody have any suggestion on how to solve this issue?
> 

No.

Go to the CRAN page for largeVis.
Click on the CRAN check link to largeVis results (https://cran.r-project.org/web/checks/check_results_largeVis.html)

and you will see that on most systems the same error is generated.

So it may be best to send an email to the maintainer.

Berend hasselman


From macqueen1 at llnl.gov  Mon Feb 13 17:16:42 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 13 Feb 2017 16:16:42 +0000
Subject: [R] Query - Merging and conditional replacement of values in a
 data frame
In-Reply-To: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
References: <CAEGXkYUFub3HoS6z5bJ-kxmEaaePZFQY9mzTbLbxD=PaFF9KDg@mail.gmail.com>
Message-ID: <6099EE37-476C-4A7F-83E1-50D137186196@llnl.gov>

How about this?

foo <- merge(df1, df2, all=TRUE)

is.new <- !is.na(foo$v11)
foo$v1[is.new] <- foo$v11[is.new]

foo <- foo[, names(df1)]

> foo
  time  v1 v2 v3
1    1   2  3  4
2    2   5  6  4
3    3 112  3  4
4    4 112  3  4
5    5   2  3  4
6    6   2  3  4


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 2/11/17, 4:13 PM, "R-help on behalf of Bhaskar Mitra" <r-help-bounces at r-project.org on behalf of bhaskar.kolkata at gmail.com> wrote:

    Hello Everyone,
    
    I have two data frames df1 and df2 as shown below. They
    are of different length. However, they have one common column - time.
    
    df1 <-
    time v1  v2 v3
    1     2   3  4
    2     5   6  4
    3     1   3  4
    4     1   3  4
    5     2   3  4
    6     2   3  4
    
    
    df2 <-
    time v11  v12 v13
    3     112   3  4
    4     112   3  4
    
    By matching the 'time' column in df1 and df2, I am trying to modify column
    'v1' in df1 by replacing it
    with values in column 'v11' in df2. The modified df1 should look something
    like this:
    
    df1 <-
    time v1   v2 v3
    1     2   3  4
    2     5   6  4
    3     112 3  4
    4     112 3  4
    5     2   3  4
    6     2   3  4
    
    I tried to use the 'merge' function to combine df1 and df2 followed by
    the conditional 'ifelse' statement. However, that doesn't seem to work.
    
    Can I replace the values in df1 by not merging the two data frames?
    
    Thanks for your help,
    
    Regards,
    Bhaskar
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From vodvos at zoho.com  Mon Feb 13 17:27:52 2017
From: vodvos at zoho.com (vod vos)
Date: Mon, 13 Feb 2017 08:27:52 -0800
Subject: [R] How to output "0" after paste() ?
Message-ID: <15a384d44fa.d1a0eb272791.4415673583821893624@zoho.com>

Hi everyone,



How to get "0" after init?



aa&lt;- seq(2,7,0.5)



aa 



[1] 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0



bb&lt;- paste("why no dot zero",aa,"after init",sep="")



bb



the output are:



[1] "why no dot zero2after init"   "why no dot zero2.5after init" 

[3] "why no dot zero3after init"   "why no dot zero3.5after init" 

[5] "why no dot zero4after init"   "why no dot zero4.5after init" 

[7] "why no dot zero5after init"   "why no dot zero5.5after init"

 [9] "why no dot zero6after init"   "why no dot zero6.5after init"

[11] "why no dot zero7after init" 



What I want are like: "why no dot zero2.0after init"  ,"why no dot zero3.0after init"



I used round(), signif(), but it does not help. Any ideas?


	[[alternative HTML version deleted]]


From projectbasu at gmail.com  Mon Feb 13 17:33:31 2017
From: projectbasu at gmail.com (swaraj basu)
Date: Mon, 13 Feb 2017 17:33:31 +0100
Subject: [R] Circular plot
Message-ID: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>

I want to plot segments deleted from mitochondrial DNA of patients with
neuromuscular disorders. I generate the plot on a linear chromosome using a
code similar to as shown below

start<-c(1,5,600,820)
end<-c(250,75,810,1200)
score<-c(7,-1,4,-6.5)
dat<-data.frame(start=start,end=end,score=score,col="blue",stringsAsFactors=F)
dat[dat$score<0,]$col<-"red"

plot(1:1500,rep(0,1500),type="p",ylim=c(-10,10),col="white",xlab="position",ylab="score")
segments(dat$start, dat$score, dat$end, dat$score, col=dat$col, lwd=3)


Since the human mitochondria is a circular genome, I would like to
visualise the plot generated above as a circle where all segments with
positive score lie inside the circle and those with negative score lie
outside. Attached is a representation of my requirement, although here it
is manually drawn. Can someone help me on this?


--
Swaraj Basu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example.pdf
Type: application/pdf
Size: 32195 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170213/fc5df8cb/attachment.pdf>

From dcarlson at tamu.edu  Mon Feb 13 17:43:44 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 13 Feb 2017 16:43:44 +0000
Subject: [R] How to output "0" after paste() ?
In-Reply-To: <15a384d44fa.d1a0eb272791.4415673583821893624@zoho.com>
References: <15a384d44fa.d1a0eb272791.4415673583821893624@zoho.com>
Message-ID: <d9e37ec239bf489b8846f2316b0e6cb6@exch-2p-mbx-w2.ads.tamu.edu>

First, use plain text emails. Look that what conversion from html did to your email:

aa <- seq(2,7,0.5) became aa&lt;- seq(2,7,0.5)

You need to format your numeric values with sprintf():

paste("why no dot zero", sprintf("%3.1f", aa),"after init",sep="")

?sprintf for details

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of vod vos
Sent: Monday, February 13, 2017 10:28 AM
To: r-help <r-help at r-project.org>
Subject: [R] How to output "0" after paste() ?

Hi everyone,



How to get "0" after init?



aa&lt;- seq(2,7,0.5)



aa 



[1] 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0



bb&lt;- paste("why no dot zero",aa,"after init",sep="")



bb



the output are:



[1] "why no dot zero2after init"   "why no dot zero2.5after init" 

[3] "why no dot zero3after init"   "why no dot zero3.5after init" 

[5] "why no dot zero4after init"   "why no dot zero4.5after init" 

[7] "why no dot zero5after init"   "why no dot zero5.5after init"

 [9] "why no dot zero6after init"   "why no dot zero6.5after init"

[11] "why no dot zero7after init" 



What I want are like: "why no dot zero2.0after init"  ,"why no dot zero3.0after init"



I used round(), signif(), but it does not help. Any ideas?


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From peter.mills at strath.ac.uk  Mon Feb 13 17:44:19 2017
From: peter.mills at strath.ac.uk (Peter Mills)
Date: Mon, 13 Feb 2017 16:44:19 +0000
Subject: [R] Wrap to 360
Message-ID: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86C89A@EX2010-MBX2.ds.strath.ac.uk>

Hi

Is there an equivalent for R of the Matlab function wrapTo360?

Many thanks
Peter


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Feb 13 17:51:16 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 13 Feb 2017 16:51:16 +0000
Subject: [R] How to output "0" after paste() ?
In-Reply-To: <15a384d44fa.d1a0eb272791.4415673583821893624@zoho.com>
References: <15a384d44fa.d1a0eb272791.4415673583821893624@zoho.com>
Message-ID: <58A1E404.1080404@sapo.pt>

Hello,

See the help page for ?sprintf.

sprintf("why no dot zero %1.1f after init", aa)

Hope this helps,

Rui Barradas

Em 13-02-2017 16:27, vod vos escreveu:
> Hi everyone,
>
>
>
> How to get "0" after init?
>
>
>
> aa&lt;- seq(2,7,0.5)
>
>
>
> aa
>
>
>
> [1] 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0
>
>
>
> bb&lt;- paste("why no dot zero",aa,"after init",sep="")
>
>
>
> bb
>
>
>
> the output are:
>
>
>
> [1] "why no dot zero2after init"   "why no dot zero2.5after init"
>
> [3] "why no dot zero3after init"   "why no dot zero3.5after init"
>
> [5] "why no dot zero4after init"   "why no dot zero4.5after init"
>
> [7] "why no dot zero5after init"   "why no dot zero5.5after init"
>
>   [9] "why no dot zero6after init"   "why no dot zero6.5after init"
>
> [11] "why no dot zero7after init"
>
>
>
> What I want are like: "why no dot zero2.0after init"  ,"why no dot zero3.0after init"
>
>
>
> I used round(), signif(), but it does not help. Any ideas?
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Mon Feb 13 17:57:46 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 13 Feb 2017 08:57:46 -0800
Subject: [R] Wrap to 360
In-Reply-To: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86C89A@EX2010-MBX2.ds.strath.ac.uk>
References: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86C89A@EX2010-MBX2.ds.strath.ac.uk>
Message-ID: <CAF8bMcZ-2dcipri3s-EgqGJwf6cR8Q3QphUph5KrQiE71LyokA@mail.gmail.com>

The key function is '%%' (remainder), but its result needs to be
tweaked at mulitplies of 360 because Matlab's definition of wrapTo360
is

lonWrapped = wrapTo360(lon) wraps angles in lon, in degrees, to the
interval [0 360] such that 0 maps to 0 and 360 maps to 360. (In
general, positive multiples of 360 map to 360 and negative multiples
of 360 map to zero.)

wrapTo360 <- function (lon)
{
    ret <- lon%%360
    ret[lon >= 360 & ret == 0] <- 360
    ret
}

As in:

> wrapTo360(c(-721,-720,-719,-361,-360,-359,-1,0,1,359,360,361,720,721))
 [1] 359   0   1 359   0   1 359   0   1 359 360   1 360   1


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Feb 13, 2017 at 8:44 AM, Peter Mills <peter.mills at strath.ac.uk> wrote:
> Hi
>
> Is there an equivalent for R of the Matlab function wrapTo360?
>
> Many thanks
> Peter
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Feb 13 18:52:53 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 13 Feb 2017 17:52:53 +0000
Subject: [R] Circular plot
In-Reply-To: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>
References: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>
Message-ID: <c25539dcec0747d694f54a324fb40e78@exch-2p-mbx-w2.ads.tamu.edu>

You can do this easily with the DrawCircle() function in package DescTools. It is easiest to use geometric coordinates (0 is at 3 o'clock and moves counterclockwise around the circle), but it could be converted to 12 o'clock and clockwise:

library(DescTools)

# Convert begin/stop to radians
dat$begin <- 0 + 2 * pi * dat$start/1500
dat$stop <- 0 + 2 * pi * dat$end/1500

# Open blank plot window and draw circles
Canvas(xlim = c(-5,5), xpd=TRUE)
DrawCircle (r.out = 5, r.in = 5, theta.1=.05, theta.2=2*pi-.05, lwd=3)
with(dat, DrawCircle(r.out = 5 - score/5, r.in = 5 - score/5, 
     theta.1=begin, theta.2=stop, border=col, lwd=4))
text(5.2, .4, "1", pos=4)
text(5.2, -.4, "1500", pos=4)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of swaraj basu
Sent: Monday, February 13, 2017 10:34 AM
To: r-help at r-project.org
Subject: [R] Circular plot

I want to plot segments deleted from mitochondrial DNA of patients with
neuromuscular disorders. I generate the plot on a linear chromosome using a
code similar to as shown below

start<-c(1,5,600,820)
end<-c(250,75,810,1200)
score<-c(7,-1,4,-6.5)
dat<-data.frame(start=start,end=end,score=score,col="blue",stringsAsFactors=F)
dat[dat$score<0,]$col<-"red"

plot(1:1500,rep(0,1500),type="p",ylim=c(-10,10),col="white",xlab="position",ylab="score")
segments(dat$start, dat$score, dat$end, dat$score, col=dat$col, lwd=3)


Since the human mitochondria is a circular genome, I would like to
visualise the plot generated above as a circle where all segments with
positive score lie inside the circle and those with negative score lie
outside. Attached is a representation of my requirement, although here it
is manually drawn. Can someone help me on this?


--
Swaraj Basu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mtDNAplot.png
Type: image/png
Size: 5241 bytes
Desc: mtDNAplot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170213/1ca44fe5/attachment.png>

From bgunter.4567 at gmail.com  Mon Feb 13 18:53:18 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 13 Feb 2017 09:53:18 -0800
Subject: [R] Circular plot
In-Reply-To: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>
References: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>
Message-ID: <CAGxFJbTShkFAsSt6gsjdAU153D6dOs-0LY2A8DPEvhh7T2gabw@mail.gmail.com>

If you don't get a reply here:

1. Search! (try rseek.org as an R search engine).

2. Try the Bioconductor list. As this appears to be closer to their
realm, they may have what you're looking for.


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 13, 2017 at 8:33 AM, swaraj basu <projectbasu at gmail.com> wrote:
> I want to plot segments deleted from mitochondrial DNA of patients with
> neuromuscular disorders. I generate the plot on a linear chromosome using a
> code similar to as shown below
>
> start<-c(1,5,600,820)
> end<-c(250,75,810,1200)
> score<-c(7,-1,4,-6.5)
> dat<-data.frame(start=start,end=end,score=score,col="blue",stringsAsFactors=F)
> dat[dat$score<0,]$col<-"red"
>
> plot(1:1500,rep(0,1500),type="p",ylim=c(-10,10),col="white",xlab="position",ylab="score")
> segments(dat$start, dat$score, dat$end, dat$score, col=dat$col, lwd=3)
>
>
> Since the human mitochondria is a circular genome, I would like to
> visualise the plot generated above as a circle where all segments with
> positive score lie inside the circle and those with negative score lie
> outside. Attached is a representation of my requirement, although here it
> is manually drawn. Can someone help me on this?
>
>
> --
> Swaraj Basu
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From acefix at rocketmail.com  Mon Feb 13 17:50:28 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Mon, 13 Feb 2017 16:50:28 +0000 (UTC)
Subject: [R] get() return nothing
In-Reply-To: <8f6e9c10-be6b-c6de-6120-ae9c0d385d38@gmail.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
	<1020994841.500566.1486837984563@mail.yahoo.com>
	<8f6e9c10-be6b-c6de-6120-ae9c0d385d38@gmail.com>
Message-ID: <1620966806.3423620.1487004628401@mail.yahoo.com>

Well, I am not trying to print anything. I just would like to get the dimension information for all the dataframes I created. Could you please help me to develop the script?
Thanks.
Ace 

    On Saturday, February 11, 2017 7:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
 

 On 11/02/2017 1:33 PM, Fix Ace via R-help wrote:
> Hello, there,
> I wrote a loop to check the dimension of all the .txt dataframes:> ls()
>? [1] "actualpca.table" "b4galnt2"? ? ? ? "b4galnt2.txt"? ? "data"
>? [5] "galnt4"? ? ? ? ? "galnt4.txt"? ? ? "galnt5"? ? ? ? ? "galnt5.txt"
>? [9] "galnt6"? ? ? ? ? "galnt6.txt"? ? ? "glyco"? ? ? ? ? "glyco.txt"
> [13] "i"? ? ? ? ? ? ? "mtscaled"? ? ? ? "newsig.table"? ? "nicepca"
> [17] "pca"? ? ? ? ? ? "sig.txt"? ? ? ? "st3gal3"? ? ? ? "st3gal3.txt"
> [21] "st3gal5"? ? ? ? "st3gal5.txt"? ? "st6gal1"? ? ? ? "st6gal1.txt"
>> for(i in ls(pattern="txt")){dim(get(i))}
>>
> If I check individual ones, they are ok:
>> dim(get("galnt4.txt"))
> [1] 8 3
>>
> could anyone help me to figure out why it did not work with a loop?
> Thanks a lot!

It's the difference between

for (i in 1:10) i

(which prints nothing) and

for (i in 1:10) print(i)

Duncan Murdoch



   
	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Mon Feb 13 18:03:18 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Mon, 13 Feb 2017 17:03:18 +0000 (UTC)
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <CAF8bMcYO4gEJLgjdESsbF_Djr3CS5SH47Fj8RsfjKdFBB9ub0w@mail.gmail.com>
References: <78845307.2701201.1486902860381.ref@mail.yahoo.com>
	<78845307.2701201.1486902860381@mail.yahoo.com>
	<CAF8bMcYO4gEJLgjdESsbF_Djr3CS5SH47Fj8RsfjKdFBB9ub0w@mail.gmail.com>
Message-ID: <1103703269.3459396.1487005398349@mail.yahoo.com>

Dang, i should notice that forecastS and forecast thingy. Now it works like a charm. ThANKS 

    On Monday, 13 February 2017, 3:56, William Dunlap <wdunlap at tibco.com> wrote:
 

 > Error in forecast[[d + 1]] = paste(index(lEJReturnsOffset[windowLength]),? : object of type 'closure' is not subsettable

A 'closure' is a function and you cannot use '[' or '[[' to make a
subset of a function.

You used
? forecast[d+1] <- ...
in one branch of the 'if' statement and
? forecasts[d+1] <- ...
in the other.? Do you see the problem now?

By the way, the code snippet in the error message says '[[d+1]]' but
the code you supplied has '[d+1]'.? Does the html mangling selectively
double brackets or did you not show us the code that generated that
message?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Feb 12, 2017 at 4:34 AM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> Hi.
> I tried to run this R-code but still completely no idea why it still gives error message: Error in forecast[[d + 1]] = paste(index(lEJReturnsOffset[windowLength]),? : object of type 'closure' is not subsettable
> Here is the R-code:
> library(rugarch); library(sos); library(forecast);library(lattice)library(quantmod); require(stochvol); require(fBasics);data = read.table("EURJPY.m1440.csv", header=F)names(data)data=ts(data)lEJ=log(data)lret.EJ = 100*diff(lEJ)lret.EJ = ts(lret.EJ)lret.EJ[as.character(head(index(lret.EJ)))]=0windowLength=500foreLength=length(lret.EJ)-windowLengthforecasts<-vector(mode="character", length=foreLength)for (d in 0:foreLength) {? lEJReturnsOffset=lret.EJ[(1+d):(windowLength+d)]? final.aic<-Inf? final.order<-c(0,0,0)? for (p in 0:5) for (q in 0:5) {? ? if(p == 0 && q == 0) {? ? ? next? ? }? ? ? ? arimaFit=tryCatch(arima(lEJReturnsOffset, order=c(p,0,q)),? ? ? ? ? ? ? ? ? ? ? error=function(err)FALSE,? ? ? ? ? ? ? ? ? ? ? warning=function(err)FALSE)? ? if(!is.logical(arimaFit)) {? ? ? current.aic<-AIC(arimaFit)? ? ? if(current.aic<final.aic) {? ? ? ? final.aic<-current.aic? ? ? ? final.order<-c(p,0,q)? ? ? ? final.arima<-arima(lEJReturnsOffset, order=final.order)? ? ? }? ? } else {? ? ? next? ? }? }
> spec <- ugarchspec(variance.model = list(model = "sGARCH", garchOrder = c(1,1)),? ? ? ? ? ? ? ? ? ? mean.model = list(armaOrder = c(final.order[1], final.order[3]), arfima = FALSE, include.mean = TRUE),? ? ? ? ? ? ? ? ? ? distribution.model = "sged")fit <- tryCatch(ugarchfit(spec, lEJReturnsOffset, solver='gosolnp'),? error=function(e) e, warning=function(w) w)if(is(fit, "warning")) {? forecast[d+1]=paste(index(lEJReturnsOffset[windowLength]), 1, sep=",")? print(paste(index(lEJReturnsOffset[windowLength]), 1, sep=","))} else {? fore = ugarchforecast(fit, n.ahead=1)? ind = fore at forecast$seriesFor? forecasts[d+1] = paste(colnames(ind), ifelse(ind[1] < 0, -1, 1), sep=",")? print(paste(colnames(ind), ifelse(ind[1] < 0, -1, 1), sep=",")) }}write.csv(forecasts, file="forecasts.csv", row.names=FALSE)
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Mon Feb 13 18:06:43 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Mon, 13 Feb 2017 17:06:43 +0000 (UTC)
Subject: [R] [Python] NameError: name 'hurst' is not defined
References: <1205795624.3415204.1487005603330.ref@mail.yahoo.com>
Message-ID: <1205795624.3415204.1487005603330@mail.yahoo.com>

Hi. Not sure why this code produces the error like this. This error appears when i run the code of print "Hurst(GBM): ? %s" % hurst(gbm):?
Traceback (most recent call last):? File "<pyshell#31>", line 1, in <module>? ? print "Hurst(GBM): ? %s" % hurst(gbm)NameError: name 'hurst' is not defined

Here is the full code:>>> import statsmodels.tsa.stattools as ts
>>> import urllib>>> from datetime import datetime>>> from pandas_datareader import data, wb>>> from pandas_datareader.data import DataReader>>> goog = DataReader("GOOG", "yahoo", datetime(2000,1,1), datetime(2017,1,1))>>> ts.adfuller(goog['Adj Close'], 1>>> import numpy as np
>>> from numpy import cumsum, log, polyfit, sqrt, std, subtract>>> from numpy.random import randn>>> def hurst(ts): lags = range(2, 100) tau = [sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in lags] poly = polyfit(log(lags), log(tau), 1) return poly[0]*2.0>>> gbm = log(cumsum(randn(100000))+1000)>>> mr = log(randn(100000)+1000)>>> tr = log(cumsum(randn(100000)+1)+1000)>>> print "Hurst(GBM): ? %s" % hurst(gbm)


	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Mon Feb 13 18:08:18 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Mon, 13 Feb 2017 17:08:18 +0000 (UTC)
Subject: [R] [Python] NameError: name 'hurst' is not defined
In-Reply-To: <1205795624.3415204.1487005603330@mail.yahoo.com>
References: <1205795624.3415204.1487005603330.ref@mail.yahoo.com>
	<1205795624.3415204.1487005603330@mail.yahoo.com>
Message-ID: <504528805.3481492.1487005698690@mail.yahoo.com>

Correction, it should look like this:**def hurst(ts): lags = range(2, 100) tau = [np.sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in lags] poly = np.polyfit(log(lags), log(tau), 1) return poly[0]*2.0 

    On Tuesday, 14 February 2017, 0:06, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
 

 Hi. Not sure why this code produces the error like this. This error appears when i run the code of print "Hurst(GBM): ? %s" % hurst(gbm):?
Traceback (most recent call last):? File "<pyshell#31>", line 1, in <module>? ? print "Hurst(GBM): ? %s" % hurst(gbm)NameError: name 'hurst' is not defined

Here is the full code:>>> import statsmodels.tsa.stattools as ts
>>> import urllib>>> from datetime import datetime>>> from pandas_datareader import data, wb>>> from pandas_datareader.data import DataReader>>> goog = DataReader("GOOG", "yahoo", datetime(2000,1,1), datetime(2017,1,1))>>> ts.adfuller(goog['Adj Close'], 1>>> import numpy as np
>>> from numpy import cumsum, log, polyfit, sqrt, std, subtract>>> from numpy.random import randn>>> def hurst(ts): lags = range(2, 100) tau = [sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in lags] poly = polyfit(log(lags), log(tau), 1) return poly[0]*2.0>>> gbm = log(cumsum(randn(100000))+1000)>>> mr = log(randn(100000)+1000)>>> tr = log(cumsum(randn(100000)+1)+1000)>>> print "Hurst(GBM): ? %s" % hurst(gbm)



   
	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Mon Feb 13 17:41:10 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Mon, 13 Feb 2017 11:41:10 -0500
Subject: [R] evaluating function over seq of values
Message-ID: <14ebaa88-df54-5ef9-23b7-de5e8866536d@gmail.com>

The MWE (below) shows what I'm hoping to get some help with:

step 1\ specify the likelihood expression I want to evaluate using a 
brute-force grid search (not that I would do this in practice, but it is 
a convenient approach to explain the idea in a class...).

step 2\ want to evaluate the likelihood at each of a sequence of values 
of N (for this example, seq(80,200,1)).

step 3\ take all of the values of the likelihood at each value for N, 
and (say) plot them

I'm sure there is a clever way to vectorize all this, but my token 
attempts at wrestling sapply into submission have failed me here. In my 
MWE, I use a simple loop, which has the advantages of working, and being 
completely transparent as to what it is doing. For teaching purposes, 
this is perhaps fine, but I'm curious as to how I could accomplish the 
same thing avoiding the loop.

Thanks in advance...

-----<MWE code below>-----


# ML estimation by simple grid search

rm(list=ls())
library("optimx")

# set up likelihood function

f_like <- function(par) {
                             p1 <- par[1];
                             p2 <- par[2];
                             p3 <- par[3];
                             p4 <- par[4];
                                    lfactorial(N)-lfactorial(N-79) +
                                     (30*log(p1)+(N-30)*log(1-p1)) +
                                     (15*log(p2)+(N-15)*log(1-p2)) +
                                     (22*log(p3)+(N-22)*log(1-p3)) +
                                     (45*log(p4)+(N-45)*log(1-p4)) }


# do the otimization using optimx nested in a loop (works, but guessing 
there is an
# easier way using lapply or some such...)

count <- 1;

dat <- matrix(c(0,0,0),length(seq(80,200,1)),3)

for (N in seq(80,200,1)) {

results_optx <- optim(c(0.2,0.2,0.2,0.2), f_like,
      method = "L-BFGS-B", lower=c(0.005,0.005,0.005,0.005), 
upper=c(0.990,0.995,0.995,0.995),
       hessian = TRUE,control=list(fnscale=-1))

like_mod <- results_optx$value;
  dat[count,1] <- count;
  dat[count,2] <- N;
  dat[count,3] <- like_mod;
count=count+1;
}

plot(dat[,2],dat[,3],type="l",bty="n",  xlim=c(79,205), yaxs = 
"i",main="likelihood profile",xlab="N", ylab="Likelihood")


From bgunter.4567 at gmail.com  Mon Feb 13 21:32:07 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 13 Feb 2017 12:32:07 -0800
Subject: [R] evaluating function over seq of values
In-Reply-To: <14ebaa88-df54-5ef9-23b7-de5e8866536d@gmail.com>
References: <14ebaa88-df54-5ef9-23b7-de5e8866536d@gmail.com>
Message-ID: <CAGxFJbQdm9XYAEY9wV2ojgLJ7WrXWTsbM7w_dEJ805eaOJx=AA@mail.gmail.com>

The apply() family of functions **are** loops (at the interpreted
level). They are **not vectorized** (looping at the C level). Their
typical virtue is in code clarity and (sometimes) the utiity of the
return structure, not greater efficiency. Sometimes they are a bit
faster, sometimes a bit slower, than *well-written* explicit loops.

Note that in your likelihood function, N can be a vector of values, so
you can compute the likelihood for all values of N and just access the
value you want via subscripting rather than repeatedly computing it
for different N's.  If all you want to do is maximize over a grid of
values, I don't know why you need optim() at all -- but I probably
just don't get what you're doing.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 13, 2017 at 8:41 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
> The MWE (below) shows what I'm hoping to get some help with:
>
> step 1\ specify the likelihood expression I want to evaluate using a
> brute-force grid search (not that I would do this in practice, but it is a
> convenient approach to explain the idea in a class...).
>
> step 2\ want to evaluate the likelihood at each of a sequence of values of N
> (for this example, seq(80,200,1)).
>
> step 3\ take all of the values of the likelihood at each value for N, and
> (say) plot them
>
> I'm sure there is a clever way to vectorize all this, but my token attempts
> at wrestling sapply into submission have failed me here. In my MWE, I use a
> simple loop, which has the advantages of working, and being completely
> transparent as to what it is doing. For teaching purposes, this is perhaps
> fine, but I'm curious as to how I could accomplish the same thing avoiding
> the loop.
>
> Thanks in advance...
>
> -----<MWE code below>-----
>
>
> # ML estimation by simple grid search
>
> rm(list=ls())
> library("optimx")
>
> # set up likelihood function
>
> f_like <- function(par) {
>                             p1 <- par[1];
>                             p2 <- par[2];
>                             p3 <- par[3];
>                             p4 <- par[4];
>                                    lfactorial(N)-lfactorial(N-79) +
>                                     (30*log(p1)+(N-30)*log(1-p1)) +
>                                     (15*log(p2)+(N-15)*log(1-p2)) +
>                                     (22*log(p3)+(N-22)*log(1-p3)) +
>                                     (45*log(p4)+(N-45)*log(1-p4)) }
>
>
> # do the otimization using optimx nested in a loop (works, but guessing
> there is an
> # easier way using lapply or some such...)
>
> count <- 1;
>
> dat <- matrix(c(0,0,0),length(seq(80,200,1)),3)
>
> for (N in seq(80,200,1)) {
>
> results_optx <- optim(c(0.2,0.2,0.2,0.2), f_like,
>      method = "L-BFGS-B", lower=c(0.005,0.005,0.005,0.005),
> upper=c(0.990,0.995,0.995,0.995),
>       hessian = TRUE,control=list(fnscale=-1))
>
> like_mod <- results_optx$value;
>  dat[count,1] <- count;
>  dat[count,2] <- N;
>  dat[count,3] <- like_mod;
> count=count+1;
> }
>
> plot(dat[,2],dat[,3],type="l",bty="n",  xlim=c(79,205), yaxs =
> "i",main="likelihood profile",xlab="N", ylab="Likelihood")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From evan.cooch at gmail.com  Mon Feb 13 21:53:33 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Mon, 13 Feb 2017 15:53:33 -0500
Subject: [R] evaluating function over seq of values
In-Reply-To: <CAGxFJbQdm9XYAEY9wV2ojgLJ7WrXWTsbM7w_dEJ805eaOJx=AA@mail.gmail.com>
References: <14ebaa88-df54-5ef9-23b7-de5e8866536d@gmail.com>
	<CAGxFJbQdm9XYAEY9wV2ojgLJ7WrXWTsbM7w_dEJ805eaOJx=AA@mail.gmail.com>
Message-ID: <3b57da7c-4297-3734-e2f2-9c192e8fe1b0@gmail.com>


> Note that in your likelihood function, N can be a vector of values, so
> you can compute the likelihood for all values of N and just access the
> value you want via subscripting rather than repeatedly computing it
> for different N's.

OK -- that is the part I'm stuck at - pointers to how to do precisely 
that appreciated (I don't use R a lot -- and it shows ;-)

>


From wdunlap at tibco.com  Mon Feb 13 21:56:08 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 13 Feb 2017 12:56:08 -0800
Subject: [R] evaluating function over seq of values
In-Reply-To: <14ebaa88-df54-5ef9-23b7-de5e8866536d@gmail.com>
References: <14ebaa88-df54-5ef9-23b7-de5e8866536d@gmail.com>
Message-ID: <CAF8bMcZYtqZWG00Rxss3A=KWW4mHAHrZhV=Lp7jWFab=NfXnXg@mail.gmail.com>

The reason you are having trouble with using an *apply function is
that f_like does
not have an argument 'N', so the N it uses is the N from the
environment in which
f_like was defined, .GlobalEnv, not one you might set in *apply's FUN argument.
Hence, make N an argument to f_like and use it in *apply.  I like
vapply since it gives
you error checking and predictable results.

f_like2 <- function(par, N) {
                            p1 <- par[1];
                            p2 <- par[2];
                            p3 <- par[3];
                            p4 <- par[4];
                                   lfactorial(N)-lfactorial(N-79) +
                                    (30*log(p1)+(N-30)*log(1-p1)) +
                                    (15*log(p2)+(N-15)*log(1-p2)) +
                                    (22*log(p3)+(N-22)*log(1-p3)) +
                                    (45*log(p4)+(N-45)*log(1-p4)) }
N <- seq(80, 200, 1)
like_mod <- vapply(N,
   FUN = function(Ni) {
      optim(c(0.2,0.2,0.2,0.2), function(par) f_like2(par, N=Ni),
         method = "L-BFGS-B", lower=c(0.005,0.005,0.005,0.005),
upper=c(0.990,0.995,0.995,0.995),
         hessian = TRUE,control=list(fnscale=-1))$value
      },
   FUN.VALUE=0.0)
plot(N, like_mod)
datNew <- cbind(count = seq_along(N), N = N, like_mod = like_mod) #
like your 'dat'

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Feb 13, 2017 at 8:41 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
> The MWE (below) shows what I'm hoping to get some help with:
>
> step 1\ specify the likelihood expression I want to evaluate using a
> brute-force grid search (not that I would do this in practice, but it is a
> convenient approach to explain the idea in a class...).
>
> step 2\ want to evaluate the likelihood at each of a sequence of values of N
> (for this example, seq(80,200,1)).
>
> step 3\ take all of the values of the likelihood at each value for N, and
> (say) plot them
>
> I'm sure there is a clever way to vectorize all this, but my token attempts
> at wrestling sapply into submission have failed me here. In my MWE, I use a
> simple loop, which has the advantages of working, and being completely
> transparent as to what it is doing. For teaching purposes, this is perhaps
> fine, but I'm curious as to how I could accomplish the same thing avoiding
> the loop.
>
> Thanks in advance...
>
> -----<MWE code below>-----
>
>
> # ML estimation by simple grid search
>
> rm(list=ls())
> library("optimx")
>
> # set up likelihood function
>
> f_like <- function(par) {
>                             p1 <- par[1];
>                             p2 <- par[2];
>                             p3 <- par[3];
>                             p4 <- par[4];
>                                    lfactorial(N)-lfactorial(N-79) +
>                                     (30*log(p1)+(N-30)*log(1-p1)) +
>                                     (15*log(p2)+(N-15)*log(1-p2)) +
>                                     (22*log(p3)+(N-22)*log(1-p3)) +
>                                     (45*log(p4)+(N-45)*log(1-p4)) }
>
>
> # do the otimization using optimx nested in a loop (works, but guessing
> there is an
> # easier way using lapply or some such...)
>
> count <- 1;
>
> dat <- matrix(c(0,0,0),length(seq(80,200,1)),3)
>
> for (N in seq(80,200,1)) {
>
> results_optx <- optim(c(0.2,0.2,0.2,0.2), f_like,
>      method = "L-BFGS-B", lower=c(0.005,0.005,0.005,0.005),
> upper=c(0.990,0.995,0.995,0.995),
>       hessian = TRUE,control=list(fnscale=-1))
>
> like_mod <- results_optx$value;
>  dat[count,1] <- count;
>  dat[count,2] <- N;
>  dat[count,3] <- like_mod;
> count=count+1;
> }
>
> plot(dat[,2],dat[,3],type="l",bty="n",  xlim=c(79,205), yaxs =
> "i",main="likelihood profile",xlab="N", ylab="Likelihood")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From projectbasu at gmail.com  Mon Feb 13 22:58:24 2017
From: projectbasu at gmail.com (swaraj basu)
Date: Mon, 13 Feb 2017 22:58:24 +0100
Subject: [R] Circular plot
In-Reply-To: <c25539dcec0747d694f54a324fb40e78@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>
	<c25539dcec0747d694f54a324fb40e78@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAKNnbJRpGWrmEyiCv_1zobG_o2y0S0x3dC5d3tb4ttBAeOzv=A@mail.gmail.com>

Thank you David, I could get the circle at 12 and clockwise however I
believe my solution is not the optimal one, could you help me out with the
best way to generate the circle clockwise at 12 and then convert the
begin/stop to radians

Here is what I tried

par(mar=c(2,2,2,2),xpd=TRUE);
plot(c(1,800),c(1,800),type="n",axes=FALSE,xlab="",ylab="",main="");
DrawCircle (x=400,y=400,r.out = 400, r.in = 400, theta.1=1.57,
theta.2=-2*pi-4.67, lwd=1)

On Mon, Feb 13, 2017 at 6:52 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> You can do this easily with the DrawCircle() function in package
> DescTools. It is easiest to use geometric coordinates (0 is at 3 o'clock
> and moves counterclockwise around the circle), but it could be converted to
> 12 o'clock and clockwise:
>
> library(DescTools)
>
> # Convert begin/stop to radians
> dat$begin <- 0 + 2 * pi * dat$start/1500
> dat$stop <- 0 + 2 * pi * dat$end/1500
>
> # Open blank plot window and draw circles
> Canvas(xlim = c(-5,5), xpd=TRUE)
> DrawCircle (r.out = 5, r.in = 5, theta.1=.05, theta.2=2*pi-.05, lwd=3)
> with(dat, DrawCircle(r.out = 5 - score/5, r.in = 5 - score/5,
>      theta.1=begin, theta.2=stop, border=col, lwd=4))
> text(5.2, .4, "1", pos=4)
> text(5.2, -.4, "1500", pos=4)
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of swaraj
> basu
> Sent: Monday, February 13, 2017 10:34 AM
> To: r-help at r-project.org
> Subject: [R] Circular plot
>
> I want to plot segments deleted from mitochondrial DNA of patients with
> neuromuscular disorders. I generate the plot on a linear chromosome using a
> code similar to as shown below
>
> start<-c(1,5,600,820)
> end<-c(250,75,810,1200)
> score<-c(7,-1,4,-6.5)
> dat<-data.frame(start=start,end=end,score=score,col="blue"
> ,stringsAsFactors=F)
> dat[dat$score<0,]$col<-"red"
>
> plot(1:1500,rep(0,1500),type="p",ylim=c(-10,10),col="white",
> xlab="position",ylab="score")
> segments(dat$start, dat$score, dat$end, dat$score, col=dat$col, lwd=3)
>
>
> Since the human mitochondria is a circular genome, I would like to
> visualise the plot generated above as a circle where all segments with
> positive score lie inside the circle and those with negative score lie
> outside. Attached is a representation of my requirement, although here it
> is manually drawn. Can someone help me on this?
>
>
> --
> Swaraj Basu
>



-- 
Swaraj Basu

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Feb 14 00:04:58 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 14 Feb 2017 10:04:58 +1100
Subject: [R] Circular plot
In-Reply-To: <CAKNnbJRpGWrmEyiCv_1zobG_o2y0S0x3dC5d3tb4ttBAeOzv=A@mail.gmail.com>
References: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>
	<c25539dcec0747d694f54a324fb40e78@exch-2p-mbx-w2.ads.tamu.edu>
	<CAKNnbJRpGWrmEyiCv_1zobG_o2y0S0x3dC5d3tb4ttBAeOzv=A@mail.gmail.com>
Message-ID: <CA+8X3fXdPLHD27_+_NVppwmCYqb_fFktOe8_NVSy2_v44ofTEw@mail.gmail.com>

Hi Swaraj,
As David pointed out, you can get the arcs without too much trouble:

library(plotrix)
mdf<-data.frame(score=c(-1,7,4,-7),start=c(0,0,600,800),
 finish=c(100,200,800,1250))
par(mar=c(4,4,1,1))
plot(0,type="n",xlim=c(-20,20),ylim=c(-20,20),xlab="",ylab="",
 xaxt="n",yaxt="n")
axis(1,at=c(-20,-10,0,10,20),labels=c(10,0,-10,0,10))
axis(2,at=c(-20,-10,0,10,20),labels=c(10,0,-10,0,10))
draw.circle(0,0,10,lty=2,border="black")
mlength<-1500
for(i in 1:dim(mdf)[1]) {
draw.arc(0,0,10+mdf$score[i],
 angle1=2*pi*mdf$start[i]/mlength,
 angle2=2*pi*mdf$finish[i]/mlength,
 lwd=3,col=ifelse(mdf$score[i]<0,"red","blue"))
}

However, you may want a circular grid as well as clockwise angles:

par(mar=c(1,1,1,1))
plot(0,type="n",xlim=c(-6,6),ylim=c(-6,6),
 xlab="",ylab="",axes=FALSE)
radial.grid(seq(0,1250,by=250),radial.lim=c(0,10),
 label.pos=seq(0,12.5/15,by=2.5/15)*2*pi,
 grid.pos=seq(0,12.5/15,by=2.5/15)*2*pi,
 start=pi/2,clockwise=TRUE)
for(i in 1:dim(mdf)[1]) {
 draw.arc(0,0,(10+mdf$score[i])/4.5,
  deg1=450-360*mdf$start[i]/mlength,
  deg2=450-360*mdf$finish[i]/mlength,
  lwd=3,col=ifelse(mdf$score[i]<0,"red","blue"))
}

Both of these examples are pretty messy, but could be improved if you
have a lot of work like this.

Jim


On Tue, Feb 14, 2017 at 8:58 AM, swaraj basu <projectbasu at gmail.com> wrote:
> Thank you David, I could get the circle at 12 and clockwise however I
> believe my solution is not the optimal one, could you help me out with the
> best way to generate the circle clockwise at 12 and then convert the
> begin/stop to radians
>
> Here is what I tried
>
> par(mar=c(2,2,2,2),xpd=TRUE);
> plot(c(1,800),c(1,800),type="n",axes=FALSE,xlab="",ylab="",main="");
> DrawCircle (x=400,y=400,r.out = 400, r.in = 400, theta.1=1.57,
> theta.2=-2*pi-4.67, lwd=1)
>
> On Mon, Feb 13, 2017 at 6:52 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>
>> You can do this easily with the DrawCircle() function in package
>> DescTools. It is easiest to use geometric coordinates (0 is at 3 o'clock
>> and moves counterclockwise around the circle), but it could be converted to
>> 12 o'clock and clockwise:
>>
>> library(DescTools)
>>
>> # Convert begin/stop to radians
>> dat$begin <- 0 + 2 * pi * dat$start/1500
>> dat$stop <- 0 + 2 * pi * dat$end/1500
>>
>> # Open blank plot window and draw circles
>> Canvas(xlim = c(-5,5), xpd=TRUE)
>> DrawCircle (r.out = 5, r.in = 5, theta.1=.05, theta.2=2*pi-.05, lwd=3)
>> with(dat, DrawCircle(r.out = 5 - score/5, r.in = 5 - score/5,
>>      theta.1=begin, theta.2=stop, border=col, lwd=4))
>> text(5.2, .4, "1", pos=4)
>> text(5.2, -.4, "1500", pos=4)
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of swaraj
>> basu
>> Sent: Monday, February 13, 2017 10:34 AM
>> To: r-help at r-project.org
>> Subject: [R] Circular plot
>>
>> I want to plot segments deleted from mitochondrial DNA of patients with
>> neuromuscular disorders. I generate the plot on a linear chromosome using a
>> code similar to as shown below
>>
>> start<-c(1,5,600,820)
>> end<-c(250,75,810,1200)
>> score<-c(7,-1,4,-6.5)
>> dat<-data.frame(start=start,end=end,score=score,col="blue"
>> ,stringsAsFactors=F)
>> dat[dat$score<0,]$col<-"red"
>>
>> plot(1:1500,rep(0,1500),type="p",ylim=c(-10,10),col="white",
>> xlab="position",ylab="score")
>> segments(dat$start, dat$score, dat$end, dat$score, col=dat$col, lwd=3)
>>
>>
>> Since the human mitochondria is a circular genome, I would like to
>> visualise the plot generated above as a circle where all segments with
>> positive score lie inside the circle and those with negative score lie
>> outside. Attached is a representation of my requirement, although here it
>> is manually drawn. Can someone help me on this?
>>
>>
>> --
>> Swaraj Basu
>>
>
>
>
> --
> Swaraj Basu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Feb 14 00:37:04 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 13 Feb 2017 15:37:04 -0800
Subject: [R] [Python] NameError: name 'hurst' is not defined
In-Reply-To: <504528805.3481492.1487005698690@mail.yahoo.com>
References: <1205795624.3415204.1487005603330.ref@mail.yahoo.com>
	<1205795624.3415204.1487005603330@mail.yahoo.com>
	<504528805.3481492.1487005698690@mail.yahoo.com>
Message-ID: <8EF58240-AF1D-4DC9-A97E-DB0647536E51@dcn.davis.ca.us>

This question is off topic here. 
-- 
Sent from my phone. Please excuse my brevity.

On February 13, 2017 9:08:18 AM PST, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
>Correction, it should look like this:**def hurst(ts): lags = range(2,
>100) tau = [np.sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in
>lags] poly = np.polyfit(log(lags), log(tau), 1) return poly[0]*2.0 
>
>On Tuesday, 14 February 2017, 0:06, Allan Tanaka
><allantanaka11 at yahoo.com> wrote:
> 
>
>Hi. Not sure why this code produces the error like this. This error
>appears when i run the code of print "Hurst(GBM): ? %s" % hurst(gbm):?
>Traceback (most recent call last):? File "<pyshell#31>", line 1, in
><module>? ? print "Hurst(GBM): ? %s" % hurst(gbm)NameError: name
>'hurst' is not defined
>
>Here is the full code:>>> import statsmodels.tsa.stattools as ts
>>>> import urllib>>> from datetime import datetime>>> from
>pandas_datareader import data, wb>>> from pandas_datareader.data import
>DataReader>>> goog = DataReader("GOOG", "yahoo", datetime(2000,1,1),
>datetime(2017,1,1))>>> ts.adfuller(goog['Adj Close'], 1>>> import numpy
>as np
>>>> from numpy import cumsum, log, polyfit, sqrt, std, subtract>>> from
>numpy.random import randn>>> def hurst(ts): lags = range(2, 100) tau =
>[sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in lags] poly =
>polyfit(log(lags), log(tau), 1) return poly[0]*2.0>>> gbm =
>log(cumsum(randn(100000))+1000)>>> mr = log(randn(100000)+1000)>>> tr =
>log(cumsum(randn(100000)+1)+1000)>>> print "Hurst(GBM): ? %s" %
>hurst(gbm)
>
>
>
>   
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Feb 14 06:06:30 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 13 Feb 2017 21:06:30 -0800
Subject: [R] get() return nothing
In-Reply-To: <1620966806.3423620.1487004628401@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
	<1020994841.500566.1486837984563@mail.yahoo.com>
	<8f6e9c10-be6b-c6de-6120-ae9c0d385d38@gmail.com>
	<1620966806.3423620.1487004628401@mail.yahoo.com>
Message-ID: <7A4BEC08-DA81-48E6-8EFE-59437996372D@comcast.net>


> On Feb 13, 2017, at 8:50 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> 
> Well, I am not trying to print anything. I just would like to get the dimension information for all the dataframes I created. Could you please help me to develop the script?

You should post R code that builds objects of similar structure as your use case. 
(
At the moment we don't know how these dataframes are assembled (in a list?) or having names with a structure that we need to get() or with an associated character vector with their names that are not R names.)

-- 
David.
> Thanks.
> Ace 
> 
>    On Saturday, February 11, 2017 7:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> 
> On 11/02/2017 1:33 PM, Fix Ace via R-help wrote:
>> Hello, there,
>> I wrote a loop to check the dimension of all the .txt dataframes:> ls()
>>   [1] "actualpca.table" "b4galnt2"        "b4galnt2.txt"    "data"
>>   [5] "galnt4"          "galnt4.txt"      "galnt5"          "galnt5.txt"
>>   [9] "galnt6"          "galnt6.txt"      "glyco"          "glyco.txt"
>> [13] "i"              "mtscaled"        "newsig.table"    "nicepca"
>> [17] "pca"            "sig.txt"        "st3gal3"        "st3gal3.txt"
>> [21] "st3gal5"        "st3gal5.txt"    "st6gal1"        "st6gal1.txt"
>>> for(i in ls(pattern="txt")){dim(get(i))}
>>> 
>> If I check individual ones, they are ok:
>>> dim(get("galnt4.txt"))
>> [1] 8 3
>>> 
>> could anyone help me to figure out why it did not work with a loop?
>> Thanks a lot!
> 
> It's the difference between
> 
> for (i in 1:10) i
> 
> (which prints nothing) and
> 
> for (i in 1:10) print(i)
> 
> Duncan Murdoch
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Tue Feb 14 08:57:56 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 14 Feb 2017 20:57:56 +1300
Subject: [R] [FORGED] Re:  get() return nothing
In-Reply-To: <1620966806.3423620.1487004628401@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
	<1020994841.500566.1486837984563@mail.yahoo.com>
	<8f6e9c10-be6b-c6de-6120-ae9c0d385d38@gmail.com>
	<1620966806.3423620.1487004628401@mail.yahoo.com>
Message-ID: <2b2d3c83-e6ca-3886-cd8f-3c53f462c992@auckland.ac.nz>


On 14/02/17 05:50, Fix Ace via R-help wrote:

> Well, I am not trying to print anything. I just would like to get the dimension information for all the dataframes I created. Could you please help me to develop the script?
> Thanks.
> Ace

Yes you *are* trying to print something.  You are trying to print the 
dimension information, i.e. dim(get(i))!!! For Pete's sake (a) *think* 
about what you are doing and (b) *try* example that Duncan suggested to you.

cheers,

Rolf Turner
>
>     On Saturday, February 11, 2017 7:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>
>  On 11/02/2017 1:33 PM, Fix Ace via R-help wrote:
>> Hello, there,
>> I wrote a loop to check the dimension of all the .txt dataframes:> ls()
>>   [1] "actualpca.table" "b4galnt2"        "b4galnt2.txt"    "data"
>>   [5] "galnt4"          "galnt4.txt"      "galnt5"          "galnt5.txt"
>>   [9] "galnt6"          "galnt6.txt"      "glyco"          "glyco.txt"
>> [13] "i"              "mtscaled"        "newsig.table"    "nicepca"
>> [17] "pca"            "sig.txt"        "st3gal3"        "st3gal3.txt"
>> [21] "st3gal5"        "st3gal5.txt"    "st6gal1"        "st6gal1.txt"
>>> for(i in ls(pattern="txt")){dim(get(i))}
>>>
>> If I check individual ones, they are ok:
>>> dim(get("galnt4.txt"))
>> [1] 8 3
>>>
>> could anyone help me to figure out why it did not work with a loop?
>> Thanks a lot!
>
> It's the difference between
>
> for (i in 1:10) i
>
> (which prints nothing) and
>
> for (i in 1:10) print(i)
>
> Duncan Murdoch
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From careyshan at gmail.com  Tue Feb 14 11:53:57 2017
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 14 Feb 2017 10:53:57 +0000
Subject: [R] Create gif from series of png files
Message-ID: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>

Hi,

I have many png files that I would like to stitch together, in order to
make a gif file.

Any ideas how I would do this?

Thanks

-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Feb 14 12:33:45 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 14 Feb 2017 11:33:45 +0000
Subject: [R] Create gif from series of png files
In-Reply-To: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>
References: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>
Message-ID: <CAKVAULNncSMdH1DrMKo8MC2=1gEhg2-U6PKbBmw4d+AB_AXzVQ@mail.gmail.com>

Hi Shane,

Wrong forum. This might be what you are looking for

ffmpeg -i %03d.png output.gif

Or use the library gganimate.

Best
Ulrik

Shane Carey <careyshan at gmail.com> schrieb am Di., 14. Feb. 2017, 12:08:

> Hi,
>
> I have many png files that I would like to stitch together, in order to
> make a gif file.
>
> Any ideas how I would do this?
>
> Thanks
>
> --
> Le gach dea ghui,
> Shane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From careyshan at gmail.com  Tue Feb 14 12:52:20 2017
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 14 Feb 2017 11:52:20 +0000
Subject: [R] Create gif from series of png files
In-Reply-To: <CAKVAULNncSMdH1DrMKo8MC2=1gEhg2-U6PKbBmw4d+AB_AXzVQ@mail.gmail.com>
References: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>
	<CAKVAULNncSMdH1DrMKo8MC2=1gEhg2-U6PKbBmw4d+AB_AXzVQ@mail.gmail.com>
Message-ID: <CA+jRDxCk9h5P3pO7OjM5gPzLb-Eq12pBGnc=+U2dR2L8mVeURQ@mail.gmail.com>

Hi Ulrick,

I created the png's in R and was hoping there would be a way of stitching
them together in R. Is there a different forum I should be  posting to?

Thanks

On Tue, Feb 14, 2017 at 11:33 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Shane,
>
> Wrong forum. This might be what you are looking for
>
> ffmpeg -i %03d.png output.gif
>
> Or use the library gganimate.
>
> Best
> Ulrik
>
> Shane Carey <careyshan at gmail.com> schrieb am Di., 14. Feb. 2017, 12:08:
>
>> Hi,
>>
>> I have many png files that I would like to stitch together, in order to
>> make a gif file.
>>
>> Any ideas how I would do this?
>>
>> Thanks
>>
>> --
>> Le gach dea ghui,
>> Shane
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Tue Feb 14 14:48:00 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 14 Feb 2017 08:48:00 -0500
Subject: [R] [FORGED] Re:  get() return nothing
In-Reply-To: <2b2d3c83-e6ca-3886-cd8f-3c53f462c992@auckland.ac.nz>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
	<1020994841.500566.1486837984563@mail.yahoo.com>
	<8f6e9c10-be6b-c6de-6120-ae9c0d385d38@gmail.com>
	<1620966806.3423620.1487004628401@mail.yahoo.com>
	<2b2d3c83-e6ca-3886-cd8f-3c53f462c992@auckland.ac.nz>
Message-ID: <D1F3FBE5-0D02-4A35-A68C-FC84FF5703A2@bigelow.org>

Hi,

When you want to get 'something' out of a loop you need to assign that 'something' to a variable that persists outside of the loop. I think it is a scoping thing. In your situation you could create a list with as many elements as there are objects with 'txt' in their names.  I can't quite follow what is is you are after, but perhaps something like this (untested and I'm still on my first cup of coffee) ...

obj_names <- ls(pattern="txt")
obj_dims <- vector(mode = 'list', length = length(obj_names))
names(obj_dims) <- obj_names
for (nm in obj_names)){
    obj_dims[[nm]] <- dim(get(nm)) 
}

Does that do what you want?  If so, you could probably use lapply() for the purpose instead of the for loop, but even better is to store each of your objects in a list as you create them rather than letting them get loose in the global environment.  That way you don't have to do this get-by-name rodeo to get info on them.

Cheers,
Ben



> On Feb 14, 2017, at 2:57 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 14/02/17 05:50, Fix Ace via R-help wrote:
> 
>> Well, I am not trying to print anything. I just would like to get the dimension information for all the dataframes I created. Could you please help me to develop the script?
>> Thanks.
>> Ace
> 
> Yes you *are* trying to print something.  You are trying to print the dimension information, i.e. dim(get(i))!!! For Pete's sake (a) *think* about what you are doing and (b) *try* example that Duncan suggested to you.
> 
> cheers,
> 
> Rolf Turner
>> 
>>    On Saturday, February 11, 2017 7:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> 
>> On 11/02/2017 1:33 PM, Fix Ace via R-help wrote:
>>> Hello, there,
>>> I wrote a loop to check the dimension of all the .txt dataframes:> ls()
>>>  [1] "actualpca.table" "b4galnt2"        "b4galnt2.txt"    "data"
>>>  [5] "galnt4"          "galnt4.txt"      "galnt5"          "galnt5.txt"
>>>  [9] "galnt6"          "galnt6.txt"      "glyco"          "glyco.txt"
>>> [13] "i"              "mtscaled"        "newsig.table"    "nicepca"
>>> [17] "pca"            "sig.txt"        "st3gal3"        "st3gal3.txt"
>>> [21] "st3gal5"        "st3gal5.txt"    "st6gal1"        "st6gal1.txt"
>>>> for(i in ls(pattern="txt")){dim(get(i))}
>>>> 
>>> If I check individual ones, they are ok:
>>>> dim(get("galnt4.txt"))
>>> [1] 8 3
>>>> 
>>> could anyone help me to figure out why it did not work with a loop?
>>> Thanks a lot!
>> 
>> It's the difference between
>> 
>> for (i in 1:10) i
>> 
>> (which prints nothing) and
>> 
>> for (i in 1:10) print(i)
>> 
>> Duncan Murdoch
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From lal.prasad at gmail.com  Tue Feb 14 16:02:34 2017
From: lal.prasad at gmail.com (Lal Prasad)
Date: Tue, 14 Feb 2017 20:32:34 +0530
Subject: [R] VAR for Non Stationary series using R
Message-ID: <CACuGqaLxn4-OSU9MsrorojyPrZ1vrswh9GQnUOuJ5PjZ6gTW8Q@mail.gmail.com>

Hi All,


Is there any suggested approaches for using non-stationary series in VAR
model? As per otexts.org
<http://stats.stackexchange.com/questions/261876/var-for-non-stationary-series-using-r>,
there is something like "VAR in differences which could be used for such
series.

Are there any other approaches for creating a forecasting mode non
stationary series in a multi variate series?

Any leads on this would be helpful. I'm looking for implementing this model
in R.

Regards
Lal

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Feb 14 16:12:43 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 14 Feb 2017 10:12:43 -0500
Subject: [R] Create gif from series of png files
In-Reply-To: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>
References: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>
Message-ID: <365a02bb-7d05-83da-b664-545ed1d7d262@gmail.com>

On 14/02/2017 5:53 AM, Shane Carey wrote:
> Hi,
>
> I have many png files that I would like to stitch together, in order to
> make a gif file.
>
> Any ideas how I would do this?

ImageMagick is good for this.  The magick package in R makes most (all?) 
of its features available.  The image_animate() function can produce an 
animation; see either the ImageMagick docs online, or the "intro" 
vignette in the magick package for examples and instructions.

Duncan Murdoch


From g.wieteska at yahoo.ie  Tue Feb 14 12:56:52 2017
From: g.wieteska at yahoo.ie (Malgorzata Wieteska)
Date: Tue, 14 Feb 2017 11:56:52 +0000 (UTC)
Subject: [R] minpack package in R version 3.3.2
References: <2052484023.7117838.1487073412953.ref@mail.yahoo.com>
Message-ID: <2052484023.7117838.1487073412953@mail.yahoo.com>

Hello,
I'm?new to R. I found very useful for me code for parameter estimation. Unfortunately, while trying to install "minpack" I get info, that this package is not available for version 3.3.2.
I'm using Windows 10. Does anyone know?how to overcome this and maybe a hint on which version of R it has been working (I would try to install a?previous version)?
Thanks in advance for any hint.Gosia
	[[alternative HTML version deleted]]


From tavella.teresa23 at gmail.com  Tue Feb 14 15:17:00 2017
From: tavella.teresa23 at gmail.com (Teresa Tavella)
Date: Tue, 14 Feb 2017 15:17:00 +0100
Subject: [R] renameSeqlevels
Message-ID: <CAOr_NAkHFNoZOVT60CXjBS_EjjEazQ4Y+DrAB38w-c4PV8wKpg@mail.gmail.com>

Dear all,

I would like to ask if it is possible to change the seqnames of a bam file
giving a vector of character to the function renameSeqlevels. This is
because in order to use the fuction summarizeOverlap or count/find, the
seqnames have to match.
>From the bamfile below I have extracted the locus annotations form the
seqnames (i.e ERCC00002, NC_001133.9...etc) and I have created a list (same
length as the seqlevels of the bam file).


*bamfile*
GAlignments object with 6 alignments and 0 metadata columns:

seqnames

<Rle>
  [1]
DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
  [2]
DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
  [3]
DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
  [4]
DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
  [5]
DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
  [6]
DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
      strand       cigar    qwidth     start       end     width     njunc
       <Rle> <character> <integer> <integer> <integer> <integer> <integer>
  [1]      +     8M2D27M        35      1025      1061        37         0
  [2]      +     8M2D27M        35      1025      1061        37         0
  [3]      -         36M        36      1025      1060        36         0
  [4]      -         36M        36      1026      1061        36         0
  [5]      +         35M        35      1027      1061        35         0
  [6]      +         35M        35      1027      1061        35         0
  -------
*gffile*
GRanges object with 6 ranges and 12 metadata columns:
         seqnames           ranges strand |       source     type     score
            <Rle>        <IRanges>  <Rle> |     <factor> <factor> <numeric>
  [1] NC_001133.9 [ 24837,  25070]      + | s_cerevisiae     exon      <NA>
  [2] NC_001133.9 [ 25048,  25394]      + | s_cerevisiae     exon      <NA>
  [3] NC_001133.9 [ 27155,  27786]      + | s_cerevisiae     exon      <NA>
  [4] NC_001133.9 [ 73431,  73792]      + | s_cerevisiae     exon      <NA>
  [5] NC_001133.9 [165314, 165561]      + | s_cerevisiae     exon      <NA>
  [6] NC_001133.9 [165388, 165781]      + | s_cerevisiae     exon      <NA>
          phase     gene_id  transcript_id exon_number   gene_name
      <integer> <character>    <character> <character> <character>
  [1]      <NA> XLOC_000040 TCONS_00000191           1        FLO9
  [2]      <NA> XLOC_000040 TCONS_00000192           1        FLO9
  [3]      <NA> XLOC_000041 TCONS_00000193           1        FLO9
  [4]      <NA> XLOC_000055 TCONS_00000200           1   YAL037C-A
  [5]      <NA> XLOC_000075 TCONS_00000100           1     YAR010C
  [6]      <NA> XLOC_000075 TCONS_00000219           1     YAR010C
                                         oId nearest_ref  class_code
                                 <character> <character> <character>
  [1]   {TRINITY_GG_normal}16_c1_g1_i1.mrna1        rna8           x
  [2]   {TRINITY_GG_normal}16_c0_g1_i1.mrna1        rna8           x
  [3]   {TRINITY_GG_normal}12_c0_g1_i1.mrna1        rna8           x
  [4]    {TRINITY_GG_normal}3_c3_g1_i1.mrna1       rna31           x
  [5] {TRINITY_GG_normal}3479_c0_g1_i1.mrna1       rna77           x
  [6]   {TRINITY_GG_normal}24_c0_g1_i1.mrna1       rna77           x
           tss_id
      <character>
  [1]       TSS42
  [2]       TSS43
  [3]       TSS44
  [4]       TSS71
  [5]      TSS118
  [6]      TSS118
  -------

It is possible to replace the seqlevels names with the list?
I have tried:

bamfile1 <- renameSeqlevels(seqlevels(bamfile), listx)

Thank you for any advice,

Kind regards,

Teresa
-------------- next part --------------
A non-text attachment was scrubbed...
Name: bamfile.png
Type: image/png
Size: 19163 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170214/94975aa3/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: gfffile.png
Type: image/png
Size: 31020 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170214/94975aa3/attachment-0001.png>

From lordpreetam at gmail.com  Tue Feb 14 13:18:26 2017
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 14 Feb 2017 17:48:26 +0530
Subject: [R] Forecasting using VECM
Message-ID: <CAHVFrXF1PfPAGtCWPxA+zoqQFAEPEwyJTtJwRrD5owSo5whuYg@mail.gmail.com>

Hi,

I have attached the historical dataset (titled data) containing numerical
variables GDP, HPA, FX and Y - I am interested to predict Y given some
future values of GDP, HPA and FX.

   - Some variables are non-statioanry as per adf.test()
   - I wanted to implement a VECM framework for modeling cointegration, so
   I have used *result = VECM(data, lag = 3, r = 1)* , and I get the output
   below showing that cointegration relationship does exist between these 4
   variables:
   - My question is: How do I get predictions of Y given
   externally-generated future values of the other variables (for say,
   upcoming 10 time points), using this result programmatically?

Regards,
Preetam
#############
Model VECM
#############
Full sample size: 25 End sample size: 22
Number of variables: 4 Number of estimated slope parameters 40
AIC 23.84198 BIC 70.75681 SSR 156.5155
Cointegrating vector (estimated by ML):
   GDP      HPA        FX           Y
r1   1 2.171994 -6.823215 -0.07767563


             ECT                 Intercept           GDP -1
Equation GDP 0.0612(0.0436)      0.0141(0.0687)      -0.4268(0.2494)
Equation HPA -0.6368(0.2381)*    0.1858(0.3749)      3.1656(1.3609)*
Equation FX  0.1307(0.0874)      -0.0039(0.1377)     0.1739(0.4997)
Equation Y   -0.0852(0.4261)     0.3219(0.6711)      -5.0248(2.4359).
             HPA -1              FX -1               Y -1
Equation GDP -0.0910(0.0790)     0.1988(0.2261)      0.0413(0.0299)
Equation HPA 0.4891(0.4311)      -2.2140(1.2337).    -0.3206(0.1631).
Equation FX  -0.2108(0.1583)     -0.2536(0.4530)     -0.0303(0.0599)
Equation Y   -0.3686(0.7716)     0.5234(2.2083)      -0.9638(0.2920)**
             GDP -2              HPA -2              FX -2
Equation GDP -0.2892(0.2452)     -0.0622(0.0563)     0.0598(0.1352)
Equation HPA -0.7084(1.3379)     0.1877(0.3069)      -0.2231(0.7377)
Equation FX  -0.1773(0.4913)     -0.0170(0.1127)     -0.2486(0.2709)
Equation Y   -3.8521(2.3948)     -0.4559(0.5494)     1.1239(1.3205)
             Y -2
Equation GDP 0.0411(0.0279)
Equation HPA -0.2447(0.1521)
Equation FX  -0.0102(0.0559)
Equation Y   -0.1696(0.2723)
-------------- next part --------------
GDP	        HPA	        FX      	Y
0.514662421	0.635997077	1.37802145	1.773342598
0.936722	3.127683176	1.391916535	3.709809052
0.101482324	1.270555421	0.831157511	0.226267793
0.017548634	2.456061547	1.003945759	9.510258161
0.236462416	0.988324147	0.223682679	5.026671536
0.372005149	2.177631629	0.904226065	4.219235789
0.153915709	4.620341653	0.033410743	3.17396006
0.524887329	1.050861084	0.518201484	7.950098612
0.776616937	0.503349512	0.666089868	3.320938471
0.760074361	3.635853456	0.470220952	6.380945175
0.802986662	1.260738545	0.452674872	1.036040804
0.375145127	0.20035625	1.837306306	6.486871565
0.002568896	3.532359526	0.556752154	8.536594244
0.754309276	3.952381767	0.247402168	8.559081716
0.585966577	4.01463047	1.184382133	0.148121669
0.39767356	1.553753452	0.983129422	5.378373676
0.859898623	4.73191381	0.828795696	3.367809329
0.741376169	4.993350692	1.758051281	5.516460988
0.329240391	3.465836416	1.701655508	1.249497907
0.078661064	3.298298811	0.04575857	5.132921426
0.270971873	0.46627043	1.739487411	4.94697541
0.731072625	0.940642982	0.728747166	7.583041122
0.385038046	3.51048946	0.021866584	7.361148458
0.530760376	1.204422978	0.415530715	1.163503483
0.555323667	4.777712592	1.844184811	8.596644394

From siswantosumargo at gmail.com  Tue Feb 14 15:39:04 2017
From: siswantosumargo at gmail.com (Siswanto Sumargo)
Date: Tue, 14 Feb 2017 21:39:04 +0700
Subject: [R] CAR
Message-ID: <CAM6-swSOByE9MOb8e858CfAxrw3vyO9j6sXHiJc1ZGzJLOTWVw@mail.gmail.com>

*I would like to simulate spatial data conditional **autoregressive
(CAR) model with weighted matrix order 2**Is there any package or
function in R to perform it ?
**Thanks in advance*

*Best Regards
Siswanto*

-- 
*Siswanto*
Department of Statistics, Faculty of Mathematics and Natural Science
Bogor Agricultural University, Dramaga Bogor Indonesia 16680
Telp         : 0899 130 20 89
Email       : siswantosumargo at gmail.com

*?Success is getting what you want, happiness is wanting what you get? *

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 14 16:47:31 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Feb 2017 07:47:31 -0800
Subject: [R] Forecasting using VECM
In-Reply-To: <CAHVFrXF1PfPAGtCWPxA+zoqQFAEPEwyJTtJwRrD5owSo5whuYg@mail.gmail.com>
References: <CAHVFrXF1PfPAGtCWPxA+zoqQFAEPEwyJTtJwRrD5owSo5whuYg@mail.gmail.com>
Message-ID: <CAGxFJbSdmJ7hVRii75+hwWewpsUkyf=9rO58+iDCs8J_xe8-bw@mail.gmail.com>

Searching on "VECM" on rseek.org brought up:

"VECM" on the Rdocumentation site, which clearly states:

"The predict method contains a newdata argument allowing to compute
rolling forecasts."

If that is not what you want, you'll need to explain why not, I think.
If it is, please do such searching on your own in future.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 14, 2017 at 4:18 AM, Preetam Pal <lordpreetam at gmail.com> wrote:
> Hi,
>
> I have attached the historical dataset (titled data) containing numerical
> variables GDP, HPA, FX and Y - I am interested to predict Y given some
> future values of GDP, HPA and FX.
>
>    - Some variables are non-statioanry as per adf.test()
>    - I wanted to implement a VECM framework for modeling cointegration, so
>    I have used *result = VECM(data, lag = 3, r = 1)* , and I get the output
>    below showing that cointegration relationship does exist between these 4
>    variables:
>    - My question is: How do I get predictions of Y given
>    externally-generated future values of the other variables (for say,
>    upcoming 10 time points), using this result programmatically?
>
> Regards,
> Preetam
> #############
> Model VECM
> #############
> Full sample size: 25 End sample size: 22
> Number of variables: 4 Number of estimated slope parameters 40
> AIC 23.84198 BIC 70.75681 SSR 156.5155
> Cointegrating vector (estimated by ML):
>    GDP      HPA        FX           Y
> r1   1 2.171994 -6.823215 -0.07767563
>
>
>              ECT                 Intercept           GDP -1
> Equation GDP 0.0612(0.0436)      0.0141(0.0687)      -0.4268(0.2494)
> Equation HPA -0.6368(0.2381)*    0.1858(0.3749)      3.1656(1.3609)*
> Equation FX  0.1307(0.0874)      -0.0039(0.1377)     0.1739(0.4997)
> Equation Y   -0.0852(0.4261)     0.3219(0.6711)      -5.0248(2.4359).
>              HPA -1              FX -1               Y -1
> Equation GDP -0.0910(0.0790)     0.1988(0.2261)      0.0413(0.0299)
> Equation HPA 0.4891(0.4311)      -2.2140(1.2337).    -0.3206(0.1631).
> Equation FX  -0.2108(0.1583)     -0.2536(0.4530)     -0.0303(0.0599)
> Equation Y   -0.3686(0.7716)     0.5234(2.2083)      -0.9638(0.2920)**
>              GDP -2              HPA -2              FX -2
> Equation GDP -0.2892(0.2452)     -0.0622(0.0563)     0.0598(0.1352)
> Equation HPA -0.7084(1.3379)     0.1877(0.3069)      -0.2231(0.7377)
> Equation FX  -0.1773(0.4913)     -0.0170(0.1127)     -0.2486(0.2709)
> Equation Y   -3.8521(2.3948)     -0.4559(0.5494)     1.1239(1.3205)
>              Y -2
> Equation GDP 0.0411(0.0279)
> Equation HPA -0.2447(0.1521)
> Equation FX  -0.0102(0.0559)
> Equation Y   -0.1696(0.2723)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb 14 16:51:20 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Feb 2017 07:51:20 -0800
Subject: [R] CAR
In-Reply-To: <CAM6-swSOByE9MOb8e858CfAxrw3vyO9j6sXHiJc1ZGzJLOTWVw@mail.gmail.com>
References: <CAM6-swSOByE9MOb8e858CfAxrw3vyO9j6sXHiJc1ZGzJLOTWVw@mail.gmail.com>
Message-ID: <CAGxFJbTgtvLaGtKH+AJOz-2YQk9wiDDJ3J7r9t2cfM=bL7o7YA@mail.gmail.com>

Rseek.org brings up what look like relevant hits on "conditional
autoregressive models." Have you looked at these? If so and they do
not suit, perhaps you should explain why not. If they do, please do
such searching on your own in future.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 14, 2017 at 6:39 AM, Siswanto Sumargo
<siswantosumargo at gmail.com> wrote:
> *I would like to simulate spatial data conditional **autoregressive
> (CAR) model with weighted matrix order 2**Is there any package or
> function in R to perform it ?
> **Thanks in advance*
>
> *Best Regards
> Siswanto*
>
> --
> *Siswanto*
> Department of Statistics, Faculty of Mathematics and Natural Science
> Bogor Agricultural University, Dramaga Bogor Indonesia 16680
> Telp         : 0899 130 20 89
> Email       : siswantosumargo at gmail.com
>
> *?Success is getting what you want, happiness is wanting what you get? *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From martin.morgan at roswellpark.org  Tue Feb 14 16:52:05 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 14 Feb 2017 10:52:05 -0500
Subject: [R] renameSeqlevels
In-Reply-To: <CAOr_NAkHFNoZOVT60CXjBS_EjjEazQ4Y+DrAB38w-c4PV8wKpg@mail.gmail.com>
References: <CAOr_NAkHFNoZOVT60CXjBS_EjjEazQ4Y+DrAB38w-c4PV8wKpg@mail.gmail.com>
Message-ID: <b77182ea-d650-2a47-5663-c55894dcac96@roswellpark.org>

Rsamtools and GenomicAlignments are Bioconductor packages so ask on the 
Bioconductor support site

   https://support.bioconductor.org

You cannot rename the seqlevels in the bam file; you could rename the 
seqlevels in the object(s) you have created from the bam file.

Martin

On 02/14/2017 09:17 AM, Teresa Tavella wrote:
> Dear all,
>
> I would like to ask if it is possible to change the seqnames of a bam file
> giving a vector of character to the function renameSeqlevels. This is
> because in order to use the fuction summarizeOverlap or count/find, the
> seqnames have to match.
>>From the bamfile below I have extracted the locus annotations form the
> seqnames (i.e ERCC00002, NC_001133.9...etc) and I have created a list (same
> length as the seqlevels of the bam file).
>
>
> *bamfile*
> GAlignments object with 6 alignments and 0 metadata columns:
>
> seqnames
>
> <Rle>
>   [1]
> DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
>   [2]
> DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
>   [3]
> DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
>   [4]
> DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
>   [5]
> DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
>   [6]
> DQ459430_gene=ERCC00002_loc:ERCC00002|1-1061|+_exons:1-1061_segs:1-1061
>       strand       cigar    qwidth     start       end     width     njunc
>        <Rle> <character> <integer> <integer> <integer> <integer> <integer>
>   [1]      +     8M2D27M        35      1025      1061        37         0
>   [2]      +     8M2D27M        35      1025      1061        37         0
>   [3]      -         36M        36      1025      1060        36         0
>   [4]      -         36M        36      1026      1061        36         0
>   [5]      +         35M        35      1027      1061        35         0
>   [6]      +         35M        35      1027      1061        35         0
>   -------
> *gffile*
> GRanges object with 6 ranges and 12 metadata columns:
>          seqnames           ranges strand |       source     type     score
>             <Rle>        <IRanges>  <Rle> |     <factor> <factor> <numeric>
>   [1] NC_001133.9 [ 24837,  25070]      + | s_cerevisiae     exon      <NA>
>   [2] NC_001133.9 [ 25048,  25394]      + | s_cerevisiae     exon      <NA>
>   [3] NC_001133.9 [ 27155,  27786]      + | s_cerevisiae     exon      <NA>
>   [4] NC_001133.9 [ 73431,  73792]      + | s_cerevisiae     exon      <NA>
>   [5] NC_001133.9 [165314, 165561]      + | s_cerevisiae     exon      <NA>
>   [6] NC_001133.9 [165388, 165781]      + | s_cerevisiae     exon      <NA>
>           phase     gene_id  transcript_id exon_number   gene_name
>       <integer> <character>    <character> <character> <character>
>   [1]      <NA> XLOC_000040 TCONS_00000191           1        FLO9
>   [2]      <NA> XLOC_000040 TCONS_00000192           1        FLO9
>   [3]      <NA> XLOC_000041 TCONS_00000193           1        FLO9
>   [4]      <NA> XLOC_000055 TCONS_00000200           1   YAL037C-A
>   [5]      <NA> XLOC_000075 TCONS_00000100           1     YAR010C
>   [6]      <NA> XLOC_000075 TCONS_00000219           1     YAR010C
>                                          oId nearest_ref  class_code
>                                  <character> <character> <character>
>   [1]   {TRINITY_GG_normal}16_c1_g1_i1.mrna1        rna8           x
>   [2]   {TRINITY_GG_normal}16_c0_g1_i1.mrna1        rna8           x
>   [3]   {TRINITY_GG_normal}12_c0_g1_i1.mrna1        rna8           x
>   [4]    {TRINITY_GG_normal}3_c3_g1_i1.mrna1       rna31           x
>   [5] {TRINITY_GG_normal}3479_c0_g1_i1.mrna1       rna77           x
>   [6]   {TRINITY_GG_normal}24_c0_g1_i1.mrna1       rna77           x
>            tss_id
>       <character>
>   [1]       TSS42
>   [2]       TSS43
>   [3]       TSS44
>   [4]       TSS71
>   [5]      TSS118
>   [6]      TSS118
>   -------
>
> It is possible to replace the seqlevels names with the list?
> I have tried:
>
> bamfile1 <- renameSeqlevels(seqlevels(bamfile), listx)
>
> Thank you for any advice,
>
> Kind regards,
>
> Teresa
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


This email message may contain legally privileged and/or...{{dropped:2}}


From jdnewmil at dcn.davis.ca.us  Tue Feb 14 17:09:57 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 14 Feb 2017 08:09:57 -0800
Subject: [R] minpack package in R version 3.3.2
In-Reply-To: <2052484023.7117838.1487073412953@mail.yahoo.com>
References: <2052484023.7117838.1487073412953.ref@mail.yahoo.com>
	<2052484023.7117838.1487073412953@mail.yahoo.com>
Message-ID: <51EAB801-B64A-4B34-B073-E140F0B6BD26@dcn.davis.ca.us>

The primary place for finding out about packages is the Comprehensive R Archive Network, or CRAN. Try entering 

R package minpack CRAN

into Google and you should be able to see what you need to do on your own. If you still need help, tell us what you found and why it didn't help when you post your next question. 
-- 
Sent from my phone. Please excuse my brevity.

On February 14, 2017 3:56:52 AM PST, Malgorzata Wieteska via R-help <r-help at r-project.org> wrote:
>Hello,
>I'm?new to R. I found very useful for me code for parameter estimation.
>Unfortunately, while trying to install "minpack" I get info, that this
>package is not available for version 3.3.2.
>I'm using Windows 10. Does anyone know?how to overcome this and maybe a
>hint on which version of R it has been working (I would try to install
>a?previous version)?
>Thanks in advance for any hint.Gosia
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From profjcnash at gmail.com  Tue Feb 14 17:12:40 2017
From: profjcnash at gmail.com (J C Nash)
Date: Tue, 14 Feb 2017 11:12:40 -0500
Subject: [R] minpack package in R version 3.3.2
In-Reply-To: <2052484023.7117838.1487073412953@mail.yahoo.com>
References: <2052484023.7117838.1487073412953.ref@mail.yahoo.com>
	<2052484023.7117838.1487073412953@mail.yahoo.com>
Message-ID: <8093d277-289f-2d82-5095-9a7552d61590@gmail.com>

You probably wanted minpack.lm, not minpack.

FYI, Duncan Murdoch and I just put up nlsr on CRAN. It does ANALYTIC derivatives on expression-form nonlinear models, 
and also handles function-form problems. It does a Marquardt-stabilized solution, and allows fixed parameters by 
specifying upper and lower bounds equal.

JN


On 2017-02-14 06:56 AM, Malgorzata Wieteska via R-help wrote:
> Hello,
> I'm new to R. I found very useful for me code for parameter estimation. Unfortunately, while trying to install "minpack" I get info, that this package is not available for version 3.3.2.
> I'm using Windows 10. Does anyone know how to overcome this and maybe a hint on which version of R it has been working (I would try to install a previous version)?
> Thanks in advance for any hint.Gosia
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Tue Feb 14 17:53:24 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 14 Feb 2017 16:53:24 +0000
Subject: [R] Circular plot
In-Reply-To: <CAKNnbJRpGWrmEyiCv_1zobG_o2y0S0x3dC5d3tb4ttBAeOzv=A@mail.gmail.com>
References: <CAKNnbJTpHpJYikat0Ot=aUbL+cADP7iOyreu_5FKdHnepeKHcA@mail.gmail.com>
	<c25539dcec0747d694f54a324fb40e78@exch-2p-mbx-w2.ads.tamu.edu>
	<CAKNnbJRpGWrmEyiCv_1zobG_o2y0S0x3dC5d3tb4ttBAeOzv=A@mail.gmail.com>
Message-ID: <a489745826b0471497b7fb5fef0bb246@exch-2p-mbx-w2.ads.tamu.edu>

This is pretty close to your original plot. To get clockwise we multiply the radians by -1 and then add pi/2 to move the origin to 12 o'clock. We need to flip the start and end values since now we are be plotting from the end to the start:

start<-c(1,5,600,820)
end<-c(250,75,810,1200)
score<-c(7,-1,4,-6.5)
dat<-data.frame(start=start,end=end,score=score,col="blue",stringsAsFactors=F)
dat[dat$score<0,]$col<-"red"

# Convert begin/stop to radians
dat$stop <- -(2 * pi * dat$start/1500) + pi/2
dat$begin <- -(2 * pi * dat$end/1500) + pi/2

# Open blank plot window and draw circles
Canvas(xlim = c(-5,5), xpd=TRUE)
DrawCircle (r.out = 5, r.in = 5, theta.1=pi/2+.05, theta.2=pi*5/2-.05, lwd=3)
with(dat, DrawCircle(r.out = 5 - score/5, r.in = 5 - score/5, 
     theta.1= begin, theta.2= stop, border=col, lwd=4))
text(.1, 5.5, "1", pos=4)
text(-.1, 5.5, "1500", pos=2)

David C


From: swaraj basu [mailto:projectbasu at gmail.com] 
Sent: Monday, February 13, 2017 3:58 PM
To: David L Carlson <dcarlson at tamu.edu>; r-help at r-project.org
Subject: Re: [R] Circular plot

Thank you David, I could get the circle at 12 and clockwise however I believe my solution is not the optimal one, could you help me out with the best way to generate the circle clockwise at 12 and then convert the begin/stop to radians

Here is what I tried

par(mar=c(2,2,2,2),xpd=TRUE);
plot(c(1,800),c(1,800),type="n",axes=FALSE,xlab="",ylab="",main="");
DrawCircle (x=400,y=400,r.out = 400, r.in = 400, theta.1=1.57, theta.2=-2*pi-4.67, lwd=1)

On Mon, Feb 13, 2017 at 6:52 PM, David L Carlson <dcarlson at tamu.edu> wrote:
You can do this easily with the DrawCircle() function in package DescTools. It is easiest to use geometric coordinates (0 is at 3 o'clock and moves counterclockwise around the circle), but it could be converted to 12 o'clock and clockwise:

library(DescTools)

# Convert begin/stop to radians
dat$begin <- 0 + 2 * pi * dat$start/1500
dat$stop <- 0 + 2 * pi * dat$end/1500

# Open blank plot window and draw circles
Canvas(xlim = c(-5,5), xpd=TRUE)
DrawCircle (r.out = 5, r.in = 5, theta.1=.05, theta.2=2*pi-.05, lwd=3)
with(dat, DrawCircle(r.out = 5 - score/5, r.in = 5 - score/5,
? ? ?theta.1=begin, theta.2=stop, border=col, lwd=4))
text(5.2, .4, "1", pos=4)
text(5.2, -.4, "1500", pos=4)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of swaraj basu
Sent: Monday, February 13, 2017 10:34 AM
To: r-help at r-project.org
Subject: [R] Circular plot

I want to plot segments deleted from mitochondrial DNA of patients with
neuromuscular disorders. I generate the plot on a linear chromosome using a
code similar to as shown below

start<-c(1,5,600,820)
end<-c(250,75,810,1200)
score<-c(7,-1,4,-6.5)
dat<-data.frame(start=start,end=end,score=score,col="blue",stringsAsFactors=F)
dat[dat$score<0,]$col<-"red"

plot(1:1500,rep(0,1500),type="p",ylim=c(-10,10),col="white",xlab="position",ylab="score")
segments(dat$start, dat$score, dat$end, dat$score, col=dat$col, lwd=3)


Since the human mitochondria is a circular genome, I would like to
visualise the plot generated above as a circle where all segments with
positive score lie inside the circle and those with negative score lie
outside. Attached is a representation of my requirement, although here it
is manually drawn. Can someone help me on this?


--
Swaraj Basu




-- 
Swaraj Basu
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mtDNAplot.png
Type: image/png
Size: 5065 bytes
Desc: mtDNAplot.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170214/5e64683a/attachment.png>

From peter.mills at strath.ac.uk  Tue Feb 14 17:55:42 2017
From: peter.mills at strath.ac.uk (Peter Mills)
Date: Tue, 14 Feb 2017 16:55:42 +0000
Subject: [R] Von Mises mixtures: mu and kappa?
Message-ID: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86CCD8@EX2010-MBX2.ds.strath.ac.uk>

Hello

I am trying to calculate the values of the concentration parameters (kappa) and preferred direction (mu) for a Von Mises mixture model. I currently have some R code that gives me optimised values for the product of kappa and mu, but I'm not sure how to calculate them when both are unknown? How could I calculate mu and kappa from y2 if I didn't know either in the 1st place? I what to use movMF to give me values of kappa from some directional data where I don't know either kappa or mu.


## Generate and fit a "small-mix" data set a la Banerjee et al.
mu <- rbind(c(-0.251, -0.968),
            c(0.399, 0.917))
kappa <- c(4, 4)

theta <- kappa * mu
theta
alpha <- c(0.48, 0.52)

## Generate a sample of size n = 50 from the von Mises-Fisher mixture
## with the above parameters.
set.seed(123)
x <- rmovMF(50, theta, alpha)
## Fit a von Mises-Fisher mixture with the "right" number of components,
## using 10 EM runs.
y2 <- movMF(x, 2, nruns = 10)

Y2 gives
> y2
theta:
       [,1]      [,2]
1  2.443225  5.259337
2 -1.851384 -4.291278
alpha:
[1] 0.4823648 0.5176352
L:
[1] 24.98124

How could I calculate kappa and mu if I didn't know either in the 1st place?

Thanks
Peter


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 14 18:48:31 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Feb 2017 09:48:31 -0800
Subject: [R] Von Mises mixtures: mu and kappa?
In-Reply-To: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86CCD8@EX2010-MBX2.ds.strath.ac.uk>
References: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86CCD8@EX2010-MBX2.ds.strath.ac.uk>
Message-ID: <CAGxFJbQn74BYsGe3sx_FCh-jJu783OW7syf9gf7uCOHg3_JEYA@mail.gmail.com>

Please search before posting!

Searching "von mises mixture distributions" on rseek.org brought up
what appeared to be several relevant hits. If none of these meet your
needs, you should probably explain why not in a follow up post.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 14, 2017 at 8:55 AM, Peter Mills <peter.mills at strath.ac.uk> wrote:
> Hello
>
> I am trying to calculate the values of the concentration parameters (kappa) and preferred direction (mu) for a Von Mises mixture model. I currently have some R code that gives me optimised values for the product of kappa and mu, but I'm not sure how to calculate them when both are unknown? How could I calculate mu and kappa from y2 if I didn't know either in the 1st place? I what to use movMF to give me values of kappa from some directional data where I don't know either kappa or mu.
>
>
> ## Generate and fit a "small-mix" data set a la Banerjee et al.
> mu <- rbind(c(-0.251, -0.968),
>             c(0.399, 0.917))
> kappa <- c(4, 4)
>
> theta <- kappa * mu
> theta
> alpha <- c(0.48, 0.52)
>
> ## Generate a sample of size n = 50 from the von Mises-Fisher mixture
> ## with the above parameters.
> set.seed(123)
> x <- rmovMF(50, theta, alpha)
> ## Fit a von Mises-Fisher mixture with the "right" number of components,
> ## using 10 EM runs.
> y2 <- movMF(x, 2, nruns = 10)
>
> Y2 gives
>> y2
> theta:
>        [,1]      [,2]
> 1  2.443225  5.259337
> 2 -1.851384 -4.291278
> alpha:
> [1] 0.4823648 0.5176352
> L:
> [1] 24.98124
>
> How could I calculate kappa and mu if I didn't know either in the 1st place?
>
> Thanks
> Peter
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb 14 19:02:10 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Feb 2017 10:02:10 -0800
Subject: [R] Create gif from series of png files
In-Reply-To: <CAKVAULNncSMdH1DrMKo8MC2=1gEhg2-U6PKbBmw4d+AB_AXzVQ@mail.gmail.com>
References: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>
	<CAKVAULNncSMdH1DrMKo8MC2=1gEhg2-U6PKbBmw4d+AB_AXzVQ@mail.gmail.com>
Message-ID: <CAGxFJbTOp-kO72Z77gyMVy_4SDzzeWcE6b1WTTDtnDogHA--=g@mail.gmail.com>

Ulrik:

Sheepishly Nitpicking (only because you are a regular and wise R-help
contibutor):

gganimate is not a library, it's a package.

No need to reply.

Best,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 14, 2017 at 3:33 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
> Hi Shane,
>
> Wrong forum. This might be what you are looking for
>
> ffmpeg -i %03d.png output.gif
>
> Or use the library gganimate.
>
> Best
> Ulrik
>
> Shane Carey <careyshan at gmail.com> schrieb am Di., 14. Feb. 2017, 12:08:
>
>> Hi,
>>
>> I have many png files that I would like to stitch together, in order to
>> make a gif file.
>>
>> Any ideas how I would do this?
>>
>> Thanks
>>
>> --
>> Le gach dea ghui,
>> Shane
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Feb 14 20:05:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Feb 2017 11:05:36 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
Message-ID: <CAGxFJbTg0fTcL_r=9YhOfK-e5ZUJTWdZYkau3GwmCFzvn-TLuw@mail.gmail.com>

Did you ever receive a reply to this?

Note that for your example:
> tapply(l,index,sum)
Error in FUN(X[[i]], ...) : invalid 'type' (list) of argument

A list is definitely not atomic (is.recursive(l) ).

So it looks like a "quirk" that FUN = unlist doesn't raise an error.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 4, 2017 at 4:17 AM, Tal Galili <tal.galili at gmail.com> wrote:
> In the help page of ?tapply it says that the first argument (X) is "an
> atomic object, typically a vector."
>
> However, tapply seems to be able to handle list objects. For example:
>
> ###################
>
> l <- as.list(1:10)
> is.atomic(l) # FALSE
> index <- c(rep(1,5),rep(2,5))
> tapply(l,index,unlist)
>
>> tapply(l,index,unlist)
> $`1`
> [1] 1 2 3 4 5
>
> $`2`
> [1]  6  7  8  9 10
>
>
> ###################
>
> Hence, does it mean a list an atomic object? (which I thought it wasn't) or
> is the help for tapply needs updating?
> (or some third option I'm missing?)
>
> Thanks.
>
>
>
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Wed Feb 15 02:10:05 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 14 Feb 2017 17:10:05 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
Message-ID: <8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>

Hi,

tapply() will work on any object 'X' that has a length and supports
single-bracket subsetting. These objects are sometimes called
"vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
and "[" method, etc... are examples of "vector-like" objects.

So instead of saying

   X: an atomic object, typically a vector.

I think it would be more accurate if the man page was saying something
like

   X: a vector-like object that supports subsetting with `[`, typically
      an atomic vector.

H.

On 02/04/2017 04:17 AM, Tal Galili wrote:
> In the help page of ?tapply it says that the first argument (X) is "an
> atomic object, typically a vector."
>
> However, tapply seems to be able to handle list objects. For example:
>
> ###################
>
> l <- as.list(1:10)
> is.atomic(l) # FALSE
> index <- c(rep(1,5),rep(2,5))
> tapply(l,index,unlist)
>
>> tapply(l,index,unlist)
> $`1`
> [1] 1 2 3 4 5
>
> $`2`
> [1]  6  7  8  9 10
>
>
> ###################
>
> Hence, does it mean a list an atomic object? (which I thought it wasn't) or
> is the help for tapply needs updating?
> (or some third option I'm missing?)
>
> Thanks.
>
>
>
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fredhutch.org  Wed Feb 15 02:10:05 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 14 Feb 2017 17:10:05 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
Message-ID: <8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>

Hi,

tapply() will work on any object 'X' that has a length and supports
single-bracket subsetting. These objects are sometimes called
"vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
and "[" method, etc... are examples of "vector-like" objects.

So instead of saying

   X: an atomic object, typically a vector.

I think it would be more accurate if the man page was saying something
like

   X: a vector-like object that supports subsetting with `[`, typically
      an atomic vector.

H.

On 02/04/2017 04:17 AM, Tal Galili wrote:
> In the help page of ?tapply it says that the first argument (X) is "an
> atomic object, typically a vector."
>
> However, tapply seems to be able to handle list objects. For example:
>
> ###################
>
> l <- as.list(1:10)
> is.atomic(l) # FALSE
> index <- c(rep(1,5),rep(2,5))
> tapply(l,index,unlist)
>
>> tapply(l,index,unlist)
> $`1`
> [1] 1 2 3 4 5
>
> $`2`
> [1]  6  7  8  9 10
>
>
> ###################
>
> Hence, does it mean a list an atomic object? (which I thought it wasn't) or
> is the help for tapply needs updating?
> (or some third option I'm missing?)
>
> Thanks.
>
>
>
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From bgunter.4567 at gmail.com  Wed Feb 15 02:28:11 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Feb 2017 17:28:11 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
Message-ID: <CAGxFJbTTcrBJPgKPC-mH4CTRWiDOPW9ukRLOZLHAPbhJH7ZNLQ@mail.gmail.com>

Herv?:

Kindly explain this, then:

> l <- as.list(1:10)
> is.atomic(l) # FALSE
[1] FALSE
> index <- c(rep(1,5),rep(2,5))
>
>
> tapply(l,index,unlist)
$`1`
[1] 1 2 3 4 5

$`2`
[1]  6  7  8  9 10

>
> ## But
>
> tapply(l,index, sum)
Error in FUN(X[[i]], ...) : invalid 'type' (list) of argument

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 14, 2017 at 5:10 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Hi,
>
> tapply() will work on any object 'X' that has a length and supports
> single-bracket subsetting. These objects are sometimes called
> "vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
> and "[" method, etc... are examples of "vector-like" objects.
>
> So instead of saying
>
>   X: an atomic object, typically a vector.
>
> I think it would be more accurate if the man page was saying something
> like
>
>   X: a vector-like object that supports subsetting with `[`, typically
>      an atomic vector.
>
> H.
>
> On 02/04/2017 04:17 AM, Tal Galili wrote:
>>
>> In the help page of ?tapply it says that the first argument (X) is "an
>> atomic object, typically a vector."
>>
>> However, tapply seems to be able to handle list objects. For example:
>>
>> ###################
>>
>> l <- as.list(1:10)
>> is.atomic(l) # FALSE
>> index <- c(rep(1,5),rep(2,5))
>> tapply(l,index,unlist)
>>
>>> tapply(l,index,unlist)
>>
>> $`1`
>> [1] 1 2 3 4 5
>>
>> $`2`
>> [1]  6  7  8  9 10
>>
>>
>> ###################
>>
>> Hence, does it mean a list an atomic object? (which I thought it wasn't)
>> or
>> is the help for tapply needs updating?
>> (or some third option I'm missing?)
>>
>> Thanks.
>>
>>
>>
>>
>>
>> ----------------Contact
>> Details:-------------------------------------------------------
>> Contact me: Tal.Galili at gmail.com |
>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>> www.r-statistics.com (English)
>>
>> ----------------------------------------------------------------------------------------------
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Feb 15 02:41:47 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 14 Feb 2017 20:41:47 -0500
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <CAGxFJbTTcrBJPgKPC-mH4CTRWiDOPW9ukRLOZLHAPbhJH7ZNLQ@mail.gmail.com>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
	<CAGxFJbTTcrBJPgKPC-mH4CTRWiDOPW9ukRLOZLHAPbhJH7ZNLQ@mail.gmail.com>
Message-ID: <CAGx1TMCEw6+aCgrKqzu+M=rPZLdW8-p5dEc4_RFguXzWkJ+hRQ@mail.gmail.com>

The problem with Bert's second example is that sum doesn't work on a list.
The tapply worked correctly.

> unlist(l[1:5])
[1] 1 2 3 4 5

> sum(l[1:5])
Error in sum(l[1:5]) : invalid 'type' (list) of argument



On Tue, Feb 14, 2017 at 8:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Herv?:
>
> Kindly explain this, then:
>
>> l <- as.list(1:10)
>> is.atomic(l) # FALSE
> [1] FALSE
>> index <- c(rep(1,5),rep(2,5))
>>
>>
>> tapply(l,index,unlist)
> $`1`
> [1] 1 2 3 4 5
>
> $`2`
> [1]  6  7  8  9 10
>
>>
>> ## But
>>
>> tapply(l,index, sum)
> Error in FUN(X[[i]], ...) : invalid 'type' (list) of argument
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 14, 2017 at 5:10 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>> Hi,
>>
>> tapply() will work on any object 'X' that has a length and supports
>> single-bracket subsetting. These objects are sometimes called
>> "vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
>> and "[" method, etc... are examples of "vector-like" objects.
>>
>> So instead of saying
>>
>>   X: an atomic object, typically a vector.
>>
>> I think it would be more accurate if the man page was saying something
>> like
>>
>>   X: a vector-like object that supports subsetting with `[`, typically
>>      an atomic vector.
>>
>> H.
>>
>> On 02/04/2017 04:17 AM, Tal Galili wrote:
>>>
>>> In the help page of ?tapply it says that the first argument (X) is "an
>>> atomic object, typically a vector."
>>>
>>> However, tapply seems to be able to handle list objects. For example:
>>>
>>> ###################
>>>
>>> l <- as.list(1:10)
>>> is.atomic(l) # FALSE
>>> index <- c(rep(1,5),rep(2,5))
>>> tapply(l,index,unlist)
>>>
>>>> tapply(l,index,unlist)
>>>
>>> $`1`
>>> [1] 1 2 3 4 5
>>>
>>> $`2`
>>> [1]  6  7  8  9 10
>>>
>>>
>>> ###################
>>>
>>> Hence, does it mean a list an atomic object? (which I thought it wasn't)
>>> or
>>> is the help for tapply needs updating?
>>> (or some third option I'm missing?)
>>>
>>> Thanks.
>>>
>>>
>>>
>>>
>>>
>>> ----------------Contact
>>> Details:-------------------------------------------------------
>>> Contact me: Tal.Galili at gmail.com |
>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>>> www.r-statistics.com (English)
>>>
>>> ----------------------------------------------------------------------------------------------
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Wed Feb 15 03:04:01 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 14 Feb 2017 18:04:01 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <CAGx1TMCEw6+aCgrKqzu+M=rPZLdW8-p5dEc4_RFguXzWkJ+hRQ@mail.gmail.com>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
	<CAGxFJbTTcrBJPgKPC-mH4CTRWiDOPW9ukRLOZLHAPbhJH7ZNLQ@mail.gmail.com>
	<CAGx1TMCEw6+aCgrKqzu+M=rPZLdW8-p5dEc4_RFguXzWkJ+hRQ@mail.gmail.com>
Message-ID: <7a28401b-6944-dc23-ac09-e945195a0a91@fredhutch.org>

Right. More precisely the function passed thru the FUN argument must
work on the subsets of X generated internally by tapply(). You can
actually see these subsets by passing the identity function:

   X <- letters[1:10]
   INDEX <- c(rep(1,5),rep(2,5))
   tapply(X, INDEX, FUN=identity)
   # $`1`
   # [1] "a" "b" "c" "d" "e"
   #
   # $`2`
   # [1] "f" "g" "h" "i" "j"

Doing this shows you how tapply() splits the vector-like object X into
a list of subsets. If you replace the identity function with a function
that cannot be applied to these subsets, then you get an error:

   tapply(X, INDEX, FUN=sum)
   # Error in FUN(X[[i]], ...) : invalid 'type' (character) of argument

As you can see, here we get an error even though X is an atomic vector.

H.


On 02/14/2017 05:41 PM, Richard M. Heiberger wrote:
> The problem with Bert's second example is that sum doesn't work on a list.
> The tapply worked correctly.
>
>> unlist(l[1:5])
> [1] 1 2 3 4 5
>
>> sum(l[1:5])
> Error in sum(l[1:5]) : invalid 'type' (list) of argument
>
>
>
> On Tue, Feb 14, 2017 at 8:28 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Herv?:
>>
>> Kindly explain this, then:
>>
>>> l <- as.list(1:10)
>>> is.atomic(l) # FALSE
>> [1] FALSE
>>> index <- c(rep(1,5),rep(2,5))
>>>
>>>
>>> tapply(l,index,unlist)
>> $`1`
>> [1] 1 2 3 4 5
>>
>> $`2`
>> [1]  6  7  8  9 10
>>
>>>
>>> ## But
>>>
>>> tapply(l,index, sum)
>> Error in FUN(X[[i]], ...) : invalid 'type' (list) of argument
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Feb 14, 2017 at 5:10 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>>> Hi,
>>>
>>> tapply() will work on any object 'X' that has a length and supports
>>> single-bracket subsetting. These objects are sometimes called
>>> "vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
>>> and "[" method, etc... are examples of "vector-like" objects.
>>>
>>> So instead of saying
>>>
>>>   X: an atomic object, typically a vector.
>>>
>>> I think it would be more accurate if the man page was saying something
>>> like
>>>
>>>   X: a vector-like object that supports subsetting with `[`, typically
>>>      an atomic vector.
>>>
>>> H.
>>>
>>> On 02/04/2017 04:17 AM, Tal Galili wrote:
>>>>
>>>> In the help page of ?tapply it says that the first argument (X) is "an
>>>> atomic object, typically a vector."
>>>>
>>>> However, tapply seems to be able to handle list objects. For example:
>>>>
>>>> ###################
>>>>
>>>> l <- as.list(1:10)
>>>> is.atomic(l) # FALSE
>>>> index <- c(rep(1,5),rep(2,5))
>>>> tapply(l,index,unlist)
>>>>
>>>>> tapply(l,index,unlist)
>>>>
>>>> $`1`
>>>> [1] 1 2 3 4 5
>>>>
>>>> $`2`
>>>> [1]  6  7  8  9 10
>>>>
>>>>
>>>> ###################
>>>>
>>>> Hence, does it mean a list an atomic object? (which I thought it wasn't)
>>>> or
>>>> is the help for tapply needs updating?
>>>> (or some third option I'm missing?)
>>>>
>>>> Thanks.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ----------------Contact
>>>> Details:-------------------------------------------------------
>>>> Contact me: Tal.Galili at gmail.com |
>>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>>>> www.r-statistics.com (English)
>>>>
>>>> ----------------------------------------------------------------------------------------------
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> --
>>> Herv? Pag?s
>>>
>>> Program in Computational Biology
>>> Division of Public Health Sciences
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, M1-B514
>>> P.O. Box 19024
>>> Seattle, WA 98109-1024
>>>
>>> E-mail: hpages at fredhutch.org
>>> Phone:  (206) 667-5791
>>> Fax:    (206) 667-1319
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From bgunter.4567 at gmail.com  Wed Feb 15 03:39:37 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 14 Feb 2017 18:39:37 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <7a28401b-6944-dc23-ac09-e945195a0a91@fredhutch.org>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
	<CAGxFJbTTcrBJPgKPC-mH4CTRWiDOPW9ukRLOZLHAPbhJH7ZNLQ@mail.gmail.com>
	<CAGx1TMCEw6+aCgrKqzu+M=rPZLdW8-p5dEc4_RFguXzWkJ+hRQ@mail.gmail.com>
	<7a28401b-6944-dc23-ac09-e945195a0a91@fredhutch.org>
Message-ID: <CAGxFJbSweTNYY5x0O_a2U7a8pbp8FFGLWaLbnbjbR_5dROZvyw@mail.gmail.com>

Yes, exactly.

So my point is that this:

  "X: a vector-like object that supports subsetting with `[`, typically
     an atomic vector."

is incorrect, or at least a bit opaque, without further emphasizing
that FUN must accept the result of "[". With atomic vectors, the error
that you produced was obvious, but with lists, I believe not so. I
Appreciate the desire for brevity, but I think clarity should be the
primary goal. Maybe it *is* just me, but I think a few extra words of
explanation here would not go amiss.

But, anyway, thanks for the clarification.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 14, 2017 at 6:04 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Right. More precisely the function passed thru the FUN argument must
> work on the subsets of X generated internally by tapply(). You can
> actually see these subsets by passing the identity function:
>
>   X <- letters[1:10]
>   INDEX <- c(rep(1,5),rep(2,5))
>   tapply(X, INDEX, FUN=identity)
>   # $`1`
>   # [1] "a" "b" "c" "d" "e"
>   #
>   # $`2`
>   # [1] "f" "g" "h" "i" "j"
>
> Doing this shows you how tapply() splits the vector-like object X into
> a list of subsets. If you replace the identity function with a function
> that cannot be applied to these subsets, then you get an error:
>
>   tapply(X, INDEX, FUN=sum)
>   # Error in FUN(X[[i]], ...) : invalid 'type' (character) of argument
>
> As you can see, here we get an error even though X is an atomic vector.
>
> H.
>
>
>
> On 02/14/2017 05:41 PM, Richard M. Heiberger wrote:
>>
>> The problem with Bert's second example is that sum doesn't work on a list.
>> The tapply worked correctly.
>>
>>> unlist(l[1:5])
>>
>> [1] 1 2 3 4 5
>>
>>> sum(l[1:5])
>>
>> Error in sum(l[1:5]) : invalid 'type' (list) of argument
>>
>>
>>
>> On Tue, Feb 14, 2017 at 8:28 PM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>>
>>> Herv?:
>>>
>>> Kindly explain this, then:
>>>
>>>> l <- as.list(1:10)
>>>> is.atomic(l) # FALSE
>>>
>>> [1] FALSE
>>>>
>>>> index <- c(rep(1,5),rep(2,5))
>>>>
>>>>
>>>> tapply(l,index,unlist)
>>>
>>> $`1`
>>> [1] 1 2 3 4 5
>>>
>>> $`2`
>>> [1]  6  7  8  9 10
>>>
>>>>
>>>> ## But
>>>>
>>>> tapply(l,index, sum)
>>>
>>> Error in FUN(X[[i]], ...) : invalid 'type' (list) of argument
>>>
>>> Cheers,
>>> Bert
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Tue, Feb 14, 2017 at 5:10 PM, Herv? Pag?s <hpages at fredhutch.org>
>>> wrote:
>>>>
>>>> Hi,
>>>>
>>>> tapply() will work on any object 'X' that has a length and supports
>>>> single-bracket subsetting. These objects are sometimes called
>>>> "vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
>>>> and "[" method, etc... are examples of "vector-like" objects.
>>>>
>>>> So instead of saying
>>>>
>>>>   X: an atomic object, typically a vector.
>>>>
>>>> I think it would be more accurate if the man page was saying something
>>>> like
>>>>
>>>>   X: a vector-like object that supports subsetting with `[`, typically
>>>>      an atomic vector.
>>>>
>>>> H.
>>>>
>>>> On 02/04/2017 04:17 AM, Tal Galili wrote:
>>>>>
>>>>>
>>>>> In the help page of ?tapply it says that the first argument (X) is "an
>>>>> atomic object, typically a vector."
>>>>>
>>>>> However, tapply seems to be able to handle list objects. For example:
>>>>>
>>>>> ###################
>>>>>
>>>>> l <- as.list(1:10)
>>>>> is.atomic(l) # FALSE
>>>>> index <- c(rep(1,5),rep(2,5))
>>>>> tapply(l,index,unlist)
>>>>>
>>>>>> tapply(l,index,unlist)
>>>>>
>>>>>
>>>>> $`1`
>>>>> [1] 1 2 3 4 5
>>>>>
>>>>> $`2`
>>>>> [1]  6  7  8  9 10
>>>>>
>>>>>
>>>>> ###################
>>>>>
>>>>> Hence, does it mean a list an atomic object? (which I thought it
>>>>> wasn't)
>>>>> or
>>>>> is the help for tapply needs updating?
>>>>> (or some third option I'm missing?)
>>>>>
>>>>> Thanks.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ----------------Contact
>>>>> Details:-------------------------------------------------------
>>>>> Contact me: Tal.Galili at gmail.com |
>>>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew)
>>>>> |
>>>>> www.r-statistics.com (English)
>>>>>
>>>>>
>>>>> ----------------------------------------------------------------------------------------------
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> --
>>>> Herv? Pag?s
>>>>
>>>> Program in Computational Biology
>>>> Division of Public Health Sciences
>>>> Fred Hutchinson Cancer Research Center
>>>> 1100 Fairview Ave. N, M1-B514
>>>> P.O. Box 19024
>>>> Seattle, WA 98109-1024
>>>>
>>>> E-mail: hpages at fredhutch.org
>>>> Phone:  (206) 667-5791
>>>> Fax:    (206) 667-1319
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From hpages at fredhutch.org  Wed Feb 15 07:07:25 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 14 Feb 2017 22:07:25 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <CAGxFJbSweTNYY5x0O_a2U7a8pbp8FFGLWaLbnbjbR_5dROZvyw@mail.gmail.com>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
	<CAGxFJbTTcrBJPgKPC-mH4CTRWiDOPW9ukRLOZLHAPbhJH7ZNLQ@mail.gmail.com>
	<CAGx1TMCEw6+aCgrKqzu+M=rPZLdW8-p5dEc4_RFguXzWkJ+hRQ@mail.gmail.com>
	<7a28401b-6944-dc23-ac09-e945195a0a91@fredhutch.org>
	<CAGxFJbSweTNYY5x0O_a2U7a8pbp8FFGLWaLbnbjbR_5dROZvyw@mail.gmail.com>
Message-ID: <fdcb8429-17b4-1838-3270-4ba8d4858ad4@fredhutch.org>

On 02/14/2017 06:39 PM, Bert Gunter wrote:
> Yes, exactly.
>
> So my point is that this:
>
>   "X: a vector-like object that supports subsetting with `[`, typically
>      an atomic vector."
>
> is incorrect, or at least a bit opaque, without further emphasizing
> that FUN must accept the result of "[".

Maybe this kind of details belong to the description of the FUN
argument. However please note that the man page for lapply() or the
other *apply() functions don't emphasize the fact that the supplied
FUN must be a function that accepts the things it applies to either,
and nobody seems to make a big deal of it. Maybe because it's obvious?

> With atomic vectors, the error
> that you produced was obvious, but with lists, I believe not so.

Well, it's the same error. Maybe what's not obvious is that in both
cases the error is coming from sum(), not from tapply() itself.
sum() is complaining that it receives something that it doesn't
know how to handle. The clue is in how the error message starts:

   Error in FUN(X[[i]], ...):

Maybe one could argue this is a little bit cryptic. Note the difference
when the error is coming from tapply() itself:

   > X <- letters[1:9]
   > INDEX <- c(rep(1,5),rep(2,5))
   > tapply(X, INDEX, FUN=identity)
   Error in tapply(X, INDEX, FUN = identity) :
     arguments must have same length

H.

> I Appreciate the desire for brevity, but I think clarity should be the
> primary goal. Maybe it *is* just me, but I think a few extra words of
> explanation here would not go amiss.
>
> But, anyway, thanks for the clarification.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 14, 2017 at 6:04 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>> Right. More precisely the function passed thru the FUN argument must
>> work on the subsets of X generated internally by tapply(). You can
>> actually see these subsets by passing the identity function:
>>
>>   X <- letters[1:10]
>>   INDEX <- c(rep(1,5),rep(2,5))
>>   tapply(X, INDEX, FUN=identity)
>>   # $`1`
>>   # [1] "a" "b" "c" "d" "e"
>>   #
>>   # $`2`
>>   # [1] "f" "g" "h" "i" "j"
>>
>> Doing this shows you how tapply() splits the vector-like object X into
>> a list of subsets. If you replace the identity function with a function
>> that cannot be applied to these subsets, then you get an error:
>>
>>   tapply(X, INDEX, FUN=sum)
>>   # Error in FUN(X[[i]], ...) : invalid 'type' (character) of argument
>>
>> As you can see, here we get an error even though X is an atomic vector.
>>
>> H.
>>
>>
>>
>> On 02/14/2017 05:41 PM, Richard M. Heiberger wrote:
>>>
>>> The problem with Bert's second example is that sum doesn't work on a list.
>>> The tapply worked correctly.
>>>
>>>> unlist(l[1:5])
>>>
>>> [1] 1 2 3 4 5
>>>
>>>> sum(l[1:5])
>>>
>>> Error in sum(l[1:5]) : invalid 'type' (list) of argument
>>>
>>>
>>>
>>> On Tue, Feb 14, 2017 at 8:28 PM, Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>>
>>>> Herv?:
>>>>
>>>> Kindly explain this, then:
>>>>
>>>>> l <- as.list(1:10)
>>>>> is.atomic(l) # FALSE
>>>>
>>>> [1] FALSE
>>>>>
>>>>> index <- c(rep(1,5),rep(2,5))
>>>>>
>>>>>
>>>>> tapply(l,index,unlist)
>>>>
>>>> $`1`
>>>> [1] 1 2 3 4 5
>>>>
>>>> $`2`
>>>> [1]  6  7  8  9 10
>>>>
>>>>>
>>>>> ## But
>>>>>
>>>>> tapply(l,index, sum)
>>>>
>>>> Error in FUN(X[[i]], ...) : invalid 'type' (list) of argument
>>>>
>>>> Cheers,
>>>> Bert
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Tue, Feb 14, 2017 at 5:10 PM, Herv? Pag?s <hpages at fredhutch.org>
>>>> wrote:
>>>>>
>>>>> Hi,
>>>>>
>>>>> tapply() will work on any object 'X' that has a length and supports
>>>>> single-bracket subsetting. These objects are sometimes called
>>>>> "vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
>>>>> and "[" method, etc... are examples of "vector-like" objects.
>>>>>
>>>>> So instead of saying
>>>>>
>>>>>   X: an atomic object, typically a vector.
>>>>>
>>>>> I think it would be more accurate if the man page was saying something
>>>>> like
>>>>>
>>>>>   X: a vector-like object that supports subsetting with `[`, typically
>>>>>      an atomic vector.
>>>>>
>>>>> H.
>>>>>
>>>>> On 02/04/2017 04:17 AM, Tal Galili wrote:
>>>>>>
>>>>>>
>>>>>> In the help page of ?tapply it says that the first argument (X) is "an
>>>>>> atomic object, typically a vector."
>>>>>>
>>>>>> However, tapply seems to be able to handle list objects. For example:
>>>>>>
>>>>>> ###################
>>>>>>
>>>>>> l <- as.list(1:10)
>>>>>> is.atomic(l) # FALSE
>>>>>> index <- c(rep(1,5),rep(2,5))
>>>>>> tapply(l,index,unlist)
>>>>>>
>>>>>>> tapply(l,index,unlist)
>>>>>>
>>>>>>
>>>>>> $`1`
>>>>>> [1] 1 2 3 4 5
>>>>>>
>>>>>> $`2`
>>>>>> [1]  6  7  8  9 10
>>>>>>
>>>>>>
>>>>>> ###################
>>>>>>
>>>>>> Hence, does it mean a list an atomic object? (which I thought it
>>>>>> wasn't)
>>>>>> or
>>>>>> is the help for tapply needs updating?
>>>>>> (or some third option I'm missing?)
>>>>>>
>>>>>> Thanks.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ----------------Contact
>>>>>> Details:-------------------------------------------------------
>>>>>> Contact me: Tal.Galili at gmail.com |
>>>>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew)
>>>>>> |
>>>>>> www.r-statistics.com (English)
>>>>>>
>>>>>>
>>>>>> ----------------------------------------------------------------------------------------------
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>> --
>>>>> Herv? Pag?s
>>>>>
>>>>> Program in Computational Biology
>>>>> Division of Public Health Sciences
>>>>> Fred Hutchinson Cancer Research Center
>>>>> 1100 Fairview Ave. N, M1-B514
>>>>> P.O. Box 19024
>>>>> Seattle, WA 98109-1024
>>>>>
>>>>> E-mail: hpages at fredhutch.org
>>>>> Phone:  (206) 667-5791
>>>>> Fax:    (206) 667-1319
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From tr206 at kent.ac.uk  Wed Feb 15 08:56:51 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 15 Feb 2017 07:56:51 +0000
Subject: [R] coeftest() R squared
In-Reply-To: <9848df7a6b24413c915c29b8ec9db2d8@ex13-live-mbn1.ad.kent.ac.uk>
References: <9848df7a6b24413c915c29b8ec9db2d8@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <1487145411207.89850@kent.ac.uk>


Dear all,
I want to run a regression using lm() with Newey West corrected standard errors.

This is the code

Reg<-lm(g~sent + liquidity + Cape, data=dataUsa)
CoefNW<-coeftest(Reg, vcov.=NeweyWest)
CoefNW

In contrast to summary(Reg) the output of CoefNW neither returns the adjusted R squared nor the F-statistic. How can I obtain the R squared for coeftest? Alternatively, how do I get robust standard errors and the R squared of the regression?
Thanks for your help.


From Achim.Zeileis at uibk.ac.at  Wed Feb 15 09:54:52 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 15 Feb 2017 09:54:52 +0100 (CET)
Subject: [R] coeftest() R squared
In-Reply-To: <1487145411207.89850@kent.ac.uk>
References: <9848df7a6b24413c915c29b8ec9db2d8@ex13-live-mbn1.ad.kent.ac.uk>
	<1487145411207.89850@kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1702150952330.19948@paninaro>

On Wed, 15 Feb 2017, T.Riedle wrote:

>
> Dear all,
> I want to run a regression using lm() with Newey West corrected standard errors.
>
> This is the code
>
> Reg<-lm(g~sent + liquidity + Cape, data=dataUsa)
> CoefNW<-coeftest(Reg, vcov.=NeweyWest)
> CoefNW
>
> In contrast to summary(Reg) the output of CoefNW neither returns the 
> adjusted R squared nor the F-statistic. How can I obtain the R squared 
> for coeftest? Alternatively, how do I get robust standard errors and the 
> R squared of the regression?

The adjusted analogue to the F statistic can be obtained by
waldtest(Reg, vcov = NeweyWest)

For the R-squared there is no appropriate quantity with analogous
properties. Hence nothing is provided in the package.

> Thanks for your help.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From careyshan at gmail.com  Wed Feb 15 10:02:10 2017
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 15 Feb 2017 09:02:10 +0000
Subject: [R] Create gif from series of png files
In-Reply-To: <CAGxFJbTOp-kO72Z77gyMVy_4SDzzeWcE6b1WTTDtnDogHA--=g@mail.gmail.com>
References: <CA+jRDxCuY6Y9pDD-uU6Ji=iU3rLojrZj90SGb7p7QRgUW_5Fuw@mail.gmail.com>
	<CAKVAULNncSMdH1DrMKo8MC2=1gEhg2-U6PKbBmw4d+AB_AXzVQ@mail.gmail.com>
	<CAGxFJbTOp-kO72Z77gyMVy_4SDzzeWcE6b1WTTDtnDogHA--=g@mail.gmail.com>
Message-ID: <CA+jRDxDF5L=NzAMRGJNOXv7mcxeX2NqqEwBe0zq-ShSSUj+p5Q@mail.gmail.com>

For those interested, I figured out a way using "convert" on the linux
command line.

Thanks

On Tue, Feb 14, 2017 at 6:02 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Ulrik:
>
> Sheepishly Nitpicking (only because you are a regular and wise R-help
> contibutor):
>
> gganimate is not a library, it's a package.
>
> No need to reply.
>
> Best,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Feb 14, 2017 at 3:33 AM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
> > Hi Shane,
> >
> > Wrong forum. This might be what you are looking for
> >
> > ffmpeg -i %03d.png output.gif
> >
> > Or use the library gganimate.
> >
> > Best
> > Ulrik
> >
> > Shane Carey <careyshan at gmail.com> schrieb am Di., 14. Feb. 2017, 12:08:
> >
> >> Hi,
> >>
> >> I have many png files that I would like to stitch together, in order to
> >> make a gif file.
> >>
> >> Any ideas how I would do this?
> >>
> >> Thanks
> >>
> >> --
> >> Le gach dea ghui,
> >> Shane
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Le gach dea ghui,
Shane

	[[alternative HTML version deleted]]


From g.wieteska at yahoo.ie  Wed Feb 15 11:32:20 2017
From: g.wieteska at yahoo.ie (Malgorzata Wieteska)
Date: Wed, 15 Feb 2017 10:32:20 +0000 (UTC)
Subject: [R] non-linear optimisation ODE models
References: <264407025.8366931.1487154740852.ref@mail.yahoo.com>
Message-ID: <264407025.8366931.1487154740852@mail.yahoo.com>

Hello,
I'm new to R, so sorry for this question. I found a piece of code on stack overflow community, title: r-parameter and initial conditions fitting ODE models with nls.lm.
I've tried to implement a change suggested, but I get an error: Error in unname(myparms[4], B = 0, C = 0) :?? unused arguments (B = 0, C = 0)
I'll appreciate any hint.
Malgosia

#set working directorysetwd("~/R/wkspace")#load librarieslibrary(ggplot2)library(reshape2)library(deSolve)library(minpack.lm)time=c(0,0.263,0.526,0.789,1.053,1.316,1.579,1.842,2.105,2.368,2.632,2.895,3.158,3.421,3.684,3.947,4.211,4.474,4.737,5)ca=c(0.957,0.557,0.342,0.224,0.123,0.079,0.035,0.029,0.025,0.017,-0.002,0.009,-0.023,0.006,0.016,0.014,-0.009,-0.03,0.004,-0.024)cb=c(-0.031,0.33,0.512,0.499,0.428,0.396,0.303,0.287,0.221,0.148,0.182,0.116,0.079,0.078,0.059,0.036,0.014,0.036,0.036,0.028)cc=c(-0.015,0.044,0.156,0.31,0.454,0.556,0.651,0.658,0.75,0.854,0.845,0.893,0.942,0.899,0.942,0.991,0.988,0.941,0.971,0.985)df<-data.frame(time,ca,cb,cc)dfnames(df)=c("time","ca","cb","cc")#plot datatmp=melt(df,id.vars=c("time"),variable.name="species",value.name="conc")ggplot(data=tmp,aes(x=time,y=conc,color=species))+geom_point(size=3)#rate functionrxnrate=function(t,c,parms){? #rate constant passed through a list called? k1=parms$k1? k2=parms$k2? k3=parms$k3? #c is the concentration of species? #derivatives dc/dt are computed below? r=rep(0,length(c))? r[1]=-k1*c["A"] #dcA/dt? r[2]=k1*c["A"]-k2*c["B"]+k3*c["C"] #dcB/dt? r[3]=k2*c["B"]-k3*c["C"] #dcC/dt? return(list(r))}# predicted concentration for a given parametercinit=c(A=1,B=0,C=0)t=df$timeparms=list(k1=2, k2=1, k3=3)out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))head(out)
ssq=function(myparms){? #initial concentration? cinit=c(A=myparms[4],B=0,C=0)? cinit=c(A=unname(myparms[4],B=0,C=0))? print(cinit)? #time points for which conc is reported? #include the points where data is available? t=c(seq(0,5,0.1),df$time)? t=sort(unique(t))? #parameters from the parameters estimation? k1=myparms[1]? k2=myparms[2]? k3=myparms[3]? #solve ODE for a given set of parameters? out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))? #Filter data that contains time points? outdf=data.frame(out)? outdf=outdf[outdf$time%in% df$time,]? #Evaluate predicted vs experimental residual? preddf=melt(outdf,id.var="time",variable.name="species",value.name="conc")? expdf=melt(df,id.var="time",variable.name="species",value.name="conc")? ssqres=preddf$conc-expdf$conc? return(ssqres)}# parameter fitting using levenberg marquart#initial guess for parametersmyparms=c(k1=0.5,k2=0.5,k3=3,1)cinit=c(A=unname(myparms[4],B=0,C=0))print(cinit)#fittingfitval=nls.lm(par=parms,fn=ssq)#summary of fitsummary(fitval)
	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Wed Feb 15 11:44:15 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 15 Feb 2017 11:44:15 +0100
Subject: [R] non-linear optimisation ODE models
In-Reply-To: <264407025.8366931.1487154740852@mail.yahoo.com>
References: <264407025.8366931.1487154740852.ref@mail.yahoo.com>
	<264407025.8366931.1487154740852@mail.yahoo.com>
Message-ID: <1A288236-78CC-4223-A0AC-DB42E65C2103@xs4all.nl>


> On 15 Feb 2017, at 11:32, Malgorzata Wieteska via R-help <r-help at r-project.org> wrote:
> 
> Hello,
> I'm new to R, so sorry for this question. I found a piece of code on stack overflow community, title: r-parameter and initial conditions fitting ODE models with nls.lm.
> I've tried to implement a change suggested, but I get an error: Error in unname(myparms[4], B = 0, C = 0) :   unused arguments (B = 0, C = 0)
> I'll appreciate any hint.
> Malgosia
> 
> #set working directorysetwd("~/R/wkspace")#load librarieslibrary(ggplot2)library(reshape2)library(deSolve)library(minpack.lm)time=c(0,0.263,0.526,0.789,1.053,1.316,1.579,1.842,2.105,2.368,2.632,2.895,3.158,3.421,3.684,3.947,4.211,4.474,4.737,5)ca=c(0.957,0.557,0.342,0.224,0.123,0.079,0.035,0.029,0.025,0.017,-0.002,0.009,-0.023,0.006,0.016,0.014,-0.009,-0.03,0.004,-0.024)cb=c(-0.031,0.33,0.512,0.499,0.428,0.396,0.303,0.287,0.221,0.148,0.182,0.116,0.079,0.078,0.059,0.036,0.014,0.036,0.036,0.028)cc=c(-0.015,0.044,0.156,0.31,0.454,0.556,0.651,0.658,0.75,0.854,0.845,0.893,0.942,0.899,0.942,0.991,0.988,0.941,0.971,0.985)df<-data.frame(time,ca,cb,cc)dfnames(df)=c("time","ca","cb","cc")#plot datatmp=melt(df,id.vars=c("time"),variable.name="species",value.name="conc")ggplot(data=tmp,aes(x=time,y=conc,color=species))+geom_point(size=3)#rate functionrxnrate=function(t,c,parms){  #rate constant passed through a list called  k1=parms$k1  k2=parms$k2  k3=parms$k3  #c is the concentration of species  #derivatives dc/dt are computed below  r=rep(0,length(c))  r[1]=-k1*c["A"] #dcA/dt  r[2]=k1*c["A"]-k2*c["B"]+k3*c["C"] #dcB/dt  r[3]=k2*c["B"]-k3*c["C"] #dcC/dt  return(list(r))}# predicted concentration for a given parametercinit=c(A=1,B=0,C=0)t=df$timeparms=list(k1=2, k2=1, k3=3)out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))head(out)
> ssq=function(myparms){  #initial concentration  cinit=c(A=myparms[4],B=0,C=0)  cinit=c(A=unname(myparms[4],B=0,C=0))  print(cinit)  #time points for which conc is reported  #include the points where data is available  t=c(seq(0,5,0.1),df$time)  t=sort(unique(t))  #parameters from the parameters estimation  k1=myparms[1]  k2=myparms[2]  k3=myparms[3]  #solve ODE for a given set of parameters  out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))  #Filter data that contains time points  outdf=data.frame(out)  outdf=outdf[outdf$time%in% df$time,]  #Evaluate predicted vs experimental residual  preddf=melt(outdf,id.var="time",variable.name="species",value.name="conc")  expdf=melt(df,id.var="time",variable.name="species",value.name="conc")  ssqres=preddf$conc-expdf$conc  return(ssqres)}# parameter fitting using levenberg marquart#initial guess for parametersmyparms=c(k1=0.5,k2=0.5,k3=3,1)cinit=c(A=unname(myparms[4],B=0,C=0))print(cinit)#fittingfitval=nls.lm(par=parms,fn=ssq)#summary of fitsummary(fitval)


Totally unreadable code because you did not read the Posting Guide.

> 	[[alternative HTML version deleted]]


Do not post in HTML.

Berend Hasselman

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw1958 at gmail.com  Wed Feb 15 13:49:50 2017
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Wed, 15 Feb 2017 07:49:50 -0500
Subject: [R] Works outside but not inside!
Message-ID: <C680651F-31F6-43BD-A5CE-30307DBD793A@gmail.com>

Folks,
The following function works like a charm!

> #Amortization for multiple rows
> createAmorts<-function(ams, numPer, term) {
>   fctrs<-rep(1:term, each = numPer)
>   
>   oneRow<-function(am,  fac){      
>     tdf<-data.frame(ams = c(am), yrs=fac)      
>     agg<-aggregate(ams ~ yrs, data = tdf, sum)     
>     agg$ams<-1-cumsum(agg$ams)     
>     agg     
>   }     
>   data.frame(id = rep(1:nrow(ams), each = term),
>              do.call(rbind, apply(ams, 1, oneRow, fctrs)))
> }

But when I run the function inside some other code:
> retrieveSSdata<-function(inputPath) {
>   iList<-list()
>   theWb<-loadWorkbook(inputPath)
>   
>   # Set up the amorts using inputs and term and frequency
>   theTerm<-readNamedRegion(theWb, "Term", useCachedValues = TRUE, header = FALSE)
>   theFreq<-readNamedRegion(theWb, "freq", useCachedValues = TRUE, header = FALSE)
>   allAmorts<-readNamedRegion(theWb, "allAmorts", useCachedValues = TRUE, header = FALSE)

>   theAmorts<-createAmorts(allAmorts, 12/theFreq, theTerm*theFreq)

>   iList[["amort"]]<-theAmorts
>   iList[["PremAttach"]]<-readNamedRegion(theWb, "amPremAttach", useCachedValues = TRUE)
>   #
>   
>   iList
> }


> Note that in the above code everything seems to work fine except for the ?createAmorts" code.



I have the following packages loaded:
require(XLConnect)
require(plyr)
require(sm)
require(fOptions)
require(fCopulae)

I have spent a lot of time on this to no avail.

Any help would be appreciated.

Best,
KW


From sarah.goslee at gmail.com  Wed Feb 15 14:10:29 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 15 Feb 2017 13:10:29 +0000
Subject: [R] Works outside but not inside!
In-Reply-To: <C680651F-31F6-43BD-A5CE-30307DBD793A@gmail.com>
References: <C680651F-31F6-43BD-A5CE-30307DBD793A@gmail.com>
Message-ID: <CAM_vjum6LaEF4ow+KdEP445i2=PcpyrzhDjdjTG2HT+PXg+uOg@mail.gmail.com>

Well, what happens? "Doesn't work" covers a lot of ground, and you don't
provide a reproducible example.

Also, why all the > at the beginning PDF lines? Your R prompts shouldn't
look like that when entering a function, and they make it impossible to
just cut and paste the code. Not that we have any data to try it on,
either.

However, I'm going to take a wild guess that you meant to call the argument
to the first function am rather than ams because you use an object named
the former in the function, ands  not the latter. I'm further going to
guess that you have an object named am in your workspace, so the function
is running from the console because it is silently using that object. But
from another function it can't find it.

So, your first function is not actually correct, and starting from a clean
session would have shown you that, as would the process of making a
reproducible example.

Sarah

On Wed, Feb 15, 2017 at 7:51 AM Keith S Weintraub <kw1958 at gmail.com> wrote:

> Folks,
> The following function works like a charm!
>
> > #Amortization for multiple rows
> > createAmorts<-function(ams, numPer, term) {
> >   fctrs<-rep(1:term, each = numPer)
> >
> >   oneRow<-function(am,  fac){
> >     tdf<-data.frame(ams = c(am), yrs=fac)
> >     agg<-aggregate(ams ~ yrs, data = tdf, sum)
> >     agg$ams<-1-cumsum(agg$ams)
> >     agg
> >   }
> >   data.frame(id = rep(1:nrow(ams), each = term),
> >              do.call(rbind, apply(ams, 1, oneRow, fctrs)))
> > }
>
> But when I run the function inside some other code:
> > retrieveSSdata<-function(inputPath) {
> >   iList<-list()
> >   theWb<-loadWorkbook(inputPath)
> >
> >   # Set up the amorts using inputs and term and frequency
> >   theTerm<-readNamedRegion(theWb, "Term", useCachedValues = TRUE, header
> = FALSE)
> >   theFreq<-readNamedRegion(theWb, "freq", useCachedValues = TRUE, header
> = FALSE)
> >   allAmorts<-readNamedRegion(theWb, "allAmorts", useCachedValues = TRUE,
> header = FALSE)
>
> >   theAmorts<-createAmorts(allAmorts, 12/theFreq, theTerm*theFreq)
>
> >   iList[["amort"]]<-theAmorts
> >   iList[["PremAttach"]]<-readNamedRegion(theWb, "amPremAttach",
> useCachedValues = TRUE)
> >   #
> >
> >   iList
> > }
>
>
> > Note that in the above code everything seems to work fine except for the
> ?createAmorts" code.
>
>
>
> I have the following packages loaded:
> require(XLConnect)
> require(plyr)
> require(sm)
> require(fOptions)
> require(fCopulae)
>
> I have spent a lot of time on this to no avail.
>
> Any help would be appreciated.
>
> Best,
> KW
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From bradyrichter at gmail.com  Wed Feb 15 00:27:10 2017
From: bradyrichter at gmail.com (Brady Richter)
Date: Tue, 14 Feb 2017 18:27:10 -0500
Subject: [R] New R user- Simple optimization problem
Message-ID: <02c001d28719$dd7f5f10$987e1d30$@gmail.com>

Hi I am learning R currently and I having trouble structuring a program.

 

Data consists of 1 data frame with a day of the week, a class list, and a
utility score.

 

Date                   Class                   Utility

 

Monday              Chem                  85

Monday              Physics               75

Tuesday              Chem                  95

Tuesday              Math                  93

Tuesday              History               87

Tuesday              Language           86

 

And so on through Friday.

 

I want to maximize total utility (the sum) given 2 constraints:

 

1.	The number of classes you must take each day is fixed. (Must take 1
class on Monday, 2 on Tuesday, 1 on Wednesday etc.)
2.	No repeats- You can only take any given class zero or one time.  

 

Any help to go about this would be appreciated.

 

Thank you.

 

bhr

 

 


	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Wed Feb 15 20:32:59 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 15 Feb 2017 13:32:59 -0600
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
Message-ID: <CABdHhvFiJdOX7r-ATp=+d_V5v49_a0KLKht4PPY-R5OnGv4Ttw@mail.gmail.com>

It seems like this should be consistent with split(), since that's
what actually powers the behaviour.

Reading the description for split leads to this rather interesting example:

tapply(mtcars, 1:11, I)

Hadley

On Tue, Feb 14, 2017 at 7:10 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
> Hi,
>
> tapply() will work on any object 'X' that has a length and supports
> single-bracket subsetting. These objects are sometimes called
> "vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
> and "[" method, etc... are examples of "vector-like" objects.
>
> So instead of saying
>
>   X: an atomic object, typically a vector.
>
> I think it would be more accurate if the man page was saying something
> like
>
>   X: a vector-like object that supports subsetting with `[`, typically
>      an atomic vector.
>
> H.
>
>
> On 02/04/2017 04:17 AM, Tal Galili wrote:
>>
>> In the help page of ?tapply it says that the first argument (X) is "an
>> atomic object, typically a vector."
>>
>> However, tapply seems to be able to handle list objects. For example:
>>
>> ###################
>>
>> l <- as.list(1:10)
>> is.atomic(l) # FALSE
>> index <- c(rep(1,5),rep(2,5))
>> tapply(l,index,unlist)
>>
>>> tapply(l,index,unlist)
>>
>> $`1`
>> [1] 1 2 3 4 5
>>
>> $`2`
>> [1]  6  7  8  9 10
>>
>>
>> ###################
>>
>> Hence, does it mean a list an atomic object? (which I thought it wasn't)
>> or
>> is the help for tapply needs updating?
>> (or some third option I'm missing?)
>>
>> Thanks.
>>
>>
>>
>>
>>
>> ----------------Contact
>> Details:-------------------------------------------------------
>> Contact me: Tal.Galili at gmail.com |
>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>> www.r-statistics.com (English)
>>
>> ----------------------------------------------------------------------------------------------
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From drjimlemon at gmail.com  Wed Feb 15 22:43:10 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 16 Feb 2017 08:43:10 +1100
Subject: [R] non-linear optimisation ODE models
In-Reply-To: <1A288236-78CC-4223-A0AC-DB42E65C2103@xs4all.nl>
References: <264407025.8366931.1487154740852.ref@mail.yahoo.com>
	<264407025.8366931.1487154740852@mail.yahoo.com>
	<1A288236-78CC-4223-A0AC-DB42E65C2103@xs4all.nl>
Message-ID: <CA+8X3fXg4nw+0DqrCQe9HpmT=XLQFnhe-jzQXVNFvCwfc2z5Ag@mail.gmail.com>

Hi Malgorzata,
The function "rxnrate" seems to want three values in a list with the
names "k1", "k2" and "k3". If you are passing something with different
names, it is probably going to complain, so the names "A", "B" and "C"
may be your problem. I can't run the example, so this is a guess.

Jim


> On 15 Feb 2017, at 11:32, Malgorzata Wieteska via R-help <r-help at r-project.org> wrote:
>
> Hello,
> I'm new to R, so sorry for this question. I found a piece of code on stack overflow community, title: r-parameter and initial conditions fitting ODE models with nls.lm.
> I've tried to implement a change suggested, but I get an error: Error in unname(myparms[4], B = 0, C = 0) :   unused arguments (B = 0, C = 0)
> I'll appreciate any hint.
> Malgosia
>
> #set working directorysetwd("~/R/wkspace")#load librarieslibrary(ggplot2)library(reshape2)library(deSolve)library(minpack.lm)time=c(0,0.263,0.526,0.789,1.053,1.316,1.579,1.842,2.105,2.368,2.632,2.895,3.158,3.421,3.684,3.947,4.211,4.474,4.737,5)ca=c(0.957,0.557,0.342,0.224,0.123,0.079,0.035,0.029,0.025,0.017,-0.002,0.009,-0.023,0.006,0.016,0.014,-0.009,-0.03,0.004,-0.024)cb=c(-0.031,0.33,0.512,0.499,0.428,0.396,0.303,0.287,0.221,0.148,0.182,0.116,0.079,0.078,0.059,0.036,0.014,0.036,0.036,0.028)cc=c(-0.015,0.044,0.156,0.31,0.454,0.556,0.651,0.658,0.75,0.854,0.845,0.893,0.942,0.899,0.942,0.991,0.988,0.941,0.971,0.985)df<-data.frame(time,ca,cb,cc)dfnames(df)=c("time","ca","cb","cc")#plot datatmp=melt(df,id.vars=c("time"),variable.name="species",value.name="conc")ggplot(data=tmp,aes(x=time,y=conc,color=species))+geom_point(size=3)#rate functionrxnrate=function(t,c,parms){  #rate constant passed through a list called  k1=parms$k1  k2=parms$k2  k3=parms$k3  #c is the concentratio!
>  n of species  #derivatives dc/dt are computed below  r=rep(0,length(c))  r[1]=-k1*c["A"] #dcA/dt  r[2]=k1*c["A"]-k2*c["B"]+k3*c["C"] #dcB/dt  r[3]=k2*c["B"]-k3*c["C"] #dcC/dt  return(list(r))}# predicted concentration for a given parametercinit=c(A=1,B=0,C=0)t=df$timeparms=list(k1=2, k2=1, k3=3)out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))head(out)
>> ssq=function(myparms){  #initial concentration  cinit=c(A=myparms[4],B=0,C=0)  cinit=c(A=unname(myparms[4],B=0,C=0))  print(cinit)  #time points for which conc is reported  #include the points where data is available  t=c(seq(0,5,0.1),df$time)  t=sort(unique(t))  #parameters from the parameters estimation  k1=myparms[1]  k2=myparms[2]  k3=myparms[3]  #solve ODE for a given set of parameters  out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))  #Filter data that contains time points  outdf=data.frame(out)  outdf=outdf[outdf$time%in% df$time,]  #Evaluate predicted vs experimental residual  preddf=melt(outdf,id.var="time",variable.name="species",value.name="conc")  expdf=melt(df,id.var="time",variable.name="species",value.name="conc")  ssqres=preddf$conc-expdf$conc  return(ssqres)}# parameter fitting using levenberg marquart#initial guess for parametersmyparms=c(k1=0.5,k2=0.5,k3=3,1)cinit=c(A=unname(myparms[4],B=0,C=0))print(cinit)#fittingfitval=nls.lm(par=par!
>  ms,fn=ssq)#summary of fitsummary(fitval)
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hpages at fredhutch.org  Thu Feb 16 00:02:50 2017
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 15 Feb 2017 15:02:50 -0800
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <CABdHhvFiJdOX7r-ATp=+d_V5v49_a0KLKht4PPY-R5OnGv4Ttw@mail.gmail.com>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
	<CABdHhvFiJdOX7r-ATp=+d_V5v49_a0KLKht4PPY-R5OnGv4Ttw@mail.gmail.com>
Message-ID: <778dd995-98bb-e5f3-db18-571796fef356@fredhutch.org>

You could also call this "interesting example" a bug.

Clearly not enough code reuse in the implementation of tapply().
Instead of the current 25 lines of code, it could be a simple
wrapper around split() and sapply() e.g.. something like:

   tapply2 <- function(X, INDEX, FUN=NULL, ..., simplify=TRUE)
   {
     f <- make_factor_from_INDEX(INDEX)  # same as tapply(INDEX=INDEX, 
FUN=NULL)
     sapply(split(X, f), FUN, ..., simplify=simplify, USE.NAMES=FALSE)
   }

and then be guaranteed to behave consistently with split() and
sapply(). Also the make_factor_from_INDEX() step maybe could be
shared with what aggregate.data.frame() does internally with its
'by' argument.

Still a mystery to me why the power of code sharing/reuse is so
often underestimated :-/

H.

On 02/15/2017 11:32 AM, Hadley Wickham wrote:
> It seems like this should be consistent with split(), since that's
> what actually powers the behaviour.
>
> Reading the description for split leads to this rather interesting example:
>
> tapply(mtcars, 1:11, I)
>
> Hadley
>
> On Tue, Feb 14, 2017 at 7:10 PM, Herv? Pag?s <hpages at fredhutch.org> wrote:
>> Hi,
>>
>> tapply() will work on any object 'X' that has a length and supports
>> single-bracket subsetting. These objects are sometimes called
>> "vector-like" objects. Atomic vectors, lists, S4 objects with a "length"
>> and "[" method, etc... are examples of "vector-like" objects.
>>
>> So instead of saying
>>
>>   X: an atomic object, typically a vector.
>>
>> I think it would be more accurate if the man page was saying something
>> like
>>
>>   X: a vector-like object that supports subsetting with `[`, typically
>>      an atomic vector.
>>
>> H.
>>
>>
>> On 02/04/2017 04:17 AM, Tal Galili wrote:
>>>
>>> In the help page of ?tapply it says that the first argument (X) is "an
>>> atomic object, typically a vector."
>>>
>>> However, tapply seems to be able to handle list objects. For example:
>>>
>>> ###################
>>>
>>> l <- as.list(1:10)
>>> is.atomic(l) # FALSE
>>> index <- c(rep(1,5),rep(2,5))
>>> tapply(l,index,unlist)
>>>
>>>> tapply(l,index,unlist)
>>>
>>> $`1`
>>> [1] 1 2 3 4 5
>>>
>>> $`2`
>>> [1]  6  7  8  9 10
>>>
>>>
>>> ###################
>>>
>>> Hence, does it mean a list an atomic object? (which I thought it wasn't)
>>> or
>>> is the help for tapply needs updating?
>>> (or some third option I'm missing?)
>>>
>>> Thanks.
>>>
>>>
>>>
>>>
>>>
>>> ----------------Contact
>>> Details:-------------------------------------------------------
>>> Contact me: Tal.Galili at gmail.com |
>>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>>> www.r-statistics.com (English)
>>>
>>> ----------------------------------------------------------------------------------------------
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fredhutch.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From matt at jacobmail.org  Thu Feb 16 02:14:39 2017
From: matt at jacobmail.org (Matt Jacob)
Date: Wed, 15 Feb 2017 18:14:39 -0700
Subject: [R] Validating Minitab's "Expanded Gage R&R Study" using R and lme4
Message-ID: <1487207679.720120.882533184.0904CD2D@webmail.messagingengine.com>

I'm trying to validate the results of an "Expanded Gage R&R Study" in
Minitab using R and lme4, but I can't get the numbers to match up in
certain situations. I can't tell whether my model is wrong, my data is
bad, or something else is going on.

For instance, here's some data for which the results don't match:

https://i.stack.imgur.com/5PCgm.png

After running the gage study, these are the results according to
Minitab:

                                Study Var  %Study Var  %Tolerance
Source             StdDev (SD)   (6 * SD)       (%SV)  (SV/Toler)
Total Gage R&R         1.76277    10.5766      100.00       14.36
  Repeatability        0.00000     0.0000        0.00        0.00
  Reproducibility      1.76277    10.5766      100.00       14.36
    B                  0.00000     0.0000        0.00        0.00
    A*B                1.76277    10.5766      100.00       14.36
Part-To-Part           0.00000     0.0000        0.00        0.00
  A                    0.00000     0.0000        0.00        0.00
Total Variation        1.76277    10.5766      100.00       14.36

But when I mimic Minitab's results by parsing the output from lmer() and
doing the arithmetic in Excel, this is what I see:

https://i.stack.imgur.com/EGg9F.png

The raw output from lmer() was:

Linear mixed model fit by REML ['lmerMod']
Formula: y ~ 1 + (1 | A) + (1 | B) + (1 | A:B)
   Data: d

REML criterion at convergence: -100.1

Scaled residuals: 
       Min         1Q     Median         3Q        Max 
-1.308e-07 -1.308e-07 -1.308e-07 -6.541e-08  1.308e-07 

Random effects:
 Groups   Name        Variance  Std.Dev. 
 A:B      (Intercept) 1.333e+00 1.154e+00
 B        (Intercept) 7.066e-04 2.658e-02
 A        (Intercept) 2.260e-03 4.754e-02
 Residual             2.655e-14 1.629e-07
Number of obs: 8, groups:  A:B, 4; B, 2; A, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)    52.17       0.57   91.53
convergence code: 0
Model failed to converge with max|grad| = 0.422755 (tol = 0.002,
component 1)
Model is nearly unidentifiable: very large eigenvalue
 - Rescale variables?

And the R code that produced that output is:

library(lme4)
A <- factor(c(1, 1, 2, 2, 2, 1, 2, 1))
B <- factor(c(1, 2, 1, 2, 1, 2, 2, 1))
y <- c(51.356124843620798, 51.356124843620798, 54.8816618912481,
51.356124843620798, 54.8816618912481, 51.356124843620798,
51.356124843620798, 51.356124843620798)
d <- data.frame(y, A, B)
fm <- lmer(y ~ 1 + (1|A) + (1|B) + (1|A:B), d)
summary(fm)

For a different measurement with a different response, it's a completely
different situation! Given the following data:

https://i.stack.imgur.com/cH0bO.png

The resulting table from Minitab is:

                                Study Var  %Study Var  %Tolerance
Source             StdDev (SD)   (6 * SD)       (%SV)  (SV/Toler)
Total Gage R&R        0.193649    1.16190       55.90        1.00
  Repeatability       0.093541    0.56125       27.00        0.48
  Reproducibility     0.169558    1.01735       48.95        0.88
    B                 0.132288    0.79373       38.19        0.68
    A*B               0.106066    0.63640       30.62        0.55
Part-To-Part          0.287228    1.72337       82.92        1.49
  A                   0.287228    1.72337       82.92        1.49
Total Variation       0.346410    2.07846      100.00        1.79

And after plugging my R results into Excel, I get exactly the same
thing:

https://i.stack.imgur.com/jUEAP.png

Which was produced by this R code:

library(lme4)
A <- factor(c(1, 1, 2, 2, 2, 1, 2, 1))
B <- factor(c(1, 2, 1, 2, 1, 2, 2, 1))
y <- c(-49.4, -49.8, -50.1, -50.1, -50.0, -49.9, -50.2, -49.6)
d <- data.frame(y, A, B)
fm <- lmer(y ~ 1 + (1|A) + (1|B) + (1|A:B), d)
summary(fm)

That generated the following lmer() summary:

Linear mixed model fit by REML ['lmerMod']
Formula: y ~ 1 + (1 | A) + (1 | B) + (1 | A:B)
   Data: d

REML criterion at convergence: -3.8

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-0.7705 -0.6853 -0.1039  0.4379  1.4151 

Random effects:
 Groups   Name        Variance Std.Dev.
 A:B      (Intercept) 0.01125  0.10607 
 B        (Intercept) 0.01750  0.13229 
 A        (Intercept) 0.08250  0.28723 
 Residual             0.00875  0.09354 
Number of obs: 8, groups:  A:B, 4; B, 2; A, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept) -49.8875     0.2322  -214.9

Is the difference attributable to the warnings produced by lmer() about
the model failing to converge and being nearly unidentifiable? What
could Minitab be doing differently when the measurement data contains
only two distinct values?

Matt

This question is cross-posted to
http://stats.stackexchange.com/questions/262170/how-can-i-validate-minitabs-expanded-gage-rr-study-using-open-source-tools


From bgunter.4567 at gmail.com  Thu Feb 16 02:46:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 15 Feb 2017 17:46:32 -0800
Subject: [R] New R user- Simple optimization problem
In-Reply-To: <02c001d28719$dd7f5f10$987e1d30$@gmail.com>
References: <02c001d28719$dd7f5f10$987e1d30$@gmail.com>
Message-ID: <CAGxFJbTzF13sOLbrsCeGb+=oE2yFzmrKfEEPcPDoNYbbh3kiCQ@mail.gmail.com>

Homework?

If so, we don't do hw here. Otherwise, we usually ask people to show us
their failed coding efforts rather than expecting us to do the problem for
them. Please read and follow the posting guide.

Cheers,

Bert


On Feb 15, 2017 10:25 AM, "Brady Richter" <bradyrichter at gmail.com> wrote:

Hi I am learning R currently and I having trouble structuring a program.



Data consists of 1 data frame with a day of the week, a class list, and a
utility score.



Date                   Class                   Utility



Monday              Chem                  85

Monday              Physics               75

Tuesday              Chem                  95

Tuesday              Math                  93

Tuesday              History               87

Tuesday              Language           86



And so on through Friday.



I want to maximize total utility (the sum) given 2 constraints:



1.      The number of classes you must take each day is fixed. (Must take 1
class on Monday, 2 on Tuesday, 1 on Wednesday etc.)
2.      No repeats- You can only take any given class zero or one time.



Any help to go about this would be appreciated.



Thank you.



bhr






        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Feb 16 03:10:39 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 15 Feb 2017 18:10:39 -0800
Subject: [R] New R user- Simple optimization problem
In-Reply-To: <040b01d287f8$b929cfd0$2b7d6f70$@gmail.com>
References: <02c001d28719$dd7f5f10$987e1d30$@gmail.com>
	<CAGxFJbTzF13sOLbrsCeGb+=oE2yFzmrKfEEPcPDoNYbbh3kiCQ@mail.gmail.com>
	<040b01d287f8$b929cfd0$2b7d6f70$@gmail.com>
Message-ID: <CAGxFJbTwAKipB5dTwQ_Q_ZvTotiPYfVZwDoZQWGpkpxbcwEgGg@mail.gmail.com>

Please cc the list. It's too much trouble for me, but maybe not for someone
else.

Bert

On Feb 15, 2017 6:02 PM, "Brady Richter" <bradyrichter at gmail.com> wrote:

> Bert,
>
>
>
> I?m 46- I don?t get homework.  Just looking for a bit of help getting
> started organizing the loop structure, but since it seems to be too much
> trouble I will figure it out on my own.
>
>
>
> Regards,
>
>
>
> Brady
>
>
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Wednesday, February 15, 2017 8:47 PM
> *To:* Brady Richter <bradyrichter at gmail.com>
> *Cc:* R-help <r-help at r-project.org>
> *Subject:* Re: [R] New R user- Simple optimization problem
>
>
>
> Homework?
>
>
>
> If so, we don't do hw here. Otherwise, we usually ask people to show us
> their failed coding efforts rather than expecting us to do the problem for
> them. Please read and follow the posting guide.
>
>
>
> Cheers,
>
>
>
> Bert
>
>
>
>
>
> On Feb 15, 2017 10:25 AM, "Brady Richter" <bradyrichter at gmail.com> wrote:
>
> Hi I am learning R currently and I having trouble structuring a program.
>
>
>
> Data consists of 1 data frame with a day of the week, a class list, and a
> utility score.
>
>
>
> Date                   Class                   Utility
>
>
>
> Monday              Chem                  85
>
> Monday              Physics               75
>
> Tuesday              Chem                  95
>
> Tuesday              Math                  93
>
> Tuesday              History               87
>
> Tuesday              Language           86
>
>
>
> And so on through Friday.
>
>
>
> I want to maximize total utility (the sum) given 2 constraints:
>
>
>
> 1.      The number of classes you must take each day is fixed. (Must take 1
> class on Monday, 2 on Tuesday, 1 on Wednesday etc.)
> 2.      No repeats- You can only take any given class zero or one time.
>
>
>
> Any help to go about this would be appreciated.
>
>
>
> Thank you.
>
>
>
> bhr
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From jake.andrae at adelaide.edu.au  Thu Feb 16 07:58:21 2017
From: jake.andrae at adelaide.edu.au (Jake William Andrae)
Date: Thu, 16 Feb 2017 06:58:21 +0000
Subject: [R] Help with marmap package
Message-ID: <SY3PR01MB207473385C1532F14D98AAE7A95A0@SY3PR01MB2074.ausprd01.prod.outlook.com>

Hello,


I'm using the 'Marmap' R package to create ocean bathymetry maps. I've managed quite well, but I'm having a little difficulty with setting my x-axis (longitude) limits. When I run the code, the map is projected with large white bands on either side of the desired longitude limits. I've tried setting the limits myself (i.e xlim = c(115, 130)). I've also tried setting the 'xaxs' parameter to 'i', with no luck. I've included the code below, with the NOAA bathymetry data I'm trying to map.


If anyone has had any experience with this package and has encountered similar problems and has a solution, I'd love to hear about it.



# Load package
library(marmap)

# Import bathymetry
bat <- getNOAA.bathy(130, 115, -26, -12, res = 1, keep = TRUE)

# Plot map with isobaths every 1000m
plot(bat, image = TRUE, land = TRUE, deep=-10000, shallow=-1000, step=1000,
                      drawlabels = TRUE, bpal = list(c(min(bat,na.rm=TRUE), 0, blues),
                      c(0, max(bat, na.rm=TRUE), greenbrowns)), lwd = 0.1, col = 'grey20')


Regards,


Jake Andrae
PhD Candidate
Geology & Geophysics ? Sprigg Geobiology Centre
Department of Earth Science
School of Physical Sciences
The University of Adelaide, AUSTRALIA 5005
Phone: 0407701565
Email: jake.andrae at adelaide.edu.au


	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Thu Feb 16 14:04:08 2017
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 16 Feb 2017 07:04:08 -0600
Subject: [R] MS SQL Server R Services review.
Message-ID: <CAAJSdjjnScwiUkMdzonZd_PeMr_KXzJ6zWvFAnUVyq7_jJ4gpw@mail.gmail.com>

I just picked this up over on "Vulture Central"
http://www.theregister.co.uk/2017/02/16/r_sql_server_great_but_beware/

The author seems both pleased and not pleased. Mainly digging at R's use
(or abuse) of memory being a cause of many failures. And the fact that is
is "slow" (states Python runs 17x faster) due to being interpreted.

Also, to me, it seems weird to run R within the data base server itself,
rather than on a client using RODBC.

-- 
"Irrigation of the land with seawater desalinated by fusion power is
ancient. It's called 'rain'." -- Michael McClary, in alt.fusion

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From saubhagya at gatech.edu  Wed Feb 15 18:36:50 2017
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Wed, 15 Feb 2017 17:36:50 +0000
Subject: [R] R version 3.3.2,
 Windows 10 -- gstat.predict() function often return NaN values
 (GSTAT Package)
Message-ID: <DM5PR07MB31792E135401AC2EB5C73819CF5B0@DM5PR07MB3179.namprd07.prod.outlook.com>

A non-text attachment was scrubbed...
Name: Expected Output.png
Type: image/png
Size: 10081 bytes
Desc: Expected Output.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170215/65efcbab/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Undesired Output.png
Type: image/png
Size: 7668 bytes
Desc: Undesired Output.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170215/65efcbab/attachment-0001.png>

From marongiu.luigi at gmail.com  Thu Feb 16 16:30:57 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 16 Feb 2017 15:30:57 +0000
Subject: [R] cluster data in lattice dotplot and show stdev
Message-ID: <CAMk+s2QSbX_UOe0h1UDBwocCynXWxw2vT80NT+_UzifH9cEpig@mail.gmail.com>

dear all,
i have a set of data that is separated in the variables: cluster (two
runs), type (blank, negative and positive) and target (A and B), each
duplicated. I am plotting it with lattice and the result is a 2x2 matrix
plot in which the top two cells (or panels) are relative to run 2, the
lower to run 2; each panel is then subdivided in target A or B and I have
colour-coded the dots to match the target.
However i would like to have a 1x2 panel plot representing the targets, and
within each panel having a cluster of 3 dots (representing the types) for
run 1 and another for run 2. I tried to represent such requirement in the
rough construction at the end of the example.
also, since each run is actually formed by duplicates, each dot should
indicate the standard deviation of the values.
How would I do that? any tips?
thanks
luigi

>>>
cluster <- c(rep("run_1", 6), rep("run_2", 6))
type <- rep(c("blank", "positive", "negative"),2)
target <- c(rep("A", 6), rep("B", 6))
value <- c(0.01, 1.1, 0.5,
           0.02, 1.6, 0.8,
           0.07, 1.4, 0.7,
           0.03, 1.4, 0.4)
my.data <- data.frame(cluster, type, target, value)

library(lattice)
dotplot(
  value ~ type|cluster + target,
  my.data,
  groups = type,
  pch=21,
  main = "Luminex analysis MTb humans",
  xlab = "Target", ylab = "Reading",
  col = c("grey", "green", "red"),
  par.settings = list(strip.background = list(col="paleturquoise")),
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  key = list(
    space = "top",
    columns = 3,
    text = list(c("Blank", "Negative", "Positive"), col="black"),
    rectangles = list(col=c("grey", "green", "red"))
  )
)

x <- 1:7
plot(x , c(max(my.data$value), min(my.data$value), my.data$value[1:5]),
col="white", xaxt = "n", ylab="value", xlab="target")
points(x[1], mean(my.data$value[1], my.data$value[4]), col="grey")
points(x[2], mean(my.data$value[2], my.data$value[5]), col="red")
points(x[3], mean(my.data$value[3], my.data$value[6]), col="green")
points(x[5], mean(my.data$value[7], my.data$value[10]), col="grey")
points(x[6], mean(my.data$value[8], my.data$value[11]), col="red")
points(x[7], mean(my.data$value[9], my.data$value[12]), col="green")
axis(side=1, at = x[2], lab = "A", cex.axis=1)
axis(side=1, at = x[6], lab = "B", cex.axis=1)

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Feb 16 19:41:47 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 16 Feb 2017 10:41:47 -0800
Subject: [R] non-linear optimisation ODE models
In-Reply-To: <CA+8X3fXg4nw+0DqrCQe9HpmT=XLQFnhe-jzQXVNFvCwfc2z5Ag@mail.gmail.com>
References: <264407025.8366931.1487154740852.ref@mail.yahoo.com>
	<264407025.8366931.1487154740852@mail.yahoo.com>
	<1A288236-78CC-4223-A0AC-DB42E65C2103@xs4all.nl>
	<CA+8X3fXg4nw+0DqrCQe9HpmT=XLQFnhe-jzQXVNFvCwfc2z5Ag@mail.gmail.com>
Message-ID: <88737E56-C873-4ACE-89A2-A63E27AE0382@comcast.net>


> On Feb 15, 2017, at 1:43 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Malgorzata,
> The function "rxnrate" seems to want three values in a list with the
> names "k1", "k2" and "k3". If you are passing something with different
> names, it is probably going to complain, so the names "A", "B" and "C"
> may be your problem. I can't run the example, so this is a guess.

There's a more readable version at:
http://stackoverflow.com/questions/42256509/how-to-feed-data-into-ide-while-doing-optimisation

It can be run, but does not produce the errors offered when I do so.

-- 
David.

> 
> Jim
> 
> 
>> On 15 Feb 2017, at 11:32, Malgorzata Wieteska via R-help <r-help at r-project.org> wrote:
>> 
>> Hello,
>> I'm new to R, so sorry for this question. I found a piece of code on stack overflow community, title: r-parameter and initial conditions fitting ODE models with nls.lm.
>> I've tried to implement a change suggested, but I get an error: Error in unname(myparms[4], B = 0, C = 0) :   unused arguments (B = 0, C = 0)
>> I'll appreciate any hint.
>> Malgosia
>> 
>> #set working directorysetwd("~/R/wkspace")#load librarieslibrary(ggplot2)library(reshape2)library(deSolve)library(minpack.lm)time=c(0,0.263,0.526,0.789,1.053,1.316,1.579,1.842,2.105,2.368,2.632,2.895,3.158,3.421,3.684,3.947,4.211,4.474,4.737,5)ca=c(0.957,0.557,0.342,0.224,0.123,0.079,0.035,0.029,0.025,0.017,-0.002,0.009,-0.023,0.006,0.016,0.014,-0.009,-0.03,0.004,-0.024)cb=c(-0.031,0.33,0.512,0.499,0.428,0.396,0.303,0.287,0.221,0.148,0.182,0.116,0.079,0.078,0.059,0.036,0.014,0.036,0.036,0.028)cc=c(-0.015,0.044,0.156,0.31,0.454,0.556,0.651,0.658,0.75,0.854,0.845,0.893,0.942,0.899,0.942,0.991,0.988,0.941,0.971,0.985)df<-data.frame(time,ca,cb,cc)dfnames(df)=c("time","ca","cb","cc")#plot datatmp=melt(df,id.vars=c("time"),variable.name="species",value.name="conc")ggplot(data=tmp,aes(x=time,y=conc,color=species))+geom_point(size=3)#rate functionrxnrate=function(t,c,parms){  #rate constant passed through a list called  k1=parms$k1  k2=parms$k2  k3=parms$k3  #c is the concentratio!
>> n of species  #derivatives dc/dt are computed below  r=rep(0,length(c))  r[1]=-k1*c["A"] #dcA/dt  r[2]=k1*c["A"]-k2*c["B"]+k3*c["C"] #dcB/dt  r[3]=k2*c["B"]-k3*c["C"] #dcC/dt  return(list(r))}# predicted concentration for a given parametercinit=c(A=1,B=0,C=0)t=df$timeparms=list(k1=2, k2=1, k3=3)out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))head(out)
>>> ssq=function(myparms){  #initial concentration  cinit=c(A=myparms[4],B=0,C=0)  cinit=c(A=unname(myparms[4],B=0,C=0))  print(cinit)  #time points for which conc is reported  #include the points where data is available  t=c(seq(0,5,0.1),df$time)  t=sort(unique(t))  #parameters from the parameters estimation  k1=myparms[1]  k2=myparms[2]  k3=myparms[3]  #solve ODE for a given set of parameters  out=ode(y=cinit,times=t,func=rxnrate,parms=list(k1=k1,k2=k2,k3=k3))  #Filter data that contains time points  outdf=data.frame(out)  outdf=outdf[outdf$time%in% df$time,]  #Evaluate predicted vs experimental residual  preddf=melt(outdf,id.var="time",variable.name="species",value.name="conc")  expdf=melt(df,id.var="time",variable.name="species",value.name="conc")  ssqres=preddf$conc-expdf$conc  return(ssqres)}# parameter fitting using levenberg marquart#initial guess for parametersmyparms=c(k1=0.5,k2=0.5,k3=3,1)cinit=c(A=unname(myparms[4],B=0,C=0))print(cinit)#fittingfitval=nls.lm(par=pa!
> r!
>> ms,fn=ssq)#summary of fitsummary(fitval)
>> 
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From saubhagya at gatech.edu  Thu Feb 16 20:40:58 2017
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Thu, 16 Feb 2017 19:40:58 +0000
Subject: [R] R version 3.3.2,
 Windows 10 -- gstat.predict() function often return NaN values
 (GSTAT Package)
In-Reply-To: <DM5PR07MB31792E135401AC2EB5C73819CF5B0@DM5PR07MB3179.namprd07.prod.outlook.com>
References: <DM5PR07MB31792E135401AC2EB5C73819CF5B0@DM5PR07MB3179.namprd07.prod.outlook.com>
Message-ID: <DM5PR07MB3179A022A1A70B48E73B9E58CF5A0@DM5PR07MB3179.namprd07.prod.outlook.com>

I am adding my message in the mail body as I found it missing from the mail that finally got posted on the list. 

I am trying to simulate a combination of two different random fields (yy1 and yy2 different mean and correlation length) with an irregular boundary. I have attached the picture of my expected outcome. The code is not giving such output consistently and I am frequently getting atleast one of the yy1 and yy2 as as NaN, which results in the Undesired output as shown in image. 

The key steps I used are:

1)	Created two gsat objects with different means and psill (rf1 and rf2)
2)	Created two computational grids (one for each random field) in the form of data frame with two variables "x" and "y" coordinates. 
3)	Predicted two random fields using unconditional simulation. 

The code is fairly small hence I am pasting in here itself. Any help in this regard would be highly appreciated. 

## Code starts ===================================================================================
library(gstat)

xy <- expand.grid(1:150, 1:200) # grid is created in the form of a dataframe with x and y vectors
names(xy)<-c('x','y') # giving names to the variables

# Creating gsat objects

rf1<-gstat(formula=z~1,locations=~x+y,dummy = T,beta=c(1,0,0), model=vgm(psill=0.025, range=5, model='Exp'), nmax=20)  # dummy=T treats this as a unditional simulation
rf2<-gstat(formula=z~1,locations=~x+y,dummy = T,beta=c(4,0,0), model=vgm(psill=0.025, range=10, model='Exp'), nmax=20)  # dummy=T treats this as a unditional simulation

# Splitting the computational grid into two

rows<-nrow(xy)
xy_shift <- expand.grid(60:90, 75:100)
names(xy_shift)<-c('x','y')

library(dplyr) # for antijoin
xy1<-xy[1:(rows/2),]
xy1<-anti_join(xy1, xy_shift, by = c("x","y")) # creating the irregular boundary
xy2<-rbind(xy[(rows/2+1):rows,],xy_shift)

# Simulation

yy1<- predict(rf1, newdata=xy1, nsim=1) # random field 1
yy2<- predict(rf2, newdata=xy2, nsim=1) # random field 2

yy<-rbind(yy1,yy2)

# Plotting the field

library(sp)
gridded(yy) = ~x+y
spplot(obj=yy[1])

## Code ends=====================================================================

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rathore, Saubhagya Singh
Sent: Wednesday, February 15, 2017 12:37 PM
To: r-help at r-project.org
Subject: [R] R version 3.3.2, Windows 10 -- gstat.predict() function often return NaN values (GSTAT Package)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Expected Output.png
Type: image/png
Size: 10081 bytes
Desc: Expected Output.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170216/5fb8244d/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Undesired Output.png
Type: image/png
Size: 7668 bytes
Desc: Undesired Output.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170216/5fb8244d/attachment-0001.png>

From drjimlemon at gmail.com  Thu Feb 16 22:53:40 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 17 Feb 2017 08:53:40 +1100
Subject: [R] cluster data in lattice dotplot and show stdev
In-Reply-To: <CAMk+s2QSbX_UOe0h1UDBwocCynXWxw2vT80NT+_UzifH9cEpig@mail.gmail.com>
References: <CAMk+s2QSbX_UOe0h1UDBwocCynXWxw2vT80NT+_UzifH9cEpig@mail.gmail.com>
Message-ID: <CA+8X3fUvk3zNnqAvcC34ZBZKbsejU6t9eFYoLAwXXO6gotAEpg@mail.gmail.com>

Hi Luigi,
Are you looking for something like this?

library(plotrix)
ylim=c(0,1.7)
png("lmplot.png",width=600,height=300)
par(mfrow=c(1,2))
brkdn.plot(value~type,data=my.data[my.data$target=="A",],
 main="Run 1",ylab="Value",xlab="",xaxlab="target",ylim=ylim,
 mct="mean",md="sd",pch=c("B","N","P"))
brkdn.plot(value~type,data=my.data[my.data$target=="B",],
 main="Run 2",ylab="Value",xlab="",xaxlab="target",ylim=ylim,
 mct="mean",md="sd",pch=c("B","N","P"))
dev.off()

Jim


On Fri, Feb 17, 2017 at 2:30 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> dear all,
> i have a set of data that is separated in the variables: cluster (two
> runs), type (blank, negative and positive) and target (A and B), each
> duplicated. I am plotting it with lattice and the result is a 2x2 matrix
> plot in which the top two cells (or panels) are relative to run 2, the
> lower to run 2; each panel is then subdivided in target A or B and I have
> colour-coded the dots to match the target.
> However i would like to have a 1x2 panel plot representing the targets, and
> within each panel having a cluster of 3 dots (representing the types) for
> run 1 and another for run 2. I tried to represent such requirement in the
> rough construction at the end of the example.
> also, since each run is actually formed by duplicates, each dot should
> indicate the standard deviation of the values.
> How would I do that? any tips?
> thanks
> luigi
>
>>>>
> cluster <- c(rep("run_1", 6), rep("run_2", 6))
> type <- rep(c("blank", "positive", "negative"),2)
> target <- c(rep("A", 6), rep("B", 6))
> value <- c(0.01, 1.1, 0.5,
>            0.02, 1.6, 0.8,
>            0.07, 1.4, 0.7,
>            0.03, 1.4, 0.4)
> my.data <- data.frame(cluster, type, target, value)
>
> library(lattice)
> dotplot(
>   value ~ type|cluster + target,
>   my.data,
>   groups = type,
>   pch=21,
>   main = "Luminex analysis MTb humans",
>   xlab = "Target", ylab = "Reading",
>   col = c("grey", "green", "red"),
>   par.settings = list(strip.background = list(col="paleturquoise")),
>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>   key = list(
>     space = "top",
>     columns = 3,
>     text = list(c("Blank", "Negative", "Positive"), col="black"),
>     rectangles = list(col=c("grey", "green", "red"))
>   )
> )
>
> x <- 1:7
> plot(x , c(max(my.data$value), min(my.data$value), my.data$value[1:5]),
> col="white", xaxt = "n", ylab="value", xlab="target")
> points(x[1], mean(my.data$value[1], my.data$value[4]), col="grey")
> points(x[2], mean(my.data$value[2], my.data$value[5]), col="red")
> points(x[3], mean(my.data$value[3], my.data$value[6]), col="green")
> points(x[5], mean(my.data$value[7], my.data$value[10]), col="grey")
> points(x[6], mean(my.data$value[8], my.data$value[11]), col="red")
> points(x[7], mean(my.data$value[9], my.data$value[12]), col="green")
> axis(side=1, at = x[2], lab = "A", cex.axis=1)
> axis(side=1, at = x[6], lab = "B", cex.axis=1)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lmplot.png
Type: image/png
Size: 2787 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170217/0e9cbc02/attachment.png>

From dulcalma at bigpond.com  Fri Feb 17 01:06:36 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 17 Feb 2017 11:06:36 +1100
Subject: [R] cluster data in lattice dotplot and show stdev
In-Reply-To: <CAMk+s2QSbX_UOe0h1UDBwocCynXWxw2vT80NT+_UzifH9cEpig@mail.gmail.com>
References: <CAMk+s2QSbX_UOe0h1UDBwocCynXWxw2vT80NT+_UzifH9cEpig@mail.gmail.com>
Message-ID: <000f01d288b1$b4b586b0$1e209410$@bigpond.com>

Hi Luigi

I think your data is duplicated

> xtabs(~cluster+type+target,my.data)
, , target = A

       type
cluster blank negative positive
  run_1     2        2        2
  run_2     0        0        0

, , target = B

       type
cluster blank negative positive
  run_1     0        0        0
  run_2     2        2        2

> xtabs(~cluster+target,my.data)
       target
cluster A B
  run_1 6 0
  run_2 0 6

I am not sure exactly what you want partly because what Jim has plotted.
I have thought of 2 ways. I have added columns coding the factors as numeric
to make it flexible

1. By runs
my.data$Target <- paste0(rep(LETTERS[1:2],each= 6),rep(1:2,each=3))
my.data$x <- rep(c(0.8,1.2),each=3)
my.data$xrun <- rep(1:3)

xyplot(value ~ x|target,my.data,
       groups = type,
       xlim = c(0.5,1.5),
       scales = list(x = list(at= c(0.8,1.2),
                     label=paste("Run",1:2)),
                     alternating = 1),
       auto.key = list(points = T,
                       lines = F),
       pch=16,
       panel = panel.superpose,
       panel.groups = function(x,y,...){
       
                        panel.xyplot(x,y, ...)
                        
       
               }
)

2. By type

xyplot(value ~ xrun|target,my.data,
       groups = run,
       xlim = c(0,4),       
      par.settings = list(strip.background = list(col = "transparent")),
       scales = list(x = list(at= c(1:3),
                     label= unique(my.data$type),
                     alternating = 1)),
       auto.key = list(points = T,
                       lines = F),
       pch=16,
       panel = panel.superpose,
       panel.groups = function(x,y,...){

                        panel.xyplot(x,y, ...)


               }
)

If you want error bars use the functions in 
demo(lattice::intervals)
or use your own panel .segments

If you decide not to use default colours etc use 

panel.settings = list(superpose.symbol = list(pch = ... ,
                                              col = ... ,
                                              cex = 1))

makes keys easier
                                                    
example by hand error bars

xyplot(value ~ xrun|target,my.data,
       groups = run,
       xlim = c(0,4),
       par.settings = list(strip.background = list(col = "transparent"),
                                          grid.pars = list(lineend =
"butt")),
       scales = list(x = list(at= c(1:3),
                     label= unique(my.data$type),
                     alternating = 1)),
       auto.key = list(points = T,
                       lines = F),
       pch=16,
       panel = panel.superpose,
       panel.groups = function(x,y,...,group.number){

                        panel.xyplot(x,y, ...)

                        panel.arrows(group.number+0.3, group.number-0.6,
group.number+0.3, group.number-0.4,
                              length = 0.04,
                              unit = "inches",
                              angle = 90,
                              code = 3)

               }
)

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Friday, 17 February 2017 02:31
To: r-help
Subject: [R] cluster data in lattice dotplot and show stdev

dear all,
i have a set of data that is separated in the variables: cluster (two
runs), type (blank, negative and positive) and target (A and B), each
duplicated. I am plotting it with lattice and the result is a 2x2 matrix
plot in which the top two cells (or panels) are relative to run 2, the
lower to run 2; each panel is then subdivided in target A or B and I have
colour-coded the dots to match the target.
However i would like to have a 1x2 panel plot representing the targets, and
within each panel having a cluster of 3 dots (representing the types) for
run 1 and another for run 2. I tried to represent such requirement in the
rough construction at the end of the example.
also, since each run is actually formed by duplicates, each dot should
indicate the standard deviation of the values.
How would I do that? any tips?
thanks
luigi

>>>
cluster <- c(rep("run_1", 6), rep("run_2", 6))
type <- rep(c("blank", "positive", "negative"),2)
target <- c(rep("A", 6), rep("B", 6))
value <- c(0.01, 1.1, 0.5,
           0.02, 1.6, 0.8,
           0.07, 1.4, 0.7,
           0.03, 1.4, 0.4)
my.data <- data.frame(cluster, type, target, value)

library(lattice)
dotplot(
  value ~ type|cluster + target,
  my.data,
  groups = type,
  pch=21,
  main = "Luminex analysis MTb humans",
  xlab = "Target", ylab = "Reading",
  col = c("grey", "green", "red"),
  par.settings = list(strip.background = list(col="paleturquoise")),
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  key = list(
    space = "top",
    columns = 3,
    text = list(c("Blank", "Negative", "Positive"), col="black"),
    rectangles = list(col=c("grey", "green", "red"))
  )
)

x <- 1:7
plot(x , c(max(my.data$value), min(my.data$value), my.data$value[1:5]),
col="white", xaxt = "n", ylab="value", xlab="target")
points(x[1], mean(my.data$value[1], my.data$value[4]), col="grey")
points(x[2], mean(my.data$value[2], my.data$value[5]), col="red")
points(x[3], mean(my.data$value[3], my.data$value[6]), col="green")
points(x[5], mean(my.data$value[7], my.data$value[10]), col="grey")
points(x[6], mean(my.data$value[8], my.data$value[11]), col="red")
points(x[7], mean(my.data$value[9], my.data$value[12]), col="green")
axis(side=1, at = x[2], lab = "A", cex.axis=1)
axis(side=1, at = x[6], lab = "B", cex.axis=1)

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From art.tem.us at gmail.com  Fri Feb 17 00:12:08 2017
From: art.tem.us at gmail.com (Art U)
Date: Thu, 16 Feb 2017 18:12:08 -0500
Subject: [R] Empirical k-quantile function
Message-ID: <CAKY_brEXpsyFTZzYaqmrTUzNmfd8p+VYeqhRKtoHjPDS0t7DAA@mail.gmail.com>

Hello,

Suppose I have one vector of values or even matrix of those vectors and I
want to calculate q_k(V/k), where V is the vector, k is a quantile and q_k
is empirical k-quantile function. Finally I want to calculate Q_k=min(1,
q_k) for k=(0,1).

Can you please help me with this code?
quantile function provides value

Basically I'm trying to reproduce results from paper "P-values for
High-Dimensional Regression", Meinshausen, Meier, Buhlmann.

Thank you in advance.
Art

-- 
*I like to pretend I'm alone*. *Completely alone*. *Maybe post-apocalypse
or plague*... *Whatever*. *No-one left to act normal for. No need to hide
who I really am. It would be... freeing*. *...*

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Feb 17 09:48:42 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 17 Feb 2017 21:48:42 +1300
Subject: [R] [FORGED]  Empirical k-quantile function
In-Reply-To: <CAKY_brEXpsyFTZzYaqmrTUzNmfd8p+VYeqhRKtoHjPDS0t7DAA@mail.gmail.com>
References: <CAKY_brEXpsyFTZzYaqmrTUzNmfd8p+VYeqhRKtoHjPDS0t7DAA@mail.gmail.com>
Message-ID: <75cd8351-4227-3cdd-08f9-3915139c9cac@auckland.ac.nz>

On 17/02/17 12:12, Art U wrote:
> Hello,
>
> Suppose I have one vector of values or even matrix of those vectors and I
> want to calculate q_k(V/k), where V is the vector, k is a quantile and q_k
> is empirical k-quantile function. Finally I want to calculate Q_k=min(1,
> q_k) for k=(0,1).
>
> Can you please help me with this code?
> quantile function provides value
>
> Basically I'm trying to reproduce results from paper "P-values for
> High-Dimensional Regression", Meinshausen, Meier, Buhlmann.

Your question is IMHO vague and to my limited mental capacities, 
incomprehensible.  Please try to adhere to the R-help desideratum of 
providing (minimal) *reproducible* examples of whatever it is that you 
are trying to accomplish.  (This includes data, code, and the *desired* 
result that you are not at present able to obtain.

cheers,

Rolf Turner

P.S.  Are you familiar with the functions (a) quantile(), and
(b) apply()?  If not, become so!

R. T.


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bjoern.fisseler at googlemail.com  Fri Feb 17 13:54:44 2017
From: bjoern.fisseler at googlemail.com (=?UTF-8?Q?Bj=c3=b6rn_Fisseler?=)
Date: Fri, 17 Feb 2017 13:54:44 +0100
Subject: [R] Feature space problem regarding text classification using SVM
Message-ID: <38c64615-db83-6c30-c335-d7d6b240ec25@gmail.com>

Dear list members,

I'm currently working on text classification of student's essays, trying 
to identify texts that fit to a certain class or not. I use texts from 
one semester (A) for training and texts from another semester (B) for 
testing the classifier. My workflow is like this:

  * read all texts from A, build a DTM(A) with about 1387 terms
  * read all texts from B, build a DTM(B) with about 626 terms
  * train the classifier with DTM(A), using a SVM (package e1071)

Now I want to classify all texts in DTM(B) using the classifyer. But 
when I try to use predict(), I always get the error message: Error in 
eval(expr, envir, enclos) : object 'XY' not found. As I found out, the 
reason for this is that DTM(A) and DTM(B) have a different number of 
terms and consequently not every term used for training the model is 
available in DTM(B).

My question is: how should/do I deal with this? Should I match the terms 
used in DTM(A) and DTM(B), in order to get an identical feature space? 
This could be achieved either reducing the number of terms in DTM(A) or 
adding several empty/NA columns to DTM(B). Or is there another solution 
to my problem?

Kind regards

   Bj?rn



	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Fri Feb 17 18:20:08 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Fri, 17 Feb 2017 17:20:08 +0000 (UTC)
Subject: [R]  unidentified option(s) in mean.model
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
Message-ID: <2116363132.1334313.1487352008288@mail.yahoo.com>

So i tried brute force to find best fitted GARCH model for prediction.The code works fine as it runs but at the end of processing, there's error like this: There were 50 or more warnings (use warnings() to see the first 50).
So i type warnings(), then the error become:unidentified option(s) in mean.model?
Not sure what's gone wrong?
See attached for R script

From bgunter.4567 at gmail.com  Sat Feb 18 04:40:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 17 Feb 2017 19:40:29 -0800
Subject: [R] Feature space problem regarding text classification using
	SVM
In-Reply-To: <CAGxFJbT+NKdB=J8tZMmc8ep_oKn6KcuayU_HGOW58o-xHUEAAQ@mail.gmail.com>
References: <38c64615-db83-6c30-c335-d7d6b240ec25@gmail.com>
	<CAGxFJbRmrMC-K=8xG7WFowHxUBBPEK0OrF2az2YF2V-fJQ=j_A@mail.gmail.com>
	<CAGxFJbTg-QgpEfurwRacW7_R9_pD3rMmAfhip=5WCy1KV1AwzA@mail.gmail.com>
	<CAGxFJbRWqyXbyr+ZhGj_xL7E7e8n67vfLQXjJimfLWZr29YseA@mail.gmail.com>
	<CAGxFJbR0AnK4hkgs2+h1Kf9NNYaa9ORTixSJP4V39VFTaaWHug@mail.gmail.com>
	<CAGxFJbT+NKdB=J8tZMmc8ep_oKn6KcuayU_HGOW58o-xHUEAAQ@mail.gmail.com>
Message-ID: <CAGxFJbSbnmFJpe_WeOPp5Y+rWX0Gg-cpnxmj_nWcPFuaeS7PNg@mail.gmail.com>

This question is about statistics and therefore is off topic for this list.
However, if I understand correctly isn't the answer obvious? -- how can you
classify by features whose values are unknown?

Cheers,
Bert



On Feb 17, 2017 5:28 AM, "Bj?rn Fisseler via R-help" <r-help at r-project.org>
wrote:

Dear list members,

I'm currently working on text classification of student's essays, trying
to identify texts that fit to a certain class or not. I use texts from
one semester (A) for training and texts from another semester (B) for
testing the classifier. My workflow is like this:

  * read all texts from A, build a DTM(A) with about 1387 terms
  * read all texts from B, build a DTM(B) with about 626 terms
  * train the classifier with DTM(A), using a SVM (package e1071)

Now I want to classify all texts in DTM(B) using the classifyer. But
when I try to use predict(), I always get the error message: Error in
eval(expr, envir, enclos) : object 'XY' not found. As I found out, the
reason for this is that DTM(A) and DTM(B) have a different number of
terms and consequently not every term used for training the model is
available in DTM(B).

My question is: how should/do I deal with this? Should I match the terms
used in DTM(A) and DTM(B), in order to get an identical feature space?
This could be achieved either reducing the number of terms in DTM(A) or
adding several empty/NA columns to DTM(B). Or is there another solution
to my problem?

Kind regards

   Bj?rn



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Feb 18 14:47:02 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 18 Feb 2017 13:47:02 +0000
Subject: [R] unidentified option(s) in mean.model
In-Reply-To: <2116363132.1334313.1487352008288@mail.yahoo.com>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
Message-ID: <58A85056.3000804@sapo.pt>

Helo,

No attachment came through. Change the file extension from .R to .txt 
and resend, there aren't many types of files r-help accepts.

Rui Barradas

Em 17-02-2017 17:20, Allan Tanaka escreveu:
> So i tried brute force to find best fitted GARCH model for prediction.The code works fine as it runs but at the end of processing, there's error like this: There were 50 or more warnings (use warnings() to see the first 50).
> So i type warnings(), then the error become:unidentified option(s) in mean.model
> Not sure what's gone wrong?
> See attached for R script
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gratebill at yahoo.gr  Sat Feb 18 17:21:39 2017
From: gratebill at yahoo.gr (Vasilis Bardakos)
Date: Sat, 18 Feb 2017 16:21:39 +0000 (UTC)
Subject: [R] Graph and Compare Distributions
References: <2100336859.366203.1487434899716.ref@mail.yahoo.com>
Message-ID: <2100336859.366203.1487434899716@mail.yahoo.com>

Dear Sirs,
I'm trying to demonstrate and compare my data first digit distributions in comparison with benford's law, but I cannot figure out how do a correct ggplot histogram. plot() works fine though.
The data are the following (probabilities):
[1] 0.37101911 0.17515924 0.08917197 0.08121019 0.06210191 0.06050955 0.07484076 0.03662420 0.04936306
[2] 0.524419536 0.253002402 0.092073659 0.032826261 0.025620496 0.019215372 0.008807046 0.012009608 0.032025620

These are my data first digit probabilities, while below there is the original distribution which would be represented with a smooth line:
[3] 0.30103000 0.17609126 0.12493874 0.09691001 0.07918125 0.06694679 0.05799195 0.05115252 0.04575749

Kind Regards,V. Bardakos
	[[alternative HTML version deleted]]


From oikos.nemo at gmail.com  Sat Feb 18 10:49:56 2017
From: oikos.nemo at gmail.com (Rodriguetti)
Date: Sat, 18 Feb 2017 10:49:56 +0100
Subject: [R] Discrete Hours Labour Supply Modelling
Message-ID: <5e38e110-5c39-5d74-8295-c1d080d0c2f5@gmail.com>

Hello,
I am an economist migrating from Stata to R and I am modelling labour 
supply responses with a discrete choice model.
I would just like to know if any person here knows about a researcher 
working in "Discrete Hours Labour Supply Modelling".
Amazingly, I am having difficulties to find economists working in this 
topic with R.
Thanks
Ernesto

---
El software de antivirus Avast ha analizado este correo electr?nico en busca de virus.
https://www.avast.com/antivirus


From tz05 at me.com  Sat Feb 18 05:18:19 2017
From: tz05 at me.com (T. Zhang)
Date: Fri, 17 Feb 2017 23:18:19 -0500
Subject: [R] A strange arithmetic error in R (maybe a bug)
Message-ID: <686E9826-AE82-4C38-8831-1A12B1DEB00E@me.com>

Hello,

Today I happened to notice a strange error in R. If you type (2.01-0.06)==1.95, output from R is ?FALSE?, which is wrong. But if you type (1.01-0.06)==0.95, output is ?TRUE?, which is correct. I tested this in two systems: R 3.3.2 in my iMac and R 3.2.0 on my school?s Linux server. Both gave same outputs. As shown in the following:

> 2.01-0.06
[1] 1.95
> (2.01-0.06)==1.95  # should be TRUE; output is wrong
[1] FALSE
> 1.01-0.06
[1] 0.95
> (1.01-0.06)==0.95  # should be TRUE; output is correct
[1] TRUE
> (2.01-0.06)>1.95  # should be FALSE; output is correct
[1] FALSE
> (2.01-0.06)<1.95  # should be FALSE; output is wrong
[1] TRUE

Similar errors could be found with simple alterations of the above inputs, such as:
> 5.533-5.412
[1] 0.121
> (5.533-5.412)==0.121  # should be TRUE; output is wrong
[1] FALSE
> 2.533-2.412
[1] 0.121
> (2.533-2.412)==0.121  # should be TRUE; output is correct
[1] TRUE

Could any of you test whether you have same outputs as mine? And does anyone know what is wrong with these? My guess is that R has a bug in processing double numbers. Thanks!

TZ

From zkokia at 163.com  Sat Feb 18 09:03:02 2017
From: zkokia at 163.com (Kokia Z)
Date: Sat, 18 Feb 2017 16:03:02 +0800 (CST)
Subject: [R] splm/spgm : How to specify the instrumental variables for
 certain dependent variable ?
Message-ID: <1ad3c187.2941.15a503ee25e.Coremail.zkokia@163.com>

spgm(formula, data=list(), index=NULL, listw =NULL, listw2 = NULL,
model=c("within","random"), lag = FALSE, spatial.error=TRUE,
moments = c("initial", "weights", "fullweights"), endog = NULL,
instruments= ~ X1 + X2, lag.instruments = FALSE, verbose = FALSE,
method = c("w2sls", "b2sls", "g2sls", "ec2sls"), control = list(),
optim.method = "nlminb", pars = NULL)


Here's where I'm stuck in R:
I need to use the instruments= ~ X1 + X2 as only one of my dependent variable,
in stata, the code can be written as :
    ivreg2 Y x1 x2 x3 ...( xn = IV_1 + IV_2 ),gmm2s robust
now in R,  how can I specify the instrumental variables for my certain dependent variable?
Thanks.






	[[alternative HTML version deleted]]


From dusa.adrian at unibuc.ro  Sat Feb 18 21:19:15 2017
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Sat, 18 Feb 2017 22:19:15 +0200
Subject: [R] A strange arithmetic error in R (maybe a bug)
In-Reply-To: <686E9826-AE82-4C38-8831-1A12B1DEB00E@me.com>
References: <686E9826-AE82-4C38-8831-1A12B1DEB00E@me.com>
Message-ID: <CAJ=0CtB3H39io=Vzt2wu328W41KJ+ogUrb=7=X5DYeEGHHyOkQ@mail.gmail.com>

There is no bug, of course, this is a common floating point arithmetic
misunderstanding.

> print(2.01, digits = 20)
[1] 2.0099999999999997868

Please search for "What every scientist should know about floating-point
arithmetic" and you'll hopefully understand what the "bug" is.

Hth,
Adrian



On Sat, Feb 18, 2017 at 6:18 AM, T. Zhang <tz05 at me.com> wrote:

> Hello,
>
> Today I happened to notice a strange error in R. If you type
> (2.01-0.06)==1.95, output from R is ?FALSE?, which is wrong. But if you
> type (1.01-0.06)==0.95, output is ?TRUE?, which is correct. I tested this
> in two systems: R 3.3.2 in my iMac and R 3.2.0 on my school?s Linux server.
> Both gave same outputs. As shown in the following:
>
> > 2.01-0.06
> [1] 1.95
> > (2.01-0.06)==1.95  # should be TRUE; output is wrong
> [1] FALSE
> > 1.01-0.06
> [1] 0.95
> > (1.01-0.06)==0.95  # should be TRUE; output is correct
> [1] TRUE
> > (2.01-0.06)>1.95  # should be FALSE; output is correct
> [1] FALSE
> > (2.01-0.06)<1.95  # should be FALSE; output is wrong
> [1] TRUE
>
> Similar errors could be found with simple alterations of the above inputs,
> such as:
> > 5.533-5.412
> [1] 0.121
> > (5.533-5.412)==0.121  # should be TRUE; output is wrong
> [1] FALSE
> > 2.533-2.412
> [1] 0.121
> > (2.533-2.412)==0.121  # should be TRUE; output is correct
> [1] TRUE
>
> Could any of you test whether you have same outputs as mine? And does
> anyone know what is wrong with these? My guess is that R has a bug in
> processing double numbers. Thanks!
>
> TZ
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr. 90-92
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sat Feb 18 21:35:03 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 18 Feb 2017 21:35:03 +0100
Subject: [R] A strange arithmetic error in R (maybe a bug)
In-Reply-To: <686E9826-AE82-4C38-8831-1A12B1DEB00E@me.com>
References: <686E9826-AE82-4C38-8831-1A12B1DEB00E@me.com>
Message-ID: <6DA8FE3D-A1A3-4891-8DFA-40B26CF94854@xs4all.nl>


> On 18 Feb 2017, at 05:18, T. Zhang <tz05 at me.com> wrote:
> 
> Hello,
> 
> Today I happened to notice a strange error in R. If you type (2.01-0.06)==1.95, output from R is ?FALSE?, which is wrong. But if you type (1.01-0.06)==0.95, output is ?TRUE?, which is correct. I tested this in two systems: R 3.3.2 in my iMac and R 3.2.0 on my school?s Linux server. Both gave same outputs. As shown in the following:
> 
>> 2.01-0.06
> [1] 1.95
>> (2.01-0.06)==1.95  # should be TRUE; output is wrong
> [1] FALSE
>> 1.01-0.06
> [1] 0.95
>> (1.01-0.06)==0.95  # should be TRUE; output is correct
> [1] TRUE
>> (2.01-0.06)>1.95  # should be FALSE; output is correct
> [1] FALSE
>> (2.01-0.06)<1.95  # should be FALSE; output is wrong
> [1] TRUE
> 
> Similar errors could be found with simple alterations of the above inputs, such as:
>> 5.533-5.412
> [1] 0.121
>> (5.533-5.412)==0.121  # should be TRUE; output is wrong
> [1] FALSE
>> 2.533-2.412
> [1] 0.121
>> (2.533-2.412)==0.121  # should be TRUE; output is correct
> [1] TRUE
> 
> Could any of you test whether you have same outputs as mine? And does anyone know what is wrong with these? My guess is that R has a bug in processing double numbers. Thanks!
> 

Not a bug. See the R FAQ section 7.31.

Berend Hasselman

> TZ
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Feb 18 22:25:03 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 18 Feb 2017 13:25:03 -0800
Subject: [R] Graph and Compare Distributions
In-Reply-To: <2100336859.366203.1487434899716@mail.yahoo.com>
References: <2100336859.366203.1487434899716.ref@mail.yahoo.com>
	<2100336859.366203.1487434899716@mail.yahoo.com>
Message-ID: <3D138418-F16E-4749-88EE-AACA2C5F4EB0@dcn.davis.ca.us>

Please post your code. Read the Posting Guide, which points out that you need to put the code in the body of your email and make sure the email is sent in plain text format (a setting in your mail software).

This is not a "do your work for you" mailing list. 
-- 
Sent from my phone. Please excuse my brevity.

On February 18, 2017 8:21:39 AM PST, Vasilis Bardakos <gratebill at yahoo.gr> wrote:
>Dear Sirs,
>I'm trying to demonstrate and compare my data first digit distributions
>in comparison with benford's law, but I cannot figure out how do a
>correct ggplot histogram. plot() works fine though.
>The data are the following (probabilities):
>[1] 0.37101911 0.17515924 0.08917197 0.08121019 0.06210191 0.06050955
>0.07484076 0.03662420 0.04936306
>[2] 0.524419536 0.253002402 0.092073659 0.032826261 0.025620496
>0.019215372 0.008807046 0.012009608 0.032025620
>
>These are my data first digit probabilities, while below there is the
>original distribution which would be represented with a smooth line:
>[3] 0.30103000 0.17609126 0.12493874 0.09691001 0.07918125 0.06694679
>0.05799195 0.05115252 0.04575749
>
>Kind Regards,V. Bardakos
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From acefix at rocketmail.com  Sat Feb 18 22:55:04 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Sat, 18 Feb 2017 21:55:04 +0000 (UTC)
Subject: [R] [FORGED] Re:  get() return nothing
In-Reply-To: <D1F3FBE5-0D02-4A35-A68C-FC84FF5703A2@bigelow.org>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<1718993451.2837139.1485682314808@mail.yahoo.com>
	<1020994841.500566.1486837984563@mail.yahoo.com>
	<8f6e9c10-be6b-c6de-6120-ae9c0d385d38@gmail.com>
	<1620966806.3423620.1487004628401@mail.yahoo.com>
	<2b2d3c83-e6ca-3886-cd8f-3c53f462c992@auckland.ac.nz>
	<D1F3FBE5-0D02-4A35-A68C-FC84FF5703A2@bigelow.org>
Message-ID: <666569797.252791.1487454904539@mail.yahoo.com>

Thank you very much for the information! I will try it!
Ace 

    On Tuesday, February 14, 2017 8:48 AM, Ben Tupper <btupper at bigelow.org> wrote:
 

 Hi,

When you want to get 'something' out of a loop you need to assign that 'something' to a variable that persists outside of the loop. I think it is a scoping thing. In your situation you could create a list with as many elements as there are objects with 'txt' in their names.? I can't quite follow what is is you are after, but perhaps something like this (untested and I'm still on my first cup of coffee) ...

obj_names <- ls(pattern="txt")
obj_dims <- vector(mode = 'list', length = length(obj_names))
names(obj_dims) <- obj_names
for (nm in obj_names)){
? ? obj_dims[[nm]] <- dim(get(nm)) 
}

Does that do what you want?? If so, you could probably use lapply() for the purpose instead of the for loop, but even better is to store each of your objects in a list as you create them rather than letting them get loose in the global environment.? That way you don't have to do this get-by-name rodeo to get info on them.

Cheers,
Ben



> On Feb 14, 2017, at 2:57 AM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 14/02/17 05:50, Fix Ace via R-help wrote:
> 
>> Well, I am not trying to print anything. I just would like to get the dimension information for all the dataframes I created. Could you please help me to develop the script?
>> Thanks.
>> Ace
> 
> Yes you *are* trying to print something.? You are trying to print the dimension information, i.e. dim(get(i))!!! For Pete's sake (a) *think* about what you are doing and (b) *try* example that Duncan suggested to you.
> 
> cheers,
> 
> Rolf Turner
>> 
>>? ? On Saturday, February 11, 2017 7:53 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> 
>> On 11/02/2017 1:33 PM, Fix Ace via R-help wrote:
>>> Hello, there,
>>> I wrote a loop to check the dimension of all the .txt dataframes:> ls()
>>>? [1] "actualpca.table" "b4galnt2"? ? ? ? "b4galnt2.txt"? ? "data"
>>>? [5] "galnt4"? ? ? ? ? "galnt4.txt"? ? ? "galnt5"? ? ? ? ? "galnt5.txt"
>>>? [9] "galnt6"? ? ? ? ? "galnt6.txt"? ? ? "glyco"? ? ? ? ? "glyco.txt"
>>> [13] "i"? ? ? ? ? ? ? "mtscaled"? ? ? ? "newsig.table"? ? "nicepca"
>>> [17] "pca"? ? ? ? ? ? "sig.txt"? ? ? ? "st3gal3"? ? ? ? "st3gal3.txt"
>>> [21] "st3gal5"? ? ? ? "st3gal5.txt"? ? "st6gal1"? ? ? ? "st6gal1.txt"
>>>> for(i in ls(pattern="txt")){dim(get(i))}
>>>> 
>>> If I check individual ones, they are ok:
>>>> dim(get("galnt4.txt"))
>>> [1] 8 3
>>>> 
>>> could anyone help me to figure out why it did not work with a loop?
>>> Thanks a lot!
>> 
>> It's the difference between
>> 
>> for (i in 1:10) i
>> 
>> (which prints nothing) and
>> 
>> for (i in 1:10) print(i)
>> 
>> Duncan Murdoch
>> 
>> 
>> 
>> 
>> ??? [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org




   
	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Sun Feb 19 14:13:51 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sun, 19 Feb 2017 13:13:51 +0000
Subject: [R] irf in vars package
Message-ID: <23d178ae296641d0a788f74fd2b5bfda@ex13-live-mbn1.ad.kent.ac.uk>

Dear all,
I am trying to replicate the Canada example in the vars vignette. Unfortunately, the irf() does not work. R returns following error:
unused arguments (response = "U", n.ahead = 48, boot = TRUE)

Why is the example not working?

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Sun Feb 19 14:35:53 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Sun, 19 Feb 2017 13:35:53 +0000
Subject: [R] lmtest package - Difference between vcov and vcov.
Message-ID: <1487511353457.30683@kent.ac.uk>

Dear all,

I want to run a regression using coeftest() in combination with the waldtest() function from the lmtest package. I am confused about the argument vcov. The coeftest uses vcov. whereas according to the manual waldtest uses vcov and I am not sure about the difference between vcov. in coeftest() and vcov in waldtest().

If I use vcov. and vcov in the waldtest, I get different results for the F-test and the p-value. In addition, vcov. returns an error message that for numeric model specifications all values have to be >=1. The sandwich package vignette (e.g. p. 10) uses vcov = ... as argument in the coeftest() function.



Hence, my question is which argument to use in the both functions coeftest() and waldtest(). Shall I use vcov. in coeftest() and vcov in waldtest() or should I use vcov in both functions?



I kindly ask for your help.



Thanks in advance.



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Feb 19 15:41:29 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 19 Feb 2017 06:41:29 -0800
Subject: [R] irf in vars package
In-Reply-To: <23d178ae296641d0a788f74fd2b5bfda@ex13-live-mbn1.ad.kent.ac.uk>
References: <23d178ae296641d0a788f74fd2b5bfda@ex13-live-mbn1.ad.kent.ac.uk>
Message-ID: <C44AFAA2-586D-4706-89BD-9DBE562BA8B8@dcn.davis.ca.us>

Hard to say, since you did not tell us what you did per the Posting Guide.  Did you read footnote 4?
-- 
Sent from my phone. Please excuse my brevity.

On February 19, 2017 5:13:51 AM PST, "T.Riedle" <tr206 at kent.ac.uk> wrote:
>Dear all,
>I am trying to replicate the Canada example in the vars vignette.
>Unfortunately, the irf() does not work. R returns following error:
>unused arguments (response = "U", n.ahead = 48, boot = TRUE)
>
>Why is the example not working?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lal.prasad at gmail.com  Sun Feb 19 15:48:51 2017
From: lal.prasad at gmail.com (Lal Prasad)
Date: Sun, 19 Feb 2017 20:18:51 +0530
Subject: [R] Seasonality of VAR + Inventory Management Packages
Message-ID: <CACuGqa+Q1NpsE7TbZ7Ji7dGFP0hT5gfoXNdH0S0+UUrUeisi2Q@mail.gmail.com>

Hi All,

Could you help me with the below questions on VAR Model and Inventory
Management/Supply Chain related models in R.

1)Could you let me know if VAR model will work with multivariate time
series with Seasonality?

2)Anything needs to be done explicitly for VAR to handle seasonality and
random components of the constituent timeseries(s)?

3)What are the other multivariate time series similar to VAR model?

4) Are there any R packages that supports Inventory Management other than
SCPerf and InventoryModelPackage? I'm looking for implementing inventory
optimization using R. Any leads/sample code could be helpful for me.

Regards
Lal

	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Sun Feb 19 14:17:42 2017
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sun, 19 Feb 2017 18:47:42 +0530
Subject: [R] Forecasting using VECM
In-Reply-To: <CAGxFJbSdmJ7hVRii75+hwWewpsUkyf=9rO58+iDCs8J_xe8-bw@mail.gmail.com>
References: <CAHVFrXF1PfPAGtCWPxA+zoqQFAEPEwyJTtJwRrD5owSo5whuYg@mail.gmail.com>
	<CAGxFJbSdmJ7hVRii75+hwWewpsUkyf=9rO58+iDCs8J_xe8-bw@mail.gmail.com>
Message-ID: <CAHVFrXF3N=kmcHLDDd1fG5iyonusvab_32SyyMMbVnMXhJi7Gg@mail.gmail.com>

Hey Bert,
The predict function in the link you mentioned does not seem to use
independently generated future values of the variables cpiUSA and cpiCAN in
calculating the future values of the variable of interest, i.e. dolCAN. As
I mentioned in the mail, I have the future cpiUSA and cpiCAN values
externally given to me (instead of generated by VECM), which I need to
use.Let me know if this explains what I am trying to get here. Thanks.
Regards,
Preetam

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Feb 19 19:20:49 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 19 Feb 2017 10:20:49 -0800
Subject: [R] Forecasting using VECM
In-Reply-To: <CAHVFrXF3N=kmcHLDDd1fG5iyonusvab_32SyyMMbVnMXhJi7Gg@mail.gmail.com>
References: <CAHVFrXF1PfPAGtCWPxA+zoqQFAEPEwyJTtJwRrD5owSo5whuYg@mail.gmail.com>
	<CAGxFJbSdmJ7hVRii75+hwWewpsUkyf=9rO58+iDCs8J_xe8-bw@mail.gmail.com>
	<CAHVFrXF3N=kmcHLDDd1fG5iyonusvab_32SyyMMbVnMXhJi7Gg@mail.gmail.com>
Message-ID: <8A8D8F57-AD67-472E-BD35-AA31A24E5562@dcn.davis.ca.us>

It will if you use it properly. Have you read the help for that function? You didn't show your code, and you didn't post your email using plain text, so we can't help much here. 
-- 
Sent from my phone. Please excuse my brevity.

On February 19, 2017 5:17:42 AM PST, Preetam Pal <lordpreetam at gmail.com> wrote:
>Hey Bert,
>The predict function in the link you mentioned does not seem to use
>independently generated future values of the variables cpiUSA and
>cpiCAN in
>calculating the future values of the variable of interest, i.e. dolCAN.
>As
>I mentioned in the mail, I have the future cpiUSA and cpiCAN values
>externally given to me (instead of generated by VECM), which I need to
>use.Let me know if this explains what I am trying to get here. Thanks.
>Regards,
>Preetam
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sun Feb 19 20:37:13 2017
From: tmrsg11 at gmail.com (C W)
Date: Sun, 19 Feb 2017 14:37:13 -0500
Subject: [R] Confused about using data.table package,
Message-ID: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>

Hi R,

I am a little confused by the data.table package.

library(data.table)

df <- data.frame(w=rnorm(20, -10, 1), x= rnorm(20, 0, 1), y=rnorm(20, 10, 1),
z=rnorm(20, 20, 1))

df <- data.table(df)

#drop column w

df_1 <- df[, w := NULL] # I thought you are supposed to do: df_1 <- df[, -w]

df_2 <- df[x<y] # aren't you supposed to do df_2 <- df[x<y]?

df_3 <- df[, a := x-y] # created new column a using x minus y, why are we
using colon equals?

I am a bit confused by this syntax.

Thanks!

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Sun Feb 19 20:39:56 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 19 Feb 2017 20:39:56 +0100 (CET)
Subject: [R] lmtest package - Difference between vcov and vcov.
In-Reply-To: <1487511353457.30683@kent.ac.uk>
References: <1487511353457.30683@kent.ac.uk>
Message-ID: <alpine.DEB.2.20.1702192034510.15295@paninaro>

On Sun, 19 Feb 2017, T.Riedle wrote:

> Dear all,
>
> I want to run a regression using coeftest() in combination with the 
> waldtest() function from the lmtest package. I am confused about the 
> argument vcov. The coeftest uses vcov. whereas according to the manual 
> waldtest uses vcov and I am not sure about the difference between vcov. 
> in coeftest() and vcov in waldtest().

In both cases this is intended to be used as "vcov = ..." by the end-user, 
e.g., "vcov = sandwich" etc. The reason why "vcov." rather than "vcov" was 
used was to avoid name confusions in pre-NAMESPACE times.

The 'trick' with vcov. (rather than vcov) could not be used in waldtest() 
because that always requires exact matching due to the preceeding ... 
argument..

> If I use vcov. and vcov in the waldtest, I get different results for the 
> F-test and the p-value. In addition, vcov. returns an error message that 
> for numeric model specifications all values have to be >=1.

Yes, because then the specification goes into '...' rather than 'vcov' and 
is interpreted as a rule for model updating. This cannot work, though.

> The sandwich package vignette (e.g. p. 10) uses vcov = ... as argument 
> in the coeftest() function.
>
>
> Hence, my question is which argument to use in the both functions coeftest() and waldtest(). Shall I use vcov. in coeftest() and vcov in waldtest() or should I use vcov in both functions?
>
>
>
> I kindly ask for your help.
>
>
>
> Thanks in advance.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sun Feb 19 22:01:36 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 19 Feb 2017 13:01:36 -0800
Subject: [R] Confused about using data.table package,
In-Reply-To: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>
References: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>
Message-ID: <F2C4B71E-3912-4BF8-9870-2ADCA5BB53EE@comcast.net>


> On Feb 19, 2017, at 11:37 AM, C W <tmrsg11 at gmail.com> wrote:
> 
> Hi R,
> 
> I am a little confused by the data.table package.
> 
> library(data.table)
> 
> df <- data.frame(w=rnorm(20, -10, 1), x= rnorm(20, 0, 1), y=rnorm(20, 10, 1),
> z=rnorm(20, 20, 1))
> 
> df <- data.table(df)

  df <- setDT(df) is preferred.
> 
> #drop column w
> 
> df_1 <- df[, w := NULL] # I thought you are supposed to do: df_1 <- df[, -w]

Nope. The "[.data.table" function is very different from the "[.data.frame' function. As you should be able to see, an expression in the `j` position for "[.data.table" gets evaluated in the environment of the data.table object, so unquoted column names get returned after application of any function. Here it's just a unary minus. 

Actually "nope" on two accounts. You cannot use a unary minus for column names in `[.data.frame` either. Would have needed to be df[ , !colnames(df) in "w"]  # logical indexing


> 
> df_2 <- df[x<y] # aren't you supposed to do df_2 <- df[x<y]?

I don't see a difference. 

> 
> df_3 <- df[, a := x-y] # created new column a using x minus y, why are we
> using colon equals?

You need to do more study of the extensive documentation. The behavior of the ":=" function is discussed in detail there.

> 
> I am a bit confused by this syntax.

It's non-standard for R but many people find the efficiencies of the package worth the extra effort to learn what is essentially a different evaluation strategy.


> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]

Rhelp is a plain text mailing list,

-- 
David
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tr206 at kent.ac.uk  Mon Feb 20 13:46:50 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Mon, 20 Feb 2017 12:46:50 +0000
Subject: [R] vars package - irf() does not work
Message-ID: <1487594810802.89921@kent.ac.uk>

Dear all,


I want to run an impulse response analysis using the vars() package. The code looks as follwows.


# list of class varest
varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type = "both")

varest.USA

summary(varest.USA)



#Run irf analysis
irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)

plot(irf.USAg)


The problem is that R returns an error that the arguments in irf are unused. That is, unused arguments (response="g", n.ahead = 48, boot = TRUE, ci=0.95)
The strangeness is that it sometimes works but most of the time it does not. I installed vars() last month and irf() worked well but now it does only occasionally. I have just edited the data but kept the code unchanged.


In addition, I have the same problem when I am trying to replicate the example on irf() in the vars vignette althoug it also worked well when I installed vars and run the example.


Does anybody have an idea what is wrong?







	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Feb 20 14:31:49 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Feb 2017 14:31:49 +0100
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
Message-ID: <22698.61381.171017.453325@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Tue, 14 Feb 2017 17:10:05 -0800 writes:

    > Hi, tapply() will work on any object 'X' that has a length
    > and supports single-bracket subsetting. These objects are
    > sometimes called "vector-like" objects. Atomic vectors,
    > lists, S4 objects with a "length" and "[" method,
    > etc... are examples of "vector-like" objects.

    > So instead of saying

    >    X: an atomic object, typically a vector.

    > I think it would be more accurate if the man page was
    > saying something like

    >    X: a vector-like object that supports subsetting with
    > `[`, typically an atomic vector.

Thank you, Herv?!

Actually (someone else mentioned ?)
only   length(X) and  split(X, <group>)   need to work,
and as split() itself is an S3 generic function,  X can be even
more general... well depending on how exactly you understand
"vector-like".

So I would go with

       X: an R object for which a ?split? method exists.  Typically
          vector-like, allowing subsetting with ?[?.


Martin


    > H.

    > On 02/04/2017 04:17 AM, Tal Galili wrote:
    >> In the help page of ?tapply it says that the first
    >> argument (X) is "an atomic object, typically a vector."
    >> 
    >> However, tapply seems to be able to handle list
    >> objects. For example:
    >> 
    >> ###################
    >> 
    >> l <- as.list(1:10) is.atomic(l) # FALSE index <-
    >> c(rep(1,5),rep(2,5)) tapply(l,index,unlist)
    >> 
    >>> tapply(l,index,unlist)
    >> $`1` [1] 1 2 3 4 5
    >> 
    >> $`2` [1] 6 7 8 9 10
    >> 
    >> 
    >> ###################
    >> 
    >> Hence, does it mean a list an atomic object? (which I
    >> thought it wasn't) or is the help for tapply needs
    >> updating?  (or some third option I'm missing?)
    >> 
    >> Thanks.


From maechler at stat.math.ethz.ch  Mon Feb 20 15:15:27 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 20 Feb 2017 15:15:27 +0100
Subject: [R] R scripts attached to e-mails - correct MIME type ?!
In-Reply-To: <58A85056.3000804@sapo.pt>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
Message-ID: <22698.63999.756178.367552@stat.math.ethz.ch>

>>>>> Rui Barradas <ruipbarradas at sapo.pt>
>>>>>     on Sat, 18 Feb 2017 13:47:02 +0000 writes:

    > Helo, No attachment came through. Change the file
    > extension from .R to .txt and resend, there aren't many
    > types of files r-help accepts.

    > Rui Barradas


As a matter of fact, one would have to blame the e-mail program
you use.  The file extension is *not* equivalent to the file
type, and the mailing list software accepts the (MIME) type  text/plain
and a couple of others.

The problem with most modern e-mail clients/programs/apps/... is that
they use something you could translate as  "unknown binary format" 
as type for their attachments if they can't guess the correct
file type from the file extension.
It would be interesting to know (for me) if there are modern
e-mail programs / web apps which you could *teach* about the
mime type, e.g., for all files ending with extension '.R'...

Martin Maechler
ETH Zurich, Seminar fuer Statistik,
== the provider of all the (standard) R mailing lists.


    > Em 17-02-2017 17:20, Allan Tanaka escreveu:
    >> ....
    >> ....  See attached for R script


From ruipbarradas at sapo.pt  Mon Feb 20 15:45:56 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 20 Feb 2017 14:45:56 +0000
Subject: [R] R scripts attached to e-mails - correct MIME type ?!
In-Reply-To: <22698.63999.756178.367552@stat.math.ethz.ch>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>	<2116363132.1334313.1487352008288@mail.yahoo.com>	<58A85056.3000804@sapo.pt>
	<22698.63999.756178.367552@stat.math.ethz.ch>
Message-ID: <58AB0124.7080908@sapo.pt>

Hello,

I use Mozilla Thunderbird and I don't see a way of teaching it about the 
mime type.
My understanding is that files with the .R extension are eliminated by 
the r-help mail server, but .txt pass. Is this correct?

Rui Barradas

Em 20-02-2017 14:15, Martin Maechler escreveu:
>>>>>> Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>      on Sat, 18 Feb 2017 13:47:02 +0000 writes:
>
>      > Helo, No attachment came through. Change the file
>      > extension from .R to .txt and resend, there aren't many
>      > types of files r-help accepts.
>
>      > Rui Barradas
>
>
> As a matter of fact, one would have to blame the e-mail program
> you use.  The file extension is *not* equivalent to the file
> type, and the mailing list software accepts the (MIME) type  text/plain
> and a couple of others.
>
> The problem with most modern e-mail clients/programs/apps/... is that
> they use something you could translate as  "unknown binary format"
> as type for their attachments if they can't guess the correct
> file type from the file extension.
> It would be interesting to know (for me) if there are modern
> e-mail programs / web apps which you could *teach* about the
> mime type, e.g., for all files ending with extension '.R'...
>
> Martin Maechler
> ETH Zurich, Seminar fuer Statistik,
> == the provider of all the (standard) R mailing lists.
>
>
>      > Em 17-02-2017 17:20, Allan Tanaka escreveu:
>      >> ....
>      >> ....  See attached for R script
>


From lpfgarcia at gmail.com  Mon Feb 20 12:18:34 2017
From: lpfgarcia at gmail.com (=?UTF-8?Q?Lu=C3=ADs_Paulo_F=2E_Garcia?=)
Date: Mon, 20 Feb 2017 08:18:34 -0300
Subject: [R] [R-pkgs]  Announcing mfe 0.1.0
Message-ID: <CAPK6mFqS5j6OszPH+-W7MDKxrDt_5xwHO1yD4px73Van0z3zcA@mail.gmail.com>

Dear R users,

I am pleased to announce that the package mfe (Meta-Feature Extractor) is
now
available on CRAN (https://cran.r-project.org/package=mfe).

The mfe package extracts meta-features from datasets to support the design
of
recommendation systems based on Meta-Learning. The meta-features, also
called
characterization measures, are able to characterize the complexity of
datasets
and to provide estimates of algorithm performance. The package contains not
only the standard characterization measures, but also more recent
characterization measures.

Please, visit the repository on GitHub (https://github.com/rivolli/mfe) or
the
Vignette (https://cran.r-project.org/web/packages/mfe/vignettes/
mfe-vignette.html)
for more information.

Kind regards,
Luis

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From g.wieteska at yahoo.ie  Mon Feb 20 16:26:43 2017
From: g.wieteska at yahoo.ie (Malgorzata Wieteska)
Date: Mon, 20 Feb 2017 15:26:43 +0000 (UTC)
Subject: [R] optimisation of the system of differential equations
References: <297758535.2154902.1487604403971.ref@mail.yahoo.com>
Message-ID: <297758535.2154902.1487604403971@mail.yahoo.com>


I try to do optimisation of the system of the differential equations. I've managed to make my exemplary code working, however after changing equations on the exact model and data on the real one, I get an error messages and code doesn't work.
I have a partial data for L (concentrations were assessed only for 3 days, the cycle lasted 24. My data for external variables (concentrations) of 2 other variables cE and cP have more datapoints (cP was assessed on each day)
I couldn't fit more parameters than number of equations (excluded parameters for the initial values, which weren't assessed, so I try to get them as a result ?of parameterisation). The most sensitive parameters were labelled as k1 and k2, the values for other were derived from the literature and embedded in the system of equations.
I've attached my code. Thanks in advance for any hint why this code doesn't work or information were I can find examples for optimisation of the similar system of the equations.
Kind Regards,Malgorzata

From jdnewmil at dcn.davis.ca.us  Mon Feb 20 16:48:58 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 20 Feb 2017 07:48:58 -0800
Subject: [R] optimisation of the system of differential equations
In-Reply-To: <297758535.2154902.1487604403971@mail.yahoo.com>
References: <297758535.2154902.1487604403971.ref@mail.yahoo.com>
	<297758535.2154902.1487604403971@mail.yahoo.com>
Message-ID: <599F9436-2805-4E25-B22D-15DBE61C2472@dcn.davis.ca.us>

Go back and read the Posting Guide.

1) Missing code. Only certain types of attachments get through, and the recommendation is to include everything in the body of the email. Whatever you did,  it did not get through to us. 

2) Please make it clear what results you obtained and what results you expected. This is not the "do your research for you" mailing list, so please keep your question focused on how R does things, not on whether your theory is correct. 
-- 
Sent from my phone. Please excuse my brevity.

On February 20, 2017 7:26:43 AM PST, Malgorzata Wieteska via R-help <r-help at r-project.org> wrote:
>
>I try to do optimisation of the system of the differential equations.
>I've managed to make my exemplary code working, however after changing
>equations on the exact model and data on the real one, I get an error
>messages and code doesn't work.
>I have a partial data for L (concentrations were assessed only for 3
>days, the cycle lasted 24. My data for external variables
>(concentrations) of 2 other variables cE and cP have more datapoints
>(cP was assessed on each day)
>I couldn't fit more parameters than number of equations (excluded
>parameters for the initial values, which weren't assessed, so I try to
>get them as a result ?of parameterisation). The most sensitive
>parameters were labelled as k1 and k2, the values for other were
>derived from the literature and embedded in the system of equations.
>I've attached my code. Thanks in advance for any hint why this code
>doesn't work or information were I can find examples for optimisation
>of the similar system of the equations.
>Kind Regards,Malgorzata
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Mon Feb 20 17:04:58 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 20 Feb 2017 10:04:58 -0600
Subject: [R] Is a list an atomic object? (or is there an issue with the
 help page of ?tapply ?)
In-Reply-To: <22698.61381.171017.453325@stat.math.ethz.ch>
References: <CANdJ3dXLR7HorCfXTvXJN33FoNGmzGoZ6S+YBE2qvVy9xYKnnQ@mail.gmail.com>
	<8b3e683e-020c-7e86-53d9-76ede45764d5@fredhutch.org>
	<22698.61381.171017.453325@stat.math.ethz.ch>
Message-ID: <CABdHhvHWHipshhuKc9GsMZoc-NzrgYOk9wnaDMTE=1XPtWny4Q@mail.gmail.com>

On Mon, Feb 20, 2017 at 7:31 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>>     on Tue, 14 Feb 2017 17:10:05 -0800 writes:
>
>     > Hi, tapply() will work on any object 'X' that has a length
>     > and supports single-bracket subsetting. These objects are
>     > sometimes called "vector-like" objects. Atomic vectors,
>     > lists, S4 objects with a "length" and "[" method,
>     > etc... are examples of "vector-like" objects.
>
>     > So instead of saying
>
>     >    X: an atomic object, typically a vector.
>
>     > I think it would be more accurate if the man page was
>     > saying something like
>
>     >    X: a vector-like object that supports subsetting with
>     > `[`, typically an atomic vector.
>
> Thank you, Herv?!
>
> Actually (someone else mentioned ?)
> only   length(X) and  split(X, <group>)   need to work,
> and as split() itself is an S3 generic function,  X can be even
> more general... well depending on how exactly you understand
> "vector-like".
>
> So I would go with
>
>        X: an R object for which a ?split? method exists.  Typically
>           vector-like, allowing subsetting with ?[?.

I think technically tapply() should be using NROW() check that X and
INDEX are compatible. That would make it more compatible with split()
semantics.

Hadley

-- 
http://hadley.nz


From h.wickham at gmail.com  Mon Feb 20 17:12:23 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 20 Feb 2017 10:12:23 -0600
Subject: [R] Confused about using data.table package,
In-Reply-To: <F2C4B71E-3912-4BF8-9870-2ADCA5BB53EE@comcast.net>
References: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>
	<F2C4B71E-3912-4BF8-9870-2ADCA5BB53EE@comcast.net>
Message-ID: <CABdHhvGrs4JJszrRQzORR+ZAi24Dt-2tHu2gqOnZoE6PRRz2jg@mail.gmail.com>

On Sun, Feb 19, 2017 at 3:01 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Feb 19, 2017, at 11:37 AM, C W <tmrsg11 at gmail.com> wrote:
>>
>> Hi R,
>>
>> I am a little confused by the data.table package.
>>
>> library(data.table)
>>
>> df <- data.frame(w=rnorm(20, -10, 1), x= rnorm(20, 0, 1), y=rnorm(20, 10, 1),
>> z=rnorm(20, 20, 1))
>>
>> df <- data.table(df)
>
>   df <- setDT(df) is preferred.

Don't you mean just

setDT(df)

?

setDT() modifies by reference.

>>
>> df_3 <- df[, a := x-y] # created new column a using x minus y, why are we
>> using colon equals?
>
> You need to do more study of the extensive documentation. The behavior of the ":=" function is discussed in detail there.

You can get to that documentation with ?":="

Hadley

-- 
http://hadley.nz


From G.Maubach at weinwolf.de  Mon Feb 20 17:33:17 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 20 Feb 2017 17:33:17 +0100
Subject: [R] packrat: Failed to download current version of foreign(0.8-67)
Message-ID: <OF55ED1198.A075078E-ONC12580CD.005AD5C0-C12580CD.005AF05A@lotus.hawesko.de>

Hi All,

I tried to use packrat on

R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Germany.1252 
[2] LC_CTYPE=German_Germany.1252 
[3] LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C 
[5] LC_TIME=German_Germany.1252 

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods 
[7] base 

other attached packages:
[1] packrat_0.4.8-1

loaded via a namespace (and not attached):
[1] tools_3.3.2

Due to internal firewall restrictions the package "foreign" could not be 
downloaded as source. I assume that the package also contains some binary 
parts which will be blocked by the firewall.

When running packrat a directory "packrat" and a file called .Rprofile 
were created in the project directory. A lot of library sources were 
download, but not for "foreign".

After finishing the process the directory "packrat" and the file .Rprofile 
were deleted from the project directory.

Why is that? Just one source library missing and the whole directory is 
gone? Having all libraries for my project without just one is better than 
none!

How can I use packrat with the missing library "foreign"?

Kind regards

Georg


From G.Maubach at weinwolf.de  Mon Feb 20 17:35:32 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 20 Feb 2017 17:35:32 +0100
Subject: [R] Antwort: Re:  RStudio: Place for Storing Options
In-Reply-To: <22684.34149.431821.945334@stat.math.ethz.ch>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
	<22684.34149.431821.945334@stat.math.ethz.ch>
Message-ID: <OFDBBBDB7B.DDA2BAEE-ONC12580CD.005AFDE4-C12580CD.005B2528@lotus.hawesko.de>

Hi Martin,
Hi Ulrik,

I am still working on the answer. I got a message from RStudio team but I 
am still working on the clearification of the answer and a possible 
solution.

Kind regards

Georg




Von:    Martin Maechler <maechler at stat.math.ethz.ch>
An:     <G.Maubach at weinwolf.de>, 
Kopie:  Ulrik Stervbo <ulrik.stervbo at gmail.com>, R-help mailing list 
<r-help at r-project.org>
Datum:  09.02.2017 16:05
Betreff:        Re: [R] RStudio: Place for Storing Options




>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>>>>     on Thu, 9 Feb 2017 14:37:57 +0000 writes:

    > Hi Georg,
    > maybe someone here knows, but I think you are more likely to get 
answers to
    > Rstudio related questions with RStudio support:
    > https://support.rstudio.com/hc/en-us

    > Best,
    > Ulrik

Indeed, thank you, Ulrik.

In this special case, however, I'm quite sure many readers of
R-help would be interested in the answer; so once you receive an
answer, please post it (or a link to a public URL with it) here
on R-help, thank you in advance.

We would like to be able to *save*, or sometimes *set* / *reset*
such options  "in a scripted manner", e.g. for
controlled exam sessions.

Martin Maechler,
ETH Zurich

    > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de> wrote:

    >> Hi All,
    >> I would like to make a backup of my RStudio IDE options I configure 
using 
    >> "Tools/Global Options" from the menu bar. Searching the
    >> web did not reveal anything.

    >> Can you tell me where RStudio IDE does store its configuration?

    >> Kind regards
    >> Georg


From dwinsemius at comcast.net  Mon Feb 20 17:50:15 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Feb 2017 08:50:15 -0800
Subject: [R] Confused about using data.table package,
In-Reply-To: <CABdHhvGrs4JJszrRQzORR+ZAi24Dt-2tHu2gqOnZoE6PRRz2jg@mail.gmail.com>
References: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>
	<F2C4B71E-3912-4BF8-9870-2ADCA5BB53EE@comcast.net>
	<CABdHhvGrs4JJszrRQzORR+ZAi24Dt-2tHu2gqOnZoE6PRRz2jg@mail.gmail.com>
Message-ID: <053E0866-BA5B-42FC-A9A5-F70971A19803@comcast.net>


> On Feb 20, 2017, at 8:12 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> 
> On Sun, Feb 19, 2017 at 3:01 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Feb 19, 2017, at 11:37 AM, C W <tmrsg11 at gmail.com> wrote:
>>> 
>>> Hi R,
>>> 
>>> I am a little confused by the data.table package.
>>> 
>>> library(data.table)
>>> 
>>> df <- data.frame(w=rnorm(20, -10, 1), x= rnorm(20, 0, 1), y=rnorm(20, 10, 1),
>>> z=rnorm(20, 20, 1))
>>> 
>>> df <- data.table(df)
>> 
>>  df <- setDT(df) is preferred.
> 
> Don't you mean just
> 
> setDT(df)
> 
> ?
> 
> setDT() modifies by reference.

Thanks for the correction.


> 
>>> 
>>> df_3 <- df[, a := x-y] # created new column a using x minus y, why are we
>>> using colon equals?
>> 
>> You need to do more study of the extensive documentation. The behavior of the ":=" function is discussed in detail there.
> 
> You can get to that documentation with ?":="

That's a good place to start reading, but I was thinking of data.table::datatable-faq, data.table::datatable-intro which are on the Vignettes page from: help(pac=data.table).

> 
> Hadley
> 
> -- 
> http://hadley.nz

David Winsemius
Alameda, CA, USA


From hannah.hlx at gmail.com  Mon Feb 20 18:14:57 2017
From: hannah.hlx at gmail.com (li li)
Date: Mon, 20 Feb 2017 12:14:57 -0500
Subject: [R] weighted sum of independent chi square random variables
Message-ID: <CAHLnndbKKrfYKyJYigwvf2-TJxnzq4OyavB-63sfcoUfjYMSrQ@mail.gmail.com>

Hi all,
   Is there a function in R that can calculate the quantiles or percentiles
for the weighted sum of independent chi square random variables. I found a
few functions for calculating probability distribution function for such
random variables (e.g. pchisqsum..), but can not find any function for
finding quantiles.
   Thanks in advance.
    Hanna

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Feb 20 18:31:00 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 20 Feb 2017 09:31:00 -0800
Subject: [R] weighted sum of independent chi square random variables
In-Reply-To: <CAHLnndbKKrfYKyJYigwvf2-TJxnzq4OyavB-63sfcoUfjYMSrQ@mail.gmail.com>
References: <CAHLnndbKKrfYKyJYigwvf2-TJxnzq4OyavB-63sfcoUfjYMSrQ@mail.gmail.com>
Message-ID: <CAGxFJbTGz25jr+paRnsvcdjPV=E0KFcEtabvYYbRO2QFek=M0A@mail.gmail.com>

The quantile function is just the inverse of the distribution function, so
if you have the latter you can always get the former, e.g by simple
interpolation using approx(). Assuming you can't find it already written
for you of course.

Bert





On Feb 20, 2017 7:15 AM, "li li" <hannah.hlx at gmail.com> wrote:

> Hi all,
>    Is there a function in R that can calculate the quantiles or percentiles
> for the weighted sum of independent chi square random variables. I found a
> few functions for calculating probability distribution function for such
> random variables (e.g. pchisqsum..), but can not find any function for
> finding quantiles.
>    Thanks in advance.
>     Hanna
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tkeitt at utexas.edu  Thu Feb 16 19:34:14 2017
From: tkeitt at utexas.edu (Tim Keitt)
Date: Thu, 16 Feb 2017 12:34:14 -0600
Subject: [R] [R-pkgs] CRAN updates: rpg and odeintr
Message-ID: <CANnL8go6tpwxXBMiLsKJamc2xQpD5ciar031X2xC-QTjzjQ+Fg@mail.gmail.com>

rpg is a package for working with postgresql: https://github.com/thk686/rpg
odeintr is a package for integrating differential equations:
https://github.com/thk686/odeintr

Cheers,
THK

http://www.keittlab.org/

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From giuliavalva89 at gmail.com  Mon Feb 20 10:02:14 2017
From: giuliavalva89 at gmail.com (Giulia Valvassori)
Date: Mon, 20 Feb 2017 10:02:14 +0100
Subject: [R] Linkage Disequilibrium for RADseq data with R
Message-ID: <CALn5NoqoQwcWesHCRDwgHopr=_rQhmy2JWMSjDX-tVfF9AesPQ@mail.gmail.com>

Dear all,

I would like to perform a Linkage Disequilibrium analysis on RADseq matrix.
Can anyone suggest me which R package and function should i use and which
kind of input file i should prepare?

Thank you in advance for your help and time.
Giulia

	[[alternative HTML version deleted]]


From luis.de.sousa at protonmail.ch  Mon Feb 20 14:41:12 2017
From: luis.de.sousa at protonmail.ch (=?UTF-8?Q?Lu=C3=AD=C2=ADs_Moreira_de_Sousa?=)
Date: Mon, 20 Feb 2017 08:41:12 -0500
Subject: [R] JRI: obtain error messages from the R engine
Message-ID: <QKbl_OM-1WUBkfci2GFuvFY4wZlLFLxozU7pZ2oab06n5Xc580eIOoubjcO9IdKKPHzpmf_O4qpM9_KDZoiM5A==@protonmail.ch>

Dear all,

I am using JRI to execute a number of computations using the R engine. As pointed in various tutorials out there in the web I am using the eval method of the Rengine class, e.g.:

engine.eval("meanVal=mean(rVector)");

At some point the eval method starts returning NULL, which according to the documentation means "something went wrong". However, I can not identify in the Rengine class a property or a method that would provide an error message, error status or R console output to identify the cause. Is there any way to obtain detailed information on what might be happening?



Thank you.

Lu?s
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Feb 20 19:45:18 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 20 Feb 2017 19:45:18 +0100
Subject: [R] R scripts attached to e-mails - correct MIME type ?!
In-Reply-To: <58AB0124.7080908@sapo.pt>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<22698.63999.756178.367552@stat.math.ethz.ch>
	<58AB0124.7080908@sapo.pt>
Message-ID: <EF3ECAA7-15BD-46FE-9DAA-12DCF45ABF9B@gmail.com>

Not by the mail server as such, no, at least not for that reason. However, T-bird likely sends .txt as text/plain and .R as application/octet-stream (or so) and _therefore_ the server eliminates the latter and lets the former pass.

-pd

> On 20 Feb 2017, at 15:45 , Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> I use Mozilla Thunderbird and I don't see a way of teaching it about the mime type.
> My understanding is that files with the .R extension are eliminated by the r-help mail server, but .txt pass. Is this correct?
> 
> Rui Barradas
> 
> Em 20-02-2017 14:15, Martin Maechler escreveu:
>>>>>>> Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>>     on Sat, 18 Feb 2017 13:47:02 +0000 writes:
>> 
>>     > Helo, No attachment came through. Change the file
>>     > extension from .R to .txt and resend, there aren't many
>>     > types of files r-help accepts.
>> 
>>     > Rui Barradas
>> 
>> 
>> As a matter of fact, one would have to blame the e-mail program
>> you use.  The file extension is *not* equivalent to the file
>> type, and the mailing list software accepts the (MIME) type  text/plain
>> and a couple of others.
>> 
>> The problem with most modern e-mail clients/programs/apps/... is that
>> they use something you could translate as  "unknown binary format"
>> as type for their attachments if they can't guess the correct
>> file type from the file extension.
>> It would be interesting to know (for me) if there are modern
>> e-mail programs / web apps which you could *teach* about the
>> mime type, e.g., for all files ending with extension '.R'...
>> 
>> Martin Maechler
>> ETH Zurich, Seminar fuer Statistik,
>> == the provider of all the (standard) R mailing lists.
>> 
>> 
>>     > Em 17-02-2017 17:20, Allan Tanaka escreveu:
>>     >> ....
>>     >> ....  See attached for R script
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ligges at statistik.tu-dortmund.de  Mon Feb 20 21:29:53 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 20 Feb 2017 21:29:53 +0100
Subject: [R] packrat: Failed to download current version of
 foreign(0.8-67)
In-Reply-To: <OF55ED1198.A075078E-ONC12580CD.005AD5C0-C12580CD.005AF05A@lotus.hawesko.de>
References: <OF55ED1198.A075078E-ONC12580CD.005AD5C0-C12580CD.005AF05A@lotus.hawesko.de>
Message-ID: <a7a80862-cafc-8382-5bf3-797fc5469b0e@statistik.tu-dortmund.de>

foreign is a recommended package that is already part of your R 
installation. and there shoudl not be a problem to install a recent 
version of it.

What is the error message of you run
install.packages("foreign") from a new R session?

Best,
Uwe Ligges



On 20.02.2017 17:33, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I tried to use packrat on
>
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=German_Germany.1252
> [2] LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> other attached packages:
> [1] packrat_0.4.8-1
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.2
>
> Due to internal firewall restrictions the package "foreign" could not be
> downloaded as source. I assume that the package also contains some binary
> parts which will be blocked by the firewall.
>
> When running packrat a directory "packrat" and a file called .Rprofile
> were created in the project directory. A lot of library sources were
> download, but not for "foreign".
>
> After finishing the process the directory "packrat" and the file .Rprofile
> were deleted from the project directory.
>
> Why is that? Just one source library missing and the whole directory is
> gone? Having all libraries for my project without just one is better than
> none!
>
> How can I use packrat with the missing library "foreign"?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Mon Feb 20 21:49:26 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 21 Feb 2017 07:49:26 +1100
Subject: [R] optimisation of the system of differential equations
In-Reply-To: <297758535.2154902.1487604403971@mail.yahoo.com>
References: <297758535.2154902.1487604403971.ref@mail.yahoo.com>
	<297758535.2154902.1487604403971@mail.yahoo.com>
Message-ID: <CA+8X3fURZRi7gj9eVgj-Na7k9uerK__dWgEu473y766m_bkZ9g@mail.gmail.com>

Hi Malgorzata,
There is currently another thread on the list about attaching R code
to emails. The problem appears to be that if you attach a file with
the extension ".R" it is sent in a way that is blocked by the mail
server. If you want to attach an R code file to your message, change
the extension to ".txt". You can also just copy it into your message,
although if it is very long it may be hard to read.

Jim


On Tue, Feb 21, 2017 at 2:26 AM, Malgorzata Wieteska via R-help
<r-help at r-project.org> wrote:
>
> I try to do optimisation of the system of the differential equations. I've managed to make my exemplary code working, however after changing equations on the exact model and data on the real one, I get an error messages and code doesn't work.
> I have a partial data for L (concentrations were assessed only for 3 days, the cycle lasted 24. My data for external variables (concentrations) of 2 other variables cE and cP have more datapoints (cP was assessed on each day)
> I couldn't fit more parameters than number of equations (excluded parameters for the initial values, which weren't assessed, so I try to get them as a result  of parameterisation). The most sensitive parameters were labelled as k1 and k2, the values for other were derived from the literature and embedded in the system of equations.
> I've attached my code. Thanks in advance for any hint why this code doesn't work or information were I can find examples for optimisation of the similar system of the equations.
> Kind Regards,Malgorzata
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From letter at openmailbox.org  Mon Feb 20 22:10:20 2017
From: letter at openmailbox.org (message)
Date: Mon, 20 Feb 2017 21:10:20 +0000
Subject: [R] use table function with data frame subsets
Message-ID: <1cc651638ac339f933b7bd23163c48c2@openmailbox.org>

Readers,

Data set:

20170101,10020,A,b,Y
20170101,10020,B,b,N
20170101,10020,C,d,Y
20170102,20001,C,d,Y
20170102,20001,D,m,Y
20170102,20001,L,a,Y

testtable<-read.csv('~/tmp/data.csv',header=F)
testtablea<-testtable[grep('^10',testtable[,2]),]
> testtable
         V1    V2 V3 V4 V5
1 20170101 10020  A  b  Y
2 20170101 10020  B  b  N
3 20170101 10020  C  d  Y
4 20170102 20001  C  d  Y
5 20170102 20001  D  m  Y
6 20170102 20001  L  a  Y
> testtablea
         V1    V2 V3 V4 V5
1 20170101 10020  A  b  Y
2 20170101 10020  B  b  N
3 20170101 10020  C  d  Y


> table(testtable[,4],testtable[,5])

     N Y
   a 0 1
   b 1 1
   d 0 2
   m 0 1
> table(testtablea[,4],testtablea[,5])

     N Y
   a 0 0
   b 1 1
   d 0 1
   m 0 0

Wy do values for rows beginning 'a' and 'm' appear when they do not 
satisfy the regular expression for the object 'testtablea'?

Please, how to use the 'table' function to show:

> table(testtablea[,4],testtablea[,5])

     N Y
   b 1 1
   d 0 1

Thanks.


From ssefick at gmail.com  Mon Feb 20 22:20:20 2017
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 20 Feb 2017 15:20:20 -0600
Subject: [R] Make sure a data frame has been "fun through" a function
Message-ID: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>

Hello,

I would like to add something to a data frame that is 1) invisible to the
user, 2) has no side effects, and 3) I can test for in a following
function. Is this possible? I am exploring classes and attributes and I
have thought about using a list (but 1 and 2 not satisfied). Any help would
be greatly appreciated.

I did not provide a reproducible example because I see this as more of a R
language question, but I will be happy to make a toy example if that would
help.

I appreciate all of the help.

kindest regards,

-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Feb 20 22:27:28 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 20 Feb 2017 21:27:28 +0000
Subject: [R] use table function with data frame subsets
In-Reply-To: <1cc651638ac339f933b7bd23163c48c2@openmailbox.org>
References: <1cc651638ac339f933b7bd23163c48c2@openmailbox.org>
Message-ID: <02f0868f116b42e99e69ad7e77eb43af@exch-2p-mbx-w2.ads.tamu.edu>

The default for read.csv() is stringsAsFactors=TRUE when creating a data frame so all the character strings in your .csv file were converted to factors:

> testtable <- read.csv("clipboard", header=F)
> str(testtable)
'data.frame':   6 obs. of  5 variables:
 $ V1: int  20170101 20170101 20170101 20170102 20170102 20170102
 $ V2: int  10020 10020 10020 20001 20001 20001
 $ V3: Factor w/ 5 levels "A","B","C","D",..: 1 2 3 3 4 5
 $ V4: Factor w/ 4 levels "a","b","d","m": 2 2 3 3 4 1
 $ V5: Factor w/ 2 levels "N","Y": 2 1 2 2 2 2

When you subset a data frame, the empty factor levels are not automatically removed:

> testtablea<-testtable[grep('^10',testtable[,2]),]
> str(testtablea)
'data.frame':   3 obs. of  5 variables:
 $ V1: int  20170101 20170101 20170101
 $ V2: int  10020 10020 10020
 $ V3: Factor w/ 5 levels "A","B","C","D",..: 1 2 3
 $ V4: Factor w/ 4 levels "a","b","d","m": 2 2 3
 $ V5: Factor w/ 2 levels "N","Y": 2 1 2

To drop the missing levels from all of the factors, use the droplevels() function:

> testtablea <- droplevels(testtablea)
> str(testtablea)
'data.frame':   3 obs. of  5 variables:
 $ V1: int  20170101 20170101 20170101
 $ V2: int  10020 10020 10020
 $ V3: Factor w/ 3 levels "A","B","C": 1 2 3
 $ V4: Factor w/ 2 levels "b","d": 1 1 2
 $ V5: Factor w/ 2 levels "N","Y": 2 1 2
> table(testtablea[,4],testtablea[,5])
   
    N Y
  b 1 1
  d 0 1

OR use stringsAsFactors=FALSE with read.csv() when you create the original data frame:

> testtable <- read.csv("clipboard", header=F, stringsAsFactors=FALSE)
> str(testtable)
'data.frame':   6 obs. of  5 variables:
 $ V1: int  20170101 20170101 20170101 20170102 20170102 20170102
 $ V2: int  10020 10020 10020 20001 20001 20001
 $ V3: chr  "A" "B" "C" "C" ...
 $ V4: chr  "b" "b" "d" "d" ...
 $ V5: chr  "Y" "N" "Y" "Y" ...
> testtablea<-testtable[grep('^10',testtable[,2]),]
> table(testtablea[,4],testtablea[,5])
   
    N Y
  b 1 1
  d 0 1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of message
Sent: Monday, February 20, 2017 3:10 PM
To: r-help at r-project.org
Subject: [R] use table function with data frame subsets

Readers,

Data set:

20170101,10020,A,b,Y
20170101,10020,B,b,N
20170101,10020,C,d,Y
20170102,20001,C,d,Y
20170102,20001,D,m,Y
20170102,20001,L,a,Y

testtable<-read.csv('~/tmp/data.csv',header=F)
testtablea<-testtable[grep('^10',testtable[,2]),]
> testtable
         V1    V2 V3 V4 V5
1 20170101 10020  A  b  Y
2 20170101 10020  B  b  N
3 20170101 10020  C  d  Y
4 20170102 20001  C  d  Y
5 20170102 20001  D  m  Y
6 20170102 20001  L  a  Y
> testtablea
         V1    V2 V3 V4 V5
1 20170101 10020  A  b  Y
2 20170101 10020  B  b  N
3 20170101 10020  C  d  Y


> table(testtable[,4],testtable[,5])

     N Y
   a 0 1
   b 1 1
   d 0 2
   m 0 1
> table(testtablea[,4],testtablea[,5])

     N Y
   a 0 0
   b 1 1
   d 0 1
   m 0 0

Wy do values for rows beginning 'a' and 'm' appear when they do not 
satisfy the regular expression for the object 'testtablea'?

Please, how to use the 'table' function to show:

> table(testtablea[,4],testtablea[,5])

     N Y
   b 1 1
   d 0 1

Thanks.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From glennmschultz at me.com  Mon Feb 20 22:41:50 2017
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 20 Feb 2017 15:41:50 -0600
Subject: [R] help with grep list files
Message-ID: <5D84E981-5E0D-49E5-A8F6-B298674DAF12@me.com>

All,

I have the following files in a directory and I would like only a list of those starting with ?lld" and ending with ?dat?.  I used the following and it gives me the lld files 

 list.files(path = readpath, pattern = "^lld[A-Z0-9]")
 
to get just .dat files I tried

 list.files(path = readpath, pattern = "^lld[A-Z0-9].dat$?) but nothing is returned


below is a dput from the first command.  $ is an end of line anchor correct?  What am I doing wrong?


Best,
Glenn

c("lld022017_AB7755_AS0038.dat", "lld022017_AS0039_AS5210.dat", 
"lld022017_AS5211_AS7917.dat", "lld022017_AS7918_AT8661.dat", 
"lld022017_AT8662_AW6667.dat", "lld022017_AW6668_AZ3066.dat", 
"lld022017_AZ3067_BC9534.dat", "lld022017_BC9535_MA2230.dat", 
"lld022017_MA2231_MB0288.dat", "lld022017.zip")


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Feb 20 22:53:59 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 20 Feb 2017 21:53:59 +0000
Subject: [R] help with grep list files
In-Reply-To: <5D84E981-5E0D-49E5-A8F6-B298674DAF12@me.com>
References: <5D84E981-5E0D-49E5-A8F6-B298674DAF12@me.com>
Message-ID: <58AB6577.5010501@sapo.pt>

Hello,

Maybe if you change the pattern to

"^lld[A-Z0-9]*\\.dat$"

Hope this helps,

Rui Barradas

Em 20-02-2017 21:41, Glenn Schultz escreveu:
> All,
>
> I have the following files in a directory and I would like only a list of those starting with ?lld" and ending with ?dat?.  I used the following and it gives me the lld files
>
>   list.files(path = readpath, pattern = "^lld[A-Z0-9]")
>
> to get just .dat files I tried
>
>   list.files(path = readpath, pattern = "^lld[A-Z0-9].dat$?) but nothing is returned
>
>
> below is a dput from the first command.  $ is an end of line anchor correct?  What am I doing wrong?
>
>
> Best,
> Glenn
>
> c("lld022017_AB7755_AS0038.dat", "lld022017_AS0039_AS5210.dat",
> "lld022017_AS5211_AS7917.dat", "lld022017_AS7918_AT8661.dat",
> "lld022017_AT8662_AW6667.dat", "lld022017_AW6668_AZ3066.dat",
> "lld022017_AZ3067_BC9534.dat", "lld022017_BC9535_MA2230.dat",
> "lld022017_MA2231_MB0288.dat", "lld022017.zip")
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Mon Feb 20 22:54:28 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 21 Feb 2017 10:54:28 +1300
Subject: [R] [FORGED]  help with grep list files
In-Reply-To: <5D84E981-5E0D-49E5-A8F6-B298674DAF12@me.com>
References: <5D84E981-5E0D-49E5-A8F6-B298674DAF12@me.com>
Message-ID: <1e78d6ee-7222-a566-3e80-9d59162e6cab@auckland.ac.nz>

On 21/02/17 10:41, Glenn Schultz wrote:
> All,
>
> I have the following files in a directory and I would like only a list of those starting with ?lld" and ending with ?dat?.  I used the following and it gives me the lld files
>
>  list.files(path = readpath, pattern = "^lld[A-Z0-9]")
>
> to get just .dat files I tried
>
>  list.files(path = readpath, pattern = "^lld[A-Z0-9].dat$?) but nothing is returned
>
>
> below is a dput from the first command.  $ is an end of line anchor correct?  What am I doing wrong?
>
>
> Best,
> Glenn
>
> c("lld022017_AB7755_AS0038.dat", "lld022017_AS0039_AS5210.dat",
> "lld022017_AS5211_AS7917.dat", "lld022017_AS7918_AT8661.dat",
> "lld022017_AT8662_AW6667.dat", "lld022017_AW6668_AZ3066.dat",
> "lld022017_AZ3067_BC9534.dat", "lld022017_BC9535_MA2230.dat",
> "lld022017_MA2231_MB0288.dat", "lld022017.zip")

     list.files(pattern="^lld.*\\.dat$")

seems to work for me.

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r at catwhisker.org  Mon Feb 20 22:57:10 2017
From: r at catwhisker.org (David Wolfskill)
Date: Mon, 20 Feb 2017 13:57:10 -0800
Subject: [R] help with grep list files
In-Reply-To: <5D84E981-5E0D-49E5-A8F6-B298674DAF12@me.com>
References: <5D84E981-5E0D-49E5-A8F6-B298674DAF12@me.com>
Message-ID: <20170220215710.GD1280@albert.catwhisker.org>

On Mon, Feb 20, 2017 at 03:41:50PM -0600, Glenn Schultz wrote:
> All,
> 
> I have the following files in a directory and I would like only a list of those starting with ?lld" and ending with ?dat?.  I used the following and it gives me the lld files 
> 
>  list.files(path = readpath, pattern = "^lld[A-Z0-9]")
>  
> to get just .dat files I tried
> 
>  list.files(path = readpath, pattern = "^lld[A-Z0-9].dat$?) but nothing is returned
> 
> 
> below is a dput from the first command.  $ is an end of line anchor correct?  What am I doing wrong?

Note that help(list.files) mentions (among other things):

| Note:
| 
|      File naming conventions are platform dependent.  The pattern
|      matching works with the case of file names as returned by the OS.

Also, your pattern ("^lld[A-Z0-9].dat$") does not include the '_'
character.

I was able to get the results you requested in my environment (FreeBSD
stable/11) using:

list.files(path = readpath, pattern = "^lld[_A-Z0-9]*.dat$")

(Note the '*' in there, as well.)

But "filename globbing" is not the same as "regular expressions," and as
the above-cited Note warns, results may well be platform-dependent, so
be careful.

> Best,
> Glenn
> .... 

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
How could one possibly "respect" a misogynist, racist, bullying con-man??!?

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 603 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170220/b504f5a3/attachment.bin>

From istazahn at gmail.com  Tue Feb 21 00:25:32 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 20 Feb 2017 18:25:32 -0500
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
Message-ID: <CA+vqiLEihv02TggNVjCRswHp1BJVnE7S4p-uKOFhvWnEy2oS7Q@mail.gmail.com>

It depends on what you mean by 1). If you mean "won't annoy the user" then
yes, e.g., add something to the class attribute. If 1) means "can't be
discovered by the user" then no (at least not easily). Anything you can see
they can see.

Best,
Ista


On Feb 20, 2017 4:21 PM, "stephen sefick" <ssefick at gmail.com> wrote:

Hello,

I would like to add something to a data frame that is 1) invisible to the
user, 2) has no side effects, and 3) I can test for in a following
function. Is this possible? I am exploring classes and attributes and I
have thought about using a list (but 1 and 2 not satisfied). Any help would
be greatly appreciated.

I did not provide a reproducible example because I see this as more of a R
language question, but I will be happy to make a toy example if that would
help.

I appreciate all of the help.

kindest regards,

--
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 21 00:53:24 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 20 Feb 2017 15:53:24 -0800
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CAGxFJbTwSarOyFUwtVhcvQXtpnOJO=geCoQdd_M39=xfV7kpyA@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<CA+vqiLEihv02TggNVjCRswHp1BJVnE7S4p-uKOFhvWnEy2oS7Q@mail.gmail.com>
	<CAGxFJbTy8YV2-WAVXZ2W5hAJptJuLs-K+_mY0+KjZ-wa5g5MfA@mail.gmail.com>
	<CAGxFJbTwSarOyFUwtVhcvQXtpnOJO=geCoQdd_M39=xfV7kpyA@mail.gmail.com>
Message-ID: <CAGxFJbS2j1MusUu_h9NUr-7b8415E61O58+0B900AWwMNCPYAg@mail.gmail.com>

Yes.

To elaborate a bit on Ista's reply:

A)   The only way I can imagine hiding info from a user would be to encrypt
it. This could be done programmatically I think, but I would have to
research it to figure out how.

B) If all you want to do is prevent the info from being printed, just
create e.g  an S3 class of type "foo" that inherits from "data.frame" with
your info as an attribute and provide a print.foo method that just prints
the data frame without the attribute. Your function can access and use the
attribute any way it likes.

Cheers,
Bert


Bert

On Feb 20, 2017 1:27 PM, "Ista Zahn" <istazahn at gmail.com> wrote:

It depends on what you mean by 1). If you mean "won't annoy the user" then
yes, e.g., add something to the class attribute. If 1) means "can't be
discovered by the user" then no (at least not easily). Anything you can see
they can see.

Best,
Ista


On Feb 20, 2017 4:21 PM, "stephen sefick" <ssefick at gmail.com> wrote:

Hello,

I would like to add something to a data frame that is 1) invisible to the
user, 2) has no side effects, and 3) I can test for in a following
function. Is this possible? I am exploring classes and attributes and I
have thought about using a list (but 1 and 2 not satisfied). Any help would
be greatly appreciated.

I did not provide a reproducible example because I see this as more of a R
language question, but I will be happy to make a toy example if that would
help.

I appreciate all of the help.

kindest regards,

--
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Feb 21 00:59:59 2017
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 20 Feb 2017 17:59:59 -0600
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CA+vqiLEihv02TggNVjCRswHp1BJVnE7S4p-uKOFhvWnEy2oS7Q@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<CA+vqiLEihv02TggNVjCRswHp1BJVnE7S4p-uKOFhvWnEy2oS7Q@mail.gmail.com>
Message-ID: <CADKEMqhscbsdu22qoUX=a7JXA+f-SsaS15ndJ8Rn9_rnRi1C+g@mail.gmail.com>

Yes, I mean "won't annoy the user", will allow them to do anything they
need to do with a dataframe (write to csv, etc.), but will allow me to test
for in a down stream function of the analysis to stop the function and
present an error. Adding something to the class attribute seems like the
right thing to do. With my clarification do you think these seems like a
sensible thing to do? Thank you for all of the help.
kindest regards,

Stephen

On Mon, Feb 20, 2017 at 5:25 PM, Ista Zahn <istazahn at gmail.com> wrote:

> It depends on what you mean by 1). If you mean "won't annoy the user" then
> yes, e.g., add something to the class attribute. If 1) means "can't be
> discovered by the user" then no (at least not easily). Anything you can see
> they can see.
>
> Best,
> Ista
>
>
> On Feb 20, 2017 4:21 PM, "stephen sefick" <ssefick at gmail.com> wrote:
>
> Hello,
>
> I would like to add something to a data frame that is 1) invisible to the
> user, 2) has no side effects, and 3) I can test for in a following
> function. Is this possible? I am exploring classes and attributes and I
> have thought about using a list (but 1 and 2 not satisfied). Any help would
> be greatly appreciated.
>
> I did not provide a reproducible example because I see this as more of a R
> language question, but I will be happy to make a toy example if that would
> help.
>
> I appreciate all of the help.
>
> kindest regards,
>
> --
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Feb 21 01:02:08 2017
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 20 Feb 2017 18:02:08 -0600
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CAGxFJbS2j1MusUu_h9NUr-7b8415E61O58+0B900AWwMNCPYAg@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<CA+vqiLEihv02TggNVjCRswHp1BJVnE7S4p-uKOFhvWnEy2oS7Q@mail.gmail.com>
	<CAGxFJbTy8YV2-WAVXZ2W5hAJptJuLs-K+_mY0+KjZ-wa5g5MfA@mail.gmail.com>
	<CAGxFJbTwSarOyFUwtVhcvQXtpnOJO=geCoQdd_M39=xfV7kpyA@mail.gmail.com>
	<CAGxFJbS2j1MusUu_h9NUr-7b8415E61O58+0B900AWwMNCPYAg@mail.gmail.com>
Message-ID: <CADKEMqhP_xykr6mfgH3KcUfmXRT9Pty8RBdu3oi5TKwn7wsq8g@mail.gmail.com>

Just as clarification, I don't want to hide anything from the user. I just
want to add something that I can test for in downstream function. I
appreciate all of the help.
kindest regards,

Stephen

On Mon, Feb 20, 2017 at 5:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Yes.
>
> To elaborate a bit on Ista's reply:
>
> A)   The only way I can imagine hiding info from a user would be to
> encrypt it. This could be done programmatically I think, but I would have
> to research it to figure out how.
>
> B) If all you want to do is prevent the info from being printed, just
> create e.g  an S3 class of type "foo" that inherits from "data.frame" with
> your info as an attribute and provide a print.foo method that just prints
> the data frame without the attribute. Your function can access and use the
> attribute any way it likes.
>
> Cheers,
> Bert
>
>
> Bert
>
> On Feb 20, 2017 1:27 PM, "Ista Zahn" <istazahn at gmail.com> wrote:
>
> It depends on what you mean by 1). If you mean "won't annoy the user" then
> yes, e.g., add something to the class attribute. If 1) means "can't be
> discovered by the user" then no (at least not easily). Anything you can see
> they can see.
>
> Best,
> Ista
>
>
> On Feb 20, 2017 4:21 PM, "stephen sefick" <ssefick at gmail.com> wrote:
>
> Hello,
>
> I would like to add something to a data frame that is 1) invisible to the
> user, 2) has no side effects, and 3) I can test for in a following
> function. Is this possible? I am exploring classes and attributes and I
> have thought about using a list (but 1 and 2 not satisfied). Any help would
> be greatly appreciated.
>
> I did not provide a reproducible example because I see this as more of a R
> language question, but I will be happy to make a toy example if that would
> help.
>
> I appreciate all of the help.
>
> kindest regards,
>
> --
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Tue Feb 21 01:24:14 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Mon, 20 Feb 2017 16:24:14 -0800
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>

On Mon, 20 Feb 2017, stephen sefick wrote:

> Hello,
>
> I would like to add something to a data frame that is 1) invisible to the
> user, 2) has no side effects, and 3) I can test for in a following
> function. Is this possible? I am exploring classes and attributes and I
> have thought about using a list (but 1 and 2 not satisfied). Any help would
> be greatly appreciated.
>

Depends on exactly what you mean by `invisible' and `side effects'.

You can do this (but I am not necessarily recommending this):

> add.stuff <- function(x,...){
+ class(x)<- c("more.stuff",class(x))
+ attr(x,"stuff")<- list(...)
+ x}
>

And printing and model functions will be unaffected:

> df <- data.frame(a=1:3,b=letters[1:3])
> df2 <- add.stuff(df,comment="wow", length="3 rows")
> df2
   a b
1 1 a
2 2 b
3 3 c
> attr(df2,"stuff")
$comment
[1] "wow"

$length
[1] "3 rows"

> all.equal(lm(a~b,df),lm(a~b,df2)) # only call should differ
[1] "Component ?call?: target, current do not match when deparsed"
>

And if you need some generics to take account of the "stuff" attribute, 
you can write the methods to do that.

---

Another solution is to put your data.framne in a package and then have 
other objects hold the 'stuff' stuff. Once your package is loaded or 
imported, the user will have access to the data in a way that might be 
said to be `invisible' in ordinary usage.

---

But seriously, you should say *why* you want to do this. There are 
probably excellent solutions that do not involve directly altering the 
data.frame and may not involve putting together a package.

HTH,

Chuck

From ssefick at gmail.com  Tue Feb 21 01:43:42 2017
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 20 Feb 2017 18:43:42 -0600
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>
Message-ID: <CADKEMqg2mbKUu9TNFu0ZC9GXFWNKV=Fy3eT_vX-6FkrztQ=BKQ@mail.gmail.com>

Hello All,

I am writing a package. I would like to encourage the user to look at the
data to rectify errors with function A before utilizing function B to code
these data as binary. I thought about solving this problem by adding a
"flag" in the attributes that could be used downstream in B, and have a
function that adds this "flag" if the user is convinced that everything is
okay. This would allow the user to utilize their data as is, if error
checking is not necessary. Maybe I am overthinking this. Thanks again.
kindest regards,

Stephen

On Mon, Feb 20, 2017 at 6:24 PM, Charles C. Berry <ccberry at ucsd.edu> wrote:

> On Mon, 20 Feb 2017, stephen sefick wrote:
>
> Hello,
>>
>> I would like to add something to a data frame that is 1) invisible to the
>> user, 2) has no side effects, and 3) I can test for in a following
>> function. Is this possible? I am exploring classes and attributes and I
>> have thought about using a list (but 1 and 2 not satisfied). Any help
>> would
>> be greatly appreciated.
>>
>>
> Depends on exactly what you mean by `invisible' and `side effects'.
>
> You can do this (but I am not necessarily recommending this):
>
> add.stuff <- function(x,...){
>>
> + class(x)<- c("more.stuff",class(x))
> + attr(x,"stuff")<- list(...)
> + x}
>
>>
>>
> And printing and model functions will be unaffected:
>
> df <- data.frame(a=1:3,b=letters[1:3])
>> df2 <- add.stuff(df,comment="wow", length="3 rows")
>> df2
>>
>   a b
> 1 1 a
> 2 2 b
> 3 3 c
>
>> attr(df2,"stuff")
>>
> $comment
> [1] "wow"
>
> $length
> [1] "3 rows"
>
> all.equal(lm(a~b,df),lm(a~b,df2)) # only call should differ
>>
> [1] "Component ?call?: target, current do not match when deparsed"
>
>>
>>
> And if you need some generics to take account of the "stuff" attribute,
> you can write the methods to do that.
>
> ---
>
> Another solution is to put your data.framne in a package and then have
> other objects hold the 'stuff' stuff. Once your package is loaded or
> imported, the user will have access to the data in a way that might be said
> to be `invisible' in ordinary usage.
>
> ---
>
> But seriously, you should say *why* you want to do this. There are
> probably excellent solutions that do not involve directly altering the
> data.frame and may not involve putting together a package.
>
> HTH,
>
> Chuck




-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Tue Feb 21 03:53:29 2017
From: tmrsg11 at gmail.com (C W)
Date: Mon, 20 Feb 2017 21:53:29 -0500
Subject: [R] Confused about using data.table package,
In-Reply-To: <CABdHhvGrs4JJszrRQzORR+ZAi24Dt-2tHu2gqOnZoE6PRRz2jg@mail.gmail.com>
References: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>
	<F2C4B71E-3912-4BF8-9870-2ADCA5BB53EE@comcast.net>
	<CABdHhvGrs4JJszrRQzORR+ZAi24Dt-2tHu2gqOnZoE6PRRz2jg@mail.gmail.com>
Message-ID: <CAE2FW2=a3ystMW-c-OHyC5Ewey320qLLieZySCGMM+UgaNS-qg@mail.gmail.com>

Thanks Hadley!

While I got your attention, what is a good way to get started on ggplot2? ;)

My impression is that I first need to learn plyr, dplyr, AND THEN ggplot2.
That's A LOT!

Suppose i have this:
iris
iris2 <- cbind(iris, grade = sample(1:5, 150, replace = TRUE))
iris2

I want to have some kind of graph conditioned on species, by grade . What's
a good lead to learn about plotting this?

Thank you!



On Mon, Feb 20, 2017 at 11:12 AM, Hadley Wickham <h.wickham at gmail.com>
wrote:

> On Sun, Feb 19, 2017 at 3:01 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >> On Feb 19, 2017, at 11:37 AM, C W <tmrsg11 at gmail.com> wrote:
> >>
> >> Hi R,
> >>
> >> I am a little confused by the data.table package.
> >>
> >> library(data.table)
> >>
> >> df <- data.frame(w=rnorm(20, -10, 1), x= rnorm(20, 0, 1), y=rnorm(20,
> 10, 1),
> >> z=rnorm(20, 20, 1))
> >>
> >> df <- data.table(df)
> >
> >   df <- setDT(df) is preferred.
>
> Don't you mean just
>
> setDT(df)
>
> ?
>
> setDT() modifies by reference.
>
> >>
> >> df_3 <- df[, a := x-y] # created new column a using x minus y, why are
> we
> >> using colon equals?
> >
> > You need to do more study of the extensive documentation. The behavior
> of the ":=" function is discussed in detail there.
>
> You can get to that documentation with ?":="
>
> Hadley
>
> --
> http://hadley.nz
>

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Tue Feb 21 08:16:38 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 21 Feb 2017 08:16:38 +0100
Subject: [R] Antwort: Re: packrat: Failed to download current version of
	foreign(0.8-67)
In-Reply-To: <a7a80862-cafc-8382-5bf3-797fc5469b0e@statistik.tu-dortmund.de>
References: <OF55ED1198.A075078E-ONC12580CD.005AD5C0-C12580CD.005AF05A@lotus.hawesko.de>
	<a7a80862-cafc-8382-5bf3-797fc5469b0e@statistik.tu-dortmund.de>
Message-ID: <OFD3638432.D5B8FB85-ONC12580CE.002781F6-C12580CE.0027F98D@lotus.hawesko.de>

Hi Mr. Ligges,

doing as you said R responds with

install.packages("foreign")
trying URL 
'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip'
Warning in install.packages :
  cannot open URL 
'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip': 
HTTP status was '403 Forbidden (Content blocked by Trustwave Secure Web 
Gateway)'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 
'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip'
Warning in install.packages :
  download of package ?foreign? failed

Running

install.packages("foreign", type = "source")
trying URL 
'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz'
Warning in install.packages :
  cannot open URL 
'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz': HTTP 
status was '403 Forbidden (Content blocked by Trustwave Secure Web 
Gateway)'
Error in download.file(url, destfile, method, mode = "wb", ...) : 
  cannot open URL 
'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz'
Warning in install.packages :
  download of package ?foreign? failed

The firewall in my company blocks all binary files. Foreign is downloaded 
in "wb" mode. Thus I have no chance to get it. The first fresh 
installation was done from an external drive. As packrat is also 
downloading the binaries instead of the source my download will always 
fail.

My sessionInfo() is
sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Germany.1252 
[2] LC_CTYPE=German_Germany.1252 
[3] LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C 
[5] LC_TIME=German_Germany.1252 

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods 
[7] base 

loaded via a namespace (and not attached):
[1] tools_3.3.2

Do have a suggestion?

Kind regards

Georg





Von:    Uwe Ligges <ligges at statistik.tu-dortmund.de>
An:     G.Maubach at weinwolf.de, r-help at r-project.org, 
Datum:  20.02.2017 21:29
Betreff:        Re: [R] packrat: Failed to download current version of 
foreign(0.8-67)



foreign is a recommended package that is already part of your R 
installation. and there shoudl not be a problem to install a recent 
version of it.

What is the error message of you run
install.packages("foreign") from a new R session?

Best,
Uwe Ligges



On 20.02.2017 17:33, G.Maubach at weinwolf.de wrote:
> Hi All,
>
> I tried to use packrat on
>
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=German_Germany.1252
> [2] LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> other attached packages:
> [1] packrat_0.4.8-1
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.2
>
> Due to internal firewall restrictions the package "foreign" could not be
> downloaded as source. I assume that the package also contains some 
binary
> parts which will be blocked by the firewall.
>
> When running packrat a directory "packrat" and a file called .Rprofile
> were created in the project directory. A lot of library sources were
> download, but not for "foreign".
>
> After finishing the process the directory "packrat" and the file 
.Rprofile
> were deleted from the project directory.
>
> Why is that? Just one source library missing and the whole directory is
> gone? Having all libraries for my project without just one is better 
than
> none!
>
> How can I use packrat with the missing library "foreign"?
>
> Kind regards
>
> Georg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jdnewmil at dcn.davis.ca.us  Tue Feb 21 09:09:16 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Feb 2017 00:09:16 -0800
Subject: [R] Confused about using data.table package,
In-Reply-To: <CAE2FW2=a3ystMW-c-OHyC5Ewey320qLLieZySCGMM+UgaNS-qg@mail.gmail.com>
References: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>
	<F2C4B71E-3912-4BF8-9870-2ADCA5BB53EE@comcast.net>
	<CABdHhvGrs4JJszrRQzORR+ZAi24Dt-2tHu2gqOnZoE6PRRz2jg@mail.gmail.com>
	<CAE2FW2=a3ystMW-c-OHyC5Ewey320qLLieZySCGMM+UgaNS-qg@mail.gmail.com>
Message-ID: <CA701AD1-3A53-46D0-9D84-45E69450D865@dcn.davis.ca.us>

I suspect Hadley would recommend reading his new book, R for Data Science (r4ds.had.co.nz), in particular Chapter 3. You don't need plyr, but it won't take long before you will want to be using dplyr and tidyr, which are covered in later chapters.
-- 
Sent from my phone. Please excuse my brevity.

On February 20, 2017 6:53:29 PM PST, C W <tmrsg11 at gmail.com> wrote:
>Thanks Hadley!
>
>While I got your attention, what is a good way to get started on
>ggplot2? ;)
>
>My impression is that I first need to learn plyr, dplyr, AND THEN
>ggplot2.
>That's A LOT!
>
>Suppose i have this:
>iris
>iris2 <- cbind(iris, grade = sample(1:5, 150, replace = TRUE))
>iris2
>
>I want to have some kind of graph conditioned on species, by grade .
>What's
>a good lead to learn about plotting this?
>
>Thank you!
>
>
>
>On Mon, Feb 20, 2017 at 11:12 AM, Hadley Wickham <h.wickham at gmail.com>
>wrote:
>
>> On Sun, Feb 19, 2017 at 3:01 PM, David Winsemius
><dwinsemius at comcast.net>
>> wrote:
>> >
>> >> On Feb 19, 2017, at 11:37 AM, C W <tmrsg11 at gmail.com> wrote:
>> >>
>> >> Hi R,
>> >>
>> >> I am a little confused by the data.table package.
>> >>
>> >> library(data.table)
>> >>
>> >> df <- data.frame(w=rnorm(20, -10, 1), x= rnorm(20, 0, 1),
>y=rnorm(20,
>> 10, 1),
>> >> z=rnorm(20, 20, 1))
>> >>
>> >> df <- data.table(df)
>> >
>> >   df <- setDT(df) is preferred.
>>
>> Don't you mean just
>>
>> setDT(df)
>>
>> ?
>>
>> setDT() modifies by reference.
>>
>> >>
>> >> df_3 <- df[, a := x-y] # created new column a using x minus y, why
>are
>> we
>> >> using colon equals?
>> >
>> > You need to do more study of the extensive documentation. The
>behavior
>> of the ":=" function is discussed in detail there.
>>
>> You can get to that documentation with ?":="
>>
>> Hadley
>>
>> --
>> http://hadley.nz
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Tue Feb 21 09:51:06 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 21 Feb 2017 09:51:06 +0100
Subject: [R] Antwort: Re: packrat: Failed to download current version of
 foreign(0.8-67)
In-Reply-To: <OFD3638432.D5B8FB85-ONC12580CE.002781F6-C12580CE.0027F98D@lotus.hawesko.de>
References: <OF55ED1198.A075078E-ONC12580CD.005AD5C0-C12580CD.005AF05A@lotus.hawesko.de>
	<a7a80862-cafc-8382-5bf3-797fc5469b0e@statistik.tu-dortmund.de>
	<OFD3638432.D5B8FB85-ONC12580CE.002781F6-C12580CE.0027F98D@lotus.hawesko.de>
Message-ID: <034f8836-234d-b8fc-8b9e-813457dc01d3@statistik.tu-dortmund.de>

Yes, then we cannot help and you have to ask your company how to get the 
files, of course.

Best,
Uwe Ligges



On 21.02.2017 08:16, G.Maubach at weinwolf.de wrote:
> Hi Mr. Ligges,
>
> doing as you said R responds with
>
> install.packages("foreign")
> trying URL
> 'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip'
> Warning in install.packages :
>   cannot open URL
> 'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip':
> HTTP status was '403 Forbidden (Content blocked by Trustwave Secure Web
> Gateway)'
> Error in download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open URL
> 'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip'
> Warning in install.packages :
>   download of package ?foreign? failed
>
> Running
>
> install.packages("foreign", type = "source")
> trying URL
> 'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz'
> Warning in install.packages :
>   cannot open URL
> 'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz': HTTP
> status was '403 Forbidden (Content blocked by Trustwave Secure Web
> Gateway)'
> Error in download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open URL
> 'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz'
> Warning in install.packages :
>   download of package ?foreign? failed
>
> The firewall in my company blocks all binary files. Foreign is downloaded
> in "wb" mode. Thus I have no chance to get it. The first fresh
> installation was done from an external drive. As packrat is also
> downloading the binaries instead of the source my download will always
> fail.
>
> My sessionInfo() is
> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=German_Germany.1252
> [2] LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.2
>
> Do have a suggestion?
>
> Kind regards
>
> Georg
>
>
>
>
>
> Von:    Uwe Ligges <ligges at statistik.tu-dortmund.de>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  20.02.2017 21:29
> Betreff:        Re: [R] packrat: Failed to download current version of
> foreign(0.8-67)
>
>
>
> foreign is a recommended package that is already part of your R
> installation. and there shoudl not be a problem to install a recent
> version of it.
>
> What is the error message of you run
> install.packages("foreign") from a new R session?
>
> Best,
> Uwe Ligges
>
>
>
> On 20.02.2017 17:33, G.Maubach at weinwolf.de wrote:
>> Hi All,
>>
>> I tried to use packrat on
>>
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252
>> [2] LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods
>> [7] base
>>
>> other attached packages:
>> [1] packrat_0.4.8-1
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.3.2
>>
>> Due to internal firewall restrictions the package "foreign" could not be
>> downloaded as source. I assume that the package also contains some
> binary
>> parts which will be blocked by the firewall.
>>
>> When running packrat a directory "packrat" and a file called .Rprofile
>> were created in the project directory. A lot of library sources were
>> download, but not for "foreign".
>>
>> After finishing the process the directory "packrat" and the file
> .Rprofile
>> were deleted from the project directory.
>>
>> Why is that? Just one source library missing and the whole directory is
>> gone? Having all libraries for my project without just one is better
> than
>> none!
>>
>> How can I use packrat with the missing library "foreign"?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From G.Maubach at weinwolf.de  Tue Feb 21 10:34:24 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 21 Feb 2017 10:34:24 +0100
Subject: [R] Antwort: Re: Antwort: Re: packrat: Failed to download current
 version of foreign(0.8-67)
In-Reply-To: <034f8836-234d-b8fc-8b9e-813457dc01d3@statistik.tu-dortmund.de>
References: <OF55ED1198.A075078E-ONC12580CD.005AD5C0-C12580CD.005AF05A@lotus.hawesko.de>
	<a7a80862-cafc-8382-5bf3-797fc5469b0e@statistik.tu-dortmund.de>
	<OFD3638432.D5B8FB85-ONC12580CE.002781F6-C12580CE.0027F98D@lotus.hawesko.de>
	<034f8836-234d-b8fc-8b9e-813457dc01d3@statistik.tu-dortmund.de>
Message-ID: <OF2AB3DC18.761CF150-ONC12580CE.003451EF-C12580CE.0034964F@lotus.hawesko.de>

Packrat does a beautiful job, creating local project repositories of all 
used libraries. If only one library is missing the complete repository is 
not stored. Having all but one library in the repository is far better 
than having none.

I suggest to change the behaviour of packrat to store all libraries it can 
get in the directory "packrat" and not delete it if one library is 
missing. This would help a lot.

Is this possible?

Kind regards

Georg




Von:    Uwe Ligges <ligges at statistik.tu-dortmund.de>
An:     G.Maubach at weinwolf.de, 
Kopie:  r-help at r-project.org
Datum:  21.02.2017 09:50
Betreff:        Re: Antwort: Re: [R] packrat: Failed to download current 
version of foreign(0.8-67)



Yes, then we cannot help and you have to ask your company how to get the 
files, of course.

Best,
Uwe Ligges



On 21.02.2017 08:16, G.Maubach at weinwolf.de wrote:
> Hi Mr. Ligges,
>
> doing as you said R responds with
>
> install.packages("foreign")
> trying URL
> 
'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip'
> Warning in install.packages :
>   cannot open URL
> 
'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip':
> HTTP status was '403 Forbidden (Content blocked by Trustwave Secure Web
> Gateway)'
> Error in download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open URL
> 
'https://cran.uni-muenster.de/bin/windows/contrib/3.3/foreign_0.8-67.zip'
> Warning in install.packages :
>   download of package ?foreign? failed
>
> Running
>
> install.packages("foreign", type = "source")
> trying URL
> 'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz'
> Warning in install.packages :
>   cannot open URL
> 'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz': HTTP
> status was '403 Forbidden (Content blocked by Trustwave Secure Web
> Gateway)'
> Error in download.file(url, destfile, method, mode = "wb", ...) :
>   cannot open URL
> 'https://cran.uni-muenster.de/src/contrib/foreign_0.8-67.tar.gz'
> Warning in install.packages :
>   download of package ?foreign? failed
>
> The firewall in my company blocks all binary files. Foreign is 
downloaded
> in "wb" mode. Thus I have no chance to get it. The first fresh
> installation was done from an external drive. As packrat is also
> downloading the binaries instead of the source my download will always
> fail.
>
> My sessionInfo() is
> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=German_Germany.1252
> [2] LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> loaded via a namespace (and not attached):
> [1] tools_3.3.2
>
> Do have a suggestion?
>
> Kind regards
>
> Georg
>
>
>
>
>
> Von:    Uwe Ligges <ligges at statistik.tu-dortmund.de>
> An:     G.Maubach at weinwolf.de, r-help at r-project.org,
> Datum:  20.02.2017 21:29
> Betreff:        Re: [R] packrat: Failed to download current version of
> foreign(0.8-67)
>
>
>
> foreign is a recommended package that is already part of your R
> installation. and there shoudl not be a problem to install a recent
> version of it.
>
> What is the error message of you run
> install.packages("foreign") from a new R session?
>
> Best,
> Uwe Ligges
>
>
>
> On 20.02.2017 17:33, G.Maubach at weinwolf.de wrote:
>> Hi All,
>>
>> I tried to use packrat on
>>
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252
>> [2] LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods
>> [7] base
>>
>> other attached packages:
>> [1] packrat_0.4.8-1
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.3.2
>>
>> Due to internal firewall restrictions the package "foreign" could not 
be
>> downloaded as source. I assume that the package also contains some
> binary
>> parts which will be blocked by the firewall.
>>
>> When running packrat a directory "packrat" and a file called .Rprofile
>> were created in the project directory. A lot of library sources were
>> download, but not for "foreign".
>>
>> After finishing the process the directory "packrat" and the file
> .Rprofile
>> were deleted from the project directory.
>>
>> Why is that? Just one source library missing and the whole directory is
>> gone? Having all libraries for my project without just one is better
> than
>> none!
>>
>> How can I use packrat with the missing library "foreign"?
>>
>> Kind regards
>>
>> Georg
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>



From pdalgd at gmail.com  Tue Feb 21 10:49:14 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 21 Feb 2017 10:49:14 +0100
Subject: [R] Confused about using data.table package,
In-Reply-To: <CAE2FW2=a3ystMW-c-OHyC5Ewey320qLLieZySCGMM+UgaNS-qg@mail.gmail.com>
References: <CAE2FW2=QOrHTkGjy3xUin6NdMnq=z09PTSE_cGfcQVL5gf6sAQ@mail.gmail.com>
	<F2C4B71E-3912-4BF8-9870-2ADCA5BB53EE@comcast.net>
	<CABdHhvGrs4JJszrRQzORR+ZAi24Dt-2tHu2gqOnZoE6PRRz2jg@mail.gmail.com>
	<CAE2FW2=a3ystMW-c-OHyC5Ewey320qLLieZySCGMM+UgaNS-qg@mail.gmail.com>
Message-ID: <D9800583-3591-488D-9904-0B611DE5F942@gmail.com>

Just. Don't. Do. This. (Hint: Threading mail readers.)

On 21 Feb 2017, at 03:53 , C W <tmrsg11 at gmail.com> wrote:

> Thanks Hadley!
> 
> While I got your attention, what is a good way to get started on ggplot2? ;)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Tue Feb 21 11:27:31 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 21 Feb 2017 11:27:31 +0100
Subject: [R] R scripts attached to e-mails - correct MIME type ?!
In-Reply-To: <EF3ECAA7-15BD-46FE-9DAA-12DCF45ABF9B@gmail.com>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<22698.63999.756178.367552@stat.math.ethz.ch>
	<58AB0124.7080908@sapo.pt>
	<EF3ECAA7-15BD-46FE-9DAA-12DCF45ABF9B@gmail.com>
Message-ID: <22700.5651.624991.763080@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Mon, 20 Feb 2017 19:45:18 +0100 writes:

    > Not by the mail server as such, no, at least not for that
    > reason. However, T-bird likely sends .txt as text/plain
    > and .R as application/octet-stream (or so) and _therefore_
    > the server eliminates the latter and lets the former pass.
    > -pd

Exactly.  Thank, you, Peter.


From infojomy at gmail.com  Tue Feb 21 11:47:53 2017
From: infojomy at gmail.com (Jomy Jose)
Date: Tue, 21 Feb 2017 16:17:53 +0530
Subject: [R] Yates correction
Message-ID: <CADGufDEpUDsPNpo0P3JtdEWBDgL6YV4p8G3R8dGDwdgMBzpXyw@mail.gmail.com>

 I tried to do chi square test for the following observed frequencies
---------------------------------------------------------------------------------------------
   A  B
A  8  4
B 12 10

R gave the following output:
-------------------------------------------------------------------------------------------
        Pearson's Chi-squared test with Yates' continuity correction

data:  M
X-squared = 0.10349, df = 1, p-value = 0.7477

Warning message:
In chisq.test(M) : Chi-squared approximation may be incorrect

---------------------------------------------------------------------------------------------------------------
Whether this result can be relied or we have to use Fishers exact test ?

Jose

	[[alternative HTML version deleted]]


From g.wieteska at yahoo.ie  Tue Feb 21 12:03:53 2017
From: g.wieteska at yahoo.ie (Malgorzata Wieteska)
Date: Tue, 21 Feb 2017 11:03:53 +0000 (UTC)
Subject: [R] optimisation - Error in checkFunc(Func2, times, y,
 rho) : The number of derivatives returned by func() (22) must equal
 the length of the initial conditions vector (2)
References: <89028320.3148770.1487675033048.ref@mail.yahoo.com>
Message-ID: <89028320.3148770.1487675033048@mail.yahoo.com>

Hello,
I get an error message:Error in checkFunc(Func2, times, y, rho) :?? The number of derivatives returned by func() (22) must equal the length of the initial conditions vector (2)
I try to optimise system of differential equations with 2 extra variables derived from the data.frame.
I didn't manage to install XLConnect package, so I don't know if this is the source of the problem.
Loading required package: XLConnectWarning message:In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, ?:? there is no package called ?XLConnect?
I have missing data, so time frame is limited. I haven't got values for solution of the first equation, but I hope that it isn't problem, I've got the same message when putting random numbers as x values.
The code is as follow:time=c(16,17,18,19,20,21,22,23,24,25,26)

#x=c(20.2,18.9,16.5)y=c(7.63,9.22,4.86,4.78,0.38,6.13,3.91,38.41,2.58,36.95,1.73)
cE=c(15.05,38.01,41.09,31.41,3.54,15.92,24.01,25.29,14.82,43.93,2.45)cP=c(0.47,0.43,4.8,1.07,0.38,0.3,0.14,0.29,0.9,2.51,1.94)

#df<-data.frame(time,y,cE,cP)#dfrequire(FME)require(XLConnect)
#Initial values of the parametersparms=c(k1=500, k2=4500, k3=200,k4=2.42, k5=0.26,k6=12.2,k7=0.004,k8=55,? ? ? ? ? ?k9=24,k10=8)
#definition of the parameters functionderivs<-function(time,y,pars){? with(as.list(c(pars,y)),{? ? cE=c(15.05,38.01,41.09,31.41,3.54,15.92,24.01,25.29,14.82,43.93,2.45)? ? cP=c(0.47,0.43,4.8,1.07,0.38,0.3,0.14,0.29,0.9,2.51,1.94)? ??? ? dx=(k1+(k2*cE^k10)/(k3^k10+cE^k10))/(1+cP/k6)-k4*((1+k5*cP)/(1+k7*cE))*x; #dRP_LH/dt? ? dy=(1/k8)*k4*((1+k5*cP)/(1+k7*cE))*x-k9*y #dL/dt? ? list(c(dx,dy))? })}initial<-c(x=x[1],y=y[1])
model_cost<-function(pars){? out<-ode(y=initial,time=time,func=derivs,parms=pars)? cost<-modCost(model=out,obs=df,x="time")? return(cost)? model_cost(parms)$model# model fitting? model_fit<-modFit(f=model_cost,p=parms)}model_cost(parms)
Thank you in advance for any help.
PS, I've tried to put cE and cP as initial conditions or/and as parameters, but it didn't solve the problem.
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Feb 21 13:41:28 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Feb 2017 04:41:28 -0800
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CADKEMqg2mbKUu9TNFu0ZC9GXFWNKV=Fy3eT_vX-6FkrztQ=BKQ@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>
	<CADKEMqg2mbKUu9TNFu0ZC9GXFWNKV=Fy3eT_vX-6FkrztQ=BKQ@mail.gmail.com>
Message-ID: <FA9FEE6A-5AED-411C-BE48-75AACE112711@comcast.net>


> On Feb 20, 2017, at 4:43 PM, stephen sefick <ssefick at gmail.com> wrote:
> 
> Hello All,
> 
> I am writing a package. I would like to encourage the user to look at the
> data to rectify errors with function A before utilizing function B to code
> these data as binary. I thought about solving this problem by adding a
> "flag" in the attributes that could be used downstream in B, and have a
> function that adds this "flag" if the user is convinced that everything is
> okay. This would allow the user to utilize their data as is, if error
> checking is not necessary. Maybe I am overthinking this. Thanks again.
> kindest regards,

Still not clear what is needed but there is an `attr<-` function. You might get waht you wnat by having function A add an attribute which is then checked by B.

-- 
David
> 
> Stephen
> 
> On Mon, Feb 20, 2017 at 6:24 PM, Charles C. Berry <ccberry at ucsd.edu> wrote:
> 
>> On Mon, 20 Feb 2017, stephen sefick wrote:
>> 
>> Hello,
>>> 
>>> I would like to add something to a data frame that is 1) invisible to the
>>> user, 2) has no side effects, and 3) I can test for in a following
>>> function. Is this possible? I am exploring classes and attributes and I
>>> have thought about using a list (but 1 and 2 not satisfied). Any help
>>> would
>>> be greatly appreciated.
>>> 
>>> 
>> Depends on exactly what you mean by `invisible' and `side effects'.
>> 
>> You can do this (but I am not necessarily recommending this):
>> 
>> add.stuff <- function(x,...){
>>> 
>> + class(x)<- c("more.stuff",class(x))
>> + attr(x,"stuff")<- list(...)
>> + x}
>> 
>>> 
>>> 
>> And printing and model functions will be unaffected:
>> 
>> df <- data.frame(a=1:3,b=letters[1:3])
>>> df2 <- add.stuff(df,comment="wow", length="3 rows")
>>> df2
>>> 
>>  a b
>> 1 1 a
>> 2 2 b
>> 3 3 c
>> 
>>> attr(df2,"stuff")
>>> 
>> $comment
>> [1] "wow"
>> 
>> $length
>> [1] "3 rows"
>> 
>> all.equal(lm(a~b,df),lm(a~b,df2)) # only call should differ
>>> 
>> [1] "Component ?call?: target, current do not match when deparsed"
>> 
>>> 
>>> 
>> And if you need some generics to take account of the "stuff" attribute,
>> you can write the methods to do that.
>> 
>> ---
>> 
>> Another solution is to put your data.framne in a package and then have
>> other objects hold the 'stuff' stuff. Once your package is loaded or
>> imported, the user will have access to the data in a way that might be said
>> to be `invisible' in ordinary usage.
>> 
>> ---
>> 
>> But seriously, you should say *why* you want to do this. There are
>> probably excellent solutions that do not involve directly altering the
>> data.frame and may not involve putting together a package.
>> 
>> HTH,
>> 
>> Chuck
> 
> 
> 
> 
> -- 
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
> 
>                                -K. Mullis
> 
> "A big computer, a complex algorithm and a long time does not equal
> science."
> 
>                              -Robert Gentleman
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Tue Feb 21 14:40:57 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 21 Feb 2017 13:40:57 +0000
Subject: [R] Yates correction
In-Reply-To: <CADGufDEpUDsPNpo0P3JtdEWBDgL6YV4p8G3R8dGDwdgMBzpXyw@mail.gmail.com>
References: <CADGufDEpUDsPNpo0P3JtdEWBDgL6YV4p8G3R8dGDwdgMBzpXyw@mail.gmail.com>
Message-ID: <e60833ce407540aab333388b00d98080@exch-2p-mbx-w2.ads.tamu.edu>

Use fisher.test(). Yates' correction compensates for a tendency for Chi-square to be overestimated in a 2x2 table, but Yates' can overcompensate, reducing Chi-square too much. It's main advantage was when computers were expensive and Fisher's Exact was hard to compute by hand.  You can see from the following that Fisher's Exact estimates the p-value as .717, a bit less than .7477.

> M <- matrix(c(8, 12, 4, 10), 2, 2)
> fisher.test(M)

        Fisher's Exact Test for Count Data

data:  M
p-value = 0.717
alternative hypothesis: true odds ratio is not equal to 1
95 percent confidence interval:
 0.3160571 9.7976232
sample estimates:
odds ratio 
  1.641969

An alternative would be to let chisq.test() use simulations to estimate the p-value:

> chisq.test(M, simulate.p.value=TRUE)

        Pearson's Chi-squared test with simulated p-value (based on 2000 replicates)

data:  M
X-squared = 0.471, df = NA, p-value = 0.7141

Which agrees pretty well with fisher.test(). The X-squared value of 0.471 is the uncorrected value so you can see that the Yates' correction reduced it substantially (to .1035).

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jomy Jose
Sent: Tuesday, February 21, 2017 4:48 AM
To: r-help at r-project.org
Subject: [R] Yates correction

 I tried to do chi square test for the following observed frequencies
---------------------------------------------------------------------------------------------
   A  B
A  8  4
B 12 10

R gave the following output:
-------------------------------------------------------------------------------------------
        Pearson's Chi-squared test with Yates' continuity correction

data:  M
X-squared = 0.10349, df = 1, p-value = 0.7477

Warning message:
In chisq.test(M) : Chi-squared approximation may be incorrect

---------------------------------------------------------------------------------------------------------------
Whether this result can be relied or we have to use Fishers exact test ?

Jose

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From adem2 at student.monash.edu  Tue Feb 21 01:30:24 2017
From: adem2 at student.monash.edu (Angus Dempster)
Date: Tue, 21 Feb 2017 11:30:24 +1100
Subject: [R] [R-pkgs] New package: opusminer
Message-ID: <CAPsOnmbD8PAnhy=WXnfSnvvQv08pQdLOQabrk+9nY3G1Z17b1g@mail.gmail.com>

Dear all,

The new package opusminer is now available on CRAN:
<https://CRAN.R-project.org/package=opusminer>.

opusminer provides an interface to the OPUS Miner algorithm
(implemented in C++) for finding the key associations in transaction
data.  The OPUS Miner algorithm uses the OPUS search algorithm to
efficiently discover the key associations in transaction data, in the
form of self-sufficient itemsets, using either leverage or lift.

opusminer can read transaction data directly from a file, from a list,
or from an object of class transactions (from the package arules).

Best,

Angus

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ssefick at gmail.com  Tue Feb 21 15:12:24 2017
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 21 Feb 2017 08:12:24 -0600
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <FA9FEE6A-5AED-411C-BE48-75AACE112711@comcast.net>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>
	<CADKEMqg2mbKUu9TNFu0ZC9GXFWNKV=Fy3eT_vX-6FkrztQ=BKQ@mail.gmail.com>
	<FA9FEE6A-5AED-411C-BE48-75AACE112711@comcast.net>
Message-ID: <CADKEMqj5-SYp-SkzcR10ERcYiGm7n+9dh7KEB0BOid0anKk4vw@mail.gmail.com>

Sorry for not being clear. I have never used S3 methods before. Below is
some R code that sketches out my idea. Is this a sensible solution?

test_data <- data.frame(a=1:10, b=1:10, c=1:10)

functionA <- function(x, impossible_genotype){
    ##some data processing
    y <- x

    ##return S3 to be able to use impossible genotype later
    class(y) <- append(class(y),"genotypes")

    attr(y, "impossible_genotype") <- impossible_genotype

    return(y)
}

test_data_genotypes <- functionA(test_data, impossible_genotype="Ref")

functionB <- function(x){
    ##stop if pre-processed with functionA
    if(sum(class(x)=="genotypes")!=1){stop("Need to pre-process data with
functionA")}

    ##use this later in functionB to
    impossible_genotype <- attributes(x)$impossible_genotype

    alleles <- c("Ref", "Alt")

    coded_genotype <- alleles[alleles!=impossible_genotype]



    return(coded_genotype)
}

##stop if not pre-processed with functionA
functionB(test_data)

##processed with functionA
functionB(test_data_genotypes)

On Tue, Feb 21, 2017 at 6:41 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Feb 20, 2017, at 4:43 PM, stephen sefick <ssefick at gmail.com> wrote:
> >
> > Hello All,
> >
> > I am writing a package. I would like to encourage the user to look at the
> > data to rectify errors with function A before utilizing function B to
> code
> > these data as binary. I thought about solving this problem by adding a
> > "flag" in the attributes that could be used downstream in B, and have a
> > function that adds this "flag" if the user is convinced that everything
> is
> > okay. This would allow the user to utilize their data as is, if error
> > checking is not necessary. Maybe I am overthinking this. Thanks again.
> > kindest regards,
>
> Still not clear what is needed but there is an `attr<-` function. You
> might get waht you wnat by having function A add an attribute which is then
> checked by B.
>
> --
> David
> >
> > Stephen
> >
> > On Mon, Feb 20, 2017 at 6:24 PM, Charles C. Berry <ccberry at ucsd.edu>
> wrote:
> >
> >> On Mon, 20 Feb 2017, stephen sefick wrote:
> >>
> >> Hello,
> >>>
> >>> I would like to add something to a data frame that is 1) invisible to
> the
> >>> user, 2) has no side effects, and 3) I can test for in a following
> >>> function. Is this possible? I am exploring classes and attributes and I
> >>> have thought about using a list (but 1 and 2 not satisfied). Any help
> >>> would
> >>> be greatly appreciated.
> >>>
> >>>
> >> Depends on exactly what you mean by `invisible' and `side effects'.
> >>
> >> You can do this (but I am not necessarily recommending this):
> >>
> >> add.stuff <- function(x,...){
> >>>
> >> + class(x)<- c("more.stuff",class(x))
> >> + attr(x,"stuff")<- list(...)
> >> + x}
> >>
> >>>
> >>>
> >> And printing and model functions will be unaffected:
> >>
> >> df <- data.frame(a=1:3,b=letters[1:3])
> >>> df2 <- add.stuff(df,comment="wow", length="3 rows")
> >>> df2
> >>>
> >>  a b
> >> 1 1 a
> >> 2 2 b
> >> 3 3 c
> >>
> >>> attr(df2,"stuff")
> >>>
> >> $comment
> >> [1] "wow"
> >>
> >> $length
> >> [1] "3 rows"
> >>
> >> all.equal(lm(a~b,df),lm(a~b,df2)) # only call should differ
> >>>
> >> [1] "Component ?call?: target, current do not match when deparsed"
> >>
> >>>
> >>>
> >> And if you need some generics to take account of the "stuff" attribute,
> >> you can write the methods to do that.
> >>
> >> ---
> >>
> >> Another solution is to put your data.framne in a package and then have
> >> other objects hold the 'stuff' stuff. Once your package is loaded or
> >> imported, the user will have access to the data in a way that might be
> said
> >> to be `invisible' in ordinary usage.
> >>
> >> ---
> >>
> >> But seriously, you should say *why* you want to do this. There are
> >> probably excellent solutions that do not involve directly altering the
> >> data.frame and may not involve putting together a package.
> >>
> >> HTH,
> >>
> >> Chuck
> >
> >
> >
> >
> > --
> > Let's not spend our time and resources thinking about things that are so
> > little or so large that all they really do for us is puff us up and make
> us
> > feel like gods.  We are mammals, and have not exhausted the annoying
> little
> > problems of being mammals.
> >
> >                                -K. Mullis
> >
> > "A big computer, a complex algorithm and a long time does not equal
> > science."
> >
> >                              -Robert Gentleman
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Feb 21 16:15:04 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 21 Feb 2017 09:15:04 -0600
Subject: [R] Yates correction
In-Reply-To: <e60833ce407540aab333388b00d98080@exch-2p-mbx-w2.ads.tamu.edu>
References: <CADGufDEpUDsPNpo0P3JtdEWBDgL6YV4p8G3R8dGDwdgMBzpXyw@mail.gmail.com>
	<e60833ce407540aab333388b00d98080@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CEA19A02-CE3C-4DAA-BB52-6A08A6E1D92C@me.com>

Hi,

In general, statistical questions that are more conceptual in nature, which is the case here, are generally frowned upon on this list, since they are considered off-topic here.

That being said, increasingly, both the Fisher Exact test and the use of the Yates correction to the Chi-Square test are being challenged as being overly conservative in small sample situations. The same goes for the common recommendation of switching to the Fisher Exact Test when there are any expected cell values of <5, which is what is generating the "Chi-squared approximation may be incorrect" in the examples below, since one of your expected cell values is 4.94.

There was a paper by Campbell back in 2007 that discussed this:
  
Chi-squared and Fisher?Irwin tests of two-by-two tables with small sample recommendations
http://onlinelibrary.wiley.com/doi/10.1002/sim.2832/abstract

and he has a web site here with additional resources:

http://www.iancampbell.co.uk/twobytwo/twobytwo.htm

Even using his 'n-1' variant of the test with his online calculator on the above web site, you end up with a p value of 0.5, which is close to the p value for the uncorrected chi-square (chisq.test() with correct = FALSE) of 0.4925. Thus, none of these cases results in a "statistically significant" p value of <=0.05. Not that you should be p value hunting anyway here. 

The whole p value discussion is further from being on topic here, but under none of these hypothesis tests would you reject the null.

Further consultation with a local statistical expert would seem prudent.

Regards,

Marc Schwartz


> On Feb 21, 2017, at 7:40 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> Use fisher.test(). Yates' correction compensates for a tendency for Chi-square to be overestimated in a 2x2 table, but Yates' can overcompensate, reducing Chi-square too much. It's main advantage was when computers were expensive and Fisher's Exact was hard to compute by hand.  You can see from the following that Fisher's Exact estimates the p-value as .717, a bit less than .7477.
> 
>> M <- matrix(c(8, 12, 4, 10), 2, 2)
>> fisher.test(M)
> 
>        Fisher's Exact Test for Count Data
> 
> data:  M
> p-value = 0.717
> alternative hypothesis: true odds ratio is not equal to 1
> 95 percent confidence interval:
> 0.3160571 9.7976232
> sample estimates:
> odds ratio 
>  1.641969
> 
> An alternative would be to let chisq.test() use simulations to estimate the p-value:
> 
>> chisq.test(M, simulate.p.value=TRUE)
> 
>        Pearson's Chi-squared test with simulated p-value (based on 2000 replicates)
> 
> data:  M
> X-squared = 0.471, df = NA, p-value = 0.7141
> 
> Which agrees pretty well with fisher.test(). The X-squared value of 0.471 is the uncorrected value so you can see that the Yates' correction reduced it substantially (to .1035).
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jomy Jose
> Sent: Tuesday, February 21, 2017 4:48 AM
> To: r-help at r-project.org
> Subject: [R] Yates correction
> 
> I tried to do chi square test for the following observed frequencies
> ---------------------------------------------------------------------------------------------
>   A  B
> A  8  4
> B 12 10
> 
> R gave the following output:
> -------------------------------------------------------------------------------------------
>        Pearson's Chi-squared test with Yates' continuity correction
> 
> data:  M
> X-squared = 0.10349, df = 1, p-value = 0.7477
> 
> Warning message:
> In chisq.test(M) : Chi-squared approximation may be incorrect
> 
> ---------------------------------------------------------------------------------------------------------------
> Whether this result can be relied or we have to use Fishers exact test ?
> 
> Jose


From george.trojan at noaa.gov  Tue Feb 21 17:30:35 2017
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Tue, 21 Feb 2017 16:30:35 +0000
Subject: [R] Question about logspline
Message-ID: <CABie7_qr5k1TRO7C5v34qYT-A_m0ZSsxBPzG1JBCTSvEhH2yHg@mail.gmail.com>

I have a dataset with values of limited precision. I am trying to plot its
density using package logspline. The logspline() call with default
parameters causes oscillations in the density plot. My solution was to
fuzzify the input values, using function:

 > fuzz <- function(x, prec) x + runif(length(x), -prec / 2, prec /2)

Is there a better idea, perhaps setting mind?

Example:

> x <- seq(-1, 1, by = 0.01)
> ds <- rnorm(1000, sd = 0.2)
> hist(ds, breaks = 40, freq = FALSE)
> s <- logspline(ds)
> lines(x, dlogspline(x, s), col = "red")
> ds2 <- as.numeric(sapply(ds, function(x) sprintf("%.1f", x)))
> s2 <- logspline(ds2)
> lines(x, dlogspline(x, s2), col = "blue")
> ds3 <- fuzz(ds2, 0.1)
> s3 <- logspline(ds3)
> lines(x, dlogspline(x, s3), col = "green")
>

George

	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Tue Feb 21 17:30:45 2017
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Tue, 21 Feb 2017 08:30:45 -0800
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CADKEMqj5-SYp-SkzcR10ERcYiGm7n+9dh7KEB0BOid0anKk4vw@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>
	<CADKEMqg2mbKUu9TNFu0ZC9GXFWNKV=Fy3eT_vX-6FkrztQ=BKQ@mail.gmail.com>
	<FA9FEE6A-5AED-411C-BE48-75AACE112711@comcast.net>
	<CADKEMqj5-SYp-SkzcR10ERcYiGm7n+9dh7KEB0BOid0anKk4vw@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1702210815470.669@charles-berrys-macbook.local>

On Tue, 21 Feb 2017, stephen sefick wrote:

> Sorry for not being clear. I have never used S3 methods before. Below is
> some R code that sketches out my idea. Is this a sensible solution?
>

Sure. See comments (untested) inline.

Chuck

> test_data <- data.frame(a=1:10, b=1:10, c=1:10)
>
> functionA <- function(x, impossible_genotype){
>    ##some data processing
>    y <- x
>
>    ##return S3 to be able to use impossible genotype later
>    class(y) <- append(class(y),"genotypes")

      class(y) <- c("genotypes",class(y))

>
>    attr(y, "impossible_genotype") <- impossible_genotype
>
>    return(y)
> }
>
> test_data_genotypes <- functionA(test_data, impossible_genotype="Ref")
>
> functionB <- function(x){
>    ##stop if pre-processed with functionA
>    if(sum(class(x)=="genotypes")!=1){stop("Need to pre-process data with
> functionA")}

     if(!(inherits("genotypes")){
 	stop("Need to pre-process data with functionA")}


or in functionA you could skip the class()<- and just set the
"impossible_genotypes" attribute to FALSE when there are none such.

Then here test

      if (is.null(attr(x,"impossible_genotypes"))){
 		stop("Need to pre-process data with functionA")
 	} else {
 		return(alleles)
 	}


>
>    ##use this later in functionB to
>    impossible_genotype <- attributes(x)$impossible_genotype

      impossible_genotype <- attr(x,"impossible_genotype")
>
>    alleles <- c("Ref", "Alt")
>
>    coded_genotype <- alleles[alleles!=impossible_genotype]

      maybe `!is.element(alleles,impossible_genotype)' is safer than `!='

>
>
>
>    return(coded_genotype)
> }
>
> ##stop if not pre-processed with functionA
> functionB(test_data)
>
> ##processed with functionA
> functionB(test_data_genotypes)
>


From sstoline at gmail.com  Tue Feb 21 15:38:13 2017
From: sstoline at gmail.com (Steven Stoline)
Date: Tue, 21 Feb 2017 09:38:13 -0500
Subject: [R] Cronbach's Alpha Values
Message-ID: <CAHDp66AUD6fCm13tg8aPrecLkaGK1vmrtM0GCGf-uDG1-pHW=w@mail.gmail.com>

Dear All:


I am using *alpha(data, **check.keys=TRUE) *to compute the Cronbach's
Alpha. I am using  *check.keys=TRUE*  to automatically reverse items.


*My question is: *how can I get the correlation tables (matrix) of the
reverse items as part of the R output.



thank you
steve

-- 
Steven M. Stoline
sstoline at gmail.com

	[[alternative HTML version deleted]]


From sstoline at gmail.com  Tue Feb 21 16:43:00 2017
From: sstoline at gmail.com (Steven Stoline)
Date: Tue, 21 Feb 2017 10:43:00 -0500
Subject: [R] Correlations Table of Items when compute Cronbach's Alpha
Message-ID: <CAHDp66BMC9ZKT45Euk1sZ+2GhyPwhyFZjvAtYW3rsERigTnc3g@mail.gmail.com>

Dear All:


I am using *alpha(data, **check.keys=TRUE)  or  alpha(data, keys = c(1, 1,
1, -1))*  to compute the Cronbach's Alpha. I am using  *check.keys=TRUE*
or *keys = c(1, 1, 1, -1) *to automatically reverse items.


*My question is: *how can I get the correlation tables (matrix) of the
reversed items as part of the R output.



*Here is an example of the data set:*


 X1 X2 X3 X4
  2  5   4   4
  1  1   1   6
  1  2   1   6
  2  3   2   4
  1  2   1   6
  1  3   1   6
  2  2   2   5
  2  1   1   6
  2  2   4   5
  5  5   2   1
  1  3   1   6
  1  1   1   6
  1  1   1   6
  2  2   2   5
  2  2   2   2
  1  6   1   6
  1  2   1   6
  2  2   3   5
  2  5   4   5
  2  1   2   6
  2  2   1   5
  2  2   2   6
  1  1   1   6
  1  1   1   6
  1  1   1   5
  1  2   2   5
  2  2   2   5
  1  2   2   5
  1  4   2   5
  2  2   2   2
  2  2   4   5
  2  1   2   5
  2  2   2   5
  2  2   2   5
  2  2   2   5
  2  2   2   5
  5  2   2   5
  2  2   1   5
  2  5   6   2
  2  4   2   5
  2  2   2   4
  2  3   5   1
  3  3   3   6
  2  2   2   4
  2  2   2   5
  2  2   2   5
  1  1   1   6
  1  1   1   5
  6  1   1   6
  1  1   1   6
  2  6   4   3
  1  1   1   6
  1  1   1   6
  4  5   5   5
  5  2   2   5
  2  2   2   5
  1  2   1   6
  1  5   1   6
  1  4   2   5
  2  1   1   5
  4  2   1   5
  2  2   2   5
  1  1   1   6
  6  1   1   4
  1  2   1   6
  1  1   1   5
  1  1   1   6
  1  4   1   3
  1  1   1   6
  5  2   2   5
  2  2   2   5
  1  1   1   6
  1  1   1   5
  4  4   2   4
  3  2   2   5
  1  2   1   6
  1  2   1   6
  2  1   1   5
  2  6   1   6
  4  3   1   5
  1  1   1   5
  1  1   1   6
  4  5   4   5
  1  1   1   2
  1  1   1   6
  1  1   1   6
  4  4   3   4
  2  2   2   4
  1  2   2   4
  1  1   1   6
  2  3   2   5
  2  6  NA   5
  2  2   2   5
  1  2   3   4
  2  1   2   5
  1  2   2   6
  1  1   2   6
  1  2   2   5
  2  2   2   5
  1  5   5   2
  1  2   1   5
  1  5   2   4
  2  4   1   6
  6  1   1   2
  2  2   2   5
  1  1   1   6
  1  1   1   2
  2  2   2   4
  1  1   1   6
  4  2   2   5
  2  3   1   5
  2  1   2   5
  2  2   1   5
  1  2   2   5
  1  2   1   5
  6  2   2   4
  2  2   5   2
  2  5   3   5
  1  4   4   4
  1  1   1   6


thank you
steve

------------------------
Steven M. Stoline
sstoline at gmail.com

	[[alternative HTML version deleted]]


From ac.dasilva at ulg.ac.be  Tue Feb 21 17:23:30 2017
From: ac.dasilva at ulg.ac.be (ac.dasilva at ulg.ac.be)
Date: Tue, 21 Feb 2017 17:23:30 +0100 (CET)
Subject: [R] Multiply row of a matrix
In-Reply-To: <mailman.0.1487693413.9626.r-help@r-project.org>
References: <mailman.0.1487693413.9626.r-help@r-project.org>
Message-ID: <771991607.854364.1487694210349.JavaMail.zimbra@ulg.ac.be>

If we have the following matrix: 

Mat<-matrix(1:9, byrow=TRUE, nrow=3)
Mat

     [,1] [,2] [,3]
[1,]    1    2    3
[2,]    4    5    6
[3,]    7    8    9

 I would like to have each row multiplied by a different number. 
So I would like row 1 multiplied by 3, row2 by 1 and row3 by 0.5
Which would give: 

     [,1] [,2] [,3]
[1,]    3    6    9
[2,]    4    5    6
[3,]    3.5  4    4.5


Whatever I try, I always obtain 
     [,1] [,2] [,3]
[1,]    3    2  1.5
[2,]   12    5  3.0
[3,]   21    8  4.5

Which corresponds to the columns multiplied by the factors 

Could anyone help we to get the proper result ?
Best, Anne-Christine da Silva


From wdunlap at tibco.com  Tue Feb 21 17:52:06 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 21 Feb 2017 08:52:06 -0800
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <alpine.OSX.2.20.1702210815470.669@charles-berrys-macbook.local>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>
	<CADKEMqg2mbKUu9TNFu0ZC9GXFWNKV=Fy3eT_vX-6FkrztQ=BKQ@mail.gmail.com>
	<FA9FEE6A-5AED-411C-BE48-75AACE112711@comcast.net>
	<CADKEMqj5-SYp-SkzcR10ERcYiGm7n+9dh7KEB0BOid0anKk4vw@mail.gmail.com>
	<alpine.OSX.2.20.1702210815470.669@charles-berrys-macbook.local>
Message-ID: <CAF8bMcaC3VN+pos8AC7erS4Fv0qTUyt64vQFuXi5=1cHgHkFyA@mail.gmail.com>

Stray attributes on data.frames may or may not survive some simple
operations on the data.frame.  E.g.,

> d <- data.frame(X=1:5, Y=log(1:5), G=factor(rep(c("a","b"),c(2,3))))
> attr(d, "checked") <- TRUE
> wasChecked <- function(x) isTRUE(attr(x, "checked"))
> wasChecked(d)
[1] TRUE
> wasChecked(d[1:4,]) # select some rows
[1] TRUE
> wasChecked(d[,1:2]) # select some columns
[1] FALSE
> d[1,1] <- 10 # change a single value
> wasChecked(d)
[1] TRUE
> d$NewColumn <- 11:15 # add a column
> wasChecked(d)
[1] TRUE

I don't know if this would be an issue in your case.  If it is, you
could subclass "data.frame" and define methods so that the operations
of interest preserve or remove the attribute in the way that you
desire.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Feb 21, 2017 at 8:30 AM, Charles C. Berry <ccberry at ucsd.edu> wrote:
> On Tue, 21 Feb 2017, stephen sefick wrote:
>
>> Sorry for not being clear. I have never used S3 methods before. Below is
>> some R code that sketches out my idea. Is this a sensible solution?
>>
>
> Sure. See comments (untested) inline.
>
> Chuck
>
>> test_data <- data.frame(a=1:10, b=1:10, c=1:10)
>>
>> functionA <- function(x, impossible_genotype){
>>    ##some data processing
>>    y <- x
>>
>>    ##return S3 to be able to use impossible genotype later
>>    class(y) <- append(class(y),"genotypes")
>
>
>      class(y) <- c("genotypes",class(y))
>
>>
>>    attr(y, "impossible_genotype") <- impossible_genotype
>>
>>    return(y)
>> }
>>
>> test_data_genotypes <- functionA(test_data, impossible_genotype="Ref")
>>
>> functionB <- function(x){
>>    ##stop if pre-processed with functionA
>>    if(sum(class(x)=="genotypes")!=1){stop("Need to pre-process data with
>> functionA")}
>
>
>     if(!(inherits("genotypes")){
>         stop("Need to pre-process data with functionA")}
>
>
> or in functionA you could skip the class()<- and just set the
> "impossible_genotypes" attribute to FALSE when there are none such.
>
> Then here test
>
>      if (is.null(attr(x,"impossible_genotypes"))){
>                 stop("Need to pre-process data with functionA")
>         } else {
>                 return(alleles)
>         }
>
>
>>
>>    ##use this later in functionB to
>>    impossible_genotype <- attributes(x)$impossible_genotype
>
>
>      impossible_genotype <- attr(x,"impossible_genotype")
>>
>>
>>    alleles <- c("Ref", "Alt")
>>
>>    coded_genotype <- alleles[alleles!=impossible_genotype]
>
>
>      maybe `!is.element(alleles,impossible_genotype)' is safer than `!='
>
>>
>>
>>
>>    return(coded_genotype)
>> }
>>
>> ##stop if not pre-processed with functionA
>> functionB(test_data)
>>
>> ##processed with functionA
>> functionB(test_data_genotypes)
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Feb 21 18:00:59 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 21 Feb 2017 09:00:59 -0800
Subject: [R] Multiply row of a matrix
In-Reply-To: <771991607.854364.1487694210349.JavaMail.zimbra@ulg.ac.be>
References: <mailman.0.1487693413.9626.r-help@r-project.org>
	<771991607.854364.1487694210349.JavaMail.zimbra@ulg.ac.be>
Message-ID: <CAF8bMcakNuN6bATc5vyWrxsM3kOsBg+c4A3H8WJzrzsNzPamug@mail.gmail.com>

> Mat * c(3, 1, 0.5)
     [,1] [,2] [,3]
[1,]  3.0    6  9.0
[2,]  4.0    5  6.0
[3,]  3.5    4  4.5


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Feb 21, 2017 at 8:23 AM,  <ac.dasilva at ulg.ac.be> wrote:
> If we have the following matrix:
>
> Mat<-matrix(1:9, byrow=TRUE, nrow=3)
> Mat
>
>      [,1] [,2] [,3]
> [1,]    1    2    3
> [2,]    4    5    6
> [3,]    7    8    9
>
>  I would like to have each row multiplied by a different number.
> So I would like row 1 multiplied by 3, row2 by 1 and row3 by 0.5
> Which would give:
>
>      [,1] [,2] [,3]
> [1,]    3    6    9
> [2,]    4    5    6
> [3,]    3.5  4    4.5
>
>
> Whatever I try, I always obtain
>      [,1] [,2] [,3]
> [1,]    3    2  1.5
> [2,]   12    5  3.0
> [3,]   21    8  4.5
>
> Which corresponds to the columns multiplied by the factors
>
> Could anyone help we to get the proper result ?
> Best, Anne-Christine da Silva
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Tue Feb 21 18:13:58 2017
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 21 Feb 2017 17:13:58 +0000
Subject: [R] Correlations Table of Items when compute Cronbach's Alpha
In-Reply-To: <CAHDp66BMC9ZKT45Euk1sZ+2GhyPwhyFZjvAtYW3rsERigTnc3g@mail.gmail.com>
References: <CAHDp66BMC9ZKT45Euk1sZ+2GhyPwhyFZjvAtYW3rsERigTnc3g@mail.gmail.com>
Message-ID: <5C82BA8C-2D8A-43EC-B811-F145C6527277@TxBiomed.org>

Have you looked at the help page?
?alpha::alpha

See the section labeled Value.

Look at
output <- alpha(data, keys = c(1, 1, 1, -1))
output$r
output$r.cor
output$r.drop


R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Feb 21, 2017, at 9:43 AM, Steven Stoline <sstoline at gmail.com> wrote:
>
> Dear All:
>
>
> I am using *alpha(data, **check.keys=TRUE)  or  alpha(data, keys = c(1, 1,
> 1, -1))*  to compute the Cronbach's Alpha. I am using  *check.keys=TRUE*
> or *keys = c(1, 1, 1, -1) *to automatically reverse items.
>
>
> *My question is: *how can I get the correlation tables (matrix) of the
> reversed items as part of the R output.
>
>
>
> *Here is an example of the data set:*
>
>
> X1 X2 X3 X4
>  2  5   4   4
>  1  1   1   6
>  1  2   1   6
>  2  3   2   4
>  1  2   1   6
>  1  3   1   6
>  2  2   2   5
>  2  1   1   6
>  2  2   4   5
>  5  5   2   1
>  1  3   1   6
>  1  1   1   6
>  1  1   1   6
>  2  2   2   5
>  2  2   2   2
>  1  6   1   6
>  1  2   1   6
>  2  2   3   5
>  2  5   4   5
>  2  1   2   6
>  2  2   1   5
>  2  2   2   6
>  1  1   1   6
>  1  1   1   6
>  1  1   1   5
>  1  2   2   5
>  2  2   2   5
>  1  2   2   5
>  1  4   2   5
>  2  2   2   2
>  2  2   4   5
>  2  1   2   5
>  2  2   2   5
>  2  2   2   5
>  2  2   2   5
>  2  2   2   5
>  5  2   2   5
>  2  2   1   5
>  2  5   6   2
>  2  4   2   5
>  2  2   2   4
>  2  3   5   1
>  3  3   3   6
>  2  2   2   4
>  2  2   2   5
>  2  2   2   5
>  1  1   1   6
>  1  1   1   5
>  6  1   1   6
>  1  1   1   6
>  2  6   4   3
>  1  1   1   6
>  1  1   1   6
>  4  5   5   5
>  5  2   2   5
>  2  2   2   5
>  1  2   1   6
>  1  5   1   6
>  1  4   2   5
>  2  1   1   5
>  4  2   1   5
>  2  2   2   5
>  1  1   1   6
>  6  1   1   4
>  1  2   1   6
>  1  1   1   5
>  1  1   1   6
>  1  4   1   3
>  1  1   1   6
>  5  2   2   5
>  2  2   2   5
>  1  1   1   6
>  1  1   1   5
>  4  4   2   4
>  3  2   2   5
>  1  2   1   6
>  1  2   1   6
>  2  1   1   5
>  2  6   1   6
>  4  3   1   5
>  1  1   1   5
>  1  1   1   6
>  4  5   4   5
>  1  1   1   2
>  1  1   1   6
>  1  1   1   6
>  4  4   3   4
>  2  2   2   4
>  1  2   2   4
>  1  1   1   6
>  2  3   2   5
>  2  6  NA   5
>  2  2   2   5
>  1  2   3   4
>  2  1   2   5
>  1  2   2   6
>  1  1   2   6
>  1  2   2   5
>  2  2   2   5
>  1  5   5   2
>  1  2   1   5
>  1  5   2   4
>  2  4   1   6
>  6  1   1   2
>  2  2   2   5
>  1  1   1   6
>  1  1   1   2
>  2  2   2   4
>  1  1   1   6
>  4  2   2   5
>  2  3   1   5
>  2  1   2   5
>  2  2   1   5
>  1  2   2   5
>  1  2   1   5
>  6  2   2   4
>  2  2   5   2
>  2  5   3   5
>  1  4   4   4
>  1  1   1   6
>
>
> thank you
> steve
>
> ------------------------
> Steven M. Stoline
> sstoline at gmail.com
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From tmrsg11 at gmail.com  Tue Feb 21 18:29:38 2017
From: tmrsg11 at gmail.com (C W)
Date: Tue, 21 Feb 2017 12:29:38 -0500
Subject: [R] Error in match.fun(f) : object 'x' not found
Message-ID: <CAE2FW2nNFCuzNFWYcWzjnWObKwYSN0kLsyYUrmM7zH9P3YSv_g@mail.gmail.com>

Dear R list,

I am having a little trouble understanding the R code. I want to compute
expectation of normal pdf.

I did the following:

integrate(x*dnorm(x, rate=1), -Inf, Inf)
Error in match.fun(f) : object 'x' not found

If I did this, I get,
integrate(dexp(x, rate=1), -Inf, Inf)
Error in dexp(x, rate = 1) : object 'x' not found

How should I fix this? I remember when I did it for curve(), it was fine.

curve(pexp(x, rate = 1/2), from = 0, to = 5)

What am I not getting here? Thank you so much!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Feb 21 18:34:30 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 21 Feb 2017 09:34:30 -0800
Subject: [R] Multiply row of a matrix
In-Reply-To: <CAF8bMcakNuN6bATc5vyWrxsM3kOsBg+c4A3H8WJzrzsNzPamug@mail.gmail.com>
References: <mailman.0.1487693413.9626.r-help@r-project.org>
	<771991607.854364.1487694210349.JavaMail.zimbra@ulg.ac.be>
	<CAF8bMcakNuN6bATc5vyWrxsM3kOsBg+c4A3H8WJzrzsNzPamug@mail.gmail.com>
Message-ID: <6C1F4D6E-87E4-4350-B014-9A694D27CB46@dcn.davis.ca.us>

Why this works does not become clear until you actually pay attention to how matrices are laid out in memory as a vector, and how vector replication works.  Those ideas are not that difficult to learn, but they feel different than in other languages (e.g. matlab) and they make a huge difference when you want to speed things up. Read the appropriate section in the Introduction to R document that comes with R until you see what is happening, and ask for clarification if you are still lost. 
-- 
Sent from my phone. Please excuse my brevity.

On February 21, 2017 9:00:59 AM PST, William Dunlap via R-help <r-help at r-project.org> wrote:
>> Mat * c(3, 1, 0.5)
>     [,1] [,2] [,3]
>[1,]  3.0    6  9.0
>[2,]  4.0    5  6.0
>[3,]  3.5    4  4.5
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Tue, Feb 21, 2017 at 8:23 AM,  <ac.dasilva at ulg.ac.be> wrote:
>> If we have the following matrix:
>>
>> Mat<-matrix(1:9, byrow=TRUE, nrow=3)
>> Mat
>>
>>      [,1] [,2] [,3]
>> [1,]    1    2    3
>> [2,]    4    5    6
>> [3,]    7    8    9
>>
>>  I would like to have each row multiplied by a different number.
>> So I would like row 1 multiplied by 3, row2 by 1 and row3 by 0.5
>> Which would give:
>>
>>      [,1] [,2] [,3]
>> [1,]    3    6    9
>> [2,]    4    5    6
>> [3,]    3.5  4    4.5
>>
>>
>> Whatever I try, I always obtain
>>      [,1] [,2] [,3]
>> [1,]    3    2  1.5
>> [2,]   12    5  3.0
>> [3,]   21    8  4.5
>>
>> Which corresponds to the columns multiplied by the factors
>>
>> Could anyone help we to get the proper result ?
>> Best, Anne-Christine da Silva
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Tue Feb 21 18:39:03 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 21 Feb 2017 18:39:03 +0100
Subject: [R] Error in match.fun(f) : object 'x' not found
In-Reply-To: <CAE2FW2nNFCuzNFWYcWzjnWObKwYSN0kLsyYUrmM7zH9P3YSv_g@mail.gmail.com>
References: <CAE2FW2nNFCuzNFWYcWzjnWObKwYSN0kLsyYUrmM7zH9P3YSv_g@mail.gmail.com>
Message-ID: <fb30e3a1-4af1-6145-944e-ce95e7d9e79c@statistik.tu-dortmund.de>



On 21.02.2017 18:29, C W wrote:
> Dear R list,
>
> I am having a little trouble understanding the R code. I want to compute
> expectation of normal pdf.
>
> I did the following:
>
> integrate(x*dnorm(x, rate=1), -Inf, Inf)


integrate needs a function as first argument, hence:

  integrate(function(x) x*dnorm(x, rate=1), -Inf, Inf)

and then you have the next error that is more obvious to fix...



> Error in match.fun(f) : object 'x' not found
>
> If I did this, I get,
> integrate(dexp(x, rate=1), -Inf, Inf)
> Error in dexp(x, rate = 1) : object 'x' not found

same here.


> How should I fix this? I remember when I did it for curve(), it was fine.
>
> curve(pexp(x, rate = 1/2), from = 0, to = 5)

curve() is an exception in that it can use an unevaluated  function call.

Best,
Uwe Ligges



> What am I not getting here? Thank you so much!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Tue Feb 21 18:44:15 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 21 Feb 2017 17:44:15 +0000
Subject: [R] Correlations Table of Items when compute Cronbach's Alpha
In-Reply-To: <5C82BA8C-2D8A-43EC-B811-F145C6527277@TxBiomed.org>
References: <CAHDp66BMC9ZKT45Euk1sZ+2GhyPwhyFZjvAtYW3rsERigTnc3g@mail.gmail.com>
	<5C82BA8C-2D8A-43EC-B811-F145C6527277@TxBiomed.org>
Message-ID: <7977d63d5a0e49d88ce18621a2b1daec@exch-2p-mbx-w2.ads.tamu.edu>

Actually you will need ?psych::alpha to get the help page. The correlations provided in output$item.stats are with the total score. If you want a correlation matrix for the original 4 variables you can use sweep() to invert the necessary column(s):

> cor(sweep(dat, 2, c(1, 1, 1, -1), FUN="*"), use="complete.obs")
          X1        X2        X3        X4
X1 1.0000000 0.1396653 0.1916540 0.2865590
X2 0.1396653 1.0000000 0.5184912 0.2938423
X3 0.1916540 0.5184912 1.0000000 0.5037861
X4 0.2865590 0.2938423 0.5037861 1.0000000

If you use check.keys=TRUE you can extract the vector from the results:

> output <- alpha(dat, check.keys=TRUE)
Warning message:
In alpha(dat, check.keys = TRUE) :
  Some items were negatively correlated with total scale and were automatically reversed.
 This is indicated by a negative sign for the variable name.
> output$keys
[1]  1  1  1 -1

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mark Sharp
Sent: Tuesday, February 21, 2017 11:14 AM
To: Steven Stoline <sstoline at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Correlations Table of Items when compute Cronbach's Alpha

Have you looked at the help page?
?alpha::alpha

See the section labeled Value.

Look at
output <- alpha(data, keys = c(1, 1, 1, -1))
output$r
output$r.cor
output$r.drop


R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Feb 21, 2017, at 9:43 AM, Steven Stoline <sstoline at gmail.com> wrote:
>
> Dear All:
>
>
> I am using *alpha(data, **check.keys=TRUE)  or  alpha(data, keys = c(1, 1,
> 1, -1))*  to compute the Cronbach's Alpha. I am using  *check.keys=TRUE*
> or *keys = c(1, 1, 1, -1) *to automatically reverse items.
>
>
> *My question is: *how can I get the correlation tables (matrix) of the
> reversed items as part of the R output.
>
>
>
> *Here is an example of the data set:*
>
>
> X1 X2 X3 X4
>  2  5   4   4
>  1  1   1   6
>  1  2   1   6
>  2  3   2   4
>  1  2   1   6
>  1  3   1   6
>  2  2   2   5
>  2  1   1   6
>  2  2   4   5
>  5  5   2   1
>  1  3   1   6
>  1  1   1   6
>  1  1   1   6
>  2  2   2   5
>  2  2   2   2
>  1  6   1   6
>  1  2   1   6
>  2  2   3   5
>  2  5   4   5
>  2  1   2   6
>  2  2   1   5
>  2  2   2   6
>  1  1   1   6
>  1  1   1   6
>  1  1   1   5
>  1  2   2   5
>  2  2   2   5
>  1  2   2   5
>  1  4   2   5
>  2  2   2   2
>  2  2   4   5
>  2  1   2   5
>  2  2   2   5
>  2  2   2   5
>  2  2   2   5
>  2  2   2   5
>  5  2   2   5
>  2  2   1   5
>  2  5   6   2
>  2  4   2   5
>  2  2   2   4
>  2  3   5   1
>  3  3   3   6
>  2  2   2   4
>  2  2   2   5
>  2  2   2   5
>  1  1   1   6
>  1  1   1   5
>  6  1   1   6
>  1  1   1   6
>  2  6   4   3
>  1  1   1   6
>  1  1   1   6
>  4  5   5   5
>  5  2   2   5
>  2  2   2   5
>  1  2   1   6
>  1  5   1   6
>  1  4   2   5
>  2  1   1   5
>  4  2   1   5
>  2  2   2   5
>  1  1   1   6
>  6  1   1   4
>  1  2   1   6
>  1  1   1   5
>  1  1   1   6
>  1  4   1   3
>  1  1   1   6
>  5  2   2   5
>  2  2   2   5
>  1  1   1   6
>  1  1   1   5
>  4  4   2   4
>  3  2   2   5
>  1  2   1   6
>  1  2   1   6
>  2  1   1   5
>  2  6   1   6
>  4  3   1   5
>  1  1   1   5
>  1  1   1   6
>  4  5   4   5
>  1  1   1   2
>  1  1   1   6
>  1  1   1   6
>  4  4   3   4
>  2  2   2   4
>  1  2   2   4
>  1  1   1   6
>  2  3   2   5
>  2  6  NA   5
>  2  2   2   5
>  1  2   3   4
>  2  1   2   5
>  1  2   2   6
>  1  1   2   6
>  1  2   2   5
>  2  2   2   5
>  1  5   5   2
>  1  2   1   5
>  1  5   2   4
>  2  4   1   6
>  6  1   1   2
>  2  2   2   5
>  1  1   1   6
>  1  1   1   2
>  2  2   2   4
>  1  1   1   6
>  4  2   2   5
>  2  3   1   5
>  2  1   2   5
>  2  2   1   5
>  1  2   2   5
>  1  2   1   5
>  6  2   2   4
>  2  2   5   2
>  2  5   3   5
>  1  4   4   4
>  1  1   1   6
>
>
> thank you
> steve
>
> ------------------------
> Steven M. Stoline
> sstoline at gmail.com
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:9}}


From pdalgd at gmail.com  Tue Feb 21 19:56:21 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 21 Feb 2017 19:56:21 +0100
Subject: [R] Error in match.fun(f) : object 'x' not found
In-Reply-To: <CAE2FW2nNFCuzNFWYcWzjnWObKwYSN0kLsyYUrmM7zH9P3YSv_g@mail.gmail.com>
References: <CAE2FW2nNFCuzNFWYcWzjnWObKwYSN0kLsyYUrmM7zH9P3YSv_g@mail.gmail.com>
Message-ID: <BF80085C-FC7E-452F-A567-9D6A78B58073@gmail.com>

The curve() function is being (overly?) clever in allowing nonstandard evaluation to let you specify an expression for the function argument. For integrate(), you need to go the standard way and set up an actual function of 1 argument and pass that. It's not all that hard:

> f <- function(x) x*dnorm(x, mean=1.234)
> integrate(f, -Inf, Inf)
1.234 with absolute error < 3.1e-07

(In fact, reading the examples on the help page for integrate() might have gotten you there faster than writing for help...)

Notice, incidentally, that curve() also works with functions:

> curve(f, -2, 4)

-pd

On 21 Feb 2017, at 18:29 , C W <tmrsg11 at gmail.com> wrote:

> Dear R list,
> 
> I am having a little trouble understanding the R code. I want to compute
> expectation of normal pdf.
> 
> I did the following:
> 
> integrate(x*dnorm(x, rate=1), -Inf, Inf)
> Error in match.fun(f) : object 'x' not found
> 
> If I did this, I get,
> integrate(dexp(x, rate=1), -Inf, Inf)
> Error in dexp(x, rate = 1) : object 'x' not found
> 
> How should I fix this? I remember when I did it for curve(), it was fine.
> 
> curve(pexp(x, rate = 1/2), from = 0, to = 5)
> 
> What am I not getting here? Thank you so much!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From suttoncarl at ymail.com  Tue Feb 21 22:21:08 2017
From: suttoncarl at ymail.com (Carl Sutton)
Date: Tue, 21 Feb 2017 21:21:08 +0000 (UTC)
Subject: [R] Confused about using data.table package,
References: <835232876.2007851.1487712068087.ref@mail.yahoo.com>
Message-ID: <835232876.2007851.1487712068087@mail.yahoo.com>

Hi
I have found that:A)? Hadley's new book to be wonderful on how to use dplyr, ggplot2 and his other packages.? Read this and using as a reference saves major frustration.
b)? Data Camps courses on ggplot2 are also wonderful.? GGPLOT2 has more capability than I have mastered or needed.? To be an expert with ggplot2 will take some effort.? To just get run of the mill helpful, beautiful plots, no major time needed for that.
I use both of these sources regularly, especially when what is in my grey matter memory banks is not working.? Refreshers are sometimes needed. 

If your data sets are large and available memory limited, then data.table is the package I use.?? I am amazed at the difference of memory usage with data.table versus other packages.? My laptop has 16gb ram, and tidyr maxed it but data.table melt used less than 6gb(if I remember correctly) on my current work.? Since discovering fread and fwrite, read.table, read.csv, and write have been benched.?? Every script I have includes library(data.table)

Carl Sutton
	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Tue Feb 21 22:40:30 2017
From: tmrsg11 at gmail.com (C W)
Date: Tue, 21 Feb 2017 16:40:30 -0500
Subject: [R] Confused about using data.table package,
In-Reply-To: <835232876.2007851.1487712068087@mail.yahoo.com>
References: <835232876.2007851.1487712068087.ref@mail.yahoo.com>
	<835232876.2007851.1487712068087@mail.yahoo.com>
Message-ID: <CAE2FW2mmJFBbgZkOszKoLxm=udCOJ6iYDRPS7ex_eGTMpmnucg@mail.gmail.com>

Hi Carl,

I have not fully learned dplyr, but it seems harder than tapply() and the
?apply() family in general.

Almost every ggplot2 data I have seen is manipulated using dplyr. Something
must be good about dplyr.

aggregate(), tapply(), do.call(), rbind() will be sorely missed! :(

Thanks!

On Tue, Feb 21, 2017 at 4:21 PM, Carl Sutton <suttoncarl at ymail.com> wrote:

> Hi
>
> I have found that:
> A)  Hadley's new book to be wonderful on how to use dplyr, ggplot2 and his
> other packages.  Read this and using as a reference saves major frustration.
> b)  Data Camps courses on ggplot2 are also wonderful.  GGPLOT2 has more
> capability than I have mastered or needed.  To be an expert with ggplot2
> will take some effort.  To just get run of the mill helpful, beautiful
> plots, no major time needed for that.
>
> I use both of these sources regularly, especially when what is in my grey
> matter memory banks is not working.  Refreshers are sometimes needed.
>
> If your data sets are large and available memory limited, then data.table
> is the package I use.   I am amazed at the difference of memory usage with
> data.table versus other packages.  My laptop has 16gb ram, and tidyr maxed
> it but data.table melt used less than 6gb(if I remember correctly) on my
> current work.  Since discovering fread and fwrite, read.table, read.csv,
> and write have been benched.   Every script I have includes
> library(data.table)
>
> Carl Sutton
>

	[[alternative HTML version deleted]]


From philipt900 at iinet.net.au  Tue Feb 21 22:47:00 2017
From: philipt900 at iinet.net.au (P Tennant)
Date: Wed, 22 Feb 2017 08:47:00 +1100
Subject: [R] Confused about using data.table package,
In-Reply-To: <CAE2FW2mmJFBbgZkOszKoLxm=udCOJ6iYDRPS7ex_eGTMpmnucg@mail.gmail.com>
References: <835232876.2007851.1487712068087.ref@mail.yahoo.com>
	<835232876.2007851.1487712068087@mail.yahoo.com>
	<CAE2FW2mmJFBbgZkOszKoLxm=udCOJ6iYDRPS7ex_eGTMpmnucg@mail.gmail.com>
Message-ID: <58ACB554.5040105@iinet.net.au>

aggregate(), tapply(), do.call(), rbind() (etc.) are extremely useful 
functions that have been available in R for a long time. They remain 
useful regardless what plotting approach you use - base graphics, 
lattice or the more recent ggplot.

Philip


On 22/02/2017 8:40 AM, C W wrote:
> Hi Carl,
>
> I have not fully learned dplyr, but it seems harder than tapply() and the
> ?apply() family in general.
>
> Almost every ggplot2 data I have seen is manipulated using dplyr. Something
> must be good about dplyr.
>
> aggregate(), tapply(), do.call(), rbind() will be sorely missed! :(
>
> Thanks!
>
> On Tue, Feb 21, 2017 at 4:21 PM, Carl Sutton<suttoncarl at ymail.com>  wrote:
>
>> Hi
>>
>> I have found that:
>> A)  Hadley's new book to be wonderful on how to use dplyr, ggplot2 and his
>> other packages.  Read this and using as a reference saves major frustration.
>> b)  Data Camps courses on ggplot2 are also wonderful.  GGPLOT2 has more
>> capability than I have mastered or needed.  To be an expert with ggplot2
>> will take some effort.  To just get run of the mill helpful, beautiful
>> plots, no major time needed for that.
>>
>> I use both of these sources regularly, especially when what is in my grey
>> matter memory banks is not working.  Refreshers are sometimes needed.
>>
>> If your data sets are large and available memory limited, then data.table
>> is the package I use.   I am amazed at the difference of memory usage with
>> data.table versus other packages.  My laptop has 16gb ram, and tidyr maxed
>> it but data.table melt used less than 6gb(if I remember correctly) on my
>> current work.  Since discovering fread and fwrite, read.table, read.csv,
>> and write have been benched.   Every script I have includes
>> library(data.table)
>>
>> Carl Sutton
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Feb 21 22:56:14 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 22 Feb 2017 08:56:14 +1100
Subject: [R] optimisation - Error in checkFunc(Func2, times, y,
 rho) : The number of derivatives returned by func() (22) must equal
 the length of the initial conditions vector (2)
In-Reply-To: <89028320.3148770.1487675033048@mail.yahoo.com>
References: <89028320.3148770.1487675033048.ref@mail.yahoo.com>
	<89028320.3148770.1487675033048@mail.yahoo.com>
Message-ID: <CA+8X3fWWMFHLvu1mQD9eEBYAN9-iNan3w5Q9=JLJ37THqh4-Wg@mail.gmail.com>

Hi Malgorzata,
Did you try to _install_ rather than just _load_ the XLConnect package?

install.packages("XLConnect")

Sad to say, your code:

time=c(16,17,18,19,20,21,22,23,24,25,26)
#x=c(20.2,18.9,16.5)
y=c(7.63,9.22,4.86,4.78,0.38,6.13,3.91,38.41,2.58,36.95,1.73)
cE=c(15.05,38.01,41.09,31.41,3.54,15.92,24.01,25.29,14.82,43.93,2.45)
cP=c(0.47,0.43,4.8,1.07,0.38,0.3,0.14,0.29,0.9,2.51,1.94)
#df<-data.frame(time,y,cE,cP)
#dfrequire(FME)
### this will fail unless XLConnect has been installed
require(XLConnect)
#Initial values of the parameters
parms=c(k1=500, k2=4500, k3=200,k4=2.42, k5=0.26,k6=12.2,k7=0.004,
 k8=55,k9=24,k10=8)
#definition of the parameters function
derivs<-function(time,y,pars){
 with(as.list(c(pars,y)),{
  cE=c(15.05,38.01,41.09,31.41,3.54,15.92,24.01,25.29,14.82,43.93,2.45)
  cP=c(0.47,0.43,4.8,1.07,0.38,0.3,0.14,0.29,0.9,2.51,1.94)
  dx=(k1+(k2*cE^k10)/(k3^k10+cE^k10))/(1+cP/k6)-
   k4*((1+k5*cP)/(1+k7*cE))*x;
  #dRP_LH/dt
  dy=(1/k8)*k4*((1+k5*cP)/(1+k7*cE))*x-k9*y
  #dL/dt
  list(c(dx,dy))
 })
}
initial<-c(x=x[1],y=y[1])
model_cost<-function(pars){
 out<-ode(y=initial,time=time,func=derivs,parms=pars)
 cost<-modCost(model=out,obs=df,x="time")
 return(cost)
} ### you seem to be missing a closing brace here
model_cost(parms)$model
# model fitting
model_fit<-modFit(f=model_cost,p=parms)
} ### maybe this is the missing closing brace
model_cost(parms)

is pretty messy with several lines commented out that may be
necessary, and has a number of possible errors. I have pointed out a
few (see ### comments). If the problem is the missing XLConnect
package, perhaps installing it will produce some meaningful error
messages.

Jim

On Tue, Feb 21, 2017 at 10:03 PM, Malgorzata Wieteska via R-help
<r-help at r-project.org> wrote:
> Hello,
> I get an error message:Error in checkFunc(Func2, times, y, rho) :   The number of derivatives returned by func() (22) must equal the length of the initial conditions vector (2)
> I try to optimise system of differential equations with 2 extra variables derived from the data.frame.
> I didn't manage to install XLConnect package, so I don't know if this is the source of the problem.
> Loading required package: XLConnectWarning message:In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :  there is no package called ?XLConnect?
> I have missing data, so time frame is limited. I haven't got values for solution of the first equation, but I hope that it isn't problem, I've got the same message when putting random numbers as x values.


From r.turner at auckland.ac.nz  Tue Feb 21 23:14:20 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 22 Feb 2017 11:14:20 +1300
Subject: [R] [FORGED]  Yates correction
In-Reply-To: <CADGufDEpUDsPNpo0P3JtdEWBDgL6YV4p8G3R8dGDwdgMBzpXyw@mail.gmail.com>
References: <CADGufDEpUDsPNpo0P3JtdEWBDgL6YV4p8G3R8dGDwdgMBzpXyw@mail.gmail.com>
Message-ID: <c067b9f3-0b57-f766-596c-5397fb4b9e9e@auckland.ac.nz>

On 21/02/17 23:47, Jomy Jose wrote:
>  I tried to do chi square test for the following observed frequencies
> ---------------------------------------------------------------------------------------------
>    A  B
> A  8  4
> B 12 10
>
> R gave the following output:
> -------------------------------------------------------------------------------------------
>         Pearson's Chi-squared test with Yates' continuity correction
>
> data:  M
> X-squared = 0.10349, df = 1, p-value = 0.7477
>
> Warning message:
> In chisq.test(M) : Chi-squared approximation may be incorrect
>
> ---------------------------------------------------------------------------------------------------------------
> Whether this result can be relied or we have to use Fishers exact test ?

(a) With a p-value of 0.7477 there is no evidence against the null 
hypothesis no matter how you slice it.

(b) To assuage your trepidations, use "simulate.p.value=TRUE".

E.g.

    chisq.test(M,simulate.p.value=TRUE,B=9999)

Note that the value of X-squared that is returned is "of course" the 
same as what you'd get by setting correct=FALSE. I got a p-value of 
0.7178; you will get something slightly different, since a simulated 
p-value is random, but it will be about 0.71 or 0.72.

Bottom line:  Don't reject H_0!!!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From btyner at gmail.com  Wed Feb 22 00:10:20 2017
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 21 Feb 2017 18:10:20 -0500
Subject: [R] flushing on.exit prior to q()
Message-ID: <5a1857e4-8bb8-7aae-47a2-9be3c46830ad@gmail.com>

Hi,

When using a custom error function that calls q(), what is the 
recommended way to "flush" the calling function's on.exit ?

For example, say I have a script:

    #!/usr/bin/Rscript --no-init-file

    options(error = function() {

       cat("on error message\n", file = stderr())

       q(save = "no", status = 1)
    })

    test <- function() {

        on.exit(cat("on exit message\n", file = stderr()))

        stop("error")
    }

    test()

when I run the script, the "on exit message" does not print. (I found 
one solution might involve adding a stop() to my custom error function 
prior to the q(); however this is somewhat less than ideal: it also 
triggers an "error during wrapup" because of the recursion).

Other ideas, best practices?

Thanks
Ben


From josestadistico at gmail.com  Wed Feb 22 00:51:19 2017
From: josestadistico at gmail.com (=?UTF-8?Q?Jos=C3=A9_Luis_Aguilar?=)
Date: Wed, 22 Feb 2017 00:51:19 +0100
Subject: [R] function for remove white space
Message-ID: <CACt-d0h0-UTO8bELjeM4TNBDMe91tw=r-f3URUf9PrEJJJ_fuQ@mail.gmail.com>

Hi all,

i have a dataframe with 34 columns and 1534 observations.

In some columns I have strings with spaces, i want remove the space.
Is there a function that removes whitespace from the entire dataframe?
I use gsub but I would need some function to automate this.

Thank you very much in advance,

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Feb 22 01:05:33 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 22 Feb 2017 13:05:33 +1300
Subject: [R] [FORGED]  function for remove white space
In-Reply-To: <CACt-d0h0-UTO8bELjeM4TNBDMe91tw=r-f3URUf9PrEJJJ_fuQ@mail.gmail.com>
References: <CACt-d0h0-UTO8bELjeM4TNBDMe91tw=r-f3URUf9PrEJJJ_fuQ@mail.gmail.com>
Message-ID: <ae85e471-659f-6b15-5b91-ddbfebc9bd8a@auckland.ac.nz>

On 22/02/17 12:51, Jos? Luis Aguilar wrote:
> Hi all,
>
> i have a dataframe with 34 columns and 1534 observations.
>
> In some columns I have strings with spaces, i want remove the space.
> Is there a function that removes whitespace from the entire dataframe?
> I use gsub but I would need some function to automate this.

Something like

X <- as.data.frame(lapply(X,function(x){gsub(" ","",x)}))

Untested, since you provide no reproducible example (despite being told 
by the posting guide to do so).

I do not know what my idea will do to numeric columns or to factors.

However it should give you at least a start.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From wjm1 at caa.columbia.edu  Wed Feb 22 03:39:02 2017
From: wjm1 at caa.columbia.edu (William Michels)
Date: Tue, 21 Feb 2017 18:39:02 -0800
Subject: [R] [FORGED] function for remove white space
In-Reply-To: <ae85e471-659f-6b15-5b91-ddbfebc9bd8a@auckland.ac.nz>
References: <CACt-d0h0-UTO8bELjeM4TNBDMe91tw=r-f3URUf9PrEJJJ_fuQ@mail.gmail.com>
	<ae85e471-659f-6b15-5b91-ddbfebc9bd8a@auckland.ac.nz>
Message-ID: <CAA99HCxrhsH=vXHBfJJM7tJ0p1U3B4a6Kf9ykG-KHQvyw28q_Q@mail.gmail.com>

Hi Jos? (and Rolf),

It's not entirely clear what type of 'whitespace' you're referring to,
but if you're using read.table() or read.csv() to create your
dataframe in the first place, setting 'strip.white = TRUE' will remove
leading and trailing whitespace 'from unquoted character fields
(numeric fields are always stripped).'

> ?read.table
>?read.csv

Cheers,

Bill


On 2/21/17, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 22/02/17 12:51, Jos? Luis Aguilar wrote:
>> Hi all,
>>
>> i have a dataframe with 34 columns and 1534 observations.
>>
>> In some columns I have strings with spaces, i want remove the space.
>> Is there a function that removes whitespace from the entire dataframe?
>> I use gsub but I would need some function to automate this.
>
> Something like
>
> X <- as.data.frame(lapply(X,function(x){gsub(" ","",x)}))
>
> Untested, since you provide no reproducible example (despite being told
> by the posting guide to do so).
>
> I do not know what my idea will do to numeric columns or to factors.
>
> However it should give you at least a start.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From josestadistico at gmail.com  Wed Feb 22 08:35:46 2017
From: josestadistico at gmail.com (=?utf-8?Q?Jos=C3=A9_Luis?=)
Date: Wed, 22 Feb 2017 08:35:46 +0100
Subject: [R] [FORGED] function for remove white space
In-Reply-To: <CAA99HCxrhsH=vXHBfJJM7tJ0p1U3B4a6Kf9ykG-KHQvyw28q_Q@mail.gmail.com>
References: <CACt-d0h0-UTO8bELjeM4TNBDMe91tw=r-f3URUf9PrEJJJ_fuQ@mail.gmail.com>
	<ae85e471-659f-6b15-5b91-ddbfebc9bd8a@auckland.ac.nz>
	<CAA99HCxrhsH=vXHBfJJM7tJ0p1U3B4a6Kf9ykG-KHQvyw28q_Q@mail.gmail.com>
Message-ID: <18CC0834-6570-4CFD-9A0F-CFFD22312F04@gmail.com>

Thank's for your answer.

I'm using read.csv.

Enviado desde mi iPad

> El 22/2/2017, a las 3:39, William Michels <wjm1 at caa.columbia.edu> escribi?:
> 
> Hi Jos? (and Rolf),
> 
> It's not entirely clear what type of 'whitespace' you're referring to,
> but if you're using read.table() or read.csv() to create your
> dataframe in the first place, setting 'strip.white = TRUE' will remove
> leading and trailing whitespace 'from unquoted character fields
> (numeric fields are always stripped).'
> 
>> ?read.table
>> ?read.csv
> 
> Cheers,
> 
> Bill
> 
> 
>> On 2/21/17, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> On 22/02/17 12:51, Jos? Luis Aguilar wrote:
>>> Hi all,
>>> 
>>> i have a dataframe with 34 columns and 1534 observations.
>>> 
>>> In some columns I have strings with spaces, i want remove the space.
>>> Is there a function that removes whitespace from the entire dataframe?
>>> I use gsub but I would need some function to automate this.
>> 
>> Something like
>> 
>> X <- as.data.frame(lapply(X,function(x){gsub(" ","",x)}))
>> 
>> Untested, since you provide no reproducible example (despite being told
>> by the posting guide to do so).
>> 
>> I do not know what my idea will do to numeric columns or to factors.
>> 
>> However it should give you at least a start.
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 


From marongiu.luigi at gmail.com  Wed Feb 22 10:03:10 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Wed, 22 Feb 2017 09:03:10 +0000
Subject: [R] single strip for the same group in dotplot lattice
Message-ID: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>

dear all,
I have a set of data that is subdivided in cluster (run 1/run 2) and in
target (A/B). When plotting, I obtain a panel strip with "run 1" and "run
2" for each "A" and "B" panel, so "run 1" appears twice and so does "run
2". It is possible to merge the strip together so that I will have "run 1"
or "run 2" only once? this will reduce the complexity of the data and allow
more space for more detailed information in the strip.
the data follows,
thank you
L

>>>
cluster <- c(rep("run_1", 6), rep("run_2", 6))
type <- rep(c("blank", "positive", "negative"),2)
target <- c(rep("A", 6), rep("B", 6))
value <- c(0.01, 1.1, 0.5,
           0.02, 1.6, 0.8,
           0.07, 1.4, 0.7,
           0.03, 1.4, 0.4)
my.data <- data.frame(cluster, type, target, value)

library(lattice)
dotplot(
  value ~ type|target + cluster,
  my.data,
  groups = type,
  pch=21,
  main = "Luminex analysis MTb humans",
  xlab = "Target", ylab = "Reading",
  col = c("grey", "green", "red"),
  par.settings = list(strip.background = list(col="paleturquoise")),
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  key = list(
    space = "top",
    columns = 3,
    text = list(c("Blank", "Negative", "Positive"), col="black"),
    rectangles = list(col=c("grey", "green", "red"))
  )
)

	[[alternative HTML version deleted]]


From philipt900 at iinet.net.au  Wed Feb 22 10:53:34 2017
From: philipt900 at iinet.net.au (P Tennant)
Date: Wed, 22 Feb 2017 20:53:34 +1100
Subject: [R] single strip for the same group in dotplot lattice
In-Reply-To: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>
References: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>
Message-ID: <58AD5F9E.5070205@iinet.net.au>

Hi Luigi,

I'm afraid I don't understand your toy data as you've described it, but 
if you really don't have run 2 for target A, and don't have run 1 for 
target B, why not just create another factor that reflects this, and 
plot that?

  my.data$clus2 <- with(my.data, interaction(cluster, target))

  and call: dotplot(value ~ type| clus2, ... )


Philip

On 22/02/2017 8:03 PM, Luigi Marongiu wrote:
> dear all,
> I have a set of data that is subdivided in cluster (run 1/run 2) and in
> target (A/B). When plotting, I obtain a panel strip with "run 1" and "run
> 2" for each "A" and "B" panel, so "run 1" appears twice and so does "run
> 2". It is possible to merge the strip together so that I will have "run 1"
> or "run 2" only once? this will reduce the complexity of the data and allow
> more space for more detailed information in the strip.
> the data follows,
> thank you
> L
>
> cluster<- c(rep("run_1", 6), rep("run_2", 6))
> type<- rep(c("blank", "positive", "negative"),2)
> target<- c(rep("A", 6), rep("B", 6))
> value<- c(0.01, 1.1, 0.5,
>             0.02, 1.6, 0.8,
>             0.07, 1.4, 0.7,
>             0.03, 1.4, 0.4)
> my.data<- data.frame(cluster, type, target, value)
>
> library(lattice)
> dotplot(
>    value ~ type|target + cluster,
>    my.data,
>    groups = type,
>    pch=21,
>    main = "Luminex analysis MTb humans",
>    xlab = "Target", ylab = "Reading",
>    col = c("grey", "green", "red"),
>    par.settings = list(strip.background = list(col="paleturquoise")),
>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>    key = list(
>      space = "top",
>      columns = 3,
>      text = list(c("Blank", "Negative", "Positive"), col="black"),
>      rectangles = list(col=c("grey", "green", "red"))
>    )
> )
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr206 at kent.ac.uk  Wed Feb 22 10:57:00 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 22 Feb 2017 09:57:00 +0000
Subject: [R] vars package - irf() does not work
In-Reply-To: <1487594810802.89921@kent.ac.uk>
References: <1487594810802.89921@kent.ac.uk>
Message-ID: <1487757420140.51553@kent.ac.uk>




Dear all,

I have not received any response on this email. Is there anybody who can help me?

I want to run an impulse response analysis using the vars() package. The code looks as follwows.


# list of class varest
varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type = "both")

varest.USA

summary(varest.USA)



#Run irf analysis
irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)

plot(irf.USAg)


The problem is that R returns an error that the arguments in irf are unused. That is, unused arguments (response="g", n.ahead = 48, boot = TRUE, ci=0.95)
The strangeness is that it sometimes works but most of the time it does not. I installed vars() last month and irf() worked well but now it does only occasionally. I have just edited the data but kept the code unchanged.


In addition, I have the same problem when I am trying to replicate the example on irf() in the vars vignette althoug it also worked well when I installed vars and run the example.


Does anybody have an idea what is wrong?







        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Wed Feb 22 11:25:43 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Wed, 22 Feb 2017 10:25:43 +0000
Subject: [R] single strip for the same group in dotplot lattice
In-Reply-To: <58AD5F9E.5070205@iinet.net.au>
References: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>
	<58AD5F9E.5070205@iinet.net.au>
Message-ID: <CAMk+s2T_QK1Lp89KEH1RofNXz5xC3iyb5mcMKqgSzOwE_n359Q@mail.gmail.com>

Dear Philip,
the data is indeed a toy data: the real one will have 15 panels (=targets)
and two or three clusters. this means that I will have 15 strips with the
label "run 1" = "cluster 1" etc. the point of the toy data is that I get a
4x4 panel plot with 8 strips labelled "run 1", "run 2", "A" and "B". What I
am looking for is to collapse the strips so to get only one label "run 1"
and only one with "run 2" in order to simplify the plot. Hope this helps.
Thanks
Luigi

On Wed, Feb 22, 2017 at 9:53 AM, P Tennant <philipt900 at iinet.net.au> wrote:

> Hi Luigi,
>
> I'm afraid I don't understand your toy data as you've described it, but if
> you really don't have run 2 for target A, and don't have run 1 for target
> B, why not just create another factor that reflects this, and plot that?
>
>  my.data$clus2 <- with(my.data, interaction(cluster, target))
>
>  and call: dotplot(value ~ type| clus2, ... )
>
>
> Philip
>
>
> On 22/02/2017 8:03 PM, Luigi Marongiu wrote:
>
>> dear all,
>> I have a set of data that is subdivided in cluster (run 1/run 2) and in
>> target (A/B). When plotting, I obtain a panel strip with "run 1" and "run
>> 2" for each "A" and "B" panel, so "run 1" appears twice and so does "run
>> 2". It is possible to merge the strip together so that I will have "run 1"
>> or "run 2" only once? this will reduce the complexity of the data and
>> allow
>> more space for more detailed information in the strip.
>> the data follows,
>> thank you
>> L
>>
>> cluster<- c(rep("run_1", 6), rep("run_2", 6))
>> type<- rep(c("blank", "positive", "negative"),2)
>> target<- c(rep("A", 6), rep("B", 6))
>> value<- c(0.01, 1.1, 0.5,
>>             0.02, 1.6, 0.8,
>>             0.07, 1.4, 0.7,
>>             0.03, 1.4, 0.4)
>> my.data<- data.frame(cluster, type, target, value)
>>
>> library(lattice)
>> dotplot(
>>    value ~ type|target + cluster,
>>    my.data,
>>    groups = type,
>>    pch=21,
>>    main = "Luminex analysis MTb humans",
>>    xlab = "Target", ylab = "Reading",
>>    col = c("grey", "green", "red"),
>>    par.settings = list(strip.background = list(col="paleturquoise")),
>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>    key = list(
>>      space = "top",
>>      columns = 3,
>>      text = list(c("Blank", "Negative", "Positive"), col="black"),
>>      rectangles = list(col=c("grey", "green", "red"))
>>    )
>> )
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From vivek4 at mail.usf.edu  Wed Feb 22 14:50:51 2017
From: vivek4 at mail.usf.edu (Vivek kumar Singh)
Date: Wed, 22 Feb 2017 08:50:51 -0500
Subject: [R] Facebook package error - Can't get reactions
Message-ID: <004d01d28d12$ae44d500$0ace7f00$@mail.usf.edu>

Hi All,

 

I am using facebook package in R. Following is my code.

 

install.packages('Rfacebook',dependencies = T)

library('Rfacebook')

#create a favebook app and add http://localhost:1410/ to your app

fb_oauth <- fbOAuth(app_id="***",

                    app_secret="*****")

 

fb_page <- getPage(page="subway", token=fb_oauth,n=50,feed = T,reactions =
T)

 

I get an error when I try to get reactions (i.e., reactions=T). When I
remove the 'reactions' argument, it works.

 

fb_page <- getPage(page="subway", token=fb_oauth,n=50,feed = T)  works.

 

Please let me know why am I getting error with reactions? Also, suggest if
there are alternate packages for Facebook in R.

 

Regards,

 

Vivek

 


	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Feb 22 14:51:09 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 22 Feb 2017 13:51:09 +0000
Subject: [R] vars package - irf() does not work
In-Reply-To: <1487757420140.51553@kent.ac.uk>
References: <1487594810802.89921@kent.ac.uk> <1487757420140.51553@kent.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A170BA@SRVEXCHCM301.precheza.cz>

Hi

I have no knowledge of vars package. However from what you describe that it sometimes works and sometimes not (although I wonder what it does mean) it seems to me that you either mask some arguments used by the function in your environment or misspell sometimes arguments or use invalid string in response argument.

It would be very unusual if

irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)

resulted in error and when you repeat it, it does not.

If you want better answer maybe from more knowledgeable people  than myself, you should provide an example which works and which does not with some data (either your own or from e.g. package data).

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of T.Riedle
> Sent: Wednesday, February 22, 2017 10:57 AM
> To: R-help at r-project.org
> Subject: [R] vars package - irf() does not work
>
>
>
>
> Dear all,
>
> I have not received any response on this email. Is there anybody who can
> help me?
>
> I want to run an impulse response analysis using the vars() package. The code
> looks as follwows.
>
>
> # list of class varest
> varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type =
> "both")
>
> varest.USA
>
> summary(varest.USA)
>
>
>
> #Run irf analysis
> irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)
>
> plot(irf.USAg)
>
>
> The problem is that R returns an error that the arguments in irf are unused.
> That is, unused arguments (response="g", n.ahead = 48, boot = TRUE,
> ci=0.95) The strangeness is that it sometimes works but most of the time it
> does not. I installed vars() last month and irf() worked well but now it does
> only occasionally. I have just edited the data but kept the code unchanged.
>
>
> In addition, I have the same problem when I am trying to replicate the
> example on irf() in the vars vignette althoug it also worked well when I
> installed vars and run the example.
>
>
> Does anybody have an idea what is wrong?
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From vodvos at zoho.com  Wed Feb 22 16:53:52 2017
From: vodvos at zoho.com (vod vos)
Date: Wed, 22 Feb 2017 07:53:52 -0800
Subject: [R] How to search t value when you know degree of freedom?
Message-ID: <15a66875fdf.10bcba69e2918.2834251748968068611@zoho.com>


Hi everyone,

How to search t value when you know degree of freedom? 

For example, the degree of freedom is 29, how to use R to calculate the t value for it? 

t.test does not help, or pnorm? I am not sure.

Thanks.


From ruipbarradas at sapo.pt  Wed Feb 22 17:04:36 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 22 Feb 2017 16:04:36 +0000
Subject: [R] How to search t value when you know degree of freedom?
In-Reply-To: <15a66875fdf.10bcba69e2918.2834251748968068611@zoho.com>
References: <15a66875fdf.10bcba69e2918.2834251748968068611@zoho.com>
Message-ID: <58ADB694.4010505@sapo.pt>

Hello,

It would be ?pt not pnorm.
And as you can see in that help page you need another value, the value 
of the quantile. (Don't worry about the arguments ncp or log just q and df)

Hope this helps,

Rui Barradas

Em 22-02-2017 15:53, vod vos escreveu:
>
> Hi everyone,
>
> How to search t value when you know degree of freedom?
>
> For example, the degree of freedom is 29, how to use R to calculate the t value for it?
>
> t.test does not help, or pnorm? I am not sure.
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Wed Feb 22 17:49:24 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 22 Feb 2017 08:49:24 -0800
Subject: [R] [FORGED] function for remove white space
In-Reply-To: <18CC0834-6570-4CFD-9A0F-CFFD22312F04@gmail.com>
References: <CACt-d0h0-UTO8bELjeM4TNBDMe91tw=r-f3URUf9PrEJJJ_fuQ@mail.gmail.com>
	<ae85e471-659f-6b15-5b91-ddbfebc9bd8a@auckland.ac.nz>
	<CAA99HCxrhsH=vXHBfJJM7tJ0p1U3B4a6Kf9ykG-KHQvyw28q_Q@mail.gmail.com>
	<18CC0834-6570-4CFD-9A0F-CFFD22312F04@gmail.com>
Message-ID: <CAF8bMcbYYm+ZJyEk9Cd+AVcPqP7apBT8Sd4k5A94G8h9dvCcNg@mail.gmail.com>

Try the following function to apply gsub to all character or factor
columns of a data.frame (and maintain change the class of all
columns):

gsubDataFrame <- function(pattern, replacement, x, ...) {
    stopifnot(is.data.frame(x))
    for(i in seq_len(ncol(x))) {
        if (is.character(x[[i]])) {
            x[[i]] <- gsub(pattern, replacement, x[[i]], ...)
        } else if (is.factor(x[[i]])) {
            levels(x[[i]]) <- gsub(pattern, replacement, levels(x[[i]]), ...)
        } # else do nothing for numeric or other column types
    }
    x
}

E.g.,
> d <- data.frame(stringsAsFactors = FALSE,
+                 Int=1:5,
+                 Char=c("a a", "baa", "a a ", " aa", "b a a"),
+                 Fac=factor(c("x x", "yxx", "x x ", " xx", "y x x")))
> str(d)
'data.frame':   5 obs. of  3 variables:
 $ Int : int  1 2 3 4 5
 $ Char: chr  "a a" "baa" "a a " " aa" ...
 $ Fac : Factor w/ 5 levels " xx","x x","x x ",..: 2 5 3 1 4
> str(gsubDataFrame(" ", "", d)) # delete spaces, use "[[:space:]]" for whitespace
'data.frame':   5 obs. of  3 variables:
 $ Int : int  1 2 3 4 5
 $ Char: chr  "aa" "baa" "aa" "aa" ...
 $ Fac : Factor w/ 2 levels "xx","yxx": 1 2 1 1 2

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Feb 21, 2017 at 11:35 PM, Jos? Luis <josestadistico at gmail.com> wrote:
> Thank's for your answer.
>
> I'm using read.csv.
>
> Enviado desde mi iPad
>
>> El 22/2/2017, a las 3:39, William Michels <wjm1 at caa.columbia.edu> escribi?:
>>
>> Hi Jos? (and Rolf),
>>
>> It's not entirely clear what type of 'whitespace' you're referring to,
>> but if you're using read.table() or read.csv() to create your
>> dataframe in the first place, setting 'strip.white = TRUE' will remove
>> leading and trailing whitespace 'from unquoted character fields
>> (numeric fields are always stripped).'
>>
>>> ?read.table
>>> ?read.csv
>>
>> Cheers,
>>
>> Bill
>>
>>
>>> On 2/21/17, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>> On 22/02/17 12:51, Jos? Luis Aguilar wrote:
>>>> Hi all,
>>>>
>>>> i have a dataframe with 34 columns and 1534 observations.
>>>>
>>>> In some columns I have strings with spaces, i want remove the space.
>>>> Is there a function that removes whitespace from the entire dataframe?
>>>> I use gsub but I would need some function to automate this.
>>>
>>> Something like
>>>
>>> X <- as.data.frame(lapply(X,function(x){gsub(" ","",x)}))
>>>
>>> Untested, since you provide no reproducible example (despite being told
>>> by the posting guide to do so).
>>>
>>> I do not know what my idea will do to numeric columns or to factors.
>>>
>>> However it should give you at least a start.
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> --
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tahiraperveen16 at gmail.com  Wed Feb 22 15:59:31 2017
From: tahiraperveen16 at gmail.com (Tahira Perveen)
Date: Wed, 22 Feb 2017 06:59:31 -0800
Subject: [R] how we combine more than one matrix aafter finding their
	variance
Message-ID: <CACVA2p_WES5vPvUHG+TzSOkseUeV-qcdfvk-Js69sBvkEg_9jw@mail.gmail.com>



	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Wed Feb 22 20:33:15 2017
From: chocold12 at gmail.com (lily li)
Date: Wed, 22 Feb 2017 12:33:15 -0700
Subject: [R] converting time format
Message-ID: <CAN5afy_zM=kPwCoga1dNRdy94=HN63zaZT0J9XuhubAO5wDhUA@mail.gmail.com>

Hi R users,

I have a dataframe, with year, month, day, and other variables. I wanted to
calculated monthly values of the variables. For example, there is one
variable called 'count'. I use the code below to convert daily data to
monthly data.

df.count.mon = aggregate(count ~ year+month, data= df, sum)

The new dataframe has three columns: year, month, and count. Now I want to
add one more column as 'time', which has the format 'yyyy-mm'. I use the
code below but the new column has all NA values. What is the problem and
how to solve it?

df.count.mon$time = as.Date(paste(df.count.mon$year, df.count.mon$month),
'%Y %m')

I had experience to add one more column with the format 'yyyy-mm-dd', which
works, but not with monthly format. Thanks for your help.

	[[alternative HTML version deleted]]


From josestadistico at gmail.com  Wed Feb 22 21:49:04 2017
From: josestadistico at gmail.com (=?utf-8?Q?Jos=C3=A9_Luis?=)
Date: Wed, 22 Feb 2017 21:49:04 +0100
Subject: [R] [FORGED] function for remove white space
In-Reply-To: <CAF8bMcbYYm+ZJyEk9Cd+AVcPqP7apBT8Sd4k5A94G8h9dvCcNg@mail.gmail.com>
References: <CACt-d0h0-UTO8bELjeM4TNBDMe91tw=r-f3URUf9PrEJJJ_fuQ@mail.gmail.com>
	<ae85e471-659f-6b15-5b91-ddbfebc9bd8a@auckland.ac.nz>
	<CAA99HCxrhsH=vXHBfJJM7tJ0p1U3B4a6Kf9ykG-KHQvyw28q_Q@mail.gmail.com>
	<18CC0834-6570-4CFD-9A0F-CFFD22312F04@gmail.com>
	<CAF8bMcbYYm+ZJyEk9Cd+AVcPqP7apBT8Sd4k5A94G8h9dvCcNg@mail.gmail.com>
Message-ID: <1101F019-191F-4AD3-B954-CA41B21E7B7A@gmail.com>

Oh, thank you so much!!

It's perfect!!



Enviado desde mi iPhone

> El 22 feb 2017, a las 17:49, William Dunlap <wdunlap at tibco.com> escribi?:
> 
> Try the following function to apply gsub to all character or factor
> columns of a data.frame (and maintain change the class of all
> columns):
> 
> gsubDataFrame <- function(pattern, replacement, x, ...) {
>    stopifnot(is.data.frame(x))
>    for(i in seq_len(ncol(x))) {
>        if (is.character(x[[i]])) {
>            x[[i]] <- gsub(pattern, replacement, x[[i]], ...)
>        } else if (is.factor(x[[i]])) {
>            levels(x[[i]]) <- gsub(pattern, replacement, levels(x[[i]]), ...)
>        } # else do nothing for numeric or other column types
>    }
>    x
> }
> 
> E.g.,
>> d <- data.frame(stringsAsFactors = FALSE,
> +                 Int=1:5,
> +                 Char=c("a a", "baa", "a a ", " aa", "b a a"),
> +                 Fac=factor(c("x x", "yxx", "x x ", " xx", "y x x")))
>> str(d)
> 'data.frame':   5 obs. of  3 variables:
> $ Int : int  1 2 3 4 5
> $ Char: chr  "a a" "baa" "a a " " aa" ...
> $ Fac : Factor w/ 5 levels " xx","x x","x x ",..: 2 5 3 1 4
>> str(gsubDataFrame(" ", "", d)) # delete spaces, use "[[:space:]]" for whitespace
> 'data.frame':   5 obs. of  3 variables:
> $ Int : int  1 2 3 4 5
> $ Char: chr  "aa" "baa" "aa" "aa" ...
> $ Fac : Factor w/ 2 levels "xx","yxx": 1 2 1 1 2
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
>> On Tue, Feb 21, 2017 at 11:35 PM, Jos? Luis <josestadistico at gmail.com> wrote:
>> Thank's for your answer.
>> 
>> I'm using read.csv.
>> 
>> Enviado desde mi iPad
>> 
>>> El 22/2/2017, a las 3:39, William Michels <wjm1 at caa.columbia.edu> escribi?:
>>> 
>>> Hi Jos? (and Rolf),
>>> 
>>> It's not entirely clear what type of 'whitespace' you're referring to,
>>> but if you're using read.table() or read.csv() to create your
>>> dataframe in the first place, setting 'strip.white = TRUE' will remove
>>> leading and trailing whitespace 'from unquoted character fields
>>> (numeric fields are always stripped).'
>>> 
>>>> ?read.table
>>>> ?read.csv
>>> 
>>> Cheers,
>>> 
>>> Bill
>>> 
>>> 
>>>>> On 2/21/17, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>> On 22/02/17 12:51, Jos? Luis Aguilar wrote:
>>>>> Hi all,
>>>>> 
>>>>> i have a dataframe with 34 columns and 1534 observations.
>>>>> 
>>>>> In some columns I have strings with spaces, i want remove the space.
>>>>> Is there a function that removes whitespace from the entire dataframe?
>>>>> I use gsub but I would need some function to automate this.
>>>> 
>>>> Something like
>>>> 
>>>> X <- as.data.frame(lapply(X,function(x){gsub(" ","",x)}))
>>>> 
>>>> Untested, since you provide no reproducible example (despite being told
>>>> by the posting guide to do so).
>>>> 
>>>> I do not know what my idea will do to numeric columns or to factors.
>>>> 
>>>> However it should give you at least a start.
>>>> 
>>>> cheers,
>>>> 
>>>> Rolf Turner
>>>> 
>>>> --
>>>> Technical Editor ANZJS
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Feb 22 22:10:47 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 23 Feb 2017 08:10:47 +1100
Subject: [R] converting time format
In-Reply-To: <CAN5afy_zM=kPwCoga1dNRdy94=HN63zaZT0J9XuhubAO5wDhUA@mail.gmail.com>
References: <CAN5afy_zM=kPwCoga1dNRdy94=HN63zaZT0J9XuhubAO5wDhUA@mail.gmail.com>
Message-ID: <CA+8X3fVjc4jBj5Z+Zg75j+VQ3k81t3ccikQv4af7mdmDHD7QoQ@mail.gmail.com>

Hi Lily.
Two problems. You have named the month field "mon" and then refer to
it as "month". Second, as the resolution of as.Date is days, it can't
produce a valid date without specifying the day. Thus:

df.count.mon<-data.frame(count=sample(1:24,24),
 year=rep(2014:2015,each=2),mon=rep(1:12,2))
# make each day the first day of the month
df.count.mon$time<-
 as.Date(paste(df.count.mon$year, df.count.mon$mon,1),
 '%Y %m %d')
df.count.mon
   count year mon       time
1     22 2014   1 2014-01-01
2     12 2014   2 2014-02-01
...
You will get values, but I don't think they are the ones you want.

Jim

On Thu, Feb 23, 2017 at 6:33 AM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I have a dataframe, with year, month, day, and other variables. I wanted to
> calculated monthly values of the variables. For example, there is one
> variable called 'count'. I use the code below to convert daily data to
> monthly data.
>
> df.count.mon = aggregate(count ~ year+month, data= df, sum)
>
> The new dataframe has three columns: year, month, and count. Now I want to
> add one more column as 'time', which has the format 'yyyy-mm'. I use the
> code below but the new column has all NA values. What is the problem and
> how to solve it?
>
> df.count.mon$time = as.Date(paste(df.count.mon$year, df.count.mon$month),
> '%Y %m')
>
> I had experience to add one more column with the format 'yyyy-mm-dd', which
> works, but not with monthly format. Thanks for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Wed Feb 22 22:18:53 2017
From: chocold12 at gmail.com (lily li)
Date: Wed, 22 Feb 2017 14:18:53 -0700
Subject: [R] converting time format
In-Reply-To: <CA+8X3fVjc4jBj5Z+Zg75j+VQ3k81t3ccikQv4af7mdmDHD7QoQ@mail.gmail.com>
References: <CAN5afy_zM=kPwCoga1dNRdy94=HN63zaZT0J9XuhubAO5wDhUA@mail.gmail.com>
	<CA+8X3fVjc4jBj5Z+Zg75j+VQ3k81t3ccikQv4af7mdmDHD7QoQ@mail.gmail.com>
Message-ID: <CAN5afy_mPdm_3m6CXKvac=TrxLc7ZyeVs85QNiFi5U8vA9h1uQ@mail.gmail.com>

Yes, it is a little different. Is there a way to get 'yyyy-mm' format?
Thanks.

On Wed, Feb 22, 2017 at 2:10 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Lily.
> Two problems. You have named the month field "mon" and then refer to
> it as "month". Second, as the resolution of as.Date is days, it can't
> produce a valid date without specifying the day. Thus:
>
> df.count.mon<-data.frame(count=sample(1:24,24),
>  year=rep(2014:2015,each=2),mon=rep(1:12,2))
> # make each day the first day of the month
> df.count.mon$time<-
>  as.Date(paste(df.count.mon$year, df.count.mon$mon,1),
>  '%Y %m %d')
> df.count.mon
>    count year mon       time
> 1     22 2014   1 2014-01-01
> 2     12 2014   2 2014-02-01
> ...
> You will get values, but I don't think they are the ones you want.
>
> Jim
>
> On Thu, Feb 23, 2017 at 6:33 AM, lily li <chocold12 at gmail.com> wrote:
> > Hi R users,
> >
> > I have a dataframe, with year, month, day, and other variables. I wanted
> to
> > calculated monthly values of the variables. For example, there is one
> > variable called 'count'. I use the code below to convert daily data to
> > monthly data.
> >
> > df.count.mon = aggregate(count ~ year+month, data= df, sum)
> >
> > The new dataframe has three columns: year, month, and count. Now I want
> to
> > add one more column as 'time', which has the format 'yyyy-mm'. I use the
> > code below but the new column has all NA values. What is the problem and
> > how to solve it?
> >
> > df.count.mon$time = as.Date(paste(df.count.mon$year,
> df.count.mon$month),
> > '%Y %m')
> >
> > I had experience to add one more column with the format 'yyyy-mm-dd',
> which
> > works, but not with monthly format. Thanks for your help.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Feb 22 23:06:58 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 23 Feb 2017 09:06:58 +1100
Subject: [R] converting time format
In-Reply-To: <CAN5afy_mPdm_3m6CXKvac=TrxLc7ZyeVs85QNiFi5U8vA9h1uQ@mail.gmail.com>
References: <CAN5afy_zM=kPwCoga1dNRdy94=HN63zaZT0J9XuhubAO5wDhUA@mail.gmail.com>
	<CA+8X3fVjc4jBj5Z+Zg75j+VQ3k81t3ccikQv4af7mdmDHD7QoQ@mail.gmail.com>
	<CAN5afy_mPdm_3m6CXKvac=TrxLc7ZyeVs85QNiFi5U8vA9h1uQ@mail.gmail.com>
Message-ID: <CA+8X3fVLFyKpi2EJrN4a+arL9CaGnv0MzMKeZhpa+QZtMPVHvw@mail.gmail.com>

Sure:

df.count.mon$time<-format(as.Date(paste(df.count.mon$year,  df.count.mon$mon,1),
 '%Y %m %d'),"%Y %m")
> df.count.mon
   count year mon    time
1     22 2014   1 2014 01
2     12 2014   2 2014 02
...

Jim

On Thu, Feb 23, 2017 at 8:18 AM, lily li <chocold12 at gmail.com> wrote:
> Yes, it is a little different. Is there a way to get 'yyyy-mm' format?
> Thanks.
>
> On Wed, Feb 22, 2017 at 2:10 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Lily.
>> Two problems. You have named the month field "mon" and then refer to
>> it as "month". Second, as the resolution of as.Date is days, it can't
>> produce a valid date without specifying the day. Thus:
>>
>> df.count.mon<-data.frame(count=sample(1:24,24),
>>  year=rep(2014:2015,each=2),mon=rep(1:12,2))
>> # make each day the first day of the month
>> df.count.mon$time<-
>>  as.Date(paste(df.count.mon$year, df.count.mon$mon,1),
>>  '%Y %m %d')
>> df.count.mon
>>    count year mon       time
>> 1     22 2014   1 2014-01-01
>> 2     12 2014   2 2014-02-01
>> ...
>> You will get values, but I don't think they are the ones you want.
>>
>> Jim
>>
>> On Thu, Feb 23, 2017 at 6:33 AM, lily li <chocold12 at gmail.com> wrote:
>> > Hi R users,
>> >
>> > I have a dataframe, with year, month, day, and other variables. I wanted
>> > to
>> > calculated monthly values of the variables. For example, there is one
>> > variable called 'count'. I use the code below to convert daily data to
>> > monthly data.
>> >
>> > df.count.mon = aggregate(count ~ year+month, data= df, sum)
>> >
>> > The new dataframe has three columns: year, month, and count. Now I want
>> > to
>> > add one more column as 'time', which has the format 'yyyy-mm'. I use the
>> > code below but the new column has all NA values. What is the problem and
>> > how to solve it?
>> >
>> > df.count.mon$time = as.Date(paste(df.count.mon$year,
>> > df.count.mon$month),
>> > '%Y %m')
>> >
>> > I had experience to add one more column with the format 'yyyy-mm-dd',
>> > which
>> > works, but not with monthly format. Thanks for your help.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Wed Feb 22 23:40:22 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 23 Feb 2017 09:40:22 +1100
Subject: [R] optimisation - Error in checkFunc(Func2, times, y,
 rho) : The number of derivatives returned by func() (22) must equal
 the length of the initial conditions vector (2)
In-Reply-To: <185923463.4401666.1487757487313@mail.yahoo.com>
References: <89028320.3148770.1487675033048.ref@mail.yahoo.com>
	<89028320.3148770.1487675033048@mail.yahoo.com>
	<CA+8X3fWWMFHLvu1mQD9eEBYAN9-iNan3w5Q9=JLJ37THqh4-Wg@mail.gmail.com>
	<185923463.4401666.1487757487313@mail.yahoo.com>
Message-ID: <CA+8X3fWrLFx7v1cJbDXy0j8B8obB6eQkugKQn0XYKutTjRz9hA@mail.gmail.com>

I'm not really familiar with what you are doing. when I try to debug
something like this, I run each step separately to determine where the
error is. For example, if I clean up the code a bit and run the derivs
function:

 derivs(time,y,parms)
[[1]]
 [1]  429.709540  438.844035  281.741953  404.175692  435.341449  447.532442
 [7]  448.103560  443.722972  419.132716  345.992428  363.259812 -182.179223
[13] -220.477447 -115.238330 -113.710739   -8.218996 -146.384226  -92.999563
[19] -921.027854  -61.074252 -885.550697  -40.281082

Warning messages:
1: In k4 * ((1 + k5 * cP)/(1 + k7 * cE)) * x :
  longer object length is not a multiple of shorter object length
2: In (1/k8) * k4 * ((1 + k5 * cP)/(1 + k7 * cE)) * x :
  longer object length is not a multiple of shorter object length

Obviously there is a problem with the length of "x" as it is recycled
within the function. Also, your cE and cP values are not causing a
problem as the function runs and returns what may be reasonable
values. As I don't have the deSolve package installed (and I have my
own work to do) I can only suggest trying a stepwise debugging
process.

Jim

On Wed, Feb 22, 2017 at 8:58 PM, Malgorzata Wieteska
<g.wieteska at yahoo.ie> wrote:
> Thank you Jim,
>
> I've installed XLConnect using Tools tab (install.packages option didn't
> work for some reason -I've tried before) and fixed the bracket. However, I
> still get the same error message. I've checked what cause this error and is
> caused by external data (cE and cP) fed into equations in derivs function.
>
> Do you have any suggestion how to input those values at corresponding time
> points into equations to make ode in the model_cost to integrate?
>
> Malgosia
>
>
> On Tuesday, 21 February 2017, 22:03:10, Jim Lemon <drjimlemon at gmail.com>
> wrote:
>
>
> Hi Malgorzata,
> Did you try to _install_ rather than just _load_ the XLConnect package?
>
> install.packages("XLConnect")
>
> Sad to say, your code:
>
> time=c(16,17,18,19,20,21,22,23,24,25,26)
> #x=c(20.2,18.9,16.5)
> y=c(7.63,9.22,4.86,4.78,0.38,6.13,3.91,38.41,2.58,36.95,1.73)
> cE=c(15.05,38.01,41.09,31.41,3.54,15.92,24.01,25.29,14.82,43.93,2.45)
> cP=c(0.47,0.43,4.8,1.07,0.38,0.3,0.14,0.29,0.9,2.51,1.94)
> #df<-data.frame(time,y,cE,cP)
> #dfrequire(FME)
> ### this will fail unless XLConnect has been installed
> require(XLConnect)
> #Initial values of the parameters
> parms=c(k1=500, k2=4500, k3=200,k4=2.42, k5=0.26,k6=12.2,k7=0.004,
> k8=55,k9=24,k10=8)
> #definition of the parameters function
> derivs<-function(time,y,pars){
> with(as.list(c(pars,y)),{
>   cE=c(15.05,38.01,41.09,31.41,3.54,15.92,24.01,25.29,14.82,43.93,2.45)
>   cP=c(0.47,0.43,4.8,1.07,0.38,0.3,0.14,0.29,0.9,2.51,1.94)
>   dx=(k1+(k2*cE^k10)/(k3^k10+cE^k10))/(1+cP/k6)-
>   k4*((1+k5*cP)/(1+k7*cE))*x;
>   #dRP_LH/dt
>   dy=(1/k8)*k4*((1+k5*cP)/(1+k7*cE))*x-k9*y
>   #dL/dt
>   list(c(dx,dy))
> })
> }
> initial<-c(x=x[1],y=y[1])
> model_cost<-function(pars){
> out<-ode(y=initial,time=time,func=derivs,parms=pars)
> cost<-modCost(model=out,obs=df,x="time")
> return(cost)
> } ### you seem to be missing a closing brace here
> model_cost(parms)$model
> # model fitting
> model_fit<-modFit(f=model_cost,p=parms)
> } ### maybe this is the missing closing brace
> model_cost(parms)
>
> is pretty messy with several lines commented out that may be
> necessary, and has a number of possible errors. I have pointed out a
> few (see ### comments). If the problem is the missing XLConnect
> package, perhaps installing it will produce some meaningful error
> messages.
>
> Jim
>
> On Tue, Feb 21, 2017 at 10:03 PM, Malgorzata Wieteska via R-help
> <r-help at r-project.org> wrote:
>> Hello,
>> I get an error message:Error in checkFunc(Func2, times, y, rho) :  The
>> number of derivatives returned by func() (22) must equal the length of the
>> initial conditions vector (2)
>> I try to optimise system of differential equations with 2 extra variables
>> derived from the data.frame.
>> I didn't manage to install XLConnect package, so I don't know if this is
>> the source of the problem.
>> Loading required package: XLConnectWarning message:In library(package,
>> lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :  there
>> is no package called ?XLConnect?
>> I have missing data, so time frame is limited. I haven't got values for
>> solution of the first equation, but I hope that it isn't problem, I've got
>> the same message when putting random numbers as x values.
>
>


From dulcalma at bigpond.com  Thu Feb 23 03:50:19 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 23 Feb 2017 13:50:19 +1100
Subject: [R] single strip for the same group in dotplot lattice
In-Reply-To: <CAMk+s2T_QK1Lp89KEH1RofNXz5xC3iyb5mcMKqgSzOwE_n359Q@mail.gmail.com>
References: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>	<58AD5F9E.5070205@iinet.net.au>
	<CAMk+s2T_QK1Lp89KEH1RofNXz5xC3iyb5mcMKqgSzOwE_n359Q@mail.gmail.com>
Message-ID: <000301d28d7f$92244820$b66cd860$@bigpond.com>

Hi Liugi

Here are some ideas quickly

4 panels diagonals are blank

mdata = my.data
mdata$ct <- paste(target, "Run", rep(1:2, each = 6))
mdata$typeT <- paste(mdata$target,mdata$type)

dotplot(
  value ~ type|ct,
  mdata2,
  groups = typeT,
  par.settings = list(strip.background = list(col="paleturquoise"),
                      superpose.symbol = list(col = c(2:4),
                                              pch = rep(c(1,20),each = 3))),
# type
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  main = "Luminex analysis MTb humans",
  xlab = "Target", 
  ylab = "Reading",
  auto.key = T,
  panel = panel.superpose
)

# for when the 4 panels have plots not 2 as now
 mdata2 = mdata
 mdata2$target = rep(LETTERS[2:1], ea=6)
 mdata2$value= mdata2$value+0.1
 mdata2 <- rbind(mdata,mdata2)

mdata2$typeT <- paste(mdata2$target,mdata2$type)

 dotplot(
   value ~ type|target + cluster,
   mdata2,
   groups = typeT,
   par.settings = list(strip.background = list(col="paleturquoise"),
                       superpose.symbol = list(col = c(2:4),
                                               pch = rep(c(1,20),each =
3))), # type
   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
   main = "Luminex analysis MTb humans",
   xlab = "Target", 
   ylab = "Reading",
   auto.key = T,
   panel = panel.superpose
 )


 dotplot(
   value ~ type|ct,
   mdata2,
   groups = typeT,
   par.settings = list(strip.background = list(col="paleturquoise"),
                       superpose.symbol = list(col = c(2:4),
                                               pch = rep(c(1,20),each =
3))), # type
   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
   main = "Luminex analysis MTb humans",
   strip    = strip.custom(factor.levels = paste("Run",1:2),
                        par.strip.text = list(cex = 1) ),
   xlab = "Target", 
   ylab = "Reading",
   auto.key = T,
   panel = panel.superpose
 )

dotplot(
  value ~ type|cluster,
  mdata2,
  groups = typeT,
  par.settings = list(strip.background = list(col="paleturquoise"),
                      superpose.symbol = list(col = c(2:4),
                                              pch = rep(c(1,20),each = 3))),
# type
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  main = "Luminex analysis MTb humans",
  xlab = "Target", 
  ylab = "Reading",
  auto.key = T,
  panel = panel.superpose
)


Regards

Duncan

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Wednesday, 22 February 2017 21:26
To: P Tennant; r-help
Subject: Re: [R] single strip for the same group in dotplot lattice

Dear Philip,
the data is indeed a toy data: the real one will have 15 panels (=targets)
and two or three clusters. this means that I will have 15 strips with the
label "run 1" = "cluster 1" etc. the point of the toy data is that I get a
4x4 panel plot with 8 strips labelled "run 1", "run 2", "A" and "B". What I
am looking for is to collapse the strips so to get only one label "run 1"
and only one with "run 2" in order to simplify the plot. Hope this helps.
Thanks
Luigi

On Wed, Feb 22, 2017 at 9:53 AM, P Tennant <philipt900 at iinet.net.au> wrote:

> Hi Luigi,
>
> I'm afraid I don't understand your toy data as you've described it, but if
> you really don't have run 2 for target A, and don't have run 1 for target
> B, why not just create another factor that reflects this, and plot that?
>
>  my.data$clus2 <- with(my.data, interaction(cluster, target))
>
>  and call: dotplot(value ~ type| clus2, ... )
>
>
> Philip
>
>
> On 22/02/2017 8:03 PM, Luigi Marongiu wrote:
>
>> dear all,
>> I have a set of data that is subdivided in cluster (run 1/run 2) and in
>> target (A/B). When plotting, I obtain a panel strip with "run 1" and "run
>> 2" for each "A" and "B" panel, so "run 1" appears twice and so does "run
>> 2". It is possible to merge the strip together so that I will have "run
1"
>> or "run 2" only once? this will reduce the complexity of the data and
>> allow
>> more space for more detailed information in the strip.
>> the data follows,
>> thank you
>> L
>>
>> cluster<- c(rep("run_1", 6), rep("run_2", 6))
>> type<- rep(c("blank", "positive", "negative"),2)
>> target<- c(rep("A", 6), rep("B", 6))
>> value<- c(0.01, 1.1, 0.5,
>>             0.02, 1.6, 0.8,
>>             0.07, 1.4, 0.7,
>>             0.03, 1.4, 0.4)
>> my.data<- data.frame(cluster, type, target, value)
>>
>> library(lattice)
>> dotplot(
>>    value ~ type|target + cluster,
>>    my.data,
>>    groups = type,
>>    pch=21,
>>    main = "Luminex analysis MTb humans",
>>    xlab = "Target", ylab = "Reading",
>>    col = c("grey", "green", "red"),
>>    par.settings = list(strip.background = list(col="paleturquoise")),
>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>    key = list(
>>      space = "top",
>>      columns = 3,
>>      text = list(c("Blank", "Negative", "Positive"), col="black"),
>>      rectangles = list(col=c("grey", "green", "red"))
>>    )
>> )
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Feb 23 06:31:38 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 23 Feb 2017 16:31:38 +1100
Subject: [R] single strip for the same group in dotplot lattice
References: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>	<58AD5F9E.5070205@iinet.net.au>
	<CAMk+s2T_QK1Lp89KEH1RofNXz5xC3iyb5mcMKqgSzOwE_n359Q@mail.gmail.com>
Message-ID: <000001d28d96$1b32f1a0$5198d4e0$@bigpond.com>

Resending the previous email as the data = mdata2 is wrong for the first
plot should be mdata

dotplot(
  value ~ type|ct,
  mdata,
  groups = typeT,
  par.settings = list(strip.background = list(col="paleturquoise"),
                      superpose.symbol = list(col = c(2:4),
                                              pch = rep(c(1,20),each = 3))),
# type
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  main = "Luminex analysis MTb humans",
  xlab = "Target", 
  ylab = "Reading",
  auto.key = T
)


Adding:
Depending on preferences for cluster (run) and target the new columns could
be changed to suit.

With "duplication" pch and col, rather than arguments themselves can be
adjusted to suit in par.settings which makes doing the key easier

Regards

Duncan


-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Thursday, 23 February 2017 13:50
To: R; 'Luigi Marongiu'
Subject: RE: [R] single strip for the same group in dotplot lattice

Hi Liugi

Here are some ideas quickly

4 panels diagonals are blank

mdata = my.data
mdata$ct <- paste(target, "Run", rep(1:2, each = 6))
mdata$typeT <- paste(mdata$target,mdata$type)

dotplot(
  value ~ type|ct,
  mdata2,
  groups = typeT,
  par.settings = list(strip.background = list(col="paleturquoise"),
                      superpose.symbol = list(col = c(2:4),
                                              pch = rep(c(1,20),each = 3))),
# type
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  main = "Luminex analysis MTb humans",
  xlab = "Target", 
  ylab = "Reading",
  auto.key = T,
  panel = panel.superpose
)

# for when the 4 panels have plots not 2 as now
 mdata2 = mdata
 mdata2$target = rep(LETTERS[2:1], ea=6)
 mdata2$value= mdata2$value+0.1
 mdata2 <- rbind(mdata,mdata2)

mdata2$typeT <- paste(mdata2$target,mdata2$type)

 dotplot(
   value ~ type|target + cluster,
   mdata2,
   groups = typeT,
   par.settings = list(strip.background = list(col="paleturquoise"),
                       superpose.symbol = list(col = c(2:4),
                                               pch = rep(c(1,20),each =
3))), # type
   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
   main = "Luminex analysis MTb humans",
   xlab = "Target", 
   ylab = "Reading",
   auto.key = T,
   panel = panel.superpose
 )


 dotplot(
   value ~ type|ct,
   mdata2,
   groups = typeT,
   par.settings = list(strip.background = list(col="paleturquoise"),
                       superpose.symbol = list(col = c(2:4),
                                               pch = rep(c(1,20),each =
3))), # type
   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
   main = "Luminex analysis MTb humans",
   strip    = strip.custom(factor.levels = paste("Run",1:2),
                        par.strip.text = list(cex = 1) ),
   xlab = "Target", 
   ylab = "Reading",
   auto.key = T,
   panel = panel.superpose
 )

dotplot(
  value ~ type|cluster,
  mdata2,
  groups = typeT,
  par.settings = list(strip.background = list(col="paleturquoise"),
                      superpose.symbol = list(col = c(2:4),
                                              pch = rep(c(1,20),each = 3))),
# type
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  main = "Luminex analysis MTb humans",
  xlab = "Target", 
  ylab = "Reading",
  auto.key = T,
  panel = panel.superpose
)


Regards

Duncan

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Wednesday, 22 February 2017 21:26
To: P Tennant; r-help
Subject: Re: [R] single strip for the same group in dotplot lattice

Dear Philip,
the data is indeed a toy data: the real one will have 15 panels (=targets)
and two or three clusters. this means that I will have 15 strips with the
label "run 1" = "cluster 1" etc. the point of the toy data is that I get a
4x4 panel plot with 8 strips labelled "run 1", "run 2", "A" and "B". What I
am looking for is to collapse the strips so to get only one label "run 1"
and only one with "run 2" in order to simplify the plot. Hope this helps.
Thanks
Luigi

On Wed, Feb 22, 2017 at 9:53 AM, P Tennant <philipt900 at iinet.net.au> wrote:

> Hi Luigi,
>
> I'm afraid I don't understand your toy data as you've described it, but if
> you really don't have run 2 for target A, and don't have run 1 for target
> B, why not just create another factor that reflects this, and plot that?
>
>  my.data$clus2 <- with(my.data, interaction(cluster, target))
>
>  and call: dotplot(value ~ type| clus2, ... )
>
>
> Philip
>
>
> On 22/02/2017 8:03 PM, Luigi Marongiu wrote:
>
>> dear all,
>> I have a set of data that is subdivided in cluster (run 1/run 2) and in
>> target (A/B). When plotting, I obtain a panel strip with "run 1" and "run
>> 2" for each "A" and "B" panel, so "run 1" appears twice and so does "run
>> 2". It is possible to merge the strip together so that I will have "run
1"
>> or "run 2" only once? this will reduce the complexity of the data and
>> allow
>> more space for more detailed information in the strip.
>> the data follows,
>> thank you
>> L
>>
>> cluster<- c(rep("run_1", 6), rep("run_2", 6))
>> type<- rep(c("blank", "positive", "negative"),2)
>> target<- c(rep("A", 6), rep("B", 6))
>> value<- c(0.01, 1.1, 0.5,
>>             0.02, 1.6, 0.8,
>>             0.07, 1.4, 0.7,
>>             0.03, 1.4, 0.4)
>> my.data<- data.frame(cluster, type, target, value)
>>
>> library(lattice)
>> dotplot(
>>    value ~ type|target + cluster,
>>    my.data,
>>    groups = type,
>>    pch=21,
>>    main = "Luminex analysis MTb humans",
>>    xlab = "Target", ylab = "Reading",
>>    col = c("grey", "green", "red"),
>>    par.settings = list(strip.background = list(col="paleturquoise")),
>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>    key = list(
>>      space = "top",
>>      columns = 3,
>>      text = list(c("Blank", "Negative", "Positive"), col="black"),
>>      rectangles = list(col=c("grey", "green", "red"))
>>    )
>> )
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mayukh.dass at gmail.com  Thu Feb 23 07:03:31 2017
From: mayukh.dass at gmail.com (Mayukh Dass)
Date: Thu, 23 Feb 2017 00:03:31 -0600
Subject: [R] forecast using linear model
Message-ID: <CAHWpsEEBciCcppdLmmyzWARmFykwk_+dNPYim2S6GKJQOAqD3Q@mail.gmail.com>

Hello,

I have a time series with sales data of two products A and B. The sales
data are reported weekly.

I want to forecast next 26 weeks sales data for product A using trend,
seasonality and sales of B.

So first I forecast next 26 weeks sales of B with only trend and season.
Next, I tried to create a data frame with these new 26 values of B, and
forecast sales of A. Unfortunately, I am getting the following error:

> train.lm.trend.season.pred <- forecast(train.lm.trend.season, h=26,
newdata=future_data)
Error in eval(expr, envir, enclos) : object 'solvedFN___1' not found

The code used:



nFuture <- 26
trainc1.ts <- window(pB.ts) #sales of Product B
train.ts <- window(pA.ts) #sales of Product A

trainc1.lm.trend.season <- tslm(trainc1.ts ~ trend + season)
summary(trainc1.lm.trend.season)
trainc1.lm.trend.season.pred <- forecast(trainc1.lm.trend.season, h =
nFuture, level = 0)

future_data <- data.frame(
  com1 = trainc1.lm.trend.season.pred$mean
)

forecast(fit, newdata=future_data)

train.lm.trend.season <- tslm(train.ts ~ trend + season+trainc1.ts)
summary(train.lm.trend.season)

train.lm.trend.season.pred <- forecast(train.lm.trend.season, h=26,
newdata=future_data)


It will be great if you can help me.

Mayukh

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Feb 23 07:49:24 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 23 Feb 2017 06:49:24 +0000
Subject: [R] vars package - irf() does not work
In-Reply-To: <CAHrK517pVo3N+C2MR3NmW_mWgAF21hdscbRtCcFPEFiN6bHVpw@mail.gmail.com>
References: <1487594810802.89921@kent.ac.uk> <1487757420140.51553@kent.ac.uk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A170BA@SRVEXCHCM301.precheza.cz>
	<CAHrK517pVo3N+C2MR3NmW_mWgAF21hdscbRtCcFPEFiN6bHVpw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A171DB@SRVEXCHCM301.precheza.cz>

Hi

You sent it to wrong person. I am not the one who have problems with vars code. It was T.Riedle who had. I am cc?ing it to R help so he can answer you if he read it.

Cheers
Petr

From: John C Frain [mailto:frainj at gmail.com]
Sent: Wednesday, February 22, 2017 9:51 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] vars package - irf() does not work



John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html<http://www.tcd.ie/Economics/staff/frainj/home.html>
mailto:frainj at tcd.ie<mailto:frainj at tcd.ie>
mailto:frainj at gmail.com<mailto:frainj at gmail.com>

On 22 February 2017 at 13:51, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

I have no knowledge of vars package. However from what you describe that it sometimes works and sometimes not (although I wonder what it does mean) it seems to me that you either mask some arguments used by the function in your environment or misspell sometimes arguments or use invalid string in response argument.

It would be very unusual if

irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)

resulted in error and when you repeat it, it does not.

If you want better answer maybe from more knowledgeable people  than myself, you should provide an example which works and which does not with some data (either your own or from e.g. package data).

Cheers
Petr

The following script
The following example taken from the help files for the vars package and your script works fine for me

rm(list=ls())
library(vars)
data(Canada)
test.var <- VAR(Canada, lag.max = 4, ic = "SC", type = "both")
test.var
summary(test.var)
#irf.test<-irf(test.var, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)
irf.test<-irf(test.var, response = "e", n.ahead = 48, boot = TRUE, ci=0.95)
plot(irf.test)

adapted from the vars package help files and your script works fine for me. Your script looks ok to me. Can you send a minimum example of a complete script and data that shows the problem. Otherwise no one will be able to tell you what is wrong.

If you are cutting and pasting from a pdf some characters (e.g. quote marks, ^  etc.) may not copy correctly. There may also be hidden characters in spaces that may be causing problems. If this is the case it is easily fixed by deleting the offending characters and spaces.

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of T.Riedle
> Sent: Wednesday, February 22, 2017 10:57 AM
> To: R-help at r-project.org<mailto:R-help at r-project.org>
> Subject: [R] vars package - irf() does not work
>
>
>
>
> Dear all,
>
> I have not received any response on this email. Is there anybody who can
> help me?
>
> I want to run an impulse response analysis using the vars() package. The code
> looks as follwows.
>
>
> # list of class varest
> varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type =
> "both")
>
> varest.USA
>
> summary(varest.USA)
>
>
>
> #Run irf analysis
> irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)
>
> plot(irf.USAg)
>
>
> The problem is that R returns an error that the arguments in irf are unused.
> That is, unused arguments (response="g", n.ahead = 48, boot = TRUE,
> ci=0.95) The strangeness is that it sometimes works but most of the time it
> does not. I installed vars() last month and irf() worked well but now it does
> only occasionally. I have just edited the data but kept the code unchanged.
>
>
> In addition, I have the same problem when I am trying to replicate the
> example on irf() in the vars vignette althoug it also worked well when I
> installed vars and run the example.
>
>
> Does anybody have an idea what is wrong?
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Feb 23 08:38:27 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 23 Feb 2017 08:38:27 +0100
Subject: [R] RStudio: Place for Storing Options
In-Reply-To: <alpine.BSF.2.00.1702110801470.71951@pedal.dcn.davis.ca.us>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
	<22684.34149.431821.945334@stat.math.ethz.ch>
	<alpine.BSF.2.00.1702110801470.71951@pedal.dcn.davis.ca.us>
Message-ID: <22702.37235.988957.574018@stat.math.ethz.ch>

>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>     on Sat, 11 Feb 2017 08:09:36 -0800 writes:

    > For the record, then, Google listened to my incantation of
    > "rstudio configuration file" and the second result was:

    > https://support.rstudio.com/hc/en-us/articles/200534577-Resetting-RStudio-Desktop-s-State

    > RStudio Desktop is also open source, so you can download
    > the source code and look at the operating-system-specific
    > bits (for "where") if the above link goes out of date or
    > disappears.

Thanks a lot, Jeff!

And for the archives:  On reasonable OS's,  the hidden
directory/folder containing all the info is
		 ~/.rstudio-desktop/
and if "things are broken" the recommendation is to rename that
   mv ~/.rstudio-desktop  ~/backup-rstudio-desktop
and (zip and) send along with your e-mail to the experts for diagnosis.


    > On Thu, 9 Feb 2017, Martin Maechler wrote:

    >> 
    >>>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com> on Thu, 9
    >>>>>>> Feb 2017 14:37:57 +0000 writes:
    >> 
    >> > Hi Georg, > maybe someone here knows, but I think you
    >> are more likely to get answers to > Rstudio related
    >> questions with RStudio support: >
    >> https://support.rstudio.com/hc/en-us
    >> 
    >> > Best, > Ulrik
    >> 
    >> Indeed, thank you, Ulrik.
    >> 
    >> In this special case, however, I'm quite sure many
    >> readers of R-help would be interested in the answer; so
    >> once you receive an answer, please post it (or a link to
    >> a public URL with it) here on R-help, thank you in
    >> advance.
    >> 
    >> We would like to be able to *save*, or sometimes *set* /
    >> *reset* such options "in a scripted manner", e.g. for
    >> controlled exam sessions.
    >> 
    >> Martin Maechler, ETH Zurich
    >> 
    >> > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de>
    >> wrote:
    >> 
    >> >> Hi All, >> I would like to make a backup of my RStudio
    >> IDE options I configure using >> "Tools/Global Options"
    >> from the menu bar. Searching the >> web did not reveal
    >> anything.
    >> 
    >> >> Can you tell me where RStudio IDE does store its
    >> configuration?
    >> 
    >> >> Kind regards >> Georg
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 

    > ---------------------------------------------------------------------------
    > Jeff Newmiller The .....  .....  Go Live...
    > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
    > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
    > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
    > Controllers) .OO#.  .OO#.  rocks...1k
    > ---------------------------------------------------------------------------


From G.Maubach at weinwolf.de  Thu Feb 23 09:00:58 2017
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Thu, 23 Feb 2017 09:00:58 +0100
Subject: [R] Antwort: Re:  RStudio: Place for Storing Options
In-Reply-To: <22702.37235.988957.574018@stat.math.ethz.ch>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>
	<22684.34149.431821.945334@stat.math.ethz.ch>	<alpine.BSF.2.00.1702110801470.71951@pedal.dcn.davis.ca.us>
	<22702.37235.988957.574018@stat.math.ethz.ch>
Message-ID: <OF5EFCA44F.2C2ABCFF-ONC12580D0.002B0E44-C12580D0.002C0835@lotus.hawesko.de>

Hi Martin,

the command

%localappdata%\RStudio-Desktop

gives on my machine

"The command is written wrong or could not be found.".

I found "RStudio-Desktop" under

C:\Users\<username>\AppData\Local\RStudio-Desktop

There references on created notebooks and presentations are stored in the 
folder "RStudio-Desktop". RStudio config is not documented yet.

Kind regards

Georg




Von:    Martin Maechler <maechler at stat.math.ethz.ch>
An:     Jeff Newmiller <jdnewmil at dcn.davis.ca.us>, 
Kopie:  Martin Maechler <maechler at stat.math.ethz.ch>, 
<G.Maubach at weinwolf.de>, R-help mailing list <r-help at r-project.org>
Datum:  23.02.2017 08:37
Betreff:        Re: [R] RStudio: Place for Storing Options



>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>     on Sat, 11 Feb 2017 08:09:36 -0800 writes:

    > For the record, then, Google listened to my incantation of
    > "rstudio configuration file" and the second result was:

    > 
https://support.rstudio.com/hc/en-us/articles/200534577-Resetting-RStudio-Desktop-s-State


    > RStudio Desktop is also open source, so you can download
    > the source code and look at the operating-system-specific
    > bits (for "where") if the above link goes out of date or
    > disappears.

Thanks a lot, Jeff!

And for the archives:  On reasonable OS's,  the hidden
directory/folder containing all the info is
                                  ~/.rstudio-desktop/
and if "things are broken" the recommendation is to rename that
   mv ~/.rstudio-desktop  ~/backup-rstudio-desktop
and (zip and) send along with your e-mail to the experts for diagnosis.


    > On Thu, 9 Feb 2017, Martin Maechler wrote:

    >> 
    >>>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com> on Thu, 9
    >>>>>>> Feb 2017 14:37:57 +0000 writes:
    >> 
    >> > Hi Georg, > maybe someone here knows, but I think you
    >> are more likely to get answers to > Rstudio related
    >> questions with RStudio support: >
    >> https://support.rstudio.com/hc/en-us
    >> 
    >> > Best, > Ulrik
    >> 
    >> Indeed, thank you, Ulrik.
    >> 
    >> In this special case, however, I'm quite sure many
    >> readers of R-help would be interested in the answer; so
    >> once you receive an answer, please post it (or a link to
    >> a public URL with it) here on R-help, thank you in
    >> advance.
    >> 
    >> We would like to be able to *save*, or sometimes *set* /
    >> *reset* such options "in a scripted manner", e.g. for
    >> controlled exam sessions.
    >> 
    >> Martin Maechler, ETH Zurich
    >> 
    >> > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de>
    >> wrote:
    >> 
    >> >> Hi All, >> I would like to make a backup of my RStudio
    >> IDE options I configure using >> "Tools/Global Options"
    >> from the menu bar. Searching the >> web did not reveal
    >> anything.
    >> 
    >> >> Can you tell me where RStudio IDE does store its
    >> configuration?
    >> 
    >> >> Kind regards >> Georg
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 

    > 
---------------------------------------------------------------------------
    > Jeff Newmiller The .....  .....  Go Live...
    > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
    > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
    > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
    > Controllers) .OO#.  .OO#.  rocks...1k
    >


From marongiu.luigi at gmail.com  Thu Feb 23 10:00:59 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 23 Feb 2017 09:00:59 +0000
Subject: [R] single strip for the same group in dotplot lattice
In-Reply-To: <000301d28d7f$92244820$b66cd860$@bigpond.com>
References: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>
	<58AD5F9E.5070205@iinet.net.au>
	<CAMk+s2T_QK1Lp89KEH1RofNXz5xC3iyb5mcMKqgSzOwE_n359Q@mail.gmail.com>
	<000301d28d7f$92244820$b66cd860$@bigpond.com>
Message-ID: <CAMk+s2QEHaELBM7vx-iS6ubHC9hmF=xyG4c41j1CK6h7VQTD=w@mail.gmail.com>

Dear Duncan and Philip,
thank you for your answers. maybe the toy data I gave it is a bit too easy,
so I am attaching a new dataset with 5 targets. As you can see from it, now
there are 5 panel strips with the label "run_1" and 5 with the label
"run_2". What I would like to do is to merge those with the same label so
to have only two labels "run_1" and "run_2".
the examples from Duncan contains plenty of keys but I think make the
reading of the plot more difficult; most of the plots have only one strip.
thank you
luigi

>>>
# the values are actually repeated, but they are just for example
cluster <- c(rep("run_1", 45), rep("run_2", 45))
type <- rep(c("blank", "positive", "negative"),30)
target <- rep(c(rep("A", 3), rep("B", 3), rep("C", 3), rep("D", 3),
rep("E", 3)), 6)
value <- rep(c(rnorm(1, mean=0.001, sd=0.1), rnorm(1, mean=2, sd=1),
rnorm(1, mean=1, sd=1)),30)
my.data <- data.frame(cluster, type, target, value)

library(lattice)
dotplot(
  value ~ type|target + cluster,
  my.data,
  groups = type,
  pch=21,
  main = "Luminex analysis MTb humans",
  xlab = "Target", ylab = "Reading",
  col = c("grey", "green", "red"),
  par.settings = list(strip.background = list(col="paleturquoise")),
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  key = list(
    space = "top",
    columns = 3,
    text = list(c("Blank", "Negative", "Positive"), col="black"),
    rectangles = list(col=c("grey", "green", "red"))
  )
)


On Thu, Feb 23, 2017 at 2:50 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:

> Hi Liugi
>
> Here are some ideas quickly
>
> 4 panels diagonals are blank
>
> mdata = my.data
> mdata$ct <- paste(target, "Run", rep(1:2, each = 6))
> mdata$typeT <- paste(mdata$target,mdata$type)
>
> dotplot(
>   value ~ type|ct,
>   mdata2,
>   groups = typeT,
>   par.settings = list(strip.background = list(col="paleturquoise"),
>                       superpose.symbol = list(col = c(2:4),
>                                               pch = rep(c(1,20),each =
> 3))),
> # type
>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>   main = "Luminex analysis MTb humans",
>   xlab = "Target",
>   ylab = "Reading",
>   auto.key = T,
>   panel = panel.superpose
> )
>
> # for when the 4 panels have plots not 2 as now
>  mdata2 = mdata
>  mdata2$target = rep(LETTERS[2:1], ea=6)
>  mdata2$value= mdata2$value+0.1
>  mdata2 <- rbind(mdata,mdata2)
>
> mdata2$typeT <- paste(mdata2$target,mdata2$type)
>
>  dotplot(
>    value ~ type|target + cluster,
>    mdata2,
>    groups = typeT,
>    par.settings = list(strip.background = list(col="paleturquoise"),
>                        superpose.symbol = list(col = c(2:4),
>                                                pch = rep(c(1,20),each =
> 3))), # type
>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>    main = "Luminex analysis MTb humans",
>    xlab = "Target",
>    ylab = "Reading",
>    auto.key = T,
>    panel = panel.superpose
>  )
>
>
>  dotplot(
>    value ~ type|ct,
>    mdata2,
>    groups = typeT,
>    par.settings = list(strip.background = list(col="paleturquoise"),
>                        superpose.symbol = list(col = c(2:4),
>                                                pch = rep(c(1,20),each =
> 3))), # type
>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>    main = "Luminex analysis MTb humans",
>    strip    = strip.custom(factor.levels = paste("Run",1:2),
>                         par.strip.text = list(cex = 1) ),
>    xlab = "Target",
>    ylab = "Reading",
>    auto.key = T,
>    panel = panel.superpose
>  )
>
> dotplot(
>   value ~ type|cluster,
>   mdata2,
>   groups = typeT,
>   par.settings = list(strip.background = list(col="paleturquoise"),
>                       superpose.symbol = list(col = c(2:4),
>                                               pch = rep(c(1,20),each =
> 3))),
> # type
>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>   main = "Luminex analysis MTb humans",
>   xlab = "Target",
>   ylab = "Reading",
>   auto.key = T,
>   panel = panel.superpose
> )
>
>
> Regards
>
> Duncan
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
> Marongiu
> Sent: Wednesday, 22 February 2017 21:26
> To: P Tennant; r-help
> Subject: Re: [R] single strip for the same group in dotplot lattice
>
> Dear Philip,
> the data is indeed a toy data: the real one will have 15 panels (=targets)
> and two or three clusters. this means that I will have 15 strips with the
> label "run 1" = "cluster 1" etc. the point of the toy data is that I get a
> 4x4 panel plot with 8 strips labelled "run 1", "run 2", "A" and "B". What I
> am looking for is to collapse the strips so to get only one label "run 1"
> and only one with "run 2" in order to simplify the plot. Hope this helps.
> Thanks
> Luigi
>
> On Wed, Feb 22, 2017 at 9:53 AM, P Tennant <philipt900 at iinet.net.au>
> wrote:
>
> > Hi Luigi,
> >
> > I'm afraid I don't understand your toy data as you've described it, but
> if
> > you really don't have run 2 for target A, and don't have run 1 for target
> > B, why not just create another factor that reflects this, and plot that?
> >
> >  my.data$clus2 <- with(my.data, interaction(cluster, target))
> >
> >  and call: dotplot(value ~ type| clus2, ... )
> >
> >
> > Philip
> >
> >
> > On 22/02/2017 8:03 PM, Luigi Marongiu wrote:
> >
> >> dear all,
> >> I have a set of data that is subdivided in cluster (run 1/run 2) and in
> >> target (A/B). When plotting, I obtain a panel strip with "run 1" and
> "run
> >> 2" for each "A" and "B" panel, so "run 1" appears twice and so does "run
> >> 2". It is possible to merge the strip together so that I will have "run
> 1"
> >> or "run 2" only once? this will reduce the complexity of the data and
> >> allow
> >> more space for more detailed information in the strip.
> >> the data follows,
> >> thank you
> >> L
> >>
> >> cluster<- c(rep("run_1", 6), rep("run_2", 6))
> >> type<- rep(c("blank", "positive", "negative"),2)
> >> target<- c(rep("A", 6), rep("B", 6))
> >> value<- c(0.01, 1.1, 0.5,
> >>             0.02, 1.6, 0.8,
> >>             0.07, 1.4, 0.7,
> >>             0.03, 1.4, 0.4)
> >> my.data<- data.frame(cluster, type, target, value)
> >>
> >> library(lattice)
> >> dotplot(
> >>    value ~ type|target + cluster,
> >>    my.data,
> >>    groups = type,
> >>    pch=21,
> >>    main = "Luminex analysis MTb humans",
> >>    xlab = "Target", ylab = "Reading",
> >>    col = c("grey", "green", "red"),
> >>    par.settings = list(strip.background = list(col="paleturquoise")),
> >>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
> >>    key = list(
> >>      space = "top",
> >>      columns = 3,
> >>      text = list(c("Blank", "Negative", "Positive"), col="black"),
> >>      rectangles = list(col=c("grey", "green", "red"))
> >>    )
> >> )
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From Keith.Jewell at campdenbri.co.uk  Thu Feb 23 10:16:42 2017
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Thu, 23 Feb 2017 09:16:42 +0000
Subject: [R] Antwort: Re:  RStudio: Place for Storing Options
In-Reply-To: <OF5EFCA44F.2C2ABCFF-ONC12580D0.002B0E44-C12580D0.002C0835@lotus.hawesko.de>
References: <OF2AD33A34.7FBB12EC-ONC12580C2.003F15A3-C12580C2.003F49D7@lotus.hawesko.de>	<22684.34149.431821.945334@stat.math.ethz.ch>	<alpine.BSF.2.00.1702110801470.71951@pedal.dcn.davis.ca.us>	<22702.37235.988957.574018@stat.math.ethz.ch>
	<OF5EFCA44F.2C2ABCFF-ONC12580D0.002B0E44-C12580D0.002C0835@lotus.hawesko.de>
Message-ID: <o8m99k$1c0$1@blaine.gmane.org>

RStudio seems to not pay due regard to the distinction between APPDATA 
and LOCALAPPDATA.

See 
https://support.rstudio.com/hc/en-us/community/posts/200650543-File-history-and-project-history-stored-in-LOCALAPPDATA

On 23/02/2017 08:00, G.Maubach at weinwolf.de wrote:
> Hi Martin,
>
> the command
>
> %localappdata%\RStudio-Desktop
>
> gives on my machine
>
> "The command is written wrong or could not be found.".
>
> I found "RStudio-Desktop" under
>
> C:\Users\<username>\AppData\Local\RStudio-Desktop
>
> There references on created notebooks and presentations are stored in the
> folder "RStudio-Desktop". RStudio config is not documented yet.
>
> Kind regards
>
> Georg
>
>
>
>
> Von:    Martin Maechler <maechler at stat.math.ethz.ch>
> An:     Jeff Newmiller <jdnewmil at dcn.davis.ca.us>,
> Kopie:  Martin Maechler <maechler at stat.math.ethz.ch>,
> <G.Maubach at weinwolf.de>, R-help mailing list <r-help at r-project.org>
> Datum:  23.02.2017 08:37
> Betreff:        Re: [R] RStudio: Place for Storing Options
>
>
>
>>>>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>>>>      on Sat, 11 Feb 2017 08:09:36 -0800 writes:
>
>      > For the record, then, Google listened to my incantation of
>      > "rstudio configuration file" and the second result was:
>
>      >
> https://support.rstudio.com/hc/en-us/articles/200534577-Resetting-RStudio-Desktop-s-State
>
>
>      > RStudio Desktop is also open source, so you can download
>      > the source code and look at the operating-system-specific
>      > bits (for "where") if the above link goes out of date or
>      > disappears.
>
> Thanks a lot, Jeff!
>
> And for the archives:  On reasonable OS's,  the hidden
> directory/folder containing all the info is
>                                    ~/.rstudio-desktop/
> and if "things are broken" the recommendation is to rename that
>     mv ~/.rstudio-desktop  ~/backup-rstudio-desktop
> and (zip and) send along with your e-mail to the experts for diagnosis.
>
>
>      > On Thu, 9 Feb 2017, Martin Maechler wrote:
>
>      >>
>      >>>>>>> Ulrik Stervbo <ulrik.stervbo at gmail.com> on Thu, 9
>      >>>>>>> Feb 2017 14:37:57 +0000 writes:
>      >>
>      >> > Hi Georg, > maybe someone here knows, but I think you
>      >> are more likely to get answers to > Rstudio related
>      >> questions with RStudio support: >
>      >> https://support.rstudio.com/hc/en-us
>      >>
>      >> > Best, > Ulrik
>      >>
>      >> Indeed, thank you, Ulrik.
>      >>
>      >> In this special case, however, I'm quite sure many
>      >> readers of R-help would be interested in the answer; so
>      >> once you receive an answer, please post it (or a link to
>      >> a public URL with it) here on R-help, thank you in
>      >> advance.
>      >>
>      >> We would like to be able to *save*, or sometimes *set* /
>      >> *reset* such options "in a scripted manner", e.g. for
>      >> controlled exam sessions.
>      >>
>      >> Martin Maechler, ETH Zurich
>      >>
>      >> > On Thu, 9 Feb 2017 at 12:35 <G.Maubach at weinwolf.de>
>      >> wrote:
>      >>
>      >> >> Hi All, >> I would like to make a backup of my RStudio
>      >> IDE options I configure using >> "Tools/Global Options"
>      >> from the menu bar. Searching the >> web did not reveal
>      >> anything.
>      >>
>      >> >> Can you tell me where RStudio IDE does store its
>      >> configuration?
>      >>
>      >> >> Kind regards >> Georg
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>      >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>      >> PLEASE do read the posting guide
>      >> http://www.R-project.org/posting-guide.html and provide
>      >> commented, minimal, self-contained, reproducible code.
>      >>
>
>      >
> ---------------------------------------------------------------------------
>      > Jeff Newmiller The .....  .....  Go Live...
>      > DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#.  ##.#.  Live
>      > Go...  Live: OO#.. Dead: OO#..  Playing Research Engineer
>      > (Solar/Batteries O.O#.  #.O#.  with /Software/Embedded
>      > Controllers) .OO#.  .OO#.  rocks...1k
>      >
>


From pdalgd at gmail.com  Thu Feb 23 10:58:03 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 23 Feb 2017 10:58:03 +0100
Subject: [R] vars package - irf() does not work
In-Reply-To: <1487757420140.51553@kent.ac.uk>
References: <1487594810802.89921@kent.ac.uk> <1487757420140.51553@kent.ac.uk>
Message-ID: <D27C4003-AF8D-4D6F-A9DF-8580150027AB@gmail.com>

You are not giving us a fully reproducible example, nor telling us the exact error messages. However, chances are that you have another irf() function that gets in the way. Does it work with vars::irf(....) ?

-pd

On 22 Feb 2017, at 10:57 , T.Riedle <tr206 at kent.ac.uk> wrote:

> 
> 
> 
> Dear all,
> 
> I have not received any response on this email. Is there anybody who can help me?
> 
> I want to run an impulse response analysis using the vars() package. The code looks as follwows.
> 
> 
> # list of class varest
> varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type = "both")
> 
> varest.USA
> 
> summary(varest.USA)
> 
> 
> 
> #Run irf analysis
> irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE, ci=0.95)
> 
> plot(irf.USAg)
> 
> 
> The problem is that R returns an error that the arguments in irf are unused. That is, unused arguments (response="g", n.ahead = 48, boot = TRUE, ci=0.95)
> The strangeness is that it sometimes works but most of the time it does not. I installed vars() last month and irf() worked well but now it does only occasionally. I have just edited the data but kept the code unchanged.
> 
> 
> In addition, I have the same problem when I am trying to replicate the example on irf() in the vars vignette althoug it also worked well when I installed vars and run the example.
> 
> 
> Does anybody have an idea what is wrong?
> 
> 
> 
> 
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From vodvos at zoho.com  Thu Feb 23 11:40:32 2017
From: vodvos at zoho.com (vod vos)
Date: Thu, 23 Feb 2017 02:40:32 -0800
Subject: [R] How to search t value when you know degree of freedom?
In-Reply-To: <58ADB694.4010505@sapo.pt>
References: <15a66875fdf.10bcba69e2918.2834251748968068611@zoho.com>
	<58ADB694.4010505@sapo.pt>
Message-ID: <15a6a8edf99.ea17c8d214086.47035206492946309@zoho.com>

If we want to get 95% limit of t value, the result will be

pt(0.975, 29)  =  2.045

is that right?


 ---- On ???, 22 ?? 2017 08:04:36 -0800 Rui Barradas <ruipbarradas at sapo.pt> wrote ---- 
 > Hello, 
 >  
 > It would be ?pt not pnorm. 
 > And as you can see in that help page you need another value, the value  
 > of the quantile. (Don't worry about the arguments ncp or log just q and df) 
 >  
 > Hope this helps, 
 >  
 > Rui Barradas 
 >  
 > Em 22-02-2017 15:53, vod vos escreveu: 
 > > 
 > > Hi everyone, 
 > > 
 > > How to search t value when you know degree of freedom? 
 > > 
 > > For example, the degree of freedom is 29, how to use R to calculate the t value for it? 
 > > 
 > > t.test does not help, or pnorm? I am not sure. 
 > > 
 > > Thanks. 
 > > 
 > > ______________________________________________ 
 > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
 > > https://stat.ethz.ch/mailman/listinfo/r-help 
 > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
 > > and provide commented, minimal, self-contained, reproducible code. 
 > > 
 > 


From Thomas.Chesney at nottingham.ac.uk  Thu Feb 23 12:49:03 2017
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Thu, 23 Feb 2017 11:49:03 +0000
Subject: [R] How to stop as.integer removing dimenions
Message-ID: <6D29AA73-B477-4755-B31C-62FCCD089182@exmail.nottingham.ac.uk>

I have:

net1 <- array(0, dim=c(5,5))

str(net1)
 num [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...

and what I want is:

str(net1)
 int [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...

Neither of the following work:

net1 <- as.integer(net1, drop=FALSE)

net1 <- as.integer(net1, dim=c(5,5))

Can someone please help?

Thank you,

Thomas




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From Gerrit.Eichner at math.uni-giessen.de  Thu Feb 23 12:56:13 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 23 Feb 2017 12:56:13 +0100
Subject: [R] How to stop as.integer removing dimenions
In-Reply-To: <6D29AA73-B477-4755-B31C-62FCCD089182@exmail.nottingham.ac.uk>
References: <6D29AA73-B477-4755-B31C-62FCCD089182@exmail.nottingham.ac.uk>
Message-ID: <247ea082-2fa2-99fe-c4eb-76c9121bfadc@math.uni-giessen.de>

Hi, Thomas,

maybe

mode(net1) <- "integer"

does what you want?

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 23.02.2017 um 12:49 schrieb Thomas Chesney:
> I have:
>
> net1 <- array(0, dim=c(5,5))
>
> str(net1)
>  num [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...
>
> and what I want is:
>
> str(net1)
>  int [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...
>
> Neither of the following work:
>
> net1 <- as.integer(net1, drop=FALSE)
>
> net1 <- as.integer(net1, dim=c(5,5))
>
> Can someone please help?
>
> Thank you,
>
> Thomas
>
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
>
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
>
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Gerrit.Eichner at math.uni-giessen.de  Thu Feb 23 12:57:59 2017
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 23 Feb 2017 12:57:59 +0100
Subject: [R] How to stop as.integer removing dimenions
In-Reply-To: <6D29AA73-B477-4755-B31C-62FCCD089182@exmail.nottingham.ac.uk>
References: <6D29AA73-B477-4755-B31C-62FCCD089182@exmail.nottingham.ac.uk>
Message-ID: <99cf61be-41af-9660-8c76-21e8dea93ac3@math.uni-giessen.de>

... or:

net1 <- array(0L, dim=c(5,5))

Note the difference between 0 and 0L.


  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 23.02.2017 um 12:49 schrieb Thomas Chesney:
> I have:
>
> net1 <- array(0, dim=c(5,5))
>
> str(net1)
>  num [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...
>
> and what I want is:
>
> str(net1)
>  int [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...
>
> Neither of the following work:
>
> net1 <- as.integer(net1, drop=FALSE)
>
> net1 <- as.integer(net1, dim=c(5,5))
>
> Can someone please help?
>
> Thank you,
>
> Thomas
>
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
>
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
>
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lists at dewey.myzen.co.uk  Thu Feb 23 13:18:01 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 23 Feb 2017 12:18:01 +0000
Subject: [R] How to search t value when you know degree of freedom?
In-Reply-To: <15a6a8edf99.ea17c8d214086.47035206492946309@zoho.com>
References: <15a66875fdf.10bcba69e2918.2834251748968068611@zoho.com>
	<58ADB694.4010505@sapo.pt>
	<15a6a8edf99.ea17c8d214086.47035206492946309@zoho.com>
Message-ID: <5b7ac385-d93f-efc5-c6c9-4e670e3836c5@dewey.myzen.co.uk>

When I do pt(0.975, 29) I do not get 2.045 so I think you must have 
declared a new function pt which is interfering with things.

On 23/02/2017 10:40, vod vos wrote:
> If we want to get 95% limit of t value, the result will be
>
> pt(0.975, 29)  =  2.045
>
> is that right?
>
>
>  ---- On ???, 22 ?? 2017 08:04:36 -0800 Rui Barradas <ruipbarradas at sapo.pt> wrote ----
>  > Hello,
>  >
>  > It would be ?pt not pnorm.
>  > And as you can see in that help page you need another value, the value
>  > of the quantile. (Don't worry about the arguments ncp or log just q and df)
>  >
>  > Hope this helps,
>  >
>  > Rui Barradas
>  >
>  > Em 22-02-2017 15:53, vod vos escreveu:
>  > >
>  > > Hi everyone,
>  > >
>  > > How to search t value when you know degree of freedom?
>  > >
>  > > For example, the degree of freedom is 29, how to use R to calculate the t value for it?
>  > >
>  > > t.test does not help, or pnorm? I am not sure.
>  > >
>  > > Thanks.
>  > >
>  > > ______________________________________________
>  > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  > > https://stat.ethz.ch/mailman/listinfo/r-help
>  > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>  > > and provide commented, minimal, self-contained, reproducible code.
>  > >
>  >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dcarlson at tamu.edu  Thu Feb 23 14:06:23 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 23 Feb 2017 13:06:23 +0000
Subject: [R] How to search t value when you know degree of freedom?
In-Reply-To: <5b7ac385-d93f-efc5-c6c9-4e670e3836c5@dewey.myzen.co.uk>
References: <15a66875fdf.10bcba69e2918.2834251748968068611@zoho.com>
	<58ADB694.4010505@sapo.pt>
	<15a6a8edf99.ea17c8d214086.47035206492946309@zoho.com>
	<5b7ac385-d93f-efc5-c6c9-4e670e3836c5@dewey.myzen.co.uk>
Message-ID: <68db58a9481340fba939a8206814f0e6@exch-2p-mbx-w2.ads.tamu.edu>

Perhaps a typo? It should be qt() not pt():

> pt(0.975, 29) 
[1] 0.8311882
> qt(0.975, 29) 
[1] 2.04523

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Dewey
Sent: Thursday, February 23, 2017 6:18 AM
To: vod vos <vodvos at zoho.com>; Rui Barradas <ruipbarradas at sapo.pt>
Cc: R-help at r-project.org
Subject: Re: [R] How to search t value when you know degree of freedom?

When I do pt(0.975, 29) I do not get 2.045 so I think you must have 
declared a new function pt which is interfering with things.

On 23/02/2017 10:40, vod vos wrote:
> If we want to get 95% limit of t value, the result will be
>
> pt(0.975, 29)  =  2.045
>
> is that right?
>
>
>  ---- On ???, 22 ?? 2017 08:04:36 -0800 Rui Barradas <ruipbarradas at sapo.pt> wrote ----
>  > Hello,
>  >
>  > It would be ?pt not pnorm.
>  > And as you can see in that help page you need another value, the value
>  > of the quantile. (Don't worry about the arguments ncp or log just q and df)
>  >
>  > Hope this helps,
>  >
>  > Rui Barradas
>  >
>  > Em 22-02-2017 15:53, vod vos escreveu:
>  > >
>  > > Hi everyone,
>  > >
>  > > How to search t value when you know degree of freedom?
>  > >
>  > > For example, the degree of freedom is 29, how to use R to calculate the t value for it?
>  > >
>  > > t.test does not help, or pnorm? I am not sure.
>  > >
>  > > Thanks.
>  > >
>  > > ______________________________________________
>  > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  > > https://stat.ethz.ch/mailman/listinfo/r-help
>  > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>  > > and provide commented, minimal, self-contained, reproducible code.
>  > >
>  >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From henrique.monte66 at gmail.com  Wed Feb 22 23:52:55 2017
From: henrique.monte66 at gmail.com (henrique monte)
Date: Wed, 22 Feb 2017 19:52:55 -0300
Subject: [R] Web scraping - Having trouble figuring out how to approach this
	problem
Message-ID: <CAGLme_XXre4LTbNsVayv3qH6LoB9pWTGHRqy13xvehMy9CjZ-g@mail.gmail.com>

Sometimes I need to get some data from the web organizing it into a
dataframe and waste a lot of time doing it manually. I've been trying to
figure out how to optimize this proccess, and I've tried with some R
scraping approaches, but couldn't get to do it right and I thought there
could be an easier way to do this, can anyone help me out with this?

Fictional example:

Here's a webpage with countries listed by continents:
https://simple.wikipedia.org/wiki/List_of_countries_by_continents

Each country name is also a link that leads to another webpage (specific of
each country, e.g. https://simple.wikipedia.org/wiki/Angola).

I would like as a final result to get a data frame with number of
observations (rows) = number of countries listed and 4 variables (colums)
as ID=Country Name, Continent=Continent it belongs to, Language=Official
language (from the specific webpage of the Countries) and Population = most
recent population count (from the specific webpage of the Countries).

...

The main issue I'm trying to figure out is handling several webpages, like,
would it be possible to scrape from the first link of the problem the
countries as a list with the links of the countries webpages and then
create and run a function to run a scraping command in each of those links
from the list to get the specific data I'm looking for?

	[[alternative HTML version deleted]]


From vadim at sourced.tech  Thu Feb 23 11:37:50 2017
From: vadim at sourced.tech (Vadim Markovtsev)
Date: Thu, 23 Feb 2017 11:37:50 +0100
Subject: [R] Multi-GPU "Yinyang" K-means and K-nn for R
Message-ID: <CADUeS-LT2OxmwJV4YAvs+HcGWd23Ug749--b9zk3TbZaGtWYsg@mail.gmail.com>

?Hola!

This is to announce that [kmcuda](https://github.com/src-d/kmcuda) has
obtained native R bindings and ask for the help with CRAN packaging.
kmcuda is my child: an efficient GPGPU (CUDA) library to do K-means
and K-nn on as much data as fits into memory. It supports running on
multiple GPUs simultaneously, angular distance metric, Yinyang
refinement, float16 (well, not in R for sure), K-means++ and AFK-MC2
initialization. I am thinking about Minibatch in the near future.

Usage example:

    dyn.load("libKMCUDA.so")
    samples <- replicate(4, runif(16000))
    result = .External("kmeans_cuda", samples, 50, tolerance=0.01,
                                 seed=777, verbosity=1)
    print(result$centroids)
    print(result$assignments[1:10,])

This library only supports Linux and macOS at the moment. Windows
port is welcome.

I knew pretty much nothing about R a week ago so would be glad to your
suggestions. Besides, I've never published anything to CRAN and it
will take some time for me to design a full package following the
guidelines and rules. It will be awesome If somebody is willing to
help! It seems to be the special fun to package the CUDA+OpenMP
code for R and this fun doubles on macOS where you need a specific
combination of two different clang compilers to make it work.

Besides, I have a question which prevents me from sleeping at night:
how is R able to support matrices with dimensions larger than
INT32_MAX if the only integer type in C API is int (32-bit signed on
Linux)? Even getting the dimensions with INTEGER() automatically leads
to the overflow.
--
Best regards,

Vadim Markovtsev
Lead Machine Learning Engineer || source{d} / sourced.tech / Madrid
StackOverflow: 69708/markhor | GitHub: vmarkovtsev | data.world: vmarkovtsev


From paulbernal07 at gmail.com  Thu Feb 23 16:49:33 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 23 Feb 2017 10:49:33 -0500
Subject: [R] Generating Web Service for R Time Series Model in Microsoft
 Machine Learning Studio
Message-ID: <CAMOcQfNVXrFnY8Cbn_6m-=V3S2bk+1NLjJ=3wR-WLejhHEDJ5Q@mail.gmail.com>

Dear all,

I just created an R script to generate forecasts in Microsoft Azure Machine
Learning Studio, however, I want to create a web service for this model.

Does anybody has any idea of how to do it? I have been searching in the
web, but haven?t found anything yet.

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From cdetermanjr at gmail.com  Thu Feb 23 17:05:32 2017
From: cdetermanjr at gmail.com (Charles Determan)
Date: Thu, 23 Feb 2017 10:05:32 -0600
Subject: [R] Multi-GPU "Yinyang" K-means and K-nn for R
In-Reply-To: <CADUeS-LT2OxmwJV4YAvs+HcGWd23Ug749--b9zk3TbZaGtWYsg@mail.gmail.com>
References: <CADUeS-LT2OxmwJV4YAvs+HcGWd23Ug749--b9zk3TbZaGtWYsg@mail.gmail.com>
Message-ID: <CAKxd1KOcmrRVCnR46p4LUG8PsRPs5gD5gu-_sCSSmKtSFYrNtQ@mail.gmail.com>

Hi Vadim,

I would be happy to explore helping you out with this.  I am quite active
in development for GPU use in R.  You can see my work on my github (
https://github.com/cdeterman) and the group I created for additional
packages in development (https://github.com/gpuRcore).  I believe it would
be best though to take this conversation off list though.  If you would
like to discuss this further please email me separately.

Kind regards,
Charles


On Thu, Feb 23, 2017 at 4:37 AM, Vadim Markovtsev <vadim at sourced.tech>
wrote:

> ?Hola!
>
> This is to announce that [kmcuda](https://github.com/src-d/kmcuda) has
> obtained native R bindings and ask for the help with CRAN packaging.
> kmcuda is my child: an efficient GPGPU (CUDA) library to do K-means
> and K-nn on as much data as fits into memory. It supports running on
> multiple GPUs simultaneously, angular distance metric, Yinyang
> refinement, float16 (well, not in R for sure), K-means++ and AFK-MC2
> initialization. I am thinking about Minibatch in the near future.
>
> Usage example:
>
>     dyn.load("libKMCUDA.so")
>     samples <- replicate(4, runif(16000))
>     result = .External("kmeans_cuda", samples, 50, tolerance=0.01,
>                                  seed=777, verbosity=1)
>     print(result$centroids)
>     print(result$assignments[1:10,])
>
> This library only supports Linux and macOS at the moment. Windows
> port is welcome.
>
> I knew pretty much nothing about R a week ago so would be glad to your
> suggestions. Besides, I've never published anything to CRAN and it
> will take some time for me to design a full package following the
> guidelines and rules. It will be awesome If somebody is willing to
> help! It seems to be the special fun to package the CUDA+OpenMP
> code for R and this fun doubles on macOS where you need a specific
> combination of two different clang compilers to make it work.
>
> Besides, I have a question which prevents me from sleeping at night:
> how is R able to support matrices with dimensions larger than
> INT32_MAX if the only integer type in C API is int (32-bit signed on
> Linux)? Even getting the dimensions with INTEGER() automatically leads
> to the overflow.
> --
> Best regards,
>
> Vadim Markovtsev
> Lead Machine Learning Engineer || source{d} / sourced.tech / Madrid
> StackOverflow: 69708/markhor | GitHub: vmarkovtsev | data.world:
> vmarkovtsev
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From andrewkc at live.unc.edu  Thu Feb 23 15:42:15 2017
From: andrewkc at live.unc.edu (Castro, Andrew William Keahi)
Date: Thu, 23 Feb 2017 14:42:15 +0000
Subject: [R] Impose Structure for Exogenous in vars Package
Message-ID: <CY1PR03MB222025A23EF461AACA4FA7F7E3530@CY1PR03MB2220.namprd03.prod.outlook.com>

Hello everyone,

I see there are structural VAR options in the vars package for the endogenous variables, but is there any easy way to impose structure on the exogenous variable matrix (notated as the matrix C on page 45 of https://cran.r-project.org/web/packages/vars/vars.pdf). Thanks!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Feb 23 19:03:42 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 23 Feb 2017 10:03:42 -0800
Subject: [R] Web scraping - Having trouble figuring out how to approach
	this	problem
In-Reply-To: <CAGLme_XXre4LTbNsVayv3qH6LoB9pWTGHRqy13xvehMy9CjZ-g@mail.gmail.com>
References: <CAGLme_XXre4LTbNsVayv3qH6LoB9pWTGHRqy13xvehMy9CjZ-g@mail.gmail.com>
Message-ID: <BFFFD051-B1D4-47EA-8083-A65640C8B88D@dcn.davis.ca.us>

The answer is yes, and does not seem like a big step from where you are now, so seeing what you already know how to do (reproducible example, or RE) would help focus the assistance. There are quite a few ways to do this kind of thing, and what you already know would be clarified with a RE.
-- 
Sent from my phone. Please excuse my brevity.

On February 22, 2017 2:52:55 PM PST, henrique monte <henrique.monte66 at gmail.com> wrote:
>Sometimes I need to get some data from the web organizing it into a
>dataframe and waste a lot of time doing it manually. I've been trying
>to
>figure out how to optimize this proccess, and I've tried with some R
>scraping approaches, but couldn't get to do it right and I thought
>there
>could be an easier way to do this, can anyone help me out with this?
>
>Fictional example:
>
>Here's a webpage with countries listed by continents:
>https://simple.wikipedia.org/wiki/List_of_countries_by_continents
>
>Each country name is also a link that leads to another webpage
>(specific of
>each country, e.g. https://simple.wikipedia.org/wiki/Angola).
>
>I would like as a final result to get a data frame with number of
>observations (rows) = number of countries listed and 4 variables
>(colums)
>as ID=Country Name, Continent=Continent it belongs to,
>Language=Official
>language (from the specific webpage of the Countries) and Population =
>most
>recent population count (from the specific webpage of the Countries).
>
>...
>
>The main issue I'm trying to figure out is handling several webpages,
>like,
>would it be possible to scrape from the first link of the problem the
>countries as a list with the links of the countries webpages and then
>create and run a function to run a scraping command in each of those
>links
>from the list to get the specific data I'm looking for?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Thu Feb 23 20:01:27 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 23 Feb 2017 19:01:27 +0000
Subject: [R] How to stop as.integer removing dimenions
Message-ID: <2A6F4008-94BF-4066-AA15-48E51E5631F4@llnl.gov>

> net1 <- array(0L, dim=c(5,5))
> str(net1)
 int [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 2/23/17, 3:49 AM, "R-help on behalf of Thomas Chesney" <r-help-bounces at r-project.org on behalf of Thomas.Chesney at nottingham.ac.uk> wrote:

    I have:
    
    net1 <- array(0, dim=c(5,5))
    
    str(net1)
     num [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...
    
    and what I want is:
    
    str(net1)
     int [1:5, 1:5] 0 0 0 0 0 0 0 0 0 0 ...
    
    Neither of the following work:
    
    net1 <- as.integer(net1, drop=FALSE)
    
    net1 <- as.integer(net1, dim=c(5,5))
    
    Can someone please help?
    
    Thank you,
    
    Thomas
    
    
    
    
    This message and any attachment are intended solely for the addressee
    and may contain confidential information. If you have received this
    message in error, please send it back to me, and immediately delete it. 
    
    Please do not use, copy or disclose the information contained in this
    message or in any attachment.  Any views or opinions expressed by the
    author of this email do not necessarily reflect the views of the
    University of Nottingham.
    
    This message has been checked for viruses but the contents of an
    attachment may still contain software viruses which could damage your
    computer system, you are advised to perform your own checks. Email
    communications with the University of Nottingham may be monitored as
    permitted by UK legislation.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From andrluis at ualberta.ca  Thu Feb 23 23:37:38 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Thu, 23 Feb 2017 15:37:38 -0700
Subject: [R] Help with data management
Message-ID: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>

Dear R users,

I have the following dataframes (A, B, and C) stored in a list:

A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
colnames(A) <- c ("Family", "NormalizedCount", "Hits")
A


B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
colnames(B) <- c ("Family", "NormalizedCount", "Hits")
B


C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
colnames(C) <- c ("Family", "NormalizedCount", "Hits")
C

mylist <- list(A=A,B=B,C=C)
mylist


My idea is to merge the three dataframes into another dataframe (let's name
it: 'D')  with a structure in which the rows are the Families and columns
the "Hits" of each family detected in the dataframes A, B, and C. If a
given 'Family' does NOT have a 'Hit' in the dataframe we need to assign
number 0 to it.

The dataframe 'D' would need to be populated as follows:


Family                                                      A
       B                                      C
c 1 1 0
d 2 0 0
e 3 0 0
f 0 4 5
a 0 3 0
q 0 0 10
o 0 0 4


Thank you very much for your great help,


?
-- 
Andre

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Feb 24 00:24:29 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Feb 2017 10:24:29 +1100
Subject: [R] Help with data management
In-Reply-To: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>
References: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>
Message-ID: <CA+8X3fWBNX-QA+LPQXsP6XqV0r9zftGUDVNZmFo0hgGYkNBbkg@mail.gmail.com>

Hi Andre,
This might do it:

A<-data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
colnames(A) <- c ("Family", "NormalizedCount", "Hits")
B<-data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
colnames(B) <- c ("Family", "NormalizedCount", "Hits")
C<-data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
colnames(C) <- c ("Family", "NormalizedCount", "Hits")
keepcols<-c("Family","Hits")
D<-merge(A[,keepcols],B[,keepcols],by="Family",all=TRUE)
D<-merge(D,C[,keepcols],by="Family",all=TRUE)
D[,2:4]<-sapply(D[,-1],function(x) { x[is.na(x)]<-0; x })
names(D)<-c("Family","A","B","C")

Jim


On Fri, Feb 24, 2017 at 9:37 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Dear R users,
>
> I have the following dataframes (A, B, and C) stored in a list:
>
> A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
> colnames(A) <- c ("Family", "NormalizedCount", "Hits")
> A
>
>
> B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
> colnames(B) <- c ("Family", "NormalizedCount", "Hits")
> B
>
>
> C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
> colnames(C) <- c ("Family", "NormalizedCount", "Hits")
> C
>
> mylist <- list(A=A,B=B,C=C)
> mylist
>
>
> My idea is to merge the three dataframes into another dataframe (let's name
> it: 'D')  with a structure in which the rows are the Families and columns
> the "Hits" of each family detected in the dataframes A, B, and C. If a
> given 'Family' does NOT have a 'Hit' in the dataframe we need to assign
> number 0 to it.
>
> The dataframe 'D' would need to be populated as follows:
>
>
> Family                                                      A
>        B                                      C
> c 1 1 0
> d 2 0 0
> e 3 0 0
> f 0 4 5
> a 0 3 0
> q 0 0 10
> o 0 0 4
>
>
> Thank you very much for your great help,
>
>
>
> --
> Andre
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Feb 24 01:00:23 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 24 Feb 2017 11:00:23 +1100
Subject: [R] Help with data management
In-Reply-To: <CAHxKz8b7YdUURm-9=5a1kr9Am8RWwVWyttoRjRNZC-+t1J3cvQ@mail.gmail.com>
References: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>
	<CA+8X3fWBNX-QA+LPQXsP6XqV0r9zftGUDVNZmFo0hgGYkNBbkg@mail.gmail.com>
	<CAHxKz8b7YdUURm-9=5a1kr9Am8RWwVWyttoRjRNZC-+t1J3cvQ@mail.gmail.com>
Message-ID: <CA+8X3fUG7QcG=cKkgL8wRWEP5_EEzLOEZ4bUa+9QyPpbG-Yz=Q@mail.gmail.com>

Hi Andre,
As far as I am aware, merges can only be accomplished between two data
frames, so I think you would have to do it one by one. It is probably
possible to program this to operate on your list of data frames, but I
suspect that it would take as much time as a bit of copying and
pasting. If your data is being extracted from an external database, it
may be possible to perform the operation in SQL, I don't have the time
to work that out at the moment.

Jim


On Fri, Feb 24, 2017 at 10:53 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Hi, Jim:
>
> Your code worked great, but I have 48 dataframes. After merging A and B in
> D, you merged C in D. In this case, do I need to add them one by one until
> getting the 48 dataframes merged in one?
>
> Thank you for your great help.
>
> Andre
>
> On Thu, Feb 23, 2017 at 4:24 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Andre,
>> This might do it:
>>
>> A<-data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
>> colnames(A) <- c ("Family", "NormalizedCount", "Hits")
>> B<-data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
>> colnames(B) <- c ("Family", "NormalizedCount", "Hits")
>> C<-data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
>> colnames(C) <- c ("Family", "NormalizedCount", "Hits")
>> keepcols<-c("Family","Hits")
>> D<-merge(A[,keepcols],B[,keepcols],by="Family",all=TRUE)
>> D<-merge(D,C[,keepcols],by="Family",all=TRUE)
>> D[,2:4]<-sapply(D[,-1],function(x) { x[is.na(x)]<-0; x })
>> names(D)<-c("Family","A","B","C")
>>
>> Jim
>>
>>
>> On Fri, Feb 24, 2017 at 9:37 AM, Andr? Luis Neves <andrluis at ualberta.ca>
>> wrote:
>> > Dear R users,
>> >
>> > I have the following dataframes (A, B, and C) stored in a list:
>> >
>> > A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
>> > colnames(A) <- c ("Family", "NormalizedCount", "Hits")
>> > A
>> >
>> >
>> > B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
>> > colnames(B) <- c ("Family", "NormalizedCount", "Hits")
>> > B
>> >
>> >
>> > C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
>> > colnames(C) <- c ("Family", "NormalizedCount", "Hits")
>> > C
>> >
>> > mylist <- list(A=A,B=B,C=C)
>> > mylist
>> >
>> >
>> > My idea is to merge the three dataframes into another dataframe (let's
>> > name
>> > it: 'D')  with a structure in which the rows are the Families and
>> > columns
>> > the "Hits" of each family detected in the dataframes A, B, and C. If a
>> > given 'Family' does NOT have a 'Hit' in the dataframe we need to assign
>> > number 0 to it.
>> >
>> > The dataframe 'D' would need to be populated as follows:
>> >
>> >
>> > Family                                                      A
>> >        B                                      C
>> > c 1 1 0
>> > d 2 0 0
>> > e 3 0 0
>> > f 0 4 5
>> > a 0 3 0
>> > q 0 0 10
>> > o 0 0 4
>> >
>> >
>> > Thank you very much for your great help,
>> >
>> >
>> >
>> > --
>> > Andre
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Andre


From jwd at surewest.net  Fri Feb 24 01:46:48 2017
From: jwd at surewest.net (John Dougherty)
Date: Thu, 23 Feb 2017 16:46:48 -0800
Subject: [R] vars package - irf() does not work
In-Reply-To: <1487757420140.51553@kent.ac.uk>
References: <1487594810802.89921@kent.ac.uk> <1487757420140.51553@kent.ac.uk>
Message-ID: <20170223164648.247642fd@draco>

On Wed, 22 Feb 2017 09:57:00 +0000
"T.Riedle" <tr206 at kent.ac.uk> wrote:

> Dear all,
> 
> I have not received any response on this email. Is there anybody who
> can help me?
> 
> I want to run an impulse response analysis using the vars() package.
> The code looks as follwows.
> 
> 
> # list of class varest
> varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type =
> "both")
> 
> varest.USA
> 
> summary(varest.USA)
> 
> 
> 
> #Run irf analysis
> irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE,
> ci=0.95)
> 
> plot(irf.USAg)
> 
> 
> The problem is that R returns an error that the arguments in irf are
> unused. That is, unused arguments (response="g", n.ahead = 48, boot =
> TRUE, ci=0.95) The strangeness is that it sometimes works but most of
> the time it does not. I installed vars() last month and irf() worked
> well but now it does only occasionally. I have just edited the data
> but kept the code unchanged.
> 
> 
> In addition, I have the same problem when I am trying to replicate
> the example on irf() in the vars vignette althoug it also worked well
> when I installed vars and run the example.
> 
> 
> Does anybody have an idea what is wrong?
> 
Two guesses are 1) you are not consistently entering the commands and
thus get variable outcomes, and 2) possibly there are "depends" that
irf() needs that need to updated.  You could also contact the package
creators.  I would also observe that this looks remarkably like you
might be asking for help on your homework.  

I would create a script of the commands you use as they work, each
entered in sequence as you used it. You use it essentially as a lab
notebook that documents procedures.  RStudio works well for this, since
you can copy each line that works from the Console to a script file in
the editor.  You can do the same with a text editor, while using R from
a console, but it is somewhat more clumsy.  


-- 

John


From paul at stat.auckland.ac.nz  Fri Feb 24 02:26:45 2017
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 24 Feb 2017 14:26:45 +1300
Subject: [R] [FORGED] Re: single strip for the same group in dotplot
 lattice
In-Reply-To: <CAMk+s2QEHaELBM7vx-iS6ubHC9hmF=xyG4c41j1CK6h7VQTD=w@mail.gmail.com>
References: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>
	<58AD5F9E.5070205@iinet.net.au>
	<CAMk+s2T_QK1Lp89KEH1RofNXz5xC3iyb5mcMKqgSzOwE_n359Q@mail.gmail.com>
	<000301d28d7f$92244820$b66cd860$@bigpond.com>
	<CAMk+s2QEHaELBM7vx-iS6ubHC9hmF=xyG4c41j1CK6h7VQTD=w@mail.gmail.com>
Message-ID: <d659be8f-050e-6cbe-4692-11eb8b1540c4@stat.auckland.ac.nz>

Hi

The following is a bit customised to your example, but maybe if there's 
no other way ...

library(grid)
## Go down to the viewport that lays everything out
downViewport("plot_01.toplevel.vp")
## Eyeball the widths and heights (the "null"s are the plot regions)
## current.viewport()$layout$widths
## current.viewport()$layout$heights
## Make a viewport along the top strips and draw in it
pushViewport(viewport(layout.pos.col=7:25,
                       layout.pos.row=8))
grid.rect(y=1, height=unit(1, "lines"), just="top",
           gp=gpar(fill="paleturquoise"))
grid.text("run_2", y=unit(1, "npc") - unit(.5, "lines"))
upViewport()
## Make a viewport along the bottom strips and draw in it
pushViewport(viewport(layout.pos.col=7:25,
                       layout.pos.row=12))
grid.rect(y=1, height=unit(1, "lines"), just="top",
           gp=gpar(fill="paleturquoise"))
grid.text("run_1", y=unit(1, "npc") - unit(.5, "lines"))
upViewport()

Paul

On 23/02/17 22:00, Luigi Marongiu wrote:
> Dear Duncan and Philip,
> thank you for your answers. maybe the toy data I gave it is a bit too easy,
> so I am attaching a new dataset with 5 targets. As you can see from it, now
> there are 5 panel strips with the label "run_1" and 5 with the label
> "run_2". What I would like to do is to merge those with the same label so
> to have only two labels "run_1" and "run_2".
> the examples from Duncan contains plenty of keys but I think make the
> reading of the plot more difficult; most of the plots have only one strip.
> thank you
> luigi
>
>>>>
> # the values are actually repeated, but they are just for example
> cluster <- c(rep("run_1", 45), rep("run_2", 45))
> type <- rep(c("blank", "positive", "negative"),30)
> target <- rep(c(rep("A", 3), rep("B", 3), rep("C", 3), rep("D", 3),
> rep("E", 3)), 6)
> value <- rep(c(rnorm(1, mean=0.001, sd=0.1), rnorm(1, mean=2, sd=1),
> rnorm(1, mean=1, sd=1)),30)
> my.data <- data.frame(cluster, type, target, value)
>
> library(lattice)
> dotplot(
>   value ~ type|target + cluster,
>   my.data,
>   groups = type,
>   pch=21,
>   main = "Luminex analysis MTb humans",
>   xlab = "Target", ylab = "Reading",
>   col = c("grey", "green", "red"),
>   par.settings = list(strip.background = list(col="paleturquoise")),
>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>   key = list(
>     space = "top",
>     columns = 3,
>     text = list(c("Blank", "Negative", "Positive"), col="black"),
>     rectangles = list(col=c("grey", "green", "red"))
>   )
> )
>
>
> On Thu, Feb 23, 2017 at 2:50 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>
>> Hi Liugi
>>
>> Here are some ideas quickly
>>
>> 4 panels diagonals are blank
>>
>> mdata = my.data
>> mdata$ct <- paste(target, "Run", rep(1:2, each = 6))
>> mdata$typeT <- paste(mdata$target,mdata$type)
>>
>> dotplot(
>>   value ~ type|ct,
>>   mdata2,
>>   groups = typeT,
>>   par.settings = list(strip.background = list(col="paleturquoise"),
>>                       superpose.symbol = list(col = c(2:4),
>>                                               pch = rep(c(1,20),each =
>> 3))),
>> # type
>>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>   main = "Luminex analysis MTb humans",
>>   xlab = "Target",
>>   ylab = "Reading",
>>   auto.key = T,
>>   panel = panel.superpose
>> )
>>
>> # for when the 4 panels have plots not 2 as now
>>  mdata2 = mdata
>>  mdata2$target = rep(LETTERS[2:1], ea=6)
>>  mdata2$value= mdata2$value+0.1
>>  mdata2 <- rbind(mdata,mdata2)
>>
>> mdata2$typeT <- paste(mdata2$target,mdata2$type)
>>
>>  dotplot(
>>    value ~ type|target + cluster,
>>    mdata2,
>>    groups = typeT,
>>    par.settings = list(strip.background = list(col="paleturquoise"),
>>                        superpose.symbol = list(col = c(2:4),
>>                                                pch = rep(c(1,20),each =
>> 3))), # type
>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>    main = "Luminex analysis MTb humans",
>>    xlab = "Target",
>>    ylab = "Reading",
>>    auto.key = T,
>>    panel = panel.superpose
>>  )
>>
>>
>>  dotplot(
>>    value ~ type|ct,
>>    mdata2,
>>    groups = typeT,
>>    par.settings = list(strip.background = list(col="paleturquoise"),
>>                        superpose.symbol = list(col = c(2:4),
>>                                                pch = rep(c(1,20),each =
>> 3))), # type
>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>    main = "Luminex analysis MTb humans",
>>    strip    = strip.custom(factor.levels = paste("Run",1:2),
>>                         par.strip.text = list(cex = 1) ),
>>    xlab = "Target",
>>    ylab = "Reading",
>>    auto.key = T,
>>    panel = panel.superpose
>>  )
>>
>> dotplot(
>>   value ~ type|cluster,
>>   mdata2,
>>   groups = typeT,
>>   par.settings = list(strip.background = list(col="paleturquoise"),
>>                       superpose.symbol = list(col = c(2:4),
>>                                               pch = rep(c(1,20),each =
>> 3))),
>> # type
>>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>   main = "Luminex analysis MTb humans",
>>   xlab = "Target",
>>   ylab = "Reading",
>>   auto.key = T,
>>   panel = panel.superpose
>> )
>>
>>
>> Regards
>>
>> Duncan
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
>> Marongiu
>> Sent: Wednesday, 22 February 2017 21:26
>> To: P Tennant; r-help
>> Subject: Re: [R] single strip for the same group in dotplot lattice
>>
>> Dear Philip,
>> the data is indeed a toy data: the real one will have 15 panels (=targets)
>> and two or three clusters. this means that I will have 15 strips with the
>> label "run 1" = "cluster 1" etc. the point of the toy data is that I get a
>> 4x4 panel plot with 8 strips labelled "run 1", "run 2", "A" and "B". What I
>> am looking for is to collapse the strips so to get only one label "run 1"
>> and only one with "run 2" in order to simplify the plot. Hope this helps.
>> Thanks
>> Luigi
>>
>> On Wed, Feb 22, 2017 at 9:53 AM, P Tennant <philipt900 at iinet.net.au>
>> wrote:
>>
>>> Hi Luigi,
>>>
>>> I'm afraid I don't understand your toy data as you've described it, but
>> if
>>> you really don't have run 2 for target A, and don't have run 1 for target
>>> B, why not just create another factor that reflects this, and plot that?
>>>
>>>  my.data$clus2 <- with(my.data, interaction(cluster, target))
>>>
>>>  and call: dotplot(value ~ type| clus2, ... )
>>>
>>>
>>> Philip
>>>
>>>
>>> On 22/02/2017 8:03 PM, Luigi Marongiu wrote:
>>>
>>>> dear all,
>>>> I have a set of data that is subdivided in cluster (run 1/run 2) and in
>>>> target (A/B). When plotting, I obtain a panel strip with "run 1" and
>> "run
>>>> 2" for each "A" and "B" panel, so "run 1" appears twice and so does "run
>>>> 2". It is possible to merge the strip together so that I will have "run
>> 1"
>>>> or "run 2" only once? this will reduce the complexity of the data and
>>>> allow
>>>> more space for more detailed information in the strip.
>>>> the data follows,
>>>> thank you
>>>> L
>>>>
>>>> cluster<- c(rep("run_1", 6), rep("run_2", 6))
>>>> type<- rep(c("blank", "positive", "negative"),2)
>>>> target<- c(rep("A", 6), rep("B", 6))
>>>> value<- c(0.01, 1.1, 0.5,
>>>>             0.02, 1.6, 0.8,
>>>>             0.07, 1.4, 0.7,
>>>>             0.03, 1.4, 0.4)
>>>> my.data<- data.frame(cluster, type, target, value)
>>>>
>>>> library(lattice)
>>>> dotplot(
>>>>    value ~ type|target + cluster,
>>>>    my.data,
>>>>    groups = type,
>>>>    pch=21,
>>>>    main = "Luminex analysis MTb humans",
>>>>    xlab = "Target", ylab = "Reading",
>>>>    col = c("grey", "green", "red"),
>>>>    par.settings = list(strip.background = list(col="paleturquoise")),
>>>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>>>    key = list(
>>>>      space = "top",
>>>>      columns = 3,
>>>>      text = list(c("Blank", "Negative", "Positive"), col="black"),
>>>>      rectangles = list(col=c("grey", "green", "red"))
>>>>    )
>>>> )
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From sebastien.bihorel at cognigencorp.com  Fri Feb 24 05:52:30 2017
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Thu, 23 Feb 2017 23:52:30 -0500 (EST)
Subject: [R] Vertical boxplot with a continuous X axis
Message-ID: <2039994774.47306.1487911950034.JavaMail.zimbra@cognigencorp.com>


Hi,

Can the boxplot design illustrated in the post (http://stackoverflow.com/questions/39849459/how-to-create-boxplots-with-a-continuous-x-axis-in-r) be reproduced with lattice or a lattice-derived function?

Thank you

Sebastien


From rmh at temple.edu  Fri Feb 24 07:10:44 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 24 Feb 2017 01:10:44 -0500
Subject: [R] Vertical boxplot with a continuous X axis
In-Reply-To: <2039994774.47306.1487911950034.JavaMail.zimbra@cognigencorp.com>
References: <2039994774.47306.1487911950034.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGx1TMAXXw4AcMDqGm6OVM_9oWcdM8hh+3fKEbXXkGdn5U6YyQ@mail.gmail.com>

Yes, this is exactly what the panel function
    panel.bwplot.intermediate.hh
along with the
    position()
function in the HH package was designed for.

Continuing with the example in the linked stackoverflow

df <- structure(list(X1 = c(67.0785968921204, 45.5968692796599,
36.9528452430474,
59.0160838607585, 50.0432724395945, 44.3381091105162, 57.9705240678336,
52.5298724133533, 62.0004216014734, 54.1111551461596), X2 = c(66.4508598009841,
46.9692156851792, 37.1419457255043, 60.0582991817961, 50.7717368681294,
44.6962314013419, 57.5490276313784, 52.6394305113891, 62.9297233041122,
56.8151766642767), X3 = c(66.4517425831512, 46.2946539468733,
36.5946733567535, 59.2477934854157, 49.1558840130484, 44.7507905380111,
59.1132983272444, 53.710627728232, 61.7923277906642, 57.5999862897015
), X4 = c(66.1516449763315, 45.4660590159847, 37.2239262718906,
59.2975530712561, 50.2546321578291, 44.7220452966667, 59.8879656465763,
52.321734919241, 62.0802304973764, 56.6507005349853), X5 = c(66.1810558292955,
46.3301985628267, 36.4487743101244, 60.054119632362, 49.1593136549535,
44.5708909518076, 58.5865142665164, 52.5527273219855, 61.3749185309236,
54.1823379401272), X6 = c(65.9530929286517, 45.5120010675769,
36.7924160587984, 58.9428613519645, 50.3412809263164, 44.9671678827697,
57.8718260182012, 51.8954544252633, 62.0173019998447, 56.3833840769146
), X7 = c(66.3862581408135, 46.5872469340431, 36.7585555977493,
58.1374309578563, 50.3399735165261, 44.5739565876491, 57.5245695195136,
52.7613488669329, 61.2500297922529, 55.9202360622414), X8 = c(67.5577910713347,
46.1891742544371, 36.4689522649804, 59.5271358261971, 49.6776114214636,
44.1995317742719, 58.4881363877987, 52.1946266979144, 62.1149998459759,
55.3748655464147), X9 = c(66.3943390258844, 45.843835703738,
37.3485122393333, 59.8591304277037, 49.387883195468, 44.4283817056918,
58.1874530826789, 53.5091378916001, 62.1187451212786, 55.3632760142297
), X10 = c(66.9748072219828, 46.20735965374, 36.7069272963502,
59.5035069226904, 48.8446530329762, 44.8753686249692, 58.0223695284058,
53.2732448917674, 61.2509571513, 54.9615424261546), age = c(55,
37, 31, 59, 49, 47, 69, 68, 69, 66)), .Names = c("X1", "X2",
"X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "age"), row.names =
c("GSM1051533_7800246024_R03C02",
"GSM1051534_7800246024_R04C02", "GSM1051535_7800246024_R05C02",
"GSM1051536_7800246024_R06C02", "GSM1051537_7800246085_R01C01",
"GSM1051538_7800246085_R02C01", "GSM1051539_7800246085_R03C01",
"GSM1051540_7800246085_R04C01", "GSM1051541_7800246085_R05C01",
"GSM1051542_7800246085_R06C01"), class = "data.frame")

##  install.packages("HH")  ## if necessary
library(HH)

df.melt <- reshape2::melt(df, id.vars=c("age"))
df.melt$age.pos <- factor(df.melt$age)
position(df.melt$age.pos) <- levels(df.melt$age.pos)


## three options of x ticks and color

bwplot(value ~ age.pos, data=df.melt,
       horizontal=FALSE,
       panel=panel.bwplot.intermediate.hh,
       scales=list(
         x=list(
           at=position(df.melt$age.pos), ## placement of tick labels and marks
           limits=c(29, 71),             ## x limits
           tck=1)),                      ## draw tick marks
       xlab="age",
       main=list("value ~ age", cex=1.4))

bwplot(value ~ age.pos, data=df.melt,
       horizontal=FALSE,
       panel=panel.bwplot.intermediate.hh,
       scales=list(
         x=list(
        ## at=position(df.melt$age.pos), ## placement of tick labels and marks
           limits=c(29, 71),             ## x limits
           tck=1)),                      ## draw tick marks
       xlab="age",
       main=list("value ~ age", cex=1.4))

bwplot(value ~ age.pos, data=df.melt,
       horizontal=FALSE,
       panel=panel.bwplot.intermediate.hh,
       col="blue",                       ## constant color
       scales=list(
         x=list(
       ##  at=position(df.melt$age.pos), ## placement of tick labels and marks
           limits=c(29, 71),             ## x limits
           tck=1)),                      ## draw tick marks
       xlab="age",
       main=list("value ~ age", cex=1.4))

On Thu, Feb 23, 2017 at 11:52 PM, Sebastien Bihorel
<sebastien.bihorel at cognigencorp.com> wrote:
>
> Hi,
>
> Can the boxplot design illustrated in the post (http://stackoverflow.com/questions/39849459/how-to-create-boxplots-with-a-continuous-x-axis-in-r) be reproduced with lattice or a lattice-derived function?
>
> Thank you
>
> Sebastien
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Feb 24 08:01:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 23 Feb 2017 23:01:36 -0800
Subject: [R] Vertical boxplot with a continuous X axis
In-Reply-To: <2039994774.47306.1487911950034.JavaMail.zimbra@cognigencorp.com>
References: <2039994774.47306.1487911950034.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbS0eTtB-zCCGkO2JV3_69MLNOK3H-gUgZM4_w2cmpPtgg@mail.gmail.com>

Sebastien:

The linked post is unclear: two of the rows have the same age, so
should there be 10 boxplots for the 10 rows or 9 for the 9 different
ages? I assumed the latter, as otherwise how could one disciminate
rows with the same age that have overlapping values?

For lattice, I just used age as the group= parameter to group by ages
and used panel.bwplot for the panel.groups function. My "aesthetics"
are different than shown in the linked post, but can be altered in
lattice through the panel.bwplot and par.settings parameters as
described in ?panel.bwplot:

   y <- unlist(df[,-11])
   age <- rep(df[,"age"],10) ## Could be done programatically
   xyplot(y~age, groups = age,
          panel = function(...){
             panel.abline(h = seq(40,65, by=5),
                          v = seq(30,70, by =5),
                          col="lightgray")
             panel.superpose(...)
          },
          panel.groups = function(x,y,...)
                panel.bwplot(x,y,horiz=FALSE,fill = "lightgray",
                        pch = 16, cex=.7,col= "black",box.width = 1.5),
          par.settings =list(box.rectangle = list(col="black"))
   )

However, note that this too could produce a hopeless mishmosh if the
ages are close together so that the boxplots overlap; or you could end
up getting nearly invisible skinny boxes, as in the plot shown in the
linked post.  So on the whole, I think you are better off treating the
ages as a factor and thereby separating them, e.g.

   bwplot(y~age, fill = "lightgray", horiz = FALSE,
          panel = function(...){
             panel.abline(h = seq(40,65, by=5),col="lightgray")
             panel.bwplot(...)
             },
          scales = list(x= list(lab = sort(unique(age)))),
          par.settings =list(box.rectangle = list(col="black"))
   )



Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 23, 2017 at 8:52 PM, Sebastien Bihorel
<sebastien.bihorel at cognigencorp.com> wrote:
>
> Hi,
>
> Can the boxplot design illustrated in the post (http://stackoverflow.com/questions/39849459/how-to-create-boxplots-with-a-continuous-x-axis-in-r) be reproduced with lattice or a lattice-derived function?
>
> Thank you
>
> Sebastien
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Fri Feb 24 10:27:54 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Fri, 24 Feb 2017 09:27:54 +0000
Subject: [R] single strip for the same group in dotplot lattice
In-Reply-To: <CAMk+s2QEHaELBM7vx-iS6ubHC9hmF=xyG4c41j1CK6h7VQTD=w@mail.gmail.com>
References: <CAMk+s2S4iHOBuQ29uWJc-DgvbQLmhmth=DbH_-AL40XfT7r8zw@mail.gmail.com>
	<58AD5F9E.5070205@iinet.net.au>
	<CAMk+s2T_QK1Lp89KEH1RofNXz5xC3iyb5mcMKqgSzOwE_n359Q@mail.gmail.com>
	<000301d28d7f$92244820$b66cd860$@bigpond.com>
	<CAMk+s2QEHaELBM7vx-iS6ubHC9hmF=xyG4c41j1CK6h7VQTD=w@mail.gmail.com>
Message-ID: <CAMk+s2SCX3Z192PZpKw_sS6iE=boUfN3JYiZEOFYCKsB5xLLBg@mail.gmail.com>

Dear all,
Duncan has provided a splendid example that works within lattice that
sorted the problem. For sake of argument I will report the updated script
with the solution (the optimum now would be to customize the label of the
outer strips); this new version requires latticeExtra and uses the
useOuterStrips function:

>>>
cluster <- c(rep("run_1", 45), rep("run_2", 45))
type <- rep(c("blank", "positive", "negative"),30)
target <- rep(c(rep("A", 3), rep("B", 3), rep("C", 3), rep("D", 3),
rep("E", 3)), 6)
value <- rep(c(rnorm(1, mean=0.001, sd=0.1), rnorm(1, mean=2, sd=1),
rnorm(1, mean=1, sd=1)),30)
my.data <- data.frame(cluster, type, target, value)

library(lattice)
library(latticeExtra)
useOuterStrips(
  strip = strip.custom(par.strip.text = list(cex = 0.75)),
  strip.left = strip.custom(par.strip.text = list(cex = 0.75)),
dotplot(
  value ~ type|target + cluster,
  my.data,
  groups = type,
  pch=21,
  main = "Luminex analysis MTb humans",
  xlab = "Target", ylab = "Reading",
  col = c("grey", "green", "red"),
  par.settings = list(strip.background = list(col="paleturquoise")),
  scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
  key = list(
    space = "top",
    columns = 3,
    text = list(c("Blank", "Negative", "Positive"), col="black"),
    rectangles = list(col=c("grey", "green", "red"))
  )
)
)

<<<
also, the answer provided by Paul does the job all right, but uses the
package grid instead of lattice. The stripless package (Bert Gunter's
suggestion) might be another approach but again require to study the code
in detail.
Thank you all very much indeed for  your support,
Luigi

On Thu, Feb 23, 2017 at 9:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Dear Duncan and Philip,
> thank you for your answers. maybe the toy data I gave it is a bit too
> easy, so I am attaching a new dataset with 5 targets. As you can see from
> it, now there are 5 panel strips with the label "run_1" and 5 with the
> label "run_2". What I would like to do is to merge those with the same
> label so to have only two labels "run_1" and "run_2".
> the examples from Duncan contains plenty of keys but I think make the
> reading of the plot more difficult; most of the plots have only one strip.
> thank you
> luigi
>
> >>>
> # the values are actually repeated, but they are just for example
> cluster <- c(rep("run_1", 45), rep("run_2", 45))
> type <- rep(c("blank", "positive", "negative"),30)
> target <- rep(c(rep("A", 3), rep("B", 3), rep("C", 3), rep("D", 3),
> rep("E", 3)), 6)
> value <- rep(c(rnorm(1, mean=0.001, sd=0.1), rnorm(1, mean=2, sd=1),
> rnorm(1, mean=1, sd=1)),30)
> my.data <- data.frame(cluster, type, target, value)
>
> library(lattice)
> dotplot(
>   value ~ type|target + cluster,
>   my.data,
>   groups = type,
>   pch=21,
>   main = "Luminex analysis MTb humans",
>   xlab = "Target", ylab = "Reading",
>   col = c("grey", "green", "red"),
>   par.settings = list(strip.background = list(col="paleturquoise")),
>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>   key = list(
>     space = "top",
>     columns = 3,
>     text = list(c("Blank", "Negative", "Positive"), col="black"),
>     rectangles = list(col=c("grey", "green", "red"))
>   )
> )
>
>
> On Thu, Feb 23, 2017 at 2:50 AM, Duncan Mackay <dulcalma at bigpond.com>
> wrote:
>
>> Hi Liugi
>>
>> Here are some ideas quickly
>>
>> 4 panels diagonals are blank
>>
>> mdata = my.data
>> mdata$ct <- paste(target, "Run", rep(1:2, each = 6))
>> mdata$typeT <- paste(mdata$target,mdata$type)
>>
>> dotplot(
>>   value ~ type|ct,
>>   mdata2,
>>   groups = typeT,
>>   par.settings = list(strip.background = list(col="paleturquoise"),
>>                       superpose.symbol = list(col = c(2:4),
>>                                               pch = rep(c(1,20),each =
>> 3))),
>> # type
>>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>   main = "Luminex analysis MTb humans",
>>   xlab = "Target",
>>   ylab = "Reading",
>>   auto.key = T,
>>   panel = panel.superpose
>> )
>>
>> # for when the 4 panels have plots not 2 as now
>>  mdata2 = mdata
>>  mdata2$target = rep(LETTERS[2:1], ea=6)
>>  mdata2$value= mdata2$value+0.1
>>  mdata2 <- rbind(mdata,mdata2)
>>
>> mdata2$typeT <- paste(mdata2$target,mdata2$type)
>>
>>  dotplot(
>>    value ~ type|target + cluster,
>>    mdata2,
>>    groups = typeT,
>>    par.settings = list(strip.background = list(col="paleturquoise"),
>>                        superpose.symbol = list(col = c(2:4),
>>                                                pch = rep(c(1,20),each =
>> 3))), # type
>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>    main = "Luminex analysis MTb humans",
>>    xlab = "Target",
>>    ylab = "Reading",
>>    auto.key = T,
>>    panel = panel.superpose
>>  )
>>
>>
>>  dotplot(
>>    value ~ type|ct,
>>    mdata2,
>>    groups = typeT,
>>    par.settings = list(strip.background = list(col="paleturquoise"),
>>                        superpose.symbol = list(col = c(2:4),
>>                                                pch = rep(c(1,20),each =
>> 3))), # type
>>    scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>    main = "Luminex analysis MTb humans",
>>    strip    = strip.custom(factor.levels = paste("Run",1:2),
>>                         par.strip.text = list(cex = 1) ),
>>    xlab = "Target",
>>    ylab = "Reading",
>>    auto.key = T,
>>    panel = panel.superpose
>>  )
>>
>> dotplot(
>>   value ~ type|cluster,
>>   mdata2,
>>   groups = typeT,
>>   par.settings = list(strip.background = list(col="paleturquoise"),
>>                       superpose.symbol = list(col = c(2:4),
>>                                               pch = rep(c(1,20),each =
>> 3))),
>> # type
>>   scales = list(alternating = FALSE, x = list(labels = c("", "", ""))),
>>   main = "Luminex analysis MTb humans",
>>   xlab = "Target",
>>   ylab = "Reading",
>>   auto.key = T,
>>   panel = panel.superpose
>> )
>>
>>
>> Regards
>>
>> Duncan
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
>> Marongiu
>> Sent: Wednesday, 22 February 2017 21:26
>> To: P Tennant; r-help
>> Subject: Re: [R] single strip for the same group in dotplot lattice
>>
>> Dear Philip,
>> the data is indeed a toy data: the real one will have 15 panels (=targets)
>> and two or three clusters. this means that I will have 15 strips with the
>> label "run 1" = "cluster 1" etc. the point of the toy data is that I get a
>> 4x4 panel plot with 8 strips labelled "run 1", "run 2", "A" and "B". What
>> I
>> am looking for is to collapse the strips so to get only one label "run 1"
>> and only one with "run 2" in order to simplify the plot. Hope this helps.
>> Thanks
>> Luigi
>>
>> On Wed, Feb 22, 2017 at 9:53 AM, P Tennant <philipt900 at iinet.net.au>
>> wrote:
>>
>> > Hi Luigi,
>> >
>> > I'm afraid I don't understand your toy data as you've described it, but
>> if
>> > you really don't have run 2 for target A, and don't have run 1 for
>> target
>> > B, why not just create another factor that reflects this, and plot that?
>> >
>> >  my.data$clus2 <- with(my.data, interaction(cluster, target))
>> >
>> >  and call: dotplot(value ~ type| clus2, ... )
>> >
>> >
>> > Philip
>> >
>> >
>> > On 22/02/2017 8:03 PM, Luigi Marongiu wrote:
>> >
>> >> dear all,
>> >> I have a set of data that is subdivided in cluster (run 1/run 2) and in
>> >> target (A/B). When plotting, I obtain a panel strip with "run 1" and
>> "run
>> >> 2" for each "A" and "B" panel, so "run 1" appears twice and so does
>> "run
>> >> 2". It is possible to merge the strip together so that I will have "run
>> 1"
>> >> or "run 2" only once? this will reduce the complexity of the data and
>> >> allow
>> >> more space for more detailed information in the strip.
>> >> the data follows,
>> >> thank you
>> >> L
>> >>
>> >> cluster<- c(rep("run_1", 6), rep("run_2", 6))
>> >> type<- rep(c("blank", "positive", "negative"),2)
>> >> target<- c(rep("A", 6), rep("B", 6))
>> >> value<- c(0.01, 1.1, 0.5,
>> >>             0.02, 1.6, 0.8,
>> >>             0.07, 1.4, 0.7,
>> >>             0.03, 1.4, 0.4)
>> >> my.data<- data.frame(cluster, type, target, value)
>> >>
>> >> library(lattice)
>> >> dotplot(
>> >>    value ~ type|target + cluster,
>> >>    my.data,
>> >>    groups = type,
>> >>    pch=21,
>> >>    main = "Luminex analysis MTb humans",
>> >>    xlab = "Target", ylab = "Reading",
>> >>    col = c("grey", "green", "red"),
>> >>    par.settings = list(strip.background = list(col="paleturquoise")),
>> >>    scales = list(alternating = FALSE, x = list(labels = c("", "",
>> ""))),
>> >>    key = list(
>> >>      space = "top",
>> >>      columns = 3,
>> >>      text = list(c("Blank", "Negative", "Positive"), col="black"),
>> >>      rectangles = list(col=c("grey", "green", "red"))
>> >>    )
>> >> )
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posti
>> >> ng-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Fri Feb 24 10:27:59 2017
From: tr206 at kent.ac.uk (T.Riedle)
Date: Fri, 24 Feb 2017 09:27:59 +0000
Subject: [R] vars package - irf() does not work
In-Reply-To: <20170223164648.247642fd@draco>
References: <1487594810802.89921@kent.ac.uk>
	<1487757420140.51553@kent.ac.uk>,<20170223164648.247642fd@draco>
Message-ID: <1487928479810.5002@kent.ac.uk>

The code is written in a script and I use Rstudio. The script stops when the irf() command should be executed returning the error mentioned below. I tried to writte an independent script just for the irf() function but it does not work either with the same error.

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of John Dougherty <jwd at surewest.net>
Sent: 24 February 2017 00:46
To: r-help at r-project.org
Subject: Re: [R] vars package - irf() does not work

On Wed, 22 Feb 2017 09:57:00 +0000
"T.Riedle" <tr206 at kent.ac.uk> wrote:

> Dear all,
>
> I have not received any response on this email. Is there anybody who
> can help me?
>
> I want to run an impulse response analysis using the vars() package.
> The code looks as follwows.
>
>
> # list of class varest
> varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type =
> "both")
>
> varest.USA
>
> summary(varest.USA)
>
>
>
> #Run irf analysis
> irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE,
> ci=0.95)
>
> plot(irf.USAg)
>
>
> The problem is that R returns an error that the arguments in irf are
> unused. That is, unused arguments (response="g", n.ahead = 48, boot =
> TRUE, ci=0.95) The strangeness is that it sometimes works but most of
> the time it does not. I installed vars() last month and irf() worked
> well but now it does only occasionally. I have just edited the data
> but kept the code unchanged.
>
>
> In addition, I have the same problem when I am trying to replicate
> the example on irf() in the vars vignette althoug it also worked well
> when I installed vars and run the example.
>
>
> Does anybody have an idea what is wrong?
>
Two guesses are 1) you are not consistently entering the commands and
thus get variable outcomes, and 2) possibly there are "depends" that
irf() needs that need to updated.  You could also contact the package
creators.  I would also observe that this looks remarkably like you
might be asking for help on your homework.

I would create a script of the commands you use as they work, each
entered in sequence as you used it. You use it essentially as a lab
notebook that documents procedures.  RStudio works well for this, since
you can copy each line that works from the Console to a script file in
the editor.  You can do the same with a text editor, while using R from
a console, but it is somewhat more clumsy.


--

John

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Feb 24 10:57:04 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 24 Feb 2017 10:57:04 +0100
Subject: [R] vars package - irf() does not work
In-Reply-To: <1487928479810.5002@kent.ac.uk>
References: <1487594810802.89921@kent.ac.uk> <1487757420140.51553@kent.ac.uk>
	<20170223164648.247642fd@draco> <1487928479810.5002@kent.ac.uk>
Message-ID: <8F972987-233B-40C2-ACA4-D12AC26EF14C@gmail.com>

So did you check that you have only one irf() function around?  

Try findFunction("irf")

-pd

> On 24 Feb 2017, at 10:27 , T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> The code is written in a script and I use Rstudio. The script stops when the irf() command should be executed returning the error mentioned below. I tried to writte an independent script just for the irf() function but it does not work either with the same error.
> 
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of John Dougherty <jwd at surewest.net>
> Sent: 24 February 2017 00:46
> To: r-help at r-project.org
> Subject: Re: [R] vars package - irf() does not work
> 
> On Wed, 22 Feb 2017 09:57:00 +0000
> "T.Riedle" <tr206 at kent.ac.uk> wrote:
> 
>> Dear all,
>> 
>> I have not received any response on this email. Is there anybody who
>> can help me?
>> 
>> I want to run an impulse response analysis using the vars() package.
>> The code looks as follwows.
>> 
>> 
>> # list of class varest
>> varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type =
>> "both")
>> 
>> varest.USA
>> 
>> summary(varest.USA)
>> 
>> 
>> 
>> #Run irf analysis
>> irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE,
>> ci=0.95)
>> 
>> plot(irf.USAg)
>> 
>> 
>> The problem is that R returns an error that the arguments in irf are
>> unused. That is, unused arguments (response="g", n.ahead = 48, boot =
>> TRUE, ci=0.95) The strangeness is that it sometimes works but most of
>> the time it does not. I installed vars() last month and irf() worked
>> well but now it does only occasionally. I have just edited the data
>> but kept the code unchanged.
>> 
>> 
>> In addition, I have the same problem when I am trying to replicate
>> the example on irf() in the vars vignette althoug it also worked well
>> when I installed vars and run the example.
>> 
>> 
>> Does anybody have an idea what is wrong?
>> 
> Two guesses are 1) you are not consistently entering the commands and
> thus get variable outcomes, and 2) possibly there are "depends" that
> irf() needs that need to updated.  You could also contact the package
> creators.  I would also observe that this looks remarkably like you
> might be asking for help on your homework.
> 
> I would create a script of the commands you use as they work, each
> entered in sequence as you used it. You use it essentially as a lab
> notebook that documents procedures.  RStudio works well for this, since
> you can copy each line that works from the Console to a script file in
> the editor.  You can do the same with a text editor, while using R from
> a console, but it is somewhat more clumsy.
> 
> 
> --
> 
> John
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Fri Feb 24 11:42:30 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 24 Feb 2017 10:42:30 +0000
Subject: [R] vars package - irf() does not work
In-Reply-To: <1487928479810.5002@kent.ac.uk>
References: <1487594810802.89921@kent.ac.uk>
	<1487757420140.51553@kent.ac.uk>,<20170223164648.247642fd@draco>
	<1487928479810.5002@kent.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A17A89@SRVEXCHCM301.precheza.cz>

Hi

so

var.2c <- VAR(Canada, p = 2, type = "const")
irf(var.2c, impulse = "e", response = c("prod", "rw", "U"), boot = FALSE)

works only sometimes? Or it does not work with **your** data only?

If it is the later, the issue is probably in your data. You should look at them to see if

str(yourdata)

does not show some problems.

Cheers
Petr



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of T.Riedle
> Sent: Friday, February 24, 2017 10:28 AM
> To: John Dougherty <jwd at surewest.net>; r-help at r-project.org
> Subject: Re: [R] vars package - irf() does not work
>
> The code is written in a script and I use Rstudio. The script stops when the
> irf() command should be executed returning the error mentioned below. I
> tried to writte an independent script just for the irf() function but it does not
> work either with the same error.
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of John Dougherty
> <jwd at surewest.net>
> Sent: 24 February 2017 00:46
> To: r-help at r-project.org
> Subject: Re: [R] vars package - irf() does not work
>
> On Wed, 22 Feb 2017 09:57:00 +0000
> "T.Riedle" <tr206 at kent.ac.uk> wrote:
>
> > Dear all,
> >
> > I have not received any response on this email. Is there anybody who
> > can help me?
> >
> > I want to run an impulse response analysis using the vars() package.
> > The code looks as follwows.
> >
> >
> > # list of class varest
> > varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type =
> > "both")
> >
> > varest.USA
> >
> > summary(varest.USA)
> >
> >
> >
> > #Run irf analysis
> > irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE,
> > ci=0.95)
> >
> > plot(irf.USAg)
> >
> >
> > The problem is that R returns an error that the arguments in irf are
> > unused. That is, unused arguments (response="g", n.ahead = 48, boot =
> > TRUE, ci=0.95) The strangeness is that it sometimes works but most of
> > the time it does not. I installed vars() last month and irf() worked
> > well but now it does only occasionally. I have just edited the data
> > but kept the code unchanged.
> >
> >
> > In addition, I have the same problem when I am trying to replicate the
> > example on irf() in the vars vignette althoug it also worked well when
> > I installed vars and run the example.
> >
> >
> > Does anybody have an idea what is wrong?
> >
> Two guesses are 1) you are not consistently entering the commands and thus
> get variable outcomes, and 2) possibly there are "depends" that
> irf() needs that need to updated.  You could also contact the package
> creators.  I would also observe that this looks remarkably like you might be
> asking for help on your homework.
>
> I would create a script of the commands you use as they work, each entered
> in sequence as you used it. You use it essentially as a lab notebook that
> documents procedures.  RStudio works well for this, since you can copy each
> line that works from the Console to a script file in the editor.  You can do the
> same with a text editor, while using R from a console, but it is somewhat
> more clumsy.
>
>
> --
>
> John
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From mikko.korpela at helsinki.fi  Fri Feb 24 15:57:54 2017
From: mikko.korpela at helsinki.fi (Mikko Korpela)
Date: Fri, 24 Feb 2017 16:57:54 +0200
Subject: [R] nchar(type = "chars") of "latin1" string in C locale
Message-ID: <151b836c-3338-0cf5-c5ef-fd1651beb8c1@helsinki.fi>

When running R in an ASCII locale (export LC_ALL=C) on Linux, is this 
expected?

foo <- "\xe4"
Encoding(foo) <- "latin1"
foo
# [1] "<e4>"
nchar(foo)
# [1] 4
nchar(foo, type = "bytes")
# [1] 1
nchar(foo, type = "width")
# [1] 4

That is, the number of characters reported for the default 'type = 
"chars"' is the number of characters (4) used for printing the unknown byte.

Obviously, one byte is one character in the single-byte ISO-8859-1 
"latin1" encoding. Therefore I think the result of 4 characters for 1 
byte is wrong, or unintuitive.

If this is as expected, maybe it should be mentioned in the '?nchar' 
manual as a special case. Yes, I did try to read the manual for an 
explanation. According to the manual, the result should be "The number 
of human-readable characters", but there is the note that:

      This does *not* by default give the number of characters that will
      be used to 'print()' the string.  Use 'encodeString' to find that.

For UTF-8 strings, nchar() does work correctly (as documented) even in 
the C locale.

foo2 <- "\xc3\xa4"
Encoding(foo2) <- "UTF-8"
foo2
# [1] "<U+00E4>"
nchar(foo2)
# [1] 1
nchar(foo2, type = "bytes")
# [1] 2
nchar(foo2, type = "width")
# [1] 1

But, confusingly, encodeString() does not agree with print(), contrary 
to the document '?encodeString':

encodeString(foo2)
# [1] "\\u00e4"

I was using "R Under development (unstable) (2017-02-23 r72248)".

-- 
Mikko Korpela
Department of Geosciences and Geography
University of Helsinki


From dcarlson at tamu.edu  Fri Feb 24 16:40:54 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 24 Feb 2017 15:40:54 +0000
Subject: [R] Help with data management
In-Reply-To: <CA+8X3fUG7QcG=cKkgL8wRWEP5_EEzLOEZ4bUa+9QyPpbG-Yz=Q@mail.gmail.com>
References: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>
	<CA+8X3fWBNX-QA+LPQXsP6XqV0r9zftGUDVNZmFo0hgGYkNBbkg@mail.gmail.com>
	<CAHxKz8b7YdUURm-9=5a1kr9Am8RWwVWyttoRjRNZC-+t1J3cvQ@mail.gmail.com>
	<CA+8X3fUG7QcG=cKkgL8wRWEP5_EEzLOEZ4bUa+9QyPpbG-Yz=Q@mail.gmail.com>
Message-ID: <5baf99a5b3f140e39e1d737fe853ad9e@exch-2p-mbx-w2.ads.tamu.edu>

You can also combine the data frames into a single one and use xtabs:

ID <- names(mylist)
mylist <- Map(data.frame, mylist, dfn=ID)
mydf <- do.call(rbind, mylist)
mydf$Family <- factor(mydf$Family, levels=sort(levels(mydf$Family)))
xtabs(Hits~Family+dfn, mydf)
#       dfn
# Family  A  B  C
#      a  0  3  0
#      c  1  1  0
#      d  2  0  0
#      e  3  0  0
#      f  0  4  5
#      o  0  0  4
#      q  0  0 10


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Thursday, February 23, 2017 6:00 PM
To: Andr? Luis Neves <andrluis at ualberta.ca>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Help with data management

Hi Andre,
As far as I am aware, merges can only be accomplished between two data
frames, so I think you would have to do it one by one. It is probably
possible to program this to operate on your list of data frames, but I
suspect that it would take as much time as a bit of copying and
pasting. If your data is being extracted from an external database, it
may be possible to perform the operation in SQL, I don't have the time
to work that out at the moment.

Jim


On Fri, Feb 24, 2017 at 10:53 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Hi, Jim:
>
> Your code worked great, but I have 48 dataframes. After merging A and B in
> D, you merged C in D. In this case, do I need to add them one by one until
> getting the 48 dataframes merged in one?
>
> Thank you for your great help.
>
> Andre
>
> On Thu, Feb 23, 2017 at 4:24 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Andre,
>> This might do it:
>>
>> A<-data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
>> colnames(A) <- c ("Family", "NormalizedCount", "Hits")
>> B<-data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
>> colnames(B) <- c ("Family", "NormalizedCount", "Hits")
>> C<-data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
>> colnames(C) <- c ("Family", "NormalizedCount", "Hits")
>> keepcols<-c("Family","Hits")
>> D<-merge(A[,keepcols],B[,keepcols],by="Family",all=TRUE)
>> D<-merge(D,C[,keepcols],by="Family",all=TRUE)
>> D[,2:4]<-sapply(D[,-1],function(x) { x[is.na(x)]<-0; x })
>> names(D)<-c("Family","A","B","C")
>>
>> Jim
>>
>>
>> On Fri, Feb 24, 2017 at 9:37 AM, Andr? Luis Neves <andrluis at ualberta.ca>
>> wrote:
>> > Dear R users,
>> >
>> > I have the following dataframes (A, B, and C) stored in a list:
>> >
>> > A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
>> > colnames(A) <- c ("Family", "NormalizedCount", "Hits")
>> > A
>> >
>> >
>> > B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
>> > colnames(B) <- c ("Family", "NormalizedCount", "Hits")
>> > B
>> >
>> >
>> > C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
>> > colnames(C) <- c ("Family", "NormalizedCount", "Hits")
>> > C
>> >
>> > mylist <- list(A=A,B=B,C=C)
>> > mylist
>> >
>> >
>> > My idea is to merge the three dataframes into another dataframe (let's
>> > name
>> > it: 'D')  with a structure in which the rows are the Families and
>> > columns
>> > the "Hits" of each family detected in the dataframes A, B, and C. If a
>> > given 'Family' does NOT have a 'Hit' in the dataframe we need to assign
>> > number 0 to it.
>> >
>> > The dataframe 'D' would need to be populated as follows:
>> >
>> >
>> > Family                                                      A
>> >        B                                      C
>> > c 1 1 0
>> > d 2 0 0
>> > e 3 0 0
>> > f 0 4 5
>> > a 0 3 0
>> > q 0 0 10
>> > o 0 0 4
>> >
>> >
>> > Thank you very much for your great help,
>> >
>> >
>> >
>> > --
>> > Andre
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Andre

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From andrluis at ualberta.ca  Fri Feb 24 17:13:50 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Fri, 24 Feb 2017 09:13:50 -0700
Subject: [R] Help with data management
In-Reply-To: <5baf99a5b3f140e39e1d737fe853ad9e@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>
	<CA+8X3fWBNX-QA+LPQXsP6XqV0r9zftGUDVNZmFo0hgGYkNBbkg@mail.gmail.com>
	<CAHxKz8b7YdUURm-9=5a1kr9Am8RWwVWyttoRjRNZC-+t1J3cvQ@mail.gmail.com>
	<CA+8X3fUG7QcG=cKkgL8wRWEP5_EEzLOEZ4bUa+9QyPpbG-Yz=Q@mail.gmail.com>
	<5baf99a5b3f140e39e1d737fe853ad9e@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAHxKz8agCQbWeKYJSPqP=BjEYUKX4T5wkXV3Xn6Jm1XP5BJrqg@mail.gmail.com>

Hi, David:

Thank you so much for your answer.

I just added some commands and got what I wanted.

The final command would be something like this:


A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
colnames(A) <- c ("Family", "NormalizedCount", "Hits")
A
B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
colnames(B) <- c ("Family", "NormalizedCount", "Hits")
B
C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
colnames(C) <- c ("Family", "NormalizedCount", "Hits")
C
mylist <- list(A=A,B=B,C=C)
mylist
ID <- names(mylist)
mylist <- Map(data.frame, mylist, dfn=ID)
mydf <- do.call(rbind, mylist)
mydf$Family <- factor(mydf$Family, levels=sort(levels(mydf$Family)))
z <- xtabs(Hits~Family+dfn, mydf)
x <- as.data.frame(z)
x
library(reshape2)
y <- dcast(x, Family ~ dfn, value.var = "Freq")
y


Thank you very much.

Andre


On Fri, Feb 24, 2017 at 8:40 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> You can also combine the data frames into a single one and use xtabs:
>
> ID <- names(mylist)
> mylist <- Map(data.frame, mylist, dfn=ID)
> mydf <- do.call(rbind, mylist)
> mydf$Family <- factor(mydf$Family, levels=sort(levels(mydf$Family)))
> xtabs(Hits~Family+dfn, mydf)
> #       dfn
> # Family  A  B  C
> #      a  0  3  0
> #      c  1  1  0
> #      d  2  0  0
> #      e  3  0  0
> #      f  0  4  5
> #      o  0  0  4
> #      q  0  0 10
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Thursday, February 23, 2017 6:00 PM
> To: Andr? Luis Neves <andrluis at ualberta.ca>; r-help mailing list <
> r-help at r-project.org>
> Subject: Re: [R] Help with data management
>
> Hi Andre,
> As far as I am aware, merges can only be accomplished between two data
> frames, so I think you would have to do it one by one. It is probably
> possible to program this to operate on your list of data frames, but I
> suspect that it would take as much time as a bit of copying and
> pasting. If your data is being extracted from an external database, it
> may be possible to perform the operation in SQL, I don't have the time
> to work that out at the moment.
>
> Jim
>
>
> On Fri, Feb 24, 2017 at 10:53 AM, Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
> > Hi, Jim:
> >
> > Your code worked great, but I have 48 dataframes. After merging A and B
> in
> > D, you merged C in D. In this case, do I need to add them one by one
> until
> > getting the 48 dataframes merged in one?
> >
> > Thank you for your great help.
> >
> > Andre
> >
> > On Thu, Feb 23, 2017 at 4:24 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Andre,
> >> This might do it:
> >>
> >> A<-data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
> >> colnames(A) <- c ("Family", "NormalizedCount", "Hits")
> >> B<-data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
> >> colnames(B) <- c ("Family", "NormalizedCount", "Hits")
> >> C<-data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
> >> colnames(C) <- c ("Family", "NormalizedCount", "Hits")
> >> keepcols<-c("Family","Hits")
> >> D<-merge(A[,keepcols],B[,keepcols],by="Family",all=TRUE)
> >> D<-merge(D,C[,keepcols],by="Family",all=TRUE)
> >> D[,2:4]<-sapply(D[,-1],function(x) { x[is.na(x)]<-0; x })
> >> names(D)<-c("Family","A","B","C")
> >>
> >> Jim
> >>
> >>
> >> On Fri, Feb 24, 2017 at 9:37 AM, Andr? Luis Neves <andrluis at ualberta.ca
> >
> >> wrote:
> >> > Dear R users,
> >> >
> >> > I have the following dataframes (A, B, and C) stored in a list:
> >> >
> >> > A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
> >> > colnames(A) <- c ("Family", "NormalizedCount", "Hits")
> >> > A
> >> >
> >> >
> >> > B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
> >> > colnames(B) <- c ("Family", "NormalizedCount", "Hits")
> >> > B
> >> >
> >> >
> >> > C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
> >> > colnames(C) <- c ("Family", "NormalizedCount", "Hits")
> >> > C
> >> >
> >> > mylist <- list(A=A,B=B,C=C)
> >> > mylist
> >> >
> >> >
> >> > My idea is to merge the three dataframes into another dataframe (let's
> >> > name
> >> > it: 'D')  with a structure in which the rows are the Families and
> >> > columns
> >> > the "Hits" of each family detected in the dataframes A, B, and C. If a
> >> > given 'Family' does NOT have a 'Hit' in the dataframe we need to
> assign
> >> > number 0 to it.
> >> >
> >> > The dataframe 'D' would need to be populated as follows:
> >> >
> >> >
> >> > Family                                                      A
> >> >        B                                      C
> >> > c 1 1 0
> >> > d 2 0 0
> >> > e 3 0 0
> >> > f 0 4 5
> >> > a 0 3 0
> >> > q 0 0 10
> >> > o 0 0 4
> >> >
> >> >
> >> > Thank you very much for your great help,
> >> >
> >> >
> >> >
> >> > --
> >> > Andre
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Andre
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Andre

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Feb 24 19:00:51 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 24 Feb 2017 18:00:51 +0000
Subject: [R] Help with data management
In-Reply-To: <CAHxKz8agCQbWeKYJSPqP=BjEYUKX4T5wkXV3Xn6Jm1XP5BJrqg@mail.gmail.com>
References: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>
	<CA+8X3fWBNX-QA+LPQXsP6XqV0r9zftGUDVNZmFo0hgGYkNBbkg@mail.gmail.com>
	<CAHxKz8b7YdUURm-9=5a1kr9Am8RWwVWyttoRjRNZC-+t1J3cvQ@mail.gmail.com>
	<CA+8X3fUG7QcG=cKkgL8wRWEP5_EEzLOEZ4bUa+9QyPpbG-Yz=Q@mail.gmail.com>
	<5baf99a5b3f140e39e1d737fe853ad9e@exch-2p-mbx-w2.ads.tamu.edu>
	<CAHxKz8agCQbWeKYJSPqP=BjEYUKX4T5wkXV3Xn6Jm1XP5BJrqg@mail.gmail.com>
Message-ID: <1000803f03354a7883ac887a61b379c8@exch-2p-mbx-w2.ads.tamu.edu>

You can also get there without reshape2:

z <- xtabs(Hits~Family+dfn, mydf)
x <- as.data.frame.matrix(z) # Convert the table without changing the format
y <- data.frame(Family=dimnames(z)$Family, as.data.frame.matrix(z)) # Add Family column
rownames(y) <- NULL # Optional, but it replaces the rownames numbers
str(y)
# data.frame':   7 obs. of  4 variables:
#  $ Family: Factor w/ 7 levels "a","c","d","e",..: 1 2 3 4 5 6 7
#  $ A     : num  0 1 2 3 0 0 0
#  $ B     : num  3 1 0 0 4 0 0
#  $ C     : num  0 0 0 0 5 4 10

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



From: Andr? Luis Neves [mailto:andrluis at ualberta.ca] 
Sent: Friday, February 24, 2017 10:14 AM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Jim Lemon <drjimlemon at gmail.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Help with data management

Hi, David:

Thank you so much for your answer.

I just added some commands and got what I wanted.

The final command would be something like this:


A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
colnames(A) <- c ("Family", "NormalizedCount", "Hits")?
A?
B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))?
colnames(B) <- c ("Family", "NormalizedCount", "Hits")
B
C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))?
colnames(C) <- c ("Family", "NormalizedCount", "Hits")
C
mylist <- list(A=A,B=B,C=C)
mylist
ID <- names(mylist)
mylist <- Map(data.frame, mylist, dfn=ID)
mydf <- do.call(rbind, mylist)
mydf$Family <- factor(mydf$Family, levels=sort(levels(mydf$Family)))
z <- xtabs(Hits~Family+dfn, mydf)
x <- as.data.frame(z)
x
library(reshape2)
y <- dcast(x, Family ~ dfn, value.var = "Freq")
y


Thank you very much.

Andre


On Fri, Feb 24, 2017 at 8:40 AM, David L Carlson <dcarlson at tamu.edu> wrote:
You can also combine the data frames into a single one and use xtabs:

ID <- names(mylist)
mylist <- Map(data.frame, mylist, dfn=ID)
mydf <- do.call(rbind, mylist)
mydf$Family <- factor(mydf$Family, levels=sort(levels(mydf$Family)))
xtabs(Hits~Family+dfn, mydf)
#? ? ? ?dfn
# Family? A? B? C
#? ? ? a? 0? 3? 0
#? ? ? c? 1? 1? 0
#? ? ? d? 2? 0? 0
#? ? ? e? 3? 0? 0
#? ? ? f? 0? 4? 5
#? ? ? o? 0? 0? 4
#? ? ? q? 0? 0 10


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Thursday, February 23, 2017 6:00 PM
To: Andr? Luis Neves <andrluis at ualberta.ca>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Help with data management

Hi Andre,
As far as I am aware, merges can only be accomplished between two data
frames, so I think you would have to do it one by one. It is probably
possible to program this to operate on your list of data frames, but I
suspect that it would take as much time as a bit of copying and
pasting. If your data is being extracted from an external database, it
may be possible to perform the operation in SQL, I don't have the time
to work that out at the moment.

Jim


On Fri, Feb 24, 2017 at 10:53 AM, Andr? Luis Neves <andrluis at ualberta.ca> wrote:
> Hi, Jim:
>
> Your code worked great, but I have 48 dataframes. After merging A and B in
> D, you merged C in D. In this case, do I need to add them one by one until
> getting the 48 dataframes merged in one?
>
> Thank you for your great help.
>
> Andre
>
> On Thu, Feb 23, 2017 at 4:24 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Andre,
>> This might do it:
>>
>> A<-data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
>> colnames(A) <- c ("Family", "NormalizedCount", "Hits")
>> B<-data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
>> colnames(B) <- c ("Family", "NormalizedCount", "Hits")
>> C<-data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
>> colnames(C) <- c ("Family", "NormalizedCount", "Hits")
>> keepcols<-c("Family","Hits")
>> D<-merge(A[,keepcols],B[,keepcols],by="Family",all=TRUE)
>> D<-merge(D,C[,keepcols],by="Family",all=TRUE)
>> D[,2:4]<-sapply(D[,-1],function(x) { x[is.na(x)]<-0; x })
>> names(D)<-c("Family","A","B","C")
>>
>> Jim
>>
>>
>> On Fri, Feb 24, 2017 at 9:37 AM, Andr? Luis Neves <andrluis at ualberta.ca>
>> wrote:
>> > Dear R users,
>> >
>> > I have the following dataframes (A, B, and C) stored in a list:
>> >
>> > A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
>> > colnames(A) <- c ("Family", "NormalizedCount", "Hits")
>> > A
>> >
>> >
>> > B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
>> > colnames(B) <- c ("Family", "NormalizedCount", "Hits")
>> > B
>> >
>> >
>> > C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
>> > colnames(C) <- c ("Family", "NormalizedCount", "Hits")
>> > C
>> >
>> > mylist <- list(A=A,B=B,C=C)
>> > mylist
>> >
>> >
>> > My idea is to merge the three dataframes into another dataframe (let's
>> > name
>> > it: 'D')? with a structure in which the rows are the Families and
>> > columns
>> > the "Hits" of each family detected in the dataframes A, B, and C. If a
>> > given 'Family' does NOT have a 'Hit' in the dataframe we need to assign
>> > number 0 to it.
>> >
>> > The dataframe 'D' would need to be populated as follows:
>> >
>> >
>> > Family? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? A
>> >? ? ? ? B? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? C
>> > c 1 1 0
>> > d 2 0 0
>> > e 3 0 0
>> > f 0 4 5
>> > a 0 3 0
>> > q 0 0 10
>> > o 0 0 4
>> >
>> >
>> > Thank you very much for your great help,
>> >
>> >
>> >
>> > --
>> > Andre
>> >
>> >? ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Andre

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




-- 
Andre

From andrluis at ualberta.ca  Fri Feb 24 19:10:10 2017
From: andrluis at ualberta.ca (=?UTF-8?Q?Andr=C3=A9_Luis_Neves?=)
Date: Fri, 24 Feb 2017 11:10:10 -0700
Subject: [R] Help with data management
In-Reply-To: <1000803f03354a7883ac887a61b379c8@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAHxKz8avpERU=MDyEJq3nrb=m=vHL3WzVc0SuvCFqbyVtiPyxQ@mail.gmail.com>
	<CA+8X3fWBNX-QA+LPQXsP6XqV0r9zftGUDVNZmFo0hgGYkNBbkg@mail.gmail.com>
	<CAHxKz8b7YdUURm-9=5a1kr9Am8RWwVWyttoRjRNZC-+t1J3cvQ@mail.gmail.com>
	<CA+8X3fUG7QcG=cKkgL8wRWEP5_EEzLOEZ4bUa+9QyPpbG-Yz=Q@mail.gmail.com>
	<5baf99a5b3f140e39e1d737fe853ad9e@exch-2p-mbx-w2.ads.tamu.edu>
	<CAHxKz8agCQbWeKYJSPqP=BjEYUKX4T5wkXV3Xn6Jm1XP5BJrqg@mail.gmail.com>
	<1000803f03354a7883ac887a61b379c8@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAHxKz8ZSeA8X_+JTPgsmojOcAwm6=mQMfLbqFU=nopB9Bc5vyw@mail.gmail.com>

Thank you, David, for your help.

I'm so thankful for this R mailing list, and to all R community.

Andre


On Fri, Feb 24, 2017 at 11:00 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> You can also get there without reshape2:
>
> z <- xtabs(Hits~Family+dfn, mydf)
> x <- as.data.frame.matrix(z) # Convert the table without changing the
> format
> y <- data.frame(Family=dimnames(z)$Family, as.data.frame.matrix(z)) # Add
> Family column
> rownames(y) <- NULL # Optional, but it replaces the rownames numbers
> str(y)
> # data.frame':   7 obs. of  4 variables:
> #  $ Family: Factor w/ 7 levels "a","c","d","e",..: 1 2 3 4 5 6 7
> #  $ A     : num  0 1 2 3 0 0 0
> #  $ B     : num  3 1 0 0 4 0 0
> #  $ C     : num  0 0 0 0 5 4 10
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> From: Andr? Luis Neves [mailto:andrluis at ualberta.ca]
> Sent: Friday, February 24, 2017 10:14 AM
> To: David L Carlson <dcarlson at tamu.edu>
> Cc: Jim Lemon <drjimlemon at gmail.com>; r-help mailing list <
> r-help at r-project.org>
> Subject: Re: [R] Help with data management
>
> Hi, David:
>
> Thank you so much for your answer.
>
> I just added some commands and got what I wanted.
>
> The final command would be something like this:
>
>
> A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
> colnames(A) <- c ("Family", "NormalizedCount", "Hits")
> A
> B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
> colnames(B) <- c ("Family", "NormalizedCount", "Hits")
> B
> C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
> colnames(C) <- c ("Family", "NormalizedCount", "Hits")
> C
> mylist <- list(A=A,B=B,C=C)
> mylist
> ID <- names(mylist)
> mylist <- Map(data.frame, mylist, dfn=ID)
> mydf <- do.call(rbind, mylist)
> mydf$Family <- factor(mydf$Family, levels=sort(levels(mydf$Family)))
> z <- xtabs(Hits~Family+dfn, mydf)
> x <- as.data.frame(z)
> x
> library(reshape2)
> y <- dcast(x, Family ~ dfn, value.var = "Freq")
> y
>
>
> Thank you very much.
>
> Andre
>
>
> On Fri, Feb 24, 2017 at 8:40 AM, David L Carlson <dcarlson at tamu.edu>
> wrote:
> You can also combine the data frames into a single one and use xtabs:
>
> ID <- names(mylist)
> mylist <- Map(data.frame, mylist, dfn=ID)
> mydf <- do.call(rbind, mylist)
> mydf$Family <- factor(mydf$Family, levels=sort(levels(mydf$Family)))
> xtabs(Hits~Family+dfn, mydf)
> #       dfn
> # Family  A  B  C
> #      a  0  3  0
> #      c  1  1  0
> #      d  2  0  0
> #      e  3  0  0
> #      f  0  4  5
> #      o  0  0  4
> #      q  0  0 10
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Thursday, February 23, 2017 6:00 PM
> To: Andr? Luis Neves <andrluis at ualberta.ca>; r-help mailing list <
> r-help at r-project.org>
> Subject: Re: [R] Help with data management
>
> Hi Andre,
> As far as I am aware, merges can only be accomplished between two data
> frames, so I think you would have to do it one by one. It is probably
> possible to program this to operate on your list of data frames, but I
> suspect that it would take as much time as a bit of copying and
> pasting. If your data is being extracted from an external database, it
> may be possible to perform the operation in SQL, I don't have the time
> to work that out at the moment.
>
> Jim
>
>
> On Fri, Feb 24, 2017 at 10:53 AM, Andr? Luis Neves <andrluis at ualberta.ca>
> wrote:
> > Hi, Jim:
> >
> > Your code worked great, but I have 48 dataframes. After merging A and B
> in
> > D, you merged C in D. In this case, do I need to add them one by one
> until
> > getting the 48 dataframes merged in one?
> >
> > Thank you for your great help.
> >
> > Andre
> >
> > On Thu, Feb 23, 2017 at 4:24 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Andre,
> >> This might do it:
> >>
> >> A<-data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
> >> colnames(A) <- c ("Family", "NormalizedCount", "Hits")
> >> B<-data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
> >> colnames(B) <- c ("Family", "NormalizedCount", "Hits")
> >> C<-data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
> >> colnames(C) <- c ("Family", "NormalizedCount", "Hits")
> >> keepcols<-c("Family","Hits")
> >> D<-merge(A[,keepcols],B[,keepcols],by="Family",all=TRUE)
> >> D<-merge(D,C[,keepcols],by="Family",all=TRUE)
> >> D[,2:4]<-sapply(D[,-1],function(x) { x[is.na(x)]<-0; x })
> >> names(D)<-c("Family","A","B","C")
> >>
> >> Jim
> >>
> >>
> >> On Fri, Feb 24, 2017 at 9:37 AM, Andr? Luis Neves <andrluis at ualberta.ca
> >
> >> wrote:
> >> > Dear R users,
> >> >
> >> > I have the following dataframes (A, B, and C) stored in a list:
> >> >
> >> > A= data.frame(c("c", "d", "e"),4.4:6.8,c(1,2,3))
> >> > colnames(A) <- c ("Family", "NormalizedCount", "Hits")
> >> > A
> >> >
> >> >
> >> > B= data.frame(c("c", "f", "a"),c(3.2,6.4, 4.4), c(1,4,3))
> >> > colnames(B) <- c ("Family", "NormalizedCount", "Hits")
> >> > B
> >> >
> >> >
> >> > C= data.frame(c("q", "o", "f"),c(7.2,9.4, 41.4), c(10,4,5))
> >> > colnames(C) <- c ("Family", "NormalizedCount", "Hits")
> >> > C
> >> >
> >> > mylist <- list(A=A,B=B,C=C)
> >> > mylist
> >> >
> >> >
> >> > My idea is to merge the three dataframes into another dataframe (let's
> >> > name
> >> > it: 'D')  with a structure in which the rows are the Families and
> >> > columns
> >> > the "Hits" of each family detected in the dataframes A, B, and C. If a
> >> > given 'Family' does NOT have a 'Hit' in the dataframe we need to
> assign
> >> > number 0 to it.
> >> >
> >> > The dataframe 'D' would need to be populated as follows:
> >> >
> >> >
> >> > Family                                                      A
> >> >        B                                      C
> >> > c 1 1 0
> >> > d 2 0 0
> >> > e 3 0 0
> >> > f 0 4 5
> >> > a 0 3 0
> >> > q 0 0 10
> >> > o 0 0 4
> >> >
> >> >
> >> > Thank you very much for your great help,
> >> >
> >> >
> >> >
> >> > --
> >> > Andre
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Andre
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Andre
>



-- 
Andre

	[[alternative HTML version deleted]]


From bianca12_domi at hotmail.com  Thu Feb 23 21:26:40 2017
From: bianca12_domi at hotmail.com (Biank M)
Date: Thu, 23 Feb 2017 20:26:40 +0000
Subject: [R] Differences between SPSS and R on probit analysis
Message-ID: <CY4PR06MB3014AC99A5B7ED03B5F762319A530@CY4PR06MB3014.namprd06.prod.outlook.com>

Hi,

I'm working on the effects of alternative larvicides on Aedes aegypti. Right now, I am doing a binary mortality response with a single explanatory variable (dose) on 4 concentrations of one larvicide (+ control). Our university is fond of SPSS, and I have learned to conduct the basic probit model with it, including a natural logarithm transformation on my dosis data.
Not so long ago, I've started working with R, and through a combination of the 'glm' and 'dose.p' functions, I get the same slope and intercept, as well as LD50 calculations. Nevertheless, the standard errors and Z-scores calculated through the Probit model in SPSS comes out completely different in R. Additionally, the 95% confidence intervals for the LD50 come out very differently between the two programs. I really don't have a clue on how I am getting the same slopes, intercepts and LD50's, but totally different SE, Z, and 95% CI. Can anybody help me so I can get the same results in R??

I'll pass you the script and hypothetical data:

dose <- c(6000, 4500, 3000, 1500, 0)
total <- c(100, 100, 100, 100, 100)
affected <- c(91, 82, 69, 49, 0)

finney71 <- data.frame(dose, total, affected)

fm1 <- glm(affected/total ~ log(dose),
family=binomial(link = probit), data=finney71[finney71$dose != 0, ])

xp1 <- dose.p(fm1, p=c(0.5,0.9))
xp.ci <- xp1 + attr(xp1, "SE") %*% matrix(qnorm(1 - 0.05/2)*c(-1,1), nrow=1)
EAUS.Aa <- exp(cbind(xp1, attr(xp1, "SE"), xp.ci[,1], xp.ci[,2]))
dimnames(EAUS.Aa)[[2]] <- c("LD", "SE", "LCL","UCL")

So, this is the regression results I get with R:
summary(fm1)

Deviance Residuals:
1 2 3 4
0.06655 -0.02814 -0.06268 0.03474

Coefficients:
Estimate Std. Error z value
(Intercept) -6.8940 10.7802 -0.640
log(dose) 0.9333 1.3441 0.694
Pr(>|z|)
(Intercept) 0.522
log(dose) 0.487

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 0.513878 on 3 degrees of freedom
Residual deviance: 0.010356 on 2 degrees of freedom
AIC: 6.5458

Number of Fisher Scoring iterations: 5

And the LD50 and CI transformed:

print(EAUS.Aa)
LD SE LCL UCL
p = 0.5: 1614.444 3.207876 164.3822 15855.91
p = 0.9: 6373.473 3.764879 474.1600 85669.72

These are the values I get on SPSS (just replacing the values on R output) :

Coefficients:
Estimate Std. Error z value
(Intercept) -6.8940 1.082 -6.373
(dose) 2.149 0.311 6.918

And the LD50 and CI transformed:

LD LCL UCL
p = 0.5: 1614.444 1198.932 1953.120
p = 0.9: 6373.473 5145.767 9013.354

So, please if somebody can help me with this, I'd be grateful. If working with those functions won't do it, I'll use another, the one you recommend.

Thank you very much!


Best wishes,

Bianca



PD. I've already googled it but there's no satisfactory answer.



	[[alternative HTML version deleted]]


From helio.santana.1997 at gmail.com  Fri Feb 24 12:10:27 2017
From: helio.santana.1997 at gmail.com (Helio Santana)
Date: Fri, 24 Feb 2017 12:10:27 +0100
Subject: [R] Help with a specific quantile regression problem
Message-ID: <CALA=ByrS9PVaJErJmNNq7U3ULdpffeKQWA_o3_L6pU211wXDCQ@mail.gmail.com>

Dear R community,

I am a beginner in quantile regression and I have a question about a
specific problem. I have used the quantreg package to fit a QR with
inequality constrains:

n <- 100
p <- 5
X <- matrix(rnorm(n*p),n,p)
y <- 0.95*apply(X,1,sum)+rnorm(n)
R <- cbind(0,rbind(diag(p),-diag(p)))
r <- c(rep(0,p),-rep(1,p))
model <- rq(y~X,R=R,r=r,method="fnc")

So,

> quantile(model$residuals,0.5)
> -6.68836e-11 (It should be close to 0)


However, if I try to impose no intercept in the last problem:

R <- cbind(0,rbind(diag(p),-diag(p)))
R <- R[,2:dim(R)[2]]
r <- c(rep(0,p),-rep(1,p))
model <- rq(y~X-1,R=R,r=r,method="fnc")

I obtain:

> quantile(model$residuals,0.5)
> -0.03465427

As you can see, this quantile value is not close to 0 as I expected. Have I
an error in the formulation of the QR?

Is it possible to fit a QR with inequality constrains and no intercept?

Is there another alternative for solving this kind of problem?

I would appreciate your comments.

Best regards,

Helio

	[[alternative HTML version deleted]]


From stephen.berman at gmx.net  Thu Feb 23 22:47:29 2017
From: stephen.berman at gmx.net (Stephen Berman)
Date: Thu, 23 Feb 2017 22:47:29 +0100
Subject: [R] R scripts attached to e-mails - correct MIME type ?!
In-Reply-To: <22698.63999.756178.367552@stat.math.ethz.ch> (Martin Maechler's
	message of "Mon, 20 Feb 2017 15:15:27 +0100")
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<22698.63999.756178.367552@stat.math.ethz.ch>
Message-ID: <87a89cpojy.fsf@rosalinde>

On Mon, 20 Feb 2017 15:15:27 +0100 Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>     on Sat, 18 Feb 2017 13:47:02 +0000 writes:
>
>     > Helo, No attachment came through. Change the file
>     > extension from .R to .txt and resend, there aren't many
>     > types of files r-help accepts.
>
>     > Rui Barradas
>
>
> As a matter of fact, one would have to blame the e-mail program
> you use.  The file extension is *not* equivalent to the file
> type, and the mailing list software accepts the (MIME) type  text/plain
> and a couple of others.
>
> The problem with most modern e-mail clients/programs/apps/... is that
> they use something you could translate as  "unknown binary format" 
> as type for their attachments if they can't guess the correct
> file type from the file extension.
> It would be interesting to know (for me) if there are modern
> e-mail programs / web apps which you could *teach* about the
> mime type, e.g., for all files ending with extension '.R'...

Well, there's Gnus in Emacs:

(add-to-list 'mailcap-mime-extensions '(".R" . "text/x-rsrc"))

But I guess you know that ;-)

Steve Berman


From murdoch.duncan at gmail.com  Fri Feb 24 19:44:36 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 24 Feb 2017 13:44:36 -0500
Subject: [R] R scripts attached to e-mails - correct MIME type ?!
In-Reply-To: <87a89cpojy.fsf@rosalinde>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<22698.63999.756178.367552@stat.math.ethz.ch>
	<87a89cpojy.fsf@rosalinde>
Message-ID: <0097ad65-143e-b664-4abb-52f14b4b26ee@gmail.com>

On 23/02/2017 4:47 PM, Stephen Berman wrote:
> On Mon, 20 Feb 2017 15:15:27 +0100 Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>
>>>>>>> Rui Barradas <ruipbarradas at sapo.pt>
>>>>>>>     on Sat, 18 Feb 2017 13:47:02 +0000 writes:
>>
>>     > Helo, No attachment came through. Change the file
>>     > extension from .R to .txt and resend, there aren't many
>>     > types of files r-help accepts.
>>
>>     > Rui Barradas
>>
>>
>> As a matter of fact, one would have to blame the e-mail program
>> you use.  The file extension is *not* equivalent to the file
>> type, and the mailing list software accepts the (MIME) type  text/plain
>> and a couple of others.
>>
>> The problem with most modern e-mail clients/programs/apps/... is that
>> they use something you could translate as  "unknown binary format"
>> as type for their attachments if they can't guess the correct
>> file type from the file extension.
>> It would be interesting to know (for me) if there are modern
>> e-mail programs / web apps which you could *teach* about the
>> mime type, e.g., for all files ending with extension '.R'...
>
> Well, there's Gnus in Emacs:
>
> (add-to-list 'mailcap-mime-extensions '(".R" . "text/x-rsrc"))
>
> But I guess you know that ;-)
>

He said "modern".  ;-)

Duncan Murdoch


From rkoenker at illinois.edu  Fri Feb 24 19:52:46 2017
From: rkoenker at illinois.edu (Roger Koenker)
Date: Fri, 24 Feb 2017 12:52:46 -0600
Subject: [R] Help with a specific quantile regression problem
In-Reply-To: <3e5dbf9880e6442dac9e33508d41b6f0@CITESHT1.ad.uillinois.edu>
References: <3e5dbf9880e6442dac9e33508d41b6f0@CITESHT1.ad.uillinois.edu>
Message-ID: <DC7B210A-0E8A-4827-A508-665503059F5C@illinois.edu>

What ensures that the tau-th quantile of the residuals is (nearly) zero, is that there IS
an intercept in the model, this is one of the conditions required for the subgradient to
contain 0 provided there is an intercept, when there is no intercept there is constraint
to enforce this any more.

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Feb 24, 2017, at 5:10 AM, Helio Santana <helio.santana.1997 at gmail.com> wrote:
> 
> Dear R community,
> 
> I am a beginner in quantile regression and I have a question about a
> specific problem. I have used the quantreg package to fit a QR with
> inequality constrains:
> 
> n <- 100
> p <- 5
> X <- matrix(rnorm(n*p),n,p)
> y <- 0.95*apply(X,1,sum)+rnorm(n)
> R <- cbind(0,rbind(diag(p),-diag(p)))
> r <- c(rep(0,p),-rep(1,p))
> model <- rq(y~X,R=R,r=r,method="fnc")
> 
> So,
> 
>> quantile(model$residuals,0.5)
>> -6.68836e-11 (It should be close to 0)
> 
> 
> However, if I try to impose no intercept in the last problem:
> 
> R <- cbind(0,rbind(diag(p),-diag(p)))
> R <- R[,2:dim(R)[2]]
> r <- c(rep(0,p),-rep(1,p))
> model <- rq(y~X-1,R=R,r=r,method="fnc")
> 
> I obtain:
> 
>> quantile(model$residuals,0.5)
>> -0.03465427
> 
> As you can see, this quantile value is not close to 0 as I expected. Have I
> an error in the formulation of the QR?
> 
> Is it possible to fit a QR with inequality constrains and no intercept?
> 
> Is there another alternative for solving this kind of problem?
> 
> I would appreciate your comments.
> 
> Best regards,
> 
> Helio
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From frainj at gmail.com  Fri Feb 24 20:26:46 2017
From: frainj at gmail.com (John C Frain)
Date: Fri, 24 Feb 2017 19:26:46 +0000
Subject: [R] vars package - irf() does not work
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A17A89@SRVEXCHCM301.precheza.cz>
References: <1487594810802.89921@kent.ac.uk> <1487757420140.51553@kent.ac.uk>
	<20170223164648.247642fd@draco> <1487928479810.5002@kent.ac.uk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A17A89@SRVEXCHCM301.precheza.cz>
Message-ID: <CAHrK5166uW-Rd7uehf9yTn2FuiGJx+8CiNfZ2s3qvmt=fckqLA@mail.gmail.com>

I would suggest that you comment out the offending command and re-enter it
from the keyboard. It appears that the command is failing the syntax check
in the command. I have not checked the vars package but it is usual to do a
syntax check before the data is analysed. you could also have  a look at
your script in a hex editor.

If this does not solve your problem I would suggest that you send to the
list your script and  data in text format as attachments. (I presume that
this is allowable)

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 24 February 2017 at 10:42, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> so
>
> var.2c <- VAR(Canada, p = 2, type = "const")
> irf(var.2c, impulse = "e", response = c("prod", "rw", "U"), boot = FALSE)
>
> works only sometimes? Or it does not work with **your** data only?
>
> If it is the later, the issue is probably in your data. You should look at
> them to see if
>
> str(yourdata)
>
> does not show some problems.
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of T.Riedle
> > Sent: Friday, February 24, 2017 10:28 AM
> > To: John Dougherty <jwd at surewest.net>; r-help at r-project.org
> > Subject: Re: [R] vars package - irf() does not work
> >
> > The code is written in a script and I use Rstudio. The script stops when
> the
> > irf() command should be executed returning the error mentioned below. I
> > tried to writte an independent script just for the irf() function but it
> does not
> > work either with the same error.
> >
> > ________________________________________
> > From: R-help <r-help-bounces at r-project.org> on behalf of John Dougherty
> > <jwd at surewest.net>
> > Sent: 24 February 2017 00:46
> > To: r-help at r-project.org
> > Subject: Re: [R] vars package - irf() does not work
> >
> > On Wed, 22 Feb 2017 09:57:00 +0000
> > "T.Riedle" <tr206 at kent.ac.uk> wrote:
> >
> > > Dear all,
> > >
> > > I have not received any response on this email. Is there anybody who
> > > can help me?
> > >
> > > I want to run an impulse response analysis using the vars() package.
> > > The code looks as follwows.
> > >
> > >
> > > # list of class varest
> > > varest.USA<-VAR(VAR_analsis_DataUSA, lag.max = 24, ic = "SC", type =
> > > "both")
> > >
> > > varest.USA
> > >
> > > summary(varest.USA)
> > >
> > >
> > >
> > > #Run irf analysis
> > > irf.USAg<-irf(varest.USA, response = "g", n.ahead = 48, boot = TRUE,
> > > ci=0.95)
> > >
> > > plot(irf.USAg)
> > >
> > >
> > > The problem is that R returns an error that the arguments in irf are
> > > unused. That is, unused arguments (response="g", n.ahead = 48, boot =
> > > TRUE, ci=0.95) The strangeness is that it sometimes works but most of
> > > the time it does not. I installed vars() last month and irf() worked
> > > well but now it does only occasionally. I have just edited the data
> > > but kept the code unchanged.
> > >
> > >
> > > In addition, I have the same problem when I am trying to replicate the
> > > example on irf() in the vars vignette althoug it also worked well when
> > > I installed vars and run the example.
> > >
> > >
> > > Does anybody have an idea what is wrong?
> > >
> > Two guesses are 1) you are not consistently entering the commands and
> thus
> > get variable outcomes, and 2) possibly there are "depends" that
> > irf() needs that need to updated.  You could also contact the package
> > creators.  I would also observe that this looks remarkably like you
> might be
> > asking for help on your homework.
> >
> > I would create a script of the commands you use as they work, each
> entered
> > in sequence as you used it. You use it essentially as a lab notebook that
> > documents procedures.  RStudio works well for this, since you can copy
> each
> > line that works from the Console to a script file in the editor.  You
> can do the
> > same with a text editor, while using R from a console, but it is somewhat
> > more clumsy.
> >
> >
> > --
> >
> > John
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Fri Feb 24 20:29:48 2017
From: ssefick at gmail.com (stephen sefick)
Date: Fri, 24 Feb 2017 13:29:48 -0600
Subject: [R] Make sure a data frame has been "fun through" a function
In-Reply-To: <CAF8bMcaC3VN+pos8AC7erS4Fv0qTUyt64vQFuXi5=1cHgHkFyA@mail.gmail.com>
References: <CADKEMqi5Ow5+Czta4bNC4SxhDCuMPeOiCtpSo3kan4tAbFh+Aw@mail.gmail.com>
	<alpine.OSX.2.20.1702201606250.2883@charles-berrys-macbook.local>
	<CADKEMqg2mbKUu9TNFu0ZC9GXFWNKV=Fy3eT_vX-6FkrztQ=BKQ@mail.gmail.com>
	<FA9FEE6A-5AED-411C-BE48-75AACE112711@comcast.net>
	<CADKEMqj5-SYp-SkzcR10ERcYiGm7n+9dh7KEB0BOid0anKk4vw@mail.gmail.com>
	<alpine.OSX.2.20.1702210815470.669@charles-berrys-macbook.local>
	<CAF8bMcaC3VN+pos8AC7erS4Fv0qTUyt64vQFuXi5=1cHgHkFyA@mail.gmail.com>
Message-ID: <CADKEMqhzTWQ915Gev47H_UCM2_gw69YPgqcpDFYyMZ+mm7c5cg@mail.gmail.com>

Update, I have decided to make use S4 in order to solve my problem. Are
there any particular resources that might be helpful. Thanks you for all of
the help.
kindest regards,

STephen

On Tue, Feb 21, 2017 at 10:52 AM, William Dunlap <wdunlap at tibco.com> wrote:

> Stray attributes on data.frames may or may not survive some simple
> operations on the data.frame.  E.g.,
>
> > d <- data.frame(X=1:5, Y=log(1:5), G=factor(rep(c("a","b"),c(2,3))))
> > attr(d, "checked") <- TRUE
> > wasChecked <- function(x) isTRUE(attr(x, "checked"))
> > wasChecked(d)
> [1] TRUE
> > wasChecked(d[1:4,]) # select some rows
> [1] TRUE
> > wasChecked(d[,1:2]) # select some columns
> [1] FALSE
> > d[1,1] <- 10 # change a single value
> > wasChecked(d)
> [1] TRUE
> > d$NewColumn <- 11:15 # add a column
> > wasChecked(d)
> [1] TRUE
>
> I don't know if this would be an issue in your case.  If it is, you
> could subclass "data.frame" and define methods so that the operations
> of interest preserve or remove the attribute in the way that you
> desire.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Feb 21, 2017 at 8:30 AM, Charles C. Berry <ccberry at ucsd.edu>
> wrote:
> > On Tue, 21 Feb 2017, stephen sefick wrote:
> >
> >> Sorry for not being clear. I have never used S3 methods before. Below is
> >> some R code that sketches out my idea. Is this a sensible solution?
> >>
> >
> > Sure. See comments (untested) inline.
> >
> > Chuck
> >
> >> test_data <- data.frame(a=1:10, b=1:10, c=1:10)
> >>
> >> functionA <- function(x, impossible_genotype){
> >>    ##some data processing
> >>    y <- x
> >>
> >>    ##return S3 to be able to use impossible genotype later
> >>    class(y) <- append(class(y),"genotypes")
> >
> >
> >      class(y) <- c("genotypes",class(y))
> >
> >>
> >>    attr(y, "impossible_genotype") <- impossible_genotype
> >>
> >>    return(y)
> >> }
> >>
> >> test_data_genotypes <- functionA(test_data, impossible_genotype="Ref")
> >>
> >> functionB <- function(x){
> >>    ##stop if pre-processed with functionA
> >>    if(sum(class(x)=="genotypes")!=1){stop("Need to pre-process data
> with
> >> functionA")}
> >
> >
> >     if(!(inherits("genotypes")){
> >         stop("Need to pre-process data with functionA")}
> >
> >
> > or in functionA you could skip the class()<- and just set the
> > "impossible_genotypes" attribute to FALSE when there are none such.
> >
> > Then here test
> >
> >      if (is.null(attr(x,"impossible_genotypes"))){
> >                 stop("Need to pre-process data with functionA")
> >         } else {
> >                 return(alleles)
> >         }
> >
> >
> >>
> >>    ##use this later in functionB to
> >>    impossible_genotype <- attributes(x)$impossible_genotype
> >
> >
> >      impossible_genotype <- attr(x,"impossible_genotype")
> >>
> >>
> >>    alleles <- c("Ref", "Alt")
> >>
> >>    coded_genotype <- alleles[alleles!=impossible_genotype]
> >
> >
> >      maybe `!is.element(alleles,impossible_genotype)' is safer than `!='
> >
> >>
> >>
> >>
> >>    return(coded_genotype)
> >> }
> >>
> >> ##stop if not pre-processed with functionA
> >> functionB(test_data)
> >>
> >> ##processed with functionA
> >> functionB(test_data_genotypes)
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Feb 24 21:01:47 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 24 Feb 2017 12:01:47 -0800
Subject: [R] Differences between SPSS and R on probit analysis
In-Reply-To: <CY4PR06MB3014AC99A5B7ED03B5F762319A530@CY4PR06MB3014.namprd06.prod.outlook.com>
References: <CY4PR06MB3014AC99A5B7ED03B5F762319A530@CY4PR06MB3014.namprd06.prod.outlook.com>
Message-ID: <CAF8bMcZ3gOSepD1CyP4XTq09j1MH8m-YqsfgGeko058yrHF=2A@mail.gmail.com>

Did you not get a warning from glm, such as the following one?
> fm1 <- glm(affected/total ~ log(dose), family=binomial(link = probit), data=finney71[finney71$dose != 0, ])
Warning message:
In eval(expr, envir, enclos) : non-integer #successes in a binomial glm!
Do not ignore warnings.

The left hand side of the formula should a matrix containing the counts
of the afflicted and non-afflicted:
   cbind(affected, total-affected)
not the fraction of the total that were afflicted.  Then you would get

Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -6.8940     1.0780  -6.395 1.60e-10 ***
log(dose)     0.9333     0.1344   6.944 3.82e-12 ***

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Feb 23, 2017 at 12:26 PM, Biank M <bianca12_domi at hotmail.com> wrote:
> Hi,
>
> I'm working on the effects of alternative larvicides on Aedes aegypti. Right now, I am doing a binary mortality response with a single explanatory variable (dose) on 4 concentrations of one larvicide (+ control). Our university is fond of SPSS, and I have learned to conduct the basic probit model with it, including a natural logarithm transformation on my dosis data.
> Not so long ago, I've started working with R, and through a combination of the 'glm' and 'dose.p' functions, I get the same slope and intercept, as well as LD50 calculations. Nevertheless, the standard errors and Z-scores calculated through the Probit model in SPSS comes out completely different in R. Additionally, the 95% confidence intervals for the LD50 come out very differently between the two programs. I really don't have a clue on how I am getting the same slopes, intercepts and LD50's, but totally different SE, Z, and 95% CI. Can anybody help me so I can get the same results in R??
>
> I'll pass you the script and hypothetical data:
>
> dose <- c(6000, 4500, 3000, 1500, 0)
> total <- c(100, 100, 100, 100, 100)
> affected <- c(91, 82, 69, 49, 0)
>
> finney71 <- data.frame(dose, total, affected)
>
> fm1 <- glm(affected/total ~ log(dose),
> family=binomial(link = probit), data=finney71[finney71$dose != 0, ])
>
> xp1 <- dose.p(fm1, p=c(0.5,0.9))
> xp.ci <- xp1 + attr(xp1, "SE") %*% matrix(qnorm(1 - 0.05/2)*c(-1,1), nrow=1)
> EAUS.Aa <- exp(cbind(xp1, attr(xp1, "SE"), xp.ci[,1], xp.ci[,2]))
> dimnames(EAUS.Aa)[[2]] <- c("LD", "SE", "LCL","UCL")
>
> So, this is the regression results I get with R:
> summary(fm1)
>
> Deviance Residuals:
> 1 2 3 4
> 0.06655 -0.02814 -0.06268 0.03474
>
> Coefficients:
> Estimate Std. Error z value
> (Intercept) -6.8940 10.7802 -0.640
> log(dose) 0.9333 1.3441 0.694
> Pr(>|z|)
> (Intercept) 0.522
> log(dose) 0.487
>
> (Dispersion parameter for binomial family taken to be 1)
>
> Null deviance: 0.513878 on 3 degrees of freedom
> Residual deviance: 0.010356 on 2 degrees of freedom
> AIC: 6.5458
>
> Number of Fisher Scoring iterations: 5
>
> And the LD50 and CI transformed:
>
> print(EAUS.Aa)
> LD SE LCL UCL
> p = 0.5: 1614.444 3.207876 164.3822 15855.91
> p = 0.9: 6373.473 3.764879 474.1600 85669.72
>
> These are the values I get on SPSS (just replacing the values on R output) :
>
> Coefficients:
> Estimate Std. Error z value
> (Intercept) -6.8940 1.082 -6.373
> (dose) 2.149 0.311 6.918
>
> And the LD50 and CI transformed:
>
> LD LCL UCL
> p = 0.5: 1614.444 1198.932 1953.120
> p = 0.9: 6373.473 5145.767 9013.354
>
> So, please if somebody can help me with this, I'd be grateful. If working with those functions won't do it, I'll use another, the one you recommend.
>
> Thank you very much!
>
>
> Best wishes,
>
> Bianca
>
>
>
> PD. I've already googled it but there's no satisfactory answer.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Feb 24 21:29:31 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 24 Feb 2017 12:29:31 -0800
Subject: [R] Differences between SPSS and R on probit analysis
In-Reply-To: <CAF8bMcZ3gOSepD1CyP4XTq09j1MH8m-YqsfgGeko058yrHF=2A@mail.gmail.com>
References: <CY4PR06MB3014AC99A5B7ED03B5F762319A530@CY4PR06MB3014.namprd06.prod.outlook.com>
	<CAF8bMcZ3gOSepD1CyP4XTq09j1MH8m-YqsfgGeko058yrHF=2A@mail.gmail.com>
Message-ID: <CAF8bMcZpH4Di_jzkyDDEE+tWfe=2obGwRLbhBLqmf3WSSiLBNw@mail.gmail.com>

Another model specification equivalent to
    cbind(afflicted, total-afflicted) ~ ...
is the ratio you had accompanied by the total as the 'weights' argument
    afflicted/total ~ ..., weights=total
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Feb 24, 2017 at 12:01 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Did you not get a warning from glm, such as the following one?
>> fm1 <- glm(affected/total ~ log(dose), family=binomial(link = probit), data=finney71[finney71$dose != 0, ])
> Warning message:
> In eval(expr, envir, enclos) : non-integer #successes in a binomial glm!
> Do not ignore warnings.
>
> The left hand side of the formula should a matrix containing the counts
> of the afflicted and non-afflicted:
>    cbind(affected, total-affected)
> not the fraction of the total that were afflicted.  Then you would get
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -6.8940     1.0780  -6.395 1.60e-10 ***
> log(dose)     0.9333     0.1344   6.944 3.82e-12 ***
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Feb 23, 2017 at 12:26 PM, Biank M <bianca12_domi at hotmail.com> wrote:
>> Hi,
>>
>> I'm working on the effects of alternative larvicides on Aedes aegypti. Right now, I am doing a binary mortality response with a single explanatory variable (dose) on 4 concentrations of one larvicide (+ control). Our university is fond of SPSS, and I have learned to conduct the basic probit model with it, including a natural logarithm transformation on my dosis data.
>> Not so long ago, I've started working with R, and through a combination of the 'glm' and 'dose.p' functions, I get the same slope and intercept, as well as LD50 calculations. Nevertheless, the standard errors and Z-scores calculated through the Probit model in SPSS comes out completely different in R. Additionally, the 95% confidence intervals for the LD50 come out very differently between the two programs. I really don't have a clue on how I am getting the same slopes, intercepts and LD50's, but totally different SE, Z, and 95% CI. Can anybody help me so I can get the same results in R??
>>
>> I'll pass you the script and hypothetical data:
>>
>> dose <- c(6000, 4500, 3000, 1500, 0)
>> total <- c(100, 100, 100, 100, 100)
>> affected <- c(91, 82, 69, 49, 0)
>>
>> finney71 <- data.frame(dose, total, affected)
>>
>> fm1 <- glm(affected/total ~ log(dose),
>> family=binomial(link = probit), data=finney71[finney71$dose != 0, ])
>>
>> xp1 <- dose.p(fm1, p=c(0.5,0.9))
>> xp.ci <- xp1 + attr(xp1, "SE") %*% matrix(qnorm(1 - 0.05/2)*c(-1,1), nrow=1)
>> EAUS.Aa <- exp(cbind(xp1, attr(xp1, "SE"), xp.ci[,1], xp.ci[,2]))
>> dimnames(EAUS.Aa)[[2]] <- c("LD", "SE", "LCL","UCL")
>>
>> So, this is the regression results I get with R:
>> summary(fm1)
>>
>> Deviance Residuals:
>> 1 2 3 4
>> 0.06655 -0.02814 -0.06268 0.03474
>>
>> Coefficients:
>> Estimate Std. Error z value
>> (Intercept) -6.8940 10.7802 -0.640
>> log(dose) 0.9333 1.3441 0.694
>> Pr(>|z|)
>> (Intercept) 0.522
>> log(dose) 0.487
>>
>> (Dispersion parameter for binomial family taken to be 1)
>>
>> Null deviance: 0.513878 on 3 degrees of freedom
>> Residual deviance: 0.010356 on 2 degrees of freedom
>> AIC: 6.5458
>>
>> Number of Fisher Scoring iterations: 5
>>
>> And the LD50 and CI transformed:
>>
>> print(EAUS.Aa)
>> LD SE LCL UCL
>> p = 0.5: 1614.444 3.207876 164.3822 15855.91
>> p = 0.9: 6373.473 3.764879 474.1600 85669.72
>>
>> These are the values I get on SPSS (just replacing the values on R output) :
>>
>> Coefficients:
>> Estimate Std. Error z value
>> (Intercept) -6.8940 1.082 -6.373
>> (dose) 2.149 0.311 6.918
>>
>> And the LD50 and CI transformed:
>>
>> LD LCL UCL
>> p = 0.5: 1614.444 1198.932 1953.120
>> p = 0.9: 6373.473 5145.767 9013.354
>>
>> So, please if somebody can help me with this, I'd be grateful. If working with those functions won't do it, I'll use another, the one you recommend.
>>
>> Thank you very much!
>>
>>
>> Best wishes,
>>
>> Bianca
>>
>>
>>
>> PD. I've already googled it but there's no satisfactory answer.
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sat Feb 25 02:02:46 2017
From: tmrsg11 at gmail.com (C W)
Date: Fri, 24 Feb 2017 20:02:46 -0500
Subject: [R] How to use apply() to fill matrix by rows or columns?
Message-ID: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>

Dear R,

I wanted to simulate a 5 by 3 matrix which fills up by either rows or
columns?

I started with the following filling the matrix by rows,

dat <- matrix(NA, nrow=5, ncol = 3)

for(i in 1:5){

    dat[i, ] <- rnorm(3)

}

But, R is known for no loop drama. Any suggestions?

Thanks!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Feb 25 02:23:35 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 24 Feb 2017 17:23:35 -0800
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
Message-ID: <6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>

What is wrong with

dat <- matrix(rnorm(15), nrow=5, ncol = 3)

?

And what is this "no loop drama" you refer to? I use loops frequently to loop around large memory gobbling chunks of code. 

-- 
Sent from my phone. Please excuse my brevity.

On February 24, 2017 5:02:46 PM PST, C W <tmrsg11 at gmail.com> wrote:
>Dear R,
>
>I wanted to simulate a 5 by 3 matrix which fills up by either rows or
>columns?
>
>I started with the following filling the matrix by rows,
>
>dat <- matrix(NA, nrow=5, ncol = 3)
>
>for(i in 1:5){
>
>    dat[i, ] <- rnorm(3)
>
>}
>
>But, R is known for no loop drama. Any suggestions?
>
>Thanks!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sat Feb 25 02:27:07 2017
From: tmrsg11 at gmail.com (C W)
Date: Fri, 24 Feb 2017 20:27:07 -0500
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
	<6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
Message-ID: <CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>

In theory, I am generating from group 5 groups of random numbers, each
group has 3 samples.

Isn't apply() the replacement of loops?

On Fri, Feb 24, 2017 at 8:23 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> What is wrong with
>
> dat <- matrix(rnorm(15), nrow=5, ncol = 3)
>
> ?
>
> And what is this "no loop drama" you refer to? I use loops frequently to
> loop around large memory gobbling chunks of code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 24, 2017 5:02:46 PM PST, C W <tmrsg11 at gmail.com> wrote:
> >Dear R,
> >
> >I wanted to simulate a 5 by 3 matrix which fills up by either rows or
> >columns?
> >
> >I started with the following filling the matrix by rows,
> >
> >dat <- matrix(NA, nrow=5, ncol = 3)
> >
> >for(i in 1:5){
> >
> >    dat[i, ] <- rnorm(3)
> >
> >}
> >
> >But, R is known for no loop drama. Any suggestions?
> >
> >Thanks!
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Feb 25 02:50:05 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 24 Feb 2017 17:50:05 -0800
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
	<6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
	<CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>
Message-ID: <FD04FDF1-9889-47A1-B401-1EC664740B96@dcn.davis.ca.us>

The apply function is one of many alienate ways to write a loop. It is not appreciably more efficient in cpu time than a for loop.

Your example creates the numbers in the loop... does your actual data get created in a loop? If so then your original code should be perfectly serviceable. If not then there might be a better way to do this, but you would have to expand your example to illustrate how the data comes to you in order to suggest alternatives.

Also post using plain text to prevent your code from being mangled on its way to us. 
-- 
Sent from my phone. Please excuse my brevity.

On February 24, 2017 5:27:07 PM PST, C W <tmrsg11 at gmail.com> wrote:
>In theory, I am generating from group 5 groups of random numbers, each
>group has 3 samples.
>
>Isn't apply() the replacement of loops?
>
>On Fri, Feb 24, 2017 at 8:23 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> What is wrong with
>>
>> dat <- matrix(rnorm(15), nrow=5, ncol = 3)
>>
>> ?
>>
>> And what is this "no loop drama" you refer to? I use loops frequently
>to
>> loop around large memory gobbling chunks of code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 24, 2017 5:02:46 PM PST, C W <tmrsg11 at gmail.com> wrote:
>> >Dear R,
>> >
>> >I wanted to simulate a 5 by 3 matrix which fills up by either rows
>or
>> >columns?
>> >
>> >I started with the following filling the matrix by rows,
>> >
>> >dat <- matrix(NA, nrow=5, ncol = 3)
>> >
>> >for(i in 1:5){
>> >
>> >    dat[i, ] <- rnorm(3)
>> >
>> >}
>> >
>> >But, R is known for no loop drama. Any suggestions?
>> >
>> >Thanks!
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>


From tmrsg11 at gmail.com  Sat Feb 25 02:55:15 2017
From: tmrsg11 at gmail.com (C W)
Date: Fri, 24 Feb 2017 20:55:15 -0500
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <FD04FDF1-9889-47A1-B401-1EC664740B96@dcn.davis.ca.us>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
	<6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
	<CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>
	<FD04FDF1-9889-47A1-B401-1EC664740B96@dcn.davis.ca.us>
Message-ID: <CAE2FW2=bNfUSkCwECrkZBOpf3EM=EbJv1Bm9LpwnXwaq+78L+A@mail.gmail.com>

I suppose for loop will suffice.

I simply copy & paste the code from R editor. From my email, it looks
plain. Is there a way to tell?

On Fri, Feb 24, 2017 at 8:50 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The apply function is one of many alienate ways to write a loop. It is not
> appreciably more efficient in cpu time than a for loop.
>
> Your example creates the numbers in the loop... does your actual data get
> created in a loop? If so then your original code should be perfectly
> serviceable. If not then there might be a better way to do this, but you
> would have to expand your example to illustrate how the data comes to you
> in order to suggest alternatives.
>
> Also post using plain text to prevent your code from being mangled on its
> way to us.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 24, 2017 5:27:07 PM PST, C W <tmrsg11 at gmail.com> wrote:
> >In theory, I am generating from group 5 groups of random numbers, each
> >group has 3 samples.
> >
> >Isn't apply() the replacement of loops?
> >
> >On Fri, Feb 24, 2017 at 8:23 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> What is wrong with
> >>
> >> dat <- matrix(rnorm(15), nrow=5, ncol = 3)
> >>
> >> ?
> >>
> >> And what is this "no loop drama" you refer to? I use loops frequently
> >to
> >> loop around large memory gobbling chunks of code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On February 24, 2017 5:02:46 PM PST, C W <tmrsg11 at gmail.com> wrote:
> >> >Dear R,
> >> >
> >> >I wanted to simulate a 5 by 3 matrix which fills up by either rows
> >or
> >> >columns?
> >> >
> >> >I started with the following filling the matrix by rows,
> >> >
> >> >dat <- matrix(NA, nrow=5, ncol = 3)
> >> >
> >> >for(i in 1:5){
> >> >
> >> >    dat[i, ] <- rnorm(3)
> >> >
> >> >}
> >> >
> >> >But, R is known for no loop drama. Any suggestions?
> >> >
> >> >Thanks!
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
>

	[[alternative HTML version deleted]]


From sebastien.bihorel at cognigencorp.com  Sat Feb 25 03:16:08 2017
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Fri, 24 Feb 2017 21:16:08 -0500 (EST)
Subject: [R] Vertical boxplot with a continuous X axis
In-Reply-To: <CAGx1TMAXXw4AcMDqGm6OVM_9oWcdM8hh+3fKEbXXkGdn5U6YyQ@mail.gmail.com>
References: <2039994774.47306.1487911950034.JavaMail.zimbra@cognigencorp.com>
	<CAGx1TMAXXw4AcMDqGm6OVM_9oWcdM8hh+3fKEbXXkGdn5U6YyQ@mail.gmail.com>
Message-ID: <704145339.67928.1487988968975.JavaMail.zimbra@cognigencorp.com>

Thanks for your reply

----- Original Message -----
From: "Richard M. Heiberger" <rmh at temple.edu>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
Cc: "r-help" <r-help at r-project.org>
Sent: Friday, February 24, 2017 1:10:44 AM
Subject: Re: [R] Vertical boxplot with a continuous X axis

Yes, this is exactly what the panel function
    panel.bwplot.intermediate.hh
along with the
    position()
function in the HH package was designed for.

Continuing with the example in the linked stackoverflow

df <- structure(list(X1 = c(67.0785968921204, 45.5968692796599,
36.9528452430474,
59.0160838607585, 50.0432724395945, 44.3381091105162, 57.9705240678336,
52.5298724133533, 62.0004216014734, 54.1111551461596), X2 = c(66.4508598009841,
46.9692156851792, 37.1419457255043, 60.0582991817961, 50.7717368681294,
44.6962314013419, 57.5490276313784, 52.6394305113891, 62.9297233041122,
56.8151766642767), X3 = c(66.4517425831512, 46.2946539468733,
36.5946733567535, 59.2477934854157, 49.1558840130484, 44.7507905380111,
59.1132983272444, 53.710627728232, 61.7923277906642, 57.5999862897015
), X4 = c(66.1516449763315, 45.4660590159847, 37.2239262718906,
59.2975530712561, 50.2546321578291, 44.7220452966667, 59.8879656465763,
52.321734919241, 62.0802304973764, 56.6507005349853), X5 = c(66.1810558292955,
46.3301985628267, 36.4487743101244, 60.054119632362, 49.1593136549535,
44.5708909518076, 58.5865142665164, 52.5527273219855, 61.3749185309236,
54.1823379401272), X6 = c(65.9530929286517, 45.5120010675769,
36.7924160587984, 58.9428613519645, 50.3412809263164, 44.9671678827697,
57.8718260182012, 51.8954544252633, 62.0173019998447, 56.3833840769146
), X7 = c(66.3862581408135, 46.5872469340431, 36.7585555977493,
58.1374309578563, 50.3399735165261, 44.5739565876491, 57.5245695195136,
52.7613488669329, 61.2500297922529, 55.9202360622414), X8 = c(67.5577910713347,
46.1891742544371, 36.4689522649804, 59.5271358261971, 49.6776114214636,
44.1995317742719, 58.4881363877987, 52.1946266979144, 62.1149998459759,
55.3748655464147), X9 = c(66.3943390258844, 45.843835703738,
37.3485122393333, 59.8591304277037, 49.387883195468, 44.4283817056918,
58.1874530826789, 53.5091378916001, 62.1187451212786, 55.3632760142297
), X10 = c(66.9748072219828, 46.20735965374, 36.7069272963502,
59.5035069226904, 48.8446530329762, 44.8753686249692, 58.0223695284058,
53.2732448917674, 61.2509571513, 54.9615424261546), age = c(55,
37, 31, 59, 49, 47, 69, 68, 69, 66)), .Names = c("X1", "X2",
"X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "age"), row.names =
c("GSM1051533_7800246024_R03C02",
"GSM1051534_7800246024_R04C02", "GSM1051535_7800246024_R05C02",
"GSM1051536_7800246024_R06C02", "GSM1051537_7800246085_R01C01",
"GSM1051538_7800246085_R02C01", "GSM1051539_7800246085_R03C01",
"GSM1051540_7800246085_R04C01", "GSM1051541_7800246085_R05C01",
"GSM1051542_7800246085_R06C01"), class = "data.frame")

##  install.packages("HH")  ## if necessary
library(HH)

df.melt <- reshape2::melt(df, id.vars=c("age"))
df.melt$age.pos <- factor(df.melt$age)
position(df.melt$age.pos) <- levels(df.melt$age.pos)


## three options of x ticks and color

bwplot(value ~ age.pos, data=df.melt,
       horizontal=FALSE,
       panel=panel.bwplot.intermediate.hh,
       scales=list(
         x=list(
           at=position(df.melt$age.pos), ## placement of tick labels and marks
           limits=c(29, 71),             ## x limits
           tck=1)),                      ## draw tick marks
       xlab="age",
       main=list("value ~ age", cex=1.4))

bwplot(value ~ age.pos, data=df.melt,
       horizontal=FALSE,
       panel=panel.bwplot.intermediate.hh,
       scales=list(
         x=list(
        ## at=position(df.melt$age.pos), ## placement of tick labels and marks
           limits=c(29, 71),             ## x limits
           tck=1)),                      ## draw tick marks
       xlab="age",
       main=list("value ~ age", cex=1.4))

bwplot(value ~ age.pos, data=df.melt,
       horizontal=FALSE,
       panel=panel.bwplot.intermediate.hh,
       col="blue",                       ## constant color
       scales=list(
         x=list(
       ##  at=position(df.melt$age.pos), ## placement of tick labels and marks
           limits=c(29, 71),             ## x limits
           tck=1)),                      ## draw tick marks
       xlab="age",
       main=list("value ~ age", cex=1.4))

On Thu, Feb 23, 2017 at 11:52 PM, Sebastien Bihorel
<sebastien.bihorel at cognigencorp.com> wrote:
>
> Hi,
>
> Can the boxplot design illustrated in the post (http://stackoverflow.com/questions/39849459/how-to-create-boxplots-with-a-continuous-x-axis-in-r) be reproduced with lattice or a lattice-derived function?
>
> Thank you
>
> Sebastien
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Feb 25 03:16:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 24 Feb 2017 18:16:18 -0800
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <CAE2FW2=bNfUSkCwECrkZBOpf3EM=EbJv1Bm9LpwnXwaq+78L+A@mail.gmail.com>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
	<6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
	<CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>
	<FD04FDF1-9889-47A1-B401-1EC664740B96@dcn.davis.ca.us>
	<CAE2FW2=bNfUSkCwECrkZBOpf3EM=EbJv1Bm9LpwnXwaq+78L+A@mail.gmail.com>
Message-ID: <A99EBE74-02FD-446C-89E0-17DBC2F732D3@dcn.davis.ca.us>

There is a little button near the bottom of the Gmail editing box that switches to plain text. We can immediately tell because of the

[[alternative HTML version deleted]]

line when we receive it, and sometimes it loses all of the line breaks or has extra asterisks mixed in. You can look in the archives or replies to see what we see. 
-- 
Sent from my phone. Please excuse my brevity.

On February 24, 2017 5:55:15 PM PST, C W <tmrsg11 at gmail.com> wrote:
>I suppose for loop will suffice.
>
>I simply copy & paste the code from R editor. From my email, it looks
>plain. Is there a way to tell?
>
>On Fri, Feb 24, 2017 at 8:50 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> The apply function is one of many alienate ways to write a loop. It
>is not
>> appreciably more efficient in cpu time than a for loop.
>>
>> Your example creates the numbers in the loop... does your actual data
>get
>> created in a loop? If so then your original code should be perfectly
>> serviceable. If not then there might be a better way to do this, but
>you
>> would have to expand your example to illustrate how the data comes to
>you
>> in order to suggest alternatives.
>>
>> Also post using plain text to prevent your code from being mangled on
>its
>> way to us.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 24, 2017 5:27:07 PM PST, C W <tmrsg11 at gmail.com> wrote:
>> >In theory, I am generating from group 5 groups of random numbers,
>each
>> >group has 3 samples.
>> >
>> >Isn't apply() the replacement of loops?
>> >
>> >On Fri, Feb 24, 2017 at 8:23 PM, Jeff Newmiller
>> ><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> What is wrong with
>> >>
>> >> dat <- matrix(rnorm(15), nrow=5, ncol = 3)
>> >>
>> >> ?
>> >>
>> >> And what is this "no loop drama" you refer to? I use loops
>frequently
>> >to
>> >> loop around large memory gobbling chunks of code.
>> >>
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On February 24, 2017 5:02:46 PM PST, C W <tmrsg11 at gmail.com>
>wrote:
>> >> >Dear R,
>> >> >
>> >> >I wanted to simulate a 5 by 3 matrix which fills up by either
>rows
>> >or
>> >> >columns?
>> >> >
>> >> >I started with the following filling the matrix by rows,
>> >> >
>> >> >dat <- matrix(NA, nrow=5, ncol = 3)
>> >> >
>> >> >for(i in 1:5){
>> >> >
>> >> >    dat[i, ] <- rnorm(3)
>> >> >
>> >> >}
>> >> >
>> >> >But, R is known for no loop drama. Any suggestions?
>> >> >
>> >> >Thanks!
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>>


From sebastien.bihorel at cognigencorp.com  Sat Feb 25 03:16:29 2017
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Fri, 24 Feb 2017 21:16:29 -0500 (EST)
Subject: [R] Vertical boxplot with a continuous X axis
In-Reply-To: <CAGxFJbS0eTtB-zCCGkO2JV3_69MLNOK3H-gUgZM4_w2cmpPtgg@mail.gmail.com>
References: <2039994774.47306.1487911950034.JavaMail.zimbra@cognigencorp.com>
	<CAGxFJbS0eTtB-zCCGkO2JV3_69MLNOK3H-gUgZM4_w2cmpPtgg@mail.gmail.com>
Message-ID: <2021311624.67934.1487988989231.JavaMail.zimbra@cognigencorp.com>

Thanks for your reply

----- Original Message -----
From: "Bert Gunter" <bgunter.4567 at gmail.com>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
Cc: "R-help" <r-help at r-project.org>
Sent: Friday, February 24, 2017 2:01:36 AM
Subject: Re: [R] Vertical boxplot with a continuous X axis

Sebastien:

The linked post is unclear: two of the rows have the same age, so
should there be 10 boxplots for the 10 rows or 9 for the 9 different
ages? I assumed the latter, as otherwise how could one disciminate
rows with the same age that have overlapping values?

For lattice, I just used age as the group= parameter to group by ages
and used panel.bwplot for the panel.groups function. My "aesthetics"
are different than shown in the linked post, but can be altered in
lattice through the panel.bwplot and par.settings parameters as
described in ?panel.bwplot:

   y <- unlist(df[,-11])
   age <- rep(df[,"age"],10) ## Could be done programatically
   xyplot(y~age, groups = age,
          panel = function(...){
             panel.abline(h = seq(40,65, by=5),
                          v = seq(30,70, by =5),
                          col="lightgray")
             panel.superpose(...)
          },
          panel.groups = function(x,y,...)
                panel.bwplot(x,y,horiz=FALSE,fill = "lightgray",
                        pch = 16, cex=.7,col= "black",box.width = 1.5),
          par.settings =list(box.rectangle = list(col="black"))
   )

However, note that this too could produce a hopeless mishmosh if the
ages are close together so that the boxplots overlap; or you could end
up getting nearly invisible skinny boxes, as in the plot shown in the
linked post.  So on the whole, I think you are better off treating the
ages as a factor and thereby separating them, e.g.

   bwplot(y~age, fill = "lightgray", horiz = FALSE,
          panel = function(...){
             panel.abline(h = seq(40,65, by=5),col="lightgray")
             panel.bwplot(...)
             },
          scales = list(x= list(lab = sort(unique(age)))),
          par.settings =list(box.rectangle = list(col="black"))
   )



Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Feb 23, 2017 at 8:52 PM, Sebastien Bihorel
<sebastien.bihorel at cognigencorp.com> wrote:
>
> Hi,
>
> Can the boxplot design illustrated in the post (http://stackoverflow.com/questions/39849459/how-to-create-boxplots-with-a-continuous-x-axis-in-r) be reproduced with lattice or a lattice-derived function?
>
> Thank you
>
> Sebastien
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sat Feb 25 04:37:45 2017
From: tmrsg11 at gmail.com (C W)
Date: Fri, 24 Feb 2017 22:37:45 -0500
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <A99EBE74-02FD-446C-89E0-17DBC2F732D3@dcn.davis.ca.us>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
	<6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
	<CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>
	<FD04FDF1-9889-47A1-B401-1EC664740B96@dcn.davis.ca.us>
	<CAE2FW2=bNfUSkCwECrkZBOpf3EM=EbJv1Bm9LpwnXwaq+78L+A@mail.gmail.com>
	<A99EBE74-02FD-446C-89E0-17DBC2F732D3@dcn.davis.ca.us>
Message-ID: <CAE2FW2=44M4qaUytewzhU251w7ZqmFjsPL6o9SXfyOh75mXg7A@mail.gmail.com>

Thanks for letting me know. That line does look familiar.

It's interesting how I simply copy and paste from R editor can result in
HTML format.

On Fri, Feb 24, 2017 at 9:16 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> There is a little button near the bottom of the Gmail editing box that
> switches to plain text. We can immediately tell because of the
>
> [[alternative HTML version deleted]]
>
> line when we receive it, and sometimes it loses all of the line breaks or
> has extra asterisks mixed in. You can look in the archives or replies to
> see what we see.
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 24, 2017 5:55:15 PM PST, C W <tmrsg11 at gmail.com> wrote:
> >I suppose for loop will suffice.
> >
> >I simply copy & paste the code from R editor. From my email, it looks
> >plain. Is there a way to tell?
> >
> >On Fri, Feb 24, 2017 at 8:50 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> The apply function is one of many alienate ways to write a loop. It
> >is not
> >> appreciably more efficient in cpu time than a for loop.
> >>
> >> Your example creates the numbers in the loop... does your actual data
> >get
> >> created in a loop? If so then your original code should be perfectly
> >> serviceable. If not then there might be a better way to do this, but
> >you
> >> would have to expand your example to illustrate how the data comes to
> >you
> >> in order to suggest alternatives.
> >>
> >> Also post using plain text to prevent your code from being mangled on
> >its
> >> way to us.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On February 24, 2017 5:27:07 PM PST, C W <tmrsg11 at gmail.com> wrote:
> >> >In theory, I am generating from group 5 groups of random numbers,
> >each
> >> >group has 3 samples.
> >> >
> >> >Isn't apply() the replacement of loops?
> >> >
> >> >On Fri, Feb 24, 2017 at 8:23 PM, Jeff Newmiller
> >> ><jdnewmil at dcn.davis.ca.us>
> >> >wrote:
> >> >
> >> >> What is wrong with
> >> >>
> >> >> dat <- matrix(rnorm(15), nrow=5, ncol = 3)
> >> >>
> >> >> ?
> >> >>
> >> >> And what is this "no loop drama" you refer to? I use loops
> >frequently
> >> >to
> >> >> loop around large memory gobbling chunks of code.
> >> >>
> >> >> --
> >> >> Sent from my phone. Please excuse my brevity.
> >> >>
> >> >> On February 24, 2017 5:02:46 PM PST, C W <tmrsg11 at gmail.com>
> >wrote:
> >> >> >Dear R,
> >> >> >
> >> >> >I wanted to simulate a 5 by 3 matrix which fills up by either
> >rows
> >> >or
> >> >> >columns?
> >> >> >
> >> >> >I started with the following filling the matrix by rows,
> >> >> >
> >> >> >dat <- matrix(NA, nrow=5, ncol = 3)
> >> >> >
> >> >> >for(i in 1:5){
> >> >> >
> >> >> >    dat[i, ] <- rnorm(3)
> >> >> >
> >> >> >}
> >> >> >
> >> >> >But, R is known for no loop drama. Any suggestions?
> >> >> >
> >> >> >Thanks!
> >> >> >
> >> >> >       [[alternative HTML version deleted]]
> >> >> >
> >> >> >______________________________________________
> >> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >PLEASE do read the posting guide
> >> >> >http://www.R-project.org/posting-guide.html
> >> >> >and provide commented, minimal, self-contained, reproducible
> >code.
> >> >>
> >>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Feb 25 04:49:28 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 24 Feb 2017 19:49:28 -0800
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <CAE2FW2=44M4qaUytewzhU251w7ZqmFjsPL6o9SXfyOh75mXg7A@mail.gmail.com>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
	<6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
	<CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>
	<FD04FDF1-9889-47A1-B401-1EC664740B96@dcn.davis.ca.us>
	<CAE2FW2=bNfUSkCwECrkZBOpf3EM=EbJv1Bm9LpwnXwaq+78L+A@mail.gmail.com>
	<A99EBE74-02FD-446C-89E0-17DBC2F732D3@dcn.davis.ca.us>
	<CAE2FW2=44M4qaUytewzhU251w7ZqmFjsPL6o9SXfyOh75mXg7A@mail.gmail.com>
Message-ID: <AE9F3742-0A33-4A1A-8B39-C8C163C3AD0B@dcn.davis.ca.us>

I am pretty sure it is not RStudio that is converting it to html... it is Gmail... but many email programs seem to do this these days so that people can send Wingdings symbols to their lolz pals, with no thought of the damage done to computer code examples. 
-- 
Sent from my phone. Please excuse my brevity.

On February 24, 2017 7:37:45 PM PST, C W <tmrsg11 at gmail.com> wrote:
>Thanks for letting me know. That line does look familiar.
>
>It's interesting how I simply copy and paste from R editor can result
>in
>HTML format.
>
>On Fri, Feb 24, 2017 at 9:16 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> There is a little button near the bottom of the Gmail editing box
>that
>> switches to plain text. We can immediately tell because of the
>>
>> [[alternative HTML version deleted]]
>>
>> line when we receive it, and sometimes it loses all of the line
>breaks or
>> has extra asterisks mixed in. You can look in the archives or replies
>to
>> see what we see.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 24, 2017 5:55:15 PM PST, C W <tmrsg11 at gmail.com> wrote:
>> >I suppose for loop will suffice.
>> >
>> >I simply copy & paste the code from R editor. From my email, it
>looks
>> >plain. Is there a way to tell?
>> >
>> >On Fri, Feb 24, 2017 at 8:50 PM, Jeff Newmiller
>> ><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> The apply function is one of many alienate ways to write a loop.
>It
>> >is not
>> >> appreciably more efficient in cpu time than a for loop.
>> >>
>> >> Your example creates the numbers in the loop... does your actual
>data
>> >get
>> >> created in a loop? If so then your original code should be
>perfectly
>> >> serviceable. If not then there might be a better way to do this,
>but
>> >you
>> >> would have to expand your example to illustrate how the data comes
>to
>> >you
>> >> in order to suggest alternatives.
>> >>
>> >> Also post using plain text to prevent your code from being mangled
>on
>> >its
>> >> way to us.
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On February 24, 2017 5:27:07 PM PST, C W <tmrsg11 at gmail.com>
>wrote:
>> >> >In theory, I am generating from group 5 groups of random numbers,
>> >each
>> >> >group has 3 samples.
>> >> >
>> >> >Isn't apply() the replacement of loops?
>> >> >
>> >> >On Fri, Feb 24, 2017 at 8:23 PM, Jeff Newmiller
>> >> ><jdnewmil at dcn.davis.ca.us>
>> >> >wrote:
>> >> >
>> >> >> What is wrong with
>> >> >>
>> >> >> dat <- matrix(rnorm(15), nrow=5, ncol = 3)
>> >> >>
>> >> >> ?
>> >> >>
>> >> >> And what is this "no loop drama" you refer to? I use loops
>> >frequently
>> >> >to
>> >> >> loop around large memory gobbling chunks of code.
>> >> >>
>> >> >> --
>> >> >> Sent from my phone. Please excuse my brevity.
>> >> >>
>> >> >> On February 24, 2017 5:02:46 PM PST, C W <tmrsg11 at gmail.com>
>> >wrote:
>> >> >> >Dear R,
>> >> >> >
>> >> >> >I wanted to simulate a 5 by 3 matrix which fills up by either
>> >rows
>> >> >or
>> >> >> >columns?
>> >> >> >
>> >> >> >I started with the following filling the matrix by rows,
>> >> >> >
>> >> >> >dat <- matrix(NA, nrow=5, ncol = 3)
>> >> >> >
>> >> >> >for(i in 1:5){
>> >> >> >
>> >> >> >    dat[i, ] <- rnorm(3)
>> >> >> >
>> >> >> >}
>> >> >> >
>> >> >> >But, R is known for no loop drama. Any suggestions?
>> >> >> >
>> >> >> >Thanks!
>> >> >> >
>> >> >> >       [[alternative HTML version deleted]]
>> >> >> >
>> >> >> >______________________________________________
>> >> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >PLEASE do read the posting guide
>> >> >> >http://www.R-project.org/posting-guide.html
>> >> >> >and provide commented, minimal, self-contained, reproducible
>> >code.
>> >> >>
>> >>
>>


From roslinaump at gmail.com  Sat Feb 25 05:58:10 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Sat, 25 Feb 2017 12:58:10 +0800
Subject: [R] Reading S-plus data in R
Message-ID: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>

Dear r-users,

I would like to read S-Plus data (.ssd) into R.  I tried this:

library(foreign)
read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")

and got this message:

read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
  not an S object

What is wrong with this?  Thank you so much for your help.

-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Sat Feb 25 06:08:03 2017
From: tmrsg11 at gmail.com (Mike C)
Date: Sat, 25 Feb 2017 05:08:03 +0000 (UTC)
Subject: [R] How to use apply() to fill matrix by rows or columns?
In-Reply-To: <AE9F3742-0A33-4A1A-8B39-C8C163C3AD0B@dcn.davis.ca.us>
References: <CAE2FW2kMZgnyK9wV3yZFp-GtpjR5pRqzKqqKkxneE2BiyaA4Ug@mail.gmail.com>
	<6926A7A7-86E9-45BB-AC3E-B4D860CD07A7@dcn.davis.ca.us>
	<CAE2FW2=q=r3z5wibwsfV2vNw655PN2xWR+v-QOBrfJBnPahGjQ@mail.gmail.com>
	<FD04FDF1-9889-47A1-B401-1EC664740B96@dcn.davis.ca.us>
	<CAE2FW2=bNfUSkCwECrkZBOpf3EM=EbJv1Bm9LpwnXwaq+78L+A@mail.gmail.com>
	<A99EBE74-02FD-446C-89E0-17DBC2F732D3@dcn.davis.ca.us>
	<CAE2FW2=44M4qaUytewzhU251w7ZqmFjsPL6o9SXfyOh75mXg7A@mail.gmail.com>
	<AE9F3742-0A33-4A1A-8B39-C8C163C3AD0B@dcn.davis.ca.us>
Message-ID: <458B26D55EACCF73.33106CD6-B2A0-416C-9A13-86C0F71FDDC9@mail.outlook.com>

I was using OS X native R editor. I would imagine that editor is as simple and native as it gets. But, if it's truly native, why would Gmail think of my code chunk so differently.
I'm just throwing it out there! I can always remove format in Gmail after pasting as a precaution. :)






On Fri, Feb 24, 2017 at 10:49 PM -0500, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:










I am pretty sure it is not RStudio that is converting it to html... it is Gmail... but many email programs seem to do this these days so that people can send Wingdings symbols to their lolz pals, with no thought of the damage done to computer code examples. 
-- 
Sent from my phone. Please excuse my brevity.

On February 24, 2017 7:37:45 PM PST, C W  wrote:
>Thanks for letting me know. That line does look familiar.
>
>It's interesting how I simply copy and paste from R editor can result
>in
>HTML format.
>
>On Fri, Feb 24, 2017 at 9:16 PM, Jeff Newmiller
>
>wrote:
>
>> There is a little button near the bottom of the Gmail editing box
>that
>> switches to plain text. We can immediately tell because of the
>>
>> [[alternative HTML version deleted]]
>>
>> line when we receive it, and sometimes it loses all of the line
>breaks or
>> has extra asterisks mixed in. You can look in the archives or replies
>to
>> see what we see.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On February 24, 2017 5:55:15 PM PST, C W  wrote:
>> >I suppose for loop will suffice.
>> >
>> >I simply copy & paste the code from R editor. From my email, it
>looks
>> >plain. Is there a way to tell?
>> >
>> >On Fri, Feb 24, 2017 at 8:50 PM, Jeff Newmiller
>> >
>> >wrote:
>> >
>> >> The apply function is one of many alienate ways to write a loop.
>It
>> >is not
>> >> appreciably more efficient in cpu time than a for loop.
>> >>
>> >> Your example creates the numbers in the loop... does your actual
>data
>> >get
>> >> created in a loop? If so then your original code should be
>perfectly
>> >> serviceable. If not then there might be a better way to do this,
>but
>> >you
>> >> would have to expand your example to illustrate how the data comes
>to
>> >you
>> >> in order to suggest alternatives.
>> >>
>> >> Also post using plain text to prevent your code from being mangled
>on
>> >its
>> >> way to us.
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>> >> On February 24, 2017 5:27:07 PM PST, C W 
>wrote:
>> >> >In theory, I am generating from group 5 groups of random numbers,
>> >each
>> >> >group has 3 samples.
>> >> >
>> >> >Isn't apply() the replacement of loops?
>> >> >
>> >> >On Fri, Feb 24, 2017 at 8:23 PM, Jeff Newmiller
>> >> >
>> >> >wrote:
>> >> >
>> >> >> What is wrong with
>> >> >>
>> >> >> dat <- matrix(rnorm(15), nrow=5, ncol = 3)
>> >> >>
>> >> >> ?
>> >> >>
>> >> >> And what is this "no loop drama" you refer to? I use loops
>> >frequently
>> >> >to
>> >> >> loop around large memory gobbling chunks of code.
>> >> >>
>> >> >> --
>> >> >> Sent from my phone. Please excuse my brevity.
>> >> >>
>> >> >> On February 24, 2017 5:02:46 PM PST, C W 
>> >wrote:
>> >> >> >Dear R,
>> >> >> >
>> >> >> >I wanted to simulate a 5 by 3 matrix which fills up by either
>> >rows
>> >> >or
>> >> >> >columns?
>> >> >> >
>> >> >> >I started with the following filling the matrix by rows,
>> >> >> >
>> >> >> >dat <- matrix(NA, nrow=5, ncol = 3)
>> >> >> >
>> >> >> >for(i in 1:5){
>> >> >> >
>> >> >> >    dat[i, ] <- rnorm(3)
>> >> >> >
>> >> >> >}
>> >> >> >
>> >> >> >But, R is known for no loop drama. Any suggestions?
>> >> >> >
>> >> >> >Thanks!
>> >> >> >
>> >> >> >       [[alternative HTML version deleted]]
>> >> >> >
>> >> >> >______________________________________________
>> >> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >PLEASE do read the posting guide
>> >> >> >http://www.R-project.org/posting-guide.html
>> >> >> >and provide commented, minimal, self-contained, reproducible
>> >code.
>> >> >>
>> >>
>>






	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Feb 25 06:15:02 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 24 Feb 2017 21:15:02 -0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
Message-ID: <CAGxFJbSwTMCfONbd=PcqusFE34n339g_NtRKf504hVbvndms+A@mail.gmail.com>

I see ".ssd" in your message and ".sdd" in your read.S () invocation...

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Dear r-users,
>
> I would like to read S-Plus data (.ssd) into R.  I tried this:
>
> library(foreign)
> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>
> and got this message:
>
> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>   not an S object
>
> What is wrong with this?  Thank you so much for your help.
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roslinaump at gmail.com  Sat Feb 25 06:56:47 2017
From: roslinaump at gmail.com (Roslina Zakaria)
Date: Sat, 25 Feb 2017 13:56:47 +0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CAGxFJbSwTMCfONbd=PcqusFE34n339g_NtRKf504hVbvndms+A@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAGxFJbSwTMCfONbd=PcqusFE34n339g_NtRKf504hVbvndms+A@mail.gmail.com>
Message-ID: <6e9irmc1e1grrbpnog7t0nmw.1488002207634@email.android.com>

It should be .sdd

Sent from my Sony Xperia? smartphone

---- Bert Gunter wrote ----

>I see ".ssd" in your message and ".sdd" in your read.S () invocation...
>
>-- Bert
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
><roslinaump at gmail.com> wrote:
>> Dear r-users,
>>
>> I would like to read S-Plus data (.ssd) into R.  I tried this:
>>
>> library(foreign)
>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>
>> and got this message:
>>
>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>>   not an S object
>>
>> What is wrong with this?  Thank you so much for your help.
>>
>> --
>> *Roslinazairimah Zakaria*
>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>
>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From alfredo.roccato at fastwebnet.it  Sat Feb 25 13:13:00 2017
From: alfredo.roccato at fastwebnet.it (Alfredo)
Date: Sat, 25 Feb 2017 13:13:00 +0100
Subject: [R] How to prune a tree using a validation set
Message-ID: <003701d28f60$81f07ea0$85d17be0$@fastwebnet.it>

I'd like to use a different data ( validation) set for pruning my
classification tree. Unfortunately there aren't arguments to get this in
prune.rpart().

Any suggestions?

Thanks!

Alfredo


	[[alternative HTML version deleted]]


From sewashm at gmail.com  Sat Feb 25 17:09:38 2017
From: sewashm at gmail.com (Ashta)
Date: Sat, 25 Feb 2017 10:09:38 -0600
Subject: [R] Repeat
Message-ID: <CADDFq320Xp=x51vaXt-2Pzp8h0XJTeUPDz5U5D2BJOvOCw1FLg@mail.gmail.com>

I have a data set and I want to repeat a column value based on other
column value,

my data look like

read.table(text = "Year month flag
2001 1   Z
2001 2   -
2001 4   X
2002 1   Z
2002 2   -
2003 1   -
2003 2   Z
2004 2   Z
2005 3   Z
2005 2   -
2005 3   -",  header = TRUE)

Within year If  flag = '-'  then i want replace  '-'  by the previous
row value of flag. In this example  for yea  2001 in month 2 flag is
'-' and I want replace it by the previous value of flag (i.e.,  'Z')
2001 1   Z
2001 2   Z
2001 4   X

If all values of flag  are '-' within year  then  I wan to set as N

The complete out put result will be

year month  flag
2001 1       Z
2001 2       z
2001 4       X
2002 1       Z
2002 2       Z
2003 1       Z
2003 2       Z
2004 2       Z
2005 3       Z
2005 2       N
2005 3       N

Thank you in advance


From vodvos at zoho.com  Sat Feb 25 17:21:12 2017
From: vodvos at zoho.com (vod vos)
Date: Sat, 25 Feb 2017 08:21:12 -0800
Subject: [R] How to plot distribution of relative frequncy using ggplot2?
Message-ID: <15a761378e6.e85f77b912038.6697485448109264889@zoho.com>

Hello everyone,

How to plot distribution of relative frequncy using ggplot2 ? The example figure is in the attachment.

If we have data:

aa<- c(1,5,10,20,50,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000)

bb<- c(8,16,30,24,39,54,40,68,72,62,122,80,181,259,275,380,320,434,479,587,626,648,738,766,793,851,871,957,1001,960)

aabbdiff<- aa-bb

aabb<- data.frame(aa, bb, aabbdiff)

library(ggplot2)

ggplot(aabb, aes(aabbdiff)) + geom_histogram() 

The above code line did not show what I want, how to draw the figure like in the attachment?

Thanks.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: geom.png
Type: image/png
Size: 73608 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170225/f3386505/attachment.png>

From bgunter.4567 at gmail.com  Sat Feb 25 17:29:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 25 Feb 2017 08:29:32 -0800
Subject: [R] How to plot distribution of relative frequncy using ggplot2?
In-Reply-To: <15a761378e6.e85f77b912038.6697485448109264889@zoho.com>
References: <15a761378e6.e85f77b912038.6697485448109264889@zoho.com>
Message-ID: <CAGxFJbShiTUDummGFiW9f5swCbGaW3jubC_50k9TcN3BKArs5A@mail.gmail.com>

Is this homework?

(We don't do homework here).

Also, this looks pretty basic. Have you gone through any ggplot
tutorials? -- the web and the Rstudio site have many.


-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Feb 25, 2017 at 8:21 AM, vod vos <vodvos at zoho.com> wrote:
> Hello everyone,
>
> How to plot distribution of relative frequncy using ggplot2 ? The example figure is in the attachment.
>
> If we have data:
>
> aa<- c(1,5,10,20,50,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000)
>
> bb<- c(8,16,30,24,39,54,40,68,72,62,122,80,181,259,275,380,320,434,479,587,626,648,738,766,793,851,871,957,1001,960)
>
> aabbdiff<- aa-bb
>
> aabb<- data.frame(aa, bb, aabbdiff)
>
> library(ggplot2)
>
> ggplot(aabb, aes(aabbdiff)) + geom_histogram()
>
> The above code line did not show what I want, how to draw the figure like in the attachment?
>
> Thanks.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Feb 25 17:42:12 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 25 Feb 2017 08:42:12 -0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
Message-ID: <CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>

The sdd file extension may mean that the file is in S+ 'data dump' format,
made by S+'s data.dump function and readable in S+ by its data.restore function.
foreign::data.restore can read some such files in R, but I think it
may only read well
those with using the pre-1991 format made in more recent versions of
S+ with data.dump(old.style=TRUE).
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Dear r-users,
>
> I would like to read S-Plus data (.ssd) into R.  I tried this:
>
> library(foreign)
> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>
> and got this message:
>
> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>   not an S object
>
> What is wrong with this?  Thank you so much for your help.
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370; Fax. No.+609-5492766*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Feb 25 17:50:01 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 25 Feb 2017 16:50:01 +0000
Subject: [R] unidentified option(s) in mean.model
In-Reply-To: <1611448447.875085.1488039519452@mail.yahoo.com>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<1611448447.875085.1488039519452@mail.yahoo.com>
Message-ID: <58B1B5B9.5080405@sapo.pt>

Hello,

Your minimal reproducible example is not reproducible since we don't 
have acces to file "EURJPY.m1440.csv" and is far from minimal.
Anyway, the best I can say is that you are using the attribution 
operator '<-' to set the values of a function's arguments when you 
should use '='. Try instead the fllowing.


spec = ugarchspec(variance.model = list(model = "sGARCH",garchOrder=c(1,1)),
                     mean.model = list(
                       armaOrder = c(final.order[1], final.order[3]), 
arfima = FALSE, include.mean = TRUE),
                     distribution.model = "sged")

Hope this helps,

Rui Barradas

Em 25-02-2017 16:18, Allan Tanaka escreveu:
> Hi
>
> See attached txt
>
>
> On Saturday, 18 February 2017, 20:47, Rui Barradas
> <ruipbarradas at sapo.pt> wrote:
>
>
> Helo,
>
> No attachment came through. Change the file extension from .R to .txt
> and resend, there aren't many types of files r-help accepts.
>
> Rui Barradas
>
> Em 17-02-2017 17:20, Allan Tanaka escreveu:
>  > So i tried brute force to find best fitted GARCH model for
> prediction.The code works fine as it runs but at the end of processing,
> there's error like this: There were 50 or more warnings (use warnings()
> to see the first 50).
>  > So i type warnings(), then the error become:unidentified option(s) in
> mean.model
>  > Not sure what's gone wrong?
>  > See attached for R script
>
>  > ______________________________________________
>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>  > and provide commented, minimal, self-contained, reproducible code.
>
>  >
>
>


From jdnewmil at dcn.davis.ca.us  Sat Feb 25 18:32:36 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 25 Feb 2017 09:32:36 -0800
Subject: [R] unidentified option(s) in mean.model
In-Reply-To: <58B1B5B9.5080405@sapo.pt>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<1611448447.875085.1488039519452@mail.yahoo.com>
	<58B1B5B9.5080405@sapo.pt>
Message-ID: <556344E0-0AE4-4213-9316-F9074427DCEF@dcn.davis.ca.us>

That was confusing.  One equals sign is used to assign values (actual arguments) to function inputs (formal arguments).

The assignment operator `<-` is used to assign values to variables in the current working environment. Due to popular demand, the single equals sign can ALSO be used for that purpose, but only outside the calling parenthesis for a function call.

I recognise that some people think this is a good argument for always using the single equals, but they are DIFFERENT operations in R, and pretending they are the same by using the same symbol in both situations just misleads people further, so at least be clear where each operator belongs when explaining the difference:

spec <- ugarchspec(variance.model = list(model = "sGARCH",garchOrder=c(1,1)),
                    mean.model = list(
                      armaOrder = c(final.order[1], final.order[3]), 
arfima = FALSE, include.mean = TRUE),
                    distribution.model = "sged")

and then let people decide whether to use the less precise notation after they understand what is happening.

I find it more confusing to parse

f = function( x ) x^2
x = 1
x = x
f( x = x )

than

f <- function( x ) x^2
x <- 1
x <- x
f( x = x )

(The x = x is just as useless as x <- x is outside the parameter list, but serves an important purpose when inside the parameter list.)
-- 
Sent from my phone. Please excuse my brevity.

On February 25, 2017 8:50:01 AM PST, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>Your minimal reproducible example is not reproducible since we don't 
>have acces to file "EURJPY.m1440.csv" and is far from minimal.
>Anyway, the best I can say is that you are using the attribution 
>operator '<-' to set the values of a function's arguments when you 
>should use '='. Try instead the fllowing.
>
>
>spec = ugarchspec(variance.model = list(model =
>"sGARCH",garchOrder=c(1,1)),
>                     mean.model = list(
>                       armaOrder = c(final.order[1], final.order[3]), 
>arfima = FALSE, include.mean = TRUE),
>                     distribution.model = "sged")
>
>Hope this helps,
>
>Rui Barradas
>
>Em 25-02-2017 16:18, Allan Tanaka escreveu:
>> Hi
>>
>> See attached txt
>>
>>
>> On Saturday, 18 February 2017, 20:47, Rui Barradas
>> <ruipbarradas at sapo.pt> wrote:
>>
>>
>> Helo,
>>
>> No attachment came through. Change the file extension from .R to .txt
>> and resend, there aren't many types of files r-help accepts.
>>
>> Rui Barradas
>>
>> Em 17-02-2017 17:20, Allan Tanaka escreveu:
>>  > So i tried brute force to find best fitted GARCH model for
>> prediction.The code works fine as it runs but at the end of
>processing,
>> there's error like this: There were 50 or more warnings (use
>warnings()
>> to see the first 50).
>>  > So i type warnings(), then the error become:unidentified option(s)
>in
>> mean.model
>>  > Not sure what's gone wrong?
>>  > See attached for R script
>>
>>  > ______________________________________________
>>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>To
>> UNSUBSCRIBE and more, see
>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>>  > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>>  > and provide commented, minimal, self-contained, reproducible code.
>>
>>  >
>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Feb 25 19:14:22 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 25 Feb 2017 10:14:22 -0800
Subject: [R] Repeat
In-Reply-To: <CADDFq320Xp=x51vaXt-2Pzp8h0XJTeUPDz5U5D2BJOvOCw1FLg@mail.gmail.com>
References: <CADDFq320Xp=x51vaXt-2Pzp8h0XJTeUPDz5U5D2BJOvOCw1FLg@mail.gmail.com>
Message-ID: <66B17F40-26AC-47D6-9C2F-639374F39DD1@comcast.net>


> On Feb 25, 2017, at 8:09 AM, Ashta <sewashm at gmail.com> wrote:
> 
> I have a data set and I want to repeat a column value based on other
> column value,
> 
> my data look like
> 
> read.table(text = "Year month flag
> 2001 1   Z
> 2001 2   -
> 2001 4   X
> 2002 1   Z
> 2002 2   -
> 2003 1   -
> 2003 2   Z
> 2004 2   Z
> 2005 3   Z
> 2005 2   -
> 2005 3   -",  header = TRUE)
> 
> Within year If  flag = '-'  then i want replace  '-'  by the previous
> row value of flag. In this example  for yea  2001 in month 2 flag is
> '-' and I want replace it by the previous value of flag (i.e.,  'Z')
> 2001 1   Z
> 2001 2   Z
> 2001 4   X
> 
> If all values of flag  are '-' within year  then  I wan to set as N
> 
> The complete out put result will be
> 
> year month  flag
> 2001 1       Z
> 2001 2       z
> 2001 4       X
> 2002 1       Z
> 2002 2       Z
> 2003 1       Z
> 2003 2       Z
> 2004 2       Z
> 2005 3       Z
> 2005 2       N
> 2005 3       N
> 
> Thank you in advance
> 

Your example doesn't actually match your verbal description of the algorithm because you have not specified the rule that establishes values for instances where the first value in a year is "-".

The `na.locf` function in the 'zoo' package would be useful for the task describe in your verbal description when used in conjunction with the 'stats'-package's `ave` function.

-- 
David.


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sat Feb 25 19:18:30 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 25 Feb 2017 18:18:30 +0000
Subject: [R] unidentified option(s) in mean.model
In-Reply-To: <556344E0-0AE4-4213-9316-F9074427DCEF@dcn.davis.ca.us>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<1611448447.875085.1488039519452@mail.yahoo.com>
	<58B1B5B9.5080405@sapo.pt>
	<556344E0-0AE4-4213-9316-F9074427DCEF@dcn.davis.ca.us>
Message-ID: <58B1CA76.3050702@sapo.pt>

Hello,

You're right, but the equal sign outside the function call wasn't my 
doing. I should have noticed that the OP had used
  spec = ugarchspec(...) and '<-' inside the function call to assign 
values to the function's arguments, but I heven't, so I just corrected 
the '<-'.

Rui Barradas

Em 25-02-2017 17:32, Jeff Newmiller escreveu:
> That was confusing.  One equals sign is used to assign values (actual arguments) to function inputs (formal arguments).
>
> The assignment operator `<-` is used to assign values to variables in the current working environment. Due to popular demand, the single equals sign can ALSO be used for that purpose, but only outside the calling parenthesis for a function call.
>
> I recognise that some people think this is a good argument for always using the single equals, but they are DIFFERENT operations in R, and pretending they are the same by using the same symbol in both situations just misleads people further, so at least be clear where each operator belongs when explaining the difference:
>
> spec <- ugarchspec(variance.model = list(model = "sGARCH",garchOrder=c(1,1)),
>                      mean.model = list(
>                        armaOrder = c(final.order[1], final.order[3]),
> arfima = FALSE, include.mean = TRUE),
>                      distribution.model = "sged")
>
> and then let people decide whether to use the less precise notation after they understand what is happening.
>
> I find it more confusing to parse
>
> f = function( x ) x^2
> x = 1
> x = x
> f( x = x )
>
> than
>
> f <- function( x ) x^2
> x <- 1
> x <- x
> f( x = x )
>
> (The x = x is just as useless as x <- x is outside the parameter list, but serves an important purpose when inside the parameter list.)
>


From sewashm at gmail.com  Sat Feb 25 19:45:58 2017
From: sewashm at gmail.com (Ashta)
Date: Sat, 25 Feb 2017 12:45:58 -0600
Subject: [R] Repeat
In-Reply-To: <66B17F40-26AC-47D6-9C2F-639374F39DD1@comcast.net>
References: <CADDFq320Xp=x51vaXt-2Pzp8h0XJTeUPDz5U5D2BJOvOCw1FLg@mail.gmail.com>
	<66B17F40-26AC-47D6-9C2F-639374F39DD1@comcast.net>
Message-ID: <CADDFq31Di4R4vc0=taw6CUco1cC8dZx_nzVZL-EguShCYZHEnQ@mail.gmail.com>

Thank you David.
is it not possible to sort it by year and flag so that we can make '-'
 in the second row ?  like this for that particular year.

   2003 2     Z
   2003 1      -



On Sat, Feb 25, 2017 at 12:14 PM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
>> On Feb 25, 2017, at 8:09 AM, Ashta <sewashm at gmail.com> wrote:
>>
>> I have a data set and I want to repeat a column value based on other
>> column value,
>>
>> my data look like
>>
>> read.table(text = "Year month flag
>> 2001 1   Z
>> 2001 2   -
>> 2001 4   X
>> 2002 1   Z
>> 2002 2   -
>> 2003 1   -
>> 2003 2   Z
>> 2004 2   Z
>> 2005 3   Z
>> 2005 2   -
>> 2005 3   -",  header = TRUE)
>>
>> Within year If  flag = '-'  then i want replace  '-'  by the previous
>> row value of flag. In this example  for yea  2001 in month 2 flag is
>> '-' and I want replace it by the previous value of flag (i.e.,  'Z')
>> 2001 1   Z
>> 2001 2   Z
>> 2001 4   X
>>
>> If all values of flag  are '-' within year  then  I wan to set as N
>>
>> The complete out put result will be
>>
>> year month  flag
>> 2001 1       Z
>> 2001 2       z
>> 2001 4       X
>> 2002 1       Z
>> 2002 2       Z
>> 2003 1       Z
>> 2003 2       Z
>> 2004 2       Z
>> 2005 3       Z
>> 2005 2       N
>> 2005 3       N
>>
>> Thank you in advance
>>
>
> Your example doesn't actually match your verbal description of the algorithm because you have not specified the rule that establishes values for instances where the first value in a year is "-".
>
> The `na.locf` function in the 'zoo' package would be useful for the task describe in your verbal description when used in conjunction with the 'stats'-package's `ave` function.
>
> --
> David.
>
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From allantanaka11 at yahoo.com  Sat Feb 25 17:18:39 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Sat, 25 Feb 2017 16:18:39 +0000 (UTC)
Subject: [R] unidentified option(s) in mean.model
In-Reply-To: <58A85056.3000804@sapo.pt>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
Message-ID: <1611448447.875085.1488039519452@mail.yahoo.com>

Hi
See attached txt 

    On Saturday, 18 February 2017, 20:47, Rui Barradas <ruipbarradas at sapo.pt> wrote:
 

 Helo,

No attachment came through. Change the file extension from .R to .txt 
and resend, there aren't many types of files r-help accepts.

Rui Barradas

Em 17-02-2017 17:20, Allan Tanaka escreveu:
> So i tried brute force to find best fitted GARCH model for prediction.The code works fine as it runs but at the end of processing, there's error like this: There were 50 or more warnings (use warnings() to see the first 50).
> So i type warnings(), then the error become:unidentified option(s) in mean.model
> Not sure what's gone wrong?
> See attached for R script
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


   
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: 111.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170225/4ffc2613/attachment.txt>

From allantanaka11 at yahoo.com  Sat Feb 25 17:23:27 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Sat, 25 Feb 2017 16:23:27 +0000 (UTC)
Subject: [R] unidentified option(s) in mean.model
In-Reply-To: <1611448447.875085.1488039519452@mail.yahoo.com>
References: <2116363132.1334313.1487352008288.ref@mail.yahoo.com>
	<2116363132.1334313.1487352008288@mail.yahoo.com>
	<58A85056.3000804@sapo.pt>
	<1611448447.875085.1488039519452@mail.yahoo.com>
Message-ID: <118334607.899960.1488039807079@mail.yahoo.com>

Let me know if anything 

    On Saturday, 25 February 2017, 23:18, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
 

 Hi
See attached txt 

    On Saturday, 18 February 2017, 20:47, Rui Barradas <ruipbarradas at sapo.pt> wrote:
 

 Helo,

No attachment came through. Change the file extension from .R to .txt 
and resend, there aren't many types of files r-help accepts.

Rui Barradas

Em 17-02-2017 17:20, Allan Tanaka escreveu:
> So i tried brute force to find best fitted GARCH model for prediction.The code works fine as it runs but at the end of processing, there's error like this: There were 50 or more warnings (use warnings() to see the first 50).
> So i type warnings(), then the error become:unidentified option(s) in mean.model
> Not sure what's gone wrong?
> See attached for R script
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


   

   
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Feb 26 00:43:33 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 25 Feb 2017 15:43:33 -0800
Subject: [R] Repeat
In-Reply-To: <CADDFq31Di4R4vc0=taw6CUco1cC8dZx_nzVZL-EguShCYZHEnQ@mail.gmail.com>
References: <CADDFq320Xp=x51vaXt-2Pzp8h0XJTeUPDz5U5D2BJOvOCw1FLg@mail.gmail.com>
	<66B17F40-26AC-47D6-9C2F-639374F39DD1@comcast.net>
	<CADDFq31Di4R4vc0=taw6CUco1cC8dZx_nzVZL-EguShCYZHEnQ@mail.gmail.com>
Message-ID: <666BAF47-9F9D-47F3-8E8F-FE7677C44E74@comcast.net>


> On Feb 25, 2017, at 10:45 AM, Ashta <sewashm at gmail.com> wrote:
> 
> Thank you David.
> is it not possible to sort it by year and flag so that we can make '-'
> in the second row ?  like this for that particular year.
> 
>   2003 2     Z
>   2003 1      -
> 

I was a bit surprised by the results of htis since I had assumed than an initial NA in a group would remain so, but apparently not:

dat$new <- with(dat, ave(flag, Year, FUN=function(s){ s[s=="-"] <- NA; zoo::na.locf(s) }) )

> dat
   Year month flag new
1  2001     1    Z   Z
2  2001     2    -   Z
3  2001     4    X   X
4  2002     1    Z   Z
5  2002     2    -   Z
6  2003     1    -   Z
7  2003     2    Z   Z
8  2004     2    Z   Z
9  2005     3    Z   Z
10 2005     2    -   Z
11 2005     3    -   Z

David.

> 
> 
> On Sat, Feb 25, 2017 at 12:14 PM, David Winsemius
> <dwinsemius at comcast.net> wrote:
>> 
>>> On Feb 25, 2017, at 8:09 AM, Ashta <sewashm at gmail.com> wrote:
>>> 
>>> I have a data set and I want to repeat a column value based on other
>>> column value,
>>> 
>>> my data look like
>>> 
>>> read.table(text = "Year month flag
>>> 2001 1   Z
>>> 2001 2   -
>>> 2001 4   X
>>> 2002 1   Z
>>> 2002 2   -
>>> 2003 1   -
>>> 2003 2   Z
>>> 2004 2   Z
>>> 2005 3   Z
>>> 2005 2   -
>>> 2005 3   -",  header = TRUE)
>>> 
>>> Within year If  flag = '-'  then i want replace  '-'  by the previous
>>> row value of flag. In this example  for yea  2001 in month 2 flag is
>>> '-' and I want replace it by the previous value of flag (i.e.,  'Z')
>>> 2001 1   Z
>>> 2001 2   Z
>>> 2001 4   X
>>> 
>>> If all values of flag  are '-' within year  then  I wan to set as N
>>> 
>>> The complete out put result will be
>>> 
>>> year month  flag
>>> 2001 1       Z
>>> 2001 2       z
>>> 2001 4       X
>>> 2002 1       Z
>>> 2002 2       Z
>>> 2003 1       Z
>>> 2003 2       Z
>>> 2004 2       Z
>>> 2005 3       Z
>>> 2005 2       N
>>> 2005 3       N
>>> 
>>> Thank you in advance
>>> 
>> 
>> Your example doesn't actually match your verbal description of the algorithm because you have not specified the rule that establishes values for instances where the first value in a year is "-".
>> 
>> The `na.locf` function in the 'zoo' package would be useful for the task describe in your verbal description when used in conjunction with the 'stats'-package's `ave` function.
>> 
>> --
>> David.
>> 
>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From sewashm at gmail.com  Sun Feb 26 01:36:35 2017
From: sewashm at gmail.com (Ashta)
Date: Sat, 25 Feb 2017 18:36:35 -0600
Subject: [R] Repeat
In-Reply-To: <666BAF47-9F9D-47F3-8E8F-FE7677C44E74@comcast.net>
References: <CADDFq320Xp=x51vaXt-2Pzp8h0XJTeUPDz5U5D2BJOvOCw1FLg@mail.gmail.com>
	<66B17F40-26AC-47D6-9C2F-639374F39DD1@comcast.net>
	<CADDFq31Di4R4vc0=taw6CUco1cC8dZx_nzVZL-EguShCYZHEnQ@mail.gmail.com>
	<666BAF47-9F9D-47F3-8E8F-FE7677C44E74@comcast.net>
Message-ID: <CADDFq30zdfJWQUCydiN+4P=iv2AkturcNkAGuukkJn9Xqs7+0A@mail.gmail.com>

Thank you so much David!

But if all element of a group has '-'  did not work. In this case year
2006 an example
If all values of flag  are '-' within year  then  I wan to set as N


dat=read.table(text = "Year month flag
2001 1   Z
2001 2   -
2001 4   X
2002 1   Z
2002 2   -
2003 1   -
2003 2   Z
2004 2   Z
2005 3   Z
2005 2   -
2005 3   -

2006 1   -
2006 2   - ",  header = TRUE)

dat$new <- with(dat, ave(flag, Year, FUN=function(s){ s[s=="-"] <- NA;
           zoo::na.locf(s) }) )

Error in `[<-.factor`(`*tmp*`, i, value = integer(0)) :
  replacement has length zero

On Sat, Feb 25, 2017 at 5:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Feb 25, 2017, at 10:45 AM, Ashta <sewashm at gmail.com> wrote:
>>
>> Thank you David.
>> is it not possible to sort it by year and flag so that we can make '-'
>> in the second row ?  like this for that particular year.
>>
>>   2003 2     Z
>>   2003 1      -
>>
>
> I was a bit surprised by the results of htis since I had assumed than an initial NA in a group would remain so, but apparently not:
>
> dat$new <- with(dat, ave(flag, Year, FUN=function(s){ s[s=="-"] <- NA; zoo::na.locf(s) }) )
>
>> dat
>    Year month flag new
> 1  2001     1    Z   Z
> 2  2001     2    -   Z
> 3  2001     4    X   X
> 4  2002     1    Z   Z
> 5  2002     2    -   Z
> 6  2003     1    -   Z
> 7  2003     2    Z   Z
> 8  2004     2    Z   Z
> 9  2005     3    Z   Z
> 10 2005     2    -   Z
> 11 2005     3    -   Z
>
> David.
>
>>
>>
>> On Sat, Feb 25, 2017 at 12:14 PM, David Winsemius
>> <dwinsemius at comcast.net> wrote:
>>>
>>>> On Feb 25, 2017, at 8:09 AM, Ashta <sewashm at gmail.com> wrote:
>>>>
>>>> I have a data set and I want to repeat a column value based on other
>>>> column value,
>>>>
>>>> my data look like
>>>>
>>>> read.table(text = "Year month flag
>>>> 2001 1   Z
>>>> 2001 2   -
>>>> 2001 4   X
>>>> 2002 1   Z
>>>> 2002 2   -
>>>> 2003 1   -
>>>> 2003 2   Z
>>>> 2004 2   Z
>>>> 2005 3   Z
>>>> 2005 2   -
>>>> 2005 3   -",  header = TRUE)
>>>>
>>>> Within year If  flag = '-'  then i want replace  '-'  by the previous
>>>> row value of flag. In this example  for yea  2001 in month 2 flag is
>>>> '-' and I want replace it by the previous value of flag (i.e.,  'Z')
>>>> 2001 1   Z
>>>> 2001 2   Z
>>>> 2001 4   X
>>>>
>>>> If all values of flag  are '-' within year  then  I wan to set as N
>>>>
>>>> The complete out put result will be
>>>>
>>>> year month  flag
>>>> 2001 1       Z
>>>> 2001 2       z
>>>> 2001 4       X
>>>> 2002 1       Z
>>>> 2002 2       Z
>>>> 2003 1       Z
>>>> 2003 2       Z
>>>> 2004 2       Z
>>>> 2005 3       Z
>>>> 2005 2       N
>>>> 2005 3       N
>>>>
>>>> Thank you in advance
>>>>
>>>
>>> Your example doesn't actually match your verbal description of the algorithm because you have not specified the rule that establishes values for instances where the first value in a year is "-".
>>>
>>> The `na.locf` function in the 'zoo' package would be useful for the task describe in your verbal description when used in conjunction with the 'stats'-package's `ave` function.
>>>
>>> --
>>> David.
>>>
>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Sun Feb 26 02:39:16 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 25 Feb 2017 17:39:16 -0800
Subject: [R] Repeat
In-Reply-To: <CADDFq30zdfJWQUCydiN+4P=iv2AkturcNkAGuukkJn9Xqs7+0A@mail.gmail.com>
References: <CADDFq320Xp=x51vaXt-2Pzp8h0XJTeUPDz5U5D2BJOvOCw1FLg@mail.gmail.com>
	<66B17F40-26AC-47D6-9C2F-639374F39DD1@comcast.net>
	<CADDFq31Di4R4vc0=taw6CUco1cC8dZx_nzVZL-EguShCYZHEnQ@mail.gmail.com>
	<666BAF47-9F9D-47F3-8E8F-FE7677C44E74@comcast.net>
	<CADDFq30zdfJWQUCydiN+4P=iv2AkturcNkAGuukkJn9Xqs7+0A@mail.gmail.com>
Message-ID: <B289AF6B-BC68-464B-8E21-62720756B36C@comcast.net>


> On Feb 25, 2017, at 4:36 PM, Ashta <sewashm at gmail.com> wrote:
> 
> Thank you so much David!
> 
> But if all element of a group has '-'  did not work. In this case year
> 2006 an example
> If all values of flag  are '-' within year  then  I wan to set as N

I don't see the difficulty (and your example did not provide a suitable platform for demonstration.)  Set the remaining dashes to "N". 



-- 
David.
> 
> 
> dat=read.table(text = "Year month flag
> 2001 1   Z
> 2001 2   -
> 2001 4   X
> 2002 1   Z
> 2002 2   -
> 2003 1   -
> 2003 2   Z
> 2004 2   Z
> 2005 3   Z
> 2005 2   -
> 2005 3   -
> 
> 2006 1   -
> 2006 2   - ",  header = TRUE)
> 
> dat$new <- with(dat, ave(flag, Year, FUN=function(s){ s[s=="-"] <- NA;
>           zoo::na.locf(s) }) )
> 
> Error in `[<-.factor`(`*tmp*`, i, value = integer(0)) :
>  replacement has length zero
> 
> On Sat, Feb 25, 2017 at 5:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Feb 25, 2017, at 10:45 AM, Ashta <sewashm at gmail.com> wrote:
>>> 
>>> Thank you David.
>>> is it not possible to sort it by year and flag so that we can make '-'
>>> in the second row ?  like this for that particular year.
>>> 
>>>  2003 2     Z
>>>  2003 1      -
>>> 
>> 
>> I was a bit surprised by the results of htis since I had assumed than an initial NA in a group would remain so, but apparently not:
>> 
>> dat$new <- with(dat, ave(flag, Year, FUN=function(s){ s[s=="-"] <- NA; zoo::na.locf(s) }) )
>> 
>>> dat
>>   Year month flag new
>> 1  2001     1    Z   Z
>> 2  2001     2    -   Z
>> 3  2001     4    X   X
>> 4  2002     1    Z   Z
>> 5  2002     2    -   Z
>> 6  2003     1    -   Z
>> 7  2003     2    Z   Z
>> 8  2004     2    Z   Z
>> 9  2005     3    Z   Z
>> 10 2005     2    -   Z
>> 11 2005     3    -   Z
>> 
>> David.
>> 
>>> 
>>> 
>>> On Sat, Feb 25, 2017 at 12:14 PM, David Winsemius
>>> <dwinsemius at comcast.net> wrote:
>>>> 
>>>>> On Feb 25, 2017, at 8:09 AM, Ashta <sewashm at gmail.com> wrote:
>>>>> 
>>>>> I have a data set and I want to repeat a column value based on other
>>>>> column value,
>>>>> 
>>>>> my data look like
>>>>> 
>>>>> read.table(text = "Year month flag
>>>>> 2001 1   Z
>>>>> 2001 2   -
>>>>> 2001 4   X
>>>>> 2002 1   Z
>>>>> 2002 2   -
>>>>> 2003 1   -
>>>>> 2003 2   Z
>>>>> 2004 2   Z
>>>>> 2005 3   Z
>>>>> 2005 2   -
>>>>> 2005 3   -",  header = TRUE)
>>>>> 
>>>>> Within year If  flag = '-'  then i want replace  '-'  by the previous
>>>>> row value of flag. In this example  for yea  2001 in month 2 flag is
>>>>> '-' and I want replace it by the previous value of flag (i.e.,  'Z')
>>>>> 2001 1   Z
>>>>> 2001 2   Z
>>>>> 2001 4   X
>>>>> 
>>>>> If all values of flag  are '-' within year  then  I wan to set as N
>>>>> 
>>>>> The complete out put result will be
>>>>> 
>>>>> year month  flag
>>>>> 2001 1       Z
>>>>> 2001 2       z
>>>>> 2001 4       X
>>>>> 2002 1       Z
>>>>> 2002 2       Z
>>>>> 2003 1       Z
>>>>> 2003 2       Z
>>>>> 2004 2       Z
>>>>> 2005 3       Z
>>>>> 2005 2       N
>>>>> 2005 3       N
>>>>> 
>>>>> Thank you in advance
>>>>> 
>>>> 
>>>> Your example doesn't actually match your verbal description of the algorithm because you have not specified the rule that establishes values for instances where the first value in a year is "-".
>>>> 
>>>> The `na.locf` function in the 'zoo' package would be useful for the task describe in your verbal description when used in conjunction with the 'stats'-package's `ave` function.
>>>> 
>>>> --
>>>> David.
>>>> 
>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From roslinaump at gmail.com  Sun Feb 26 08:23:30 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Sun, 26 Feb 2017 15:23:30 +0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
Message-ID: <CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>

Hi William,

Thank you so much for your reply.

However, I still got error message:

> data.dump(oldStyle=TRUE)
Error: could not find function "data.dump"
> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
Error: could not find function "data.restore"

Thank you.



On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com> wrote:

> The sdd file extension may mean that the file is in S+ 'data dump' format,
> made by S+'s data.dump function and readable in S+ by its data.restore
> function.
> foreign::data.restore can read some such files in R, but I think it
> may only read well
> those with using the pre-1991 format made in more recent versions of
> S+ with data.dump(old.style=TRUE).
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
> > Dear r-users,
> >
> > I would like to read S-Plus data (.ssd) into R.  I tried this:
> >
> > library(foreign)
> > read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >
> > and got this message:
> >
> > read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> > Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
> >   not an S object
> >
> > What is wrong with this?  Thank you so much for your help.
> >
> > --
> > *Roslinazairimah Zakaria*
> > *Tel: +609-5492370; Fax. No.+609-5492766*
> >
> > *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> > roslinaump at gmail.com <roslinaump at gmail.com>*
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From vodvos at zoho.com  Sun Feb 26 08:51:28 2017
From: vodvos at zoho.com (vod vos)
Date: Sat, 25 Feb 2017 23:51:28 -0800
Subject: [R] Why the slope and intercept of 95% CI varies at each
 calculation when using package mcr?
Message-ID: <15a796728b7.127800b4115462.7580069737264925530@zoho.com>


Hi Everybody,

aa<- c(1,5,10,20,50,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000)
bb<- c(8,16,30,24,39,54,40,68,72,62,122,80,181,259,275,380,320,434,479,587,626,648,738,766,793,851,871,957,1001,960)

library(mcr)

pbreg<- mcreg(aa,bb, method.reg = "PaBa")

pbreg at para

               EST SE       LCI       UCI
Intercept 7.081869 NA -2.824761 20.169193
Slope     1.055312 NA  1.024968  1.096982

but when you calculate again, 

pbreg<- mcreg(aa,bb, method.reg = "PaBa")

pbreg at para

               EST SE       LCI       UCI
Intercept 7.081869 NA -1.834744 20.598912
Slope     1.055312 NA  1.025339  1.095888

pbreg at para show different values of LCI and UCI compared to the first time,  how does this happen?

Thanks.


From ruipbarradas at sapo.pt  Sun Feb 26 11:54:10 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 26 Feb 2017 10:54:10 +0000
Subject: [R] Why the slope and intercept of 95% CI varies at each
 calculation when using package mcr?
In-Reply-To: <15a796728b7.127800b4115462.7580069737264925530@zoho.com>
References: <15a796728b7.127800b4115462.7580069737264925530@zoho.com>
Message-ID: <58B2B3D2.3040908@sapo.pt>

Hello,

I know nothing about package mcr but by reading the help page for 
function mcreg I conclude that CI's are calculated using a bootstrap 
resampling technique and therefore you should expect different values 
every time the function runs unless you set the random generator seed 
using ?set.seed.

Hope this helps,

Rui Barradas

Em 26-02-2017 07:51, vod vos escreveu:
>
> Hi Everybody,
>
> aa<- c(1,5,10,20,50,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000)
> bb<- c(8,16,30,24,39,54,40,68,72,62,122,80,181,259,275,380,320,434,479,587,626,648,738,766,793,851,871,957,1001,960)
>
> library(mcr)
>
> pbreg<- mcreg(aa,bb, method.reg = "PaBa")
>
> pbreg at para
>
>                 EST SE       LCI       UCI
> Intercept 7.081869 NA -2.824761 20.169193
> Slope     1.055312 NA  1.024968  1.096982
>
> but when you calculate again,
>
> pbreg<- mcreg(aa,bb, method.reg = "PaBa")
>
> pbreg at para
>
>                 EST SE       LCI       UCI
> Intercept 7.081869 NA -1.834744 20.598912
> Slope     1.055312 NA  1.025339  1.095888
>
> pbreg at para show different values of LCI and UCI compared to the first time,  how does this happen?
>
> Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Sun Feb 26 11:57:27 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 26 Feb 2017 11:57:27 +0100
Subject: [R] Why the slope and intercept of 95% CI varies at each
	calculation when using package mcr?
In-Reply-To: <15a796728b7.127800b4115462.7580069737264925530@zoho.com>
References: <15a796728b7.127800b4115462.7580069737264925530@zoho.com>
Message-ID: <65AC7D75-B64D-41EE-B2C7-0EAF19CB198A@gmail.com>

Because they are bootstrap based.

-pd

> On 26 Feb 2017, at 08:51 , vod vos <vodvos at zoho.com> wrote:
> 
> 
> Hi Everybody,
> 
> aa<- c(1,5,10,20,50,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000)
> bb<- c(8,16,30,24,39,54,40,68,72,62,122,80,181,259,275,380,320,434,479,587,626,648,738,766,793,851,871,957,1001,960)
> 
> library(mcr)
> 
> pbreg<- mcreg(aa,bb, method.reg = "PaBa")
> 
> pbreg at para
> 
>               EST SE       LCI       UCI
> Intercept 7.081869 NA -2.824761 20.169193
> Slope     1.055312 NA  1.024968  1.096982
> 
> but when you calculate again, 
> 
> pbreg<- mcreg(aa,bb, method.reg = "PaBa")
> 
> pbreg at para
> 
>               EST SE       LCI       UCI
> Intercept 7.081869 NA -1.834744 20.598912
> Slope     1.055312 NA  1.025339  1.095888
> 
> pbreg at para show different values of LCI and UCI compared to the first time,  how does this happen?
> 
> Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From thpe at simecol.de  Sun Feb 26 12:48:06 2017
From: thpe at simecol.de (Thomas Petzoldt)
Date: Sun, 26 Feb 2017 12:48:06 +0100
Subject: [R] Differential equations
In-Reply-To: <ABCDAEC0-39D6-49D1-A522-5F0F13DEB4E3@gmail.com>
References: <CANSOPkWbR5rzOs_+-pMZPz7QAmbdhjH2bkahRBrOXvds9e-4ow@mail.gmail.com>
	<ABCDAEC0-39D6-49D1-A522-5F0F13DEB4E3@gmail.com>
Message-ID: <bfc97602-8b2a-135b-4b3a-9c1c08a4ee99@simecol.de>

Hi,

yes, the suggestion of Peter Dalgaard is correct, and it can also be 
done using the "event" mechanism of deSolve, see:

library("deSolve")
?events

... or the slides from our talk given at useR-2011

http://desolve.r-forge.r-project.org/slides/petz_soet2011.pdf

... or the tutorial from L.A.

http://desolve.r-forge.r-project.org/user2014/tutorial.pdf

Thomas Petzoldt

See also:

http://desolve.r-forge.r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-dynamic-models


Am 08.02.2017 um 16:19 schrieb peter dalgaard:
> It's been a while, but I think I have gotten through this sort of situation by splitting the integration into intervals, i.e., you run from t=0 to t=20 witn initial condition c(100,0), yielding a value c(y1,y2), then you run from 20 to 40 with initial condition c(y1+100, y2), etc.
>
> -pd
>
> On 08 Feb 2017, at 11:10 , Fanny Gallais <gallais.fanny at gmail.com> wrote:
>
>> Hi,
>>
>> I'm working on a system of 2 differential equations. My initial condition
>> (t=0) is c(100,0) and i'm using lsoda function (from package deSolve) to
>> solve it.
>> My system reprensents the evoution of drug concentration in two
>> compartments throug time. Problem is I would like to model a repeated drug
>> administration. That is to say, not only 100 at t=0 but also at t=20,40,...
>> I can't find a solution to do so. I tried adding "100" to the first
>> differential equation at the times of interest but it doesn't work. Do you
>> have any idea?
>>
>> Thank you
>> F.G.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From thpe at simecol.de  Sun Feb 26 12:55:59 2017
From: thpe at simecol.de (Thomas Petzoldt)
Date: Sun, 26 Feb 2017 12:55:59 +0100
Subject: [R] non-linear optimisation ODE models
In-Reply-To: <88737E56-C873-4ACE-89A2-A63E27AE0382@comcast.net>
References: <264407025.8366931.1487154740852.ref@mail.yahoo.com>
	<264407025.8366931.1487154740852@mail.yahoo.com>
	<1A288236-78CC-4223-A0AC-DB42E65C2103@xs4all.nl>
	<CA+8X3fXg4nw+0DqrCQe9HpmT=XLQFnhe-jzQXVNFvCwfc2z5Ag@mail.gmail.com>
	<88737E56-C873-4ACE-89A2-A63E27AE0382@comcast.net>
Message-ID: <7b7a3d74-ab0d-9b3e-561b-92c69ce8727a@simecol.de>

Hi,

fitting ODE models may also be done with package FME, see:

Soetaert K, Petzoldt T. Inverse modelling, sensitivity and Monte Carlo 
analysis in R using package FME. Journal of Statistical Software. 
2010(33): 1?28. http://dx.doi.org/10.18637/jss.v033.i03

or the (interactive) poster at:

http://desolve.r-forge.r-project.org/user2014/examples/FME/fit_twocomp.svg

Regards,

Thomas P.


Am 16.02.2017 um 19:41 schrieb David Winsemius:
>
>> On Feb 15, 2017, at 1:43 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Malgorzata,
>> The function "rxnrate" seems to want three values in a list with the
>> names "k1", "k2" and "k3". If you are passing something with different
>> names, it is probably going to complain, so the names "A", "B" and "C"
>> may be your problem. I can't run the example, so this is a guess.
>
> There's a more readable version at:
> http://stackoverflow.com/questions/42256509/how-to-feed-data-into-ide-while-doing-optimisation
>
> It can be run, but does not produce the errors offered when I do so.
>


From lists at dewey.myzen.co.uk  Sun Feb 26 13:12:27 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 26 Feb 2017 12:12:27 +0000
Subject: [R] Reading S-plus data in R
In-Reply-To: <CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
Message-ID: <d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>

Did you do
library(foreign)
first?

On 26/02/2017 07:23, roslinazairimah zakaria wrote:
> Hi William,
>
> Thank you so much for your reply.
>
> However, I still got error message:
>
>> data.dump(oldStyle=TRUE)
> Error: could not find function "data.dump"
>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> Error: could not find function "data.restore"
>
> Thank you.
>
>
>
> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> The sdd file extension may mean that the file is in S+ 'data dump' format,
>> made by S+'s data.dump function and readable in S+ by its data.restore
>> function.
>> foreign::data.restore can read some such files in R, but I think it
>> may only read well
>> those with using the pre-1991 format made in more recent versions of
>> S+ with data.dump(old.style=TRUE).
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
>> <roslinaump at gmail.com> wrote:
>>> Dear r-users,
>>>
>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
>>>
>>> library(foreign)
>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>
>>> and got this message:
>>>
>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>>>   not an S object
>>>
>>> What is wrong with this?  Thank you so much for your help.
>>>
>>> --
>>> *Roslinazairimah Zakaria*
>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>
>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>> Faculty of Industrial Sciences & Technology
>>> University Malaysia Pahang
>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From roslinaump at gmail.com  Sun Feb 26 13:28:38 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Sun, 26 Feb 2017 20:28:38 +0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
Message-ID: <CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>

Hi Michael,

Yes, I did tried and still got error:


> library(foreign)

> data.dump(oldStyle=TRUE)
Error in eval(expr, envir, enclos) : could not find function "data.dump"
> source(.trPaths[5], echo=TRUE, max.deparse.length=150)

> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
Error in read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")) :
  not an S object

Thank you.

On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Did you do
> library(foreign)
> first?
>
>
> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
>
>> Hi William,
>>
>> Thank you so much for your reply.
>>
>> However, I still got error message:
>>
>> data.dump(oldStyle=TRUE)
>>>
>> Error: could not find function "data.dump"
>>
>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>
>> Error: could not find function "data.restore"
>>
>> Thank you.
>>
>>
>>
>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>
>> The sdd file extension may mean that the file is in S+ 'data dump' format,
>>> made by S+'s data.dump function and readable in S+ by its data.restore
>>> function.
>>> foreign::data.restore can read some such files in R, but I think it
>>> may only read well
>>> those with using the pre-1991 format made in more recent versions of
>>> S+ with data.dump(old.style=TRUE).
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
>>> <roslinaump at gmail.com> wrote:
>>>
>>>> Dear r-users,
>>>>
>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
>>>>
>>>> library(foreign)
>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>>
>>>> and got this message:
>>>>
>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>>>>   not an S object
>>>>
>>>> What is wrong with this?  Thank you so much for your help.
>>>>
>>>> --
>>>> *Roslinazairimah Zakaria*
>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>>
>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>> Faculty of Industrial Sciences & Technology
>>>> University Malaysia Pahang
>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>
>>> posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Feb 26 17:57:00 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 26 Feb 2017 08:57:00 -0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
	<CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
Message-ID: <CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>

You should be looking for foreign::data.restore, not data.dump nor read.S.

In any case, I think that foreign::data.restore does not recognize S-version4
data.dump files, ones whose first line is
  ## Dump S Version 4 Dump ##
Here is a quickly written and barely tested function that should read
data.frames
and other simple S+ objects in SV4 data.dump files.  It stores the
objects it reads
from the file 'file' in the environment 'env'.

data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
.GlobalEnv)
{
    if (!inherits(file, "connection")) {
        file <- file(file, "r")
        on.exit(close(file))
    }
    lineNo <- 0
    nextLine <- function(n = 1) {
        lineNo <<- lineNo + n
        readLines(file, n = n)
    }
    Message <- function(...) {
        if (verbose) {
            message(simpleMessage(paste("(line ", lineNo, ") ",
paste(..., collapse = " "), sep = ""), sys.call(-1)))
        }
    }
    Stop <- function(...) {
        stop(simpleError(paste(paste(..., collapse = " "), sep = "",
            " (file ", deparse(summary(file)$description), ", line ",
lineNo, ")"), sys.call(-1)))
    }
    txt <- nextLine()
    stopifnot(txt == "## Dump S Version 4 Dump ##")
    .data.restore4 <- function()
    {
        class <- nextLine()
        mode <- nextLine()
        length <- as.numeric(tmp <- nextLine())
        if (is.na(length) || length%%1 != 0 || length < 0) {
            Stop("Expected nonnegative integer 'length' at line ",
lineNo, " but got ", deparse(tmp))
        }
        if (mode == "character") {
            nextLine(length)
        } else if (mode == "logical") {
            txt <- nextLine(length)
            lglVector <- rep(NA, length)
            lglVector[txt != "N"] <- as.logical(as.integer(txt[txt != "N"]))
            lglVector
        } else if (mode %in% c("integer", "single", "numeric")) {
            txt <- nextLine(length)
            txt[txt == "M"] <- "NaN"
            txt[txt == "I"] <- "Inf"
            txt[txt == "J"] <- "-Inf"
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "complex") {
            txt <- nextLine(length)
            txt <- gsub("M", "NaN", txt)
            txt <- gsub("\\<I\\>", "Inf", txt)
            txt <- gsub("\\<J\\>", "-Inf", txt)
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "list") {
            vectors <- lapply(seq_len(length), function(i).data.restore4())
            vectors
        } else if (mode == "NULL") {
            NULL
        } else if (mode == "structure") {
            vectors <- lapply(seq_len(length), function(i).data.restore4())
            if (class == ".named_I" || class == "named") {
                if (length != 2) {
                    Stop("expected length of '.named_I' component is
2, but got ", length)
                } else if (length(vectors[[1]]) != length(vectors[[2]])) {
                    Stop("expected lengths of '.named_I' components to
be the same, but got ", length(vectors[[1]]), " and ",
length(vectors[[2]]))
                } else if (!is.character(vectors[[2]])) {
                    Stop("expected second component of '.named_I' to
be character, but got ", deparse(mode(vectors[[2]])))
                }
                names(vectors[[1]]) <- vectors[[2]]
                if (identical(vectors[[2]][1], ".Data")) { # a hack -
really want to know if vectors[[1] had mode "structure" or not
                    do.call(structure, vectors[[1]], quote = TRUE)
                } else {
                    vectors[[1]]
                }
            } else {
                vectors # TODO: is this ok?  It assumes that is within
a .Named_I/structure
            }
        } else if (mode == "name") {
            if (length != 1) {
                Stop("expected length of 'name' objects is 1, but got", length)
            }
            as.name(nextLine())
        } else if (mode == "call") {
            callList <- lapply(seq_len(length), function(i).data.restore4())
            as.call(callList)
        } else {
            Stop("Unimplemented mode: ", deparse(mode))
        }
    }
    while (length(objName <- nextLine()) == 1) {
        Message(objName, ": ")
        obj <- .data.restore4()
        Message("class ", deparse(class(obj)), ", size=",
object.size(obj), "\n")
        assign(objName, obj, envir=env)
    }
}



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Feb 26, 2017 at 4:28 AM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Hi Michael,
>
> Yes, I did tried and still got error:
>
>
>> library(foreign)
>
>> data.dump(oldStyle=TRUE)
> Error in eval(expr, envir, enclos) : could not find function "data.dump"
>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>
>> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
> Error in read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")) :
>   not an S object
>
> Thank you.
>
> On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
>>
>> Did you do
>> library(foreign)
>> first?
>>
>>
>> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
>>>
>>> Hi William,
>>>
>>> Thank you so much for your reply.
>>>
>>> However, I still got error message:
>>>
>>>> data.dump(oldStyle=TRUE)
>>>
>>> Error: could not find function "data.dump"
>>>>
>>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>
>>> Error: could not find function "data.restore"
>>>
>>> Thank you.
>>>
>>>
>>>
>>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com>
>>> wrote:
>>>
>>>> The sdd file extension may mean that the file is in S+ 'data dump'
>>>> format,
>>>> made by S+'s data.dump function and readable in S+ by its data.restore
>>>> function.
>>>> foreign::data.restore can read some such files in R, but I think it
>>>> may only read well
>>>> those with using the pre-1991 format made in more recent versions of
>>>> S+ with data.dump(old.style=TRUE).
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
>>>> <roslinaump at gmail.com> wrote:
>>>>>
>>>>> Dear r-users,
>>>>>
>>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
>>>>>
>>>>> library(foreign)
>>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>>>
>>>>> and got this message:
>>>>>
>>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>>>>>   not an S object
>>>>>
>>>>> What is wrong with this?  Thank you so much for your help.
>>>>>
>>>>> --
>>>>> *Roslinazairimah Zakaria*
>>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>>>
>>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>>> Faculty of Industrial Sciences & Technology
>>>>> University Malaysia Pahang
>>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>
>>>> posting-guide.html
>>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>>
>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>
>
>
>
> --
> Roslinazairimah Zakaria
> Tel: +609-5492370; Fax. No.+609-5492766
> Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
-------------- next part --------------
data.restore4 <- function(file, print = FALSE, verbose = FALSE, env = .GlobalEnv)
{
    if (!inherits(file, "connection")) {
        file <- file(file, "r")
        on.exit(close(file))
    }
    lineNo <- 0
    nextLine <- function(n = 1) {
        lineNo <<- lineNo + n
        readLines(file, n = n)
    }
    Message <- function(...) {
        if (verbose) {
            message(simpleMessage(paste("(line ", lineNo, ") ", paste(..., collapse = " "), sep = ""), sys.call(-1)))
        }
    }
    Stop <- function(...) {
        stop(simpleError(paste(paste(..., collapse = " "), sep = "",
            " (file ", deparse(summary(file)$description), ", line ", lineNo, ")"), sys.call(-1)))
    }
    txt <- nextLine()
    stopifnot(txt == "## Dump S Version 4 Dump ##")
    .data.restore4 <- function()
    {
        class <- nextLine()
        mode <- nextLine()
        length <- as.numeric(tmp <- nextLine())
        if (is.na(length) || length%%1 != 0 || length < 0) {
            Stop("Expected nonnegative integer 'length' at line ", lineNo, " but got ", deparse(tmp))
        }
        if (mode == "character") {
            nextLine(length)
        } else if (mode == "logical") {
            txt <- nextLine(length)
            lglVector <- rep(NA, length)
            lglVector[txt != "N"] <- as.logical(as.integer(txt[txt != "N"]))
            lglVector
        } else if (mode %in% c("integer", "single", "numeric")) {
            txt <- nextLine(length)
            txt[txt == "M"] <- "NaN"
            txt[txt == "I"] <- "Inf"
            txt[txt == "J"] <- "-Inf"
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "complex") {
            txt <- nextLine(length)
            txt <- gsub("M", "NaN", txt)
            txt <- gsub("\\<I\\>", "Inf", txt)
            txt <- gsub("\\<J\\>", "-Inf", txt)
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "list") {
            vectors <- lapply(seq_len(length), function(i).data.restore4())
            vectors
        } else if (mode == "NULL") {
            NULL
        } else if (mode == "structure") {
            vectors <- lapply(seq_len(length), function(i).data.restore4())
            if (class == ".named_I" || class == "named") {
                if (length != 2) {
                    Stop("expected length of '.named_I' component is 2, but got ", length)
                } else if (length(vectors[[1]]) != length(vectors[[2]])) {
                    Stop("expected lengths of '.named_I' components to be the same, but got ", length(vectors[[1]]), " and ", length(vectors[[2]]))
                } else if (!is.character(vectors[[2]])) {
                    Stop("expected second component of '.named_I' to be character, but got ", deparse(mode(vectors[[2]])))
                }
                names(vectors[[1]]) <- vectors[[2]]
                if (identical(vectors[[2]][1], ".Data")) { # a hack - really want to know if vectors[[1] had mode "structure" or not
                    do.call(structure, vectors[[1]], quote = TRUE)
                } else {
                    vectors[[1]]
                }
            } else {
                vectors # TODO: is this ok?  It assumes that is within a .Named_I/structure 
            }
        } else if (mode == "name") {
            if (length != 1) {
                Stop("expected length of 'name' objects is 1, but got", length)
            }
            as.name(nextLine())
        } else if (mode == "call") {
            callList <- lapply(seq_len(length), function(i).data.restore4())
            as.call(callList)
        } else {
            Stop("Unimplemented mode: ", deparse(mode))
        }
    }
    while (length(objName <- nextLine()) == 1) {
        Message(objName, ": ")
        obj <- .data.restore4()
        Message("class ", deparse(class(obj)), ", size=", object.size(obj), "\n")
        assign(objName, obj, envir=env)
    }
}

From allantanaka11 at yahoo.com  Sun Feb 26 16:24:08 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Sun, 26 Feb 2017 15:24:08 +0000 (UTC)
Subject: [R] order.by requires an appropriate time-based object
References: <377703184.1194921.1488122648612.ref@mail.yahoo.com>
Message-ID: <377703184.1194921.1488122648612@mail.yahoo.com>

HiNot sure why i get error like this:?Error in xts(forecasts, dates[(window.length):length(returns)]) :?? order.by requires an appropriate time-based object
I have researched for the answer that i need to convert returns into time series. I did that but still it doesn't work?See attached for file.Thanks
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: 111.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170226/408992f3/attachment.txt>

From rmh at temple.edu  Sun Feb 26 21:46:07 2017
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 26 Feb 2017 15:46:07 -0500
Subject: [R] Reading S-plus data in R
In-Reply-To: <CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
	<CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
	<CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
Message-ID: <CAGx1TMCi=_OFabhFhyH26i5eMa0byTLR8pGpN8jiWAE4hsGLoA@mail.gmail.com>

Bill,

this looks good.  Can you add it to the splus2R  package?

Rich


On Sun, Feb 26, 2017 at 11:57 AM, William Dunlap via R-help
<r-help at r-project.org> wrote:
> You should be looking for foreign::data.restore, not data.dump nor read.S.
>
> In any case, I think that foreign::data.restore does not recognize S-version4
> data.dump files, ones whose first line is
>   ## Dump S Version 4 Dump ##
> Here is a quickly written and barely tested function that should read
> data.frames
> and other simple S+ objects in SV4 data.dump files.  It stores the
> objects it reads
> from the file 'file' in the environment 'env'.
>
> data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
> .GlobalEnv)
> {
>     if (!inherits(file, "connection")) {
>         file <- file(file, "r")
>         on.exit(close(file))
>     }
>     lineNo <- 0
>     nextLine <- function(n = 1) {
>         lineNo <<- lineNo + n
>         readLines(file, n = n)
>     }
>     Message <- function(...) {
>         if (verbose) {
>             message(simpleMessage(paste("(line ", lineNo, ") ",
> paste(..., collapse = " "), sep = ""), sys.call(-1)))
>         }
>     }
>     Stop <- function(...) {
>         stop(simpleError(paste(paste(..., collapse = " "), sep = "",
>             " (file ", deparse(summary(file)$description), ", line ",
> lineNo, ")"), sys.call(-1)))
>     }
>     txt <- nextLine()
>     stopifnot(txt == "## Dump S Version 4 Dump ##")
>     .data.restore4 <- function()
>     {
>         class <- nextLine()
>         mode <- nextLine()
>         length <- as.numeric(tmp <- nextLine())
>         if (is.na(length) || length%%1 != 0 || length < 0) {
>             Stop("Expected nonnegative integer 'length' at line ",
> lineNo, " but got ", deparse(tmp))
>         }
>         if (mode == "character") {
>             nextLine(length)
>         } else if (mode == "logical") {
>             txt <- nextLine(length)
>             lglVector <- rep(NA, length)
>             lglVector[txt != "N"] <- as.logical(as.integer(txt[txt != "N"]))
>             lglVector
>         } else if (mode %in% c("integer", "single", "numeric")) {
>             txt <- nextLine(length)
>             txt[txt == "M"] <- "NaN"
>             txt[txt == "I"] <- "Inf"
>             txt[txt == "J"] <- "-Inf"
>             atomicVector <- rep(as(NA, mode), length)
>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>             atomicVector
>         } else if (mode == "complex") {
>             txt <- nextLine(length)
>             txt <- gsub("M", "NaN", txt)
>             txt <- gsub("\\<I\\>", "Inf", txt)
>             txt <- gsub("\\<J\\>", "-Inf", txt)
>             atomicVector <- rep(as(NA, mode), length)
>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>             atomicVector
>         } else if (mode == "list") {
>             vectors <- lapply(seq_len(length), function(i).data.restore4())
>             vectors
>         } else if (mode == "NULL") {
>             NULL
>         } else if (mode == "structure") {
>             vectors <- lapply(seq_len(length), function(i).data.restore4())
>             if (class == ".named_I" || class == "named") {
>                 if (length != 2) {
>                     Stop("expected length of '.named_I' component is
> 2, but got ", length)
>                 } else if (length(vectors[[1]]) != length(vectors[[2]])) {
>                     Stop("expected lengths of '.named_I' components to
> be the same, but got ", length(vectors[[1]]), " and ",
> length(vectors[[2]]))
>                 } else if (!is.character(vectors[[2]])) {
>                     Stop("expected second component of '.named_I' to
> be character, but got ", deparse(mode(vectors[[2]])))
>                 }
>                 names(vectors[[1]]) <- vectors[[2]]
>                 if (identical(vectors[[2]][1], ".Data")) { # a hack -
> really want to know if vectors[[1] had mode "structure" or not
>                     do.call(structure, vectors[[1]], quote = TRUE)
>                 } else {
>                     vectors[[1]]
>                 }
>             } else {
>                 vectors # TODO: is this ok?  It assumes that is within
> a .Named_I/structure
>             }
>         } else if (mode == "name") {
>             if (length != 1) {
>                 Stop("expected length of 'name' objects is 1, but got", length)
>             }
>             as.name(nextLine())
>         } else if (mode == "call") {
>             callList <- lapply(seq_len(length), function(i).data.restore4())
>             as.call(callList)
>         } else {
>             Stop("Unimplemented mode: ", deparse(mode))
>         }
>     }
>     while (length(objName <- nextLine()) == 1) {
>         Message(objName, ": ")
>         obj <- .data.restore4()
>         Message("class ", deparse(class(obj)), ", size=",
> object.size(obj), "\n")
>         assign(objName, obj, envir=env)
>     }
> }
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Sun, Feb 26, 2017 at 4:28 AM, roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
>> Hi Michael,
>>
>> Yes, I did tried and still got error:
>>
>>
>>> library(foreign)
>>
>>> data.dump(oldStyle=TRUE)
>> Error in eval(expr, envir, enclos) : could not find function "data.dump"
>>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>>
>>> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
>> Error in read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")) :
>>   not an S object
>>
>> Thank you.
>>
>> On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <lists at dewey.myzen.co.uk>
>> wrote:
>>>
>>> Did you do
>>> library(foreign)
>>> first?
>>>
>>>
>>> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
>>>>
>>>> Hi William,
>>>>
>>>> Thank you so much for your reply.
>>>>
>>>> However, I still got error message:
>>>>
>>>>> data.dump(oldStyle=TRUE)
>>>>
>>>> Error: could not find function "data.dump"
>>>>>
>>>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>>
>>>> Error: could not find function "data.restore"
>>>>
>>>> Thank you.
>>>>
>>>>
>>>>
>>>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com>
>>>> wrote:
>>>>
>>>>> The sdd file extension may mean that the file is in S+ 'data dump'
>>>>> format,
>>>>> made by S+'s data.dump function and readable in S+ by its data.restore
>>>>> function.
>>>>> foreign::data.restore can read some such files in R, but I think it
>>>>> may only read well
>>>>> those with using the pre-1991 format made in more recent versions of
>>>>> S+ with data.dump(old.style=TRUE).
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>
>>>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
>>>>> <roslinaump at gmail.com> wrote:
>>>>>>
>>>>>> Dear r-users,
>>>>>>
>>>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
>>>>>>
>>>>>> library(foreign)
>>>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>>>>
>>>>>> and got this message:
>>>>>>
>>>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>>>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>>>>>>   not an S object
>>>>>>
>>>>>> What is wrong with this?  Thank you so much for your help.
>>>>>>
>>>>>> --
>>>>>> *Roslinazairimah Zakaria*
>>>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>>>>>>
>>>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>>>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>>>>>> Faculty of Industrial Sciences & Technology
>>>>>> University Malaysia Pahang
>>>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>>
>>>>> posting-guide.html
>>>>>>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>
>>> --
>>> Michael
>>> http://www.dewey.myzen.co.uk/home.html
>>
>>
>>
>>
>> --
>> Roslinazairimah Zakaria
>> Tel: +609-5492370; Fax. No.+609-5492766
>> Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
>> Faculty of Industrial Sciences & Technology
>> University Malaysia Pahang
>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roslinaump at gmail.com  Mon Feb 27 00:47:25 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Mon, 27 Feb 2017 07:47:25 +0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
	<CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
	<CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
Message-ID: <CANTvJZLRE-jWyL3=+M6MbtE11ZX-2dvxpjEEza05XOkvVfdtFQ@mail.gmail.com>

Hi all,

Something is working but the data is NULL.

I tried this:

library(foreign)
> dt <- data.restore4("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> head(dt); tail(dt)
NULL
NULL


On Mon, Feb 27, 2017 at 12:57 AM, William Dunlap <wdunlap at tibco.com> wrote:

> You should be looking for foreign::data.restore, not data.dump nor read.S.
>
> In any case, I think that foreign::data.restore does not recognize
> S-version4
> data.dump files, ones whose first line is
>   ## Dump S Version 4 Dump ##
> Here is a quickly written and barely tested function that should read
> data.frames
> and other simple S+ objects in SV4 data.dump files.  It stores the
> objects it reads
> from the file 'file' in the environment 'env'.
>
> data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
> .GlobalEnv)
> {
>     if (!inherits(file, "connection")) {
>         file <- file(file, "r")
>         on.exit(close(file))
>     }
>     lineNo <- 0
>     nextLine <- function(n = 1) {
>         lineNo <<- lineNo + n
>         readLines(file, n = n)
>     }
>     Message <- function(...) {
>         if (verbose) {
>             message(simpleMessage(paste("(line ", lineNo, ") ",
> paste(..., collapse = " "), sep = ""), sys.call(-1)))
>         }
>     }
>     Stop <- function(...) {
>         stop(simpleError(paste(paste(..., collapse = " "), sep = "",
>             " (file ", deparse(summary(file)$description), ", line ",
> lineNo, ")"), sys.call(-1)))
>     }
>     txt <- nextLine()
>     stopifnot(txt == "## Dump S Version 4 Dump ##")
>     .data.restore4 <- function()
>     {
>         class <- nextLine()
>         mode <- nextLine()
>         length <- as.numeric(tmp <- nextLine())
>         if (is.na(length) || length%%1 != 0 || length < 0) {
>             Stop("Expected nonnegative integer 'length' at line ",
> lineNo, " but got ", deparse(tmp))
>         }
>         if (mode == "character") {
>             nextLine(length)
>         } else if (mode == "logical") {
>             txt <- nextLine(length)
>             lglVector <- rep(NA, length)
>             lglVector[txt != "N"] <- as.logical(as.integer(txt[txt !=
> "N"]))
>             lglVector
>         } else if (mode %in% c("integer", "single", "numeric")) {
>             txt <- nextLine(length)
>             txt[txt == "M"] <- "NaN"
>             txt[txt == "I"] <- "Inf"
>             txt[txt == "J"] <- "-Inf"
>             atomicVector <- rep(as(NA, mode), length)
>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>             atomicVector
>         } else if (mode == "complex") {
>             txt <- nextLine(length)
>             txt <- gsub("M", "NaN", txt)
>             txt <- gsub("\\<I\\>", "Inf", txt)
>             txt <- gsub("\\<J\\>", "-Inf", txt)
>             atomicVector <- rep(as(NA, mode), length)
>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>             atomicVector
>         } else if (mode == "list") {
>             vectors <- lapply(seq_len(length), function(i).data.restore4())
>             vectors
>         } else if (mode == "NULL") {
>             NULL
>         } else if (mode == "structure") {
>             vectors <- lapply(seq_len(length), function(i).data.restore4())
>             if (class == ".named_I" || class == "named") {
>                 if (length != 2) {
>                     Stop("expected length of '.named_I' component is
> 2, but got ", length)
>                 } else if (length(vectors[[1]]) != length(vectors[[2]])) {
>                     Stop("expected lengths of '.named_I' components to
> be the same, but got ", length(vectors[[1]]), " and ",
> length(vectors[[2]]))
>                 } else if (!is.character(vectors[[2]])) {
>                     Stop("expected second component of '.named_I' to
> be character, but got ", deparse(mode(vectors[[2]])))
>                 }
>                 names(vectors[[1]]) <- vectors[[2]]
>                 if (identical(vectors[[2]][1], ".Data")) { # a hack -
> really want to know if vectors[[1] had mode "structure" or not
>                     do.call(structure, vectors[[1]], quote = TRUE)
>                 } else {
>                     vectors[[1]]
>                 }
>             } else {
>                 vectors # TODO: is this ok?  It assumes that is within
> a .Named_I/structure
>             }
>         } else if (mode == "name") {
>             if (length != 1) {
>                 Stop("expected length of 'name' objects is 1, but got",
> length)
>             }
>             as.name(nextLine())
>         } else if (mode == "call") {
>             callList <- lapply(seq_len(length),
> function(i).data.restore4())
>             as.call(callList)
>         } else {
>             Stop("Unimplemented mode: ", deparse(mode))
>         }
>     }
>     while (length(objName <- nextLine()) == 1) {
>         Message(objName, ": ")
>         obj <- .data.restore4()
>         Message("class ", deparse(class(obj)), ", size=",
> object.size(obj), "\n")
>         assign(objName, obj, envir=env)
>     }
> }
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Sun, Feb 26, 2017 at 4:28 AM, roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
> > Hi Michael,
> >
> > Yes, I did tried and still got error:
> >
> >
> >> library(foreign)
> >
> >> data.dump(oldStyle=TRUE)
> > Error in eval(expr, envir, enclos) : could not find function "data.dump"
> >> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
> >
> >> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
> > Error in read.S(file.path("C:/Users/FTSI/Desktop/2
> ICGPA/1ACTIVITY.sdd")) :
> >   not an S object
> >
> > Thank you.
> >
> > On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> > wrote:
> >>
> >> Did you do
> >> library(foreign)
> >> first?
> >>
> >>
> >> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
> >>>
> >>> Hi William,
> >>>
> >>> Thank you so much for your reply.
> >>>
> >>> However, I still got error message:
> >>>
> >>>> data.dump(oldStyle=TRUE)
> >>>
> >>> Error: could not find function "data.dump"
> >>>>
> >>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >>>
> >>> Error: could not find function "data.restore"
> >>>
> >>> Thank you.
> >>>
> >>>
> >>>
> >>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com>
> >>> wrote:
> >>>
> >>>> The sdd file extension may mean that the file is in S+ 'data dump'
> >>>> format,
> >>>> made by S+'s data.dump function and readable in S+ by its data.restore
> >>>> function.
> >>>> foreign::data.restore can read some such files in R, but I think it
> >>>> may only read well
> >>>> those with using the pre-1991 format made in more recent versions of
> >>>> S+ with data.dump(old.style=TRUE).
> >>>> Bill Dunlap
> >>>> TIBCO Software
> >>>> wdunlap tibco.com
> >>>>
> >>>>
> >>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
> >>>> <roslinaump at gmail.com> wrote:
> >>>>>
> >>>>> Dear r-users,
> >>>>>
> >>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
> >>>>>
> >>>>> library(foreign)
> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >>>>>
> >>>>> and got this message:
> >>>>>
> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
> >>>>>   not an S object
> >>>>>
> >>>>> What is wrong with this?  Thank you so much for your help.
> >>>>>
> >>>>> --
> >>>>> *Roslinazairimah Zakaria*
> >>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
> >>>>>
> >>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> >>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
> >>>>> Faculty of Industrial Sciences & Technology
> >>>>> University Malaysia Pahang
> >>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> >>>>
> >>>> posting-guide.html
> >>>>>
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>>
> >>>
> >>>
> >>
> >> --
> >> Michael
> >> http://www.dewey.myzen.co.uk/home.html
> >
> >
> >
> >
> > --
> > Roslinazairimah Zakaria
> > Tel: +609-5492370; Fax. No.+609-5492766
> > Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From eva.leunissen at gmail.com  Sun Feb 26 23:26:03 2017
From: eva.leunissen at gmail.com (Eva Maria Leunissen)
Date: Mon, 27 Feb 2017 11:26:03 +1300
Subject: [R] Theta in Negative binomial GAM
Message-ID: <CAFSxBJ7dpqL2yUWCbz2MQERu4ABcQp6NQz86YgruF8saN94J-w@mail.gmail.com>

Hi, I'm fitting a negative binomial GAM (using mgcv) to my data using
family=nb() so theta is estimated during the fitting process. When I then
extract this theta from the model and refit the same model with
family=negbin(theta) it gives a much lower AIC. I know using AIC to compare
negative binomial models should be done with caution (
http://r.789695.n4.nabble.com/How-to-compare-GLM-and-GAM-models-tt827923.html#a827926)
but approximately it is ok. My questions are:

Is it better to do model selection with nb() or with negbin and a known
theta. if the latter how do you know what theta is?

can you compare models using AIC if the theta is different for each model?

Thanks in advance, any help is much appreciated

Kind regards,

Eva Leunissen

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Feb 27 03:41:44 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 26 Feb 2017 18:41:44 -0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CANTvJZLRE-jWyL3=+M6MbtE11ZX-2dvxpjEEza05XOkvVfdtFQ@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
	<CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
	<CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
	<CANTvJZLRE-jWyL3=+M6MbtE11ZX-2dvxpjEEza05XOkvVfdtFQ@mail.gmail.com>
Message-ID: <CAF8bMcbsbDyN=asc7dRWrU7=LidewjBhU9bFYdcEWvkLP07XEQ@mail.gmail.com>

> It stores the objects it reads from the file 'file' in the environment 'env'.
>
> data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
.GlobalEnv)

It returns NULL.  foreign::data.restore() returns the 'file' argument
and I should have copied that behavior (even though it is not very
useful).  You can use verbose=TRUE to have it print the names of what
it found in the file.

Use it as
   data.restore4("yourFile.sdd", verbose=TRUE, env = SplusDataEnv <- new.env())
Then objects(SplusDataEnv) will list what in the file and
SplusDataEnv[["name"]] with get the dataset "name" from the file.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Feb 26, 2017 at 3:47 PM, roslinazairimah zakaria
<roslinaump at gmail.com> wrote:
> Hi all,
>
> Something is working but the data is NULL.
>
> I tried this:
>
> library(foreign)
>> dt <- data.restore4("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> head(dt); tail(dt)
> NULL
> NULL
>
>
> On Mon, Feb 27, 2017 at 12:57 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> You should be looking for foreign::data.restore, not data.dump nor read.S.
>>
>> In any case, I think that foreign::data.restore does not recognize
>> S-version4
>> data.dump files, ones whose first line is
>>   ## Dump S Version 4 Dump ##
>> Here is a quickly written and barely tested function that should read
>> data.frames
>> and other simple S+ objects in SV4 data.dump files.  It stores the
>> objects it reads
>> from the file 'file' in the environment 'env'.
>>
>> data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
>> .GlobalEnv)
>> {
>>     if (!inherits(file, "connection")) {
>>         file <- file(file, "r")
>>         on.exit(close(file))
>>     }
>>     lineNo <- 0
>>     nextLine <- function(n = 1) {
>>         lineNo <<- lineNo + n
>>         readLines(file, n = n)
>>     }
>>     Message <- function(...) {
>>         if (verbose) {
>>             message(simpleMessage(paste("(line ", lineNo, ") ",
>> paste(..., collapse = " "), sep = ""), sys.call(-1)))
>>         }
>>     }
>>     Stop <- function(...) {
>>         stop(simpleError(paste(paste(..., collapse = " "), sep = "",
>>             " (file ", deparse(summary(file)$description), ", line ",
>> lineNo, ")"), sys.call(-1)))
>>     }
>>     txt <- nextLine()
>>     stopifnot(txt == "## Dump S Version 4 Dump ##")
>>     .data.restore4 <- function()
>>     {
>>         class <- nextLine()
>>         mode <- nextLine()
>>         length <- as.numeric(tmp <- nextLine())
>>         if (is.na(length) || length%%1 != 0 || length < 0) {
>>             Stop("Expected nonnegative integer 'length' at line ",
>> lineNo, " but got ", deparse(tmp))
>>         }
>>         if (mode == "character") {
>>             nextLine(length)
>>         } else if (mode == "logical") {
>>             txt <- nextLine(length)
>>             lglVector <- rep(NA, length)
>>             lglVector[txt != "N"] <- as.logical(as.integer(txt[txt !=
>> "N"]))
>>             lglVector
>>         } else if (mode %in% c("integer", "single", "numeric")) {
>>             txt <- nextLine(length)
>>             txt[txt == "M"] <- "NaN"
>>             txt[txt == "I"] <- "Inf"
>>             txt[txt == "J"] <- "-Inf"
>>             atomicVector <- rep(as(NA, mode), length)
>>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>>             atomicVector
>>         } else if (mode == "complex") {
>>             txt <- nextLine(length)
>>             txt <- gsub("M", "NaN", txt)
>>             txt <- gsub("\\<I\\>", "Inf", txt)
>>             txt <- gsub("\\<J\\>", "-Inf", txt)
>>             atomicVector <- rep(as(NA, mode), length)
>>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>>             atomicVector
>>         } else if (mode == "list") {
>>             vectors <- lapply(seq_len(length),
>> function(i).data.restore4())
>>             vectors
>>         } else if (mode == "NULL") {
>>             NULL
>>         } else if (mode == "structure") {
>>             vectors <- lapply(seq_len(length),
>> function(i).data.restore4())
>>             if (class == ".named_I" || class == "named") {
>>                 if (length != 2) {
>>                     Stop("expected length of '.named_I' component is
>> 2, but got ", length)
>>                 } else if (length(vectors[[1]]) != length(vectors[[2]])) {
>>                     Stop("expected lengths of '.named_I' components to
>> be the same, but got ", length(vectors[[1]]), " and ",
>> length(vectors[[2]]))
>>                 } else if (!is.character(vectors[[2]])) {
>>                     Stop("expected second component of '.named_I' to
>> be character, but got ", deparse(mode(vectors[[2]])))
>>                 }
>>                 names(vectors[[1]]) <- vectors[[2]]
>>                 if (identical(vectors[[2]][1], ".Data")) { # a hack -
>> really want to know if vectors[[1] had mode "structure" or not
>>                     do.call(structure, vectors[[1]], quote = TRUE)
>>                 } else {
>>                     vectors[[1]]
>>                 }
>>             } else {
>>                 vectors # TODO: is this ok?  It assumes that is within
>> a .Named_I/structure
>>             }
>>         } else if (mode == "name") {
>>             if (length != 1) {
>>                 Stop("expected length of 'name' objects is 1, but got",
>> length)
>>             }
>>             as.name(nextLine())
>>         } else if (mode == "call") {
>>             callList <- lapply(seq_len(length),
>> function(i).data.restore4())
>>             as.call(callList)
>>         } else {
>>             Stop("Unimplemented mode: ", deparse(mode))
>>         }
>>     }
>>     while (length(objName <- nextLine()) == 1) {
>>         Message(objName, ": ")
>>         obj <- .data.restore4()
>>         Message("class ", deparse(class(obj)), ", size=",
>> object.size(obj), "\n")
>>         assign(objName, obj, envir=env)
>>     }
>> }
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Sun, Feb 26, 2017 at 4:28 AM, roslinazairimah zakaria
>> <roslinaump at gmail.com> wrote:
>> > Hi Michael,
>> >
>> > Yes, I did tried and still got error:
>> >
>> >
>> >> library(foreign)
>> >
>> >> data.dump(oldStyle=TRUE)
>> > Error in eval(expr, envir, enclos) : could not find function "data.dump"
>> >> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>> >
>> >> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
>> > Error in read.S(file.path("C:/Users/FTSI/Desktop/2
>> > ICGPA/1ACTIVITY.sdd")) :
>> >   not an S object
>> >
>> > Thank you.
>> >
>> > On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <lists at dewey.myzen.co.uk>
>> > wrote:
>> >>
>> >> Did you do
>> >> library(foreign)
>> >> first?
>> >>
>> >>
>> >> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
>> >>>
>> >>> Hi William,
>> >>>
>> >>> Thank you so much for your reply.
>> >>>
>> >>> However, I still got error message:
>> >>>
>> >>>> data.dump(oldStyle=TRUE)
>> >>>
>> >>> Error: could not find function "data.dump"
>> >>>>
>> >>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> >>>
>> >>> Error: could not find function "data.restore"
>> >>>
>> >>> Thank you.
>> >>>
>> >>>
>> >>>
>> >>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com>
>> >>> wrote:
>> >>>
>> >>>> The sdd file extension may mean that the file is in S+ 'data dump'
>> >>>> format,
>> >>>> made by S+'s data.dump function and readable in S+ by its
>> >>>> data.restore
>> >>>> function.
>> >>>> foreign::data.restore can read some such files in R, but I think it
>> >>>> may only read well
>> >>>> those with using the pre-1991 format made in more recent versions of
>> >>>> S+ with data.dump(old.style=TRUE).
>> >>>> Bill Dunlap
>> >>>> TIBCO Software
>> >>>> wdunlap tibco.com
>> >>>>
>> >>>>
>> >>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
>> >>>> <roslinaump at gmail.com> wrote:
>> >>>>>
>> >>>>> Dear r-users,
>> >>>>>
>> >>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
>> >>>>>
>> >>>>> library(foreign)
>> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> >>>>>
>> >>>>> and got this message:
>> >>>>>
>> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> >>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>> >>>>>   not an S object
>> >>>>>
>> >>>>> What is wrong with this?  Thank you so much for your help.
>> >>>>>
>> >>>>> --
>> >>>>> *Roslinazairimah Zakaria*
>> >>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>> >>>>>
>> >>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> >>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> >>>>> Faculty of Industrial Sciences & Technology
>> >>>>> University Malaysia Pahang
>> >>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> >>>>>
>> >>>>>         [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide http://www.R-project.org/
>> >>>>
>> >>>> posting-guide.html
>> >>>>>
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>>
>> >>>
>> >>>
>> >>>
>> >>
>> >> --
>> >> Michael
>> >> http://www.dewey.myzen.co.uk/home.html
>> >
>> >
>> >
>> >
>> > --
>> > Roslinazairimah Zakaria
>> > Tel: +609-5492370; Fax. No.+609-5492766
>> > Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
>> > Faculty of Industrial Sciences & Technology
>> > University Malaysia Pahang
>> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>
>
>
>
> --
> Roslinazairimah Zakaria
> Tel: +609-5492370; Fax. No.+609-5492766
> Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia


From josh.m.ulrich at gmail.com  Mon Feb 27 06:05:11 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 26 Feb 2017 23:05:11 -0600
Subject: [R] order.by requires an appropriate time-based object
In-Reply-To: <377703184.1194921.1488122648612@mail.yahoo.com>
References: <377703184.1194921.1488122648612.ref@mail.yahoo.com>
	<377703184.1194921.1488122648612@mail.yahoo.com>
Message-ID: <CAPPM_gQYFjxoJi+o9oWhf_1QggTDSpxMwD=0Y-eaGi=LVj-wCQ@mail.gmail.com>

Please provide a minimal, reproducible example.  It's really hard for
someone to help you if you give them nearly 100 lines of code and no
data.  My guess is that data[,1] is character (or factor) and you need
to convert it to Date or POSIXct.

On Sun, Feb 26, 2017 at 9:24 AM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> HiNot sure why i get error like this: Error in xts(forecasts, dates[(window.length):length(returns)]) :   order.by requires an appropriate time-based object
> I have researched for the answer that i need to convert returns into time series. I did that but still it doesn't work?See attached for file.Thanks
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From tanasa at gmail.com  Mon Feb 27 08:48:35 2017
From: tanasa at gmail.com (Bogdan Tanasa)
Date: Sun, 26 Feb 2017 23:48:35 -0800
Subject: [R] tutorials on bootstrap, jackknife, permutation,
	randomization tests
Message-ID: <CA+JEM01yh2oK4=neKkaYNgdvWtW15oV=2TmrnmC3pos57iZV=Q@mail.gmail.com>

Dear all,

please could anyone recommend a good website/resource describing tutorials
on bootstrap, jackknife, permutation, and randomization tests in R, with
applications to biology (molecular biology). thanks,

-- bogdan

	[[alternative HTML version deleted]]


From p_connolly at slingshot.co.nz  Mon Feb 27 09:29:51 2017
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Mon, 27 Feb 2017 21:29:51 +1300
Subject: [R] ASReml-R lack of documentation
Message-ID: <20170227082951.GA22242@slingshot.co.nz>

Has anyone had any success contacting VSNi, distributors of the
non-free R package ASReml-R?  I tried posting a question on their
forum page but the forum software seems to have a bug too.

So I tried emailing their support address but with no success.  If
anyone has had recent success with either, please let me know what you
did to achieve it.

Better still. if you have experience with predictions from
asreml.binomial models, I have a question about a possible bug if
you'd bee so kind.

TIA

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From Bernhard_Pfaff at fra.invesco.com  Mon Feb 27 09:47:17 2017
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Mon, 27 Feb 2017 08:47:17 +0000
Subject: [R] Impose Structure for Exogenous in vars Package
In-Reply-To: <CY1PR03MB222025A23EF461AACA4FA7F7E3530@CY1PR03MB2220.namprd03.prod.outlook.com>
References: <CY1PR03MB222025A23EF461AACA4FA7F7E3530@CY1PR03MB2220.namprd03.prod.outlook.com>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C712E97CA4D@GBLONXMB13.corp.amvescap.net>

Hi Andrew,

if I understand your question correctly, then you would like to place constraints for your exogenous variables in some VAR equations.
If so, please have a look at ?restrict.

As a toy example:

library(vars)
?restrict
data(Canada)
N <- nrow(Canada)
ExoVar <- matrix(runif(N))
colnames(ExoVar) <- "Exogenous"
mod <- VAR(Canada, exogen = ExoVar)
summary(mod)
summary(restrict(mod))

here, ExoVar will be removed given that the plain vanilla call to restrict() removes all variables with insignificant coeffiecients (|t-stat| < 2.0)   in a VAR equation. 
You can also provide a 'constraint' matrix for entering zero-constraints.

HTH,
Bernhard



-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Castro, Andrew William Keahi
Gesendet: Donnerstag, 23. Februar 2017 15:42
An: r-help at R-project.org
Betreff: [EXT] [R] Impose Structure for Exogenous in vars Package

Hello everyone,

I see there are structural VAR options in the vars package for the endogenous variables, but is there any easy way to impose structure on the exogenous variable matrix (notated as the matrix C on page 45 of https://cran.r-project.org/web/packages/vars/vars.pdf). Thanks!

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
*****************************************************************
Confidentiality Note: The information contained in this ...{{dropped:10}}


From simon.wood at bath.edu  Mon Feb 27 09:49:02 2017
From: simon.wood at bath.edu (Simon Wood)
Date: Mon, 27 Feb 2017 08:49:02 +0000
Subject: [R] Theta in Negative binomial GAM
In-Reply-To: <CAFSxBJ7dpqL2yUWCbz2MQERu4ABcQp6NQz86YgruF8saN94J-w@mail.gmail.com>
References: <CAFSxBJ7dpqL2yUWCbz2MQERu4ABcQp6NQz86YgruF8saN94J-w@mail.gmail.com>
Message-ID: <6a616919-c381-2d79-670a-b62385e34e63@bath.edu>

nb() will default to "REML" smoothing parameter estimation, while 
negbin() will default to "UBRE" unless you use the 'method="REML"' 
option to 'gam'. Using UBRE in place of REML may lead to differences in 
model fit, and will also mean that the AIC is not corrected for 
smoothing parameter uncertainty (this correction increases the AIC). You 
also expect AIC to drop by 2 or so, because negbin is treating theta as 
fixed.

So...

m <- gam(...,family=nb())

should give similar AIC values about 2 higher than

th1 <- m$family$getTheta(TRUE)
m1 <- gam(...,family=negbin(th1),method="REML")

If you don't know theta it is better to estimate it.

best,
Simon

ps. Tedious details of AIC smoothing uncertainty correction are in 
sections 4 and 5 of this:
http://amstat.tandfonline.com/doi/pdf/10.1080/01621459.2016.1180986

On 26/02/17 22:26, Eva Maria Leunissen wrote:
> Hi, I'm fitting a negative binomial GAM (using mgcv) to my data using
> family=nb() so theta is estimated during the fitting process. When I then
> extract this theta from the model and refit the same model with
> family=negbin(theta) it gives a much lower AIC. I know using AIC to compare
> negative binomial models should be done with caution (
> http://r.789695.n4.nabble.com/How-to-compare-GLM-and-GAM-models-tt827923.html#a827926)
> but approximately it is ok. My questions are:
>
> Is it better to do model selection with nb() or with negbin and a known
> theta. if the latter how do you know what theta is?
>
> can you compare models using AIC if the theta is different for each model?
>
> Thanks in advance, any help is much appreciated
>
> Kind regards,
>
> Eva Leunissen
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, School of Mathematics, University of Bristol BS8 1TW UK
+44 (0)117 33 18273     http://www.maths.bris.ac.uk/~sw15190


From bob at rud.is  Sun Feb 26 17:23:13 2017
From: bob at rud.is (Bob Rudis)
Date: Sun, 26 Feb 2017 11:23:13 -0500
Subject: [R] [R-pkgs] New package: hrbrthemes
Message-ID: <CAA-FpKUzpVd1_ccuoF0sCSpjWcmmE2fGJydD14fEyyv0bG3Zmw@mail.gmail.com>

Hey folks,

I'm pleased to announce the inaugural release of my hrbrthemes (0.1.0)
on CRAN: https://CRAN.R-project.org/package=hrbrthemes

The primary goal of said package is to provide opinionated
typographical and other aesthetic defaults for ggplot2 charts.

Two core themes are included:

- theme_ipsum() ? an Arial Narrow-based theme
- theme_ipsum_rc() ? a Roboto Condensed-based theme.

The Roboto Condensed Google Font comes with the package along with an
installer for said font.

Other niceties include:

- scale_[xy]_comma() ? shortcut for expand=c(0,0), labels=scales::comma
- scale_[xy]_percent() ? shortcut for expand=c(0,0), labels=scales::percent
- scale_[color|fill]_ipsum() ? discrete scale with 9 colors
- gg_check() ? pass-through spell checker for ggplot2 label elements

Source version is tracked on GitHub: https://github.com/hrbrmstr/hrbrthemes

Critiques, bug reports and enhancement requests are most welcome as
GitHub issues.

-Bob

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From tungakantarci at gmail.com  Mon Feb 27 13:07:50 2017
From: tungakantarci at gmail.com (=?UTF-8?Q?Tunga_Kantarc=C4=B1?=)
Date: Mon, 27 Feb 2017 13:07:50 +0100
Subject: [R] Selecting rows and columns of a data frame using relational
	operators
Message-ID: <CAMDpC=vy9y8jWu+nfnDvyqFsK3KSTra-+4V2ECaCncke3V67Pg@mail.gmail.com>

Consider a data frame named data. data contains 4 columns and 1000
rows. Say the aim is to bring together columns 1, 2, and 4, if the
values in column 4 is equal to 1. We could use the syntax

data(data[,4] == 1, c(1 2 4))

for this purpose. Suppose now that the aim is to bring together
columns 1, 2, and 4, if the values in column 4 is equal to 1, for the
first 20 rows of column 4. We could use the syntax

data(data[1:20,4] == 1, c(1 2 4))

for this purpose. However, this does not produce the desired result.
This is surprising at least for someone coming from MATLAB because
MATLAB produces what is desired.

Question 1: The code makes sense but why does it not produce what we
expect it to produce?

Question 2: What code is instead suitable?


From ulrik.stervbo at gmail.com  Mon Feb 27 13:25:55 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 27 Feb 2017 12:25:55 +0000
Subject: [R] Selecting rows and columns of a data frame using relational
	operators
In-Reply-To: <CAMDpC=vy9y8jWu+nfnDvyqFsK3KSTra-+4V2ECaCncke3V67Pg@mail.gmail.com>
References: <CAMDpC=vy9y8jWu+nfnDvyqFsK3KSTra-+4V2ECaCncke3V67Pg@mail.gmail.com>
Message-ID: <CAKVAULN_Wm-xZGF8DKmq1Rkzr5tag1DNbzN+c1mzmGi3M2vj2g@mail.gmail.com>

Hi Tunga,

The function subset() is probably what you are looking for. You might also
want to look at a tutorial to understand the R syntax.

In addition, calling your data data is not a good idea because of the name
clash with the function data().

Hope this helps,
Ulrik

On Mon, 27 Feb 2017 at 13:10 Tunga Kantarc? <tungakantarci at gmail.com> wrote:

> Consider a data frame named data. data contains 4 columns and 1000
> rows. Say the aim is to bring together columns 1, 2, and 4, if the
> values in column 4 is equal to 1. We could use the syntax
>
> data(data[,4] == 1, c(1 2 4))
>
> for this purpose. Suppose now that the aim is to bring together
> columns 1, 2, and 4, if the values in column 4 is equal to 1, for the
> first 20 rows of column 4. We could use the syntax
>
> data(data[1:20,4] == 1, c(1 2 4))
>
> for this purpose. However, this does not produce the desired result.
> This is surprising at least for someone coming from MATLAB because
> MATLAB produces what is desired.
>
> Question 1: The code makes sense but why does it not produce what we
> expect it to produce?
>
> Question 2: What code is instead suitable?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From erich.subs at neuwirth.priv.at  Mon Feb 27 13:30:07 2017
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Mon, 27 Feb 2017 13:30:07 +0100
Subject: [R] Selecting rows and columns of a data frame using relational
 operators
In-Reply-To: <CAMDpC=vy9y8jWu+nfnDvyqFsK3KSTra-+4V2ECaCncke3V67Pg@mail.gmail.com>
References: <CAMDpC=vy9y8jWu+nfnDvyqFsK3KSTra-+4V2ECaCncke3V67Pg@mail.gmail.com>
Message-ID: <E7F8ABBD-2AC4-48C8-BF67-EB6BA069A6FC@neuwirth.priv.at>

The answer is simple

data[,4] == 1 produces a logical vector of length nrow(data)
and the subsetting mechanism for data frames in R needs a vector of the same length 
as the data frame has rows.

data[1:20,4] == 1
produces a data frame of length 20, and if this is not the length of data.
So R applies its standard procedure, it repeats this vector as often as needed to get
a vector of length == nrow(data)


Th following code illustrates what is happening

data <- data.frame(x=rnorm(100),y=rnorm(100),z=rnorm(100),a=rep(c(1,2,1,2),c(2,48,2,48)))

vec1 <- data[,4]==1
vec2 <- data[1:20,4]==1


> On 27 Feb 2017, at 13:07, Tunga Kantarc? <tungakantarci at gmail.com> wrote:
> 
> Consider a data frame named data. data contains 4 columns and 1000
> rows. Say the aim is to bring together columns 1, 2, and 4, if the
> values in column 4 is equal to 1. We could use the syntax
> 
> data(data[,4] == 1, c(1 2 4))
> 
> for this purpose. Suppose now that the aim is to bring together
> columns 1, 2, and 4, if the values in column 4 is equal to 1, for the
> first 20 rows of column 4. We could use the syntax
> 
> data(data[1:20,4] == 1, c(1 2 4))
> 
> for this purpose. However, this does not produce the desired result.
> This is surprising at least for someone coming from MATLAB because
> MATLAB produces what is desired.
> 
> Question 1: The code makes sense but why does it not produce what we
> expect it to produce?
> 
> Question 2: What code is instead suitable?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Mon Feb 27 15:26:44 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 27 Feb 2017 08:26:44 -0600
Subject: [R] How to prune using a validation set
In-Reply-To: <mailman.3.1488106801.24386.r-help@r-project.org>
References: <mailman.3.1488106801.24386.r-help@r-project.org>
Message-ID: <f40b15$5tmksj@ironport10.mayo.edu>

You will need to give more detail of exactly what you mean by "prune using a validation 
set".  THe prune.rpart function will prune at any value you want, what I suspect you are 
looking for is to compute the error of each possible tree, using a validation data set, 
then find the best one, and then prune there.

How do you define "best"?

Terry Therneau


On 02/26/2017 05:00 AM, r-help-request at r-project.org wrote:
> I'd like to use a different data ( validation) set for pruning my
> classification tree. Unfortunately there aren't arguments to get this in
> prune.rpart().
>
> Any suggestions?
>
> Thanks!
>
> Alfredo
>


From roslinaump at gmail.com  Mon Feb 27 16:06:19 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Mon, 27 Feb 2017 23:06:19 +0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CAF8bMcbsbDyN=asc7dRWrU7=LidewjBhU9bFYdcEWvkLP07XEQ@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
	<CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
	<CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
	<CANTvJZLRE-jWyL3=+M6MbtE11ZX-2dvxpjEEza05XOkvVfdtFQ@mail.gmail.com>
	<CAF8bMcbsbDyN=asc7dRWrU7=LidewjBhU9bFYdcEWvkLP07XEQ@mail.gmail.com>
Message-ID: <CANTvJZKjMNQRj0QxV3+BQyk3qCDq19A845AjaQ6SoQBumcho_g@mail.gmail.com>

Hi Willianm,

Thank you. However, still null:

> library(foreign)
> dt <- data.restore4("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd",
verbose=TRUE, print=TRUE, env = SplusDataEnv <- new.env())
> SplusDataEnv[["dt"]]
NULL




On Mon, Feb 27, 2017 at 10:41 AM, William Dunlap <wdunlap at tibco.com> wrote:

> > It stores the objects it reads from the file 'file' in the environment
> 'env'.
> >
> > data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
> .GlobalEnv)
>
> It returns NULL.  foreign::data.restore() returns the 'file' argument
> and I should have copied that behavior (even though it is not very
> useful).  You can use verbose=TRUE to have it print the names of what
> it found in the file.
>
> Use it as
>    data.restore4("yourFile.sdd", verbose=TRUE, env = SplusDataEnv <-
> new.env())
> Then objects(SplusDataEnv) will list what in the file and
> SplusDataEnv[["name"]] with get the dataset "name" from the file.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Sun, Feb 26, 2017 at 3:47 PM, roslinazairimah zakaria
> <roslinaump at gmail.com> wrote:
> > Hi all,
> >
> > Something is working but the data is NULL.
> >
> > I tried this:
> >
> > library(foreign)
> >> dt <- data.restore4("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >> head(dt); tail(dt)
> > NULL
> > NULL
> >
> >
> > On Mon, Feb 27, 2017 at 12:57 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
> >>
> >> You should be looking for foreign::data.restore, not data.dump nor
> read.S.
> >>
> >> In any case, I think that foreign::data.restore does not recognize
> >> S-version4
> >> data.dump files, ones whose first line is
> >>   ## Dump S Version 4 Dump ##
> >> Here is a quickly written and barely tested function that should read
> >> data.frames
> >> and other simple S+ objects in SV4 data.dump files.  It stores the
> >> objects it reads
> >> from the file 'file' in the environment 'env'.
> >>
> >> data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
> >> .GlobalEnv)
> >> {
> >>     if (!inherits(file, "connection")) {
> >>         file <- file(file, "r")
> >>         on.exit(close(file))
> >>     }
> >>     lineNo <- 0
> >>     nextLine <- function(n = 1) {
> >>         lineNo <<- lineNo + n
> >>         readLines(file, n = n)
> >>     }
> >>     Message <- function(...) {
> >>         if (verbose) {
> >>             message(simpleMessage(paste("(line ", lineNo, ") ",
> >> paste(..., collapse = " "), sep = ""), sys.call(-1)))
> >>         }
> >>     }
> >>     Stop <- function(...) {
> >>         stop(simpleError(paste(paste(..., collapse = " "), sep = "",
> >>             " (file ", deparse(summary(file)$description), ", line ",
> >> lineNo, ")"), sys.call(-1)))
> >>     }
> >>     txt <- nextLine()
> >>     stopifnot(txt == "## Dump S Version 4 Dump ##")
> >>     .data.restore4 <- function()
> >>     {
> >>         class <- nextLine()
> >>         mode <- nextLine()
> >>         length <- as.numeric(tmp <- nextLine())
> >>         if (is.na(length) || length%%1 != 0 || length < 0) {
> >>             Stop("Expected nonnegative integer 'length' at line ",
> >> lineNo, " but got ", deparse(tmp))
> >>         }
> >>         if (mode == "character") {
> >>             nextLine(length)
> >>         } else if (mode == "logical") {
> >>             txt <- nextLine(length)
> >>             lglVector <- rep(NA, length)
> >>             lglVector[txt != "N"] <- as.logical(as.integer(txt[txt !=
> >> "N"]))
> >>             lglVector
> >>         } else if (mode %in% c("integer", "single", "numeric")) {
> >>             txt <- nextLine(length)
> >>             txt[txt == "M"] <- "NaN"
> >>             txt[txt == "I"] <- "Inf"
> >>             txt[txt == "J"] <- "-Inf"
> >>             atomicVector <- rep(as(NA, mode), length)
> >>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
> >>             atomicVector
> >>         } else if (mode == "complex") {
> >>             txt <- nextLine(length)
> >>             txt <- gsub("M", "NaN", txt)
> >>             txt <- gsub("\\<I\\>", "Inf", txt)
> >>             txt <- gsub("\\<J\\>", "-Inf", txt)
> >>             atomicVector <- rep(as(NA, mode), length)
> >>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
> >>             atomicVector
> >>         } else if (mode == "list") {
> >>             vectors <- lapply(seq_len(length),
> >> function(i).data.restore4())
> >>             vectors
> >>         } else if (mode == "NULL") {
> >>             NULL
> >>         } else if (mode == "structure") {
> >>             vectors <- lapply(seq_len(length),
> >> function(i).data.restore4())
> >>             if (class == ".named_I" || class == "named") {
> >>                 if (length != 2) {
> >>                     Stop("expected length of '.named_I' component is
> >> 2, but got ", length)
> >>                 } else if (length(vectors[[1]]) !=
> length(vectors[[2]])) {
> >>                     Stop("expected lengths of '.named_I' components to
> >> be the same, but got ", length(vectors[[1]]), " and ",
> >> length(vectors[[2]]))
> >>                 } else if (!is.character(vectors[[2]])) {
> >>                     Stop("expected second component of '.named_I' to
> >> be character, but got ", deparse(mode(vectors[[2]])))
> >>                 }
> >>                 names(vectors[[1]]) <- vectors[[2]]
> >>                 if (identical(vectors[[2]][1], ".Data")) { # a hack -
> >> really want to know if vectors[[1] had mode "structure" or not
> >>                     do.call(structure, vectors[[1]], quote = TRUE)
> >>                 } else {
> >>                     vectors[[1]]
> >>                 }
> >>             } else {
> >>                 vectors # TODO: is this ok?  It assumes that is within
> >> a .Named_I/structure
> >>             }
> >>         } else if (mode == "name") {
> >>             if (length != 1) {
> >>                 Stop("expected length of 'name' objects is 1, but got",
> >> length)
> >>             }
> >>             as.name(nextLine())
> >>         } else if (mode == "call") {
> >>             callList <- lapply(seq_len(length),
> >> function(i).data.restore4())
> >>             as.call(callList)
> >>         } else {
> >>             Stop("Unimplemented mode: ", deparse(mode))
> >>         }
> >>     }
> >>     while (length(objName <- nextLine()) == 1) {
> >>         Message(objName, ": ")
> >>         obj <- .data.restore4()
> >>         Message("class ", deparse(class(obj)), ", size=",
> >> object.size(obj), "\n")
> >>         assign(objName, obj, envir=env)
> >>     }
> >> }
> >>
> >>
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >>
> >> On Sun, Feb 26, 2017 at 4:28 AM, roslinazairimah zakaria
> >> <roslinaump at gmail.com> wrote:
> >> > Hi Michael,
> >> >
> >> > Yes, I did tried and still got error:
> >> >
> >> >
> >> >> library(foreign)
> >> >
> >> >> data.dump(oldStyle=TRUE)
> >> > Error in eval(expr, envir, enclos) : could not find function
> "data.dump"
> >> >> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
> >> >
> >> >> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
> >> > Error in read.S(file.path("C:/Users/FTSI/Desktop/2
> >> > ICGPA/1ACTIVITY.sdd")) :
> >> >   not an S object
> >> >
> >> > Thank you.
> >> >
> >> > On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <
> lists at dewey.myzen.co.uk>
> >> > wrote:
> >> >>
> >> >> Did you do
> >> >> library(foreign)
> >> >> first?
> >> >>
> >> >>
> >> >> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
> >> >>>
> >> >>> Hi William,
> >> >>>
> >> >>> Thank you so much for your reply.
> >> >>>
> >> >>> However, I still got error message:
> >> >>>
> >> >>>> data.dump(oldStyle=TRUE)
> >> >>>
> >> >>> Error: could not find function "data.dump"
> >> >>>>
> >> >>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >> >>>
> >> >>> Error: could not find function "data.restore"
> >> >>>
> >> >>> Thank you.
> >> >>>
> >> >>>
> >> >>>
> >> >>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com
> >
> >> >>> wrote:
> >> >>>
> >> >>>> The sdd file extension may mean that the file is in S+ 'data dump'
> >> >>>> format,
> >> >>>> made by S+'s data.dump function and readable in S+ by its
> >> >>>> data.restore
> >> >>>> function.
> >> >>>> foreign::data.restore can read some such files in R, but I think it
> >> >>>> may only read well
> >> >>>> those with using the pre-1991 format made in more recent versions
> of
> >> >>>> S+ with data.dump(old.style=TRUE).
> >> >>>> Bill Dunlap
> >> >>>> TIBCO Software
> >> >>>> wdunlap tibco.com
> >> >>>>
> >> >>>>
> >> >>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
> >> >>>> <roslinaump at gmail.com> wrote:
> >> >>>>>
> >> >>>>> Dear r-users,
> >> >>>>>
> >> >>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
> >> >>>>>
> >> >>>>> library(foreign)
> >> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >> >>>>>
> >> >>>>> and got this message:
> >> >>>>>
> >> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
> >> >>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
> >> >>>>>   not an S object
> >> >>>>>
> >> >>>>> What is wrong with this?  Thank you so much for your help.
> >> >>>>>
> >> >>>>> --
> >> >>>>> *Roslinazairimah Zakaria*
> >> >>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
> >> >>>>>
> >> >>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> >> >>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
> >> >>>>> Faculty of Industrial Sciences & Technology
> >> >>>>> University Malaysia Pahang
> >> >>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >> >>>>>
> >> >>>>>         [[alternative HTML version deleted]]
> >> >>>>>
> >> >>>>> ______________________________________________
> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> >> >>>>
> >> >>>> posting-guide.html
> >> >>>>>
> >> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >> >>>>
> >> >>>>
> >> >>>
> >> >>>
> >> >>>
> >> >>
> >> >> --
> >> >> Michael
> >> >> http://www.dewey.myzen.co.uk/home.html
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Roslinazairimah Zakaria
> >> > Tel: +609-5492370; Fax. No.+609-5492766
> >> > Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
> >> > Faculty of Industrial Sciences & Technology
> >> > University Malaysia Pahang
> >> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
> >
> >
> >
> >
> > --
> > Roslinazairimah Zakaria
> > Tel: +609-5492370; Fax. No.+609-5492766
> > Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
> > Faculty of Industrial Sciences & Technology
> > University Malaysia Pahang
> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From roslinaump at gmail.com  Mon Feb 27 16:13:36 2017
From: roslinaump at gmail.com (roslinazairimah zakaria)
Date: Mon, 27 Feb 2017 23:13:36 +0800
Subject: [R] Reading S-plus data in R
In-Reply-To: <CANTvJZKjMNQRj0QxV3+BQyk3qCDq19A845AjaQ6SoQBumcho_g@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
	<CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
	<CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
	<CANTvJZLRE-jWyL3=+M6MbtE11ZX-2dvxpjEEza05XOkvVfdtFQ@mail.gmail.com>
	<CAF8bMcbsbDyN=asc7dRWrU7=LidewjBhU9bFYdcEWvkLP07XEQ@mail.gmail.com>
	<CANTvJZKjMNQRj0QxV3+BQyk3qCDq19A845AjaQ6SoQBumcho_g@mail.gmail.com>
Message-ID: <CANTvJZ+0E0OSYiJDaszWOLiVV9CokBLWsa1_ZLXJ2LzS_ewPaw@mail.gmail.com>

Hi William,

I read again your message. Yes, finally, it works beautifully!  Thank you
so much.


## Import Data from S-Plus to R
library(foreign)
data.restore4("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd", verbose=TRUE,
print=TRUE, env = SplusDataEnv <- new.env())
objects(SplusDataEnv)
dt <- SplusDataEnv[["ACTIVITY"]]
head(dt); tail(dt)

Output:
> head(dt); tail(dt)
  ESTEEM CTPS   CS SSTWRES LLL MGMT.ENTRE VALUE.ETHICS LEADERSHIP
1    760    0 1820    1190 910          0         6260       2360
2   1640    0 2220     870 870          0         7020       5080
3    600    0  940     750 470          0         3460       1880
4   1200    0  480     400 160          0         1920       3440
5    160    0  240       0  40          0          120        240
6      0    0  400      80  80          0          560         80
     ESTEEM CTPS    CS SSTWRES  LLL MGMT.ENTRE VALUE.ETHICS LEADERSHIP
6989   2880 2280  7960    4000 2270       1960        11790       5760
6990   4280 4720 10000    1060 2330       2240         8230       7240
6991   5540 2620  6520    2400 1490       1140         9310      14180
6992   4520 3940 10280    5130 2450       3180         8340       5560
6993   7640 2260  4640    1000  770       1020         9730      22440
6994   4860 3940  8600    5140 2690       2380        14690      11700




##########################################################
data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
.GlobalEnv)
{
    if (!inherits(file, "connection")) {
        file <- file(file, "r")
        on.exit(close(file))
    }
    lineNo <- 0
    nextLine <- function(n = 1) {
        lineNo <<- lineNo + n
        readLines(file, n = n)
    }
    Message <- function(...) {
        if (verbose) {
            message(simpleMessage(paste("(line ", lineNo, ") ", paste(...,
collapse = " "), sep = ""), sys.call(-1)))
        }
    }
    Stop <- function(...) {
        stop(simpleError(paste(paste(..., collapse = " "), sep = "",
            " (file ", deparse(summary(file)$description), ", line ",
lineNo, ")"), sys.call(-1)))
    }
    txt <- nextLine()
    stopifnot(txt == "## Dump S Version 4 Dump ##")
    .data.restore4 <- function()
    {
        class <- nextLine()
        mode <- nextLine()
        length <- as.numeric(tmp <- nextLine())
        if (is.na(length) || length%%1 != 0 || length < 0) {
            Stop("Expected nonnegative integer 'length' at line ", lineNo,
" but got ", deparse(tmp))
        }
        if (mode == "character") {
            nextLine(length)
        } else if (mode == "logical") {
            txt <- nextLine(length)
            lglVector <- rep(NA, length)
            lglVector[txt != "N"] <- as.logical(as.integer(txt[txt != "N"]))
            lglVector
        } else if (mode %in% c("integer", "single", "numeric")) {
            txt <- nextLine(length)
            txt[txt == "M"] <- "NaN"
            txt[txt == "I"] <- "Inf"
            txt[txt == "J"] <- "-Inf"
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "complex") {
            txt <- nextLine(length)
            txt <- gsub("M", "NaN", txt)
            txt <- gsub("\\<I\\>", "Inf", txt)
            txt <- gsub("\\<J\\>", "-Inf", txt)
            atomicVector <- rep(as(NA, mode), length)
            atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
            atomicVector
        } else if (mode == "list") {
            vectors <- lapply(seq_len(length), function(i).data.restore4())
            vectors
        } else if (mode == "NULL") {
            NULL
        } else if (mode == "structure") {
            vectors <- lapply(seq_len(length), function(i).data.restore4())
            if (class == ".named_I" || class == "named") {
                if (length != 2) {
                    Stop("expected length of '.named_I' component is 2, but
got ", length)
                } else if (length(vectors[[1]]) != length(vectors[[2]])) {
                    Stop("expected lengths of '.named_I' components to be
the same, but got ", length(vectors[[1]]), " and ", length(vectors[[2]]))
                } else if (!is.character(vectors[[2]])) {
                    Stop("expected second component of '.named_I' to be
character, but got ", deparse(mode(vectors[[2]])))
                }
                names(vectors[[1]]) <- vectors[[2]]
                if (identical(vectors[[2]][1], ".Data")) { # a hack -
really want to know if vectors[[1] had mode "structure" or not
                    do.call(structure, vectors[[1]], quote = TRUE)
                } else {
                    vectors[[1]]
                }
            } else {
                vectors # TODO: is this ok?  It assumes that is within a
.Named_I/structure
            }
        } else if (mode == "name") {
            if (length != 1) {
                Stop("expected length of 'name' objects is 1, but got",
length)
            }
            as.name(nextLine())
        } else if (mode == "call") {
            callList <- lapply(seq_len(length), function(i).data.restore4())
            as.call(callList)
        } else {
            Stop("Unimplemented mode: ", deparse(mode))
        }
    }
    while (length(objName <- nextLine()) == 1) {
        Message(objName, ": ")
        obj <- .data.restore4()
        Message("class ", deparse(class(obj)), ", size=", object.size(obj),
"\n")
        assign(objName, obj, envir=env)
    }
}

On Mon, Feb 27, 2017 at 11:06 PM, roslinazairimah zakaria <
roslinaump at gmail.com> wrote:

> Hi Willianm,
>
> Thank you. However, still null:
>
> > library(foreign)
> > dt <- data.restore4("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd",
> verbose=TRUE, print=TRUE, env = SplusDataEnv <- new.env())
> > SplusDataEnv[["dt"]]
> NULL
>
>
>
>
> On Mon, Feb 27, 2017 at 10:41 AM, William Dunlap <wdunlap at tibco.com>
> wrote:
>
>> > It stores the objects it reads from the file 'file' in the environment
>> 'env'.
>> >
>> > data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
>> .GlobalEnv)
>>
>> It returns NULL.  foreign::data.restore() returns the 'file' argument
>> and I should have copied that behavior (even though it is not very
>> useful).  You can use verbose=TRUE to have it print the names of what
>> it found in the file.
>>
>> Use it as
>>    data.restore4("yourFile.sdd", verbose=TRUE, env = SplusDataEnv <-
>> new.env())
>> Then objects(SplusDataEnv) will list what in the file and
>> SplusDataEnv[["name"]] with get the dataset "name" from the file.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Sun, Feb 26, 2017 at 3:47 PM, roslinazairimah zakaria
>> <roslinaump at gmail.com> wrote:
>> > Hi all,
>> >
>> > Something is working but the data is NULL.
>> >
>> > I tried this:
>> >
>> > library(foreign)
>> >> dt <- data.restore4("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> >> head(dt); tail(dt)
>> > NULL
>> > NULL
>> >
>> >
>> > On Mon, Feb 27, 2017 at 12:57 AM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>> >>
>> >> You should be looking for foreign::data.restore, not data.dump nor
>> read.S.
>> >>
>> >> In any case, I think that foreign::data.restore does not recognize
>> >> S-version4
>> >> data.dump files, ones whose first line is
>> >>   ## Dump S Version 4 Dump ##
>> >> Here is a quickly written and barely tested function that should read
>> >> data.frames
>> >> and other simple S+ objects in SV4 data.dump files.  It stores the
>> >> objects it reads
>> >> from the file 'file' in the environment 'env'.
>> >>
>> >> data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
>> >> .GlobalEnv)
>> >> {
>> >>     if (!inherits(file, "connection")) {
>> >>         file <- file(file, "r")
>> >>         on.exit(close(file))
>> >>     }
>> >>     lineNo <- 0
>> >>     nextLine <- function(n = 1) {
>> >>         lineNo <<- lineNo + n
>> >>         readLines(file, n = n)
>> >>     }
>> >>     Message <- function(...) {
>> >>         if (verbose) {
>> >>             message(simpleMessage(paste("(line ", lineNo, ") ",
>> >> paste(..., collapse = " "), sep = ""), sys.call(-1)))
>> >>         }
>> >>     }
>> >>     Stop <- function(...) {
>> >>         stop(simpleError(paste(paste(..., collapse = " "), sep = "",
>> >>             " (file ", deparse(summary(file)$description), ", line ",
>> >> lineNo, ")"), sys.call(-1)))
>> >>     }
>> >>     txt <- nextLine()
>> >>     stopifnot(txt == "## Dump S Version 4 Dump ##")
>> >>     .data.restore4 <- function()
>> >>     {
>> >>         class <- nextLine()
>> >>         mode <- nextLine()
>> >>         length <- as.numeric(tmp <- nextLine())
>> >>         if (is.na(length) || length%%1 != 0 || length < 0) {
>> >>             Stop("Expected nonnegative integer 'length' at line ",
>> >> lineNo, " but got ", deparse(tmp))
>> >>         }
>> >>         if (mode == "character") {
>> >>             nextLine(length)
>> >>         } else if (mode == "logical") {
>> >>             txt <- nextLine(length)
>> >>             lglVector <- rep(NA, length)
>> >>             lglVector[txt != "N"] <- as.logical(as.integer(txt[txt !=
>> >> "N"]))
>> >>             lglVector
>> >>         } else if (mode %in% c("integer", "single", "numeric")) {
>> >>             txt <- nextLine(length)
>> >>             txt[txt == "M"] <- "NaN"
>> >>             txt[txt == "I"] <- "Inf"
>> >>             txt[txt == "J"] <- "-Inf"
>> >>             atomicVector <- rep(as(NA, mode), length)
>> >>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>> >>             atomicVector
>> >>         } else if (mode == "complex") {
>> >>             txt <- nextLine(length)
>> >>             txt <- gsub("M", "NaN", txt)
>> >>             txt <- gsub("\\<I\\>", "Inf", txt)
>> >>             txt <- gsub("\\<J\\>", "-Inf", txt)
>> >>             atomicVector <- rep(as(NA, mode), length)
>> >>             atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
>> >>             atomicVector
>> >>         } else if (mode == "list") {
>> >>             vectors <- lapply(seq_len(length),
>> >> function(i).data.restore4())
>> >>             vectors
>> >>         } else if (mode == "NULL") {
>> >>             NULL
>> >>         } else if (mode == "structure") {
>> >>             vectors <- lapply(seq_len(length),
>> >> function(i).data.restore4())
>> >>             if (class == ".named_I" || class == "named") {
>> >>                 if (length != 2) {
>> >>                     Stop("expected length of '.named_I' component is
>> >> 2, but got ", length)
>> >>                 } else if (length(vectors[[1]]) !=
>> length(vectors[[2]])) {
>> >>                     Stop("expected lengths of '.named_I' components to
>> >> be the same, but got ", length(vectors[[1]]), " and ",
>> >> length(vectors[[2]]))
>> >>                 } else if (!is.character(vectors[[2]])) {
>> >>                     Stop("expected second component of '.named_I' to
>> >> be character, but got ", deparse(mode(vectors[[2]])))
>> >>                 }
>> >>                 names(vectors[[1]]) <- vectors[[2]]
>> >>                 if (identical(vectors[[2]][1], ".Data")) { # a hack -
>> >> really want to know if vectors[[1] had mode "structure" or not
>> >>                     do.call(structure, vectors[[1]], quote = TRUE)
>> >>                 } else {
>> >>                     vectors[[1]]
>> >>                 }
>> >>             } else {
>> >>                 vectors # TODO: is this ok?  It assumes that is within
>> >> a .Named_I/structure
>> >>             }
>> >>         } else if (mode == "name") {
>> >>             if (length != 1) {
>> >>                 Stop("expected length of 'name' objects is 1, but got",
>> >> length)
>> >>             }
>> >>             as.name(nextLine())
>> >>         } else if (mode == "call") {
>> >>             callList <- lapply(seq_len(length),
>> >> function(i).data.restore4())
>> >>             as.call(callList)
>> >>         } else {
>> >>             Stop("Unimplemented mode: ", deparse(mode))
>> >>         }
>> >>     }
>> >>     while (length(objName <- nextLine()) == 1) {
>> >>         Message(objName, ": ")
>> >>         obj <- .data.restore4()
>> >>         Message("class ", deparse(class(obj)), ", size=",
>> >> object.size(obj), "\n")
>> >>         assign(objName, obj, envir=env)
>> >>     }
>> >> }
>> >>
>> >>
>> >>
>> >> Bill Dunlap
>> >> TIBCO Software
>> >> wdunlap tibco.com
>> >>
>> >>
>> >> On Sun, Feb 26, 2017 at 4:28 AM, roslinazairimah zakaria
>> >> <roslinaump at gmail.com> wrote:
>> >> > Hi Michael,
>> >> >
>> >> > Yes, I did tried and still got error:
>> >> >
>> >> >
>> >> >> library(foreign)
>> >> >
>> >> >> data.dump(oldStyle=TRUE)
>> >> > Error in eval(expr, envir, enclos) : could not find function
>> "data.dump"
>> >> >> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>> >> >
>> >> >> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
>> >> > Error in read.S(file.path("C:/Users/FTSI/Desktop/2
>> >> > ICGPA/1ACTIVITY.sdd")) :
>> >> >   not an S object
>> >> >
>> >> > Thank you.
>> >> >
>> >> > On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <
>> lists at dewey.myzen.co.uk>
>> >> > wrote:
>> >> >>
>> >> >> Did you do
>> >> >> library(foreign)
>> >> >> first?
>> >> >>
>> >> >>
>> >> >> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
>> >> >>>
>> >> >>> Hi William,
>> >> >>>
>> >> >>> Thank you so much for your reply.
>> >> >>>
>> >> >>> However, I still got error message:
>> >> >>>
>> >> >>>> data.dump(oldStyle=TRUE)
>> >> >>>
>> >> >>> Error: could not find function "data.dump"
>> >> >>>>
>> >> >>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> >> >>>
>> >> >>> Error: could not find function "data.restore"
>> >> >>>
>> >> >>> Thank you.
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <
>> wdunlap at tibco.com>
>> >> >>> wrote:
>> >> >>>
>> >> >>>> The sdd file extension may mean that the file is in S+ 'data dump'
>> >> >>>> format,
>> >> >>>> made by S+'s data.dump function and readable in S+ by its
>> >> >>>> data.restore
>> >> >>>> function.
>> >> >>>> foreign::data.restore can read some such files in R, but I think
>> it
>> >> >>>> may only read well
>> >> >>>> those with using the pre-1991 format made in more recent versions
>> of
>> >> >>>> S+ with data.dump(old.style=TRUE).
>> >> >>>> Bill Dunlap
>> >> >>>> TIBCO Software
>> >> >>>> wdunlap tibco.com
>> >> >>>>
>> >> >>>>
>> >> >>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
>> >> >>>> <roslinaump at gmail.com> wrote:
>> >> >>>>>
>> >> >>>>> Dear r-users,
>> >> >>>>>
>> >> >>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
>> >> >>>>>
>> >> >>>>> library(foreign)
>> >> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> >> >>>>>
>> >> >>>>> and got this message:
>> >> >>>>>
>> >> >>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
>> >> >>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
>> >> >>>>>   not an S object
>> >> >>>>>
>> >> >>>>> What is wrong with this?  Thank you so much for your help.
>> >> >>>>>
>> >> >>>>> --
>> >> >>>>> *Roslinazairimah Zakaria*
>> >> >>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
>> >> >>>>>
>> >> >>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
>> >> >>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
>> >> >>>>> Faculty of Industrial Sciences & Technology
>> >> >>>>> University Malaysia Pahang
>> >> >>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> >> >>>>>
>> >> >>>>>         [[alternative HTML version deleted]]
>> >> >>>>>
>> >> >>>>> ______________________________________________
>> >> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> >> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>>>> PLEASE do read the posting guide http://www.R-project.org/
>> >> >>>>
>> >> >>>> posting-guide.html
>> >> >>>>>
>> >> >>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> >> >>>>
>> >> >>>>
>> >> >>>
>> >> >>>
>> >> >>>
>> >> >>
>> >> >> --
>> >> >> Michael
>> >> >> http://www.dewey.myzen.co.uk/home.html
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> > Roslinazairimah Zakaria
>> >> > Tel: +609-5492370; Fax. No.+609-5492766
>> >> > Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
>> >> > Faculty of Industrial Sciences & Technology
>> >> > University Malaysia Pahang
>> >> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>> >
>> >
>> >
>> >
>> > --
>> > Roslinazairimah Zakaria
>> > Tel: +609-5492370; Fax. No.+609-5492766
>> > Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
>> > Faculty of Industrial Sciences & Technology
>> > University Malaysia Pahang
>> > Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>>
>
>
>
> --
> *Roslinazairimah Zakaria*
> *Tel: +609-5492370 <+60%209-549%202370>; Fax. No.+609-5492766
> <+60%209-549%202766>*
>
> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
> roslinaump at gmail.com <roslinaump at gmail.com>*
> Faculty of Industrial Sciences & Technology
> University Malaysia Pahang
> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
>



-- 
*Roslinazairimah Zakaria*
*Tel: +609-5492370; Fax. No.+609-5492766*

*Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
roslinaump at gmail.com <roslinaump at gmail.com>*
Faculty of Industrial Sciences & Technology
University Malaysia Pahang
Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Feb 27 16:14:11 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 27 Feb 2017 15:14:11 +0000
Subject: [R] Selecting rows and columns of a data frame using relational
 operators
In-Reply-To: <E7F8ABBD-2AC4-48C8-BF67-EB6BA069A6FC@neuwirth.priv.at>
References: <CAMDpC=vy9y8jWu+nfnDvyqFsK3KSTra-+4V2ECaCncke3V67Pg@mail.gmail.com>
	<E7F8ABBD-2AC4-48C8-BF67-EB6BA069A6FC@neuwirth.priv.at>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A17EAE@SRVEXCHCM301.precheza.cz>

Hi

Above what was said

data(data[,4] == 1, c(1 2 4))
Error: unexpected numeric constant in "data(data[,4] == 1, c(1 2"

is not valid syntax as it assume that data is a function and c(1 2 4) is also not correct syntax (I wonder if commands in MATLAB are such free form).

And I am a little puzzled what means to bring 3 columns together. Calculate sum? Paste respective values in mentioned 3 columns.

Anyway, if you want to select only first n rows you should use something like

data[1:20,][data[1:20,4]==1,c(1,2,4)]
or
data[which(data[1:20,4]==1), c(1,2,4)]

You should also be careful with "==" if you compare numbers, especially fractions and to select without "with" if your data contain NA values in respective columns.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erich
> Subscriptions
> Sent: Monday, February 27, 2017 1:30 PM
> To: Tunga Kantarc? <tungakantarci at gmail.com>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Selecting rows and columns of a data frame using relational
> operators
>
> The answer is simple
>
> data[,4] == 1 produces a logical vector of length nrow(data) and the
> subsetting mechanism for data frames in R needs a vector of the same length
> as the data frame has rows.
>
> data[1:20,4] == 1
> produces a data frame of length 20, and if this is not the length of data.
> So R applies its standard procedure, it repeats this vector as often as needed
> to get a vector of length == nrow(data)
>
>
> Th following code illustrates what is happening
>
> data <-
> data.frame(x=rnorm(100),y=rnorm(100),z=rnorm(100),a=rep(c(1,2,1,2),c(2,4
> 8,2,48)))
>
> vec1 <- data[,4]==1
> vec2 <- data[1:20,4]==1
>
>
> > On 27 Feb 2017, at 13:07, Tunga Kantarc? <tungakantarci at gmail.com>
> wrote:
> >
> > Consider a data frame named data. data contains 4 columns and 1000
> > rows. Say the aim is to bring together columns 1, 2, and 4, if the
> > values in column 4 is equal to 1. We could use the syntax
> >
> > data(data[,4] == 1, c(1 2 4))
> >
> > for this purpose. Suppose now that the aim is to bring together
> > columns 1, 2, and 4, if the values in column 4 is equal to 1, for the
> > first 20 rows of column 4. We could use the syntax
> >
> > data(data[1:20,4] == 1, c(1 2 4))
> >
> > for this purpose. However, this does not produce the desired result.
> > This is surprising at least for someone coming from MATLAB because
> > MATLAB produces what is desired.
> >
> > Question 1: The code makes sense but why does it not produce what we
> > expect it to produce?
> >
> > Question 2: What code is instead suitable?
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From mlathouri at yahoo.gr  Mon Feb 27 16:26:43 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 27 Feb 2017 15:26:43 +0000 (UTC)
Subject: [R] plotting dates in x axis
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
Message-ID: <2026457994.3295018.1488209203201@mail.yahoo.com>

Dear all,?
I have an excel file of 180 observations with dates and one variable, from 1998 to 2012 by random months (there are some years that I might not have all the months or I might have two observations in one month). I am trying to plot the dates in x axis and the variable in y axis. I have already used as.Date for the dates so I can import them into R.?
Here is my script:> aa<-read.csv("aa.csv")> attach(aa)> names(aa)#"SDATE" "var1"
I convert the dates into R:?> sdate<-as.Date(SDATE, format="%Y-%m-%d")

I am plotting the dates with my var1:> plot(sdate, var1, type="l")
Up to now, everything seems ok. However, in the x-axis I only get three years, 2000, 2005 and 2010. As I want to show all the years or at least as many as it could be, I am using the following:
> plot(sdate, var1, type="l", xaxt="n")

> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"), cex.axis=0.8,las=2); ?I tried also to plot the dates in a month-Year form:?

> d2<-as.Date((d1[1])+150*(0:20))
> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15, labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)

But nothing happened. I cannot understand why it doesn't show anything.?
I have attached the file as well in case you want to have a more clear picture.?
I really appreciate it if you can help me on this. ?
Thank you very much in advance.?
Kind regards,Maria

From maechler at stat.math.ethz.ch  Mon Feb 27 16:29:28 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 27 Feb 2017 16:29:28 +0100
Subject: [R] Reading S-plus data in R
In-Reply-To: <CAGx1TMCi=_OFabhFhyH26i5eMa0byTLR8pGpN8jiWAE4hsGLoA@mail.gmail.com>
References: <CANTvJZKn=jeP2WAqsvbM88G93+uQNH+ioZek=bCYPnfBg5BZ2Q@mail.gmail.com>
	<CAF8bMcZMKg_AhhFCerP17WFc7iksCriYXFh9x4AmiHh=ueiuEg@mail.gmail.com>
	<CANTvJZKVShvdRC5wSRdz3+0Vr0ZoM3YXiEa9yfyeMTqV3HcmpQ@mail.gmail.com>
	<d50680a1-c0c7-b52c-a3ee-96070aafde60@dewey.myzen.co.uk>
	<CANTvJZJw0Q2U1UvD-0Bt7EfGyaOAc+ZnvcySQt4p=uNSCvFQXg@mail.gmail.com>
	<CAF8bMcbg66hAhbN9BCF27E0eanNQ4ou4dThBeq0pNHv8np6AaA@mail.gmail.com>
	<CAGx1TMCi=_OFabhFhyH26i5eMa0byTLR8pGpN8jiWAE4hsGLoA@mail.gmail.com>
Message-ID: <22708.17880.187195.624971@stat.math.ethz.ch>

>>>>> Richard M Heiberger <rmh at temple.edu>
>>>>>     on Sun, 26 Feb 2017 15:46:07 -0500 writes:

    > Bill,
    > this looks good.  Can you add it to the splus2R  package?

Well, the natural place would rather be the foreign package,
and some of use R core members would be happy with maintaining a
function  with   \author{Bill Dunlap}

Martin

    > Rich


    > On Sun, Feb 26, 2017 at 11:57 AM, William Dunlap via R-help
    > <r-help at r-project.org> wrote:
    >> You should be looking for foreign::data.restore, not data.dump nor read.S.
    >> 
    >> In any case, I think that foreign::data.restore does not recognize S-version4
    >> data.dump files, ones whose first line is
    >> ## Dump S Version 4 Dump ##
    >> Here is a quickly written and barely tested function that should read
    >> data.frames
    >> and other simple S+ objects in SV4 data.dump files.  It stores the
    >> objects it reads
    >> from the file 'file' in the environment 'env'.
    >> 
    >> data.restore4 <- function(file, print = FALSE, verbose = FALSE, env =
    >> .GlobalEnv)
    >> {
    >> if (!inherits(file, "connection")) {
    >> file <- file(file, "r")
    >> on.exit(close(file))
    >> }
    >> lineNo <- 0
    >> nextLine <- function(n = 1) {
    >> lineNo <<- lineNo + n
    >> readLines(file, n = n)
    >> }
    >> Message <- function(...) {
    >> if (verbose) {
    >> message(simpleMessage(paste("(line ", lineNo, ") ",
    >> paste(..., collapse = " "), sep = ""), sys.call(-1)))
    >> }
    >> }
    >> Stop <- function(...) {
    >> stop(simpleError(paste(paste(..., collapse = " "), sep = "",
    >> " (file ", deparse(summary(file)$description), ", line ",
    >> lineNo, ")"), sys.call(-1)))
    >> }
    >> txt <- nextLine()
    >> stopifnot(txt == "## Dump S Version 4 Dump ##")
    >> .data.restore4 <- function()
    >> {
    >> class <- nextLine()
    >> mode <- nextLine()
    >> length <- as.numeric(tmp <- nextLine())
    >> if (is.na(length) || length%%1 != 0 || length < 0) {
    >> Stop("Expected nonnegative integer 'length' at line ",
    >> lineNo, " but got ", deparse(tmp))
    >> }
    >> if (mode == "character") {
    >> nextLine(length)
    >> } else if (mode == "logical") {
    >> txt <- nextLine(length)
    >> lglVector <- rep(NA, length)
    >> lglVector[txt != "N"] <- as.logical(as.integer(txt[txt != "N"]))
    >> lglVector
    >> } else if (mode %in% c("integer", "single", "numeric")) {
    >> txt <- nextLine(length)
    >> txt[txt == "M"] <- "NaN"
    >> txt[txt == "I"] <- "Inf"
    >> txt[txt == "J"] <- "-Inf"
    >> atomicVector <- rep(as(NA, mode), length)
    >> atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
    >> atomicVector
    >> } else if (mode == "complex") {
    >> txt <- nextLine(length)
    >> txt <- gsub("M", "NaN", txt)
    >> txt <- gsub("\\<I\\>", "Inf", txt)
    >> txt <- gsub("\\<J\\>", "-Inf", txt)
    >> atomicVector <- rep(as(NA, mode), length)
    >> atomicVector[txt != "N"] <- as(txt[txt != "N"], mode)
    >> atomicVector
    >> } else if (mode == "list") {
    >> vectors <- lapply(seq_len(length), function(i).data.restore4())
    >> vectors
    >> } else if (mode == "NULL") {
    >> NULL
    >> } else if (mode == "structure") {
    >> vectors <- lapply(seq_len(length), function(i).data.restore4())
    >> if (class == ".named_I" || class == "named") {
    >> if (length != 2) {
    >> Stop("expected length of '.named_I' component is
    >> 2, but got ", length)
    >> } else if (length(vectors[[1]]) != length(vectors[[2]])) {
    >> Stop("expected lengths of '.named_I' components to
    >> be the same, but got ", length(vectors[[1]]), " and ",
    >> length(vectors[[2]]))
    >> } else if (!is.character(vectors[[2]])) {
    >> Stop("expected second component of '.named_I' to
    >> be character, but got ", deparse(mode(vectors[[2]])))
    >> }
    >> names(vectors[[1]]) <- vectors[[2]]
    >> if (identical(vectors[[2]][1], ".Data")) { # a hack -
    >> really want to know if vectors[[1] had mode "structure" or not
    >> do.call(structure, vectors[[1]], quote = TRUE)
    >> } else {
    >> vectors[[1]]
    >> }
    >> } else {
    >> vectors # TODO: is this ok?  It assumes that is within
    >> a .Named_I/structure
    >> }
    >> } else if (mode == "name") {
    >> if (length != 1) {
    >> Stop("expected length of 'name' objects is 1, but got", length)
    >> }
    >> as.name(nextLine())
    >> } else if (mode == "call") {
    >> callList <- lapply(seq_len(length), function(i).data.restore4())
    >> as.call(callList)
    >> } else {
    >> Stop("Unimplemented mode: ", deparse(mode))
    >> }
    >> }
    >> while (length(objName <- nextLine()) == 1) {
    >> Message(objName, ": ")
    >> obj <- .data.restore4()
    >> Message("class ", deparse(class(obj)), ", size=",
    >> object.size(obj), "\n")
    >> assign(objName, obj, envir=env)
    >> }
    >> }
    >> 
    >> 
    >> 
    >> Bill Dunlap
    >> TIBCO Software
    >> wdunlap tibco.com
    >> 
    >> 
    >> On Sun, Feb 26, 2017 at 4:28 AM, roslinazairimah zakaria
    >> <roslinaump at gmail.com> wrote:
    >>> Hi Michael,
    >>> 
    >>> Yes, I did tried and still got error:
    >>> 
    >>> 
    >>>> library(foreign)
    >>> 
    >>>> data.dump(oldStyle=TRUE)
    >>> Error in eval(expr, envir, enclos) : could not find function "data.dump"
    >>>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
    >>> 
    >>>> read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd"))
    >>> Error in read.S(file.path("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")) :
    >>> not an S object
    >>> 
    >>> Thank you.
    >>> 
    >>> On Sun, Feb 26, 2017 at 8:12 PM, Michael Dewey <lists at dewey.myzen.co.uk>
    >>> wrote:
    >>>> 
    >>>> Did you do
    >>>> library(foreign)
    >>>> first?
    >>>> 
    >>>> 
    >>>> On 26/02/2017 07:23, roslinazairimah zakaria wrote:
    >>>>> 
    >>>>> Hi William,
    >>>>> 
    >>>>> Thank you so much for your reply.
    >>>>> 
    >>>>> However, I still got error message:
    >>>>> 
>>>>> data.dump(oldStyle=TRUE)
    >>>>> 
    >>>>> Error: could not find function "data.dump"
    >>>>>> 
>>>>> data.restore("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
    >>>>> 
    >>>>> Error: could not find function "data.restore"
    >>>>> 
    >>>>> Thank you.
    >>>>> 
    >>>>> 
    >>>>> 
    >>>>> On Sun, Feb 26, 2017 at 12:42 AM, William Dunlap <wdunlap at tibco.com>
    >>>>> wrote:
    >>>>> 
>>>>> The sdd file extension may mean that the file is in S+ 'data dump'
>>>>> format,
>>>>> made by S+'s data.dump function and readable in S+ by its data.restore
>>>>> function.
>>>>> foreign::data.restore can read some such files in R, but I think it
>>>>> may only read well
>>>>> those with using the pre-1991 format made in more recent versions of
>>>>> S+ with data.dump(old.style=TRUE).
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
    >>>>>> 
    >>>>>> 
>>>>> On Fri, Feb 24, 2017 at 8:58 PM, roslinazairimah zakaria
>>>>> <roslinaump at gmail.com> wrote:
    >>>>>>> 
    >>>>>>> Dear r-users,
    >>>>>>> 
    >>>>>>> I would like to read S-Plus data (.ssd) into R.  I tried this:
    >>>>>>> 
    >>>>>>> library(foreign)
    >>>>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
    >>>>>>> 
    >>>>>>> and got this message:
    >>>>>>> 
    >>>>>>> read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd")
    >>>>>>> Error in read.S("C:/Users/FTSI/Desktop/2 ICGPA/1ACTIVITY.sdd") :
    >>>>>>> not an S object
    >>>>>>> 
    >>>>>>> What is wrong with this?  Thank you so much for your help.
    >>>>>>> 
    >>>>>>> --
    >>>>>>> *Roslinazairimah Zakaria*
    >>>>>>> *Tel: +609-5492370; Fax. No.+609-5492766*
    >>>>>>> 
    >>>>>>> *Email: roslinazairimah at ump.edu.my <roslinazairimah at ump.edu.my>;
    >>>>>>> roslinaump at gmail.com <roslinaump at gmail.com>*
    >>>>>>> Faculty of Industrial Sciences & Technology
    >>>>>>> University Malaysia Pahang
    >>>>>>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
    >>>>>>> 
    >>>>>>> [[alternative HTML version deleted]]
    >>>>>>> 
    >>>>>>> ______________________________________________
    >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>>>>>> PLEASE do read the posting guide http://www.R-project.org/
    >>>>>> 
>>>>> posting-guide.html
    >>>>>>> 
    >>>>>>> and provide commented, minimal, self-contained, reproducible code.
    >>>>>> 
    >>>>>> 
    >>>>> 
    >>>>> 
    >>>>> 
    >>>> 
    >>>> --
    >>>> Michael
    >>>> http://www.dewey.myzen.co.uk/home.html
    >>> 
    >>> 
    >>> 
    >>> 
    >>> --
    >>> Roslinazairimah Zakaria
    >>> Tel: +609-5492370; Fax. No.+609-5492766
    >>> Email: roslinazairimah at ump.edu.my; roslinaump at gmail.com
    >>> Faculty of Industrial Sciences & Technology
    >>> University Malaysia Pahang
    >>> Lebuhraya Tun Razak, 26300 Gambang, Pahang, Malaysia
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From alfredo.roccato at fastwebnet.it  Mon Feb 27 16:48:59 2017
From: alfredo.roccato at fastwebnet.it (Alfredo)
Date: Mon, 27 Feb 2017 16:48:59 +0100
Subject: [R] R: How to prune using holdout data
Message-ID: <006601d29111$0325b4c0$09711e40$@fastwebnet.it>

Thank you, Terry, for your answer. 

I'll try to explain better my question. When you create a classification or
regression tree you first grow a tree based on a splitting criteria: this
usually results in a large tree that provides a good fit to the training
data. The problem with this tree is its potential for overfitting the data:
the tree can be tailored too specifically to the training data and not
generalize well to new data. The solution (apart cross-validation) is to
find a smaller subtree that results in a low error rate on holdout or
validation data.

Hope it helps to clarity my question.

Best,

Alfredo

 

 

-----Messaggio originale-----
Da: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu] 

You will need to give more detail of exactly what you mean by "prune using a
validation set".  THe prune.rpart function will prune at any value you want,
what I suspect you are looking for is to compute the error of each possible
tree, using a validation data set, then find the best one, and then prune
there.

How do you define "best"?


	[[alternative HTML version deleted]]


From piyushroya at gmail.com  Mon Feb 27 08:31:11 2017
From: piyushroya at gmail.com (Piyush Roy)
Date: Mon, 27 Feb 2017 02:31:11 -0500
Subject: [R] Baddperiods and other functions
Message-ID: <CAECiGo=KbExeje=QOWW-bywELppcUCLFcS7u6jySeX-SakQZFA@mail.gmail.com>

Is there a way to use baddperiods and other Bloomberg API functions in R
through package Rblpapi or any other packages ?

Thanks

	[[alternative HTML version deleted]]


From dilorenzopl at gmail.com  Fri Feb 24 06:13:32 2017
From: dilorenzopl at gmail.com (Paolo Di Lorenzo)
Date: Fri, 24 Feb 2017 05:13:32 +0000
Subject: [R] [R-pkgs] usmap v 0.1.0 released
In-Reply-To: <CAHujmRZV-ePVGzQ-uUCM862BKzMiBj2rTsRfYVkrEpGL319Duw@mail.gmail.com>
References: <CAHujmRZV-ePVGzQ-uUCM862BKzMiBj2rTsRfYVkrEpGL319Duw@mail.gmail.com>
Message-ID: <330D71BA48EB384F.550835D7-0988-4DA4-AAD4-052BDBFE2DBD@mail.outlook.com>

Hello useRs,
I am announcing the release of my first package, usmap (http://cran.r-project.org/package=usmap).
"usmap" is a package to aid in the creation of US choropleths that include Alaska and Hawaii. It is still in its early stages (v 0.1.0) but I hope to improve it with added functionality over time.
Features can be seen in the vignettes here:https://cran.r-project.org/web/packages/usmap/vignettes/introduction.html
https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html

Feel free to contribute ideas and code:?http://github.com/pdil/usmap
If you have any questions please email me at?paolo at dilorenzo.pl?or message me on Twitter?@dilorenzopl.
Thank you,
Paolo Di Lorenzohttp://dilorenzo.plpaolo at dilorenzo.pl?// dilorenzopl at gmail.com


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From giuliavalva89 at gmail.com  Mon Feb 27 18:16:36 2017
From: giuliavalva89 at gmail.com (Giulia Valvassori)
Date: Mon, 27 Feb 2017 18:16:36 +0100
Subject: [R] Help with GENETICS package
Message-ID: <CALn5NopyKEnnK2P8KiP8viYy5pfwtUi+HQTMW4JbW_BOK4EG2A@mail.gmail.com>

Dear all,

I am writing you this email because i need your help and I will really
appreciate if you can dedicate some minutes of your time in helping me.

I'm trying to use the R genetics package for a Linkage Disequilibrium
analysis of data matrix obtained from a RADseq protocol (Stacks software).
After several filtration steps, i'm currently working on a matrix of
approximately 3000 SNPs (100 samples). I'm having some issues in
understanding which type of input file should i run. I have found something
related to the genlight format but i really don't understand how can i
convert my genepop file into this new format.

Can anyone please tell me if i'm working on the right direction and how can
i convert my file?

Thank you very much for your time!
Best regards,
Giulia

	[[alternative HTML version deleted]]


From duncanlj at mcmaster.ca  Mon Feb 27 20:05:23 2017
From: duncanlj at mcmaster.ca (Duncan, Laura)
Date: Mon, 27 Feb 2017 19:05:23 +0000
Subject: [R] Metafor multilevel metaregression: total variance increases
 when moderator added?
Message-ID: <31A98C8B8E62D84982441B63A46937D76CEE7DDB@FHSDB2D11-1.csu.mcmaster.ca>

Hi there,

I am running a two level multilevel meta-regression of 170 estimates nested within 3 informants nested within 26 studies. I run the null model to get a pooled estimate with random effects at the informant level and study level.

Then I test a series of potential moderators (one at a time, given small number of studies and adjust p-values for multiple testing). I use:
(sum(Model1$sigma2) - sum(Model2$sigma2)) / sum(Model1$sigma2)
to compute the proportional reduction in the total variance from here:
http://stackoverflow.com/questions/22356450/getting-r-squared-from-a-mixed-effects-multilevel-model-in-metafor

For one moderator, I get a negative value for reduced total variance and an unexpected negative coefficient. Based on Wolfgang's response in the link above this is possible "depending on the size of your dataset, those variance components may not be estimated very precisely and that can lead to such counter-intuitive results".

I am trying to diagnose why this model is not being estimated properly and why I am getting an unexpected negative result. When I remove the second level from the model and run a single-level random effects models of 170 estimates nested within 26 studies, the coefficient is positive and as we would expect.

Does anyone have any suggestions for what might be going on or how I might diagnose the problem with this model?

Thanks,
Laura

Laura Duncan, M.A.
Research Coordinator
Offord Centre for Child Studies
McMaster University

Tel: 905 525 9140 x21504
Fax: 905 574 6665
duncanlj at mcmaster.ca
ontariochildhealthstudy.ca<www.ontariochildhealthstudy.ca>
offordcentre.com

Mailing Address                                               Courier Address
1280 Main St. W. MIP 201A                           175 Longwood Rd. S. MIP 201A
Hamilton, Ontario L8S 4K1                             Hamilton, Ontario L8P 0A1


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Feb 27 22:11:05 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 28 Feb 2017 08:11:05 +1100
Subject: [R] plotting dates in x axis
In-Reply-To: <2026457994.3295018.1488209203201@mail.yahoo.com>
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
	<2026457994.3295018.1488209203201@mail.yahoo.com>
Message-ID: <CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>

Hi Maria,
First, Excel files don't make it through the Mexican Wall. A CSV with
the extension changed to .txt might. You can get all of the years like
this:

aa<-data.frame(var1=runif(180),
 SDATE=paste(sample(1998:2012,180,TRUE),
 sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
aa$sdate<-as.Date(aa$SDATE)
plot(aa$sdate,aa$var1,xaxt="n")
library(plotrix)
# set the tick marks at the middle of each year
axis.dates<-as.Date(paste(1998:2012,6,30,sep="-"))
staxlab(1,axis.dates,1998:2012,nlines=3)

Obviously you don't want all of the months, so just add the months to the years:

plot(aa$sdate,aa$var1,xaxt="n")
staxlab(1,axis.dates,format(axis.dates,"%b/%Y"),nlines=3)

Jim


On Tue, Feb 28, 2017 at 2:26 AM, Maria Lathouri via R-help
<r-help at r-project.org> wrote:
> Dear all,
> I have an excel file of 180 observations with dates and one variable, from 1998 to 2012 by random months (there are some years that I might not have all the months or I might have two observations in one month). I am trying to plot the dates in x axis and the variable in y axis. I have already used as.Date for the dates so I can import them into R.
> Here is my script:> aa<-read.csv("aa.csv")> attach(aa)> names(aa)#"SDATE" "var1"
> I convert the dates into R: > sdate<-as.Date(SDATE, format="%Y-%m-%d")
>
> I am plotting the dates with my var1:> plot(sdate, var1, type="l")
> Up to now, everything seems ok. However, in the x-axis I only get three years, 2000, 2005 and 2010. As I want to show all the years or at least as many as it could be, I am using the following:
>> plot(sdate, var1, type="l", xaxt="n")
>
>> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
>> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"), cex.axis=0.8,las=2);  I tried also to plot the dates in a month-Year form:
>
>> d2<-as.Date((d1[1])+150*(0:20))
>> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15, labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)
>
> But nothing happened. I cannot understand why it doesn't show anything.
> I have attached the file as well in case you want to have a more clear picture.
> I really appreciate it if you can help me on this.
> Thank you very much in advance.
> Kind regards,Maria
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From josh.m.ulrich at gmail.com  Mon Feb 27 22:12:29 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 27 Feb 2017 15:12:29 -0600
Subject: [R] order.by requires an appropriate time-based object
In-Reply-To: <863314315.1510930.1488173821023@mail.yahoo.com>
References: <377703184.1194921.1488122648612.ref@mail.yahoo.com>
	<377703184.1194921.1488122648612@mail.yahoo.com>
	<CAPPM_gQYFjxoJi+o9oWhf_1QggTDSpxMwD=0Y-eaGi=LVj-wCQ@mail.gmail.com>
	<1215070444.1476164.1488172960445@mail.yahoo.com>
	<1173883038.1477541.1488173021662@mail.yahoo.com>
	<863314315.1510930.1488173821023@mail.yahoo.com>
Message-ID: <CAPPM_gQ+29OGsO14BzBNFzAi1A8Da+7kASF1Gn2NK-WDT3kpqg@mail.gmail.com>

On Sun, Feb 26, 2017 at 11:37 PM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> Here is the screenshoot to show what's happening entirely
>
>
>
> On Monday, 27 February 2017, 12:23, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
>
>
> See attached for updated R script
>
>
> On Monday, 27 February 2017, 12:22, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
>
>
> I have converted the data into as.Date but then the dates itself (containing
> the data[,1]) have NA value. Even after removing NA values by this
> particular code:
> ag.direction.returns[1] <- 0

Your dates have NA values because you specified the format incorrectly
in your call to as.Date().  Despite the column names, the format is
"MM.DD.YYYY", not "DD.MM.YYYY".

R> head(data)
  DD.MM.YYYY      O      H      L      C
1  3/26/2009 132.63 133.90 132.33 133.70
2  3/27/2009 133.69 133.86 129.35 130.09
3  3/30/2009 129.75 130.55 126.40 128.65
4  3/31/2009 128.64 131.87 128.22 130.95
5   4/1/2009 130.94 131.89 129.86 130.54
6   4/2/2009 130.55 134.23 130.29 134.16

Additionally, 'src' and 'dateFormat' are not arguments to as.Date(),
so they're unnecessary.  Your as.Date() call should be:
dates <- as.Date(data[,1], format="%m/%d/%Y")


> it's still containing NA values, that won't be allowedwhen i try to merge
> xts in this particular code:
> both.curves <- cbind(ag.curve, buy.hold.curve)
>
>
>> both.curves <- cbind(ag.curve, buy.hold.curve)
> nan, nan
> Error in merge.xts(..., all = all, fill = fill, suffixes = suffixes) :
>   'NA' not allowed in 'index'
>
>
>
>
>
> On Monday, 27 February 2017, 12:05, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>
>
> Please provide a minimal, reproducible example.  It's really hard for
> someone to help you if you give them nearly 100 lines of code and no
> data.  My guess is that data[,1] is character (or factor) and you need
> to convert it to Date or POSIXct.
>
> On Sun, Feb 26, 2017 at 9:24 AM, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
>> HiNot sure why i get error like this: Error in xts(forecasts,
>> dates[(window.length):length(returns)]) :  order.by requires an appropriate
>> time-based object
>> I have researched for the answer that i need to convert returns into time
>> series. I did that but still it doesn't work?See attached for file.Thanks
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> R/Finance 2017 | www.rinfinance.com
>
>
>
>
>
>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From jdnewmil at dcn.davis.ca.us  Mon Feb 27 23:00:18 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Feb 2017 14:00:18 -0800
Subject: [R] plotting dates in x axis
In-Reply-To: <CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
	<2026457994.3295018.1488209203201@mail.yahoo.com>
	<CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>
Message-ID: <A62569FB-CA09-4FA4-A59E-5F62FED09AF1@dcn.davis.ca.us>

While humorous, the term "Mexican Wall" is unlikely to be clear to the OP. This is a reference to the mailing list anti-virus strategy of cutting out attachments that don't meet a very restrictive set of requirements outlined in the Posting Guide that all R-users are supposed to have read and memorized, but which few even seem to know exists. You can best avoid the "Mexican Wall" by setting your email program to send plain text instead of HTML, and to embed your R code example (believe it or not, this is not the Excel-To-R translation service, so show us your R code and text data, not your Excel file) in the email along with your description of your problem. For more help on getting help search the Internet for "R reproducible example".
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2017 1:11:05 PM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Maria,
>First, Excel files don't make it through the Mexican Wall. A CSV with
>the extension changed to .txt might. You can get all of the years like
>this:
>
>aa<-data.frame(var1=runif(180),
> SDATE=paste(sample(1998:2012,180,TRUE),
> sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
>aa$sdate<-as.Date(aa$SDATE)
>plot(aa$sdate,aa$var1,xaxt="n")
>library(plotrix)
># set the tick marks at the middle of each year
>axis.dates<-as.Date(paste(1998:2012,6,30,sep="-"))
>staxlab(1,axis.dates,1998:2012,nlines=3)
>
>Obviously you don't want all of the months, so just add the months to
>the years:
>
>plot(aa$sdate,aa$var1,xaxt="n")
>staxlab(1,axis.dates,format(axis.dates,"%b/%Y"),nlines=3)
>
>Jim
>
>
>On Tue, Feb 28, 2017 at 2:26 AM, Maria Lathouri via R-help
><r-help at r-project.org> wrote:
>> Dear all,
>> I have an excel file of 180 observations with dates and one variable,
>from 1998 to 2012 by random months (there are some years that I might
>not have all the months or I might have two observations in one month).
>I am trying to plot the dates in x axis and the variable in y axis. I
>have already used as.Date for the dates so I can import them into R.
>> Here is my script:> aa<-read.csv("aa.csv")> attach(aa)>
>names(aa)#"SDATE" "var1"
>> I convert the dates into R: > sdate<-as.Date(SDATE,
>format="%Y-%m-%d")
>>
>> I am plotting the dates with my var1:> plot(sdate, var1, type="l")
>> Up to now, everything seems ok. However, in the x-axis I only get
>three years, 2000, 2005 and 2010. As I want to show all the years or at
>least as many as it could be, I am using the following:
>>> plot(sdate, var1, type="l", xaxt="n")
>>
>>> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
>>> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"),
>cex.axis=0.8,las=2);  I tried also to plot the dates in a month-Year
>form:
>>
>>> d2<-as.Date((d1[1])+150*(0:20))
>>> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15,
>labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)
>>
>> But nothing happened. I cannot understand why it doesn't show
>anything.
>> I have attached the file as well in case you want to have a more
>clear picture.
>> I really appreciate it if you can help me on this.
>> Thank you very much in advance.
>> Kind regards,Maria
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Tue Feb 28 02:47:58 2017
From: valkremk at gmail.com (Val)
Date: Mon, 27 Feb 2017 19:47:58 -0600
Subject: [R] if and
Message-ID: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>

Currently I have  about  six or more  scripts that do the same job.  I
thought it might be possible and more efficient to use one script by using
IF ELSE statements. Here is an example but this will be expandable for
several countries ans year-months


Year-month = FEB2015, FEB2012,  Feb2010
 country  = USA, CAN.MEX
First I want to do if country = USA and year-month = FEB2015, FEB2012 do
the statements
second if country = CAN and year-month =Feb2010 do  the statements


if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
statemnt1
.
statemnt10

} else if (country="USA" & year-month ="FEB2015") {
statemnt1
.
statemnt10
}

else
{
statemnt1
.
statemnt10
}

The above script did not work. is there a different ways of doing it?

Thank you in advance
.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Feb 28 03:16:38 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 28 Feb 2017 15:16:38 +1300
Subject: [R] [FORGED]  if and
In-Reply-To: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>
References: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>
Message-ID: <4c1c7937-a8e5-99c4-0abe-470b2c513691@auckland.ac.nz>

On 28/02/17 14:47, Val wrote:
> Currently I have  about  six or more  scripts that do the same job.  I
> thought it might be possible and more efficient to use one script by using
> IF ELSE statements. Here is an example but this will be expandable for
> several countries ans year-months
>
>
> Year-month = FEB2015, FEB2012,  Feb2010
>  country  = USA, CAN.MEX
> First I want to do if country = USA and year-month = FEB2015, FEB2012 do
> the statements
> second if country = CAN and year-month =Feb2010 do  the statements
>
>
> if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
> statemnt1
> .
> statemnt10
>
> } else if (country="USA" & year-month ="FEB2015") {
> statemnt1
> .
> statemnt10
> }
>
> else
> {
> statemnt1
> .
> statemnt10
> }
>
> The above script did not work. is there a different ways of doing it?

Uh, yes.  Get the syntax right.  Use R, when you are using R.

Looking at ?Syntax and ?Logic might help you a bit.

Other than that, there's not much that one can say without seeing a 
reproducible example.  And if you sat down and wrote out a *reproducible 
example*, using correct R syntax, you probably wouldn't need any 
assistance from R-help.

Have you read any of the readily available R tutorials?  If not do so. 
If so, read them again and actually take note of what they say!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Tue Feb 28 03:45:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 27 Feb 2017 18:45:52 -0800
Subject: [R] [FORGED] if and
In-Reply-To: <4c1c7937-a8e5-99c4-0abe-470b2c513691@auckland.ac.nz>
References: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>
	<4c1c7937-a8e5-99c4-0abe-470b2c513691@auckland.ac.nz>
Message-ID: <CAGxFJbSZetdeqpPgQJ=RiJ_gp1nACU6m-HkXdB30KzB4SFWE2A@mail.gmail.com>

I note that you have "Year-month" (capital 'Y') and "year-month" in
your code; case matters in R.

Otherwise, Rolf's advice applies.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 27, 2017 at 6:16 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 28/02/17 14:47, Val wrote:
>>
>> Currently I have  about  six or more  scripts that do the same job.  I
>> thought it might be possible and more efficient to use one script by using
>> IF ELSE statements. Here is an example but this will be expandable for
>> several countries ans year-months
>>
>>
>> Year-month = FEB2015, FEB2012,  Feb2010
>>  country  = USA, CAN.MEX
>> First I want to do if country = USA and year-month = FEB2015, FEB2012 do
>> the statements
>> second if country = CAN and year-month =Feb2010 do  the statements
>>
>>
>> if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
>> statemnt1
>> .
>> statemnt10
>>
>> } else if (country="USA" & year-month ="FEB2015") {
>> statemnt1
>> .
>> statemnt10
>> }
>>
>> else
>> {
>> statemnt1
>> .
>> statemnt10
>> }
>>
>> The above script did not work. is there a different ways of doing it?
>
>
> Uh, yes.  Get the syntax right.  Use R, when you are using R.
>
> Looking at ?Syntax and ?Logic might help you a bit.
>
> Other than that, there's not much that one can say without seeing a
> reproducible example.  And if you sat down and wrote out a *reproducible
> example*, using correct R syntax, you probably wouldn't need any assistance
> from R-help.
>
> Have you read any of the readily available R tutorials?  If not do so. If
> so, read them again and actually take note of what they say!
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Tue Feb 28 04:02:29 2017
From: valkremk at gmail.com (Val)
Date: Mon, 27 Feb 2017 21:02:29 -0600
Subject: [R] [FORGED] if and
In-Reply-To: <CAGxFJbSZetdeqpPgQJ=RiJ_gp1nACU6m-HkXdB30KzB4SFWE2A@mail.gmail.com>
References: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>
	<4c1c7937-a8e5-99c4-0abe-470b2c513691@auckland.ac.nz>
	<CAGxFJbSZetdeqpPgQJ=RiJ_gp1nACU6m-HkXdB30KzB4SFWE2A@mail.gmail.com>
Message-ID: <CAJOiR6YJX+J6ymuz1aJCVhzeqm_WYLKBAOZSR5zgA-riw=eTUQ@mail.gmail.com>

Thank you  Rolf and Bert!

I found the problem and this

if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
        has be changed  to  this
if(country="USA" & year-month == "FEB2015" | year-month == "FEB2012" ){

On Mon, Feb 27, 2017 at 8:45 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I note that you have "Year-month" (capital 'Y') and "year-month" in
> your code; case matters in R.
>
> Otherwise, Rolf's advice applies.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Feb 27, 2017 at 6:16 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> > On 28/02/17 14:47, Val wrote:
> >>
> >> Currently I have  about  six or more  scripts that do the same job.  I
> >> thought it might be possible and more efficient to use one script by
> using
> >> IF ELSE statements. Here is an example but this will be expandable for
> >> several countries ans year-months
> >>
> >>
> >> Year-month = FEB2015, FEB2012,  Feb2010
> >>  country  = USA, CAN.MEX
> >> First I want to do if country = USA and year-month = FEB2015, FEB2012 do
> >> the statements
> >> second if country = CAN and year-month =Feb2010 do  the statements
> >>
> >>
> >> if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
> >> statemnt1
> >> .
> >> statemnt10
> >>
> >> } else if (country="USA" & year-month ="FEB2015") {
> >> statemnt1
> >> .
> >> statemnt10
> >> }
> >>
> >> else
> >> {
> >> statemnt1
> >> .
> >> statemnt10
> >> }
> >>
> >> The above script did not work. is there a different ways of doing it?
> >
> >
> > Uh, yes.  Get the syntax right.  Use R, when you are using R.
> >
> > Looking at ?Syntax and ?Logic might help you a bit.
> >
> > Other than that, there's not much that one can say without seeing a
> > reproducible example.  And if you sat down and wrote out a *reproducible
> > example*, using correct R syntax, you probably wouldn't need any
> assistance
> > from R-help.
> >
> > Have you read any of the readily available R tutorials?  If not do so. If
> > so, read them again and actually take note of what they say!
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Feb 28 04:46:55 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 27 Feb 2017 19:46:55 -0800
Subject: [R] [FORGED] if and
In-Reply-To: <CAJOiR6YJX+J6ymuz1aJCVhzeqm_WYLKBAOZSR5zgA-riw=eTUQ@mail.gmail.com>
References: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>
	<4c1c7937-a8e5-99c4-0abe-470b2c513691@auckland.ac.nz>
	<CAGxFJbSZetdeqpPgQJ=RiJ_gp1nACU6m-HkXdB30KzB4SFWE2A@mail.gmail.com>
	<CAJOiR6YJX+J6ymuz1aJCVhzeqm_WYLKBAOZSR5zgA-riw=eTUQ@mail.gmail.com>
Message-ID: <AB5E95F5-06D7-4D59-85E2-9856E3B22C66@dcn.davis.ca.us>

Really? That seems unlikely, given that

* = is used for moving values, not comparing them,

* - is not a legal symbol for a variable name, it is subtraction, and year-month can hardly end up as a character string like "FEB2015"

* (possible problem) & and | compare vectors one at a time, so are not generally recommended for use in "if", but are more commonly used in the "ifelse" function. 

These points are all discussed in the Introduction to R document that comes with R.
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2017 7:02:29 PM PST, Val <valkremk at gmail.com> wrote:
>Thank you  Rolf and Bert!
>
>I found the problem and this
>
>if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
>        has be changed  to  this
>if(country="USA" & year-month == "FEB2015" | year-month == "FEB2012" ){
>
>On Mon, Feb 27, 2017 at 8:45 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>
>> I note that you have "Year-month" (capital 'Y') and "year-month" in
>> your code; case matters in R.
>>
>> Otherwise, Rolf's advice applies.
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Feb 27, 2017 at 6:16 PM, Rolf Turner
><r.turner at auckland.ac.nz>
>> wrote:
>> > On 28/02/17 14:47, Val wrote:
>> >>
>> >> Currently I have  about  six or more  scripts that do the same
>job.  I
>> >> thought it might be possible and more efficient to use one script
>by
>> using
>> >> IF ELSE statements. Here is an example but this will be expandable
>for
>> >> several countries ans year-months
>> >>
>> >>
>> >> Year-month = FEB2015, FEB2012,  Feb2010
>> >>  country  = USA, CAN.MEX
>> >> First I want to do if country = USA and year-month = FEB2015,
>FEB2012 do
>> >> the statements
>> >> second if country = CAN and year-month =Feb2010 do  the statements
>> >>
>> >>
>> >> if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
>> >> statemnt1
>> >> .
>> >> statemnt10
>> >>
>> >> } else if (country="USA" & year-month ="FEB2015") {
>> >> statemnt1
>> >> .
>> >> statemnt10
>> >> }
>> >>
>> >> else
>> >> {
>> >> statemnt1
>> >> .
>> >> statemnt10
>> >> }
>> >>
>> >> The above script did not work. is there a different ways of doing
>it?
>> >
>> >
>> > Uh, yes.  Get the syntax right.  Use R, when you are using R.
>> >
>> > Looking at ?Syntax and ?Logic might help you a bit.
>> >
>> > Other than that, there's not much that one can say without seeing a
>> > reproducible example.  And if you sat down and wrote out a
>*reproducible
>> > example*, using correct R syntax, you probably wouldn't need any
>> assistance
>> > from R-help.
>> >
>> > Have you read any of the readily available R tutorials?  If not do
>so. If
>> > so, read them again and actually take note of what they say!
>> >
>> > cheers,
>> >
>> > Rolf Turner
>> >
>> > --
>> > Technical Editor ANZJS
>> > Department of Statistics
>> > University of Auckland
>> > Phone: +64-9-373-7599 ext. 88276
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From eva.leunissen at gmail.com  Mon Feb 27 22:27:26 2017
From: eva.leunissen at gmail.com (Eva Maria Leunissen)
Date: Tue, 28 Feb 2017 10:27:26 +1300
Subject: [R] concurvity
Message-ID: <CAFSxBJ6AroCGdM38M2xd1aczMC1KSrRm0bZpDpv+dd94s-WvNg@mail.gmail.com>

Hi, I'm using the concurvity function to check for concurvity in my model.
The output I get when comparing to the rest of the model (ie full=TRUE)
 many of the variables have concurvity values higher than 0.9. However when
comparing the terms pairwise most values are very small, less than 0.1
(with the worst around 0.5). I am not sure where to go from here, should
the full model output be cause for concern and should I refit the model
eliminating some terms with high concurvity? or are the pairwise
concurvities more informative?
is there anything else I can do? The terms in the model are mostly
interactions, with a few smooths and one parametric term.

Thanks in advance

	[[alternative HTML version deleted]]


From allantanaka11 at yahoo.com  Tue Feb 28 05:38:52 2017
From: allantanaka11 at yahoo.com (Allan Tanaka)
Date: Tue, 28 Feb 2017 04:38:52 +0000 (UTC)
Subject: [R] order.by requires an appropriate time-based object
In-Reply-To: <CAPPM_gQ+29OGsO14BzBNFzAi1A8Da+7kASF1Gn2NK-WDT3kpqg@mail.gmail.com>
References: <377703184.1194921.1488122648612.ref@mail.yahoo.com>
	<377703184.1194921.1488122648612@mail.yahoo.com>
	<CAPPM_gQYFjxoJi+o9oWhf_1QggTDSpxMwD=0Y-eaGi=LVj-wCQ@mail.gmail.com>
	<1215070444.1476164.1488172960445@mail.yahoo.com>
	<1173883038.1477541.1488173021662@mail.yahoo.com>
	<863314315.1510930.1488173821023@mail.yahoo.com>
	<CAPPM_gQ+29OGsO14BzBNFzAi1A8Da+7kASF1Gn2NK-WDT3kpqg@mail.gmail.com>
Message-ID: <1992487184.197362.1488256732094@mail.yahoo.com>

Jesus!! even a small mistake like that can make me a headache.Thanks, this works like charm :) :) 

    On Tuesday, 28 February 2017, 4:12, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
 

 On Sun, Feb 26, 2017 at 11:37 PM, Allan Tanaka <allantanaka11 at yahoo.com> wrote:
> Here is the screenshoot to show what's happening entirely
>
>
>
> On Monday, 27 February 2017, 12:23, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
>
>
> See attached for updated R script
>
>
> On Monday, 27 February 2017, 12:22, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
>
>
> I have converted the data into as.Date but then the dates itself (containing
> the data[,1]) have NA value. Even after removing NA values by this
> particular code:
> ag.direction.returns[1] <- 0

Your dates have NA values because you specified the format incorrectly
in your call to as.Date().? Despite the column names, the format is
"MM.DD.YYYY", not "DD.MM.YYYY".

R> head(data)
? DD.MM.YYYY? ? ? O? ? ? H? ? ? L? ? ? C
1? 3/26/2009 132.63 133.90 132.33 133.70
2? 3/27/2009 133.69 133.86 129.35 130.09
3? 3/30/2009 129.75 130.55 126.40 128.65
4? 3/31/2009 128.64 131.87 128.22 130.95
5? 4/1/2009 130.94 131.89 129.86 130.54
6? 4/2/2009 130.55 134.23 130.29 134.16

Additionally, 'src' and 'dateFormat' are not arguments to as.Date(),
so they're unnecessary.? Your as.Date() call should be:
dates <- as.Date(data[,1], format="%m/%d/%Y")


> it's still containing NA values, that won't be allowedwhen i try to merge
> xts in this particular code:
> both.curves <- cbind(ag.curve, buy.hold.curve)
>
>
>> both.curves <- cbind(ag.curve, buy.hold.curve)
> nan, nan
> Error in merge.xts(..., all = all, fill = fill, suffixes = suffixes) :
>? 'NA' not allowed in 'index'
>
>
>
>
>
> On Monday, 27 February 2017, 12:05, Joshua Ulrich <josh.m.ulrich at gmail.com>
> wrote:
>
>
> Please provide a minimal, reproducible example.? It's really hard for
> someone to help you if you give them nearly 100 lines of code and no
> data.? My guess is that data[,1] is character (or factor) and you need
> to convert it to Date or POSIXct.
>
> On Sun, Feb 26, 2017 at 9:24 AM, Allan Tanaka <allantanaka11 at yahoo.com>
> wrote:
>> HiNot sure why i get error like this: Error in xts(forecasts,
>> dates[(window.length):length(returns)]) :? order.by requires an appropriate
>> time-based object
>> I have researched for the answer that i need to convert returns into time
>> series. I did that but still it doesn't work?See attached for file.Thanks
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Joshua Ulrich? |? about.me/joshuaulrich
> FOSS Trading? |? www.fosstrading.com
> R/Finance 2017 | www.rinfinance.com
>
>
>
>
>
>
>



-- 
Joshua Ulrich? |? about.me/joshuaulrich
FOSS Trading? |? www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


   
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Feb 28 07:34:45 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 27 Feb 2017 22:34:45 -0800
Subject: [R] concurvity
In-Reply-To: <CAFSxBJ6AroCGdM38M2xd1aczMC1KSrRm0bZpDpv+dd94s-WvNg@mail.gmail.com>
References: <CAFSxBJ6AroCGdM38M2xd1aczMC1KSrRm0bZpDpv+dd94s-WvNg@mail.gmail.com>
Message-ID: <CAGxFJbQzB7RS_o07vizoDJEup86oiQjQtXv7np47z5qVC4HZeQ@mail.gmail.com>

Eva:

Yours is a statistical question, which is generally off topic here.
While you may get a reply, I think you would do better to post on a
statistics list like stats.stackexchange.com. Even better, I think,
would be to consult a local statistical expert, as it sounds like you
are fairly confused about the "concurvity" issues and may need a 1-1
discussion about what is appropriate in your application context.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Feb 27, 2017 at 1:27 PM, Eva Maria Leunissen
<eva.leunissen at gmail.com> wrote:
> Hi, I'm using the concurvity function to check for concurvity in my model.
> The output I get when comparing to the rest of the model (ie full=TRUE)
>  many of the variables have concurvity values higher than 0.9. However when
> comparing the terms pairwise most values are very small, less than 0.1
> (with the worst around 0.5). I am not sure where to go from here, should
> the full model output be cause for concern and should I refit the model
> eliminating some terms with high concurvity? or are the pairwise
> concurvities more informative?
> is there anything else I can do? The terms in the model are mostly
> interactions, with a few smooths and one parametric term.
>
> Thanks in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mlathouri at yahoo.gr  Tue Feb 28 12:53:02 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Tue, 28 Feb 2017 11:53:02 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBwbG90dGluZyBkYXRlcyBpbiB4IGF4aXM=?=
In-Reply-To: <A62569FB-CA09-4FA4-A59E-5F62FED09AF1@dcn.davis.ca.us>
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
	<2026457994.3295018.1488209203201@mail.yahoo.com>
	<CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>
	<A62569FB-CA09-4FA4-A59E-5F62FED09AF1@dcn.davis.ca.us>
Message-ID: <2124162590.4345707.1488282782793@mail.yahoo.com>

Dear all,
Sorry about that. My mistake. Here is an example of my data
> head(aa)? ? ? ?SDATE ?var11 1998-01-29 0.7282 1998-02-17 1.0803 1998-03-20 0.6374 1998-05-07 1.1205 1998-05-26 0.9036 1998-06-05 1.210.........................178 2012-10-4 ?0.71179 2012-11-4 ?0.663180 2012-12-10 0.484
I hope this helps.
Maria 

    ???? 10:00 ?.?. ???????, 27 ??????????? 2017, ?/? Jeff Newmiller <jdnewmil at dcn.davis.ca.us> ??????:
 

 While humorous, the term "Mexican Wall" is unlikely to be clear to the OP. This is a reference to the mailing list anti-virus strategy of cutting out attachments that don't meet a very restrictive set of requirements outlined in the Posting Guide that all R-users are supposed to have read and memorized, but which few even seem to know exists. You can best avoid the "Mexican Wall" by setting your email program to send plain text instead of HTML, and to embed your R code example (believe it or not, this is not the Excel-To-R translation service, so show us your R code and text data, not your Excel file) in the email along with your description of your problem. For more help on getting help search the Internet for "R reproducible example".
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2017 1:11:05 PM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Maria,
>First, Excel files don't make it through the Mexican Wall. A CSV with
>the extension changed to .txt might. You can get all of the years like
>this:
>
>aa<-data.frame(var1=runif(180),
> SDATE=paste(sample(1998:2012,180,TRUE),
> sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
>aa$sdate<-as.Date(aa$SDATE)
>plot(aa$sdate,aa$var1,xaxt="n")
>library(plotrix)
># set the tick marks at the middle of each year
>axis.dates<-as.Date(paste(1998:2012,6,30,sep="-"))
>staxlab(1,axis.dates,1998:2012,nlines=3)
>
>Obviously you don't want all of the months, so just add the months to
>the years:
>
>plot(aa$sdate,aa$var1,xaxt="n")
>staxlab(1,axis.dates,format(axis.dates,"%b/%Y"),nlines=3)
>
>Jim
>
>
>On Tue, Feb 28, 2017 at 2:26 AM, Maria Lathouri via R-help
><r-help at r-project.org> wrote:
>> Dear all,
>> I have an excel file of 180 observations with dates and one variable,
>from 1998 to 2012 by random months (there are some years that I might
>not have all the months or I might have two observations in one month).
>I am trying to plot the dates in x axis and the variable in y axis. I
>have already used as.Date for the dates so I can import them into R.
>> Here is my script:> aa<-read.csv("aa.csv")> attach(aa)>
>names(aa)#"SDATE" "var1"
>> I convert the dates into R: > sdate<-as.Date(SDATE,
>format="%Y-%m-%d")
>>
>> I am plotting the dates with my var1:> plot(sdate, var1, type="l")
>> Up to now, everything seems ok. However, in the x-axis I only get
>three years, 2000, 2005 and 2010. As I want to show all the years or at
>least as many as it could be, I am using the following:
>>> plot(sdate, var1, type="l", xaxt="n")
>>
>>> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
>>> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"),
>cex.axis=0.8,las=2);? I tried also to plot the dates in a month-Year
>form:
>>
>>> d2<-as.Date((d1[1])+150*(0:20))
>>> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15,
>labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)
>>
>> But nothing happened. I cannot understand why it doesn't show
>anything.
>> I have attached the file as well in case you want to have a more
>clear picture.
>> I really appreciate it if you can help me on this.
>> Thank you very much in advance.
>> Kind regards,Maria
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Tue Feb 28 13:13:51 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Tue, 28 Feb 2017 12:13:51 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICDOo8+HzrXPhDogIHBsb3R0aW5nIGRhdGVz?=
 =?utf-8?q?_in_x_axis?=
In-Reply-To: <2124162590.4345707.1488282782793@mail.yahoo.com>
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
	<2026457994.3295018.1488209203201@mail.yahoo.com>
	<CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>
	<A62569FB-CA09-4FA4-A59E-5F62FED09AF1@dcn.davis.ca.us>
	<2124162590.4345707.1488282782793@mail.yahoo.com>
Message-ID: <1622106255.4352257.1488284031116@mail.yahoo.com>

Dear Jim
Many thanks for this. I tried and it somehow worked. I removed the nlines=3 from your script so I can have the years in one line, but still the problem is that while trying to show all the years, there are years in the first line and then other years in a second line.?
I was wondering if I can show every two years instead. I think it would be much better. ?
Many thanks.?
Kind regards,Maria

    ???? 11:56 ?.?. ?????, 28 ??????????? 2017, ?/? Maria Lathouri via R-help <r-help at r-project.org> ??????:
 

 Dear all,
Sorry about that. My mistake. Here is an example of my data
> head(aa)? ? ? ?SDATE ?var11 1998-01-29 0.7282 1998-02-17 1.0803 1998-03-20 0.6374 1998-05-07 1.1205 1998-05-26 0.9036 1998-06-05 1.210.........................178 2012-10-4 ?0.71179 2012-11-4 ?0.663180 2012-12-10 0.484
I hope this helps.
Maria 

? ? ???? 10:00 ?.?. ???????, 27 ??????????? 2017, ?/? Jeff Newmiller <jdnewmil at dcn.davis.ca.us> ??????:
 

 While humorous, the term "Mexican Wall" is unlikely to be clear to the OP. This is a reference to the mailing list anti-virus strategy of cutting out attachments that don't meet a very restrictive set of requirements outlined in the Posting Guide that all R-users are supposed to have read and memorized, but which few even seem to know exists. You can best avoid the "Mexican Wall" by setting your email program to send plain text instead of HTML, and to embed your R code example (believe it or not, this is not the Excel-To-R translation service, so show us your R code and text data, not your Excel file) in the email along with your description of your problem. For more help on getting help search the Internet for "R reproducible example".
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2017 1:11:05 PM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
>Hi Maria,
>First, Excel files don't make it through the Mexican Wall. A CSV with
>the extension changed to .txt might. You can get all of the years like
>this:
>
>aa<-data.frame(var1=runif(180),
> SDATE=paste(sample(1998:2012,180,TRUE),
> sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
>aa$sdate<-as.Date(aa$SDATE)
>plot(aa$sdate,aa$var1,xaxt="n")
>library(plotrix)
># set the tick marks at the middle of each year
>axis.dates<-as.Date(paste(1998:2012,6,30,sep="-"))
>staxlab(1,axis.dates,1998:2012,nlines=3)
>
>Obviously you don't want all of the months, so just add the months to
>the years:
>
>plot(aa$sdate,aa$var1,xaxt="n")
>staxlab(1,axis.dates,format(axis.dates,"%b/%Y"),nlines=3)
>
>Jim
>
>
>On Tue, Feb 28, 2017 at 2:26 AM, Maria Lathouri via R-help
><r-help at r-project.org> wrote:
>> Dear all,
>> I have an excel file of 180 observations with dates and one variable,
>from 1998 to 2012 by random months (there are some years that I might
>not have all the months or I might have two observations in one month).
>I am trying to plot the dates in x axis and the variable in y axis. I
>have already used as.Date for the dates so I can import them into R.
>> Here is my script:> aa<-read.csv("aa.csv")> attach(aa)>
>names(aa)#"SDATE" "var1"
>> I convert the dates into R: > sdate<-as.Date(SDATE,
>format="%Y-%m-%d")
>>
>> I am plotting the dates with my var1:> plot(sdate, var1, type="l")
>> Up to now, everything seems ok. However, in the x-axis I only get
>three years, 2000, 2005 and 2010. As I want to show all the years or at
>least as many as it could be, I am using the following:
>>> plot(sdate, var1, type="l", xaxt="n")
>>
>>> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
>>> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"),
>cex.axis=0.8,las=2);? I tried also to plot the dates in a month-Year
>form:
>>
>>> d2<-as.Date((d1[1])+150*(0:20))
>>> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15,
>labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)
>>
>> But nothing happened. I cannot understand why it doesn't show
>anything.
>> I have attached the file as well in case you want to have a more
>clear picture.
>> I really appreciate it if you can help me on this.
>> Thank you very much in advance.
>> Kind regards,Maria
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Feb 28 13:54:19 2017
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Tue, 28 Feb 2017 12:54:19 +0000
Subject: [R] Metafor multilevel metaregression: total variance increases
 when moderator added?
In-Reply-To: <31A98C8B8E62D84982441B63A46937D76CEE7DDB@FHSDB2D11-1.csu.mcmaster.ca>
References: <31A98C8B8E62D84982441B63A46937D76CEE7DDB@FHSDB2D11-1.csu.mcmaster.ca>
Message-ID: <e11690197623435188b90b26facf151f@UM-MAIL3216.unimaas.nl>

Very difficult to diagnose what is going on without actually seeing the data. But as I said on CV: Depending on the data, the variance components may not be estimated precisely, so negative values for those kinds of pseudo-R^2 statistics are quite possible. In fact, if a particular moderator is actually unrelated to the outcomes, then in roughly 50% of the cases, the pseudo-R^2 statistic will be negative.

See also:

Lopez-Lopez, J. A., Marin-Martinez, F., Sanchez-Meca, J., Van den Noortgate, W., & Viechtbauer, W. (2014). Estimation of the predictive power of the model in mixed-effects meta-regression: A simulation study. British Journal of Mathematical and Statistical Psychology, 67(1), 30-48.

We only examined the standard mixed-effects meta-regression model with a single moderator, but found that the pseudo-R^2 statistic can be all over the place unless k is quite large.

Now you seem to have a larger number of estimates (170), but these are nested in 'only' 26 studies. So, I suspect that the estimate-level variance component is estimated fairly precisely, but not the study-level variance component. You may want to examine the profile plots (with the profile() function) and/or get (profile-likelihood) CIs of the variance components (using the confint() function). Probably the CI for the study-level variance component is quite wide.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan,
>Laura
>Sent: Monday, February 27, 2017 20:05
>To: r-help at r-project.org
>Subject: [R] Metafor multilevel metaregression: total variance increases
>when moderator added?
>
>Hi there,
>
>I am running a two level multilevel meta-regression of 170 estimates
>nested within 3 informants nested within 26 studies. I run the null model
>to get a pooled estimate with random effects at the informant level and
>study level.
>
>Then I test a series of potential moderators (one at a time, given small
>number of studies and adjust p-values for multiple testing). I use:
>(sum(Model1$sigma2) - sum(Model2$sigma2)) / sum(Model1$sigma2)
>to compute the proportional reduction in the total variance from here:
>http://stackoverflow.com/questions/22356450/getting-r-squared-from-a-
>mixed-effects-multilevel-model-in-metafor
>
>For one moderator, I get a negative value for reduced total variance and
>an unexpected negative coefficient. Based on Wolfgang's response in the
>link above this is possible "depending on the size of your dataset, those
>variance components may not be estimated very precisely and that can lead
>to such counter-intuitive results".
>
>I am trying to diagnose why this model is not being estimated properly and
>why I am getting an unexpected negative result. When I remove the second
>level from the model and run a single-level random effects models of 170
>estimates nested within 26 studies, the coefficient is positive and as we
>would expect.
>
>Does anyone have any suggestions for what might be going on or how I might
>diagnose the problem with this model?
>
>Thanks,
>Laura
>
>Laura Duncan, M.A.
>Research Coordinator
>Offord Centre for Child Studies
>McMaster University
>
>Tel: 905 525 9140 x21504
>Fax: 905 574 6665
>duncanlj at mcmaster.ca
>ontariochildhealthstudy.ca<www.ontariochildhealthstudy.ca>
>offordcentre.com
>
>Mailing Address                                               Courier
>Address
>1280 Main St. W. MIP 201A                           175 Longwood Rd. S.
>MIP 201A
>Hamilton, Ontario L8S 4K1                             Hamilton, Ontario
>L8P 0A1


From petr.pikal at precheza.cz  Tue Feb 28 14:06:25 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 28 Feb 2017 13:06:25 +0000
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICDOo8+HzrXPhDogIHBsb3R0aW5nIGRhdGVz?=
 =?utf-8?q?_in_x_axis?=
In-Reply-To: <1622106255.4352257.1488284031116@mail.yahoo.com>
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
	<2026457994.3295018.1488209203201@mail.yahoo.com>
	<CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>
	<A62569FB-CA09-4FA4-A59E-5F62FED09AF1@dcn.davis.ca.us>
	<2124162590.4345707.1488282782793@mail.yahoo.com>
	<1622106255.4352257.1488284031116@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18231@SRVEXCHCM301.precheza.cz>

Hi

better to send us your data by copying result of dput()

Based on Jims toy data, do you want something like that?

plot(aa$sdate,aa$var1,xaxt="n")
sel <- seq(1,15, 2)
axis(1, at=axis.dates[sel], labels=format(axis.dates, "%Y")[sel])

You can easily adopt it by managing the sequention.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria
> Lathouri via R-help
> Sent: Tuesday, February 28, 2017 1:14 PM
> To: r-help at r-project.org; Jim Lemon <drjimlemon at gmail.com>
> Subject: [R] ????: ????: plotting dates in x axis
>
> Dear Jim
> Many thanks for this. I tried and it somehow worked. I removed the nlines=3
> from your script so I can have the years in one line, but still the problem is
> that while trying to show all the years, there are years in the first line and
> then other years in a second line. I was wondering if I can show every two
> years instead. I think it would be much better. Many thanks. Kind
> regards,Maria
>
>     ???? 11:56 ?.?. ?????, 28 ??????????? 2017, ?/? Maria Lathouri via R-help
> <r-help at r-project.org> ??????:
>
>
>  Dear all,
> Sorry about that. My mistake. Here is an example of my data
> > head(aa)       SDATE  var11 1998-01-29 0.7282 1998-02-17 1.0803
> > 1998-03-20 0.6374 1998-05-07 1.1205 1998-05-26 0.9036 1998-06-05
> > 1.210.........................178 2012-10-4  0.71179 2012-11-4
> > 0.663180 2012-12-10 0.484
> I hope this helps.
> Maria
>
>     ???? 10:00 ?.?. ???????, 27 ??????????? 2017, ?/? Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> ??????:
>
>
>  While humorous, the term "Mexican Wall" is unlikely to be clear to the OP.
> This is a reference to the mailing list anti-virus strategy of cutting out
> attachments that don't meet a very restrictive set of requirements outlined
> in the Posting Guide that all R-users are supposed to have read and
> memorized, but which few even seem to know exists. You can best avoid the
> "Mexican Wall" by setting your email program to send plain text instead of
> HTML, and to embed your R code example (believe it or not, this is not the
> Excel-To-R translation service, so show us your R code and text data, not your
> Excel file) in the email along with your description of your problem. For more
> help on getting help search the Internet for "R reproducible example".
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 27, 2017 1:11:05 PM PST, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >Hi Maria,
> >First, Excel files don't make it through the Mexican Wall. A CSV with
> >the extension changed to .txt might. You can get all of the years like
> >this:
> >
> >aa<-data.frame(var1=runif(180),
> > SDATE=paste(sample(1998:2012,180,TRUE),
> > sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
> >aa$sdate<-as.Date(aa$SDATE)
> >plot(aa$sdate,aa$var1,xaxt="n")
> >library(plotrix)
> ># set the tick marks at the middle of each year
> >axis.dates<-as.Date(paste(1998:2012,6,30,sep="-"))
> >staxlab(1,axis.dates,1998:2012,nlines=3)
> >
> >Obviously you don't want all of the months, so just add the months to
> >the years:
> >
> >plot(aa$sdate,aa$var1,xaxt="n")
> >staxlab(1,axis.dates,format(axis.dates,"%b/%Y"),nlines=3)
> >
> >Jim
> >
> >
> >On Tue, Feb 28, 2017 at 2:26 AM, Maria Lathouri via R-help
> ><r-help at r-project.org> wrote:
> >> Dear all,
> >> I have an excel file of 180 observations with dates and one variable,
> >from 1998 to 2012 by random months (there are some years that I might
> >not have all the months or I might have two observations in one month).
> >I am trying to plot the dates in x axis and the variable in y axis. I
> >have already used as.Date for the dates so I can import them into R.
> >> Here is my script:> aa<-read.csv("aa.csv")> attach(aa)>
> >names(aa)#"SDATE" "var1"
> >> I convert the dates into R: > sdate<-as.Date(SDATE,
> >format="%Y-%m-%d")
> >>
> >> I am plotting the dates with my var1:> plot(sdate, var1, type="l") Up
> >> to now, everything seems ok. However, in the x-axis I only get
> >three years, 2000, 2005 and 2010. As I want to show all the years or at
> >least as many as it could be, I am using the following:
> >>> plot(sdate, var1, type="l", xaxt="n")
> >>
> >>> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
> >>> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"),
> >cex.axis=0.8,las=2);  I tried also to plot the dates in a month-Year
> >form:
> >>
> >>> d2<-as.Date((d1[1])+150*(0:20))
> >>> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15,
> >labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)
> >>
> >> But nothing happened. I cannot understand why it doesn't show
> >anything.
> >> I have attached the file as well in case you want to have a more
> >clear picture.
> >> I really appreciate it if you can help me on this.
> >> Thank you very much in advance.
> >> Kind regards,Maria
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pgcim15.harshal at spjimr.org  Tue Feb 28 10:38:38 2017
From: pgcim15.harshal at spjimr.org (Harshal Athawale)
Date: Tue, 28 Feb 2017 10:38:38 +0100
Subject: [R] Replace Text but not from within a word
Message-ID: <CABu02i+X5a=x9MAy_mcYL1OYaP2Pm=RALx85dvrOn6VYnyLxVg@mail.gmail.com>

I am new in R.

I have a file. This file contains name of the companies.
'data.frame': 494 obs. of  1 variable:
 $ V1: Factor w/ 470 levels "3-d engineering corp",..: 293 134 339 359 143
399 122 447 398 384 ...

Problem: I would like to remove "CO" (As it is the most frequent word). I
would like "CO" to removed from BOEING CO --> BOEING but not from SAGINAW
*CO*UNTY INC*. *

> text = c("BOEING CO","ENGMANTAYLOR CO","SAGINAW COUNTY INC")

> gsub(x = text, pattern = "CO", replacement = "")

[1] "BOEING "       "ENGMANTAYLOR " "SAGINAW UNTY"

Thanks in advance.

- Sam

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Feb 28 14:19:40 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 28 Feb 2017 07:19:40 -0600
Subject: [R] Replace Text but not from within a word
In-Reply-To: <CABu02i+X5a=x9MAy_mcYL1OYaP2Pm=RALx85dvrOn6VYnyLxVg@mail.gmail.com>
References: <CABu02i+X5a=x9MAy_mcYL1OYaP2Pm=RALx85dvrOn6VYnyLxVg@mail.gmail.com>
Message-ID: <352C8145-9583-4F5B-86A0-718454DCF21A@me.com>


> On Feb 28, 2017, at 3:38 AM, Harshal Athawale <pgcim15.harshal at spjimr.org> wrote:
> 
> I am new in R.
> 
> I have a file. This file contains name of the companies.
> 'data.frame': 494 obs. of  1 variable:
> $ V1: Factor w/ 470 levels "3-d engineering corp",..: 293 134 339 359 143
> 399 122 447 398 384 ...
> 
> Problem: I would like to remove "CO" (As it is the most frequent word). I
> would like "CO" to removed from BOEING CO --> BOEING but not from SAGINAW
> *CO*UNTY INC*. *
> 
>> text = c("BOEING CO","ENGMANTAYLOR CO","SAGINAW COUNTY INC")
> 
>> gsub(x = text, pattern = "CO", replacement = "")
> 
> [1] "BOEING "       "ENGMANTAYLOR " "SAGINAW UNTY"
> 
> Thanks in advance.
> 
> - Sam


Hi,

See ?regex and ?grep for some details and examples on how to construct the expression used for matching, as well as some of the references therein.

In this case, you want to use something along the lines of:

> gsub(" CO$", "", text)
[1] "BOEING"             "ENGMANTAYLOR"       "SAGINAW COUNTY INC"

where the "CO" is preceded by a space and followed by the "$", which is a special character that indicates the end of the string to be matched.

Regards,

Marc Schwartz


	[[alternative HTML version deleted]]


From therneau at mayo.edu  Tue Feb 28 15:26:13 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 28 Feb 2017 08:26:13 -0600
Subject: [R] R: How to prune using holdout data
In-Reply-To: <006601d29111$0325b4c0$09711e40$@fastwebnet.it>
References: <006601d29111$0325b4c0$09711e40$@fastwebnet.it>
Message-ID: <f40b15$5tvrgv@ironport10.mayo.edu>

Let me give an outline of how to answer Alfredo's question via an example.
I will split the data set "lung" into two peices.  For these subjects with
advanced lung cancer the physician's assessment of ECOG performance status
(ph.ecog) is one of the most powerful indicators of outcome.  Try to
predict it from other variables.

library(survival)   # for the test data set
library(rpart)

data1 <- lung[1:125,]
data2 <- lung[126:228,]

rfit1 <- rpart(ph.ecog ~ ., data=data1)
printcp(rfit1)

         CP nsplit rel error  xerror     xstd
1 0.565788      0   1.00000 1.04037 0.100516
2 0.098516      1   0.43421 0.44906 0.045001
3 0.042708      2   0.33570 0.35134 0.041692
4 0.031032      3   0.29299 0.37610 0.042971
5 0.019949      4   0.26196 0.37753 0.044692
6 0.010000      5   0.24201 0.39166 0.050332

# Validate using data2.  First get predictions for each of the pruned trees
cpvalues <- rfit1$cptable[,1]
pmat <- matrix(0, nrow(data2), length(cpvalues))
for (i in 1:length(cpvalues))
     pmat[,i] <- predict(prune(rfit1, cpvalues[i]), newdata=data2)

Now, we need to decide what on a measure of error.  Try simple squared error.

error <- colMeans((data2$ph.ecog - pmat)^2)
round(error, 3)
[1] 0.493 0.280 0.210 0.225 0.186 0.198

This is simple, but other cases are more complex.  The performace score is
actually an integer from 0-4 (5= dead), see
   http://ecog-acrin.org/resources/ecog-performance-status

table(lung$ph.ecog)
   0   1   2   3
  63 113  50   1

Suppose instead we fit a model and treat the response as categorical?
The total number of nested models is a bit smaller.

rfit2 <- rpart(ph.ecog ~ ., data=data1, method="class")

printcp(rfit2)
        CP nsplit rel error  xerror     xstd
1 0.35938      0   1.00000 1.00000 0.086951
2 0.12500      1   0.64062 0.64062 0.081854
3 0.06250      2   0.51562 0.70312 0.083662
4 0.03125      4   0.39062 0.57812 0.079610
5 0.01000      5   0.35938 0.56250 0.078977

  predict(rfit2, newdata=data2)[1:5,]
           0      1       2 3
126 0.03125 0.9375 0.03125 0
127 0.03125 0.9375 0.03125 0
128 0.03125 0.9375 0.03125 0
129 0.03125 0.9375 0.03125 0
130 0.37500 0.6250 0.00000 0

Now, we can ask for predicted probabilities for each class (default), which is a vector
of length 4 for each subject, or for the predicted class, which is a single value.  Which
do we want, and then what is the best measure of prediction error?
If three subjects with value 0 had prediction class vectors of (.8, .2, 0, 0),
(.8, .1, .1, 0) and (.45, .25, .2, .1), one outlook would say they all are the
same (all pick 0 as the best), others would give them different errors.  Is
the second prediction worse than the first?

What if the single subject with ph.ecog=3 had ended up in the validation data
set; how should we judge their prediction?

This complexity is one reason that there is not a simple function for
"validation" with a new data set.



On 02/27/2017 09:48 AM, Alfredo wrote:
> Thank you, Terry, for your answer.
>
> I?ll try to explain better my question. When you create a classification or regression
> tree you first grow a tree based on a splitting criteria: this usually results in a large
> tree that provides a good fit to the training data. The problem with this tree is its
> potential for overfitting the data: the tree can be tailored too specifically to the
> training data and not generalize well to new data. The solution (apart cross-validation)
> is to find a smaller subtree that results in a low error rate on *holdout or validation data.*
>
> Hope it helps to clarity my question.
>
> Best,
>
> Alfredo
>
> -----Messaggio originale-----
> Da: Therneau, Terry M., Ph.D. [mailto:therneau at mayo.edu]
>
> You will need to give more detail of exactly what you mean by "prune using a validation
> set". THe prune.rpart function will prune at any value you want, what I suspect you are
> looking for is to compute the error of each possible tree, using a validation data set,
> then find the best one, and then prune there.
>
> How do you define "best"?
>


From jdnewmil at dcn.davis.ca.us  Tue Feb 28 15:36:59 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 28 Feb 2017 06:36:59 -0800
Subject: [R] Replace Text but not from within a word
In-Reply-To: <352C8145-9583-4F5B-86A0-718454DCF21A@me.com>
References: <CABu02i+X5a=x9MAy_mcYL1OYaP2Pm=RALx85dvrOn6VYnyLxVg@mail.gmail.com>
	<352C8145-9583-4F5B-86A0-718454DCF21A@me.com>
Message-ID: <F7D18060-9248-4BFF-9F79-6718C9903C36@dcn.davis.ca.us>

For tasks like this, you will probably want to make sure to import the data as character data rather than as a factor.  E.g.

dat <- read.csv( "myfile.csv", header=FALSE, as.is=TRUE )

You can check what you have with the str() function.
-- 
Sent from my phone. Please excuse my brevity.

On February 28, 2017 5:19:40 AM PST, Marc Schwartz <marc_schwartz at me.com> wrote:
>
>> On Feb 28, 2017, at 3:38 AM, Harshal Athawale
><pgcim15.harshal at spjimr.org> wrote:
>> 
>> I am new in R.
>> 
>> I have a file. This file contains name of the companies.
>> 'data.frame': 494 obs. of  1 variable:
>> $ V1: Factor w/ 470 levels "3-d engineering corp",..: 293 134 339 359
>143
>> 399 122 447 398 384 ...
>> 
>> Problem: I would like to remove "CO" (As it is the most frequent
>word). I
>> would like "CO" to removed from BOEING CO --> BOEING but not from
>SAGINAW
>> *CO*UNTY INC*. *
>> 
>>> text = c("BOEING CO","ENGMANTAYLOR CO","SAGINAW COUNTY INC")
>> 
>>> gsub(x = text, pattern = "CO", replacement = "")
>> 
>> [1] "BOEING "       "ENGMANTAYLOR " "SAGINAW UNTY"
>> 
>> Thanks in advance.
>> 
>> - Sam
>
>
>Hi,
>
>See ?regex and ?grep for some details and examples on how to construct
>the expression used for matching, as well as some of the references
>therein.
>
>In this case, you want to use something along the lines of:
>
>> gsub(" CO$", "", text)
>[1] "BOEING"             "ENGMANTAYLOR"       "SAGINAW COUNTY INC"
>
>where the "CO" is preceded by a space and followed by the "$", which is
>a special character that indicates the end of the string to be matched.
>
>Regards,
>
>Marc Schwartz
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Tue Feb 28 15:50:18 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 28 Feb 2017 08:50:18 -0600
Subject: [R] Replace Text but not from within a word
In-Reply-To: <F7D18060-9248-4BFF-9F79-6718C9903C36@dcn.davis.ca.us>
References: <CABu02i+X5a=x9MAy_mcYL1OYaP2Pm=RALx85dvrOn6VYnyLxVg@mail.gmail.com>
	<352C8145-9583-4F5B-86A0-718454DCF21A@me.com>
	<F7D18060-9248-4BFF-9F79-6718C9903C36@dcn.davis.ca.us>
Message-ID: <BFF55064-F4DA-4B34-A23A-F03452DB7AF5@me.com>


> On Feb 28, 2017, at 8:36 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> For tasks like this, you will probably want to make sure to import the data as character data rather than as a factor.  E.g.
> 
> dat <- read.csv( "myfile.csv", header=FALSE, as.is=TRUE )
> 
> You can check what you have with the str() function.


Jeff,

Narrowly, for this particular task, that is not relevant.

gsub() and family use as.character() internally to coerce a factor to character and will work just fine:

text <- factor(c("BOEING CO","ENGMANTAYLOR CO","SAGINAW COUNTY INC"))

> text
[1] BOEING CO          ENGMANTAYLOR CO    SAGINAW COUNTY INC
Levels: BOEING CO ENGMANTAYLOR CO SAGINAW COUNTY INC

> gsub(" CO$", "", text)
[1] "BOEING"             "ENGMANTAYLOR"       "SAGINAW COUNTY INC"

Using 'as.is' becomes more a personal preference issue beyond this.

Regards,

Marc


> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On February 28, 2017 5:19:40 AM PST, Marc Schwartz <marc_schwartz at me.com> wrote:
>> 
>>> On Feb 28, 2017, at 3:38 AM, Harshal Athawale
>> <pgcim15.harshal at spjimr.org> wrote:
>>> 
>>> I am new in R.
>>> 
>>> I have a file. This file contains name of the companies.
>>> 'data.frame': 494 obs. of  1 variable:
>>> $ V1: Factor w/ 470 levels "3-d engineering corp",..: 293 134 339 359
>> 143
>>> 399 122 447 398 384 ...
>>> 
>>> Problem: I would like to remove "CO" (As it is the most frequent
>> word). I
>>> would like "CO" to removed from BOEING CO --> BOEING but not from
>> SAGINAW
>>> *CO*UNTY INC*. *
>>> 
>>>> text = c("BOEING CO","ENGMANTAYLOR CO","SAGINAW COUNTY INC")
>>> 
>>>> gsub(x = text, pattern = "CO", replacement = "")
>>> 
>>> [1] "BOEING "       "ENGMANTAYLOR " "SAGINAW UNTY"
>>> 
>>> Thanks in advance.
>>> 
>>> - Sam
>> 
>> 
>> Hi,
>> 
>> See ?regex and ?grep for some details and examples on how to construct
>> the expression used for matching, as well as some of the references
>> therein.
>> 
>> In this case, you want to use something along the lines of:
>> 
>>> gsub(" CO$", "", text)
>> [1] "BOEING"             "ENGMANTAYLOR"       "SAGINAW COUNTY INC"
>> 
>> where the "CO" is preceded by a space and followed by the "$", which is
>> a special character that indicates the end of the string to be matched.
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 


	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Tue Feb 28 16:30:29 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Tue, 28 Feb 2017 15:30:29 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICDOo8+HzrXPhDogIM6jz4fOtc+EOiAgcGxv?=
 =?utf-8?q?tting_dates_in_x_axis?=
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18231@SRVEXCHCM301.precheza.cz>
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
	<2026457994.3295018.1488209203201@mail.yahoo.com>
	<CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>
	<A62569FB-CA09-4FA4-A59E-5F62FED09AF1@dcn.davis.ca.us>
	<2124162590.4345707.1488282782793@mail.yahoo.com>
	<1622106255.4352257.1488284031116@mail.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5A18231@SRVEXCHCM301.precheza.cz>
Message-ID: <2041682215.4649722.1488295829287@mail.yahoo.com>

Hi Petr
I followed your suggestion and I have attached a saved txt file with the data and the script using dput(). I hope this time will work.?
But by the way your code worked as well.?
Many thanks.?
Kind regards,Maria 

    ???? 1:06 ?.?. ?????, 28 ??????????? 2017, ?/? PIKAL Petr <petr.pikal at precheza.cz> ??????:
 

 Hi

better to send us your data by copying result of dput()

Based on Jims toy data, do you want something like that?

plot(aa$sdate,aa$var1,xaxt="n")
sel <- seq(1,15, 2)
axis(1, at=axis.dates[sel], labels=format(axis.dates, "%Y")[sel])

You can easily adopt it by managing the sequention.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria
> Lathouri via R-help
> Sent: Tuesday, February 28, 2017 1:14 PM
> To: r-help at r-project.org; Jim Lemon <drjimlemon at gmail.com>
> Subject: [R] ????: ????: plotting dates in x axis
>
> Dear Jim
> Many thanks for this. I tried and it somehow worked. I removed the nlines=3
> from your script so I can have the years in one line, but still the problem is
> that while trying to show all the years, there are years in the first line and
> then other years in a second line. I was wondering if I can show every two
> years instead. I think it would be much better. Many thanks. Kind
> regards,Maria
>
>? ? ???? 11:56 ?.?. ?????, 28 ??????????? 2017, ?/? Maria Lathouri via R-help
> <r-help at r-project.org> ??????:
>
>
>? Dear all,
> Sorry about that. My mistake. Here is an example of my data
> > head(aa)? ? ? SDATE? var11 1998-01-29 0.7282 1998-02-17 1.0803
> > 1998-03-20 0.6374 1998-05-07 1.1205 1998-05-26 0.9036 1998-06-05
> > 1.210.........................178 2012-10-4? 0.71179 2012-11-4
> > 0.663180 2012-12-10 0.484
> I hope this helps.
> Maria
>
>? ? ???? 10:00 ?.?. ???????, 27 ??????????? 2017, ?/? Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> ??????:
>
>
>? While humorous, the term "Mexican Wall" is unlikely to be clear to the OP.
> This is a reference to the mailing list anti-virus strategy of cutting out
> attachments that don't meet a very restrictive set of requirements outlined
> in the Posting Guide that all R-users are supposed to have read and
> memorized, but which few even seem to know exists. You can best avoid the
> "Mexican Wall" by setting your email program to send plain text instead of
> HTML, and to embed your R code example (believe it or not, this is not the
> Excel-To-R translation service, so show us your R code and text data, not your
> Excel file) in the email along with your description of your problem. For more
> help on getting help search the Internet for "R reproducible example".
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 27, 2017 1:11:05 PM PST, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >Hi Maria,
> >First, Excel files don't make it through the Mexican Wall. A CSV with
> >the extension changed to .txt might. You can get all of the years like
> >this:
> >
> >aa<-data.frame(var1=runif(180),
> > SDATE=paste(sample(1998:2012,180,TRUE),
> > sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
> >aa$sdate<-as.Date(aa$SDATE)
> >plot(aa$sdate,aa$var1,xaxt="n")
> >library(plotrix)
> ># set the tick marks at the middle of each year
> >axis.dates<-as.Date(paste(1998:2012,6,30,sep="-"))
> >staxlab(1,axis.dates,1998:2012,nlines=3)
> >
> >Obviously you don't want all of the months, so just add the months to
> >the years:
> >
> >plot(aa$sdate,aa$var1,xaxt="n")
> >staxlab(1,axis.dates,format(axis.dates,"%b/%Y"),nlines=3)
> >
> >Jim
> >
> >
> >On Tue, Feb 28, 2017 at 2:26 AM, Maria Lathouri via R-help
> ><r-help at r-project.org> wrote:
> >> Dear all,
> >> I have an excel file of 180 observations with dates and one variable,
> >from 1998 to 2012 by random months (there are some years that I might
> >not have all the months or I might have two observations in one month).
> >I am trying to plot the dates in x axis and the variable in y axis. I
> >have already used as.Date for the dates so I can import them into R.
> >> Here is my script:> aa<-read.csv("aa.csv")> attach(aa)>
> >names(aa)#"SDATE" "var1"
> >> I convert the dates into R: > sdate<-as.Date(SDATE,
> >format="%Y-%m-%d")
> >>
> >> I am plotting the dates with my var1:> plot(sdate, var1, type="l") Up
> >> to now, everything seems ok. However, in the x-axis I only get
> >three years, 2000, 2005 and 2010. As I want to show all the years or at
> >least as many as it could be, I am using the following:
> >>> plot(sdate, var1, type="l", xaxt="n")
> >>
> >>> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
> >>> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"),
> >cex.axis=0.8,las=2);? I tried also to plot the dates in a month-Year
> >form:
> >>
> >>> d2<-as.Date((d1[1])+150*(0:20))
> >>> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15,
> >labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)
> >>
> >> But nothing happened. I cannot understand why it doesn't show
> >anything.
> >> I have attached the file as well in case you want to have a more
> >clear picture.
> >> I really appreciate it if you can help me on this.
> >> Thank you very much in advance.
> >> Kind regards,Maria
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>
>? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


   
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: savedaa.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170228/13e3427d/attachment.txt>

From dcarlson at tamu.edu  Tue Feb 28 16:38:59 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 28 Feb 2017 15:38:59 +0000
Subject: [R] if and
In-Reply-To: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>
References: <CAJOiR6aK0=1fcT-Sr8vNtP01whtyHQ3DYcoyiRjFV9RiT7Do9A@mail.gmail.com>
Message-ID: <dbef9cf7f0ce41c780840089a8d7ec7f@exch-2p-mbx-w2.ads.tamu.edu>

This is not a reproducible example. You did not even show us one of the scripts that apparently did work. None of your if() statements contains a logical expression. You should read "An Introduction to R" and probably other tutorials on R.

https://cran.r-project.org/doc/manuals/r-release/R-intro.html

especially

https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Logical-vectors

and the manual pages at

?Comparison

and

?"%in%"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
Sent: Monday, February 27, 2017 7:48 PM
To: R help <r-help at r-project.org>
Subject: [R] if and

Currently I have  about  six or more  scripts that do the same job.  I
thought it might be possible and more efficient to use one script by using
IF ELSE statements. Here is an example but this will be expandable for
several countries ans year-months


Year-month = FEB2015, FEB2012,  Feb2010
 country  = USA, CAN.MEX
First I want to do if country = USA and year-month = FEB2015, FEB2012 do
the statements
second if country = CAN and year-month =Feb2010 do  the statements


if(country="USA" & year-month = "FEB2015" | "FEB2012" ){
statemnt1
.
statemnt10

} else if (country="USA" & year-month ="FEB2015") {
statemnt1
.
statemnt10
}

else
{
statemnt1
.
statemnt10
}

The above script did not work. is there a different ways of doing it?

Thank you in advance
.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From peter.mills at strath.ac.uk  Tue Feb 28 16:39:20 2017
From: peter.mills at strath.ac.uk (Peter Mills)
Date: Tue, 28 Feb 2017 15:39:20 +0000
Subject: [R] Von Mises mixtures: mu and kappa?
In-Reply-To: <CAGxFJbQn74BYsGe3sx_FCh-jJu783OW7syf9gf7uCOHg3_JEYA@mail.gmail.com>
References: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86CCD8@EX2010-MBX2.ds.strath.ac.uk>
	<CAGxFJbQn74BYsGe3sx_FCh-jJu783OW7syf9gf7uCOHg3_JEYA@mail.gmail.com>
Message-ID: <614DB8CF3AC0E3418AE4E12A0C79FD6A5D86F421@EX2010-MBX2.ds.strath.ac.uk>

Thank you Bert for the references. I have found mix.vmf as a possible alternative to movMF but am stuck with applying either to my application.

Does anyone know why mix.vmf requires to 2 columns for x?

For example when I use:
gWD <- c(0.1, 1, 0.9, 0.7,0.3)
> mix.vmf(gWD, 2)

I get the error:
?Error in matrix(nrow = n, ncol = g) : non-numeric matrix extent?

The following code works but I'm not sure how to adapt this to the application I require. What I need is to calculate the mixture parameters for a vector of directional data not a matrix. Could anyone suggest how I can do this?

k <- c(1, 2)
prob <- c(0.3, 0.4, 0.3)
mu <- matrix(rnorm(4), ncol = 2)
mu <- mu / sqrt( rowSums(mu^2) )
x <- rmixvmf(10, prob, mu, k)$x
mix.vmf(x, 3)

With regards to my original post and using movMF I'm stuck with this also. I found the following from [1], I thought this was the answer however it seems to need some adjustment as it is not giving me the theta and kappa values I started with:
kappa2 <- row_norms(y2$theta)
mu2<-y2$theta/row_norms(y2$theta)

[1] On lines 94 and 107 of ?v58i10.R: R example code from the paper ? available from https://www.jstatsoft.org/article/view/v058i10

Any suggestion would be greatly appreciated as after a further week of researching this and trying code I still don't seem to have working code.


Here is some code I am using as a testing example:
################################################
## Generate and fit a "small-mix" data set a la Banerjee et al.
mu1 <- rbind(c(-0.251, -0.968),
            c(0.399, 0.917))
kappa1 <- c(4, 4)
theta <- kappa1 * mu1
alpha <- c(0.48, 0.52)
## Generate a sample of size n = 50 from the von Mises-Fisher mixture ## with the above parameters.
set.seed(123)
x <- rmovMF(50, theta, alpha)
## Fit a von Mises-Fisher mixture with the "right" number of components, ## using 10 EM runs.
y2 <- movMF(x, 2, nruns = 10)

kappa2 <- row_norms(y2$theta)
mu2<-y2$theta/row_norms(y2$theta)


mu3c <- lapply(y2, function(x) y2$theta / row_norms(y2$theta)) ################################################

I don't understand why this doesn't give me the values of mu and kappa I started with. I have tried to adapted this code to have the same number of mu and kappa values but it doesn't work then as mu is know longer a matrix.

I don't understand why both movMF and mix.vmf give both mu1 and mu2 values per kappa value. In other words for a Von Mises mixture with 3 mixtures (clusters) the code gives 6 mu values and 3 kappa values. I was expecting to get 3 preferred directions (mu).

For example:
mix.vmf(x, 3) gives

$param
                mu1        	mu2     	kappa     probs
Cluster 1 0.4985047 -0.8668870 12.281773 0.3571429
Cluster 2 0.9490725  0.3150578 34.028465 0.2857143
Cluster 3 0.1017800  0.9948069  4.182367 0.3571429

Many thanks
Peter

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: 14 February 2017 17:49
To: Peter Mills
Cc: r-help at r-project.org
Subject: Re: [R] Von Mises mixtures: mu and kappa?

Please search before posting!

Searching "von mises mixture distributions" on rseek.org brought up what appeared to be several relevant hits. If none of these meet your needs, you should probably explain why not in a follow up post.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Feb 14, 2017 at 8:55 AM, Peter Mills <peter.mills at strath.ac.uk> wrote:
> Hello
>
> I am trying to calculate the values of the concentration parameters (kappa) and preferred direction (mu) for a Von Mises mixture model. I currently have some R code that gives me optimised values for the product of kappa and mu, but I'm not sure how to calculate them when both are unknown? How could I calculate mu and kappa from y2 if I didn't know either in the 1st place? I what to use movMF to give me values of kappa from some directional data where I don't know either kappa or mu.
>
>
> ## Generate and fit a "small-mix" data set a la Banerjee et al.
> mu <- rbind(c(-0.251, -0.968),
>             c(0.399, 0.917))
> kappa <- c(4, 4)
>
> theta <- kappa * mu
> theta
> alpha <- c(0.48, 0.52)
>
> ## Generate a sample of size n = 50 from the von Mises-Fisher mixture 
> ## with the above parameters.
> set.seed(123)
> x <- rmovMF(50, theta, alpha)
> ## Fit a von Mises-Fisher mixture with the "right" number of 
> components, ## using 10 EM runs.
> y2 <- movMF(x, 2, nruns = 10)
>
> Y2 gives
>> y2
> theta:
>        [,1]      [,2]
> 1  2.443225  5.259337
> 2 -1.851384 -4.291278
> alpha:
> [1] 0.4823648 0.5176352
> L:
> [1] 24.98124
>
> How could I calculate kappa and mu if I didn't know either in the 1st place?
>
> Thanks
> Peter
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From plessthanpointohfive at gmail.com  Tue Feb 28 17:22:30 2017
From: plessthanpointohfive at gmail.com (Jen)
Date: Tue, 28 Feb 2017 16:22:30 +0000
Subject: [R] How to speed this up?
Message-ID: <CAOxgQ=XaE3UtiKmm4DeWwHRj7DxwOae10aawXmitLJCtxgUSUQ@mail.gmail.com>

Hi, I'm trying to generate 2.5 million phone numbers.  The code below
generates a random sample of 250K MPNS for Morocco.  It takes about 10
minutes.

I need to generate 2.5 million.  I've run it through once and it took about
45 hours.

Is there a way to speed this up?

Thanks,

Jen

# generate random sample of mobile phone numbers (MPNs) - Morocco

# Mobile phone number format:  +212-6xx-xxxxxx

library(data.table)

# country code

cc <- "+212"

# prefixes

IAM  <- data.table(matrix(c(610,        611,    613,    615,    616,
618,    641,    642,    648,    650,    651,    652,    653,
          654,  655,    658,    659,    661,    662,    666,    667,
668,    670,    671,    672,    673,
          676,  677,    678), dimnames=list(NULL, "IAM")))



Medi <- data.table(matrix(c(612,        614,    617,    619,    644,
645,    649,    656,    657,    660,    663,    664,    665,
          669,  674,    675,    679), dimnames=list(NULL, "Medi")))

MOROC <- data.table(matrix(c(0636, 0637), dimnames=list(NULL, "MOROC")))

# combine

mno <- c(IAM, Medi, MOROC)

# generate MPNs
MPN <- NULL

system.time(for (i in 1:250000){
# randomly select number from list

prefix <- sapply(mno[floor(runif(1, 1, length(mno)+1))], function(x)
sample(x, 1))

MNO <- names(prefix)

# randomly generate 6 numbers between 0 and 9, inclusive

nums <- floor(runif(6, 0, 9))

# concatenate

tmp <- c(paste(c(cc,prefix,t(nums)), sep="", collapse=""), MNO)

MPN[[i]] <- tmp

i <- i+1


})

# unlist

df <- data.table(matrix(unlist(MPN), nrow=length(MPN), ncol=2, byrow=T,
dimnames = list(seq(1, length(MPN),1), c("MPN", "MNO"))   ))

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Feb 28 17:46:01 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 28 Feb 2017 17:46:01 +0100
Subject: [R] How to speed this up?
In-Reply-To: <CAOxgQ=XaE3UtiKmm4DeWwHRj7DxwOae10aawXmitLJCtxgUSUQ@mail.gmail.com>
References: <CAOxgQ=XaE3UtiKmm4DeWwHRj7DxwOae10aawXmitLJCtxgUSUQ@mail.gmail.com>
Message-ID: <CAJuCY5yQehd27p5GC9VUfYM3B6yQUm91NZA0FoUkMubfdq11Pw@mail.gmail.com>

Dear Jen,

Vectorisation is the keyword here. 250k sample takes only 2.5 seconds on my
machine. 2.5 million takes 29 seconds.

n <- 250e3

# country code
cc <- "+212"
# prefixes
IAM <- c(610,        611,    613,    615,    616,
618,    641,    642,    648,    650,    651,    652,    653,
          654,  655,    658,    659,    661,    662,    666,    667,
668,    670,    671,    672,    673,
          676,  677,    678)
Medi <- c(612,        614,    617,    619,    644,
645,    649,    656,    657,    660,    663,    664,    665,
          669,  674,    675,    679)
MOROC <- c(0636, 0637)
prefix <- rbind(
  data.frame(
    region = "IAM",
    prefix = IAM
  ),
  data.frame(
    region = "Medi",
    prefix = Medi
  ),
  data.frame(
    region = "MOROC",
    prefix = MOROC
  )
)
prefix <- merge(
  prefix,
  as.data.frame(table(region = prefix$region))
)
system.time({
  prefix.sample <- sample(prefix$prefix, n, prob = prefix$Freq, replace =
TRUE)
  nums <- apply(
    matrix(
      sample(0:9, 6 * n, replace = TRUE),
      ncol = 6
    ),
    1,
    paste,
    collapse = ""
  )
  phonenumbers <- paste0(cc, prefix.sample, nums)
})


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-02-28 17:22 GMT+01:00 Jen <plessthanpointohfive at gmail.com>:

> Hi, I'm trying to generate 2.5 million phone numbers.  The code below
> generates a random sample of 250K MPNS for Morocco.  It takes about 10
> minutes.
>
> I need to generate 2.5 million.  I've run it through once and it took about
> 45 hours.
>
> Is there a way to speed this up?
>
> Thanks,
>
> Jen
>
> # generate random sample of mobile phone numbers (MPNs) - Morocco
>
> # Mobile phone number format:  +212-6xx-xxxxxx
>
> library(data.table)
>
> # country code
>
> cc <- "+212"
>
> # prefixes
>
> IAM  <- data.table(matrix(c(610,        611,    613,    615,    616,
> 618,    641,    642,    648,    650,    651,    652,    653,
>           654,  655,    658,    659,    661,    662,    666,    667,
> 668,    670,    671,    672,    673,
>           676,  677,    678), dimnames=list(NULL, "IAM")))
>
>
>
> Medi <- data.table(matrix(c(612,        614,    617,    619,    644,
> 645,    649,    656,    657,    660,    663,    664,    665,
>           669,  674,    675,    679), dimnames=list(NULL, "Medi")))
>
> MOROC <- data.table(matrix(c(0636, 0637), dimnames=list(NULL, "MOROC")))
>
> # combine
>
> mno <- c(IAM, Medi, MOROC)
>
> # generate MPNs
> MPN <- NULL
>
> system.time(for (i in 1:250000){
> # randomly select number from list
>
> prefix <- sapply(mno[floor(runif(1, 1, length(mno)+1))], function(x)
> sample(x, 1))
>
> MNO <- names(prefix)
>
> # randomly generate 6 numbers between 0 and 9, inclusive
>
> nums <- floor(runif(6, 0, 9))
>
> # concatenate
>
> tmp <- c(paste(c(cc,prefix,t(nums)), sep="", collapse=""), MNO)
>
> MPN[[i]] <- tmp
>
> i <- i+1
>
>
> })
>
> # unlist
>
> df <- data.table(matrix(unlist(MPN), nrow=length(MPN), ncol=2, byrow=T,
> dimnames = list(seq(1, length(MPN),1), c("MPN", "MNO"))   ))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ashley.patton at aol.co.uk  Tue Feb 28 15:11:38 2017
From: ashley.patton at aol.co.uk (Ashley Patton)
Date: Tue, 28 Feb 2017 09:11:38 -0500
Subject: [R] Novice users in need of urgent help with boxplots
Message-ID: <15a850ff07f-670e-63a4@webstg-a07.mail.aol.com>


Hi, please forgive me but I am completely new to R and have no experience with it other than a 3 day training course but I need to use it for an urgent project and don't have time to learn a whole new language before the deadline, although I hope to get there soon.


My question is this. I have a dataset in Excel containing data from 20 sites. The data comes from loggers recording every half hour for a year. So my Excel file has 20 columns each with the name of the site as the header and each column contains the data recorded throughout the year. What I want to do is show the variation in that data at each site. So I would have a boxplot showing site 1, site 2, site 3... etc across the x axis and then the variable data (which in this case in air temperature) on the y axis so I can see what range in temperatures occurred throughout the year, what where the max, min, outliers etc. I have trawled the Internet looking for a code that will allow me to do this but all I can find is plots that refer to data where you are looking at a range in data with a category (like range in mpg with cylinder size) whereas I want to so look at the data for all of my sites just on one plot. I know this is possible because I have seen it down by someone else but I don't know where to start. Does anyone have any code that would do this or at least know where I could go? Like I say, I am a complete begging so writing code is a brand new thing for me. Many, many thanks to anyone who helps me with this one.


Many thanks


A

	[[alternative HTML version deleted]]


From rytis.bagdziunas at openanalytics.eu  Tue Feb 28 17:07:10 2017
From: rytis.bagdziunas at openanalytics.eu (Rytis Bagdziunas)
Date: Tue, 28 Feb 2017 17:07:10 +0100
Subject: [R] Optional arguments in stats::nls
Message-ID: <20170228160710.GA23489@oa-rbagdziunas>

Hello everyone,

I've been struggling with the usage of ellipsis argument for stats::nls
and similar functions. In particular, nls manual indicates this:

...: Additional optional arguments.  None are used at present.

However, "none are used" seems to be slightly misleading. Here's an
example:

data <- data.frame("x" = rnorm(100),
                   "y" = rnorm(100))
fn <- function(y, a) a * y

## This works
nls(y ~ fn(x, a), data = data, start = list("a" = 1))
## This doesn't
nls(y ~ fn(x, a), data = data, start = list("a" = 1), myarg = FALSE)
## But this does
nls(y ~ fn(x, a), data = data, start = list("a" = 1), myarg = rnorm(100))

traceback() indicates that the additional argument is passed to
model.frame.default() but doesn't appear to do anything.

Is this expected behaviour?

Rytis


From nicholas.wray at ntlworld.com  Tue Feb 28 18:52:46 2017
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Tue, 28 Feb 2017 17:52:46 +0000 (GMT)
Subject: [R] Novice users in need of urgent help with boxplots
In-Reply-To: <15a850ff07f-670e-63a4@webstg-a07.mail.aol.com>
References: <15a850ff07f-670e-63a4@webstg-a07.mail.aol.com>
Message-ID: <1097009413.2620363.1488304366764.JavaMail.open-xchange@oxbe21.tb.ukmail.iss.as9143.net>

The first thing you need to do is to read your data in.  Convert your excel file
to a csv file, say mydata.csv, and make sure that you know where it is eg folder
"Datafile" on C drive.  Then use setwd("C:/Datafile") and then
read.csv("mydata.csv")   That should upload it and you can trawl t'internet
looking at the masses of R sites for instructions on what to do next

Nick

> 
>     On 28 February 2017 at 14:11 Ashley Patton via R-help
> <r-help at r-project.org> wrote:
> 
> 
> 
>     Hi, please forgive me but I am completely new to R and have no experience
> with it other than a 3 day training course but I need to use it for an urgent
> project and don't have time to learn a whole new language before the deadline,
> although I hope to get there soon.
> 
> 
>     My question is this. I have a dataset in Excel containing data from 20
> sites. The data comes from loggers recording every half hour for a year. So my
> Excel file has 20 columns each with the name of the site as the header and
> each column contains the data recorded throughout the year. What I want to do
> is show the variation in that data at each site. So I would have a boxplot
> showing site 1, site 2, site 3... etc across the x axis and then the variable
> data (which in this case in air temperature) on the y axis so I can see what
> range in temperatures occurred throughout the year, what where the max, min,
> outliers etc. I have trawled the Internet looking for a code that will allow
> me to do this but all I can find is plots that refer to data where you are
> looking at a range in data with a category (like range in mpg with cylinder
> size) whereas I want to so look at the data for all of my sites just on one
> plot. I know this is possible because I have seen it down by someone else b!
>     ut I don't know where to start. Does anyone have any code that would do
> this or at least know where I could go? Like I say, I am a complete begging so
> writing code is a brand new thing for me. Many, many thanks to anyone who
> helps me with this one.
> 
> 
>     Many thanks
> 
> 
>     A
> 
>     [[alternative HTML version deleted]]
> 
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Feb 28 20:05:33 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 28 Feb 2017 13:05:33 -0600
Subject: [R] Novice users in need of urgent help with boxplots
In-Reply-To: <15a850ff07f-670e-63a4@webstg-a07.mail.aol.com>
References: <15a850ff07f-670e-63a4@webstg-a07.mail.aol.com>
Message-ID: <A0BAB593-A920-481E-9316-449D1A223502@me.com>


> On Feb 28, 2017, at 8:11 AM, Ashley Patton via R-help <r-help at r-project.org> wrote:
> 
> 
> Hi, please forgive me but I am completely new to R and have no experience with it other than a 3 day training course but I need to use it for an urgent project and don't have time to learn a whole new language before the deadline, although I hope to get there soon.
> 
> 
> My question is this. I have a dataset in Excel containing data from 20 sites. The data comes from loggers recording every half hour for a year. So my Excel file has 20 columns each with the name of the site as the header and each column contains the data recorded throughout the year. What I want to do is show the variation in that data at each site. So I would have a boxplot showing site 1, site 2, site 3... etc across the x axis and then the variable data (which in this case in air temperature) on the y axis so I can see what range in temperatures occurred throughout the year, what where the max, min, outliers etc. I have trawled the Internet looking for a code that will allow me to do this but all I can find is plots that refer to data where you are looking at a range in data with a category (like range in mpg with cylinder size) whereas I want to so look at the data for all of my sites just on one plot. I know this is possible because I have seen it down by someone else b!
> ut I don't know where to start. Does anyone have any code that would do this or at least know where I could go? Like I say, I am a complete begging so writing code is a brand new thing for me. Many, many thanks to anyone who helps me with this one.
> 
> 
> Many thanks
> 
> 
> A


Hi,

First, please post in plain text, not HTML/RTF, as the formatting of the text above is problematic for reading.

Second, posting "urgent" requests to an e-mail list with thousands of **volunteer** subscribers to meet your deadline, is an expectation that is not reasonable. You don't need to learn the entire language to complete your task, but learning pretty basic commands would be required.

I am surprised that a three day intro to R course would not have covered the basics of importing data into R from common sources, such as Excel, CSV files, etc, along with basic plot operations, which in your case, would be using the boxplot() function. From my perspective, you or your employer did not get your money's worth.

See the help page for the boxplot function for examples (accessed by typing ?boxplot in the R console), notably with a formula to specify the data to be plotted. 

The basic incantation for the boxplot for you would be something along the lines of:

  boxplot(AirTemp ~ Site, data = DataFrameContainingYourData)

where AirTemp and Site are replaced by the actual column names for the temperature data and site grouping variables, respectively. DataFrameContainingYourData is the data frame that results from importing your data into R.

Also, there is a general framework for getting help with R, that is linked from the R home page:

  https://www.r-project.org/help.html

Specifically, there is a dedicated Data Import/Export manual here:

  https://cran.r-project.org/manuals.html

along with other basic R manuals listed there (notably An Introduction to R), that you should avail yourself of, along with any materials that the course itself provided.

Regards,

Marc Schwartz


From murdoch.duncan at gmail.com  Tue Feb 28 20:08:37 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 28 Feb 2017 14:08:37 -0500
Subject: [R] Optional arguments in stats::nls
In-Reply-To: <20170228160710.GA23489@oa-rbagdziunas>
References: <20170228160710.GA23489@oa-rbagdziunas>
Message-ID: <ba4cc0bc-fae7-4b95-466e-db466f919916@gmail.com>

On 28/02/2017 11:07 AM, Rytis Bagdziunas wrote:
> Hello everyone,
>
> I've been struggling with the usage of ellipsis argument for stats::nls
> and similar functions. In particular, nls manual indicates this:
>
> ...: Additional optional arguments.  None are used at present.

The documentation is incorrect.

> However, "none are used" seems to be slightly misleading. Here's an
> example:
>
> data <- data.frame("x" = rnorm(100),
>                    "y" = rnorm(100))
> fn <- function(y, a) a * y
>
> ## This works
> nls(y ~ fn(x, a), data = data, start = list("a" = 1))
> ## This doesn't
> nls(y ~ fn(x, a), data = data, start = list("a" = 1), myarg = FALSE)
> ## But this does
> nls(y ~ fn(x, a), data = data, start = list("a" = 1), myarg = rnorm(100))
>
> traceback() indicates that the additional argument is passed to
> model.frame.default() but doesn't appear to do anything.
>
> Is this expected behaviour?

The docs should say "...:  additional arguments that may be passed to 
model.frame()".

Likely the reason the docs are wrong is that the call to model.frame is 
put together in a tricky way, using match.call(), and it's not so 
obvious what the conditions are under which it will be called.  I don't 
see a simple fix to the docs other than what I wrote above.

Duncan Murdoch


From dcarlson at tamu.edu  Tue Feb 28 21:19:07 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 28 Feb 2017 20:19:07 +0000
Subject: [R] Novice users in need of urgent help with boxplots
In-Reply-To: <A0BAB593-A920-481E-9316-449D1A223502@me.com>
References: <15a850ff07f-670e-63a4@webstg-a07.mail.aol.com>
	<A0BAB593-A920-481E-9316-449D1A223502@me.com>
Message-ID: <41b425da9c724265b1df32442cd89835@exch-2p-mbx-w2.ads.tamu.edu>

As Mark and Wray have indicated, you have not told us what you have actually tried other than search the internet. If you spent 3 days learning R and don't know how to import a .csv file from Excel, you should be emailing the instructor of the course. Use Save As in Excel to save your spreadsheet file as a .csv (comma separated values) file and then start R and use read.csv() to create a data frame. 

The first two commands create a sample data frame. The third command plots the columns of the data frame as side-by-side box plots:

set.seed(42)
logs <- data.frame(matrix(rnorm(250, 20, 5), 25, 10))
boxplot(logs)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc Schwartz
Sent: Tuesday, February 28, 2017 1:06 PM
To: Ashley Patton <ashley.patton at aol.co.uk>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Novice users in need of urgent help with boxplots


> On Feb 28, 2017, at 8:11 AM, Ashley Patton via R-help <r-help at r-project.org> wrote:
> 
> 
> Hi, please forgive me but I am completely new to R and have no experience with it other than a 3 day training course but I need to use it for an urgent project and don't have time to learn a whole new language before the deadline, although I hope to get there soon.
> 
> 
> My question is this. I have a dataset in Excel containing data from 20 sites. The data comes from loggers recording every half hour for a year. So my Excel file has 20 columns each with the name of the site as the header and each column contains the data recorded throughout the year. What I want to do is show the variation in that data at each site. So I would have a boxplot showing site 1, site 2, site 3... etc across the x axis and then the variable data (which in this case in air temperature) on the y axis so I can see what range in temperatures occurred throughout the year, what where the max, min, outliers etc. I have trawled the Internet looking for a code that will allow me to do this but all I can find is plots that refer to data where you are looking at a range in data with a category (like range in mpg with cylinder size) whereas I want to so look at the data for all of my sites just on one plot. I know this is possible because I have seen it down by someone else!
  b!
> ut I don't know where to start. Does anyone have any code that would do this or at least know where I could go? Like I say, I am a complete begging so writing code is a brand new thing for me. Many, many thanks to anyone who helps me with this one.
> 
> 
> Many thanks
> 
> 
> A


Hi,

First, please post in plain text, not HTML/RTF, as the formatting of the text above is problematic for reading.

Second, posting "urgent" requests to an e-mail list with thousands of **volunteer** subscribers to meet your deadline, is an expectation that is not reasonable. You don't need to learn the entire language to complete your task, but learning pretty basic commands would be required.

I am surprised that a three day intro to R course would not have covered the basics of importing data into R from common sources, such as Excel, CSV files, etc, along with basic plot operations, which in your case, would be using the boxplot() function. From my perspective, you or your employer did not get your money's worth.

See the help page for the boxplot function for examples (accessed by typing ?boxplot in the R console), notably with a formula to specify the data to be plotted. 

The basic incantation for the boxplot for you would be something along the lines of:

  boxplot(AirTemp ~ Site, data = DataFrameContainingYourData)

where AirTemp and Site are replaced by the actual column names for the temperature data and site grouping variables, respectively. DataFrameContainingYourData is the data frame that results from importing your data into R.

Also, there is a general framework for getting help with R, that is linked from the R home page:

  https://www.r-project.org/help.html

Specifically, there is a dedicated Data Import/Export manual here:

  https://cran.r-project.org/manuals.html

along with other basic R manuals listed there (notably An Introduction to R), that you should avail yourself of, along with any materials that the course itself provided.

Regards,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Feb 28 22:12:21 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 1 Mar 2017 08:12:21 +1100
Subject: [R] =?utf-8?b?zqPPh861z4Q6IHBsb3R0aW5nIGRhdGVzIGluIHggYXhpcw==?=
In-Reply-To: <1622106255.4352257.1488284031116@mail.yahoo.com>
References: <2026457994.3295018.1488209203201.ref@mail.yahoo.com>
	<2026457994.3295018.1488209203201@mail.yahoo.com>
	<CA+8X3fXRwuVT=dEdMa5ueXmLWncc=hHo9gd=-DG9eZa04tXzFw@mail.gmail.com>
	<A62569FB-CA09-4FA4-A59E-5F62FED09AF1@dcn.davis.ca.us>
	<2124162590.4345707.1488282782793@mail.yahoo.com>
	<1622106255.4352257.1488284031116@mail.yahoo.com>
Message-ID: <CA+8X3fU+YGKhFHxj=VjS_+MEhMKnj+3aqCKW15ZEvsLAi_UPsg@mail.gmail.com>

Hi Maria,
No problem. Taking the example I used before:

aa<-data.frame(var1=runif(180),
 SDATE=paste(sample(1998:2012,180,TRUE),
 sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
aa$sdate<-as.Date(aa$SDATE)
plot(aa$sdate,aa$var1,xaxt="n")
# set the tick marks at the middle of every other year
axis.dates<-as.Date(paste(seq(1998,2012,by=2),6,30,sep="-"))
axis(1,axis.dates,seq(1998,2012,by=2))

If you want to add months, the "axis" function will drop some of the
dates. The "staxlab" function uses either multiple lines or rotates
the labels to fit more in:

plot(aa$sdate,aa$var1,xaxt="n")
library(plotrix)
staxlab(1,axis.dates,format(axis.dates,"%b-%Y"),srt=45)

Jim


On Tue, Feb 28, 2017 at 11:13 PM, Maria Lathouri <mlathouri at yahoo.gr> wrote:
> Dear Jim
>
> Many thanks for this. I tried and it somehow worked. I removed the nlines=3
> from your script so I can have the years in one line, but still the problem
> is that while trying to show all the years, there are years in the first
> line and then other years in a second line.
>
> I was wondering if I can show every two years instead. I think it would be
> much better.
>
> Many thanks.
>
> Kind regards,
> Maria
>
>
> ???? 11:56 ?.?. ?????, 28 ??????????? 2017, ?/? Maria Lathouri via R-help
> <r-help at r-project.org> ??????:
>
>
> Dear all,
> Sorry about that. My mistake. Here is an example of my data
>> head(aa)       SDATE  var11 1998-01-29 0.7282 1998-02-17 1.0803 1998-03-20
>> 0.6374 1998-05-07 1.1205 1998-05-26 0.9036 1998-06-05
>> 1.210.........................178 2012-10-4  0.71179 2012-11-4  0.663180
>> 2012-12-10 0.484
>
> I hope this helps.
> Maria
>
>     ???? 10:00 ?.?. ???????, 27 ??????????? 2017, ?/? Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> ??????:
>
>
> While humorous, the term "Mexican Wall" is unlikely to be clear to the OP.
> This is a reference to the mailing list anti-virus strategy of cutting out
> attachments that don't meet a very restrictive set of requirements outlined
> in the Posting Guide that all R-users are supposed to have read and
> memorized, but which few even seem to know exists. You can best avoid the
> "Mexican Wall" by setting your email program to send plain text instead of
> HTML, and to embed your R code example (believe it or not, this is not the
> Excel-To-R translation service, so show us your R code and text data, not
> your Excel file) in the email along with your description of your problem.
> For more help on getting help search the Internet for "R reproducible
> example".
> --
> Sent from my phone. Please excuse my brevity.
>
> On February 27, 2017 1:11:05 PM PST, Jim Lemon <drjimlemon at gmail.com> wrote:
>>Hi Maria,
>>First, Excel files don't make it through the Mexican Wall. A CSV with
>>the extension changed to .txt might. You can get all of the years like
>>this:
>>
>>aa<-data.frame(var1=runif(180),
>> SDATE=paste(sample(1998:2012,180,TRUE),
>> sample(1:12,180,TRUE),sample(1:28,180,TRUE),sep="-"))
>>aa$sdate<-as.Date(aa$SDATE)
>>plot(aa$sdate,aa$var1,xaxt="n")
>>library(plotrix)
>># set the tick marks at the middle of each year
>>axis.dates<-as.Date(paste(1998:2012,6,30,sep="-"))
>>staxlab(1,axis.dates,1998:2012,nlines=3)
>>
>>Obviously you don't want all of the months, so just add the months to
>>the years:
>>
>>plot(aa$sdate,aa$var1,xaxt="n")
>>staxlab(1,axis.dates,format(axis.dates,"%b/%Y"),nlines=3)
>>
>>Jim
>>
>>
>>On Tue, Feb 28, 2017 at 2:26 AM, Maria Lathouri via R-help
>><r-help at r-project.org> wrote:
>>> Dear all,
>>> I have an excel file of 180 observations with dates and one variable,
>>from 1998 to 2012 by random months (there are some years that I might
>>not have all the months or I might have two observations in one month).
>>I am trying to plot the dates in x axis and the variable in y axis. I
>>have already used as.Date for the dates so I can import them into R.
>>> Here is my script:> aa<-read.csv("aa.csv")> attach(aa)>
>>names(aa)#"SDATE" "var1"
>>> I convert the dates into R: > sdate<-as.Date(SDATE,
>>format="%Y-%m-%d")
>>>
>>> I am plotting the dates with my var1:> plot(sdate, var1, type="l")
>>> Up to now, everything seems ok. However, in the x-axis I only get
>>three years, 2000, 2005 and 2010. As I want to show all the years or at
>>least as many as it could be, I am using the following:
>>>> plot(sdate, var1, type="l", xaxt="n")
>>>
>>>> d1<-c((sdate[1]), (sdate[183]))> d2<-as.Date((d1[1])+365*(0:15))
>>>> axis(side=1, at=0:15, labels=strftime(d2, format="%Y"),
>>cex.axis=0.8,las=2);  I tried also to plot the dates in a month-Year
>>form:
>>>
>>>> d2<-as.Date((d1[1])+150*(0:20))
>>>> plot(sdate, var1, type="l", xaxt="n")> axis(side=1, at=0:15,
>>labels=strftime(d2, format="%m-%Y"), cex.axis=0.8,las=2)
>>>
>>> But nothing happened. I cannot understand why it doesn't show
>>anything.
>>> I have attached the file as well in case you want to have a more
>>clear picture.
>>> I really appreciate it if you can help me on this.
>>> Thank you very much in advance.
>>> Kind regards,Maria
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>
>     [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From roy.mendelssohn at noaa.gov  Tue Feb 28 22:16:03 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 28 Feb 2017 13:16:03 -0800
Subject: [R] plotly example that highlights a line
Message-ID: <7AED4B88-1DBC-42AA-AC57-9C4C18A5628A@noaa.gov>

Hi All:

In searching online,  I have found examples of using plotly with ggplot2 graphics,  say using geom_line,  where there are multiple lines and by selecting the "factor" in the legend makes the particular line disappear or reappear  (see https://plot.ly/ggplot2/).  I am wondering if anyone's an example or knows how to set it up, so that instead if I click on the factor in the legend it highlights the line, and hen unhighlights if i select again

Thanks for any help.

-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


