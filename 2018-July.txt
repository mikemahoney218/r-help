From ir@@h@renow100 @ending from y@hoo@com  Sun Jul  1 00:14:37 2018
From: ir@@h@renow100 @ending from y@hoo@com (Ira Sharenow)
Date: Sat, 30 Jun 2018 22:14:37 +0000 (UTC)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
Message-ID: <1713527611.860691.1530396877620@mail.yahoo.com>

 I would like to thank everyone who helped me out. I have obtained some offline help, so I would like to summarize all the information I have received.
Before I summarize the thread, there is one loose end.
Initially I thought
library(dplyr)
dplyr::bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
would work, but there were problems.
lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
spreads out the data frames converting the data frames from long to wide, but it messes up the names. So one question I still have, is how can I programmatically change all of the names?
After this initial step, the first data frame's names might be derived from
c("George", "Washington") 
and the second data frame's names might be derived from
c("John", "Adams", "Thomas", "Jefferson")
What I want to change to the names to:
c("First1", "Second1")
and
c("First1", "Second1", "First2", "Second2")
I believe that will enable me to then go back and use bind_rows and complete that method of solution:
Step 1: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
Step 2: Clean up the names
Step 3: bind_rows
Immediately below is hopefully a clear and precise statement of the problem and the proposed solution path. Then there are the various solutions.
# Starting list of data frames
employees4List = list(data.frame(first1 = "Al", second1 = "Jones"), 
???????????????????? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
???????????????????? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", "Smith", "Adams")),
???????????????????? data.frame(first4 = ("Al"), second4 = "Jones2"))

employees4List


# Intermediate step that messes up the names but successfully converts from long to wide
lapply(employees4List, function(x) rbind.data.frame(c(t(x))))

# The intermediate list should likely look like this listFinal
df1 = data.frame(First1 = "Al", Second1 = "Jones", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
???????????????? First4 = NA, Second4 = NA)
df2 = data.frame(First1 = "Al2", Second1 = "Jones", First2 = "Barb", Second2 = "Smith", 
???????????????? First3 = NA, Second3 = NA, First4 = NA, Second4 = NA)

df3 = data.frame(First1 = "Al3", Second1 = "Jones", First2 = "Barbara", Second2 = "Smith", 
???????????????? First3 = "Carol", Second3 = "Adams", First4 = NA, Second4 = NA)
df4 = data.frame(First1 = "Al", Second1 = "Jones2", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
???????????????? First4 = NA, Second4 = NA)
listFinal = list(df1, df2, df3, df4)
listFinal

# Requested data frame (except that the columns are not just character but some are factor or even logical)
dplyr::bind_rows(listFinal)
Sarah Goslee solved the problem using base R.
Given
employees4List = list(
? data.frame(first1 = ("Al"), second1 = "Jones"),
? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones2", "Smith")),
? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones3",
??????????????????????????????????????????????????????????????? "Smith", "Adams")),
? data.frame(first4 = ("Al"), second4 = "Jones2"))

This function produces the solution in the requested structure.
dfbycol <- function(x) {
? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
? x <- do.call(rbind, x)
? x <- data.frame(x, stringsAsFactors=FALSE)
? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
? x
}
dfbycol(employees4List)
Offline, Jeff Newmiller and Bert Gunter provided alternative approaches to the problem as well as other advice. Their solutions meet the "tidy" criterion.
Bert suggested this online.
## list of two data frames with different column names and numbers of rows:
zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 5:9,b = letters[11:15]))
## create common column names and bind them up:
do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
This and the next suggestion by Jeff produced useful solutions but not in the requested form.
library(dplyr)
# note that these data frames all have character columns
# rather than factors, due to the as.is option when the
# data are read in.
DF1 <- read.table( text =
"First????????? Last
George????????? Washington
", header=TRUE, as.is = TRUE )
# dput looks ugly but is actually much more practical for
# providing R data on the mailing list... here is an example
dput( DF1 )
#> structure(list(First = "George", Last = "Washington")
#>, .Names = c("First",
#> "Last"), class = "data.frame", row.names = c(NA, -1L))

DF2 <- read.table( text =
"Start????????????? End
John????????????? Adams
Thomas??????? Jefferson
", header = TRUE, as.is = TRUE )

DFL <- list( DF1, DF2 )

# DFNames is a set of unique identifiers
DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
????????????????? , data = DFL
????????????????? )

DFL2 <- (? DFL1
??????? %>% mutate( data = lapply( data
????????????????????????????????? , function( DF ) {
????????????????????????????????????? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
????????????????????????????????????? gather( DF, ".Col", "value", -.PK )
??????????????????????????????????? }
????????????????????????????????? )
????????????????? )
??????? %>% unnest
??????? %>% spread( .Col, value )
??????? )
DFL2
During the discussion, useful links were recommended
[1] https://www.jstatsoft.org/article/view/v059i10?? Hadley on tidy data 
[2] http://r4ds.had.co.nz/relational-data.html#keys? Hadley on relational data
[3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example? How to make a great reproducible example
http://adv-r.had.co.nz/Functionals.html???? Improving lapply and related skills
Thanks again to everyone!
Ira




    On Friday, June 29, 2018, 7:47:13 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:  
 
 Code below...

a) Just because something can be done with dplyr does not mean that is the 
best way to do it. A solution in the hand is worth two on the Internet, 
and dplyr is not always the fastest method anyway.

b) I highly recommend that you read Hadley Wickham's paper on tidy data 
[1]. Also, having a group of one or more columns at all times that 
uniquely identify where the data came from is a "key" to success [2].

c) Please read and follow one of the various online documents about making 
reproducible examples in R (e.g. [3]). HTML formatting is really a pain 
(at best... at worst, it corrupts your code) on a plain-text-only list 
(you have read the Posting Guide, right?). Consider my example below as a 
model for you to follow in the future, and make sure to set your email 
program to send plain text. (Obviously your examples don't have to achieve 
success... but they should bring us up to speed with where you are having 
troubles IN R.)

[1] https://www.jstatsoft.org/article/view/v059i10
[2] http://r4ds.had.co.nz/relational-data.html#keys
[3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

----
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>? ? filter, lag
#> The following objects are masked from 'package:base':
#>
#>? ? intersect, setdiff, setequal, union
library(tidyr)

# note that these data frames all have character columns
# rather than factors, due to the as.is option when the
# data are read in.
DF1 <- read.table( text =
"First? ? ? ? ? Last
George? ? ? ? ? Washington
", header=TRUE, as.is = TRUE )

# dput looks ugly but is actually much more practical for
# providing R data on the mailing list... here is an example
dput( DF1 )
#> structure(list(First = "George", Last = "Washington")
#>, .Names = c("First",
#> "Last"), class = "data.frame", row.names = c(NA, -1L))

DF2 <- read.table( text =
"Start? ? ? ? ? ? ? End
John? ? ? ? ? ? ? Adams
Thomas? ? ? ? Jefferson
", header = TRUE, as.is = TRUE )

DFL <- list( DF1, DF2 )

# DFNames is a set of unique identifiers
DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
? ? ? ? ? ? ? ? ? , data = DFL
? ? ? ? ? ? ? ? ? )

DFL2 <- (? DFL1
? ? ? ? %>% mutate( data = lapply( data
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? , function( DF ) {
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? gather( DF, ".Col", "value", -.PK )
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? ? ? ? ? )
? ? ? ? %>% unnest
? ? ? ? %>% spread( .Col, value )
? ? ? ? )
DFL2
#> # A tibble: 3 x 6
#>? .DFNames? .PK End? ? ? First? Last? ? ? Start
#>? <chr>? ? <int> <chr>? ? <chr>? <chr>? ? ? <chr>
#> 1 DF1? ? ? ? ? 1 <NA>? ? ? George Washington <NA>
#> 2 DF2? ? ? ? ? 1 Adams? ? <NA>? <NA>? ? ? John
#> 3 DF2? ? ? ? ? 2 Jefferson <NA>? <NA>? ? ? Thomas

#' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
----

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

>
> Sarah and David,
>
> Thank you for your responses.I will try and be clearer.
>
> Base R solution: Sarah?smethod worked perfectly
>
> Is there a dplyrsolution?
>
> START: list of dataframes
>
> FINISH: one data frame
>
> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>
> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>
> EXAMPLE: List with twodata frames
>
> # DF1
>
> First?? ???????Last
>
> George Washington
>
> ?
>
> # DF2
>
> Start????????????? End
>
> John?????????????? Adams
>
> Thomas??????? Jefferson
>
> ?
>
> # End Result. One dataframe
>
> First1????? Second1??????? First2?????????? Second2
>
> George Washington?????? NA??????????????????? NA
>
> John?????????????? Adams??? Thomas??????? Jefferson
>
> ?
>
> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>
> The suggested solution was:
>
> library(dplyr)
>
> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>
> ?
>
> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>
> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>
> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>
> Ira
>
>
>? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>
>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> It isn't super clear to me what you're after.
>
> Agree.
>
> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>
> library(dplyr)
> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
> bind_rows(newList)
>
> #---------
>
> ? first1 second1
> 1? ? ? Al? Jones
> 2? ? Al2? Jones
> 3? ? Barb? Smith
> 4? ? Al3? Jones
> 5 Barbara? Smith
> 6? Carol? Adams
> 7? ? ? Al? Jones2
>
> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>
> -- 
> David.
>> Is this what you intend?
>>
>>> dfbycol(employees4BList)
>> ? first1 last1 first2 last2 first3 last3
>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>> 3? ? Al Jones? Barb Smith? Carol Adams
>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>
>>> dfbycol(employees4List)
>> ? first1? last1? first2 last2 first3 last3
>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>
>>
>> If so:
>>
>> employees4BList = list(
>> data.frame(first1 = "Al", second1 = "Jones"),
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>
>> employees4List = list(
>> data.frame(first1 = ("Al"), second1 = "Jones"),
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>
>> ###
>>
>> dfbycol <- function(x) {
>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>> ? x <- do.call(rbind, x)
>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>> ? x
>> }
>>
>> ###
>>
>> dfbycol(employees4BList)
>>
>> dfbycol(employees4List)
>>
>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>> <r-help at r-project.org> wrote:
>>> I have a list of data frames which I would like to combine into one data
>>> frame doing something like rbind. I wish to combine in column order and
>>> not by names. However, there are issues.
>>>
>>> The number of columns is not the same for each data frame. This is an
>>> intermediate step to a problem and the number of columns could be
>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>> is that the names of the columns produced by the first step are garbage.
>>>
>>> Below is a method that I obtained by asking a question on stack
>>> overflow. Unfortunately, my example was not general enough. The code
>>> below works for the simple case where the names of the people are
>>> consistent. It does not work when the names are realistically not the same.
>>>
>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>
>>>
>>> Please note that the lapply step sets things up except for the column
>>> name issue. If I could figure out a way to change the column names, then
>>> the bind_rows step will, I believe, work.
>>>
>>> So I really have two questions. How to change all column names of all
>>> the data frames and then how to solve the original problem.
>>>
>>> # The non general case works fine. It produces one data frame and I can
>>> then change the column names to
>>>
>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>
>>> #Non general easy case
>>>
>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4BList
>>>
>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> # This produces a nice list of data frames, except for the names
>>>
>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>
>>> # This list is a disaster. I am looking for a solution that works in
>>> this case.
>>>
>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> Thanks.
>>>
>>> Ira
>>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------  
	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul  1 03:14:45 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 18:14:45 -0700 (PDT)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <1713527611.860691.1530396877620@mail.yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
 <1713527611.860691.1530396877620@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1806301736300.71159@pedal.dcn.davis.ca.us>

Your request is getting a bit complicated with so much re-hashing, but 
here are three solutions: base only, a bit of dplyr, and dplyr+tidyr:

#########
# input data
employees4List = list(data.frame(first1 = "Al", second1 = 
"Jones"),
                       data.frame(first2 = c("Al2", "Barb"),
                                  second2 = c("Jones", "Smith")),
                       data.frame(first3 = c("Al3", "Barbara", 
"Carol"),
                                  second3 = c("Jones", "Smith", 
"Adams")),
                       data.frame(first4 = ("Al"), second4 = 
"Jones2"))
employees4List
#> [[1]]
#>   first1 second1
#> 1     Al   Jones
#>
#> [[2]]
#>   first2 second2
#> 1    Al2   Jones
#> 2   Barb   Smith
#>
#> [[3]]
#>    first3 second3
#> 1     Al3   Jones
#> 2 Barbara   Smith
#> 3   Carol   Adams
#>
#> [[4]]
#>   first4 second4
#> 1     Al  Jones2

# expected output
df1 = data.frame(First1 = "Al", Second1 = "Jones",
                  First2 = NA, Second2 = NA,
                  First3 = NA, Second3 = NA,
                  First4 = NA, Second4 = NA)
df2 = data.frame(First1 = "Al2", Second1 = "Jones",
                  First2 = "Barb", Second2 = "Smith",
                  First3 = NA, Second3 = NA,
                  First4 = NA, Second4 = NA)
df3 = data.frame(First1 = "Al3", Second1 = "Jones",
                  First2 = "Barbara", Second2 = "Smith",
                  First3 = "Carol", Second3 = "Adams",
                  First4 = NA, Second4 = NA)
df4 = data.frame(First1 = "Al", Second1 = "Jones2",
                  First2 = NA, Second2 = NA,
                  First3 = NA, Second3 = NA,
                  First4 = NA, Second4 = NA)
listFinal = list(df1, df2, df3, df4)
listFinal
#> [[1]]
#>   First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1     Al   Jones     NA      NA     NA      NA     NA      NA
#>
#> [[2]]
#>   First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1    Al2   Jones   Barb   Smith     NA      NA     NA      NA
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3 First4 Second4
#> 1    Al3   Jones Barbara   Smith  Carol   Adams     NA      NA
#>
#> [[4]]
#>   First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1     Al  Jones2     NA      NA     NA      NA     NA      NA

myrename1 <- function( DF, m ) {
   # if a pair of columns is not present, raise an error
   stopifnot( 2 == length( DF ) )
   n <- nrow( DF )
   # use memory layout of elements of matrix
   # t() automatically converts to matrix (nrow=2)
   # matrix(,nrow=1) re-interprets the column-major output of t()
   # as a single row matrix
   result <- as.data.frame( matrix( t( DF ), nrow = 1 )
                          , stringsAsFactors = FALSE
                          )
   if ( n < m ) {
     result[ , seq( 2 * n + 1, 2 * m ) ] <- NA
   }
   setNames( result
           , sprintf( "%s%d"
                    , c( "First", "Second" )
                       , rep( seq.int( m ), each = 2 )
                       )
           )
}

m <- max( unlist( lapply( employees4List, nrow ) ) )
listFinal1 <- lapply( employees4List, myrename1, m = m )
listFinal1
#> [[1]]
#>   First1 Second1 First2 Second2 First3 Second3
#> 1     Al   Jones     NA      NA     NA      NA
#>
#> [[2]]
#>   First1 Second1 First2 Second2 First3 Second3
#> 1    Al2   Jones   Barb   Smith     NA      NA
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3
#> 1    Al3   Jones Barbara   Smith  Carol   Adams
#>
#> [[4]]
#>   First1 Second1 First2 Second2 First3 Second3
#> 1     Al  Jones2     NA      NA     NA      NA
result1 <- do.call( rbind, listFinal1 )
result1
#>   First1 Second1  First2 Second2 First3 Second3
#> 1     Al   Jones    <NA>    <NA>   <NA>    <NA>
#> 2    Al2   Jones    Barb   Smith   <NA>    <NA>
#> 3    Al3   Jones Barbara   Smith  Carol   Adams
#> 4     Al  Jones2    <NA>    <NA>   <NA>    <NA>

myrename2 <- function( DF ) {
   # if a pair of columns is not present, raise an error
   stopifnot( 2 == length( DF ) )
   n <- nrow( DF )
   # use memory layout of elements of matrix
   # t() automatically converts to matrix (nrow=2)
   # matrix(,nrow=1) re-interprets the column-major output of t()
   # as a single row matrix
   setNames( as.data.frame( matrix( t( DF ), nrow = 1 )
                          , stringsAsFactors = FALSE
                          )
           , sprintf( "%s%d"
                    , c( "First", "Second" )
                    , rep( seq.int( n ), each = 2 )
                    )
           )
}

listFinal2 <- lapply( employees4List, myrename2 )
listFinal2
#> [[1]]
#>   First1 Second1
#> 1     Al   Jones
#>
#> [[2]]
#>   First1 Second1 First2 Second2
#> 1    Al2   Jones   Barb   Smith
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3
#> 1    Al3   Jones Barbara   Smith  Carol   Adams
#>
#> [[4]]
#>   First1 Second1
#> 1     Al  Jones2
result2 <- dplyr::bind_rows( listFinal2 )
result2
#>   First1 Second1  First2 Second2 First3 Second3
#> 1     Al   Jones    <NA>    <NA>   <NA>    <NA>
#> 2    Al2   Jones    Barb   Smith   <NA>    <NA>
#> 3    Al3   Jones Barbara   Smith  Carol   Adams
#> 4     Al  Jones2    <NA>    <NA>   <NA>    <NA>

library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)
myrename3 <- function( DF ) {
   # if a pair of columns is not present, raise an error
   stopifnot( 2 == length( DF ) )
   names( DF ) <- c( "a", "b" )
   m <- nrow( DF )
   (   DF
   %>% mutate_all( as.character )
   %>% mutate( rw = LETTERS[ seq.int( n() ) ] )
   %>% gather( col, val, -rw )
   %>% tidyr::unite( "labels", rw, col, sep="" )
   %>% spread( labels, val )
   %>% setNames( sprintf( "%s%d"
                        , c( "First", "Second" )
                        , rep( seq.int( m ), each = 2 )
                        )
               )
   )
}

listFinal3 <- lapply( employees4List, myrename3 )
listFinal3
#> [[1]]
#>   First1 Second1
#> 1     Al   Jones
#>
#> [[2]]
#>   First1 Second1 First2 Second2
#> 1    Al2   Jones   Barb   Smith
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3
#> 1    Al3   Jones Barbara   Smith  Carol   Adams
#>
#> [[4]]
#>   First1 Second1
#> 1     Al  Jones2
result3 <- dplyr::bind_rows( listFinal3 )
result3
#>   First1 Second1  First2 Second2 First3 Second3
#> 1     Al   Jones    <NA>    <NA>   <NA>    <NA>
#> 2    Al2   Jones    Barb   Smith   <NA>    <NA>
#> 3    Al3   Jones Barbara   Smith  Carol   Adams
#> 4     Al  Jones2    <NA>    <NA>   <NA>    <NA>

#' Created on 2018-06-30 by the [reprex 
package](http://reprex.tidyverse.org) (v0.2.0).
#########

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

> I would like to thank everyone who helped me out. I have obtained some offline help, so I would like to summarize all the information I have received.
> Before I summarize the thread, there is one loose end.
> Initially I thought
> library(dplyr)
> dplyr::bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
> would work, but there were problems.
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> spreads out the data frames converting the data frames from long to wide, but it messes up the names. So one question I still have, is how can I programmatically change all of the names?
> After this initial step, the first data frame's names might be derived from
> c("George", "Washington")
> and the second data frame's names might be derived from
> c("John", "Adams", "Thomas", "Jefferson")
> What I want to change to the names to:
> c("First1", "Second1")
> and
> c("First1", "Second1", "First2", "Second2")
> I believe that will enable me to then go back and use bind_rows and complete that method of solution:
> Step 1: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> Step 2: Clean up the names
> Step 3: bind_rows
> Immediately below is hopefully a clear and precise statement of the problem and the proposed solution path. Then there are the various solutions.
> # Starting list of data frames
> employees4List = list(data.frame(first1 = "Al", second1 = "Jones"),
> ???????????????????? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> ???????????????????? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", "Smith", "Adams")),
> ???????????????????? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> employees4List
>
>
> # Intermediate step that messes up the names but successfully converts from long to wide
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> # The intermediate list should likely look like this listFinal
> df1 = data.frame(First1 = "Al", Second1 = "Jones", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> df2 = data.frame(First1 = "Al2", Second1 = "Jones", First2 = "Barb", Second2 = "Smith",
> ???????????????? First3 = NA, Second3 = NA, First4 = NA, Second4 = NA)
>
> df3 = data.frame(First1 = "Al3", Second1 = "Jones", First2 = "Barbara", Second2 = "Smith",
> ???????????????? First3 = "Carol", Second3 = "Adams", First4 = NA, Second4 = NA)
> df4 = data.frame(First1 = "Al", Second1 = "Jones2", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> listFinal = list(df1, df2, df3, df4)
> listFinal
>
> # Requested data frame (except that the columns are not just character but some are factor or even logical)
> dplyr::bind_rows(listFinal)
> Sarah Goslee solved the problem using base R.
> Given
> employees4List = list(
> ? data.frame(first1 = ("Al"), second1 = "Jones"),
> ? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones2", "Smith")),
> ? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones3",
> ??????????????????????????????????????????????????????????????? "Smith", "Adams")),
> ? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> This function produces the solution in the requested structure.
> dfbycol <- function(x) {
> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
> ? x <- do.call(rbind, x)
> ? x <- data.frame(x, stringsAsFactors=FALSE)
> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
> ? x
> }
> dfbycol(employees4List)
> Offline, Jeff Newmiller and Bert Gunter provided alternative approaches to the problem as well as other advice. Their solutions meet the "tidy" criterion.
> Bert suggested this online.
> ## list of two data frames with different column names and numbers of rows:
> zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 5:9,b = letters[11:15]))
> ## create common column names and bind them up:
> do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
> This and the next suggestion by Jeff produced useful solutions but not in the requested form.
> library(dplyr)
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First????????? Last
> George????????? Washington
> ", header=TRUE, as.is = TRUE )
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start????????????? End
> John????????????? Adams
> Thomas??????? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ????????????????? , data = DFL
> ????????????????? )
>
> DFL2 <- (? DFL1
> ??????? %>% mutate( data = lapply( data
> ????????????????????????????????? , function( DF ) {
> ????????????????????????????????????? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ????????????????????????????????????? gather( DF, ".Col", "value", -.PK )
> ??????????????????????????????????? }
> ????????????????????????????????? )
> ????????????????? )
> ??????? %>% unnest
> ??????? %>% spread( .Col, value )
> ??????? )
> DFL2
> During the discussion, useful links were recommended
> [1] https://www.jstatsoft.org/article/view/v059i10?? Hadley on tidy data
> [2] http://r4ds.had.co.nz/relational-data.html#keys? Hadley on relational data
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example? How to make a great reproducible example
> http://adv-r.had.co.nz/Functionals.html???? Improving lapply and related skills
> Thanks again to everyone!
> Ira
>
>
>
>
>    On Friday, June 29, 2018, 7:47:13 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Code below...
>
> a) Just because something can be done with dplyr does not mean that is the
> best way to do it. A solution in the hand is worth two on the Internet,
> and dplyr is not always the fastest method anyway.
>
> b) I highly recommend that you read Hadley Wickham's paper on tidy data
> [1]. Also, having a group of one or more columns at all times that
> uniquely identify where the data came from is a "key" to success [2].
>
> c) Please read and follow one of the various online documents about making
> reproducible examples in R (e.g. [3]). HTML formatting is really a pain
> (at best... at worst, it corrupts your code) on a plain-text-only list
> (you have read the Posting Guide, right?). Consider my example below as a
> model for you to follow in the future, and make sure to set your email
> program to send plain text. (Obviously your examples don't have to achieve
> success... but they should bring us up to speed with where you are having
> troubles IN R.)
>
> [1] https://www.jstatsoft.org/article/view/v059i10
> [2] http://r4ds.had.co.nz/relational-data.html#keys
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> ----
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>? ? filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>? ? intersect, setdiff, setequal, union
> library(tidyr)
>
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First? ? ? ? ? Last
> George? ? ? ? ? Washington
> ", header=TRUE, as.is = TRUE )
>
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start? ? ? ? ? ? ? End
> John? ? ? ? ? ? ? Adams
> Thomas? ? ? ? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ? ? ? ? ? ? ? ? ? , data = DFL
> ? ? ? ? ? ? ? ? ? )
>
> DFL2 <- (? DFL1
> ? ? ? ? %>% mutate( data = lapply( data
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? , function( DF ) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? gather( DF, ".Col", "value", -.PK )
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? }
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? )
> ? ? ? ? ? ? ? ? ? )
> ? ? ? ? %>% unnest
> ? ? ? ? %>% spread( .Col, value )
> ? ? ? ? )
> DFL2
> #> # A tibble: 3 x 6
> #>? .DFNames? .PK End? ? ? First? Last? ? ? Start
> #>? <chr>? ? <int> <chr>? ? <chr>? <chr>? ? ? <chr>
> #> 1 DF1? ? ? ? ? 1 <NA>? ? ? George Washington <NA>
> #> 2 DF2? ? ? ? ? 1 Adams? ? <NA>? <NA>? ? ? John
> #> 3 DF2? ? ? ? ? 2 Jefferson <NA>? <NA>? ? ? Thomas
>
> #' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
> ----
>
> On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:
>
>>
>> Sarah and David,
>>
>> Thank you for your responses.I will try and be clearer.
>>
>> Base R solution: Sarah?smethod worked perfectly
>>
>> Is there a dplyrsolution?
>>
>> START: list of dataframes
>>
>> FINISH: one data frame
>>
>> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>>
>> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>>
>> EXAMPLE: List with twodata frames
>>
>> # DF1
>>
>> First?? ???????Last
>>
>> George Washington
>>
>> ?
>>
>> # DF2
>>
>> Start????????????? End
>>
>> John?????????????? Adams
>>
>> Thomas??????? Jefferson
>>
>> ?
>>
>> # End Result. One dataframe
>>
>> First1????? Second1??????? First2?????????? Second2
>>
>> George Washington?????? NA??????????????????? NA
>>
>> John?????????????? Adams??? Thomas??????? Jefferson
>>
>> ?
>>
>> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>>
>> The suggested solution was:
>>
>> library(dplyr)
>>
>> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>>
>> ?
>>
>> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>>
>> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>>
>> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>>
>> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>>
>> Ira
>>
>>
>> ? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> It isn't super clear to me what you're after.
>>
>> Agree.
>>
>> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>>
>> library(dplyr)
>> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
>> bind_rows(newList)
>>
>> #---------
>>
>> ? first1 second1
>> 1? ? ? Al? Jones
>> 2? ? Al2? Jones
>> 3? ? Barb? Smith
>> 4? ? Al3? Jones
>> 5 Barbara? Smith
>> 6? Carol? Adams
>> 7? ? ? Al? Jones2
>>
>> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>>
>> --
>> David.
>>> Is this what you intend?
>>>
>>>> dfbycol(employees4BList)
>>> ? first1 last1 first2 last2 first3 last3
>>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>>> 3? ? Al Jones? Barb Smith? Carol Adams
>>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>>
>>>> dfbycol(employees4List)
>>> ? first1? last1? first2 last2 first3 last3
>>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>>
>>>
>>> If so:
>>>
>>> employees4BList = list(
>>> data.frame(first1 = "Al", second1 = "Jones"),
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4List = list(
>>> data.frame(first1 = ("Al"), second1 = "Jones"),
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ###
>>>
>>> dfbycol <- function(x) {
>>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>>> ? x <- do.call(rbind, x)
>>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>>> ? x
>>> }
>>>
>>> ###
>>>
>>> dfbycol(employees4BList)
>>>
>>> dfbycol(employees4List)
>>>
>>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>>> <r-help at r-project.org> wrote:
>>>> I have a list of data frames which I would like to combine into one data
>>>> frame doing something like rbind. I wish to combine in column order and
>>>> not by names. However, there are issues.
>>>>
>>>> The number of columns is not the same for each data frame. This is an
>>>> intermediate step to a problem and the number of columns could be
>>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>>> is that the names of the columns produced by the first step are garbage.
>>>>
>>>> Below is a method that I obtained by asking a question on stack
>>>> overflow. Unfortunately, my example was not general enough. The code
>>>> below works for the simple case where the names of the people are
>>>> consistent. It does not work when the names are realistically not the same.
>>>>
>>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>>
>>>>
>>>> Please note that the lapply step sets things up except for the column
>>>> name issue. If I could figure out a way to change the column names, then
>>>> the bind_rows step will, I believe, work.
>>>>
>>>> So I really have two questions. How to change all column names of all
>>>> the data frames and then how to solve the original problem.
>>>>
>>>> # The non general case works fine. It produces one data frame and I can
>>>> then change the column names to
>>>>
>>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>>
>>>> #Non general easy case
>>>>
>>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>>
>>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>>
>>>> employees4BList
>>>>
>>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> # This produces a nice list of data frames, except for the names
>>>>
>>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>>
>>>> # This list is a disaster. I am looking for a solution that works in
>>>> this case.
>>>>
>>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>>
>>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>>
>>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> Thanks.
>>>>
>>>> Ira
>>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
> /Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
> ---------------------------------------------------------------------------
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From h@@@n@diw@n @ending from gm@il@com  Sun Jul  1 04:34:06 2018
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Sat, 30 Jun 2018 19:34:06 -0700
Subject: [R] A question on Statistics
In-Reply-To: <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
Message-ID: <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>

Christofer,
On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> You should use Stack Exchange for questions about statistics.

Specifically, https://stats.stackexchange.com/ -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable


From @k@h@y_e4 @ending from hotm@il@com  Sun Jul  1 13:31:29 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sun, 1 Jul 2018 11:31:29 +0000
Subject: [R] parallel processing in r...
In-Reply-To: <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
Message-ID: <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear Members,
                                      Thanks for the reply..I do have another issue; I will be highly obliged if you answer it:
I tried "top" at the bash prompt, but it provides a way to measure CPU performance of the existing processes. I want to check the CPU usage of the execution of an R function. So I start R by this

$ R

and at the R prompt I type the function to be executed. But if I type "top" at the R prompt, it says object "top" not found.

So, should I change to bash prompt after running the R function? If yes, how do I do it? If not, how to use "top" inside the R prompt?

Again, I think this is an OS isuue....but I could'nt find any answer in the Internet. I am an independent researcher and I don't have personal access to experts.......this mail list is the only vent I have.......

Very many thanks for your time and effort...
Yours sincerely,
AKSHAY M KULKARNI

________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Saturday, June 30, 2018 11:46 PM
To: r-help at r-project.org; akshay kulkarni; R help Mailing list
Subject: Re: [R] parallel processing in r...

Use "top" at the bash prompt.

Read about the "mc.cores" parameter to mclapply.

Make a simplified example version of your analysis and post your question in the context of that example [1][2][3]. You will learn about the issues you are dealing with in the process of trimming your problem, and will have code you can share that demonstrates the issue without exposing private information.

Running parallel does not necessarily improve performance because other factors like task switching overhead and Inter-process-communication (data sharing) can drag it down. Read about the real benefits and drawbacks of parallelism... there are many discussions out there out there... you might start with [4].


[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

[4] https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html

On June 30, 2018 10:07:49 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>I am using mclapply to parallelize my code. I am using Red Hat Linux in
>AWS.
>
>When I use mclapply, I see no speed increase. I doubt that the Linux OS
>is allowing fewer than the maximum number of cores to mclapply ( by
>default, mclapply takes all the available cores to it).
>
>How do you check if the number of workers is less than the output given
>by detectCores(), in Linux? Is there any R function for it?
>
>I do acknowledge that help on an OS is not suitable for this mailing
>list, but even Internet could'nt help me. Therefore this mail......
>
>very many thanks for your time  and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Sun Jul  1 14:53:36 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 18:23:36 +0530
Subject: [R] A question on Statistics
In-Reply-To: <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
 <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
Message-ID: <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>

Hi,

I could post in StackExchange for sure, however I dont think R-help posting
guide discourage asking a question about Statistics, atleast formally.

I could further clarify if my question is not elaborate enough. And many
apologies if it is very trivial - however still I am looking for 2nd
opinion on my question.

Answer to Jeff's pointer - yes my distribution is assumed to be centered at
0.

Thanks,

On Sun, Jul 1, 2018 at 8:04 AM Hasan Diwan <hasan.diwan at gmail.com> wrote:

> Christofer,
> On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > You should use Stack Exchange for questions about statistics.
>
> Specifically, https://stats.stackexchange.com/ -- H
> --
> OpenPGP:
> https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> If you wish to request my time, please do so using
> bit.ly/hd1AppointmentRequest.
> Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.
>
> Sent from my mobile device
> Envoye de mon portable
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jeremieju@te @ending from gm@il@com  Sun Jul  1 15:32:26 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Sun, 01 Jul 2018 15:32:26 +0200
Subject: [R] running Rmpi with SGE on a cluster
Message-ID: <87y3ev3wut.fsf@gmail.com>


Hello,

I would like to know how to use Rmpi on a cluster but usually the
workflow of the cluster uses sun grid engine to launch jobs.

I found this reference on the web
http://borisv.lk.net/howtos/grid-mpi-r-howto.html.

But I could not even reproduce that example some errors with
> n.cores <- mpi.universe.size()

But regardless of this error do you have any resources on running R on a
cluster?


Best regards,

Jeremie


From bgunter@4567 @ending from gm@il@com  Sun Jul  1 16:59:43 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 1 Jul 2018 07:59:43 -0700
Subject: [R] A question on Statistics
In-Reply-To: <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
 <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
 <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>
Message-ID: <CAGxFJbQTzKyDrACYsFfOvKM7iCe9tEEhVM8Dy7-WQ_j=QGhpXQ@mail.gmail.com>

>From the posting guide:

"*R-help* is intended to be comprehensible to people who want to use R to
solve problems but who are not necessarily interested in or knowledgeable
about programming."

This says to me that R-help is for general questions about R programming,
not statistics, though I grant you that the intersection is nonempty.
Nevertheless, purely statistical issues should be posted elsewhere, and
your query appears to be such.

However, I'll just note: what does "centered at 0" mean for an asymmetric
distribution? I think you may need to reconsider Jeff's advice.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jul 1, 2018 at 5:53 AM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I could post in StackExchange for sure, however I dont think R-help posting
> guide discourage asking a question about Statistics, atleast formally.
>
> I could further clarify if my question is not elaborate enough. And many
> apologies if it is very trivial - however still I am looking for 2nd
> opinion on my question.
>
> Answer to Jeff's pointer - yes my distribution is assumed to be centered at
> 0.
>
> Thanks,
>
> On Sun, Jul 1, 2018 at 8:04 AM Hasan Diwan <hasan.diwan at gmail.com> wrote:
>
> > Christofer,
> > On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > wrote:
> > >
> > > You should use Stack Exchange for questions about statistics.
> >
> > Specifically, https://stats.stackexchange.com/ -- H
> > --
> > OpenPGP:
> > https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> > If you wish to request my time, please do so using
> > bit.ly/hd1AppointmentRequest.
> > Si vous voudrais faire connnaisance, allez a
> bit.ly/hd1AppointmentRequest.
> >
> > Sent from my mobile device
> > Envoye de mon portable
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Sun Jul  1 17:14:49 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 20:44:49 +0530
Subject: [R] A question on Statistics
In-Reply-To: <CAGxFJbQTzKyDrACYsFfOvKM7iCe9tEEhVM8Dy7-WQ_j=QGhpXQ@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
 <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
 <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>
 <CAGxFJbQTzKyDrACYsFfOvKM7iCe9tEEhVM8Dy7-WQ_j=QGhpXQ@mail.gmail.com>
Message-ID: <CA+dpOJ=a0vP1rYxt6rfYKHV-j5VqgqJ0umji08_jcCZRu2u+Dw@mail.gmail.com>

I derive posting guide from https://www.r-project.org/posting-guide.html

I am imagining a distribution where mean is zero but there are few large
observations in the positive side which are not very frequent.

On Sun, Jul 1, 2018 at 8:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> From the posting guide:
>
> "*R-help* is intended to be comprehensible to people who want to use R to
> solve problems but who are not necessarily interested in or knowledgeable
> about programming."
>
> This says to me that R-help is for general questions about R programming,
> not statistics, though I grant you that the intersection is nonempty.
> Nevertheless, purely statistical issues should be posted elsewhere, and
> your query appears to be such.
>
> However, I'll just note: what does "centered at 0" mean for an asymmetric
> distribution? I think you may need to reconsider Jeff's advice.
>
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Jul 1, 2018 at 5:53 AM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Hi,
>>
>> I could post in StackExchange for sure, however I dont think R-help
>> posting
>> guide discourage asking a question about Statistics, atleast formally.
>>
>> I could further clarify if my question is not elaborate enough. And many
>> apologies if it is very trivial - however still I am looking for 2nd
>> opinion on my question.
>>
>> Answer to Jeff's pointer - yes my distribution is assumed to be centered
>> at
>> 0.
>>
>> Thanks,
>>
>> On Sun, Jul 1, 2018 at 8:04 AM Hasan Diwan <hasan.diwan at gmail.com> wrote:
>>
>> > Christofer,
>> > On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > wrote:
>> > >
>> > > You should use Stack Exchange for questions about statistics.
>> >
>> > Specifically, https://stats.stackexchange.com/ -- H
>> > --
>> > OpenPGP:
>> > https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
>> > If you wish to request my time, please do so using
>> > bit.ly/hd1AppointmentRequest.
>> > Si vous voudrais faire connnaisance, allez a
>> bit.ly/hd1AppointmentRequest.
>> >
>> > Sent from my mobile device
>> > Envoye de mon portable
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Sun Jul  1 17:59:38 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sun, 1 Jul 2018 08:59:38 -0700
Subject: [R] running Rmpi with SGE on a cluster
In-Reply-To: <87y3ev3wut.fsf@gmail.com>
References: <87y3ev3wut.fsf@gmail.com>
Message-ID: <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net>


> On Jul 1, 2018, at 6:32 AM, Jeremie Juste <jeremiejuste at gmail.com> wrote:
> 
> 
> Hello,
> 
> I would like to know how to use Rmpi on a cluster but usually the
> workflow of the cluster uses sun grid engine to launch jobs.
> 
> I found this reference on the web
> http://borisv.lk.net/howtos/grid-mpi-r-howto.html.
> 
> But I could not even reproduce that example some errors with
>> n.cores <- mpi.universe.size()
> 

"Some errors"? I'm not sure how you could be any more vague.


> But regardless of this error do you have any resources on running R on a
> cluster?
> 
> 
> Best regards,
> 
> Jeremie
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From benoit@v@ill@nt @ending from no-log@org  Sun Jul  1 14:22:57 2018
From: benoit@v@ill@nt @ending from no-log@org (Benoit Vaillant)
Date: Sun, 1 Jul 2018 14:22:57 +0200
Subject: [R] parallel processing in r...
In-Reply-To: <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
 <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <20180701122257.ph55k2kkabo5fp7v@auroras.fr>

Hello,

On Sun, Jul 01, 2018 at 11:31:29AM +0000, akshay kulkarni wrote:
> I tried "top" at the bash prompt, but it provides a way to measure
> CPU performance of the existing processes. I want to check the CPU
> usage of the execution of an R function.

Try to open two bash prompts, in one use R and in the other use top to
monitor what is going on.

> and at the R prompt I type the function to be executed. But if I
> type "top" at the R prompt, it says object "top" not found.

top is a shell command, no issue with R not knowing about this.

> So, should I change to bash prompt after running the R function? If
> yes, how do I do it? If not, how to use "top" inside the R prompt?

Basically, you can't.

> Again, I think this is an OS isuue....but I could'nt find any answer
> in the Internet. I am an independent researcher and I don't have
> personal access to experts.......this mail list is the only vent I
> have.......

... (many more dots) Do you think we are experts on your system?

Please do your home work and get back to us once it's done. ;-)

Cheers,

-- 
Beno?t

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180701/2f010fe0/attachment.sig>

From bog@@o@chri@tofer @ending from gm@il@com  Sun Jul  1 18:29:29 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 21:59:29 +0530
Subject: [R] parallel processing in r...
In-Reply-To: <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
 <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
Message-ID: <CA+dpOJ=+5cBZXYpnDHKZ7FRqqQF79dfx8ivBFUB2__2_ZpMX6A@mail.gmail.com>

Hi,

On ' how to use "top" inside the R prompt? '
you can use system('top') command.

Thanks,

On Sun, Jul 1, 2018 at 9:53 PM Benoit Vaillant <benoit.vaillant at no-log.org>
wrote:

> Hello,
>
> On Sun, Jul 01, 2018 at 11:31:29AM +0000, akshay kulkarni wrote:
> > I tried "top" at the bash prompt, but it provides a way to measure
> > CPU performance of the existing processes. I want to check the CPU
> > usage of the execution of an R function.
>
> Try to open two bash prompts, in one use R and in the other use top to
> monitor what is going on.
>
> > and at the R prompt I type the function to be executed. But if I
> > type "top" at the R prompt, it says object "top" not found.
>
> top is a shell command, no issue with R not knowing about this.
>
> > So, should I change to bash prompt after running the R function? If
> > yes, how do I do it? If not, how to use "top" inside the R prompt?
>
> Basically, you can't.
>
> > Again, I think this is an OS isuue....but I could'nt find any answer
> > in the Internet. I am an independent researcher and I don't have
> > personal access to experts.......this mail list is the only vent I
> > have.......
>
> ... (many more dots) Do you think we are experts on your system?
>
> Please do your home work and get back to us once it's done. ;-)
>
> Cheers,
>
> --
> Beno?t
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ir@@h@renow100 @ending from y@hoo@com  Mon Jul  2 06:40:39 2018
From: ir@@h@renow100 @ending from y@hoo@com (Ira Sharenow)
Date: Mon, 2 Jul 2018 04:40:39 +0000 (UTC)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <alpine.BSF.2.00.1806301736300.71159@pedal.dcn.davis.ca.us>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
 <1713527611.860691.1530396877620@mail.yahoo.com>
 <alpine.BSF.2.00.1806301736300.71159@pedal.dcn.davis.ca.us>
Message-ID: <1866193932.1267325.1530506439060@mail.yahoo.com>

 
My final post for thisthread!

Since I first asked myquestion on Stack Overflow, I posted all the solutions along with my timingstudy there.

https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/51129202#51129202

Thanks again toeveryone for their help.

Ira


    On Saturday, June 30, 2018, 6:11:00 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:  
 
 Your request is getting a bit complicated with so much re-hashing, but 
here are three solutions: base only, a bit of dplyr, and dplyr+tidyr:

#########
# input data
employees4List = list(data.frame(first1 = "Al", second1 = 
"Jones"),
? ? ? ? ? ? ? ? ? ? ? data.frame(first2 = c("Al2", "Barb"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? second2 = c("Jones", "Smith")),
? ? ? ? ? ? ? ? ? ? ? data.frame(first3 = c("Al3", "Barbara", 
"Carol"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? second3 = c("Jones", "Smith", 
"Adams")),
? ? ? ? ? ? ? ? ? ? ? data.frame(first4 = ("Al"), second4 = 
"Jones2"))
employees4List
#> [[1]]
#>? first1 second1
#> 1? ? Al? Jones
#>
#> [[2]]
#>? first2 second2
#> 1? ? Al2? Jones
#> 2? Barb? Smith
#>
#> [[3]]
#>? ? first3 second3
#> 1? ? Al3? Jones
#> 2 Barbara? Smith
#> 3? Carol? Adams
#>
#> [[4]]
#>? first4 second4
#> 1? ? Al? Jones2

# expected output
df1 = data.frame(First1 = "Al", Second1 = "Jones",
? ? ? ? ? ? ? ? ? First2 = NA, Second2 = NA,
? ? ? ? ? ? ? ? ? First3 = NA, Second3 = NA,
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
df2 = data.frame(First1 = "Al2", Second1 = "Jones",
? ? ? ? ? ? ? ? ? First2 = "Barb", Second2 = "Smith",
? ? ? ? ? ? ? ? ? First3 = NA, Second3 = NA,
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
df3 = data.frame(First1 = "Al3", Second1 = "Jones",
? ? ? ? ? ? ? ? ? First2 = "Barbara", Second2 = "Smith",
? ? ? ? ? ? ? ? ? First3 = "Carol", Second3 = "Adams",
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
df4 = data.frame(First1 = "Al", Second1 = "Jones2",
? ? ? ? ? ? ? ? ? First2 = NA, Second2 = NA,
? ? ? ? ? ? ? ? ? First3 = NA, Second3 = NA,
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
listFinal = list(df1, df2, df3, df4)
listFinal
#> [[1]]
#>? First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al? Jones? ? NA? ? ? NA? ? NA? ? ? NA? ? NA? ? ? NA
#>
#> [[2]]
#>? First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al2? Jones? Barb? Smith? ? NA? ? ? NA? ? NA? ? ? NA
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams? ? NA? ? ? NA
#>
#> [[4]]
#>? First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al? Jones2? ? NA? ? ? NA? ? NA? ? ? NA? ? NA? ? ? NA

myrename1 <- function( DF, m ) {
? # if a pair of columns is not present, raise an error
? stopifnot( 2 == length( DF ) )
? n <- nrow( DF )
? # use memory layout of elements of matrix
? # t() automatically converts to matrix (nrow=2)
? # matrix(,nrow=1) re-interprets the column-major output of t()
? # as a single row matrix
? result <- as.data.frame( matrix( t( DF ), nrow = 1 )
? ? ? ? ? ? ? ? ? ? ? ? ? , stringsAsFactors = FALSE
? ? ? ? ? ? ? ? ? ? ? ? ? )
? if ( n < m ) {
? ? result[ , seq( 2 * n + 1, 2 * m ) ] <- NA
? }
? setNames( result
? ? ? ? ? , sprintf( "%s%d"
? ? ? ? ? ? ? ? ? ? , c( "First", "Second" )
? ? ? ? ? ? ? ? ? ? ? , rep( seq.int( m ), each = 2 )
? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? )
}

m <- max( unlist( lapply( employees4List, nrow ) ) )
listFinal1 <- lapply( employees4List, myrename1, m = m )
listFinal1
#> [[1]]
#>? First1 Second1 First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? NA? ? ? NA? ? NA? ? ? NA
#>
#> [[2]]
#>? First1 Second1 First2 Second2 First3 Second3
#> 1? ? Al2? Jones? Barb? Smith? ? NA? ? ? NA
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams
#>
#> [[4]]
#>? First1 Second1 First2 Second2 First3 Second3
#> 1? ? Al? Jones2? ? NA? ? ? NA? ? NA? ? ? NA
result1 <- do.call( rbind, listFinal1 )
result1
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? <NA>? ? <NA>? <NA>? ? <NA>
#> 2? ? Al2? Jones? ? Barb? Smith? <NA>? ? <NA>
#> 3? ? Al3? Jones Barbara? Smith? Carol? Adams
#> 4? ? Al? Jones2? ? <NA>? ? <NA>? <NA>? ? <NA>

myrename2 <- function( DF ) {
? # if a pair of columns is not present, raise an error
? stopifnot( 2 == length( DF ) )
? n <- nrow( DF )
? # use memory layout of elements of matrix
? # t() automatically converts to matrix (nrow=2)
? # matrix(,nrow=1) re-interprets the column-major output of t()
? # as a single row matrix
? setNames( as.data.frame( matrix( t( DF ), nrow = 1 )
? ? ? ? ? ? ? ? ? ? ? ? ? , stringsAsFactors = FALSE
? ? ? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? , sprintf( "%s%d"
? ? ? ? ? ? ? ? ? ? , c( "First", "Second" )
? ? ? ? ? ? ? ? ? ? , rep( seq.int( n ), each = 2 )
? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? )
}

listFinal2 <- lapply( employees4List, myrename2 )
listFinal2
#> [[1]]
#>? First1 Second1
#> 1? ? Al? Jones
#>
#> [[2]]
#>? First1 Second1 First2 Second2
#> 1? ? Al2? Jones? Barb? Smith
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams
#>
#> [[4]]
#>? First1 Second1
#> 1? ? Al? Jones2
result2 <- dplyr::bind_rows( listFinal2 )
result2
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? <NA>? ? <NA>? <NA>? ? <NA>
#> 2? ? Al2? Jones? ? Barb? Smith? <NA>? ? <NA>
#> 3? ? Al3? Jones Barbara? Smith? Carol? Adams
#> 4? ? Al? Jones2? ? <NA>? ? <NA>? <NA>? ? <NA>

library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>? ? filter, lag
#> The following objects are masked from 'package:base':
#>
#>? ? intersect, setdiff, setequal, union
library(tidyr)
myrename3 <- function( DF ) {
? # if a pair of columns is not present, raise an error
? stopifnot( 2 == length( DF ) )
? names( DF ) <- c( "a", "b" )
? m <- nrow( DF )
? (? DF
? %>% mutate_all( as.character )
? %>% mutate( rw = LETTERS[ seq.int( n() ) ] )
? %>% gather( col, val, -rw )
? %>% tidyr::unite( "labels", rw, col, sep="" )
? %>% spread( labels, val )
? %>% setNames( sprintf( "%s%d"
? ? ? ? ? ? ? ? ? ? ? ? , c( "First", "Second" )
? ? ? ? ? ? ? ? ? ? ? ? , rep( seq.int( m ), each = 2 )
? ? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? ? ? )
? )
}

listFinal3 <- lapply( employees4List, myrename3 )
listFinal3
#> [[1]]
#>? First1 Second1
#> 1? ? Al? Jones
#>
#> [[2]]
#>? First1 Second1 First2 Second2
#> 1? ? Al2? Jones? Barb? Smith
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams
#>
#> [[4]]
#>? First1 Second1
#> 1? ? Al? Jones2
result3 <- dplyr::bind_rows( listFinal3 )
result3
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? <NA>? ? <NA>? <NA>? ? <NA>
#> 2? ? Al2? Jones? ? Barb? Smith? <NA>? ? <NA>
#> 3? ? Al3? Jones Barbara? Smith? Carol? Adams
#> 4? ? Al? Jones2? ? <NA>? ? <NA>? <NA>? ? <NA>

#' Created on 2018-06-30 by the [reprex 
package](http://reprex.tidyverse.org) (v0.2.0).
#########

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

> I would like to thank everyone who helped me out. I have obtained some offline help, so I would like to summarize all the information I have received.
> Before I summarize the thread, there is one loose end.
> Initially I thought
> library(dplyr)
> dplyr::bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
> would work, but there were problems.
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> spreads out the data frames converting the data frames from long to wide, but it messes up the names. So one question I still have, is how can I programmatically change all of the names?
> After this initial step, the first data frame's names might be derived from
> c("George", "Washington")
> and the second data frame's names might be derived from
> c("John", "Adams", "Thomas", "Jefferson")
> What I want to change to the names to:
> c("First1", "Second1")
> and
> c("First1", "Second1", "First2", "Second2")
> I believe that will enable me to then go back and use bind_rows and complete that method of solution:
> Step 1: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> Step 2: Clean up the names
> Step 3: bind_rows
> Immediately below is hopefully a clear and precise statement of the problem and the proposed solution path. Then there are the various solutions.
> # Starting list of data frames
> employees4List = list(data.frame(first1 = "Al", second1 = "Jones"),
> ???????????????????? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> ???????????????????? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", "Smith", "Adams")),
> ???????????????????? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> employees4List
>
>
> # Intermediate step that messes up the names but successfully converts from long to wide
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> # The intermediate list should likely look like this listFinal
> df1 = data.frame(First1 = "Al", Second1 = "Jones", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> df2 = data.frame(First1 = "Al2", Second1 = "Jones", First2 = "Barb", Second2 = "Smith",
> ???????????????? First3 = NA, Second3 = NA, First4 = NA, Second4 = NA)
>
> df3 = data.frame(First1 = "Al3", Second1 = "Jones", First2 = "Barbara", Second2 = "Smith",
> ???????????????? First3 = "Carol", Second3 = "Adams", First4 = NA, Second4 = NA)
> df4 = data.frame(First1 = "Al", Second1 = "Jones2", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> listFinal = list(df1, df2, df3, df4)
> listFinal
>
> # Requested data frame (except that the columns are not just character but some are factor or even logical)
> dplyr::bind_rows(listFinal)
> Sarah Goslee solved the problem using base R.
> Given
> employees4List = list(
> ? data.frame(first1 = ("Al"), second1 = "Jones"),
> ? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones2", "Smith")),
> ? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones3",
> ??????????????????????????????????????????????????????????????? "Smith", "Adams")),
> ? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> This function produces the solution in the requested structure.
> dfbycol <- function(x) {
> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
> ? x <- do.call(rbind, x)
> ? x <- data.frame(x, stringsAsFactors=FALSE)
> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
> ? x
> }
> dfbycol(employees4List)
> Offline, Jeff Newmiller and Bert Gunter provided alternative approaches to the problem as well as other advice. Their solutions meet the "tidy" criterion.
> Bert suggested this online.
> ## list of two data frames with different column names and numbers of rows:
> zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 5:9,b = letters[11:15]))
> ## create common column names and bind them up:
> do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
> This and the next suggestion by Jeff produced useful solutions but not in the requested form.
> library(dplyr)
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First????????? Last
> George????????? Washington
> ", header=TRUE, as.is = TRUE )
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start????????????? End
> John????????????? Adams
> Thomas??????? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ????????????????? , data = DFL
> ????????????????? )
>
> DFL2 <- (? DFL1
> ??????? %>% mutate( data = lapply( data
> ????????????????????????????????? , function( DF ) {
> ????????????????????????????????????? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ????????????????????????????????????? gather( DF, ".Col", "value", -.PK )
> ??????????????????????????????????? }
> ????????????????????????????????? )
> ????????????????? )
> ??????? %>% unnest
> ??????? %>% spread( .Col, value )
> ??????? )
> DFL2
> During the discussion, useful links were recommended
> [1] https://www.jstatsoft.org/article/view/v059i10?? Hadley on tidy data
> [2] http://r4ds.had.co.nz/relational-data.html#keys? Hadley on relational data
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example? How to make a great reproducible example
> http://adv-r.had.co.nz/Functionals.html???? Improving lapply and related skills
> Thanks again to everyone!
> Ira
>
>
>
>
>? ? On Friday, June 29, 2018, 7:47:13 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Code below...
>
> a) Just because something can be done with dplyr does not mean that is the
> best way to do it. A solution in the hand is worth two on the Internet,
> and dplyr is not always the fastest method anyway.
>
> b) I highly recommend that you read Hadley Wickham's paper on tidy data
> [1]. Also, having a group of one or more columns at all times that
> uniquely identify where the data came from is a "key" to success [2].
>
> c) Please read and follow one of the various online documents about making
> reproducible examples in R (e.g. [3]). HTML formatting is really a pain
> (at best... at worst, it corrupts your code) on a plain-text-only list
> (you have read the Posting Guide, right?). Consider my example below as a
> model for you to follow in the future, and make sure to set your email
> program to send plain text. (Obviously your examples don't have to achieve
> success... but they should bring us up to speed with where you are having
> troubles IN R.)
>
> [1] https://www.jstatsoft.org/article/view/v059i10
> [2] http://r4ds.had.co.nz/relational-data.html#keys
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> ----
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>? ? filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>? ? intersect, setdiff, setequal, union
> library(tidyr)
>
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First? ? ? ? ? Last
> George? ? ? ? ? Washington
> ", header=TRUE, as.is = TRUE )
>
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start? ? ? ? ? ? ? End
> John? ? ? ? ? ? ? Adams
> Thomas? ? ? ? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ? ? ? ? ? ? ? ? ? , data = DFL
> ? ? ? ? ? ? ? ? ? )
>
> DFL2 <- (? DFL1
> ? ? ? ? %>% mutate( data = lapply( data
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? , function( DF ) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? gather( DF, ".Col", "value", -.PK )
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? }
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? )
> ? ? ? ? ? ? ? ? ? )
> ? ? ? ? %>% unnest
> ? ? ? ? %>% spread( .Col, value )
> ? ? ? ? )
> DFL2
> #> # A tibble: 3 x 6
> #>? .DFNames? .PK End? ? ? First? Last? ? ? Start
> #>? <chr>? ? <int> <chr>? ? <chr>? <chr>? ? ? <chr>
> #> 1 DF1? ? ? ? ? 1 <NA>? ? ? George Washington <NA>
> #> 2 DF2? ? ? ? ? 1 Adams? ? <NA>? <NA>? ? ? John
> #> 3 DF2? ? ? ? ? 2 Jefferson <NA>? <NA>? ? ? Thomas
>
> #' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
> ----
>
> On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:
>
>>
>> Sarah and David,
>>
>> Thank you for your responses.I will try and be clearer.
>>
>> Base R solution: Sarah?smethod worked perfectly
>>
>> Is there a dplyrsolution?
>>
>> START: list of dataframes
>>
>> FINISH: one data frame
>>
>> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>>
>> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>>
>> EXAMPLE: List with twodata frames
>>
>> # DF1
>>
>> First?? ???????Last
>>
>> George Washington
>>
>> ?
>>
>> # DF2
>>
>> Start????????????? End
>>
>> John?????????????? Adams
>>
>> Thomas??????? Jefferson
>>
>> ?
>>
>> # End Result. One dataframe
>>
>> First1????? Second1??????? First2?????????? Second2
>>
>> George Washington?????? NA??????????????????? NA
>>
>> John?????????????? Adams??? Thomas??????? Jefferson
>>
>> ?
>>
>> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>>
>> The suggested solution was:
>>
>> library(dplyr)
>>
>> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>>
>> ?
>>
>> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>>
>> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>>
>> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>>
>> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>>
>> Ira
>>
>>
>> ? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> It isn't super clear to me what you're after.
>>
>> Agree.
>>
>> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>>
>> library(dplyr)
>> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
>> bind_rows(newList)
>>
>> #---------
>>
>> ? first1 second1
>> 1? ? ? Al? Jones
>> 2? ? Al2? Jones
>> 3? ? Barb? Smith
>> 4? ? Al3? Jones
>> 5 Barbara? Smith
>> 6? Carol? Adams
>> 7? ? ? Al? Jones2
>>
>> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>>
>> --
>> David.
>>> Is this what you intend?
>>>
>>>> dfbycol(employees4BList)
>>> ? first1 last1 first2 last2 first3 last3
>>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>>> 3? ? Al Jones? Barb Smith? Carol Adams
>>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>>
>>>> dfbycol(employees4List)
>>> ? first1? last1? first2 last2 first3 last3
>>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>>
>>>
>>> If so:
>>>
>>> employees4BList = list(
>>> data.frame(first1 = "Al", second1 = "Jones"),
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4List = list(
>>> data.frame(first1 = ("Al"), second1 = "Jones"),
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ###
>>>
>>> dfbycol <- function(x) {
>>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>>> ? x <- do.call(rbind, x)
>>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>>> ? x
>>> }
>>>
>>> ###
>>>
>>> dfbycol(employees4BList)
>>>
>>> dfbycol(employees4List)
>>>
>>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>>> <r-help at r-project.org> wrote:
>>>> I have a list of data frames which I would like to combine into one data
>>>> frame doing something like rbind. I wish to combine in column order and
>>>> not by names. However, there are issues.
>>>>
>>>> The number of columns is not the same for each data frame. This is an
>>>> intermediate step to a problem and the number of columns could be
>>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>>> is that the names of the columns produced by the first step are garbage.
>>>>
>>>> Below is a method that I obtained by asking a question on stack
>>>> overflow. Unfortunately, my example was not general enough. The code
>>>> below works for the simple case where the names of the people are
>>>> consistent. It does not work when the names are realistically not the same.
>>>>
>>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>>
>>>>
>>>> Please note that the lapply step sets things up except for the column
>>>> name issue. If I could figure out a way to change the column names, then
>>>> the bind_rows step will, I believe, work.
>>>>
>>>> So I really have two questions. How to change all column names of all
>>>> the data frames and then how to solve the original problem.
>>>>
>>>> # The non general case works fine. It produces one data frame and I can
>>>> then change the column names to
>>>>
>>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>>
>>>> #Non general easy case
>>>>
>>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>>
>>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>>
>>>> employees4BList
>>>>
>>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> # This produces a nice list of data frames, except for the names
>>>>
>>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>>
>>>> # This list is a disaster. I am looking for a solution that works in
>>>> this case.
>>>>
>>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>>
>>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>>
>>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> Thanks.
>>>>
>>>> Ira
>>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
> /Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
> ---------------------------------------------------------------------------
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------  
	[[alternative HTML version deleted]]


From lori@@bennett @ending from fu-berlin@de  Mon Jul  2 07:54:33 2018
From: lori@@bennett @ending from fu-berlin@de (Loris Bennett)
Date: Mon, 02 Jul 2018 07:54:33 +0200
Subject: [R] running Rmpi with SGE on a cluster
In-Reply-To: <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net> (David
 Winsemius's message of "Sun, 1 Jul 2018 08:59:38 -0700")
References: <87y3ev3wut.fsf@gmail.com>
 <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net>
Message-ID: <87efgmb2sm.fsf@hornfels.zedat.fu-berlin.de>

David Winsemius <dwinsemius at comcast.net> writes:

>> On Jul 1, 2018, at 6:32 AM, Jeremie Juste <jeremiejuste at gmail.com> wrote:
>> 
>> 
>> Hello,
>> 
>> I would like to know how to use Rmpi on a cluster but usually the
>> workflow of the cluster uses sun grid engine to launch jobs.
>> 
>> I found this reference on the web
>> http://borisv.lk.net/howtos/grid-mpi-r-howto.html.
>> 
>> But I could not even reproduce that example some errors with
>>> n.cores <- mpi.universe.size()
>> 
>
> "Some errors"? I'm not sure how you could be any more vague.
>
>
>> But regardless of this error do you have any resources on running R on a
>> cluster?

In keeping with the vagueness of the posting, I can contribute my
experience that installing Rmpi on a cluster is in general not trivial.
You potentially have to ensure that your are using the correct
combination of compiler and MPI implementation to build the packages and
then ensure that the environment is correspondingly set up for the jobs
you submit to the cluster.

I would maintain that installing Rmpi should normally be done by the
cluster administrator and the he/she should then be able to provide the
users with the information about how to use it.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From jeremieju@te @ending from gm@il@com  Mon Jul  2 08:28:43 2018
From: jeremieju@te @ending from gm@il@com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Mon, 2 Jul 2018 08:28:43 +0200
Subject: [R] running Rmpi with SGE on a cluster
In-Reply-To: <87efgmb2sm.fsf@hornfels.zedat.fu-berlin.de>
References: <87y3ev3wut.fsf@gmail.com>
 <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net>
 <87efgmb2sm.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <CAPHJcdB9qL-6MNozJCqVw0LhdeCWS+=5hQw0Vx6Jv=Q6sSS7+A@mail.gmail.com>

Hello,

Many thanks to you.

Best regards,

Jeremie



On Mon, Jul 2, 2018 at 7:54 AM, Loris Bennett <loris.bennett at fu-berlin.de>
wrote:

> David Winsemius <dwinsemius at comcast.net> writes:
>
> >> On Jul 1, 2018, at 6:32 AM, Jeremie Juste <jeremiejuste at gmail.com>
> wrote:
> >>
> >>
> >> Hello,
> >>
> >> I would like to know how to use Rmpi on a cluster but usually the
> >> workflow of the cluster uses sun grid engine to launch jobs.
> >>
> >> I found this reference on the web
> >> http://borisv.lk.net/howtos/grid-mpi-r-howto.html.
> >>
> >> But I could not even reproduce that example some errors with
> >>> n.cores <- mpi.universe.size()
> >>
> >
> > "Some errors"? I'm not sure how you could be any more vague.
> >
> >
> >> But regardless of this error do you have any resources on running R on a
> >> cluster?
>
> In keeping with the vagueness of the posting, I can contribute my
> experience that installing Rmpi on a cluster is in general not trivial.
> You potentially have to ensure that your are using the correct
> combination of compiler and MPI implementation to build the packages and
> then ensure that the environment is correspondingly set up for the jobs
> you submit to the cluster.
>
> I would maintain that installing Rmpi should normally be done by the
> cluster administrator and the he/she should then be able to provide the
> users with the information about how to use it.
>
> Cheers,
>
> Loris
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Mon Jul  2 10:57:32 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Mon, 2 Jul 2018 08:57:32 +0000
Subject: [R] parallel processing in r...
In-Reply-To: <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
 <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
Message-ID: <SL2P216MB00916EE4F42FAEC790A22D04C8430@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear Benoit,
                       Amazing! I did my home work and found out that only two out of eight processors is being utilized by mclapply.

I am using general purpose t2 instances in AWS, with Linux AMI(Red Hat).

How do I make RHEL  utilize all the processors in my linux instance? Should I use the "configure" command in Linux? Is there any specific command in AWS linux instances? Or just setting the mc.cores argument of mclapply to 8(there are 8 cores in my linux instance) work?

If the answer is somewhat involved, please refer  some online resources....

Very many thanks for your time and effort....
Yours sincerely
AKSHAY M KULKARNI
________________________________
From: Benoit Vaillant <benoit.vaillant at no-log.org>
Sent: Sunday, July 1, 2018 5:52 PM
To: akshay kulkarni
Cc: R help Mailing list
Subject: Re: [R] parallel processing in r...

Hello,

On Sun, Jul 01, 2018 at 11:31:29AM +0000, akshay kulkarni wrote:
> I tried "top" at the bash prompt, but it provides a way to measure
> CPU performance of the existing processes. I want to check the CPU
> usage of the execution of an R function.

Try to open two bash prompts, in one use R and in the other use top to
monitor what is going on.

> and at the R prompt I type the function to be executed. But if I
> type "top" at the R prompt, it says object "top" not found.

top is a shell command, no issue with R not knowing about this.

> So, should I change to bash prompt after running the R function? If
> yes, how do I do it? If not, how to use "top" inside the R prompt?

Basically, you can't.

> Again, I think this is an OS isuue....but I could'nt find any answer
> in the Internet. I am an independent researcher and I don't have
> personal access to experts.......this mail list is the only vent I
> have.......

... (many more dots) Do you think we are experts on your system?

Please do your home work and get back to us once it's done. ;-)

Cheers,

--
Beno?t

	[[alternative HTML version deleted]]


From ld1083-r @ending from y@hoo@com  Mon Jul  2 11:27:16 2018
From: ld1083-r @ending from y@hoo@com (=?UTF-8?Q?J=C3=A9r=C3=B4me_Fran=C3=A7ois?=)
Date: Mon, 2 Jul 2018 09:27:16 +0000 (UTC)
Subject: [R] [FORGED]  Plot multiple time series on a seasonal plot
In-Reply-To: <79cffece-fbfa-bedf-b3e0-73f230dccd3f@auckland.ac.nz>
References: <615332437.512512.1530279679993.ref@mail.yahoo.com>
 <615332437.512512.1530279679993@mail.yahoo.com>
 <79cffece-fbfa-bedf-b3e0-73f230dccd3f@auckland.ac.nz>
Message-ID: <1241144103.2150790.1530523636274@mail.yahoo.com>

Ron,

Many thanks for your help! This solution meets perfectly my needs. I just had to set ylim 
to make the axes match.

Best wishes,

J?r?me

________________________________
De : Rolf Turner <r.turner at auckland.ac.nz>
? : J?r?me Fran?ois <ld1083-r at yahoo.com> 
Cc : "r-help at R-project.org" <r-help at R-project.org>; Rob.Hyndman at monash.edu
Envoy? le : Samedi 30 juin 2018 0h56
Objet : Re: [FORGED] [R] Plot multiple time series on a seasonal plot



On 30/06/18 01:41, J?r?me Fran?ois via R-help wrote:
> Dear members,
> 
> I would like to plot a second time series (a forecast) to a seasonal plot made with function seasonplot() from the package forecast.
> 
> 
> Here is a reproducible example:
> ts1 <- structure(c(112035, 111182, 111015, 109331, 107525, 107749, 111435,
> 111629, 112462, 112256, 109496, 107917, 108221, 107463, 105960,
> 103883, 101038, 100056, 101628, 102973, 103371, 102463, 100774,
> 100718, 100471, 99828, 99365, 98521, 95695, 96443, 96287, 97525,
> 98293, 98014, 96658, 96736, 96089, 95337, 95382, 92748, 91448,
> 91560, 92996, 94046, 94128, 93888, 93888, 91091, 91877, 91681,
> 91045, 89367, 87912), .Tsp = c(2014, 2018.33333333333, 12), class = "ts")
> 
> ts2 <- structure(c(87867.2152330971, 89713.0862474283, 89600.565347383,
> 91066.3196835822, 90523.1926861474, 89322.8025396445, 88771.5545520503,
> 89247.0913151542, 88803.5578121458, 88060.0948570082, 87015.6578227365,
> 85785.4121532206), .Tsp = c(2018.41666666667, 2019.33333333333,
> 12), class = "ts")
> 
> 
> library(forecast)seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE)
> 
> 
> How can I add ts2 to the seasonal plot? I would like it to be distinguishable from ts1 (e.g. different color).
> 
> lines(ts2) doesn't work.
> Thank you.


I don't know anything about forecast/seasonplot.  However my experience 
is that par(new=TRUE) usually rescues one in situations like this.

It's a bit shaganappi, but ...


seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE,
            main="Whatever")
OP <- par(new=TRUE,xaxt="n",yaxt="n")
seasonplot(ts2, col="red",main="")
par(OP)

seems to work.

It would be nice to have an "add=" argument (defaulting to FALSE, of 
course) to seasonplot().

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From lori@@bennett @ending from fu-berlin@de  Mon Jul  2 14:28:31 2018
From: lori@@bennett @ending from fu-berlin@de (Loris Bennett)
Date: Mon, 02 Jul 2018 14:28:31 +0200
Subject: [R] doMPI: script hangs on closeCluster
Message-ID: <87r2klrfdc.fsf@hornfels.zedat.fu-berlin.de>

Hi,

On Linux with R 3.5.1 and OpenMPI 2.1.0 I have built Rmpi and can run a
simple example just using Rmpi and printing out the rank of each worker.

However, when I try to use doMPI by running the following

  library(Rmpi)
  library(doMPI)
  cl <- startMPIcluster(count=2)
  registerDoMPI(cl)
  clusterSize(cl)
  closeCluster(cl)
  mpi.quit()

with

  mpirun -np 1 --mca mpi_warn_on_fork 0 R --no-save -f mwe.r

I get the following output

  > library("Rmpi")
  > library(doMPI)
  Loading required package: foreach
  Loading required package: iterators
  > cl <- startMPIcluster(count=2)
  	2 slaves are spawned successfully. 0 failed.
  > registerDoMPI(cl)
  > clusterSize(cl)
  [1] 2
  > closeCluster(cl)

but the program hangs and I have to end it with Ctl-C.

Can anyone shed any light on what might be wrong?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From tr@xpl@yer @ending from gm@il@com  Mon Jul  2 14:52:37 2018
From: tr@xpl@yer @ending from gm@il@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Mon, 2 Jul 2018 14:52:37 +0200
Subject: [R] Regexp bug or misunderstanding
Message-ID: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>

Hi,

   Have I found a bug in R? Or misunderstood something about grep() ?

   Case 1 gives the expected output
   Case 2 does not gives the expected output.
   I expected integer(0) also for this case.

case 1:
grep("[:digit:]", "**ABAAbabaabackabaloneaban")
integer(0)

case 2:
grep("[:digit:]", "**ABAAbabaabackabaloneaband")
[1] 1

Regards
Martin


From i@t@z@hn @ending from gm@il@com  Mon Jul  2 14:59:45 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Mon, 2 Jul 2018 08:59:45 -0400
Subject: [R] Regexp bug or misunderstanding
In-Reply-To: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
References: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
Message-ID: <CA+vqiLEdX-NcnXDEx7LJkC9iQBC+TyfgHL24aSmEc0n9V3zgyg@mail.gmail.com>

I think you want "[[:digit:]]" instead of "[:digit:]"

--Ista

On Mon, Jul 2, 2018 at 8:52 AM, Martin M?ller Skarbiniks Pedersen
<traxplayer at gmail.com> wrote:
> Hi,
>
>    Have I found a bug in R? Or misunderstood something about grep() ?
>
>    Case 1 gives the expected output
>    Case 2 does not gives the expected output.
>    I expected integer(0) also for this case.
>
> case 1:
> grep("[:digit:]", "**ABAAbabaabackabaloneaban")
> integer(0)
>
> case 2:
> grep("[:digit:]", "**ABAAbabaabackabaloneaband")
> [1] 1
>
> Regards
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From toth@dene@ @ending from kogentum@hu  Mon Jul  2 15:03:47 2018
From: toth@dene@ @ending from kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Mon, 2 Jul 2018 15:03:47 +0200
Subject: [R] Regexp bug or misunderstanding
In-Reply-To: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
References: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
Message-ID: <eded279a-28f7-588b-8e43-5c10a8d28a68@kogentum.hu>

Hi Martin,

I assume you want to check whether a particular character string 
contains a digit. In this case you should use the following pattern: 
"[[:digit:]]" instead of "[:digit:]".

 From ?regex:
"A character class is a list of characters enclosed between [ and ] 
which matches any single character in that list; unless the first 
character of the list is the caret ^, when it matches any character not 
in the list. ... Certain named classes of characters are predefined... 
For example, [[:alnum:]] means [0-9A-Za-z]"

So if you use simply "[:digit:]" as a pattern, it means: a character 
string which contains any of the following characters: ':', 'd', 'i', 
'g', 't'. Your second test case contains 'd', whereas the first case 
contains neither of the above characters.

HTH,
Denes



On 07/02/2018 02:52 PM, Martin M?ller Skarbiniks Pedersen wrote:
> Hi,
> 
>     Have I found a bug in R? Or misunderstood something about grep() ?
> 
>     Case 1 gives the expected output
>     Case 2 does not gives the expected output.
>     I expected integer(0) also for this case.
> 
> case 1:
> grep("[:digit:]", "**ABAAbabaabackabaloneaban")
> integer(0)
> 
> case 2:
> grep("[:digit:]", "**ABAAbabaabackabaloneaband")
> [1] 1
> 
> Regards
> Martin
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From morku@ @ending from protonm@il@com  Mon Jul  2 14:02:04 2018
From: morku@ @ending from protonm@il@com (Morkus)
Date: Mon, 02 Jul 2018 08:02:04 -0400
Subject: [R] R maintains old values
Message-ID: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>

Hello,

I have a strange side-effect from executing R-scripts using R and RServe.

I am executing an R-Script from a Java file using RServe in R. I also have RStudio installed, but it's not running at the time. The R-script reads a CSV file and does various statistical things. RServe enables me to run each line of the R script using "eval()" line by line.

All this works fine for a correctly-formatted CSV file. It's great.

But, if the CSV file isn't correctly formatted, AND the last CSV file did correctly get run, then, with the incorrect CSV as input, the output is what ran last time. Somehow, the last correct run is persisted and returned if there is some problem with the current CSV input.

This data persistence is maintained across reboots.

I'm thus baffled how R is maintaining these old values, but more to the point, I need to know how to clear these old values so if the CSV input is incorrect, I get nothing back, not the old CSV values from a correctly formatted file.

Hope this description is clear.

Thanks in advance to all.

- M

Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted email.
	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Mon Jul  2 16:32:05 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 2 Jul 2018 07:32:05 -0700
Subject: [R] R maintains old values
In-Reply-To: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
Message-ID: <CAF8bMcY_HtHeAWw2jZMvzb6nP2FaJweP8+Fixda+-n-5KgYddw@mail.gmail.com>

Do you have a ".RData" file in your home directory or the current working
directory?   If so, R will load it at startup.  It can be made by you
answering 'yes' to the 'Save workspace image?' question when you quit R.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jul 2, 2018 at 5:02 AM, Morkus via R-help <r-help at r-project.org>
wrote:

> Hello,
>
> I have a strange side-effect from executing R-scripts using R and RServe.
>
> I am executing an R-Script from a Java file using RServe in R. I also have
> RStudio installed, but it's not running at the time. The R-script reads a
> CSV file and does various statistical things. RServe enables me to run each
> line of the R script using "eval()" line by line.
>
> All this works fine for a correctly-formatted CSV file. It's great.
>
> But, if the CSV file isn't correctly formatted, AND the last CSV file did
> correctly get run, then, with the incorrect CSV as input, the output is
> what ran last time. Somehow, the last correct run is persisted and returned
> if there is some problem with the current CSV input.
>
> This data persistence is maintained across reboots.
>
> I'm thus baffled how R is maintaining these old values, but more to the
> point, I need to know how to clear these old values so if the CSV input is
> incorrect, I get nothing back, not the old CSV values from a correctly
> formatted file.
>
> Hope this description is clear.
>
> Thanks in advance to all.
>
> - M
>
> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> email.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Mon Jul  2 16:34:13 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 2 Jul 2018 14:34:13 +0000
Subject: [R] R maintains old values
In-Reply-To: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
Message-ID: <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>

Hi

Without code it is just fishing in murky waters. Could the problem you face be that in each run you assingn the result to some object and if the CSV is wrong your code fails but the object from previous run persists?

If this is the case just initialize your objects in the beginning (e.g. make them NULL at the beginning) and only if code delivers result the value of the result is returned otherwise NULL is returned.

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus via R-
> help
> Sent: Monday, July 2, 2018 2:02 PM
> To: r-help at r-project.org
> Subject: [R] R maintains old values
> 
> Hello,
> 
> I have a strange side-effect from executing R-scripts using R and RServe.
> 
> I am executing an R-Script from a Java file using RServe in R. I also have RStudio
> installed, but it's not running at the time. The R-script reads a CSV file and does
> various statistical things. RServe enables me to run each line of the R script
> using "eval()" line by line.
> 
> All this works fine for a correctly-formatted CSV file. It's great.
> 
> But, if the CSV file isn't correctly formatted, AND the last CSV file did correctly
> get run, then, with the incorrect CSV as input, the output is what ran last time.
> Somehow, the last correct run is persisted and returned if there is some
> problem with the current CSV input.
> 
> This data persistence is maintained across reboots.
> 
> I'm thus baffled how R is maintaining these old values, but more to the point, I
> need to know how to clear these old values so if the CSV input is incorrect, I get
> nothing back, not the old CSV values from a correctly formatted file.
> 
> Hope this description is clear.
> 
> Thanks in advance to all.
> 
> - M
> 
> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted email.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ericjberger @ending from gm@il@com  Mon Jul  2 16:47:24 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 2 Jul 2018 17:47:24 +0300
Subject: [R] R maintains old values
In-Reply-To: <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>

If you want a "fresh" R session when you start to run the script you could
consider putting as the first line

rm(list=ls())

This will remove objects from your environment (variables, functions, ..)

HTH,
Eric


On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Without code it is just fishing in murky waters. Could the problem you
> face be that in each run you assingn the result to some object and if the
> CSV is wrong your code fails but the object from previous run persists?
>
> If this is the case just initialize your objects in the beginning (e.g.
> make them NULL at the beginning) and only if code delivers result the value
> of the result is returned otherwise NULL is returned.
>
> Cheers
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner's personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
> via R-
> > help
> > Sent: Monday, July 2, 2018 2:02 PM
> > To: r-help at r-project.org
> > Subject: [R] R maintains old values
> >
> > Hello,
> >
> > I have a strange side-effect from executing R-scripts using R and RServe.
> >
> > I am executing an R-Script from a Java file using RServe in R. I also
> have RStudio
> > installed, but it's not running at the time. The R-script reads a CSV
> file and does
> > various statistical things. RServe enables me to run each line of the R
> script
> > using "eval()" line by line.
> >
> > All this works fine for a correctly-formatted CSV file. It's great.
> >
> > But, if the CSV file isn't correctly formatted, AND the last CSV file
> did correctly
> > get run, then, with the incorrect CSV as input, the output is what ran
> last time.
> > Somehow, the last correct run is persisted and returned if there is some
> > problem with the current CSV input.
> >
> > This data persistence is maintained across reboots.
> >
> > I'm thus baffled how R is maintaining these old values, but more to the
> point, I
> > need to know how to clear these old values so if the CSV input is
> incorrect, I get
> > nothing back, not the old CSV values from a correctly formatted file.
> >
> > Hope this description is clear.
> >
> > Thanks in advance to all.
> >
> > - M
> >
> > Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> email.
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Jul  2 17:11:07 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 2 Jul 2018 08:11:07 -0700
Subject: [R] R maintains old values
In-Reply-To: <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
Message-ID: <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>

... or perhaps

rm( list = ls(all = TRUE))
## see ?ls  for details.

However, see ?Startup for how to start a R in a "clean" environment, e.g.
with the --no-restore option.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:

> If you want a "fresh" R session when you start to run the script you could
> consider putting as the first line
>
> rm(list=ls())
>
> This will remove objects from your environment (variables, functions, ..)
>
> HTH,
> Eric
>
>
> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi
> >
> > Without code it is just fishing in murky waters. Could the problem you
> > face be that in each run you assingn the result to some object and if the
> > CSV is wrong your code fails but the object from previous run persists?
> >
> > If this is the case just initialize your objects in the beginning (e.g.
> > make them NULL at the beginning) and only if code delivers result the
> value
> > of the result is returned otherwise NULL is returned.
> >
> > Cheers
> > Petr
> >
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> > partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> > zasady-ochrany-osobnich-udaju/ | Information about processing and
> > protection of business partner's personal data are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> legally
> > binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
> > via R-
> > > help
> > > Sent: Monday, July 2, 2018 2:02 PM
> > > To: r-help at r-project.org
> > > Subject: [R] R maintains old values
> > >
> > > Hello,
> > >
> > > I have a strange side-effect from executing R-scripts using R and
> RServe.
> > >
> > > I am executing an R-Script from a Java file using RServe in R. I also
> > have RStudio
> > > installed, but it's not running at the time. The R-script reads a CSV
> > file and does
> > > various statistical things. RServe enables me to run each line of the R
> > script
> > > using "eval()" line by line.
> > >
> > > All this works fine for a correctly-formatted CSV file. It's great.
> > >
> > > But, if the CSV file isn't correctly formatted, AND the last CSV file
> > did correctly
> > > get run, then, with the incorrect CSV as input, the output is what ran
> > last time.
> > > Somehow, the last correct run is persisted and returned if there is
> some
> > > problem with the current CSV input.
> > >
> > > This data persistence is maintained across reboots.
> > >
> > > I'm thus baffled how R is maintaining these old values, but more to the
> > point, I
> > > need to know how to clear these old values so if the CSV input is
> > incorrect, I get
> > > nothing back, not the old CSV values from a correctly formatted file.
> > >
> > > Hope this description is clear.
> > >
> > > Thanks in advance to all.
> > >
> > > - M
> > >
> > > Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> > email.
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@ulbern@l07 @ending from gm@il@com  Mon Jul  2 22:22:39 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Mon, 2 Jul 2018 15:22:39 -0500
Subject: [R] Extracting the MAPE value from a fitted Time Series Model
Message-ID: <CAMOcQfPX9bKFMfxs5STZ7EKT3D1LymZt9HZmYLtR4k4f1La4Qg@mail.gmail.com>

Dear friends,

I want to extract the MAPE value from a fitted time series model. This is
what I have:

> str(TransitSpline)
List of 12
 $ method               : chr "Cubic Smoothing Spline"
 $ level                : num [1:2] 80 95
 $ x                    : Time-Series [1:385] from 1 to 385: 77 75 85 74 73
96 82 90 91 81 ...
 $ series               : chr "data$Transits"
 $ mean                 : Time-Series [1:10, 1] from 386 to 395: 186 178
170 163 155 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr "Series 1"
 $ upper                : Time-Series [1:10, 1:2] from 386 to 395: 202 199
197 197 197 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr [1:2] "Series 1" "Series 2"
 $ lower                : Time-Series [1:10, 1:2] from 386 to 395: 171 158
144 129 113 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr [1:2] "Series 1" "Series 2"
 $ model                :List of 2
  ..$ beta: num 6.15
  ..$ call: language splinef(y = data$Transits)
 $ fitted               : Time-Series [1:385] from 1 to 385: 76.1 77.3 78.5
80.1 82.2 ...
 $ residuals            : Time-Series [1:385] from 1 to 385: NA -1.3 9.49
-8.64 -4.34 ...
 $ standardizedresiduals: Time-Series [1:385] from 1 to 385: NA -0.875
6.517 -5.586 -2.736 ...
 $ onestepf             : Time-Series [1:385] from 1 to 385: NA 76.3 75.5
82.6 77.3 ...
 - attr(*, "class")= chr [1:2] "splineforecast" "forecast"


> str(summary(TransitSpline))
#Here I want to get the value for the MAPE measure
Forecast method: Cubic Smoothing Spline

Model Information:
$`beta`
[1] 6.149167

$call
splinef(y = data$Transits)


Error measures:
                      ME     RMSE      MAE        MPE     MAPE     MASE
   ACF1
Training set -0.07776434 12.10204 9.003675 -0.2408687 5.377131 0.930913
-0.2766975

Forecasts:
    Point Forecast     Lo 80    Hi 80      Lo 95    Hi 95
386       186.0153 170.52426 201.5064 162.323777 209.7069
387       178.2220 157.87687 198.5671 147.106804 209.3372
388       170.4287 143.80863 197.0487 129.716832 211.1405
389       162.6353 128.61257 196.6581 110.602006 214.6687
390       154.8420 112.52646 197.1576  90.125956 219.5581
391       147.0487  95.66491 198.4324  68.463984 225.6334
392       139.2553  78.10706 200.4036  45.737114 232.7736
393       131.4620  59.92462 202.9994  22.055013 240.8690
394       123.6687  41.14798 206.1894  -2.535833 249.8732
395       115.8753  21.82457 209.9261 -27.962900 259.7136
'data.frame':   10 obs. of  5 variables:
 $ Point Forecast: num  186 178 170 163 155 ...
 $ Lo 80         : num  171 158 144 129 113 ...
 $ Hi 80         : num  202 199 197 197 197 ...
 $ Lo 95         : num  162.3 147.1 129.7 110.6 90.1 ...
 $ Hi 95         : num  210 209 211 215 220 ...

any idea on how to accomplish this?

Best regards,

Paul

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jul  2 22:40:27 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 02 Jul 2018 13:40:27 -0700
Subject: [R] Extracting the MAPE value from a fitted Time Series Model
In-Reply-To: <CAMOcQfPX9bKFMfxs5STZ7EKT3D1LymZt9HZmYLtR4k4f1La4Qg@mail.gmail.com>
References: <CAMOcQfPX9bKFMfxs5STZ7EKT3D1LymZt9HZmYLtR4k4f1La4Qg@mail.gmail.com>
Message-ID: <E44D47B3-F866-4E3C-BBAE-76B457783DB0@dcn.davis.ca.us>

Google offers [1], which probably seems like a vague response but your question omitted a reproducible example and is contaminated by posting in HTML (read the Posting Guide).

[1] https://www.rdocumentation.org/packages/MLmetrics/versions/1.1.1/topics/MAPE

On July 2, 2018 1:22:39 PM PDT, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>I want to extract the MAPE value from a fitted time series model. This
>is
>what I have:
>
>> str(TransitSpline)
>List of 12
> $ method               : chr "Cubic Smoothing Spline"
> $ level                : num [1:2] 80 95
>$ x                    : Time-Series [1:385] from 1 to 385: 77 75 85 74
>73
>96 82 90 91 81 ...
> $ series               : chr "data$Transits"
>$ mean                 : Time-Series [1:10, 1] from 386 to 395: 186 178
>170 163 155 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
>  .. ..$ : chr "Series 1"
>$ upper                : Time-Series [1:10, 1:2] from 386 to 395: 202
>199
>197 197 197 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
>  .. ..$ : chr [1:2] "Series 1" "Series 2"
>$ lower                : Time-Series [1:10, 1:2] from 386 to 395: 171
>158
>144 129 113 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
>  .. ..$ : chr [1:2] "Series 1" "Series 2"
> $ model                :List of 2
>  ..$ beta: num 6.15
>  ..$ call: language splinef(y = data$Transits)
>$ fitted               : Time-Series [1:385] from 1 to 385: 76.1 77.3
>78.5
>80.1 82.2 ...
>$ residuals            : Time-Series [1:385] from 1 to 385: NA -1.3
>9.49
>-8.64 -4.34 ...
> $ standardizedresiduals: Time-Series [1:385] from 1 to 385: NA -0.875
>6.517 -5.586 -2.736 ...
>$ onestepf             : Time-Series [1:385] from 1 to 385: NA 76.3
>75.5
>82.6 77.3 ...
> - attr(*, "class")= chr [1:2] "splineforecast" "forecast"
>
>
>> str(summary(TransitSpline))
>#Here I want to get the value for the MAPE measure
>Forecast method: Cubic Smoothing Spline
>
>Model Information:
>$`beta`
>[1] 6.149167
>
>$call
>splinef(y = data$Transits)
>
>
>Error measures:
>                      ME     RMSE      MAE        MPE     MAPE     MASE
>   ACF1
>Training set -0.07776434 12.10204 9.003675 -0.2408687 5.377131 0.930913
>-0.2766975
>
>Forecasts:
>    Point Forecast     Lo 80    Hi 80      Lo 95    Hi 95
>386       186.0153 170.52426 201.5064 162.323777 209.7069
>387       178.2220 157.87687 198.5671 147.106804 209.3372
>388       170.4287 143.80863 197.0487 129.716832 211.1405
>389       162.6353 128.61257 196.6581 110.602006 214.6687
>390       154.8420 112.52646 197.1576  90.125956 219.5581
>391       147.0487  95.66491 198.4324  68.463984 225.6334
>392       139.2553  78.10706 200.4036  45.737114 232.7736
>393       131.4620  59.92462 202.9994  22.055013 240.8690
>394       123.6687  41.14798 206.1894  -2.535833 249.8732
>395       115.8753  21.82457 209.9261 -27.962900 259.7136
>'data.frame':   10 obs. of  5 variables:
> $ Point Forecast: num  186 178 170 163 155 ...
> $ Lo 80         : num  171 158 144 129 113 ...
> $ Hi 80         : num  202 199 197 197 197 ...
> $ Lo 95         : num  162.3 147.1 129.7 110.6 90.1 ...
> $ Hi 95         : num  210 209 211 215 220 ...
>
>any idea on how to accomplish this?
>
>Best regards,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From lori@@bennett @ending from fu-berlin@de  Tue Jul  3 09:09:23 2018
From: lori@@bennett @ending from fu-berlin@de (Loris Bennett)
Date: Tue, 03 Jul 2018 09:09:23 +0200
Subject: [R] doMPI: script hangs on closeCluster
In-Reply-To: <87r2klrfdc.fsf@hornfels.zedat.fu-berlin.de> (Loris Bennett's
 message of "Mon, 2 Jul 2018 14:28:31 +0200")
References: <87r2klrfdc.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <87zhz894nw.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Hi,
>
> On Linux with R 3.5.1 and OpenMPI 2.1.0 I have built Rmpi and can run a
> simple example just using Rmpi and printing out the rank of each worker.
>
> However, when I try to use doMPI by running the following
>
>   library(Rmpi)
>   library(doMPI)
>   cl <- startMPIcluster(count=2)
>   registerDoMPI(cl)
>   clusterSize(cl)
>   closeCluster(cl)
>   mpi.quit()
>
> with
>
>   mpirun -np 1 --mca mpi_warn_on_fork 0 R --no-save -f mwe.r
>
> I get the following output
>
>   > library("Rmpi")
>   > library(doMPI)
>   Loading required package: foreach
>   Loading required package: iterators
>   > cl <- startMPIcluster(count=2)
>   	2 slaves are spawned successfully. 0 failed.
>   > registerDoMPI(cl)
>   > clusterSize(cl)
>   [1] 2
>   > closeCluster(cl)
>
> but the program hangs and I have to end it with Ctl-C.
>
> Can anyone shed any light on what might be wrong?

Having come across the following link:

  https://www.sharcnet.ca/help/index.php/Using_R_and_MPI

I rebuilt with OpenMPI 1.8.6 and the problem disappeared.

Cheers,

Loris

-- 
This signature is currently under construction.


From pd@lgd @ending from gm@il@com  Tue Jul  3 09:52:46 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Tue, 3 Jul 2018 09:52:46 +0200
Subject: [R] R maintains old values
In-Reply-To: <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
Message-ID: <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>

Also beware the traveling arsonist, Jenny Bryan:

https://www.tidyverse.org/articles/2017/12/workflow-vs-script/


-pd

> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ... or perhaps
> 
> rm( list = ls(all = TRUE))
> ## see ?ls  for details.
> 
> However, see ?Startup for how to start a R in a "clean" environment, e.g.
> with the --no-restore option.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
>> If you want a "fresh" R session when you start to run the script you could
>> consider putting as the first line
>> 
>> rm(list=ls())
>> 
>> This will remove objects from your environment (variables, functions, ..)
>> 
>> HTH,
>> Eric
>> 
>> 
>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> 
>>> Hi
>>> 
>>> Without code it is just fishing in murky waters. Could the problem you
>>> face be that in each run you assingn the result to some object and if the
>>> CSV is wrong your code fails but the object from previous run persists?
>>> 
>>> If this is the case just initialize your objects in the beginning (e.g.
>>> make them NULL at the beginning) and only if code delivers result the
>> value
>>> of the result is returned otherwise NULL is returned.
>>> 
>>> Cheers
>>> Petr
>>> 
>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>> protection of business partner's personal data are available on website:
>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>> documents attached to it may be confidential and are subject to the
>> legally
>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>> 
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>> via R-
>>>> help
>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>> To: r-help at r-project.org
>>>> Subject: [R] R maintains old values
>>>> 
>>>> Hello,
>>>> 
>>>> I have a strange side-effect from executing R-scripts using R and
>> RServe.
>>>> 
>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>> have RStudio
>>>> installed, but it's not running at the time. The R-script reads a CSV
>>> file and does
>>>> various statistical things. RServe enables me to run each line of the R
>>> script
>>>> using "eval()" line by line.
>>>> 
>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>> 
>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>> did correctly
>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>> last time.
>>>> Somehow, the last correct run is persisted and returned if there is
>> some
>>>> problem with the current CSV input.
>>>> 
>>>> This data persistence is maintained across reboots.
>>>> 
>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>> point, I
>>>> need to know how to clear these old values so if the CSV input is
>>> incorrect, I get
>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>> 
>>>> Hope this description is clear.
>>>> 
>>>> Thanks in advance to all.
>>>> 
>>>> - M
>>>> 
>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>> email.
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tr@xpl@yer @ending from gm@il@com  Tue Jul  3 14:24:33 2018
From: tr@xpl@yer @ending from gm@il@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Tue, 3 Jul 2018 14:24:33 +0200
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
Message-ID: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>

Hi,
  I am currently using R v3.4.4 and I just discovered this:

> prod(NA, NaN) ; prod(NaN, NA)
[1] NA
[1] NaN

?prod says:
    If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
     cause a value of ?NA? to be returned, otherwise ?NA? values are
     ignored.

So according to the manual-page for prod() NA should be returned in both
cases?


However for sum() is opposite is true:
> sum(NA, NaN) ; sum(NaN, NA)
[1] NA
[1] NA

?sum says:
    If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
     arguments will cause a value of ?NA? or ?NaN? to be returned,
     otherwise ?NA? and ?NaN? values are ignored.


Maybe the manual for prod() should say the same as sum() that
both NA and NaN can be returned?

Regards
Martin


From profjcn@@h @ending from gm@il@com  Tue Jul  3 15:25:39 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Tue, 3 Jul 2018 09:25:39 -0400
Subject: [R] R maintains old values
In-Reply-To: <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
Message-ID: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>

For the sake of those who didn't see the link, Jenny objects strongly to startup
lines that either set a personal path or clear the workspace.

While I agree both of these are anti-social to the point of pathology for scripts
that are distributed, I have found it VERY important when testing things to actually
clear the workspace etc. Too many times I've got a result that nobody else would get
because I'm often loading some of my own packages or there are "useful" variables
lurking.

As usual, context is critical. Distributed scripts vs. developmental ones.

Now, to add to the controversy, how do you set a computer on fire?

JN

On 2018-07-03 03:52 AM, peter dalgaard wrote:
> Also beware the traveling arsonist, Jenny Bryan:
> 
> https://www.tidyverse.org/articles/2017/12/workflow-vs-script/
> 
> 
> -pd
> 
>> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> ... or perhaps
>>
>> rm( list = ls(all = TRUE))
>> ## see ?ls  for details.
>>
>> However, see ?Startup for how to start a R in a "clean" environment, e.g.
>> with the --no-restore option.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>
>>> If you want a "fresh" R session when you start to run the script you could
>>> consider putting as the first line
>>>
>>> rm(list=ls())
>>>
>>> This will remove objects from your environment (variables, functions, ..)
>>>
>>> HTH,
>>> Eric
>>>
>>>
>>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>
>>>> Hi
>>>>
>>>> Without code it is just fishing in murky waters. Could the problem you
>>>> face be that in each run you assingn the result to some object and if the
>>>> CSV is wrong your code fails but the object from previous run persists?
>>>>
>>>> If this is the case just initialize your objects in the beginning (e.g.
>>>> make them NULL at the beginning) and only if code delivers result the
>>> value
>>>> of the result is returned otherwise NULL is returned.
>>>>
>>>> Cheers
>>>> Petr
>>>>
>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>>> protection of business partner's personal data are available on website:
>>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>>> documents attached to it may be confidential and are subject to the
>>> legally
>>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>>
>>>>> -----Original Message-----
>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>>> via R-
>>>>> help
>>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] R maintains old values
>>>>>
>>>>> Hello,
>>>>>
>>>>> I have a strange side-effect from executing R-scripts using R and
>>> RServe.
>>>>>
>>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>>> have RStudio
>>>>> installed, but it's not running at the time. The R-script reads a CSV
>>>> file and does
>>>>> various statistical things. RServe enables me to run each line of the R
>>>> script
>>>>> using "eval()" line by line.
>>>>>
>>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>>>
>>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>>> did correctly
>>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>>> last time.
>>>>> Somehow, the last correct run is persisted and returned if there is
>>> some
>>>>> problem with the current CSV input.
>>>>>
>>>>> This data persistence is maintained across reboots.
>>>>>
>>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>>> point, I
>>>>> need to know how to clear these old values so if the CSV input is
>>>> incorrect, I get
>>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>>>
>>>>> Hope this description is clear.
>>>>>
>>>>> Thanks in advance to all.
>>>>>
>>>>> - M
>>>>>
>>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>>> email.
>>>>>      [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl  Tue Jul  3 15:28:45 2018
From: wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl (Viechtbauer, Wolfgang (SP))
Date: Tue, 3 Jul 2018 13:28:45 +0000
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
Message-ID: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>

Hi All,

I have one vector that I want to combine with another vector and that other vector should be the same for every row in the combined matrix. This obviously does not work:

vec <- c(2,4,3)
cbind(1:5, vec)

This does, but requires me to specify the correct value for 'n' in replicate():

cbind(1:5, t(replicate(5, vec)))

Other ways that do not require this are:

t(sapply(1:5, function(x) c(x, vec)))
do.call(rbind, lapply(1:5, function(x) c(x, vec)))
t(mapply(c, 1:5, MoreArgs=list(vec)))

I wonder if there is a simpler / more efficient way of doing this.

Best,
Wolfgang


From loe@ljrg @ending from @ccucom@net  Tue Jul  3 15:40:36 2018
From: loe@ljrg @ending from @ccucom@net (JRG)
Date: Tue, 3 Jul 2018 09:40:36 -0400
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <9f0c789f-ea14-d929-d22f-7c6374ff31ec@accucom.net>


On 07/03/2018 09:25 AM, J C Nash wrote:
> For the sake of those who didn't see the link, Jenny objects strongly to startup
> lines that either set a personal path or clear the workspace.
> 
> While I agree both of these are anti-social to the point of pathology for scripts
> that are distributed, I have found it VERY important when testing things to actually
> clear the workspace etc. Too many times I've got a result that nobody else would get
> because I'm often loading some of my own packages or there are "useful" variables
> lurking.
> 
> As usual, context is critical. Distributed scripts vs. developmental ones.


Agreed!

> 
> Now, to add to the controversy, how do you set a computer on fire?

One of the Boring Company's  Not A Flamethrowers ??


---JRG

John R. Gleason

> 
> JN
> 
> On 2018-07-03 03:52 AM, peter dalgaard wrote:
>> Also beware the traveling arsonist, Jenny Bryan:
>>
>> https://www.tidyverse.org/articles/2017/12/workflow-vs-script/
>>
>>
>> -pd
>>
>>> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> ... or perhaps
>>>
>>> rm( list = ls(all = TRUE))
>>> ## see ?ls  for details.
>>>
>>> However, see ?Startup for how to start a R in a "clean" environment, e.g.
>>> with the --no-restore option.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>>
>>>> If you want a "fresh" R session when you start to run the script you could
>>>> consider putting as the first line
>>>>
>>>> rm(list=ls())
>>>>
>>>> This will remove objects from your environment (variables, functions, ..)
>>>>
>>>> HTH,
>>>> Eric
>>>>
>>>>
>>>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>>
>>>>> Hi
>>>>>
>>>>> Without code it is just fishing in murky waters. Could the problem you
>>>>> face be that in each run you assingn the result to some object and if the
>>>>> CSV is wrong your code fails but the object from previous run persists?
>>>>>
>>>>> If this is the case just initialize your objects in the beginning (e.g.
>>>>> make them NULL at the beginning) and only if code delivers result the
>>>> value
>>>>> of the result is returned otherwise NULL is returned.
>>>>>
>>>>> Cheers
>>>>> Petr
>>>>>
>>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>>>> protection of business partner's personal data are available on website:
>>>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>>>> documents attached to it may be confidential and are subject to the
>>>> legally
>>>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>>>> via R-
>>>>>> help
>>>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>>>> To: r-help at r-project.org
>>>>>> Subject: [R] R maintains old values
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> I have a strange side-effect from executing R-scripts using R and
>>>> RServe.
>>>>>>
>>>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>>>> have RStudio
>>>>>> installed, but it's not running at the time. The R-script reads a CSV
>>>>> file and does
>>>>>> various statistical things. RServe enables me to run each line of the R
>>>>> script
>>>>>> using "eval()" line by line.
>>>>>>
>>>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>>>>
>>>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>>>> did correctly
>>>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>>>> last time.
>>>>>> Somehow, the last correct run is persisted and returned if there is
>>>> some
>>>>>> problem with the current CSV input.
>>>>>>
>>>>>> This data persistence is maintained across reboots.
>>>>>>
>>>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>>>> point, I
>>>>>> need to know how to clear these old values so if the CSV input is
>>>>> incorrect, I get
>>>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>>>>
>>>>>> Hope this description is clear.
>>>>>>
>>>>>> Thanks in advance to all.
>>>>>>
>>>>>> - M
>>>>>>
>>>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>>>> email.
>>>>>>      [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From pd@lgd @ending from gm@il@com  Tue Jul  3 16:04:30 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Tue, 3 Jul 2018 16:04:30 +0200
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <0BC49EC2-978A-48CB-939B-F3E9A810C771@gmail.com>



> On 3 Jul 2018, at 15:25 , J C Nash <profjcnash at gmail.com> wrote:
> 
> For the sake of those who didn't see the link, Jenny objects strongly to startup
> lines that either set a personal path or clear the workspace.
> 
> While I agree both of these are anti-social to the point of pathology for scripts
> that are distributed, I have found it VERY important when testing things to actually
> clear the workspace etc. Too many times I've got a result that nobody else would get
> because I'm often loading some of my own packages or there are "useful" variables
> lurking.


I think Jenny's point is more that rm(ls... is the wrong _method_ to clear the workspace, because it only does part of the job and you may end up missing require() statements, etc.  

> 
> As usual, context is critical. Distributed scripts vs. developmental ones.
> 
> Now, to add to the controversy, how do you set a computer on fire?


Short the lithium battery?

-pd

> 
> JN
> 
> On 2018-07-03 03:52 AM, peter dalgaard wrote:
>> Also beware the traveling arsonist, Jenny Bryan:
>> 
>> https://www.tidyverse.org/articles/2017/12/workflow-vs-script/
>> 
>> 
>> -pd
>> 
>>> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> ... or perhaps
>>> 
>>> rm( list = ls(all = TRUE))
>>> ## see ?ls  for details.
>>> 
>>> However, see ?Startup for how to start a R in a "clean" environment, e.g.
>>> with the --no-restore option.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>> 
>>>> If you want a "fresh" R session when you start to run the script you could
>>>> consider putting as the first line
>>>> 
>>>> rm(list=ls())
>>>> 
>>>> This will remove objects from your environment (variables, functions, ..)
>>>> 
>>>> HTH,
>>>> Eric
>>>> 
>>>> 
>>>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>> 
>>>>> Hi
>>>>> 
>>>>> Without code it is just fishing in murky waters. Could the problem you
>>>>> face be that in each run you assingn the result to some object and if the
>>>>> CSV is wrong your code fails but the object from previous run persists?
>>>>> 
>>>>> If this is the case just initialize your objects in the beginning (e.g.
>>>>> make them NULL at the beginning) and only if code delivers result the
>>>> value
>>>>> of the result is returned otherwise NULL is returned.
>>>>> 
>>>>> Cheers
>>>>> Petr
>>>>> 
>>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>>>> protection of business partner's personal data are available on website:
>>>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>>>> documents attached to it may be confidential and are subject to the
>>>> legally
>>>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>>>> via R-
>>>>>> help
>>>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>>>> To: r-help at r-project.org
>>>>>> Subject: [R] R maintains old values
>>>>>> 
>>>>>> Hello,
>>>>>> 
>>>>>> I have a strange side-effect from executing R-scripts using R and
>>>> RServe.
>>>>>> 
>>>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>>>> have RStudio
>>>>>> installed, but it's not running at the time. The R-script reads a CSV
>>>>> file and does
>>>>>> various statistical things. RServe enables me to run each line of the R
>>>>> script
>>>>>> using "eval()" line by line.
>>>>>> 
>>>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>>>> 
>>>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>>>> did correctly
>>>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>>>> last time.
>>>>>> Somehow, the last correct run is persisted and returned if there is
>>>> some
>>>>>> problem with the current CSV input.
>>>>>> 
>>>>>> This data persistence is maintained across reboots.
>>>>>> 
>>>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>>>> point, I
>>>>>> need to know how to clear these old values so if the CSV input is
>>>>> incorrect, I get
>>>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>>>> 
>>>>>> Hope this description is clear.
>>>>>> 
>>>>>> Thanks in advance to all.
>>>>>> 
>>>>>> - M
>>>>>> 
>>>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>>>> email.
>>>>>>     [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From cry@n @ending from bingh@mton@edu  Tue Jul  3 16:09:19 2018
From: cry@n @ending from bingh@mton@edu (Christopher W Ryan)
Date: Tue, 3 Jul 2018 10:09:19 -0400
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <CAM+rpYmM_2pjKQZ0P8xN8xmscQ9Xv6Ap=j=r26ygBEn=reN+4Q@mail.gmail.com>

This TV series might have some advice on that.

https://www.imdb.com/title/tt2543312/

--Chris Ryan

On Tue, Jul 3, 2018 at 9:25 AM, J C Nash <profjcnash at gmail.com> wrote:

> . . . Now, to add to the controversy, how do you set a computer on fire?
>
> JN
>
>

	[[alternative HTML version deleted]]


From nin@@@choenfelder @ending from uni-bielefeld@de  Tue Jul  3 12:33:49 2018
From: nin@@@choenfelder @ending from uni-bielefeld@de (=?UTF-8?Q?Nina_Sch=c3=b6nfelder?=)
Date: Tue, 03 Jul 2018 12:33:49 +0200
Subject: [R] R-help Digest, Vol 185, Issue 1
In-Reply-To: <mailman.350307.1.1530439201.52115.r-help@r-project.org>
References: <mailman.350307.1.1530439201.52115.r-help@r-project.org>
Message-ID: <c05ce3a0-100a-782d-9820-af2027d33355@uni-bielefeld.de>

Dear Luke,

it true that the number is not immediately displayed in the 
GMM-regression output using the plm package. To get the number of 
instruments (incl. exogenous variables and time dummies) you have to type:

 ????? k <- model??? # so that k is the pgmm-estimation output (an 
object of class c("pgmm","panelmodel")
 ??? ? ninst <- ncol(k$W[[1]])??? # the number of instruments is simply 
count as the number of columns in the matrix of instruments

Best regards,

Nina

--

*Dr. Nina Sch?nfelder*

*Nationaler Open-Access-Kontaktpunkt OA2020-DE*
Universit?t Bielefeld
Universit?tsbibliothek
Universit?tsstr. 25
D-33615 Bielefeld

Phone: +49 (0) 521/106-2546
E-mail: nina.schoenfelder at uni-bielefeld.de
Homepage: https://oa2020-de.org/
Twitter: @oa2020de
Facebook: https://www.facebook.com/oa2020de/

Am 01.07.2018 um 12:00 schrieb r-help-request at r-project.org:
> Message: 1
> Date: Sat, 30 Jun 2018 11:03:06 +0200
> From: =?UTF-8?b?xYF1a2FzeiBQacSZdGFr?=<L.Pietak at poczta.fm>
> To:r-help at r-project.org
> Subject: [R] Question
> Message-ID: <hbqeaucobgtjfdbbzufb at kmye>
> Content-Type: text/plain; charset="utf-8"
>
>
> Hi, My name is Luke and I come from Poland. I have one question, maybe very simple, but I can not resolve it. In dynamic panel data (GMM estimator) after running the model, I recieve a AR test and Sargan test, but the "number of instruments" are not displayed. In Stata and Gretl this informatios is given, in R no. My question is, how to obtain the number of instruments?.
> Thank you for helping.
> Luke
>
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Tue Jul  3 16:39:04 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 3 Jul 2018 14:39:04 +0000
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
Message-ID: <43fd0e6ac353429da2547e7f8ab369b3@SRVEXCHCM1302.precheza.cz>

Hi

If you put 1:5 vector to x you could do

cbind(x,t(replicate(length(x), vec)))

Cheers
Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Viechtbauer,
> Wolfgang (SP)
> Sent: Tuesday, July 3, 2018 3:29 PM
> To: r-help at r-project.org
> Subject: [R] Combine by columns a vector with another vector that is constant
> across rows
> 
> Hi All,
> 
> I have one vector that I want to combine with another vector and that other
> vector should be the same for every row in the combined matrix. This obviously
> does not work:
> 
> vec <- c(2,4,3)
> cbind(1:5, vec)
> 
> This does, but requires me to specify the correct value for 'n' in replicate():
> 
> cbind(1:5, t(replicate(5, vec)))
> 
> Other ways that do not require this are:
> 
> t(sapply(1:5, function(x) c(x, vec)))
> do.call(rbind, lapply(1:5, function(x) c(x, vec))) t(mapply(c, 1:5,
> MoreArgs=list(vec)))
> 
> I wonder if there is a simpler / more efficient way of doing this.
> 
> Best,
> Wolfgang
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck @ending from gm@il@com  Tue Jul  3 16:46:19 2018
From: ggrothendieck @ending from gm@il@com (Gabor Grothendieck)
Date: Tue, 3 Jul 2018 10:46:19 -0400
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
Message-ID: <CAP01uRntSXp780CNfsZ-L6DDJz-K1EaOop1Ab4HVe_AKdA_bxQ@mail.gmail.com>

Try Reduce:

  Reduce(cbind, vec, 1:5)

On Tue, Jul 3, 2018 at 9:28 AM, Viechtbauer, Wolfgang (SP)
<wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> Hi All,
>
> I have one vector that I want to combine with another vector and that other vector should be the same for every row in the combined matrix. This obviously does not work:
>
> vec <- c(2,4,3)
> cbind(1:5, vec)
>
> This does, but requires me to specify the correct value for 'n' in replicate():
>
> cbind(1:5, t(replicate(5, vec)))
>
> Other ways that do not require this are:
>
> t(sapply(1:5, function(x) c(x, vec)))
> do.call(rbind, lapply(1:5, function(x) c(x, vec)))
> t(mapply(c, 1:5, MoreArgs=list(vec)))
>
> I wonder if there is a simpler / more efficient way of doing this.
>
> Best,
> Wolfgang
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From DOgle @ending from northl@nd@edu  Tue Jul  3 17:05:22 2018
From: DOgle @ending from northl@nd@edu (Derek Ogle)
Date: Tue, 3 Jul 2018 15:05:22 +0000
Subject: [R] limit windows() rescale/resize options
Message-ID: <5C759AAB3680854DA1CFD152DD5CCE5A013D27EB55@NC-MAIL2010.northland.edu>

I am developing an application that opens an image in a new window using, at times, windows(). I don't want the user to be able to resize the window (and distort the image). The new window contains a menu item called "resize" that contains three options - "R mode", "Fit to window", and "Fixed size". The default can be set with rescale= (i.e., rescale="fixed" for my use). However, the user can still select one of the other options. Is there a way to either remove the "Resize" menu from this window or remove the "R mode" and "Fit to window" options from this menu item?

Use the following, on a Windows machine, to see what I describe above.

windows(rescale="fixed")


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jul  3 17:21:47 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Jul 2018 08:21:47 -0700
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
Message-ID: <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>

Gabor's solution seems to optimize 'simpler'.

More efficient is to learn that in R a vector is not a matrix, but a matrix is just an ornamented vector.

fastWolfgang <- function( v, vec ) {
  matrix( c( v, rep( vec, length( v ) ) )
         , now = length( v ) )
}

On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)" <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>Hi All,
>
>I have one vector that I want to combine with another vector and that
>other vector should be the same for every row in the combined matrix.
>This obviously does not work:
>
>vec <- c(2,4,3)
>cbind(1:5, vec)
>
>This does, but requires me to specify the correct value for 'n' in
>replicate():
>
>cbind(1:5, t(replicate(5, vec)))
>
>Other ways that do not require this are:
>
>t(sapply(1:5, function(x) c(x, vec)))
>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>t(mapply(c, 1:5, MoreArgs=list(vec)))
>
>I wonder if there is a simpler / more efficient way of doing this.
>
>Best,
>Wolfgang
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From Bill@Poling @ending from zeli@@com  Tue Jul  3 17:23:35 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Tue, 3 Jul 2018 15:23:35 +0000
Subject: [R] Structure to ts Error in attributes(.Data) <-
 c(attributes(.Data), attrib) :
Message-ID: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi, obviously missing something here? Getting error: Error in attributes(.Data) <- c(attributes(.Data), attrib) : invalid time series parameters specified


dat3 <- structure(c(1439713.32, 1265962.79, 1491834.9, 1276180.74, 1702077.51, 1420186.1, 1469240.11, 1415855.34, 1592933.06,   #9
                    1615926.39, 1668444.01, 1753406, 1356487.99, 1577808.22, 1906113.28, 1595299.45, 1671740.24, 1696643.33,    #9
                    1490665.78, 1937361.24, 1480193.81, 1676066.85, 2004112.69, 1798906.55, 1619973.89, 1280088.4, 1877394.67,  #9
                    2041241.6, 1390644.41, 2208564.77,                                                                          #3
                    #30

                    1384.3, -14169.24, -1455.1, -82397.77, -15564.42, 1808.77, -29776.31, -62641.51, -15418.52, #9
                    -6170.87, -14208.48, -43046.76, -43853.35, -53907.65, -29729.62, -47990.07, 54674.99,       #8
                    4029.92, -48323.28, 35197.06, -97430.56, -48994.68, -49803.5, -12870.97, -33126.07,         #8
                    -27147.19, -9559.51, -37699.07, -222996.6, -329.55,                                         #5
                    #30

                    -95835.69, -73436.06, -100240.36, -78918.26, -71763.56, -83735.15, -34898.95, -98622.59, -66763.2,         #9
                    -184645.76, -85494.47, -94503.59, -143120.57, -49829.96, -99636.61, -108242.24, -101192.2, -60214.25,      #9
                    -208992.81, -49769.11, -93133.14, -160933.77, -197905.84, -194055.39, -101310.71, -185137.96, -204476.75,  #9
                    -149305.62, -171494.96, -441145.96                                                                         #3
                    #30
)
                  ,.Dim = c(30L, 3L)
                  ,.Dimnames = list(NULL, c("Var1","Var2" ,"Var3"))
                  ,.Tsp = c(2016, 2018.5, 12), class = c("mts", "ts", "matrix"))

I am sure it's glaring at me!

Thank you for any advice.

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From ggrothendieck @ending from gm@il@com  Tue Jul  3 17:32:08 2018
From: ggrothendieck @ending from gm@il@com (Gabor Grothendieck)
Date: Tue, 3 Jul 2018 11:32:08 -0400
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <CAP01uRntSXp780CNfsZ-L6DDJz-K1EaOop1Ab4HVe_AKdA_bxQ@mail.gmail.com>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <CAP01uRntSXp780CNfsZ-L6DDJz-K1EaOop1Ab4HVe_AKdA_bxQ@mail.gmail.com>
Message-ID: <CAP01uRkecBuLwL0kpVJFt4tRL0VWR1L204jJNJbzx8GzAo_3Vg@mail.gmail.com>

or this variation if you don't want the first column to be named init:

 Reduce(cbind2, vec, 1:5)

On Tue, Jul 3, 2018 at 10:46 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Try Reduce:
>
>   Reduce(cbind, vec, 1:5)
>
> On Tue, Jul 3, 2018 at 9:28 AM, Viechtbauer, Wolfgang (SP)
> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> Hi All,
>>
>> I have one vector that I want to combine with another vector and that other vector should be the same for every row in the combined matrix. This obviously does not work:
>>
>> vec <- c(2,4,3)
>> cbind(1:5, vec)
>>
>> This does, but requires me to specify the correct value for 'n' in replicate():
>>
>> cbind(1:5, t(replicate(5, vec)))
>>
>> Other ways that do not require this are:
>>
>> t(sapply(1:5, function(x) c(x, vec)))
>> do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>> t(mapply(c, 1:5, MoreArgs=list(vec)))
>>
>> I wonder if there is a simpler / more efficient way of doing this.
>>
>> Best,
>> Wolfgang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jul  3 17:47:56 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Jul 2018 08:47:56 -0700
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
Message-ID: <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>

Sorry trying again...

fastWolfgang <- function( v, vec ) {
  matrix( c( v, rep( vec, each = length( v ) ) )
         , nrow = length( v ) )
}

On July 3, 2018 8:21:47 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>Gabor's solution seems to optimize 'simpler'.
>
>More efficient is to learn that in R a vector is not a matrix, but a
>matrix is just an ornamented vector.
>
>fastWolfgang <- function( v, vec ) {
>  matrix( c( v, rep( vec, length( v ) ) )
>         , now = length( v ) )
>}
>
>On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)"
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>Hi All,
>>
>>I have one vector that I want to combine with another vector and that
>>other vector should be the same for every row in the combined matrix.
>>This obviously does not work:
>>
>>vec <- c(2,4,3)
>>cbind(1:5, vec)
>>
>>This does, but requires me to specify the correct value for 'n' in
>>replicate():
>>
>>cbind(1:5, t(replicate(5, vec)))
>>
>>Other ways that do not require this are:
>>
>>t(sapply(1:5, function(x) c(x, vec)))
>>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>>t(mapply(c, 1:5, MoreArgs=list(vec)))
>>
>>I wonder if there is a simpler / more efficient way of doing this.
>>
>>Best,
>>Wolfgang
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ted@h@rding @ending from wl@ndre@@net  Tue Jul  3 17:58:37 2018
From: ted@h@rding @ending from wl@ndre@@net (Ted Harding)
Date: Tue, 03 Jul 2018 16:58:37 +0100
Subject: [R] R maintains old values
In-Reply-To: <CAM+rpYmM_2pjKQZ0P8xN8xmscQ9Xv6Ap=j=r26ygBEn=reN+4Q@mail.gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
 <CAM+rpYmM_2pjKQZ0P8xN8xmscQ9Xv6Ap=j=r26ygBEn=reN+4Q@mail.gmail.com>
Message-ID: <1530633517.4282.2.camel@deb2.fort.knox.uk>

On Tue, Jul 3, 2018 at 9:25 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> > . . . Now, to add to the controversy, how do you set a computer on fire?
> >
> > JN

Perhaps by exploring the context of this thread,
where new values strike a match with old values???

Ted


From ericjberger @ending from gm@il@com  Tue Jul  3 18:02:13 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Tue, 3 Jul 2018 19:02:13 +0300
Subject: [R] Structure to ts Error in attributes(.Data) <-
 c(attributes(.Data), attrib) :
In-Reply-To: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAGgJW77EqzqcyDpfE7-rurCa4kzg6djpnLy44hzryFBnr8KLrQ@mail.gmail.com>

Hi WHP,
It should be
.Tsp=c(2016,2018.4166667,12)

(off  by one error)
HTH,
Eric


On Tue, Jul 3, 2018 at 6:23 PM, Bill Poling <Bill.Poling at zelis.com> wrote:

> Hi, obviously missing something here? Getting error: Error in
> attributes(.Data) <- c(attributes(.Data), attrib) : invalid time series
> parameters specified
>
>
> dat3 <- structure(c(1439713.32, 1265962.79, 1491834.9, 1276180.74,
> 1702077.51, 1420186.1, 1469240.11, 1415855.34, 1592933.06,   #9
>                     1615926.39, 1668444.01, 1753406, 1356487.99,
> 1577808.22, 1906113.28, 1595299.45, 1671740.24, 1696643.33,    #9
>                     1490665.78, 1937361.24, 1480193.81, 1676066.85,
> 2004112.69, 1798906.55, 1619973.89, 1280088.4, 1877394.67,  #9
>                     2041241.6, 1390644.41, 2208564.77,
>                                                       #3
>                     #30
>
>                     1384.3, -14169.24, -1455.1, -82397.77, -15564.42,
> 1808.77, -29776.31, -62641.51, -15418.52, #9
>                     -6170.87, -14208.48, -43046.76, -43853.35, -53907.65,
> -29729.62, -47990.07, 54674.99,       #8
>                     4029.92, -48323.28, 35197.06, -97430.56, -48994.68,
> -49803.5, -12870.97, -33126.07,         #8
>                     -27147.19, -9559.51, -37699.07, -222996.6, -329.55,
>                                      #5
>                     #30
>
>                     -95835.69, -73436.06, -100240.36, -78918.26,
> -71763.56, -83735.15, -34898.95, -98622.59, -66763.2,         #9
>                     -184645.76, -85494.47, -94503.59, -143120.57,
> -49829.96, -99636.61, -108242.24, -101192.2, -60214.25,      #9
>                     -208992.81, -49769.11, -93133.14, -160933.77,
> -197905.84, -194055.39, -101310.71, -185137.96, -204476.75,  #9
>                     -149305.62, -171494.96, -441145.96
>                                                      #3
>                     #30
> )
>                   ,.Dim = c(30L, 3L)
>                   ,.Dimnames = list(NULL, c("Var1","Var2" ,"Var3"))
>                   ,.Tsp = c(2016, 2018.5, 12), class = c("mts", "ts",
> "matrix"))
>
> I am sure it's glaring at me!
>
> Thank you for any advice.
>
> WHP
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Tue Jul  3 18:46:04 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Tue, 3 Jul 2018 16:46:04 +0000
Subject: [R] FW: Structure to ts Error in attributes(.Data) <-
 c(attributes(.Data), attrib) :
In-Reply-To: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CY1PR0201MB1834F4002FF5D3756D4FA822EA420@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi, I have my solution.

It should be
.Tsp=c(2016,2018.4166667,12)

(off  by one error)

Thank you.
WHP

From: Bill Poling
Sent: Tuesday, July 03, 2018 11:24 AM
To: r-help (r-help at r-project.org) <r-help at r-project.org>
Cc: Bill Poling <Bill.Poling at zelis.com>
Subject: Structure to ts Error in attributes(.Data) <- c(attributes(.Data), attrib) :

Hi, obviously missing something here? Getting error: Error in attributes(.Data) <- c(attributes(.Data), attrib) : invalid time series parameters specified


dat3 <- structure(c(1439713.32, 1265962.79, 1491834.9, 1276180.74, 1702077.51, 1420186.1, 1469240.11, 1415855.34, 1592933.06,   #9
                    1615926.39, 1668444.01, 1753406, 1356487.99, 1577808.22, 1906113.28, 1595299.45, 1671740.24, 1696643.33,    #9
                    1490665.78, 1937361.24, 1480193.81, 1676066.85, 2004112.69, 1798906.55, 1619973.89, 1280088.4, 1877394.67,  #9
                    2041241.6, 1390644.41, 2208564.77,                                                                          #3
                    #30

                    1384.3, -14169.24, -1455.1, -82397.77, -15564.42, 1808.77, -29776.31, -62641.51, -15418.52, #9
                    -6170.87, -14208.48, -43046.76, -43853.35, -53907.65, -29729.62, -47990.07, 54674.99,       #8
                    4029.92, -48323.28, 35197.06, -97430.56, -48994.68, -49803.5, -12870.97, -33126.07,         #8
                    -27147.19, -9559.51, -37699.07, -222996.6, -329.55,                                         #5
                    #30

                    -95835.69, -73436.06, -100240.36, -78918.26, -71763.56, -83735.15, -34898.95, -98622.59, -66763.2,         #9
                    -184645.76, -85494.47, -94503.59, -143120.57, -49829.96, -99636.61, -108242.24, -101192.2, -60214.25,      #9
                    -208992.81, -49769.11, -93133.14, -160933.77, -197905.84, -194055.39, -101310.71, -185137.96, -204476.75,  #9
                    -149305.62, -171494.96, -441145.96                                                                         #3
                    #30
)
                  ,.Dim = c(30L, 3L)
                  ,.Dimnames = list(NULL, c("Var1","Var2" ,"Var3"))
                  ,.Tsp = c(2016, 2018.5, 12), class = c("mts", "ts", "matrix"))

I am sure it's glaring at me!

Thank you for any advice.

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl  Tue Jul  3 19:12:58 2018
From: wolfg@ng@viechtb@uer @ending from m@@@trichtuniver@ity@nl (Viechtbauer, Wolfgang (SP))
Date: Tue, 3 Jul 2018 17:12:58 +0000
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
 <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>
Message-ID: <cc6100fbab24489e9ba4a6b876c84188@UM-MAIL3213.unimaas.nl>

Thanks for all of the suggestions. I did some benchmarking:

library(microbenchmark)

x <- 1:5
vec <- c(2,4,3)

fastWolfgang <- function(v, vec)
   matrix(c(v, rep(vec, each = length(v))), nrow = length(v))

microbenchmark(cbind(x, t(replicate(length(x), vec))),
               t(sapply(x, function(x) c(x, vec))),
               do.call(rbind, lapply(x, function(x) c(x, vec))),
               t(mapply(c, x, MoreArgs=list(vec))),
               Reduce(cbind, vec, x),
               Reduce(cbind2, vec, x),
               fastWolfgang(x, vec), times=10000L)

Jeff's approach is fastest, but Gabor's Reduce(cbind, vec, x) is close (and I really like its simplicity); and very similar to the do.call() approach.

Interestingly, for larger vectors, such as:

x <- 1:50
vec <- sample(1:100, 200, replace=TRUE)

the do.call() approach is the fastest.

Best,
Wolfgang

>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Tuesday, 03 July, 2018 17:48
>To: r-help at r-project.org; Viechtbauer, Wolfgang (SP); r-help at r-
>project.org
>Subject: Re: [R] Combine by columns a vector with another vector that is
>constant across rows
>
>Sorry trying again...
>
>fastWolfgang <- function( v, vec ) {
>  matrix( c( v, rep( vec, each = length( v ) ) )
>         , nrow = length( v ) )
>}
>
>On July 3, 2018 8:21:47 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>>Gabor's solution seems to optimize 'simpler'.
>>
>>More efficient is to learn that in R a vector is not a matrix, but a
>>matrix is just an ornamented vector.
>>
>>fastWolfgang <- function( v, vec ) {
>>  matrix( c( v, rep( vec, length( v ) ) )
>>         , now = length( v ) )
>>}
>>
>>On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)"
>><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>Hi All,
>>>
>>>I have one vector that I want to combine with another vector and that
>>>other vector should be the same for every row in the combined matrix.
>>>This obviously does not work:
>>>
>>>vec <- c(2,4,3)
>>>cbind(1:5, vec)
>>>
>>>This does, but requires me to specify the correct value for 'n' in
>>>replicate():
>>>
>>>cbind(1:5, t(replicate(5, vec)))
>>>
>>>Other ways that do not require this are:
>>>
>>>t(sapply(1:5, function(x) c(x, vec)))
>>>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>>>t(mapply(c, 1:5, MoreArgs=list(vec)))
>>>
>>>I wonder if there is a simpler / more efficient way of doing this.
>>>
>>>Best,
>>>Wolfgang

From roy@mendel@@ohn @ending from no@@@gov  Tue Jul  3 23:08:22 2018
From: roy@mendel@@ohn @ending from no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 3 Jul 2018 14:08:22 -0700
Subject: [R] ggplot2 version 3
Message-ID: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>

Hi All:

When I ask about updating packages in my R distribution,  it lists ggplot2 version 3.0.0 as being available.  I know that ggplot2 version 3.0.0 has made some significant changes that will break certain things.  I would like to install the new version, to see if it breaks anything that I do,  but I would also like to be able to revert back to the old version if it makes it impossible to do some of the work I need to get done,  and then switch back again to the new version to test some more.  Is there some elegant way of doing this?  If I just drag the appropriate Folder out of my directory and replace it with the one I want,  will that do it,  or are there too many other dependencies that are involved?

Thanks for any suggestions.

-Roy




**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From r@turner @ending from @uckl@nd@@c@nz  Tue Jul  3 23:09:35 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 4 Jul 2018 09:09:35 +1200
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
In-Reply-To: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
References: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
Message-ID: <832241d7-1248-4694-b6f0-2fe27167786e@auckland.ac.nz>


On 04/07/18 00:24, Martin M?ller Skarbiniks Pedersen wrote:

> Hi,
>    I am currently using R v3.4.4 and I just discovered this:
> 
>> prod(NA, NaN) ; prod(NaN, NA)
> [1] NA
> [1] NaN
> 
> ?prod says:
>      If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
>       cause a value of ?NA? to be returned, otherwise ?NA? values are
>       ignored.
> 
> So according to the manual-page for prod() NA should be returned in both
> cases?
> 
> 
> However for sum() is opposite is true:
>> sum(NA, NaN) ; sum(NaN, NA)
> [1] NA
> [1] NA
> 
> ?sum says:
>      If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
>       arguments will cause a value of ?NA? or ?NaN? to be returned,
>       otherwise ?NA? and ?NaN? values are ignored.
> 
> 
> Maybe the manual for prod() should say the same as sum() that
> both NA and NaN can be returned?

But:

 > sum(NA,NaN)
[1] NA
 > sum(NaN,NA)
[1] NA

so sum gives NA "both ways around".  Perhaps a slight inconsistency 
here?  I doubt that it's worth losing any sleep over, however.

Interestingly (???):

 > NaN*NA
[1] NaN
 > NA*NaN
[1] NA
 > NaN+NA
[1] NaN
 > NA+NaN
[1] NA

So we have an instance of non-commutative arithmetic operations.  And 
sum() is a wee bit inconsistent with "+".

Again I doubt that the implications are all that serious.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From wdunl@p @ending from tibco@com  Tue Jul  3 23:40:26 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Tue, 3 Jul 2018 14:40:26 -0700
Subject: [R] ggplot2 version 3
In-Reply-To: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>
References: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>
Message-ID: <CAF8bMcaLPx--BLE7Emm+PoCTfePUXLS52nX8xWLoRhWMx57nqQ@mail.gmail.com>

One way to test the new ggplot2 is to make a new directory to use as an R
library and to install the new ggplot2 there.
   newLibrary <- "C:/tmp/newRLibrary"
   dir.create(newLibrary)
   install.packages("ggplot2", lib=newLibrary)
Then you can run two R sessions at once, starting one with
   .libPaths("C:/tmp/newRLibrary")
to use the new ggplot2 and the othe without that line to use the old ggpot2.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jul 3, 2018 at 2:08 PM, Roy Mendelssohn - NOAA Federal via R-help <
r-help at r-project.org> wrote:

> Hi All:
>
> When I ask about updating packages in my R distribution,  it lists ggplot2
> version 3.0.0 as being available.  I know that ggplot2 version 3.0.0 has
> made some significant changes that will break certain things.  I would like
> to install the new version, to see if it breaks anything that I do,  but I
> would also like to be able to revert back to the old version if it makes it
> impossible to do some of the work I need to get done,  and then switch back
> again to the new version to test some more.  Is there some elegant way of
> doing this?  If I just drag the appropriate Folder out of my directory and
> replace it with the one I want,  will that do it,  or are there too many
> other dependencies that are involved?
>
> Thanks for any suggestions.
>
> -Roy
>
>
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From roy@mendel@@ohn @ending from no@@@gov  Tue Jul  3 23:41:54 2018
From: roy@mendel@@ohn @ending from no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 3 Jul 2018 14:41:54 -0700
Subject: [R] ggplot2 version 3
In-Reply-To: <CAF8bMcaLPx--BLE7Emm+PoCTfePUXLS52nX8xWLoRhWMx57nqQ@mail.gmail.com>
References: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>
 <CAF8bMcaLPx--BLE7Emm+PoCTfePUXLS52nX8xWLoRhWMx57nqQ@mail.gmail.com>
Message-ID: <D7A8121B-C97B-42D1-9CCE-9BBB95E4DFED@noaa.gov>

Thanks!

-Roy


> On Jul 3, 2018, at 2:40 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> One way to test the new ggplot2 is to make a new directory to use as an R library and to install the new ggplot2 there.
>    newLibrary <- "C:/tmp/newRLibrary"
>    dir.create(newLibrary)
>    install.packages("ggplot2", lib=newLibrary)
> Then you can run two R sessions at once, starting one with
>    .libPaths("C:/tmp/newRLibrary")
> to use the new ggplot2 and the othe without that line to use the old ggpot2.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Tue, Jul 3, 2018 at 2:08 PM, Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
> Hi All:
> 
> When I ask about updating packages in my R distribution,  it lists ggplot2 version 3.0.0 as being available.  I know that ggplot2 version 3.0.0 has made some significant changes that will break certain things.  I would like to install the new version, to see if it breaks anything that I do,  but I would also like to be able to revert back to the old version if it makes it impossible to do some of the work I need to get done,  and then switch back again to the new version to test some more.  Is there some elegant way of doing this?  If I just drag the appropriate Folder out of my directory and replace it with the one I want,  will that do it,  or are there too many other dependencies that are involved?
> 
> Thanks for any suggestions.
> 
> -Roy
> 
> 
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From b@r@rym @ending from gm@il@com  Wed Jul  4 03:34:59 2018
From: b@r@rym @ending from gm@il@com (Mehrshad Barary)
Date: Wed, 4 Jul 2018 11:34:59 +1000
Subject: [R] ASExtras library
Message-ID: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>

Hi Everyone,

Does anybody know how I can get ASExtras library?


Thanks
Mehrshad

-- 
Mehrshad Barary
Senior Lecturer in Crop Ecophysiology
Department of Agronomy and Plant Breeding
Faculty of Agriculture
Ilam University
Tel: (+98)8412227019-21
Fax: (+98)8412227015

	[[alternative HTML version deleted]]


From ccberry @ending from uc@d@edu  Wed Jul  4 03:59:57 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Wed, 4 Jul 2018 01:59:57 +0000
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <F950300B-D5BE-4A73-914B-699E74AC0152@ucsd.edu>



> On Jul 3, 2018, at 6:25 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> Now, to add to the controversy, how do you set a computer on fire?

>From the bash prompt:

stuxnet --overload=cpu,disk,network,gpu --fan=off --no-warnings <your_computer_id>

HTH,

Chuck

From ericjberger @ending from gm@il@com  Wed Jul  4 08:32:57 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 4 Jul 2018 09:32:57 +0300
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <cc6100fbab24489e9ba4a6b876c84188@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
 <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>
 <cc6100fbab24489e9ba4a6b876c84188@UM-MAIL3213.unimaas.nl>
Message-ID: <CAGgJW76TM+n=BN3oXr+urWpSA2ZkK3z+RjNiGZDn1wVPbEJM-w@mail.gmail.com>

For what it's worth, for larger vectors, and following on from your
observation that the do.call() approach is faster, the following provides
some modest additional speedup:

 cbind(x,t(do.call(cbind, lapply(x, function(y) vec))))

Rgds,
Eric


On Tue, Jul 3, 2018 at 8:12 PM, Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Thanks for all of the suggestions. I did some benchmarking:
>
> library(microbenchmark)
>
> x <- 1:5
> vec <- c(2,4,3)
>
> fastWolfgang <- function(v, vec)
>    matrix(c(v, rep(vec, each = length(v))), nrow = length(v))
>
> microbenchmark(cbind(x, t(replicate(length(x), vec))),
>                t(sapply(x, function(x) c(x, vec))),
>                do.call(rbind, lapply(x, function(x) c(x, vec))),
>                t(mapply(c, x, MoreArgs=list(vec))),
>                Reduce(cbind, vec, x),
>                Reduce(cbind2, vec, x),
>                fastWolfgang(x, vec), times=10000L)
>
> Jeff's approach is fastest, but Gabor's Reduce(cbind, vec, x) is close
> (and I really like its simplicity); and very similar to the do.call()
> approach.
>
> Interestingly, for larger vectors, such as:
>
> x <- 1:50
> vec <- sample(1:100, 200, replace=TRUE)
>
> the do.call() approach is the fastest.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> >Sent: Tuesday, 03 July, 2018 17:48
> >To: r-help at r-project.org; Viechtbauer, Wolfgang (SP); r-help at r-
> >project.org
> >Subject: Re: [R] Combine by columns a vector with another vector that is
> >constant across rows
> >
> >Sorry trying again...
> >
> >fastWolfgang <- function( v, vec ) {
> >  matrix( c( v, rep( vec, each = length( v ) ) )
> >         , nrow = length( v ) )
> >}
> >
> >On July 3, 2018 8:21:47 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >wrote:
> >>Gabor's solution seems to optimize 'simpler'.
> >>
> >>More efficient is to learn that in R a vector is not a matrix, but a
> >>matrix is just an ornamented vector.
> >>
> >>fastWolfgang <- function( v, vec ) {
> >>  matrix( c( v, rep( vec, length( v ) ) )
> >>         , now = length( v ) )
> >>}
> >>
> >>On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)"
> >><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>>Hi All,
> >>>
> >>>I have one vector that I want to combine with another vector and that
> >>>other vector should be the same for every row in the combined matrix.
> >>>This obviously does not work:
> >>>
> >>>vec <- c(2,4,3)
> >>>cbind(1:5, vec)
> >>>
> >>>This does, but requires me to specify the correct value for 'n' in
> >>>replicate():
> >>>
> >>>cbind(1:5, t(replicate(5, vec)))
> >>>
> >>>Other ways that do not require this are:
> >>>
> >>>t(sapply(1:5, function(x) c(x, vec)))
> >>>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
> >>>t(mapply(c, 1:5, MoreArgs=list(vec)))
> >>>
> >>>I wonder if there is a simpler / more efficient way of doing this.
> >>>
> >>>Best,
> >>>Wolfgang
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kch@mberln @ending from gm@il@com  Wed Jul  4 11:08:38 2018
From: kch@mberln @ending from gm@il@com (1/k^c)
Date: Wed, 4 Jul 2018 03:08:38 -0600
Subject: [R] gamlss() vs glm() standard errors via summary() vs vcov()
Message-ID: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>

Hi R-helpers,

I was working with some count data using gamlss() and glm(), and
noticed that the standard errors from the two functions correspond
when extracting from either the model summary for both functions, or
using vcov for both functions, but the standard errors between those
methods do not correspond. I have been lead to believe that in SAS and
Stata, the SEs do correspond between the different methods. Can anyone
assist me in understanding what's different between the two types of
SEs I seem to be encountering when using R with either glm or gamlss?
I feel like I'm missing something obvious. I have included a small
reproducible example below.

library(COUNT) # for myTable()
library(gamlss)
len<-50
seeder<-250
set.seed(seeder)  # reproducible example
dat<-rpois(c(1:len), lambda=2)
myTable(dat)
fac<-gl(n=2, k=1, length=len, labels = c("control","treat"))

# Fit gamlss() and glm() models
fit1<-gamlss(dat~fac, family="PO")
fit2<-glm(dat~fac, family="poisson")

# Extract SEs from model summaries
SESum1<-summary(fit1)[,"Std. Error"]
SESum2<-coef(summary(fit2))[,"Std. Error"]
cbind(SESum1, SESum2) # Corresponds

# Extract SEs via vcov()
SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
cbind(SEvcov1, SEvcov2) # Corresponds

# Compare between summary() and vcov() extraction. Missmatch.
cbind(SESum1, SEvcov1)


From pd@lgd @ending from gm@il@com  Wed Jul  4 12:11:50 2018
From: pd@lgd @ending from gm@il@com (Peter Dalgaard)
Date: Wed, 4 Jul 2018 12:11:50 +0200
Subject: [R] gamlss() vs glm() standard errors via summary() vs vcov()
In-Reply-To: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>
References: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>
Message-ID: <D85EC54E-E1C4-43B0-8015-4A4EBF7268F3@gmail.com>

> # Extract SEs via vcov()
> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))

What makes you think that you need to multiply with exp(coef(....)) here???

-pd

> On 4 Jul 2018, at 11:08 , 1/k^c <kchamberln at gmail.com> wrote:
> 
> Hi R-helpers,
> 
> I was working with some count data using gamlss() and glm(), and
> noticed that the standard errors from the two functions correspond
> when extracting from either the model summary for both functions, or
> using vcov for both functions, but the standard errors between those
> methods do not correspond. I have been lead to believe that in SAS and
> Stata, the SEs do correspond between the different methods. Can anyone
> assist me in understanding what's different between the two types of
> SEs I seem to be encountering when using R with either glm or gamlss?
> I feel like I'm missing something obvious. I have included a small
> reproducible example below.
> 
> library(COUNT) # for myTable()
> library(gamlss)
> len<-50
> seeder<-250
> set.seed(seeder)  # reproducible example
> dat<-rpois(c(1:len), lambda=2)
> myTable(dat)
> fac<-gl(n=2, k=1, length=len, labels = c("control","treat"))
> 
> # Fit gamlss() and glm() models
> fit1<-gamlss(dat~fac, family="PO")
> fit2<-glm(dat~fac, family="poisson")
> 
> # Extract SEs from model summaries
> SESum1<-summary(fit1)[,"Std. Error"]
> SESum2<-coef(summary(fit2))[,"Std. Error"]
> cbind(SESum1, SESum2) # Corresponds
> 
> # Extract SEs via vcov()
> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
> cbind(SEvcov1, SEvcov2) # Corresponds
> 
> # Compare between summary() and vcov() extraction. Missmatch.
> cbind(SESum1, SEvcov1)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From b@rowling@on @ending from l@nc@@ter@@c@uk  Wed Jul  4 13:06:17 2018
From: b@rowling@on @ending from l@nc@@ter@@c@uk (Barry Rowlingson)
Date: Wed, 4 Jul 2018 12:06:17 +0100
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
In-Reply-To: <75f449fc45274830bdab0d83124b8725@AM6PR04MB4264.eurprd04.prod.outlook.com>
References: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
 <75f449fc45274830bdab0d83124b8725@AM6PR04MB4264.eurprd04.prod.outlook.com>
Message-ID: <CANVKczP4YM9+KObGfrm0DLRBanL59hnQOj0Rn7=-xHvUh27-VA@mail.gmail.com>

I'm having deja-vu of a similar discussion on R-devel:

https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html

This was the funniest inconsistency I could find:

 > sum(c(NaN,NA))
 [1] NaN
 > sum(NaN,NA)
 [1] NA

THEY'RE IN THE SAME ORDER!!!

The doc in ?NaN has this clause:

     In R, basically all mathematical functions (including basic
     ?Arithmetic?), are supposed to work properly with ?+/- Inf? and
     ?NaN? as input or output.

which doesn't define "properly", but you'd think commutativity was a
"proper" property of addition. So although they "are supposed to" they
don't. Naughty mathematical functions!

And then there's...

     Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
     which of those two is not guaranteed and may depend on the R
     platform (since compilers may re-order computations).

Which is at least telling you there is vagueness in the system. But
hey, mathematics is not a precise science... oh wait...

Barry





On Tue, Jul 3, 2018 at 10:09 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 04/07/18 00:24, Martin M?ller Skarbiniks Pedersen wrote:
>
>> Hi,
>>    I am currently using R v3.4.4 and I just discovered this:
>>
>>> prod(NA, NaN) ; prod(NaN, NA)
>> [1] NA
>> [1] NaN
>>
>> ?prod says:
>>      If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
>>       cause a value of ?NA? to be returned, otherwise ?NA? values are
>>       ignored.
>>
>> So according to the manual-page for prod() NA should be returned in both
>> cases?
>>
>>
>> However for sum() is opposite is true:
>>> sum(NA, NaN) ; sum(NaN, NA)
>> [1] NA
>> [1] NA
>>
>> ?sum says:
>>      If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
>>       arguments will cause a value of ?NA? or ?NaN? to be returned,
>>       otherwise ?NA? and ?NaN? values are ignored.
>>
>>
>> Maybe the manual for prod() should say the same as sum() that
>> both NA and NaN can be returned?
>
> But:
>
>  > sum(NA,NaN)
> [1] NA
>  > sum(NaN,NA)
> [1] NA
>
> so sum gives NA "both ways around".  Perhaps a slight inconsistency
> here?  I doubt that it's worth losing any sleep over, however.
>
> Interestingly (???):
>
>  > NaN*NA
> [1] NaN
>  > NA*NaN
> [1] NA
>  > NaN+NA
> [1] NaN
>  > NA+NaN
> [1] NA
>
> So we have an instance of non-commutative arithmetic operations.  And
> sum() is a wee bit inconsistent with "+".
>
> Again I doubt that the implications are all that serious.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwin@emiu@ @ending from comc@@t@net  Wed Jul  4 17:52:58 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 4 Jul 2018 08:52:58 -0700
Subject: [R] ASExtras library
In-Reply-To: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>
References: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>
Message-ID: <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>


> On Jul 3, 2018, at 6:34 PM, Mehrshad Barary <bararym at gmail.com> wrote:
> 
> Hi Everyone,
> 
> Does anybody know how I can get ASExtras library?

It would be helpful if you would provide information about your reasons for assuming this package's existence. Cannot find it in CRAN (including a search for 'ASExtra'), BioConductor, GitHub, or the Archives, or even with Google for that matter.

https://cran.r-project.org/src/contrib/Archive/

And within R parlance 'library' not a synonym for 'package'. Libraries are where you store packages. And `library('pkg_name')` is a command for loading a package.


> Thanks
> Mehrshad
> 
> -- 
> Mehrshad Barary
> Senior Lecturer in Crop Ecophysiology
> Department of Agronomy and Plant Breeding
> Faculty of Agriculture
> Ilam University
> Tel: (+98)8412227019-21
> Fax: (+98)8412227015
> 
> 	[[alternative HTML version deleted]]

And R help is a plain-text mailing list. Please read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ted@h@rding @ending from wl@ndre@@net  Wed Jul  4 20:18:46 2018
From: ted@h@rding @ending from wl@ndre@@net (Ted Harding)
Date: Wed, 04 Jul 2018 19:18:46 +0100
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
In-Reply-To: <CANVKczP4YM9+KObGfrm0DLRBanL59hnQOj0Rn7=-xHvUh27-VA@mail.gmail.com>
References: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
 <75f449fc45274830bdab0d83124b8725@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczP4YM9+KObGfrm0DLRBanL59hnQOj0Rn7=-xHvUh27-VA@mail.gmail.com>
Message-ID: <1530728326.3880.32.camel@deb2.fort.knox.uk>

I've been following this thread, and wondering where it might lead.
My (possibly naive) view of these matters is basically logical,
relying on (possibly over-simplified) interpretaions of "NA" and "NaN".

These are that:
  "NaN" means "Not a Number", though it can result from a
numerical calculation, e.g. '0/0' or 'Inf/Inf', while:
  "NA" means "Not Available" (e.g. "Missing Value"), but
   should be interpreted as in rhe appropriate class of its
   context -- so '2 + NA' interporets "NA" as numeric,
   while 'vec("abc",NA)' interprets "NA" as character.

On that basis, the result of 'sum(NaN, <anything>)' should be
"NaN", since 'sum' presumes that its arguments are numeric,
and the sum of <bumbers, not-a-number> is not a number.
Likewise 'sum(<anything>, NaN)' should be NaN.

And in both of 'sum(NA, NaN) and sum(NaN, NA), the "NA" should
be interepreted as a "not-available number", and because
of the "NaN" the result cannot be a number, hence is "NaN".

So it sould seem that Martin M?ller Skarbiniks Pedersen's
inconsistency:
  sum(c(NaN,NA))
  [1] NaN
  sum(NaN,NA)
  [1] NA
is not consistent with the above reasoning.

However, in my R version 2.14.0 (2011-10-31):
  sum(NaN,NA)
  [1] NA
  sum(NA,NaN)
  [1] NA
which **is** consistent! Hmmm...
Best wishes to all,
Ted.

On Wed, 2018-07-04 at 12:06 +0100, Barry Rowlingson wrote: 
> I'm having deja-vu of a similar discussion on R-devel:
> 
> https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html
> 
> This was the funniest inconsistency I could find:
> 
>  > sum(c(NaN,NA))
>  [1] NaN
>  > sum(NaN,NA)
>  [1] NA
> 
> THEY'RE IN THE SAME ORDER!!!
> 
> The doc in ?NaN has this clause:
> 
>      In R, basically all mathematical functions (including basic
>      ?Arithmetic?), are supposed to work properly with ?+/- Inf? and
>      ?NaN? as input or output.
> 
> which doesn't define "properly", but you'd think commutativity was a
> "proper" property of addition. So although they "are supposed to" they
> don't. Naughty mathematical functions!
> 
> And then there's...
> 
>      Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
>      which of those two is not guaranteed and may depend on the R
>      platform (since compilers may re-order computations).
> 
> Which is at least telling you there is vagueness in the system. But
> hey, mathematics is not a precise science... oh wait...
> 
> Barry
> 
> 
> 
> 
> 
> On Tue, Jul 3, 2018 at 10:09 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> > On 04/07/18 00:24, Martin M?ller Skarbiniks Pedersen wrote:
> >
> >> Hi,
> >>    I am currently using R v3.4.4 and I just discovered this:
> >>
> >>> prod(NA, NaN) ; prod(NaN, NA)
> >> [1] NA
> >> [1] NaN
> >>
> >> ?prod says:
> >>      If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
> >>       cause a value of ?NA? to be returned, otherwise ?NA? values are
> >>       ignored.
> >>
> >> So according to the manual-page for prod() NA should be returned in both
> >> cases?
> >>
> >>
> >> However for sum() is opposite is true:
> >>> sum(NA, NaN) ; sum(NaN, NA)
> >> [1] NA
> >> [1] NA
> >>
> >> ?sum says:
> >>      If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
> >>       arguments will cause a value of ?NA? or ?NaN? to be returned,
> >>       otherwise ?NA? and ?NaN? values are ignored.
> >>
> >>
> >> Maybe the manual for prod() should say the same as sum() that
> >> both NA and NaN can be returned?
> >
> > But:
> >
> >  > sum(NA,NaN)
> > [1] NA
> >  > sum(NaN,NA)
> > [1] NA
> >
> > so sum gives NA "both ways around".  Perhaps a slight inconsistency
> > here?  I doubt that it's worth losing any sleep over, however.
> >
> > Interestingly (???):
> >
> >  > NaN*NA
> > [1] NaN
> >  > NA*NaN
> > [1] NA
> >  > NaN+NA
> > [1] NaN
> >  > NA+NaN
> > [1] NA
> >
> > So we have an instance of non-commutative arithmetic operations.  And
> > sum() is a wee bit inconsistent with "+".
> >
> > Again I doubt that the implications are all that serious.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ad@m@Z@J@bir @ending from outlook@fr  Wed Jul  4 19:16:27 2018
From: Ad@m@Z@J@bir @ending from outlook@fr (Adam Z. Jabir)
Date: Wed, 4 Jul 2018 17:16:27 +0000
Subject: [R] R is creating a new level which is emty after importing a SAS
 file
Message-ID: <CY4PR05MB31573C71D954314DD86AA2F2A8410@CY4PR05MB3157.namprd05.prod.outlook.com>

Hi,

I have imported some sasdata into R using the sas7bdat package. I have some nominal variables with some missing values.

R is creating a new level which is emty ??.When I ask for tabulate this new level is presented with 0 as a frequency.

I want to get rid of this level and have my file imported correctly.

Do you have some hint to help solve this problem?


Please use this email adress to answer this query.


 Best,

Adam


Envoy? ? partir de Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Wed Jul  4 23:09:15 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Wed, 4 Jul 2018 23:09:15 +0200
Subject: [R] 
 R is creating a new level which is emty after importing a SAS file
In-Reply-To: <CY4PR05MB31573C71D954314DD86AA2F2A8410@CY4PR05MB3157.namprd05.prod.outlook.com>
References: <CY4PR05MB31573C71D954314DD86AA2F2A8410@CY4PR05MB3157.namprd05.prod.outlook.com>
Message-ID: <58657783-39C2-454E-8CFD-EEA771BE1688@gmail.com>

It is not obvious that this is an error. If your nominal variable in SAS has a level which is not present in data, then R might just be making a faithful translation. There is a distinction between (a) having a gender variable with two levels of which 0 females and (b) pretending that male is the only possible gender.

Anyways, droplevels() is your friend. (Notice that it easier to remove levels that you do not want than to insert levels that have been unwantedly deleted on input.) 

-pd

> On 4 Jul 2018, at 19:16 , Adam Z. Jabir <Adam.Z.Jabir at outlook.fr> wrote:
> 
> Hi,
> 
> I have imported some sasdata into R using the sas7bdat package. I have some nominal variables with some missing values.
> 
> R is creating a new level which is emty ?.When I ask for tabulate this new level is presented with 0 as a frequency.
> 
> I want to get rid of this level and have my file imported correctly.
> 
> Do you have some hint to help solve this problem?
> 
> 
> Please use this email adress to answer this query.
> 
> 
> Best,
> 
> Adam
> 
> 
> Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kch@mberln @ending from gm@il@com  Wed Jul  4 23:33:20 2018
From: kch@mberln @ending from gm@il@com (1/k^c)
Date: Wed, 4 Jul 2018 15:33:20 -0600
Subject: [R] gamlss() vs glm() standard errors via summary() vs vcov()
In-Reply-To: <D85EC54E-E1C4-43B0-8015-4A4EBF7268F3@gmail.com>
References: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>
 <D85EC54E-E1C4-43B0-8015-4A4EBF7268F3@gmail.com>
Message-ID: <CAJjKGBRds8bhJ9kpgXBqBaE6-CFpuew1=6rW5atVZ+NRqeexaQ@mail.gmail.com>

Thank you, Peter!

Sincerely,
KeithC.

On Wed, Jul 4, 2018 at 4:11 AM, Peter Dalgaard <pdalgd at gmail.com> wrote:
>> # Extract SEs via vcov()
>> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
>> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
>
> What makes you think that you need to multiply with exp(coef(....)) here???
>
> -pd
>
>> On 4 Jul 2018, at 11:08 , 1/k^c <kchamberln at gmail.com> wrote:
>>
>> Hi R-helpers,
>>
>> I was working with some count data using gamlss() and glm(), and
>> noticed that the standard errors from the two functions correspond
>> when extracting from either the model summary for both functions, or
>> using vcov for both functions, but the standard errors between those
>> methods do not correspond. I have been lead to believe that in SAS and
>> Stata, the SEs do correspond between the different methods. Can anyone
>> assist me in understanding what's different between the two types of
>> SEs I seem to be encountering when using R with either glm or gamlss?
>> I feel like I'm missing something obvious. I have included a small
>> reproducible example below.
>>
>> library(COUNT) # for myTable()
>> library(gamlss)
>> len<-50
>> seeder<-250
>> set.seed(seeder)  # reproducible example
>> dat<-rpois(c(1:len), lambda=2)
>> myTable(dat)
>> fac<-gl(n=2, k=1, length=len, labels = c("control","treat"))
>>
>> # Fit gamlss() and glm() models
>> fit1<-gamlss(dat~fac, family="PO")
>> fit2<-glm(dat~fac, family="poisson")
>>
>> # Extract SEs from model summaries
>> SESum1<-summary(fit1)[,"Std. Error"]
>> SESum2<-coef(summary(fit2))[,"Std. Error"]
>> cbind(SESum1, SESum2) # Corresponds
>>
>> # Extract SEs via vcov()
>> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
>> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
>> cbind(SEvcov1, SEvcov2) # Corresponds
>>
>> # Compare between summary() and vcov() extraction. Missmatch.
>> cbind(SESum1, SEvcov1)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


From nell@redu @ending from hotm@il@fr  Thu Jul  5 00:21:34 2018
From: nell@redu @ending from hotm@il@fr (Nelly Reduan)
Date: Wed, 4 Jul 2018 22:21:34 +0000
Subject: [R] Generate N random numbers with a given probability and condition
Message-ID: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>

Dear all,

I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:

x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))

But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
Many thanks for your time
Nell


	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jul  5 00:56:59 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 04 Jul 2018 15:56:59 -0700
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <E1C9FF51-474D-479E-BEE7-F32A5F19A436@dcn.davis.ca.us>

This looks like homework (which is off topic here per the Posting Guide). Also, please send your emails in plain text format to avoid us seeing your message differently than you do.

On July 4, 2018 3:21:34 PM PDT, Nelly Reduan <nell.redu at hotmail.fr> wrote:
>Dear all,
>
>I would like to generate N random numbers with a given probability and
>condition but I'm not sure how to do this.
>For example, I have N = 20 and the vector from which to choose is
>seq(0, 10, 1). I have tested:
>
>x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28,
>times=length(seq(0, 10, 1))))
>
>But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>Many thanks for your time
>Nell
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @ending from @uckl@nd@@c@nz  Thu Jul  5 01:11:11 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Thu, 5 Jul 2018 11:11:11 +1200
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>


On 05/07/18 10:21, Nelly Reduan wrote:

> Dear all,
> 
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
> 
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
> 
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time.

Your thinking requires considerable clarification.

(1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.

(2) Hence length(seq(0,10,1)) is 11.

(3) Likewise max(seq(0,10,1)) is 10.

(4) Your prob vector is *constant* --- so specifying "prob" makes
     no difference --- the result is the same as if you omitted "prob".

(5) You need to think carefully about what you really mean by "random".
     In what way do you want the final result to be "random"?

I expect that the lecturer who assigned this problem to you  needs to 
clarify his/her thinking as well.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@dmuzom @ending from outlook@com  Wed Jul  4 23:34:23 2018
From: r@dmuzom @ending from outlook@com (radmuzom .)
Date: Wed, 4 Jul 2018 21:34:23 +0000
Subject: [R] ASExtras library
In-Reply-To: <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>
References: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>,
 <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>
Message-ID: <MAXPR0101MB17851D0974DC6B6A28A868C4CB410@MAXPR0101MB1785.INDPRD01.PROD.OUTLOOK.COM>

The package appears to be referenced in the package "agridat" - ftp://cran.r-project.org/pub/R/web/packages/agridat/agridat.pdf (Pg 55). However, even I tried searching for it and there seems to be no reference other than this source.

Regards,
radmuzom

From: R-help <r-help-bounces at r-project.org> on behalf of David Winsemius <dwinsemius at comcast.net>
Sent: Wednesday, July 4, 2018 9:22 PM
To: Mehrshad Barary
Cc: r-help at r-project.org
Subject: Re: [R] ASExtras library
? 


> On Jul 3, 2018, at 6:34 PM, Mehrshad Barary <bararym at gmail.com> wrote:
> 
> Hi Everyone,
> 
> Does anybody know how I can get ASExtras library?

It would be helpful if you would provide information about your reasons for assuming this package's existence. Cannot find it in CRAN (including a search for 'ASExtra'), BioConductor, GitHub, or the Archives, or even with Google for that matter.

https://cran.r-project.org/src/contrib/Archive/

And within R parlance 'library' not a synonym for 'package'. Libraries are where you store packages. And `library('pkg_name')` is a command for loading a package.


> Thanks
> Mehrshad
> 
> -- 
> Mehrshad Barary
> Senior Lecturer in Crop Ecophysiology
> Department of Agronomy and Plant Breeding
> Faculty of Agriculture
> Ilam University
> Tel: (+98)8412227019-21
> Fax: (+98)8412227015
> 
>??????? [[alternative HTML version deleted]]

And R help is a plain-text mailing list. Please read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'?? -Gehm's Corollary to Clarke's Third Law

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    

From m_rez@ii73 @ending from y@hoo@com  Thu Jul  5 10:39:40 2018
From: m_rez@ii73 @ending from y@hoo@com (Maryam R)
Date: Thu, 5 Jul 2018 08:39:40 +0000 (UTC)
Subject: [R] "igraph0" package installation
References: <963992099.5316610.1530779980726.ref@mail.yahoo.com>
Message-ID: <963992099.5316610.1530779980726@mail.yahoo.com>

Hi, i want to install 'igraph0' package in R on windows 10. I downloaded "igraph0_0.5.5-1.tar" from?Index of /src/contrib/Archive/igraph0?then i try to import this package to R with this command:install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL, dependencies=TRUE)

| 
| 
|  | 
Index of /src/contrib/Archive/igraph0


 |

 |

 |


?but I face with below error. Please help me:

ERROR: compilation failed for package 'igraph0'* removing 'C:/Users/Maryam/Documents/R/win-library/3.4/igraph0'In R CMD INSTALLWarning in install.packages :? running command '"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" CMD INSTALL -l "C:\Users\Maryam\Documents\R\win-library\3.4" "C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz"' had status 1Warning in install.packages :? installation of package ?C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz? had non-zero exit status


	[[alternative HTML version deleted]]


From lori@@bennett @ending from fu-berlin@de  Thu Jul  5 14:13:08 2018
From: lori@@bennett @ending from fu-berlin@de (Loris Bennett)
Date: Thu, 05 Jul 2018 14:13:08 +0200
Subject: [R] "igraph0" package installation
In-Reply-To: <963992099.5316610.1530779980726@mail.yahoo.com> (Maryam R. via's
 message of "Thu, 5 Jul 2018 08:39:40 +0000")
References: <963992099.5316610.1530779980726.ref@mail.yahoo.com>
 <963992099.5316610.1530779980726@mail.yahoo.com>
Message-ID: <877em9zxrf.fsf@hornfels.zedat.fu-berlin.de>

Hi Maryam,

Maryam R via R-help <r-help at r-project.org> writes:

> Hi, i want to install 'igraph0' package in R on windows 10. I downloaded
> "igraph0_0.5.5-1.tar" from?Index of /src/contrib/Archive/igraph0?then i try to
> import this package to R with this
> command:install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL,
> dependencies=TRUE)

[snip (32 lines)]

You probably shouldn't be trying install 'igraph0' at all, since

  https://cran.r-project.org/web/packages/igraph0/index.html

says

  Package ?igraph0? was removed from the CRAN repository.

  Formerly available versions can be obtained from the archive.

  This was a transitional package from Mar 2012 to Sept 2013. Packages depending on it ought to have changed to igraph long ago.

  Consider using package ?igraph? instead. 

As is suggested, you should install 'igraph'.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From m_rez@ii73 @ending from y@hoo@com  Thu Jul  5 20:01:27 2018
From: m_rez@ii73 @ending from y@hoo@com (Maryam R)
Date: Thu, 5 Jul 2018 22:31:27 +0430
Subject: [R] "igraph0" package installation
References: <963992099.5316610.1530779980726@mail.yahoo.com>
Message-ID: <B9E81FDC-DC84-4759-B964-A7DD11504476@yahoo.com>

Hi, I?m maryam that ask question about  "igraph0" package installation in R-help. I thank you for your answering.  i used and install ?igraph? library in R but i faced with below error when I use this command :
results <- gspan(database)

Error: 
Error in library(igraph0) : there is no package called ?igraph0?

Sent from my iPad

Begin forwarded message:

> Hi, i want to install 'igraph0' package in R on windows 10. I downloaded "igraph0_0.5.5-1.tar" from Index of /src/contrib/Archive/igraph0 then i try to import this package to R with this command:
> install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL, dependencies=TRUE)
> 
> Index of /src/contrib/Archive/igraph0
> 
>  but I face with below error. Please help me:
> 
> ERROR: compilation failed for package 'igraph0'
> * removing 'C:/Users/Maryam/Documents/R/win-library/3.4/igraph0'
> In R CMD INSTALL
> Warning in install.packages :
>   running command '"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" CMD INSTALL -l "C:\Users\Maryam\Documents\R\win-library\3.4" "C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz"' had status 1
> Warning in install.packages :
>   installation of package ?C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz? had non-zero exit status
> 
> 

	[[alternative HTML version deleted]]


From Ad@m@Z@J@bir @ending from outlook@fr  Thu Jul  5 22:28:41 2018
From: Ad@m@Z@J@bir @ending from outlook@fr (Adam Z. Jabir)
Date: Thu, 5 Jul 2018 20:28:41 +0000
Subject: [R] command to change some vars to missing into my dataset
Message-ID: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>

Hi,

I want to simulate missing at random for my dataset. Do you know an easy way to do it?

I want to try not to have the missing?s for the same observations. I mean if one observation is been selected randomly to have missing I don?t want to have all the var of the same obs missing.

I want to be able to choose rate of missing that should be applied.

Thanks,

Adam


Envoy? ? partir de Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Thu Jul  5 22:49:40 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Thu, 5 Jul 2018 16:49:40 -0400
Subject: [R] "igraph0" package installation
In-Reply-To: <B9E81FDC-DC84-4759-B964-A7DD11504476@yahoo.com>
References: <963992099.5316610.1530779980726@mail.yahoo.com>
 <B9E81FDC-DC84-4759-B964-A7DD11504476@yahoo.com>
Message-ID: <CAM_vjukN0oe547L53pO5XdcHBVNdM5vfR7G2TzBebeuqzrW+Tw@mail.gmail.com>

Hi,

According to https://cran.r-project.org/web/packages/igraph0/index.html
igraph0 is obsolete.

I don't know what package the gspan() function comes from, but most
likely you should update that package to the current version.

Or, if it's this issue:
https://stackoverflow.com/questions/33268708/package-igraph0-deprecated-and-hence-not-able-to-access-gspan-package

about the subgraphMining package, you may be out of luck unless you
can install development tools on your computer and build igraph0 from
source. There should be more detail about the error message than what
you've posted.

https://stackoverflow.com/questions/48255675/subgraphmining-package-not-available

Or, ideally, convince the book author to upgrade the package to use igraph.

Sarah

On Thu, Jul 5, 2018 at 2:01 PM, Maryam R via R-help
<r-help at r-project.org> wrote:
> Hi, I?m maryam that ask question about  "igraph0" package installation in R-help. I thank you for your answering.  i used and install ?igraph? library in R but i faced with below error when I use this command :
> results <- gspan(database)
>
> Error:
> Error in library(igraph0) : there is no package called ?igraph0?
>
> Sent from my iPad
>
> Begin forwarded message:
>
>> Hi, i want to install 'igraph0' package in R on windows 10. I downloaded "igraph0_0.5.5-1.tar" from Index of /src/contrib/Archive/igraph0 then i try to import this package to R with this command:
>> install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL, dependencies=TRUE)
>>
>> Index of /src/contrib/Archive/igraph0
>>
>>  but I face with below error. Please help me:
>>
>> ERROR: compilation failed for package 'igraph0'
>> * removing 'C:/Users/Maryam/Documents/R/win-library/3.4/igraph0'
>> In R CMD INSTALL
>> Warning in install.packages :
>>   running command '"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" CMD INSTALL -l "C:\Users\Maryam\Documents\R\win-library\3.4" "C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz"' had status 1
>> Warning in install.packages :
>>   installation of package ?C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz? had non-zero exit status
>>
>>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ruipb@rr@d@@ @ending from @@po@pt  Thu Jul  5 23:24:54 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Thu, 5 Jul 2018 22:24:54 +0100
Subject: [R] command to change some vars to missing into my dataset
In-Reply-To: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
References: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
Message-ID: <8beea55e-0e52-4620-6439-f295f009660b@sapo.pt>

Hello,

What type of data do you have? A vector? Or is it a matrix, a 
data.frame, a list, etc?

Suppose it is a vector named x. Then you could do something like

rate <- 0.2
is.na(x) <- sample(length(x), rate*length(x))

At an R prompt type

?is.na
?sample

Hope this helps,

Rui Barradas

?s 21:28 de 05-07-2018, Adam Z. Jabir escreveu:
> Hi,
> 
> I want to simulate missing at random for my dataset. Do you know an easy way to do it?
> 
> I want to try not to have the missing?s for the same observations. I mean if one observation is been selected randomly to have missing I don?t want to have all the var of the same obs missing.
> 
> I want to be able to choose rate of missing that should be applied.
> 
> Thanks,
> 
> Adam
> 
> 
> Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon @ending from gm@il@com  Fri Jul  6 00:44:25 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 6 Jul 2018 08:44:25 +1000
Subject: [R] command to change some vars to missing into my dataset
In-Reply-To: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
References: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
Message-ID: <CA+8X3fViS1wTdpn4eCdapU_PYnw4CQ=qZ6KBn-280p=pSurSdA@mail.gmail.com>

Hi Adam,
Looks like you have a matrix or data frame and want to change one or
more observations to NA. I think this will do the trick:

# assume the matrix or data frame is named "ajdat"
randomNA<-function(x,nNA=1) {
 dimx<-dim(x)
 x[sample(1:dimx[1],nNA),sample(1:dimx[2],nNA)]<-NA
 return(x)
}

So if you want three NAs inserted, call:

randomNA(ajdat,3)

Jim


On Fri, Jul 6, 2018 at 6:28 AM, Adam Z. Jabir <Adam.Z.Jabir at outlook.fr> wrote:
> Hi,
>
> I want to simulate missing at random for my dataset. Do you know an easy way to do it?
>
> I want to try not to have the missing?s for the same observations. I mean if one observation is been selected randomly to have missing I don?t want to have all the var of the same obs missing.
>
> I want to be able to choose rate of missing that should be applied.
>
> Thanks,
>
> Adam
>
>
> Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @ending from gm@il@com  Fri Jul  6 01:55:35 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 5 Jul 2018 16:55:35 -0700
Subject: [R] command to change some vars to missing into my dataset
In-Reply-To: <CA+8X3fViS1wTdpn4eCdapU_PYnw4CQ=qZ6KBn-280p=pSurSdA@mail.gmail.com>
References: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
 <CA+8X3fViS1wTdpn4eCdapU_PYnw4CQ=qZ6KBn-280p=pSurSdA@mail.gmail.com>
Message-ID: <CAGxFJbTByxesiSiGJa8yQshSt=D_X5D9=BwLje8JmmDQRpSG-A@mail.gmail.com>

Jim/Rui:

Strictly speaking, this is wrong. What you have described is MCAR --
missing completely at random -- not MAR. They are different! Nevertheless,
the OP seems to be similarly confused about this, so MCAR may in fact be
what what  was wanted. Without further context, it is as clear as mud to me.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 5, 2018 at 3:44 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Adam,
> Looks like you have a matrix or data frame and want to change one or
> more observations to NA. I think this will do the trick:
>
> # assume the matrix or data frame is named "ajdat"
> randomNA<-function(x,nNA=1) {
>  dimx<-dim(x)
>  x[sample(1:dimx[1],nNA),sample(1:dimx[2],nNA)]<-NA
>  return(x)
> }
>
> So if you want three NAs inserted, call:
>
> randomNA(ajdat,3)
>
> Jim
>
>
> On Fri, Jul 6, 2018 at 6:28 AM, Adam Z. Jabir <Adam.Z.Jabir at outlook.fr>
> wrote:
> > Hi,
> >
> > I want to simulate missing at random for my dataset. Do you know an easy
> way to do it?
> >
> > I want to try not to have the missing?s for the same observations. I
> mean if one observation is been selected randomly to have missing I don?t
> want to have all the var of the same obs missing.
> >
> > I want to be able to choose rate of missing that should be applied.
> >
> > Thanks,
> >
> > Adam
> >
> >
> > Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
> >
> >         [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@vidm@rino838 @ending from gm@il@com  Fri Jul  6 07:23:55 2018
From: d@vidm@rino838 @ending from gm@il@com (Marino David)
Date: Fri, 6 Jul 2018 13:23:55 +0800
Subject: [R] Generate random Bernoulli draws
Message-ID: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>

Dear All,

I would like to generate N random Bernoulli draws given a probability
function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
x~U(0,2).

Can some one leave me some code lines for implementing this?

Thanks in advance.

David

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Jul  6 07:32:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 5 Jul 2018 22:32:09 -0700
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
Message-ID: <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>

Is this homework?

(There is an informal no-homework policy on this list).

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
wrote:

> Dear All,
>
> I would like to generate N random Bernoulli draws given a probability
> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
> x~U(0,2).
>
> Can some one leave me some code lines for implementing this?
>
> Thanks in advance.
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@vidm@rino838 @ending from gm@il@com  Fri Jul  6 07:35:20 2018
From: d@vidm@rino838 @ending from gm@il@com (Marino David)
Date: Fri, 6 Jul 2018 13:35:20 +0800
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
Message-ID: <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>

Dear Bert,

I know it is a simple question. But for me, at current, I fail to implement
it. So, I ask for help here.

It is not homework.

Best,

David

2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Is this homework?
>
> (There is an informal no-homework policy on this list).
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I would like to generate N random Bernoulli draws given a probability
>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>> x~U(0,2).
>>
>> Can some one leave me some code lines for implementing this?
>>
>> Thanks in advance.
>>
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From Ad@m@Z@J@bir @ending from outlook@fr  Fri Jul  6 05:56:19 2018
From: Ad@m@Z@J@bir @ending from outlook@fr (Adam Z. Jabir)
Date: Fri, 6 Jul 2018 03:56:19 +0000
Subject: [R] code to run a simulation
Message-ID: <CY4PR05MB31576EE09B818F3ABBA8EEB6A8470@CY4PR05MB3157.namprd05.prod.outlook.com>

Hi Guys,

I am doing some imputation for my dataset. I am looking for code to do simulation before choosing the right package (mice, Knn).  Does anyone have  some code that can do the following:

  1.  introduce some missing rate into the data
  2.  Apply the two imputaion methods
  3.  Compute RMSE and missclafication rate for the categorical variables
  4.  Repeate this 100,200 time and save the RMSE and misclassification rate.

I really appreciate your help,

Best,

Adam


Envoy? ? partir de Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Fri Jul  6 11:37:37 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Fri, 6 Jul 2018 09:37:37 +0000
Subject: [R] progress of a function...
Message-ID: <SLXP216MB00939F7050BFEFC2CDFEDED7C8470@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I want to use svMisc package in R to check how my function is progressing.
It has the following syntax:

f <- function(x){ for (i in 1:1000){
                              progress (i)
                              s[i] <- sqrt(i)
                             }
                             return(i)
                           }

This gives me the progress of the function as i moves.

But what if I have mclapply function instead of the for loop? How do we get the progress of an ongoing "apply" family of functions?

Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From m@rc_grt @ending from y@hoo@fr  Fri Jul  6 13:20:37 2018
From: m@rc_grt @ending from y@hoo@fr (Marc Girondot)
Date: Fri, 6 Jul 2018 13:20:37 +0200
Subject: [R] progress of a function...
In-Reply-To: <SLXP216MB00939F7050BFEFC2CDFEDED7C8470@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>
References: <SLXP216MB00939F7050BFEFC2CDFEDED7C8470@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>
Message-ID: <aba34713-ee91-229a-62ed-e8f064110478@yahoo.fr>

Take a look at the pbmcapply package. It does what you need.

Marc

Le 06/07/2018 ? 11:37, akshay kulkarni a ?crit?:
> dear members,
>                              I want to use svMisc package in R to check how my function is progressing.
> It has the following syntax:
>
> f <- function(x){ for (i in 1:1000){
>                                progress (i)
>                                s[i] <- sqrt(i)
>                               }
>                               return(i)
>                             }
>
> This gives me the progress of the function as i moves.
>
> But what if I have mclapply function instead of the for loop? How do we get the progress of an ongoing "apply" family of functions?
>
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From btupper @ending from bigelow@org  Fri Jul  6 13:33:52 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Fri, 6 Jul 2018 07:33:52 -0400
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
Message-ID: <224061B5-63E8-438C-A1D8-30BCA76709A4@bigelow.org>

Hi,

I haven't any idea about what you ask, but I do know that Rseek.org <http://rseek.org/> is a gold mine!  Check out...

https://rseek.org/?q=Bernoulli+random+variable <https://rseek.org/?q=Bernoulli+random+variable>

Cheers,
Ben

> On Jul 6, 2018, at 1:35 AM, Marino David <davidmarino838 at gmail.com> wrote:
> 
> Dear Bert,
> 
> I know it is a simple question. But for me, at current, I fail to implement
> it. So, I ask for help here.
> 
> It is not homework.
> 
> Best,
> 
> David
> 
> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
> 
>> Is this homework?
>> 
>> (There is an informal no-homework policy on this list).
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>> wrote:
>> 
>>> Dear All,
>>> 
>>> I would like to generate N random Bernoulli draws given a probability
>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>> x~U(0,2).
>>> 
>>> Can some one leave me some code lines for implementing this?
>>> 
>>> Thanks in advance.
>>> 
>>> David
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From d@vidm@rino838 @ending from gm@il@com  Fri Jul  6 14:23:16 2018
From: d@vidm@rino838 @ending from gm@il@com (Marino David)
Date: Fri, 6 Jul 2018 20:23:16 +0800
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <224061B5-63E8-438C-A1D8-30BCA76709A4@bigelow.org>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <224061B5-63E8-438C-A1D8-30BCA76709A4@bigelow.org>
Message-ID: <CABmD0bGxUmgJC0QrFKvBWeO78F1gPnyD5jrjURv61SgFvWYhGA@mail.gmail.com>

Dear Ben,

Thanks a lot for your reply.

Best,

David

2018-07-06 19:33 GMT+08:00 Ben Tupper <btupper at bigelow.org>:

> Hi,
>
> I haven't any idea about what you ask, but I do know that Rseek.org is a
> gold mine!  Check out...
>
> https://rseek.org/?q=Bernoulli+random+variable
>
> Cheers,
> Ben
>
> On Jul 6, 2018, at 1:35 AM, Marino David <davidmarino838 at gmail.com> wrote:
>
> Dear Bert,
>
> I know it is a simple question. But for me, at current, I fail to implement
> it. So, I ask for help here.
>
> It is not homework.
>
> Best,
>
> David
>
> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>
> Is this homework?
>
> (There is an informal no-homework policy on this list).
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
> wrote:
>
> Dear All,
>
> I would like to generate N random Bernoulli draws given a probability
> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
> x~U(0,2).
>
> Can some one leave me some code lines for implementing this?
>
> Thanks in advance.
>
> David
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive
> <https://maps.google.com/?q=60+Bigelow+Drive&entry=gmail&source=g>, P.O.
> Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From jenny@liu00 @ending from gm@il@com  Fri Jul  6 16:29:18 2018
From: jenny@liu00 @ending from gm@il@com (Jenny Liu)
Date: Fri, 06 Jul 2018 14:29:18 +0000
Subject: [R] Do there need to be the same number of y-values for each
 x-value when using tapply?
Message-ID: <bcb629c9-1b21-3e63-e462-c9c588ca20dc@mixmax.com>

Hi everyone,
I'm trying to fit a set of data to a non-linear distribution?(namely, rates of
insect development at different temperatures), and I'm?trying to do this using
the selfStart and GetInitial functions. (I'd of course be open to alternative
suggestions!). However, I?keep running into this error:

Error in tapply(y, x, mean, na.rm = TRUE) :
arguments must have same length

I created a post on stackoverflow that includes the data and my code, and a
more in-depth explanation. I would be grateful if someone could have a look
and let me know where I'm going wrong!

https://stackoverflow.com/questions/51119314/using-tapply-when-you-have-different-n-for-each-treatment


Thanks very much,
Jenny
	[[alternative HTML version deleted]]


From ccberry @ending from uc@d@edu  Fri Jul  6 19:18:58 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Fri, 6 Jul 2018 17:18:58 +0000
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
Message-ID: <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>

A liitle math goes along way. See below.

> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
> 
> Dear Bert,
> 
> I know it is a simple question. But for me, at current, I fail to implement
> it. So, I ask for help here.
> 
> It is not homework.
> 
> Best,
> 
> David
> 
> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
> 
>> Is this homework?
>> 
>> (There is an informal no-homework policy on this list).
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>> wrote:
>> 
>>> Dear All,
>>> 
>>> I would like to generate N random Bernoulli draws given a probability
>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>> x~U(0,2).

If each Bernoulli draw is based on its own draw of x, then

	rbinom( N, 1, 0.8013476 )

is what you want.

It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps, 

	?integrate

will help.

But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of  the prob argument.

HTH,

Chuck


>>> 
>>> Can some one leave me some code lines for implementing this?
>>> 
>>> Thanks in advance.
>>> 
>>> David
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 


From gor@n@bro@trom @ending from umu@@e  Fri Jul  6 23:10:41 2018
From: gor@n@bro@trom @ending from umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Fri, 6 Jul 2018 23:10:41 +0200
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
Message-ID: <3686d88e-d581-ad1f-8269-28be04c569b2@umu.se>



On 2018-07-06 19:18, Berry, Charles wrote:
> A liitle math goes along way. See below.
> 
>> On Jul 5, 2018, at 10:35 PM, Marino David
>> <davidmarino838 at gmail.com> wrote:
>> 
>> Dear Bert,
>> 
>> I know it is a simple question. But for me, at current, I fail to
>> implement it. So, I ask for help here.
>> 
>> It is not homework.
>> 
>> Best,
>> 
>> David
>> 
>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>> 
>>> Is this homework?
>>> 
>>> (There is an informal no-homework policy on this list).
>>> 
>>> Cheers, Bert
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming
>>> along and sticking things into it." -- Opus (aka Berkeley
>>> Breathed in his "Bloom County" comic strip )
>>> 
>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David
>>> <davidmarino838 at gmail.com> wrote:
>>> 
>>>> Dear All,
>>>> 
>>>> I would like to generate N random Bernoulli draws given a
>>>> probability function F(x)=1-exp(-2.5*x) in which x follows
>>>> uniform distribution, say x~U(0,2).
> 
> If each Bernoulli draw is based on its own draw of x, then
> 
> rbinom( N, 1, 0.8013476 )
> 
> is what you want.

Maybe it is what he wants, but note that F(x) as defined is a random 
variable, not a (cumulative) probability function.

G,

> 
> It is left as an exercise for the reader to verify that the constant
> 0.8013476 is correct up to approximation error, and to prove that
> such a Bernoulli mixture is also Bernoulli. Perhaps,
> 
> ?integrate
> 
> will help.
> 
> But if the x's are shared you need to use runif, expm1, and
> (possibly) rep to produce a vector to be used in place of  the prob
> argument.
> 
> HTH,
> 
> Chuck
> 
> 
>>>> 
>>>> Can some one leave me some code lines for implementing this?
>>>> 
>>>> Thanks in advance.
>>>> 
>>>> David
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________ 
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>>> the posting guide http://www.R-project.org/posti ng-guide.html 
>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>> 
>>> 
>>> 
>> 
>> [[alternative HTML version deleted]]
>> 
> 
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @ending from gm@il@com  Sat Jul  7 00:31:39 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Fri, 6 Jul 2018 18:31:39 -0400
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
Message-ID: <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>

On 06/07/2018 1:18 PM, Berry, Charles wrote:
> A liitle math goes along way. See below.
> 
>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
>>
>> Dear Bert,
>>
>> I know it is a simple question. But for me, at current, I fail to implement
>> it. So, I ask for help here.
>>
>> It is not homework.
>>
>> Best,
>>
>> David
>>
>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>
>>> Is this homework?
>>>
>>> (There is an informal no-homework policy on this list).
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>>> wrote:
>>>
>>>> Dear All,
>>>>
>>>> I would like to generate N random Bernoulli draws given a probability
>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>>> x~U(0,2).
> 
> If each Bernoulli draw is based on its own draw of x, then
> 
> 	rbinom( N, 1, 0.8013476 )
> 
> is what you want.
> 
> It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps,
> 
> 	?integrate
> 
> will help.
> 
> But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of  the prob argument.

That may be correct from a mathematical perspective (I haven't checked), 
but seems like a *really* bad idea from a programming perspective.  It 
would be much better to write

x <- runif(N, 0, 2)
rbinom(N, 1, 1 - exp(-2.5*x))

because it is so much more clearly related to the original problem 
statement.  Perhaps it would be a few microseconds slower, but that 
would be saved many times over when any aspect of the problem statement 
was modified.

Duncan Murdoch

> 
> HTH,
> 
> Chuck
> 
> 
>>>>
>>>> Can some one leave me some code lines for implementing this?
>>>>
>>>> Thanks in advance.
>>>>
>>>> David
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ccberry @ending from uc@d@edu  Sat Jul  7 01:27:04 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Fri, 6 Jul 2018 23:27:04 +0000
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
 <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
Message-ID: <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>



> On Jul 6, 2018, at 3:31 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 06/07/2018 1:18 PM, Berry, Charles wrote:
>> A liitle math goes along way. See below.
>>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
>>> 
>>> Dear Bert,
>>> 
>>> I know it is a simple question. But for me, at current, I fail to implement
>>> it. So, I ask for help here.
>>> 
>>> It is not homework.
>>> 
>>> Best,
>>> 
>>> David
>>> 
>>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>> 
>>>> Is this homework?
>>>> 
>>>> (There is an informal no-homework policy on this list).
>>>> 
>>>> Cheers,
>>>> Bert
>>>> 
>>>> 
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along and
>>>> sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>>>> wrote:
>>>> 
>>>>> Dear All,
>>>>> 
>>>>> I would like to generate N random Bernoulli draws given a probability
>>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>>>> x~U(0,2).
>> If each Bernoulli draw is based on its own draw of x, then
>> 	rbinom( N, 1, 0.8013476 )
>> is what you want.
>> It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps,
>> 	?integrate
>> will help.
>> But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of the prob argument.
> 
> That may be correct from a mathematical perspective (I haven't checked), but seems like a *really* bad idea from a programming perspective.  It would be much better to write

Well of course it would.  I was hoping that my somewhat obscure one-liner would suggest


> 
> x <- runif(N, 0, 2)
> rbinom(N, 1, 1 - exp(-2.5*x))
> 
> because it is so much more clearly related to the original problem statement.  Perhaps it would be a few microseconds slower, but that would be saved many times over when any aspect of the problem statement was modified.
> 
> Duncan Murdoch
> 
>> HTH,
>> Chuck
>>>>> 
>>>>> Can some one leave me some code lines for implementing this?
>>>>> 
>>>>> Thanks in advance.
>>>>> 
>>>>> David
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ccberry @ending from uc@d@edu  Sat Jul  7 01:30:22 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Fri, 6 Jul 2018 23:30:22 +0000
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
 <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
 <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>
Message-ID: <85D59BB4-1413-4AA3-BED2-964843C3F848@ucsd.edu>

Sorry about the last incomplete post. Accidentally hit send.

Meant to say that I was hoping that a correct, but  obscure response from me would motivate David to step back and think about his problem long enough to see that it has an easy solution.

Sorry if that was out-of-line.

Chuck

> On Jul 6, 2018, at 4:27 PM, Charles Berry <ccberry at ucsd.edu> wrote:
> 
>> On Jul 6, 2018, at 3:31 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 06/07/2018 1:18 PM, Berry, Charles wrote:
>>> A liitle math goes along way. See below.
>>>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
>>>> 
>>>> Dear Bert,
>>>> 
>>>> I know it is a simple question. But for me, at current, I fail to implement
>>>> it. So, I ask for help here.
>>>> 
>>>> It is not homework.
>>>> 
>>>> Best,
>>>> 
>>>> David
>>>> 
>>>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>> 
>>>>> Is this homework?
>>>>> 
>>>>> (There is an informal no-homework policy on this list).
>>>>> 
>>>>> Cheers,
>>>>> Bert
>>>>> 
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along and
>>>>> sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>>> Dear All,
>>>>>> 
>>>>>> I would like to generate N random Bernoulli draws given a probability
>>>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>>>>> x~U(0,2).
>>> If each Bernoulli draw is based on its own draw of x, then
>>> 	rbinom( N, 1, 0.8013476 )
>>> is what you want.
>>> It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps,
>>> 	?integrate
>>> will help.
>>> But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of the prob argument.
> 


From t@n@@@ @ending from gm@il@com  Sat Jul  7 01:32:41 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Fri, 6 Jul 2018 16:32:41 -0700
Subject: [R] about ECDF display in ggplot2
Message-ID: <CA+JEM018t9qtbB4rCtiMh6vZ5MR0YNPnCN7TkpiOELGa1GtC8A@mail.gmail.com>

Dear all,

I would appreciate having your advice/suggestions/comments on the following
:

1 -- starting from a vector that contains LENGTHS (numerically, the values
are from 1 to 10 000)

2 -- shall I display the ECDF by using the R code and some "limits" :

BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
           1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)

ggplot(x, aes(LENGTH)) +
          stat_ecdf(geom = "point") +
          scale_x_continuous(name = "LENGTH of DEL",
                             breaks = BREAKS,
                             limits=c(0, 500))

3 -- I am getting the following warning message : "Warning message: Removed
109 rows containing non-finite values (stat_ecdf)."

The question is : are these 109 values removed from VISUALIZATION as i set
up the "limits", or are these 109 values removed from statistical
CALCULATION?

4 -- in contrast, shall I use the standard R functions plot(ecdf), there is
no "warning mesage"

plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
                     ylab="Fraction of DEL", main="DEL", xlim=c(0,500),
                     col = "dark red")

Thanks a lot !

-- bogdan

	[[alternative HTML version deleted]]


From d@vidm@rino838 @ending from gm@il@com  Sat Jul  7 04:26:20 2018
From: d@vidm@rino838 @ending from gm@il@com (Marino David)
Date: Sat, 7 Jul 2018 10:26:20 +0800
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <85D59BB4-1413-4AA3-BED2-964843C3F848@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
 <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
 <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>
 <85D59BB4-1413-4AA3-BED2-964843C3F848@ucsd.edu>
Message-ID: <CABmD0bGwmZVrgpChr8jsa=Z22cgt2BcUE10XB5iUGvSZqCz86Q@mail.gmail.com>

Hi Chuck and all,

Thanks for your response. It is really helpful for me.

David

2018-07-07 7:30 GMT+08:00 Berry, Charles <ccberry at ucsd.edu>:

> Sorry about the last incomplete post. Accidentally hit send.
>
> Meant to say that I was hoping that a correct, but  obscure response from
> me would motivate David to step back and think about his problem long
> enough to see that it has an easy solution.
>
> Sorry if that was out-of-line.
>
> Chuck
>
> > On Jul 6, 2018, at 4:27 PM, Charles Berry <ccberry at ucsd.edu> wrote:
> >
> >> On Jul 6, 2018, at 3:31 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> >>
> >> On 06/07/2018 1:18 PM, Berry, Charles wrote:
> >>> A liitle math goes along way. See below.
> >>>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com>
> wrote:
> >>>>
> >>>> Dear Bert,
> >>>>
> >>>> I know it is a simple question. But for me, at current, I fail to
> implement
> >>>> it. So, I ask for help here.
> >>>>
> >>>> It is not homework.
> >>>>
> >>>> Best,
> >>>>
> >>>> David
> >>>>
> >>>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
> >>>>
> >>>>> Is this homework?
> >>>>>
> >>>>> (There is an informal no-homework policy on this list).
> >>>>>
> >>>>> Cheers,
> >>>>> Bert
> >>>>>
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming
> along and
> >>>>> sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <
> davidmarino838 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> Dear All,
> >>>>>>
> >>>>>> I would like to generate N random Bernoulli draws given a
> probability
> >>>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform
> distribution, say
> >>>>>> x~U(0,2).
> >>> If each Bernoulli draw is based on its own draw of x, then
> >>>     rbinom( N, 1, 0.8013476 )
> >>> is what you want.
> >>> It is left as an exercise for the reader to verify that the constant
> 0.8013476 is correct up to approximation error, and to prove that such a
> Bernoulli mixture is also Bernoulli. Perhaps,
> >>>     ?integrate
> >>> will help.
> >>> But if the x's are shared you need to use runif, expm1, and (possibly)
> rep to produce a vector to be used in place of the prob argument.
> >
>
>
>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Sat Jul  7 11:42:29 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sat, 7 Jul 2018 09:42:29 +0000
Subject: [R] pbmclapply is very much faster than mclapply....
Message-ID: <SL2P216MB0091654E0BF030373FB387A3C8460@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am using pbmclapply function to check the progress of my functions that is to be run in parallel (with function mclapply).

To my amazement, I found out that pbmclapply is more than 3X faster than mclapply!!!

Any idea on why this is so?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From @xel@urbiz @ending from gm@il@com  Sat Jul  7 21:53:50 2018
From: @xel@urbiz @ending from gm@il@com (Axel Urbiz)
Date: Sat, 7 Jul 2018 15:53:50 -0400
Subject: [R] Spatial Clustering with spdep::skater
Message-ID: <A7ABCFB3-B84E-41AF-9562-ECCFD14C9AC6@gmail.com>

Dear Experts,

I?m working with spdep::skater to fit clusters to spatial data subject to contiguity constraints. This function fits clusters by edge removal from Minimum Spanning Trees. 

In this context, I?d appreciate any pointers on how to tune the number of clusters. What is a sensible criteria to use?

Thanks
Axel.

From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul  8 06:47:43 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Jul 2018 21:47:43 -0700
Subject: [R] about ECDF display in ggplot2
In-Reply-To: <CA+JEM018t9qtbB4rCtiMh6vZ5MR0YNPnCN7TkpiOELGa1GtC8A@mail.gmail.com>
References: <CA+JEM018t9qtbB4rCtiMh6vZ5MR0YNPnCN7TkpiOELGa1GtC8A@mail.gmail.com>
Message-ID: <DA6461D3-8686-40C5-8F43-CD195BE35501@dcn.davis.ca.us>

It is a feature of ggplot that points excluded by limits raise warnings, while base graphics do not.

You may find that using coord_cartesian with the xlim=c(0,500) argument works better with ggplot by showing the consequences of points out of the limits on lines within the viewport.

There are other possible problems with your data that your non-reproducible example does not show, and sending R code in HTML-formatted email usually corrupts it.. so please follow the recommendations in the Posting Guide next time you post.

On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear all,
>
>I would appreciate having your advice/suggestions/comments on the
>following
>:
>
>1 -- starting from a vector that contains LENGTHS (numerically, the
>values
>are from 1 to 10 000)
>
>2 -- shall I display the ECDF by using the R code and some "limits" :
>
>BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400,
>500,
>         1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
>
>ggplot(x, aes(LENGTH)) +
>          stat_ecdf(geom = "point") +
>          scale_x_continuous(name = "LENGTH of DEL",
>                             breaks = BREAKS,
>                             limits=c(0, 500))
>
>3 -- I am getting the following warning message : "Warning message:
>Removed
>109 rows containing non-finite values (stat_ecdf)."
>
>The question is : are these 109 values removed from VISUALIZATION as i
>set
>up the "limits", or are these 109 values removed from statistical
>CALCULATION?
>
>4 -- in contrast, shall I use the standard R functions plot(ecdf),
>there is
>no "warning mesage"
>
>plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
>                     ylab="Fraction of DEL", main="DEL", xlim=c(0,500),
>                     col = "dark red")
>
>Thanks a lot !
>
>-- bogdan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Sun Jul  8 06:53:24 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 7 Jul 2018 21:53:24 -0700
Subject: [R] Spatial Clustering with spdep::skater
In-Reply-To: <A7ABCFB3-B84E-41AF-9562-ECCFD14C9AC6@gmail.com>
References: <A7ABCFB3-B84E-41AF-9562-ECCFD14C9AC6@gmail.com>
Message-ID: <CAGxFJbS3_U8ib2VDbz+ztzT++tmZBPhA=H05hCZwH+3pS5-MaQ@mail.gmail.com>

Generally, statistical questions are off topic for this list, which is
about R programming; but the r-sig-geo list would seem to be a better place
to post this anyway, as the expertise you seek is much more likely there.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jul 7, 2018 at 12:53 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Dear Experts,
>
> I?m working with spdep::skater to fit clusters to spatial data subject to
> contiguity constraints. This function fits clusters by edge removal from
> Minimum Spanning Trees.
>
> In this context, I?d appreciate any pointers on how to tune the number of
> clusters. What is a sensible criteria to use?
>
> Thanks
> Axel.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @orenh @ending from m@th@@@u@dk  Sun Jul  8 10:41:43 2018
From: @orenh @ending from m@th@@@u@dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 8 Jul 2018 08:41:43 +0000
Subject: [R] consider running tools::compactPDF(gs_quality = "ebook")
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3012A64C771@AD-EXCHMBX3-3.aau.dk>

Dear all,

I run

R CMD build --compact-vignettes="both"  gRbase

and/or

R CMD build --compact-vignettes="gs+qpdf"  gRbase

and in the log from r-devel (on winbuilder) I get

* checking sizes of PDF files under 'inst/doc' ... WARNING
  'gs+qpdf' made some significant size reductions:
     compacted 'gRbase-arrays.pdf' from 421Kb to 115Kb
  consider running tools::compactPDF(gs_quality = "ebook") on these files

According to "writing R extensions" things should be fine (I have gs and qpdf on my system):

"The --compact-vignettes option will run tools::compactPDF over the PDF files in inst/doc (and its subdirectories) to losslessly compress them. This is not enabled by default (it can be selected by environment variable _R_BUILD_COMPACT_VIGNETTES_) and needs qpdf (http://qpdf.sourceforge.net/) to be available. "

Can anyone please tell me what to do?

Best regards
S?ren 

---

> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.4 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] Rcpp_0.12.17    shtools_1.0     markdown_0.8    knitr_1.20     
[5] rmarkdown_1.10  devtools_1.13.5

loaded via a namespace (and not attached):
 [1] lattice_0.20-35         digest_0.6.15           withr_2.1.2            
 [4] rprojroot_1.3-2         grid_3.4.4              backports_1.1.2        
 [7] magrittr_1.5            evaluate_0.10.1         stringi_1.2.3          
[10] curl_3.2                RcppArmadillo_0.8.500.0 Matrix_1.2-14          
[13] tools_3.4.4             RcppEigen_0.3.3.4.0     stringr_1.3.1          
[16] compiler_3.4.4          memoise_1.1.0           htmltools_0.3.6



From c@t@linroibu @ending from gm@il@com  Sun Jul  8 10:44:54 2018
From: c@t@linroibu @ending from gm@il@com (catalin roibu)
Date: Sun, 8 Jul 2018 11:44:54 +0300
Subject: [R] replicate rows
Message-ID: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>

Dear R users,

I want to replicate sampled rows in data frame. The sampling results must
be in this form:

  a   b     Rep
[1,] 3 4.0 R1
[2,] 6 8.0 R1
[3,] 1 0.1 R2
[4,] 6 8.0 R2
[5,] 1 0.1 R3
[6,] 5 7.0 R3

I have a code but I didn't succeed to insert to rep column.

This is my code:
a<-c(1,2,3,4,5,6)
b<-c(0.1, 0.2, 4, 6, 7, 8)
ab<-cbind(a, b)
x<-replicate(3, sample(1:nrow(ab), 2))
aa<-ab[x, ]

Please help me to solve that problem!

Thank you very much!

Best regards!

Catalin

-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Sun Jul  8 11:51:29 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Sun, 8 Jul 2018 12:51:29 +0300
Subject: [R] replicate rows
In-Reply-To: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>
References: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>
Message-ID: <CAGgJW76a-6LFXRbDUVgO7JgHNzoDNFRqBmm8Kw=5quk2pwsEQQ@mail.gmail.com>

Hi Catalin,

This should work. I set the number of repetitions and sample sizes as
variables so it would be clear how to modify for your actual case.

nreps    <- 3
sampSize <- 2
w <- unlist( lapply(1:nreps, function(i) {
rep(paste("R",i,sep=""),sampSize) } ) )
aa2 <- cbind( as.data.frame(aa), w)

HTH,
Eric


On Sun, Jul 8, 2018 at 11:44 AM, catalin roibu <catalinroibu at gmail.com>
wrote:

> Dear R users,
>
> I want to replicate sampled rows in data frame. The sampling results must
> be in this form:
>
>   a   b     Rep
> [1,] 3 4.0 R1
> [2,] 6 8.0 R1
> [3,] 1 0.1 R2
> [4,] 6 8.0 R2
> [5,] 1 0.1 R3
> [6,] 5 7.0 R3
>
> I have a code but I didn't succeed to insert to rep column.
>
> This is my code:
> a<-c(1,2,3,4,5,6)
> b<-c(0.1, 0.2, 4, 6, 7, 8)
> ab<-cbind(a, b)
> x<-replicate(3, sample(1:nrow(ab), 2))
> aa<-ab[x, ]
>
> Please help me to solve that problem!
>
> Thank you very much!
>
> Best regards!
>
> Catalin
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Sun Jul  8 14:28:27 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sun, 8 Jul 2018 12:28:27 +0000
Subject: [R] inconsistency in display of character vector....
Message-ID: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I have the following code to update the list of stocks:

function (snlcqn)
{
                  lneq <- c()
                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
                  file.string <- tempfile()

                  download.file(URL,file.string)

                  IDT <- read_excel(file.string)

                  leq <- IDT[,1]

                  for(i in 1:length(leq)){
                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}

                  for(j in 1:length(lneq)){
                  snlcqna[j] <- paste("NSE/",lneq[j])}

                  if(identical(snlcqn,snlcqna) == "FALSE"){
                  return(snlcqna)                         }

                  else                                    {
                  return(snlcqn)                          }

}
snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):

[192] "NSE/YESBANK"
[193] "NSE/ZEEL"

Why is this happening? How can I get the return object as a contiguous list?
Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Sun Jul  8 14:37:33 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sun, 8 Jul 2018 12:37:33 +0000
Subject: [R] Fw: inconsistency in display of character vector....
In-Reply-To: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             The mail is not showing the spaces between [192] "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the two.....!!!!!!

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni <akshay_e4 at hotmail.com>
Sent: Sunday, July 8, 2018 5:58 PM
To: R help Mailing  list
Subject: [R] inconsistency in display of character vector....

dear members,
                            I have the following code to update the list of stocks:

function (snlcqn)
{
                  lneq <- c()
                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
                  file.string <- tempfile()

                  download.file(URL,file.string)

                  IDT <- read_excel(file.string)

                  leq <- IDT[,1]

                  for(i in 1:length(leq)){
                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}

                  for(j in 1:length(lneq)){
                  snlcqna[j] <- paste("NSE/",lneq[j])}

                  if(identical(snlcqn,snlcqna) == "FALSE"){
                  return(snlcqna)                         }

                  else                                    {
                  return(snlcqn)                          }

}
snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):

[192] "NSE/YESBANK"
[193] "NSE/ZEEL"

Why is this happening? How can I get the return object as a contiguous list?
Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From btupper @ending from bigelow@org  Sun Jul  8 15:48:48 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Sun, 8 Jul 2018 09:48:48 -0400
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <5B49E856-EC41-4C1C-BEAE-8728503937AB@bigelow.org>

Hi,

You will be hard pressed to get helpful answers as you have not provided any way for list readers to replicate your data and code.  Check out this https://rseek.org/?q=reproducible+example

On the other hand, ...

(1)  I have a hunch that one place you are getting tripped up by your effort to treat IDT as a regular data.frame.  In fact, read_excel(), I'm guessing from the readxl package, returns a tibble.  When you subset a tibble like you have with...

leq <- IDT[,1]

... you get a 1-column tibble...

> leq
# A tibble: 208 x 1
   SymbolSeries
   <chr>       
 1 ACCEQ       
 2 ADANIENTEQ  
 3 ADANIPORTSEQ
 4 ADANIPOWEREQ
 5 AJANTPHARMEQ
 6 ALBKEQ      
 7 AMARAJABATEQ
 8 AMBUJACEMEQ 
 9 ANDHRABANKEQ
10 APOLLOHOSPEQ
# ... with 198 more rows

So, that may be part of the issue (but I'm not really sure if it causes the problem you identify).

(2) Also another possible tripping point, when you prepend 'NSE/' to whatever lneq is supposed to be, you are using paste() without specifying the sep argument which defaults to a single space " ".  If you want it to be something else then you have to explicitly set the value of sep.

(3) Finally, you will have much better luck getting help if you configure your email client to send plain text to this list.  Fancily formatted text is made un-fancy by the list-server software - which will mess up your posted code.  That's why you keep getting ...

[[alternative HTML version deleted]]

... at the tail end of your emails.


Good luck!
Ben

> On Jul 8, 2018, at 8:37 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> dear members,
>                             The mail is not showing the spaces between [192] "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the two.....!!!!!!
> 
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni <akshay_e4 at hotmail.com>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
> 
> dear members,
>                            I have the following code to update the list of stocks:
> 
> function (snlcqn)
> {
>                  lneq <- c()
>                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                  file.string <- tempfile()
> 
>                  download.file(URL,file.string)
> 
>                  IDT <- read_excel(file.string)
> 
>                  leq <- IDT[,1]
> 
>                  for(i in 1:length(leq)){
>                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> 
>                  for(j in 1:length(lneq)){
>                  snlcqna[j] <- paste("NSE/",lneq[j])}
> 
>                  if(identical(snlcqn,snlcqna) == "FALSE"){
>                  return(snlcqna)                         }
> 
>                  else                                    {
>                  return(snlcqn)                          }
> 
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):
> 
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
> 
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul  8 16:30:05 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 08 Jul 2018 07:30:05 -0700
Subject: [R] Fw: inconsistency in display of character vector....
In-Reply-To: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <7F13FE71-A76B-4A0A-8132-6645659BD2E1@dcn.davis.ca.us>

Using dput and sending your questions with the plain text option as described in [1] will allow you to share your data with less ambiguity. To be sure you have supplied all the code needed for us to reproduce your problem, use [3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 

On July 8, 2018 5:37:33 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>The mail is not showing the spaces between [192] "NSE/YESBANK" and 
>[193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the
>two.....!!!!!!
>
>________________________________________
>From: R-help <r-help-bounces at r-project.org> on behalf of akshay
>kulkarni <akshay_e4 at hotmail.com>
>Sent: Sunday, July 8, 2018 5:58 PM
>To: R help Mailing  list
>Subject: [R] inconsistency in display of character vector....
>
>dear members,
>                I have the following code to update the list of stocks:
>
>function (snlcqn)
>{
>                  lneq <- c()
>                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                  file.string <- tempfile()
>
>                  download.file(URL,file.string)
>
>                  IDT <- read_excel(file.string)
>
>                  leq <- IDT[,1]
>
>                  for(i in 1:length(leq)){
>                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
>
>                  for(j in 1:length(lneq)){
>                  snlcqna[j] <- paste("NSE/",lneq[j])}
>
>                  if(identical(snlcqn,snlcqna) == "FALSE"){
>                  return(snlcqna)                         }
>
>                  else                                    {
>                  return(snlcqn)                          }
>
>}
>snlcqn is the list of present stocks and snlcqna is the list of updated
>stocks.
>The problem is the return object, instead of getting displayed in
>contiguous list, is getting displayed with lots of spaces...( I am
>using R on a LINUX RHEL AWS instance):
>
>[192] "NSE/YESBANK"
>[193] "NSE/ZEEL"
>
>Why is this happening? How can I get the return object as a contiguous
>list?
>Very many thanks for your time and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Sun Jul  8 16:40:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 8 Jul 2018 07:40:09 -0700
Subject: [R] consider running tools::compactPDF(gs_quality = "ebook")
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C3012A64C771@AD-EXCHMBX3-3.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C3012A64C771@AD-EXCHMBX3-3.aau.dk>
Message-ID: <CAGxFJbRBPGmt9NLdZs-k_9_X-r92Evrh1jE5+5UG=-Q+oA3ziQ@mail.gmail.com>

I believe R-package-devel is the right place to post this, not r-help. See
https://www.r-project.org/mail.html  for details.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jul 8, 2018 at 1:41 AM, S?ren H?jsgaard <sorenh at math.aau.dk> wrote:

> Dear all,
>
> I run
>
> R CMD build --compact-vignettes="both"  gRbase
>
> and/or
>
> R CMD build --compact-vignettes="gs+qpdf"  gRbase
>
> and in the log from r-devel (on winbuilder) I get
>
> * checking sizes of PDF files under 'inst/doc' ... WARNING
>   'gs+qpdf' made some significant size reductions:
>      compacted 'gRbase-arrays.pdf' from 421Kb to 115Kb
>   consider running tools::compactPDF(gs_quality = "ebook") on these files
>
> According to "writing R extensions" things should be fine (I have gs and
> qpdf on my system):
>
> "The --compact-vignettes option will run tools::compactPDF over the PDF
> files in inst/doc (and its subdirectories) to losslessly compress them.
> This is not enabled by default (it can be selected by environment variable
> _R_BUILD_COMPACT_VIGNETTES_) and needs qpdf (http://qpdf.sourceforge.net/)
> to be available. "
>
> Can anyone please tell me what to do?
>
> Best regards
> S?ren
>
> ---
>
> > sessionInfo()
> R version 3.4.4 (2018-03-15)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.4 LTS
>
> Matrix products: default
> BLAS: /usr/lib/libblas/libblas.so.3.6.0
> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] Rcpp_0.12.17    shtools_1.0     markdown_0.8    knitr_1.20
> [5] rmarkdown_1.10  devtools_1.13.5
>
> loaded via a namespace (and not attached):
>  [1] lattice_0.20-35         digest_0.6.15           withr_2.1.2
>
>  [4] rprojroot_1.3-2         grid_3.4.4              backports_1.1.2
>
>  [7] magrittr_1.5            evaluate_0.10.1         stringi_1.2.3
>
> [10] curl_3.2                RcppArmadillo_0.8.500.0 Matrix_1.2-14
>
> [13] tools_3.4.4             RcppEigen_0.3.3.4.0     stringr_1.3.1
>
> [16] compiler_3.4.4          memoise_1.1.0           htmltools_0.3.6
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From f@r@h@d@f@thi@n @ending from gm@il@com  Sun Jul  8 16:08:53 2018
From: f@r@h@d@f@thi@n @ending from gm@il@com (Farshad Fathian)
Date: Sun, 8 Jul 2018 18:38:53 +0430
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
Message-ID: <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>

Dear all,

Hello,



I am going to install the ?RWinEdt? package on R software. I had installed
it on R before, but when I downloaded the newest versions of R software
(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.

Please help and guide me to know how I can install and use the ?RWinEdt?
properly.



Look forward to hearing from you.



Best regards,


-- 

Farshad Fathian


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
07/07/18,
10:19:25 PM

	[[alternative HTML version deleted]]


From mm@echler @ending from gm@il@com  Sun Jul  8 09:54:30 2018
From: mm@echler @ending from gm@il@com (Martin Maechler)
Date: Sun, 8 Jul 2018 17:54:30 +1000
Subject: [R] Do there need to be the same number of y-values for each
 x-value when using tapply?
In-Reply-To: <bcb629c9-1b21-3e63-e462-c9c588ca20dc@mixmax.com>
References: <bcb629c9-1b21-3e63-e462-c9c588ca20dc@mixmax.com>
Message-ID: <CAPRP4-c2CUQGUwQ772uGJxiz5VZ2C59a7Qhp_v7fhMa02nK++g@mail.gmail.com>

The answer to your Q is surely a "no": That's exaxtly the point of tapply
that the number of y values may vary. The msg tells you that the x & y full
vectors must have the same length.

Hoping that helps.
Martin

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul  8 17:04:14 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 08 Jul 2018 08:04:14 -0700
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
Message-ID: <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>

Read the vignette at [1], which mentions the Read me.txt file [2]. I found both links using Google... you could too.

[1] https://cran.r-project.org/web/packages/RWinEdt/index.html.
[2] https://github.com/cran/RWinEdt/blob/master/inst/ReadMe.txt

On July 8, 2018 7:08:53 AM PDT, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>Dear all,
>
>Hello,
>
>
>
>I am going to install the ?RWinEdt? package on R software. I had
>installed
>it on R before, but when I downloaded the newest versions of R software
>(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.
>
>Please help and guide me to know how I can install and use the
>?RWinEdt?
>properly.
>
>
>
>Look forward to hearing from you.
>
>
>
>Best regards,

-- 
Sent from my phone. Please excuse my brevity.


From kim@r@nt@ @ending from gm@il@com  Sun Jul  8 12:52:59 2018
From: kim@r@nt@ @ending from gm@il@com (Kim O)
Date: Sun, 8 Jul 2018 12:52:59 +0200
Subject: [R] Help with mixOmics rcc-tune
Message-ID: <CAK8=OOLOsRT+Rv_TkPkOr6yD-74uidS90boKZfZFy3a25NLJ=A@mail.gmail.com>

Dear,


I am using the mixOmics rCCA package, but I am encountering a problem that
I cannot solve with the documentation only:


*How should I interpret the "optimal score" (opt.score) returned by
tune.rcc? *


It does not say what this score actually represent? My best guess would be
the average canonical correlations on the test set, but I am not sure?


In my specific application, I get canonical correlation of about 0.8 on
training data but a CV-score of only 0.20.... I don't know whether this is
good or bad and how to interpret this.


Can you provide information on how exactly this is calculated and how to
interpret it?


Thank you so much. Would mean so much to me!

Best,

Kim Rants

	[[alternative HTML version deleted]]


From f@r@h@d@f@thi@n @ending from gm@il@com  Sun Jul  8 18:26:47 2018
From: f@r@h@d@f@thi@n @ending from gm@il@com (Farshad Fathian)
Date: Sun, 8 Jul 2018 20:56:47 +0430
Subject: [R] Fwd: Question
In-Reply-To: <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
 <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
Message-ID: <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>

Thank you so much for your reply. But when I install the "RWinEdt" package,
the R unable to install it. I see the below warning:

"Error: package or namespace load failed for ?RWinEdt?:
 package ?RWinEdt? was installed by an R version with different internals;
it needs to be reinstalled for use with this R version"

The current version of the R is 3.5.1.




[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
07/08/18,
8:54:06 PM

On Sun, Jul 8, 2018 at 7:34 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Read the vignette at [1], which mentions the Read me.txt file [2]. I found
> both links using Google... you could too.
>
> [1] https://cran.r-project.org/web/packages/RWinEdt/index.html.
> [2] https://github.com/cran/RWinEdt/blob/master/inst/ReadMe.txt
>
> On July 8, 2018 7:08:53 AM PDT, Farshad Fathian <farshad.fathian at gmail.com>
> wrote:
> >Dear all,
> >
> >Hello,
> >
> >
> >
> >I am going to install the ?RWinEdt? package on R software. I had
> >installed
> >it on R before, but when I downloaded the newest versions of R software
> >(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.
> >
> >Please help and guide me to know how I can install and use the
> >?RWinEdt?
> >properly.
> >
> >
> >
> >Look forward to hearing from you.
> >
> >
> >
> >Best regards,
>
> --
> Sent from my phone. Please excuse my brevity.
>



-- 

Farshad Fathian

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul  8 20:32:29 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 08 Jul 2018 11:32:29 -0700
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
 <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
 <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
Message-ID: <16658586-3C9D-4ED8-B936-A626D92193A8@dcn.davis.ca.us>

I recommend that you post the output of sessionInfo() and copy-paste the commands you attempted to use that failed.

Note that I don't use this package or its associated non-free editor, but the CRAN installation check shows no significant problems, though the package hasn't been updated recently.

On July 8, 2018 9:26:47 AM PDT, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>Thank you so much for your reply. But when I install the "RWinEdt"
>package,
>the R unable to install it. I see the below warning:
>
>"Error: package or namespace load failed for ?RWinEdt?:
>package ?RWinEdt? was installed by an R version with different
>internals;
>it needs to be reinstalled for use with this R version"
>
>The current version of the R is 3.5.1.
>
>
>
>
>[image: Mailtrack]
><https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
>Sender
>notified by
>Mailtrack
><https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
>07/08/18,
>8:54:06 PM
>
>On Sun, Jul 8, 2018 at 7:34 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Read the vignette at [1], which mentions the Read me.txt file [2]. I
>found
>> both links using Google... you could too.
>>
>> [1] https://cran.r-project.org/web/packages/RWinEdt/index.html.
>> [2] https://github.com/cran/RWinEdt/blob/master/inst/ReadMe.txt
>>
>> On July 8, 2018 7:08:53 AM PDT, Farshad Fathian
><farshad.fathian at gmail.com>
>> wrote:
>> >Dear all,
>> >
>> >Hello,
>> >
>> >
>> >
>> >I am going to install the ?RWinEdt? package on R software. I had
>> >installed
>> >it on R before, but when I downloaded the newest versions of R
>software
>> >(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.
>> >
>> >Please help and guide me to know how I can install and use the
>> >?RWinEdt?
>> >properly.
>> >
>> >
>> >
>> >Look forward to hearing from you.
>> >
>> >
>> >
>> >Best regards,
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From h@@@n@diw@n @ending from gm@il@com  Sun Jul  8 20:43:53 2018
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Sun, 8 Jul 2018 11:43:53 -0700
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
 <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
 <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
Message-ID: <CAP+bYWCfMj5sa4bZJTNMn+yWwXMBHtBStGvbKJPY_tanh-2v7Q@mail.gmail.com>

Farshad,
On Sun, 8 Jul 2018 at 09:29, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>
> Thank you so much for your reply. But when I install the "RWinEdt" package,
> the R unable to install it. I see the below warning:
>
> "Error: package or namespace load failed for ?RWinEdt?:
>  package ?RWinEdt? was installed by an R version with different internals;
> it needs to be reinstalled for use with this R version"

What do the following statements:
> remove.packages('RWinEdt'); install.packages('RWinEdt')
yield?

--
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable


From m@cqueen1 @ending from llnl@gov  Sun Jul  8 23:39:23 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Sun, 8 Jul 2018 21:39:23 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <5B49E856-EC41-4C1C-BEAE-8728503937AB@bigelow.org>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <5B49E856-EC41-4C1C-BEAE-8728503937AB@bigelow.org>
Message-ID: <F44057DD-77DB-4317-BE32-725326384581@llnl.gov>

In addition to what Ben and Jeff have said, I think you can simplify your function considerably. See these examples:

> substr( c('abc', 'abcd','abcde') , c(2,1,3), c(2,2,4))
[1] "b"  "ab" "cd"

> foo <- c('abc', 'abcd','abcde') 
> substr( foo , 1, nchar(foo)-2)
[1] "a"   "ab"  "abc"

> foo <- c('abc', 'abcd','abcde') 
> paste0('NSE/',foo)
[1] "NSE/abc"   "NSE/abcd"  "NSE/abcde"

I can't test my suggestions, but just from looking at your code, I don't think you need the two loops.

function (snlcqn)
{
 ##                 lneq <- c()   ## not a good way to initialize
                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
                  file.string <- tempfile()

                  download.file(URL,file.string)

                  IDT <- read_excel(file.string)

                  leq <- IDT[,1]

   lneq <- substr( leq, 1, nchar(leq)-2)

#                  for(i in 1:length(leq)){
#                 lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}

  snlcqna <- paste0('NSE/', lneq)

#                  for(j in 1:length(lneq)){
#                  snlcqna[j] <- paste("NSE/",lneq[j])}


## functions return the value of their last expression, so the return() statements are not necessary
## testing for FALSE does not need == "FALSE"

#                  if(identical(snlcqn,snlcqna) == "FALSE"){
#                 return(snlcqna)                         }
#
#                  else                                    {
#                  return(snlcqn)                          }

  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

}


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/8/18, 6:48 AM, "R-help on behalf of Ben Tupper" <r-help-bounces at r-project.org on behalf of btupper at bigelow.org> wrote:

    Hi,
    
    You will be hard pressed to get helpful answers as you have not provided any way for list readers to replicate your data and code.  Check out this https://rseek.org/?q=reproducible+example
    
    On the other hand, ...
    
    (1)  I have a hunch that one place you are getting tripped up by your effort to treat IDT as a regular data.frame.  In fact, read_excel(), I'm guessing from the readxl package, returns a tibble.  When you subset a tibble like you have with...
    
    leq <- IDT[,1]
    
    ... you get a 1-column tibble...
    
    > leq
    # A tibble: 208 x 1
       SymbolSeries
       <chr>       
     1 ACCEQ       
     2 ADANIENTEQ  
     3 ADANIPORTSEQ
     4 ADANIPOWEREQ
     5 AJANTPHARMEQ
     6 ALBKEQ      
     7 AMARAJABATEQ
     8 AMBUJACEMEQ 
     9 ANDHRABANKEQ
    10 APOLLOHOSPEQ
    # ... with 198 more rows
    
    So, that may be part of the issue (but I'm not really sure if it causes the problem you identify).
    
    (2) Also another possible tripping point, when you prepend 'NSE/' to whatever lneq is supposed to be, you are using paste() without specifying the sep argument which defaults to a single space " ".  If you want it to be something else then you have to explicitly set the value of sep.
    
    (3) Finally, you will have much better luck getting help if you configure your email client to send plain text to this list.  Fancily formatted text is made un-fancy by the list-server software - which will mess up your posted code.  That's why you keep getting ...
    
    [[alternative HTML version deleted]]
    
    ... at the tail end of your emails.
    
    
    Good luck!
    Ben
    
    > On Jul 8, 2018, at 8:37 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
    > 
    > dear members,
    >                             The mail is not showing the spaces between [192] "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the two.....!!!!!!
    > 
    > ________________________________________
    > From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni <akshay_e4 at hotmail.com>
    > Sent: Sunday, July 8, 2018 5:58 PM
    > To: R help Mailing  list
    > Subject: [R] inconsistency in display of character vector....
    > 
    > dear members,
    >                            I have the following code to update the list of stocks:
    > 
    > function (snlcqn)
    > {
    >                  lneq <- c()
    >                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
    >                  file.string <- tempfile()
    > 
    >                  download.file(URL,file.string)
    > 
    >                  IDT <- read_excel(file.string)
    > 
    >                  leq <- IDT[,1]
    > 
    >                  for(i in 1:length(leq)){
    >                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
    > 
    >                  for(j in 1:length(lneq)){
    >                  snlcqna[j] <- paste("NSE/",lneq[j])}
    > 
    >                  if(identical(snlcqn,snlcqna) == "FALSE"){
    >                  return(snlcqna)                         }
    > 
    >                  else                                    {
    >                  return(snlcqn)                          }
    > 
    > }
    > snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
    > The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):
    > 
    > [192] "NSE/YESBANK"
    > [193] "NSE/ZEEL"
    > 
    > Why is this happening? How can I get the return object as a contiguous list?
    > Very many thanks for your time and effort...
    > yours sincerely,
    > AKSHAY M KULKARNI
    > 
    >        [[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    > 
    
    Ben Tupper
    Bigelow Laboratory for Ocean Sciences
    60 Bigelow Drive, P.O. Box 380
    East Boothbay, Maine 04544
    http://www.bigelow.org
    
    Ecological Forecasting: https://eco.bigelow.org/
    
    
    
    
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@dmuzom @ending from outlook@com  Sun Jul  8 20:01:50 2018
From: r@dmuzom @ending from outlook@com (radmuzom .)
Date: Sun, 8 Jul 2018 18:01:50 +0000
Subject: [R] replicate rows
In-Reply-To: <CAGgJW76a-6LFXRbDUVgO7JgHNzoDNFRqBmm8Kw=5quk2pwsEQQ@mail.gmail.com>
References: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>,
 <CAGgJW76a-6LFXRbDUVgO7JgHNzoDNFRqBmm8Kw=5quk2pwsEQQ@mail.gmail.com>
Message-ID: <MA1PR0101MB178120F0E2E3214047A08D89CB450@MA1PR0101MB1781.INDPRD01.PROD.OUTLOOK.COM>

While Eric's solution should work for your case, here is a slightly more general version where the number of replications is dependent on a column in the data frame. In the example, the number of replications required is the ceiling of the number of 30 day intervals between start date and end date, which are already available in the data frame. The key function is f - this takes a row index (of df) and replicates as many times as determined by the value in the column num_int for that row. To modify f, you need to replace num_int by the appropriate column name in your data set. f is then mapped to each row number of df and the replicated indices are stored in rowindex_rep as a vector. The final step is to subset df which repeats the rows appropriately. 

df <- data.frame(
  order_id = c(1, 2),
  start_date = c(as.Date("2017-05-01"), as.Date("2017-08-01")),
  end_date = c(as.Date("2017-07-06"), as.Date("2017-09-15"))
)
df$diff_days <- as.integer(df$end_date - df$start_date)
df$num_int <- ceiling(df$diff_days / 30)

f <- function(rowindex) {
  rep(rowindex, each = df[rowindex, "num_int"])
}

rowindex_rep <- unlist(Map(f, 1:nrow(df)))
df2 <- df[rowindex_rep, ]


Regards,
radmuzom



From: R-help <r-help-bounces at r-project.org> on behalf of Eric Berger <ericjberger at gmail.com>
Sent: Sunday, July 8, 2018 3:21 PM
To: catalin roibu
Cc: R Project Help
Subject: Re: [R] replicate rows
? 

Hi Catalin,

This should work. I set the number of repetitions and sample sizes as
variables so it would be clear how to modify for your actual case.

nreps??? <- 3
sampSize <- 2
w <- unlist( lapply(1:nreps, function(i) {
rep(paste("R",i,sep=""),sampSize) } ) )
aa2 <- cbind( as.data.frame(aa), w)

HTH,
Eric


On Sun, Jul 8, 2018 at 11:44 AM, catalin roibu <catalinroibu at gmail.com>
wrote:

> Dear R users,
>
> I want to replicate sampled rows in data frame. The sampling results must
> be in this form:
>
>?? a?? b???? Rep
> [1,] 3 4.0 R1
> [2,] 6 8.0 R1
> [3,] 1 0.1 R2
> [4,] 6 8.0 R2
> [5,] 1 0.1 R3
> [6,] 5 7.0 R3
>
> I have a code but I didn't succeed to insert to rep column.
>
> This is my code:
> a<-c(1,2,3,4,5,6)
> b<-c(0.1, 0.2, 4, 6, 7, 8)
> ab<-cbind(a, b)
> x<-replicate(3, sample(1:nrow(ab), 2))
> aa<-ab[x, ]
>
> Please help me to solve that problem!
>
> Thank you very much!
>
> Best regards!
>
> Catalin
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone????? +4 0230 52 29 78, ext. 531
> mobile phone??? +4 0745 53 18 01
> FAX:??????????????? +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>???????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    

From t@n@@@ @ending from gm@il@com  Mon Jul  9 02:44:45 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sun, 8 Jul 2018 17:44:45 -0700
Subject: [R] about ECDF display in ggplot2
Message-ID: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>

Dear Jeff,

thank you for your email.

Yes, in order to be more descriptive/comprehensive, please find attached to
my email the following files (my apologies ... I am sending these as
attachments, as I do not have a web server running at this moment) :

-- the R script (R_script_display_ECDF.R) that reads the file "LENGTH" and
outputs ECDF figure by using the standard R function or ggplot2.

-- the display of ECDF by using standard R function
("display.R.ecdf.LENGTH.pdf")

-- the display of ECDF by using ggplot2 ("display.ggplot2.ecdf.LENGTH.pdf")

The ECDF over xlim(0,500) looks very different (contrasting plot(ecdf) vs
ggplot2).  Please would you advise why ? what shall I change in my ggplot2
code ?

thanks a lot,

- bogdan

ps : the R code is also written below :

 library("ggplot2")
>


> file <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
>


> ############################# display with PLOT FUNCTION:
>


> pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6, paper='special')
>


> plot(ecdf(file$LENGTH), xlab="DEL SIZE",
>                      ylab="fraction of DEL",
>                      main="LENGTH of DEL",
>                      xlim=c(0,500),
>                      col = "dark red", axes = FALSE)
>


> ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
>


> axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
>


> ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
>


> axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
>


> dev.off()
>


> ############################# display in GGPLOT2 :
>


> BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
>            1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
>


> barfill <- "#4271AE"
> barlines <- "#1F3552"
>


> pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
> paper='special')
>


> ggplot(file, aes(LENGTH)) +
>           stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>           scale_x_continuous(name = "LENGTH of DEL",
>                              breaks = BREAKS,
>                              limits=c(0, 500)) +
>           scale_y_continuous(name = "FRACTION") +
>           ggtitle("ECDF of LENGTH") +
>           theme_bw() +
>           theme(legend.position = "bottom", legend.direction =
> "horizontal",
>                legend.box = "horizontal",
>                legend.key.size = unit(1, "cm"),
>                axis.title = element_text(size = 12),
>                legend.text = element_text(size = 9),
>                legend.title=element_text(face = "bold", size = 9))
>


> dev.off()








On Sat, Jul 7, 2018 at 9:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> It is a feature of ggplot that points excluded by limits raise warnings,
> while base graphics do not.
>
> You may find that using coord_cartesian with the xlim=c(0,500) argument
> works better with ggplot by showing the consequences of points out of the
> limits on lines within the viewport.
>
> There are other possible problems with your data that your
> non-reproducible example does not show, and sending R code in
> HTML-formatted email usually corrupts it.. so please follow the
> recommendations in the Posting Guide next time you post.
>
> On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >Dear all,
> >
> >I would appreciate having your advice/suggestions/comments on the
> >following
> >:
> >
> >1 -- starting from a vector that contains LENGTHS (numerically, the
> >values
> >are from 1 to 10 000)
> >
> >2 -- shall I display the ECDF by using the R code and some "limits" :
> >
> >BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400,
> >500,
> >         1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
> >
> >ggplot(x, aes(LENGTH)) +
> >          stat_ecdf(geom = "point") +
> >          scale_x_continuous(name = "LENGTH of DEL",
> >                             breaks = BREAKS,
> >                             limits=c(0, 500))
> >
> >3 -- I am getting the following warning message : "Warning message:
> >Removed
> >109 rows containing non-finite values (stat_ecdf)."
> >
> >The question is : are these 109 values removed from VISUALIZATION as i
> >set
> >up the "limits", or are these 109 values removed from statistical
> >CALCULATION?
> >
> >4 -- in contrast, shall I use the standard R functions plot(ecdf),
> >there is
> >no "warning mesage"
> >
> >plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
> >                     ylab="Fraction of DEL", main="DEL", xlim=c(0,500),
> >                     col = "dark red")
> >
> >Thanks a lot !
> >
> >-- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: display.ggplot2.ecdf.LENGTH.pdf
Type: application/pdf
Size: 8841 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180708/75da9c56/attachment.pdf>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: display.R.ecdf.LENGTH.pdf
Type: application/pdf
Size: 13600 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180708/75da9c56/attachment-0001.pdf>

From petr@pik@l @ending from prechez@@cz  Mon Jul  9 08:43:39 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Mon, 9 Jul 2018 06:43:39 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>

Hi

You definitely should not use HTML formated mail. This is plain text mailing list for reason.

If you experience space between "NSE/" and pasted second part, you should read paste help page which states

paste (..., sep = " ", collapse = NULL)

so it has space as separator.

You should use paste0 if you want to get rid of separating space or axplicitely state 
paste (..., sep = "")

> lneq <- c()
> for (i in 1:10) lneq[i] <- letters[i]
> lneq
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> snlcqna<-LETTERS[1:10]
> for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> snlcqna
 [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/ h"
 [9] "NSE/ i" "NSE/ j"
> for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> snlcqna
 [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h" "NSE/i"
[10] "NSE/j"

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of akshay
> kulkarni
> Sent: Sunday, July 8, 2018 2:38 PM
> To: R help Mailing list <r-help at r-project.org>
> Subject: [R] Fw: inconsistency in display of character vector....
> 
> dear members,
>                              The mail is not showing the spaces between [192]
> "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces
> between the two.....!!!!!!
> 
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni
> <akshay_e4 at hotmail.com>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
> 
> dear members,
>                             I have the following code to update the list of stocks:
> 
> function (snlcqn)
> {
>                   lneq <- c()
>                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                   file.string <- tempfile()
> 
>                   download.file(URL,file.string)
> 
>                   IDT <- read_excel(file.string)
> 
>                   leq <- IDT[,1]
> 
>                   for(i in 1:length(leq)){
>                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> 
>                   for(j in 1:length(lneq)){
>                   snlcqna[j] <- paste("NSE/",lneq[j])}
> 
>                   if(identical(snlcqn,snlcqna) == "FALSE"){
>                   return(snlcqna)                         }
> 
>                   else                                    {
>                   return(snlcqn)                          }
> 
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list,
> is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS
> instance):
> 
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
> 
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ericjberger @ending from gm@il@com  Mon Jul  9 08:45:03 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 9 Jul 2018 09:45:03 +0300
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>

 >  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

??

Why not just always return snicqna ?


On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You definitely should not use HTML formated mail. This is plain text
> mailing list for reason.
>
> If you experience space between "NSE/" and pasted second part, you should
> read paste help page which states
>
> paste (..., sep = " ", collapse = NULL)
>
> so it has space as separator.
>
> You should use paste0 if you want to get rid of separating space or
> axplicitely state
> paste (..., sep = "")
>
> > lneq <- c()
> > for (i in 1:10) lneq[i] <- letters[i]
> > lneq
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> > snlcqna<-LETTERS[1:10]
> > for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/
> h"
>  [9] "NSE/ i" "NSE/ j"
> > for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h"
> "NSE/i"
> [10] "NSE/j"
>
> Cheers
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner's personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of akshay
> > kulkarni
> > Sent: Sunday, July 8, 2018 2:38 PM
> > To: R help Mailing list <r-help at r-project.org>
> > Subject: [R] Fw: inconsistency in display of character vector....
> >
> > dear members,
> >                              The mail is not showing the spaces between
> [192]
> > "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty
> spaces
> > between the two.....!!!!!!
> >
> > ________________________________________
> > From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni
> > <akshay_e4 at hotmail.com>
> > Sent: Sunday, July 8, 2018 5:58 PM
> > To: R help Mailing  list
> > Subject: [R] inconsistency in display of character vector....
> >
> > dear members,
> >                             I have the following code to update the list
> of stocks:
> >
> > function (snlcqn)
> > {
> >                   lneq <- c()
> >                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
> >                   file.string <- tempfile()
> >
> >                   download.file(URL,file.string)
> >
> >                   IDT <- read_excel(file.string)
> >
> >                   leq <- IDT[,1]
> >
> >                   for(i in 1:length(leq)){
> >                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> >
> >                   for(j in 1:length(lneq)){
> >                   snlcqna[j] <- paste("NSE/",lneq[j])}
> >
> >                   if(identical(snlcqn,snlcqna) == "FALSE"){
> >                   return(snlcqna)                         }
> >
> >                   else                                    {
> >                   return(snlcqn)                          }
> >
> > }
> > snlcqn is the list of present stocks and snlcqna is the list of updated
> stocks.
> > The problem is the return object, instead of getting displayed in
> contiguous list,
> > is getting displayed with lots of spaces...( I am using R on a LINUX
> RHEL AWS
> > instance):
> >
> > [192] "NSE/YESBANK"
> > [193] "NSE/ZEEL"
> >
> > Why is this happening? How can I get the return object as a contiguous
> list?
> > Very many thanks for your time and effort...
> > yours sincerely,
> > AKSHAY M KULKARNI
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jul  9 10:14:26 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 9 Jul 2018 13:44:26 +0530
Subject: [R] R couldnt recognize US Pasific timezome
Message-ID: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>

Hi,

I wanted to convert Epoch time to readable time with US Pacific Time Zone
using 'anytime' package, as below:

> library(anytime)
> anytime(1417411980, tz = 'PST')
[1] "2014-12-01 05:33:00 GMT"
Warning message:
In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'


However it appears that R couldn't recognize the PST as the short form of
Pacific time zone.

Any help to correctly change Epoch time to corresponding pacific time would
be helpful.

Thanks,

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jul  9 10:41:58 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 9 Jul 2018 01:41:58 -0700 (PDT)
Subject: [R] about ECDF display in ggplot2
In-Reply-To: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>
References: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807090119280.18090@pedal.dcn.davis.ca.us>

Thank you for making the effort... but most attachments get stripped on 
the mailing list. Using the reprex package as I suggested and putting the 
result into the email is by far the safest approach. Since I received your 
email directly, I did get the attachments. Below is my reproducible 
example... to serve as an example for how you can get help from everyone 
on the list rather than just the few you are responding to.

My summary comment is that you have to decide whether the LENGTH values 
greater than 500 are relevant... and if they are, you REALLY SHOULD create 
a data set that is limited in this fashion. Then you won't have to create 
"fake" axes, and you won't get ggplot warnings.

Note: The reprex package allows you to confirm that the example is in fact 
reproducible, so technically it is not necessary to include the plot 
images in the question. However, reprex used to conveniently support 
putting the images on the imgur website, and for some reason it no longer 
does that, so just run the example interactively to see the graphs.

#######
############################################################
############################################################

library("ggplot2")

# "file" is the name of a very fundamental function in base R. Re-using
# that name for a data value is at best confusing to anyone reading your
# code and at worst will prevent you from using that function.
#file <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)

# Instead of giving us a file, keep the data within the example
# DF <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
# set.seed( 42 )
# also shrink the size of the data for the example... we almost
# never need all of it
# dput( DF[ sample( seq.int( nrow( DF ) ), size = 200 ), , drop=FALSE ] )
DF <- structure(list(LENGTH = c(6813L, 56035L, 123997L, 281L, 851L, 1072L,
           72196L, 21L, 304L, 110L, 198L, 5922L, 283L, 199348L, 109L,
           3317104L, 106L, 37642146L, 82641L, 20L, 125911L, 354L, 11625388L,
           330L, 9811711L, 18L, 35L, 39897L, 27L, 277L, 79L, 2657L, 17L,
           26L, 23L, 248L, 3634L, 21L, 324L, 206L, 328L, 42L, 286L, 6042409L,
           24L, 36L, 2879L, 18L, 301L, 90684L, 4296636L, 43L, 1222L, 4536L,
           3281L, 324L, 393L, 3754L, 98824541L, 459L, 18L, 1081L, 175L,
           970L, 17L, 219L, 235558L, 1167315L, 25L, 623L, 2517515L, 32L,
           217L, 29L, 17L, 1744L, 18L, 39L, 26L, 77L, 41L, 22L, 311L, 119015225L,
           146413L, 22L, 19L, 301L, 373L, 2240L, 6439L, 128L, 18L, 257L,
           783L, 5169L, 31608038L, 325L, 1533L, 25L, 69344L, 54L, 10651L,
           31L, 335062L, 1854019L, 7153L, 38605567L, 51L, 23L, 16L, 301L,
           79L, 313L, 18L, 29L, 39L, 22L, 17L, 306L, 67L, 280L, 324L, 158L,
           93L, 2561L, 302L, 134578L, 328L, 9002L, 969051L, 34L, 20L, 309L,
           355L, 28L, 9461327L, 18627013L, 305L, 64L, 18L, 2730L, 28L, 246L,
           911L, 28L, 241483L, 154691L, 58891L, 55L, 456362L, 281L, 276L,
           51L, 26L, 106821L, 313L, 78L, 29L, 400L, 61171382L, 200L, 101L,
           220331L, 128L, 325L, 28L, 22L, 325L, 2330L, 5879L, 24L, 36L,
           23L, 51L, 26L, 32584707L, 1672L, 13939L, 315L, 20L, 580785L,
           42795L, 49193543L, 695L, 48568156L, 55634L, 207L, 318L, 22056L,
           3670420L, 4815387L, 309L, 17L, 3143160L, 431L, 1164L, 33L, 5503L,
           4166L)), .Names = "LENGTH", row.names = c(8283L, 8484L, 2591L,
           7517L, 5808L, 4698L, 6665L, 1219L, 5944L, 6378L, 4140L, 6503L,
           8452L, 2310L, 4180L, 8497L, 8842L, 1062L, 4293L, 5063L, 8168L,
           1253L, 8932L, 8550L, 745L, 4643L, 3523L, 8177L, 4035L, 7545L,
           6657L, 7319L, 3502L, 6181L, 36L, 7513L, 67L, 1873L, 8174L, 5516L,
           3422L, 3928L, 338L, 8773L, 3891L, 8627L, 7997L, 5765L, 8745L,
           5573L, 3003L, 3122L, 3588L, 7064L, 351L, 6739L, 6095L, 1541L,
           2349L, 4628L, 6077L, 8839L, 6830L, 5094L, 7639L, 1704L, 2439L,
           7443L, 6230L, 2162L, 387L, 1262L, 1944L, 4306L, 1773L, 6460L,
           71L, 3371L, 4618L, 15L, 5220L, 1417L, 3222L, 5792L, 6960L, 5056L,
           2096L, 807L, 768L, 2737L, 5983L, 3L, 1870L, 8361L, 8294L, 6577L,
           2984L, 4614L, 6664L, 5545L, 5608L, 1945L, 1939L, 3482L, 8435L,
           8615L, 6621L, 6561L, 4793L, 21L, 5447L, 7484L, 6721L, 4048L,
           4790L, 4804L, 13L, 3179L, 5471L, 7407L, 3187L, 3669L, 5123L,
           5267L, 6427L, 3527L, 8207L, 8593L, 2085L, 6467L, 8065L, 5385L,
           5635L, 8363L, 7587L, 5172L, 7326L, 1015L, 6817L, 5560L, 1324L,
           716L, 4136L, 6945L, 6536L, 7281L, 1516L, 8415L, 2616L, 1328L,
           6406L, 2886L, 6933L, 3511L, 6040L, 6905L, 1672L, 259L, 1208L,
           6051L, 8315L, 4896L, 5351L, 1752L, 4759L, 1597L, 4017L, 2818L,
           1033L, 1654L, 6483L, 3659L, 3678L, 4266L, 3797L, 1212L, 7322L,
           5258L, 7052L, 6826L, 8147L, 7655L, 2813L, 2300L, 6584L, 6629L,
           8140L, 7034L, 1183L, 2551L, 1726L, 6950L, 1143L, 1144L, 641L,
           471L, 4712L, 995L, 6582L, 6476L), class = "data.frame")


############################# display with PLOT FUNCTION:


# saving files should be avoided in reproducible examples... especially files
# that cannot be transmitted through the R-help mailing list such as pdf files
#pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6, paper='special')

# Your original plot commands below create a fake impression of the data by
# falsifying the axes. If you really are only interested in data points less
# than 500, you should be explicit about creating a data set containing only
# such constrained values before plotting them.
plot(ecdf(DF$LENGTH), xlab="DEL SIZE",
                      ylab="fraction of DEL",
                      main="LENGTH of DEL",
                      xlim=c(0,500),
                      col = "dark red", axes = FALSE)
ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-1.png)

# my recommendation
DF500 <- subset( DF, LENGTH < 500 )
plot( ecdf( DF500$LENGTH )
     , xlab = "DEL SIZE"
     , ylab = "fraction of DEL"
     , main = "LENGTH of DEL"
     , col = "dark red"
     )

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-2.png)

# alternatively
plot( ecdf( DF$LENGTH )
     , xlab = "DEL SIZE"
     , ylab = "fraction of DEL"
     , main = "LENGTH of DEL"
     , col = "dark red"
     , xlim=c( 1, 1e9 )
     , log="x"
     )

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-3.png)



#dev.off()

############################# display in GGPLOT2 :

BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
            1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)

barfill <- "#4271AE"
barlines <- "#1F3552"

#pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6, paper='special')

# ggplot's limits behavior is enabling your false representation of the data, but it
# warns you of the data removal
ggplot(DF, aes(LENGTH)) +
           stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
           scale_x_continuous(name = "LENGTH of DEL",
                              breaks = BREAKS,
                              limits=c(0, 500)
                              ) +
           scale_y_continuous(name = "FRACTION") +
           ggtitle("ECDF of LENGTH") +
           theme_bw() +
           theme(legend.position = "bottom", legend.direction = "horizontal",
                legend.box = "horizontal",
                legend.key.size = unit(1, "cm"),
                axis.title = element_text(size = 12),
                legend.text = element_text(size = 9),
                legend.title=element_text(face = "bold", size = 9))
#> Warning: Removed 80 rows containing non-finite values (stat_ecdf).

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-4.png)


# my recommendation
ggplot(DF500, aes(LENGTH)) +
   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
   scale_x_continuous(name = "LENGTH of DEL",
                      breaks = BREAKS ) +
   scale_y_continuous(name = "FRACTION") +
   ggtitle("ECDF of LENGTH") +
   theme_bw() +
   theme(legend.position = "bottom", legend.direction = "horizontal",
         legend.box = "horizontal",
         legend.key.size = unit(1, "cm"),
         axis.title = element_text(size = 12),
         legend.text = element_text(size = 9),
         legend.title=element_text(face = "bold", size = 9))

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-5.png)

# or for the un-filtered data
ggplot(DF, aes(LENGTH)) +
   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
   scale_x_log10( name = "LENGTH of DEL") +
   scale_y_continuous(name = "FRACTION") +
   ggtitle("ECDF of LENGTH") +
   theme_bw() +
   theme(legend.position = "bottom", legend.direction = "horizontal",
         legend.box = "horizontal",
         legend.key.size = unit(1, "cm"),
         axis.title = element_text(size = 12),
         legend.text = element_text(size = 9),
         legend.title=element_text(face = "bold", size = 9))

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-6.png)


#dev.off()

#' Created on 2018-07-09 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#######

On Sun, 8 Jul 2018, Bogdan Tanasa wrote:

> Dear Jeff,?
> thank you for your email.?
> 
> Yes, in order to be more descriptive/comprehensive, please find attached to
> my email the following files (my apologies ... I am sending these as
> attachments, as I do not have a web server running at this moment) :?
> 
> -- the R script (R_script_display_ECDF.R) that reads the file "LENGTH" and
> outputs ECDF figure by using the standard R function or ggplot2.
> 
> -- the display of ECDF by using standard R function
> ("display.R.ecdf.LENGTH.pdf")
> 
> -- the display of ECDF by using ggplot2 ("display.ggplot2.ecdf.LENGTH.pdf")
> 
> The ECDF over xlim(0,500) looks very different (contrasting plot(ecdf) vs
> ggplot2).? Please would you advise why ? what shall I change in my ggplot2
> code ?
> 
> thanks a lot,?
> 
> - bogdan
> 
> ps : the R code is also written below :
>
>       ?library("ggplot2")
> 
> ?
>       file <- read.delim("LENGTH", sep="\t", header=T,
>       stringsAsFactors=F)?
> 
> ?
>       ############################# display with PLOT FUNCTION:?
> 
> ?
>       pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6,
>       paper='special')?
> 
> ?
>       plot(ecdf(file$LENGTH), xlab="DEL SIZE",??
>       ? ? ? ? ? ? ? ? ? ? ?ylab="fraction of DEL",?
>       ? ? ? ? ? ? ? ? ? ? ?main="LENGTH of DEL",??
>       ? ? ? ? ? ? ? ? ? ? ?xlim=c(0,500),?
>       ? ? ? ? ? ? ? ? ? ? ?col = "dark red", axes = FALSE)
> 
> ?
>       ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
> 
> ?
>       axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
> 
> ?
>       ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
> 
> ?
>       axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
> 
> ?
>       dev.off()
> 
> ?
>       ############################# display in GGPLOT2 :?
> 
> ?
>       BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
>       400, 500,?
>       ? ? ? ? ? ?1000, 10000, 100000, 1000000, 10000000, 100000000,
>       1000000000)
> 
> ?
>       barfill <- "#4271AE"
>       barlines <- "#1F3552"
> 
> ?
>       pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
>       paper='special')?
> 
> ?
>       ggplot(file, aes(LENGTH)) +?
>       ? ? ? ? ? stat_ecdf(geom = "point", colour = barlines, fill =
>       barfill) +
>       ? ? ? ? ? scale_x_continuous(name = "LENGTH of DEL",
>       ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?breaks = BREAKS,
>       ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?limits=c(0, 500)) +
>       ? ? ? ? ? scale_y_continuous(name = "FRACTION") +
>       ? ? ? ? ? ggtitle("ECDF of LENGTH") +?
>       ? ? ? ? ? theme_bw() +
>       ? ? ? ? ? theme(legend.position = "bottom", legend.direction =
>       "horizontal",
>       ? ? ? ? ? ? ? ?legend.box = "horizontal",
>       ? ? ? ? ? ? ? ?legend.key.size = unit(1, "cm"),
>       ? ? ? ? ? ? ? ?axis.title = element_text(size = 12),
>       ? ? ? ? ? ? ? ?legend.text = element_text(size = 9),
>       ? ? ? ? ? ? ? ?legend.title=element_text(face = "bold", size =
>       9))
> 
> ?
>       dev.off()
> 
> 
> 
> 
> ?
> 
> 
> On Sat, Jul 7, 2018 at 9:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>       It is a feature of ggplot that points excluded by limits raise
>       warnings, while base graphics do not.
>
>       You may find that using coord_cartesian with the xlim=c(0,500)
>       argument works better with ggplot by showing the consequences of
>       points out of the limits on lines within the viewport.
>
>       There are other possible problems with your data that your
>       non-reproducible example does not show, and sending R code in
>       HTML-formatted email usually corrupts it.. so please follow the
>       recommendations in the Posting Guide next time you post.
>
>       On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
>       wrote:
>       >Dear all,
>       >
>       >I would appreciate having your advice/suggestions/comments on
>       the
>       >following
>       >:
>       >
>       >1 -- starting from a vector that contains LENGTHS (numerically,
>       the
>       >values
>       >are from 1 to 10 000)
>       >
>       >2 -- shall I display the ECDF by using the R code and some
>       "limits" :
>       >
>       >BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>       300, 400,
>       >500,
>       >? ? ? ? ?1000, 10000, 100000, 1000000, 10000000, 100000000,
>       1000000000)
>       >
>       >ggplot(x, aes(LENGTH)) +
>       >? ? ? ? ? stat_ecdf(geom = "point") +
>       >? ? ? ? ? scale_x_continuous(name = "LENGTH of DEL",
>       >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?breaks = BREAKS,
>       >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?limits=c(0, 500))
>       >
>       >3 -- I am getting the following warning message : "Warning
>       message:
>       >Removed
>       >109 rows containing non-finite values (stat_ecdf)."
>       >
>       >The question is : are these 109 values removed from
>       VISUALIZATION as i
>       >set
>       >up the "limits", or are these 109 values removed from
>       statistical
>       >CALCULATION?
>       >
>       >4 -- in contrast, shall I use the standard R functions
>       plot(ecdf),
>       >there is
>       >no "warning mesage"
>       >
>       >plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
>       >? ? ? ? ? ? ? ? ? ? ?ylab="Fraction of DEL", main="DEL",
>       xlim=c(0,500),
>       >? ? ? ? ? ? ? ? ? ? ?col = "dark red")
>       >
>       >Thanks a lot !
>       >
>       >-- bogdan
>       >
> >? ? ? ?[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Sent from my phone. Please excuse my brevity.
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jul  9 10:46:29 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 9 Jul 2018 01:46:29 -0700 (PDT)
Subject: [R] R couldnt recognize US Pasific timezome
In-Reply-To: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>
References: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807090142300.18090@pedal.dcn.davis.ca.us>

Several of the "conventional" three letter timezone abbreviations actually 
get re-used in different parts of the world, and not all operating system 
support for timezones include the same shortcuts. The solution is to use 
the correct timezone string rather than your familiar shortcut... you can 
look through the vector returned by the OlsonNames() function in general, 
but in your case just use "Etc/GMT+8" for standard time year-round. If you 
wanted daylight savings time support, you would use "America/Los_Angeles".

On Mon, 9 Jul 2018, Christofer Bogaso wrote:

> Hi,
>
> I wanted to convert Epoch time to readable time with US Pacific Time Zone
> using 'anytime' package, as below:
>
>> library(anytime)
>> anytime(1417411980, tz = 'PST')
> [1] "2014-12-01 05:33:00 GMT"
> Warning message:
> In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
>
>
> However it appears that R couldn't recognize the PST as the short form of
> Pacific time zone.
>
> Any help to correctly change Epoch time to corresponding pacific time would
> be helpful.
>
> Thanks,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jul  9 12:22:02 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 9 Jul 2018 15:52:02 +0530
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
Message-ID: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>

Hi,

Below is my code :

library(zoo)
Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
structure(c(1512664740,
1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
"POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
structure(c(1512664740,
1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
"POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")

merge(Dat1, Dat2)

                        Dat1     Dat2
2017-12-07 22:09:00 17890.00 15804.28
2017-12-07 22:10:00 17770.01 15720.61
2017-12-07 22:11:00 17600.00 15770.00
2017-12-07 22:12:00 17593.00 15750.00
2017-12-07 22:13:00 17630.01 15770.00


So, after merging the TZ of the original series got changed.

Appreciate if someone points what went wrong

	[[alternative HTML version deleted]]


From @tyen @ending from ntu@edu@tw  Mon Jul  9 12:18:38 2018
From: @tyen @ending from ntu@edu@tw (Steven Yen)
Date: Mon, 9 Jul 2018 18:18:38 +0800
Subject: [R] Package installation
Message-ID: <34d889c5-4748-2a29-df66-dfe5cd26eb04@ntu.edu.tw>

I have had trouble installing packages (e.g., car, aod) in some 
computers (such as computers in the student lab) but no problem in my 
own laptop.
Installation typically goes through, but after I got out and back in R 
(and RStudios), the error message says "packages xxx not available". 
That is, earlier installation of the packages did not stay (despite the 
successful installation message).
I went back as far as R3.0.3 and there is no problem.
Does this tell anyone what may be going on? Thanks.

-- 
styen at ntu.edu.tw  (S.T. Yen)


	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Mon Jul  9 13:58:26 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Mon, 9 Jul 2018 07:58:26 -0400
Subject: [R] Package installation
In-Reply-To: <34d889c5-4748-2a29-df66-dfe5cd26eb04@ntu.edu.tw>
References: <34d889c5-4748-2a29-df66-dfe5cd26eb04@ntu.edu.tw>
Message-ID: <5f65866d-784e-2379-9285-33043e1d9b81@gmail.com>

On 09/07/2018 6:18 AM, Steven Yen wrote:
> I have had trouble installing packages (e.g., car, aod) in some
> computers (such as computers in the student lab) but no problem in my
> own laptop.
> Installation typically goes through, but after I got out and back in R
> (and RStudios), the error message says "packages xxx not available".
> That is, earlier installation of the packages did not stay (despite the
> successful installation message).
> I went back as far as R3.0.3 and there is no problem.
> Does this tell anyone what may be going on? Thanks.
> 

The most common package installation problem in Windows is using 
different permissions to install R and the packages.  Typically R is 
installed as administrator, but the packages are not.  This means the 
packages can't be installed to the system library, so they get installed 
in a user's personal library, and the user probably may need to set 
.libPaths() explicitly to see them.

To check for this, print .libPaths() just after installing the packages, 
and again when starting a new session.  If the printed list of paths is 
different, you'll have problems.

Duncan Murdoch


From ericjberger @ending from gm@il@com  Mon Jul  9 14:19:50 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 9 Jul 2018 15:19:50 +0300
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
In-Reply-To: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
References: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
Message-ID: <CAGgJW75rsAfgadJQ4xnNRJ+Ar4z7Qk5VwTWtsCfc5XoSwHGy+Q@mail.gmail.com>

I found the following at
https://stackoverflow.com/questions/25269425/merge-zoo-removes-time-zone

library(xts)

merge2=function(x,y) {
  as.zoo(merge(as.xts(x), as.xts(y)))}

If you define the function merge2() as above then

merge2(Dat1,Dat2)

should be ok

HTH,
Eric


On Mon, Jul 9, 2018 at 1:22 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> Below is my code :
>
> library(zoo)
> Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
>
> merge(Dat1, Dat2)
>
>                         Dat1     Dat2
> 2017-12-07 22:09:00 17890.00 15804.28
> 2017-12-07 22:10:00 17770.01 15720.61
> 2017-12-07 22:11:00 17600.00 15770.00
> 2017-12-07 22:12:00 17593.00 15750.00
> 2017-12-07 22:13:00 17630.01 15770.00
>
>
> So, after merging the TZ of the original series got changed.
>
> Appreciate if someone points what went wrong
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jul  9 15:26:58 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 9 Jul 2018 18:56:58 +0530
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
In-Reply-To: <20180709103104.GA1199@albert.catwhisker.org>
References: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
 <20180709103104.GA1199@albert.catwhisker.org>
Message-ID: <CA+dpOJn-jEJR-1V4C+T=n1pOQJxRHtgPyNLCH=xjsjnRtF6S=w@mail.gmail.com>

My default is set as GMT.

On Mon, Jul 9, 2018 at 4:01 PM David Wolfskill <r at catwhisker.org> wrote:

> On Mon, Jul 09, 2018 at 03:52:02PM +0530, Christofer Bogaso wrote:
> > Hi,
> >
> > Below is my code :
> >
> > library(zoo)
> > Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
> > structure(c(1512664740,
> > 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> > "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> > Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
> > structure(c(1512664740,
> > 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> > "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> >
> > merge(Dat1, Dat2)
> >
> >                         Dat1     Dat2
> > 2017-12-07 22:09:00 17890.00 15804.28
> > 2017-12-07 22:10:00 17770.01 15720.61
> > 2017-12-07 22:11:00 17600.00 15770.00
> > 2017-12-07 22:12:00 17593.00 15750.00
> > 2017-12-07 22:13:00 17630.01 15770.00
> >
> >
> > So, after merging the TZ of the original series got changed.
> >
> > Appreciate if someone points what went wrong
> > ....
>
> Well... when I do the above, I see:
>
> > Dat1
> 2017-12-07 08:39:00 2017-12-07 08:40:00 2017-12-07 08:41:00 2017-12-07
> 08:42:00
>            17890.00            17770.01            17600.00
> 17593.00
> 2017-12-07 08:43:00
>            17630.01
> > Dat2
> 2017-12-07 08:39:00 2017-12-07 08:40:00 2017-12-07 08:41:00 2017-12-07
> 08:42:00
>            15804.28            15720.61            15770.00
> 15750.00
> 2017-12-07 08:43:00
>            15770.00
> > merge(Dat1, Dat2)
>
>                         Dat1     Dat2
> 2017-12-07 08:39:00 17890.00 15804.28
> 2017-12-07 08:40:00 17770.01 15720.61
> 2017-12-07 08:41:00 17600.00 15770.00
> 2017-12-07 08:42:00 17593.00 15750.00
> 2017-12-07 08:43:00 17630.01 15770.00
> >
>
> That said, one aspect that may be relevant:
> > Sys.timezone()
> [1] "America/Los_Angeles"
>
> What's yours?
>
>
> Peace,
> david
> --
> David H. Wolfskill                              r at catwhisker.org
> "Fly, Trump Baby!" -- only the biggest, YUGEST insults for Donald J. Trump!
>
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.
>

	[[alternative HTML version deleted]]


From luke@m@ng@li@o@dunc@n @ending from gm@il@com  Mon Jul  9 15:34:38 2018
From: luke@m@ng@li@o@dunc@n @ending from gm@il@com (Luke Duncan)
Date: Mon, 9 Jul 2018 15:34:38 +0200
Subject: [R] glmer won't allow quasi- distribution mixed models
Message-ID: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>

Dear R folk

I am trying to run a series of models on distance data for three different
species of animals. My data are not zero-inflated (distances were recorded
for locomotion only and so if the animal didn't move, it wasn't recorded)
and are Poisson distributed. However, all of the models that I run are
horrifically over-dispersed and based on what I read online I thought that
maybe I should consider using a quasi-Poisson distribution to attempt to
account for the over-dispersion. All the online posts of others show that
they do so successfully but for some reason, my lme4 package cannot use
quasi-distributions. I have uninstalled and reinstalled R and the packages
and I still get the same problem.

I am

a) at a loss as to how to deal with the over-dispersion I have and
b) baffled by the fact that lme4 everywhere else can cope with
quasi-distributions but mine can't.

Any help would be appreciated!

My code:

library(lme4)
woodlicedata<-read.csv("Woodlice.csv",header=T)
attach(woodlicedata)
names(woodlicedata)
> ### This set of models examine whether there are differences in distances
travelled.
>
distmodel<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=poisson(link='log'))
> summary(distmodel)  ### AIC= 42972.6
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
glmerMod]
 Family: poisson  ( log )
Formula: Distance ~ Treatment * Sex + (1 | ID) + (1 | Path.set/ID)

     AIC      BIC   logLik deviance df.resid
 42972.6  43007.3 -21479.3  42958.6     1038

Scaled residuals:
    Min      1Q  Median      3Q     Max
-11.853  -4.074  -1.656   2.146  38.035

Random effects:
 Groups      Name        Variance  Std.Dev.
 ID:Path.set (Intercept) 6.485e-02 0.2546560
 ID          (Intercept) 6.906e-02 0.2627973
 Path.set    (Intercept) 1.368e-10 0.0000117
Number of obs: 1045, groups:  ID:Path.set, 104; ID, 52; Path.set, 2

Fixed effects:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  4.20814    0.07757  54.248  < 2e-16 ***
TreatmentRestricted          0.10843    0.14359   0.755  0.45015
SexMale                     -0.08408    0.11545  -0.728  0.46644
TreatmentRestricted:SexMale -0.49300    0.18781  -2.625  0.00866 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) TrtmnR SexMal
TrtmntRstrc -0.540
SexMale     -0.672  0.363
TrtmntRs:SM  0.413 -0.765 -0.615

>
distmodel2<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=quasipoisson(link='log'))
Error in lme4::glFormula(formula = Distance ~ Treatment * Sex + (1 | ID) +
:
  "quasi" families cannot be used in glmer

	[[alternative HTML version deleted]]


From t@n@@@ @ending from gm@il@com  Mon Jul  9 16:09:18 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Mon, 9 Jul 2018 07:09:18 -0700
Subject: [R] about ECDF display in ggplot2
In-Reply-To: <alpine.BSF.2.00.1807090119280.18090@pedal.dcn.davis.ca.us>
References: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>
 <alpine.BSF.2.00.1807090119280.18090@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM02G=+6vExRCvN1+O5yL8VGKpuLP3SQRD6an8Ak5Z+YxsA@mail.gmail.com>

Dear Jeff,

thank you for all your time, and very precious help.

with best regards.

-- bogdan

On Mon, Jul 9, 2018 at 1:41 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Thank you for making the effort... but most attachments get stripped on
> the mailing list. Using the reprex package as I suggested and putting the
> result into the email is by far the safest approach. Since I received your
> email directly, I did get the attachments. Below is my reproducible
> example... to serve as an example for how you can get help from everyone on
> the list rather than just the few you are responding to.
>
> My summary comment is that you have to decide whether the LENGTH values
> greater than 500 are relevant... and if they are, you REALLY SHOULD create
> a data set that is limited in this fashion. Then you won't have to create
> "fake" axes, and you won't get ggplot warnings.
>
> Note: The reprex package allows you to confirm that the example is in fact
> reproducible, so technically it is not necessary to include the plot images
> in the question. However, reprex used to conveniently support putting the
> images on the imgur website, and for some reason it no longer does that, so
> just run the example interactively to see the graphs.
>
> #######
> ############################################################
> ############################################################
>
> library("ggplot2")
>
> # "file" is the name of a very fundamental function in base R. Re-using
> # that name for a data value is at best confusing to anyone reading your
> # code and at worst will prevent you from using that function.
> #file <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
>
> # Instead of giving us a file, keep the data within the example
> # DF <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
> # set.seed( 42 )
> # also shrink the size of the data for the example... we almost
> # never need all of it
> # dput( DF[ sample( seq.int( nrow( DF ) ), size = 200 ), , drop=FALSE ] )
> DF <- structure(list(LENGTH = c(6813L, 56035L, 123997L, 281L, 851L, 1072L,
>           72196L, 21L, 304L, 110L, 198L, 5922L, 283L, 199348L, 109L,
>           3317104L, 106L, 37642146L, 82641L, 20L, 125911L, 354L, 11625388L,
>           330L, 9811711L, 18L, 35L, 39897L, 27L, 277L, 79L, 2657L, 17L,
>           26L, 23L, 248L, 3634L, 21L, 324L, 206L, 328L, 42L, 286L,
> 6042409L,
>           24L, 36L, 2879L, 18L, 301L, 90684L, 4296636L, 43L, 1222L, 4536L,
>           3281L, 324L, 393L, 3754L, 98824541L, 459L, 18L, 1081L, 175L,
>           970L, 17L, 219L, 235558L, 1167315L, 25L, 623L, 2517515L, 32L,
>           217L, 29L, 17L, 1744L, 18L, 39L, 26L, 77L, 41L, 22L, 311L,
> 119015225L,
>           146413L, 22L, 19L, 301L, 373L, 2240L, 6439L, 128L, 18L, 257L,
>           783L, 5169L, 31608038L, 325L, 1533L, 25L, 69344L, 54L, 10651L,
>           31L, 335062L, 1854019L, 7153L, 38605567L, 51L, 23L, 16L, 301L,
>           79L, 313L, 18L, 29L, 39L, 22L, 17L, 306L, 67L, 280L, 324L, 158L,
>           93L, 2561L, 302L, 134578L, 328L, 9002L, 969051L, 34L, 20L, 309L,
>           355L, 28L, 9461327L, 18627013L, 305L, 64L, 18L, 2730L, 28L, 246L,
>           911L, 28L, 241483L, 154691L, 58891L, 55L, 456362L, 281L, 276L,
>           51L, 26L, 106821L, 313L, 78L, 29L, 400L, 61171382L, 200L, 101L,
>           220331L, 128L, 325L, 28L, 22L, 325L, 2330L, 5879L, 24L, 36L,
>           23L, 51L, 26L, 32584707L, 1672L, 13939L, 315L, 20L, 580785L,
>           42795L, 49193543L, 695L, 48568156L, 55634L, 207L, 318L, 22056L,
>           3670420L, 4815387L, 309L, 17L, 3143160L, 431L, 1164L, 33L, 5503L,
>           4166L)), .Names = "LENGTH", row.names = c(8283L, 8484L, 2591L,
>           7517L, 5808L, 4698L, 6665L, 1219L, 5944L, 6378L, 4140L, 6503L,
>           8452L, 2310L, 4180L, 8497L, 8842L, 1062L, 4293L, 5063L, 8168L,
>           1253L, 8932L, 8550L, 745L, 4643L, 3523L, 8177L, 4035L, 7545L,
>           6657L, 7319L, 3502L, 6181L, 36L, 7513L, 67L, 1873L, 8174L, 5516L,
>           3422L, 3928L, 338L, 8773L, 3891L, 8627L, 7997L, 5765L, 8745L,
>           5573L, 3003L, 3122L, 3588L, 7064L, 351L, 6739L, 6095L, 1541L,
>           2349L, 4628L, 6077L, 8839L, 6830L, 5094L, 7639L, 1704L, 2439L,
>           7443L, 6230L, 2162L, 387L, 1262L, 1944L, 4306L, 1773L, 6460L,
>           71L, 3371L, 4618L, 15L, 5220L, 1417L, 3222L, 5792L, 6960L, 5056L,
>           2096L, 807L, 768L, 2737L, 5983L, 3L, 1870L, 8361L, 8294L, 6577L,
>           2984L, 4614L, 6664L, 5545L, 5608L, 1945L, 1939L, 3482L, 8435L,
>           8615L, 6621L, 6561L, 4793L, 21L, 5447L, 7484L, 6721L, 4048L,
>           4790L, 4804L, 13L, 3179L, 5471L, 7407L, 3187L, 3669L, 5123L,
>           5267L, 6427L, 3527L, 8207L, 8593L, 2085L, 6467L, 8065L, 5385L,
>           5635L, 8363L, 7587L, 5172L, 7326L, 1015L, 6817L, 5560L, 1324L,
>           716L, 4136L, 6945L, 6536L, 7281L, 1516L, 8415L, 2616L, 1328L,
>           6406L, 2886L, 6933L, 3511L, 6040L, 6905L, 1672L, 259L, 1208L,
>           6051L, 8315L, 4896L, 5351L, 1752L, 4759L, 1597L, 4017L, 2818L,
>           1033L, 1654L, 6483L, 3659L, 3678L, 4266L, 3797L, 1212L, 7322L,
>           5258L, 7052L, 6826L, 8147L, 7655L, 2813L, 2300L, 6584L, 6629L,
>           8140L, 7034L, 1183L, 2551L, 1726L, 6950L, 1143L, 1144L, 641L,
>           471L, 4712L, 995L, 6582L, 6476L), class = "data.frame")
>
>
> ############################# display with PLOT FUNCTION:
>
>
> # saving files should be avoided in reproducible examples... especially
> files
> # that cannot be transmitted through the R-help mailing list such as pdf
> files
> #pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6, paper='special')
>
> # Your original plot commands below create a fake impression of the data by
> # falsifying the axes. If you really are only interested in data points
> less
> # than 500, you should be explicit about creating a data set containing
> only
> # such constrained values before plotting them.
> plot(ecdf(DF$LENGTH), xlab="DEL SIZE",
>                      ylab="fraction of DEL",
>                      main="LENGTH of DEL",
>                      xlim=c(0,500),
>                      col = "dark red", axes = FALSE)
> ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
> axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
> ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
> axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-1.png)
>
> # my recommendation
> DF500 <- subset( DF, LENGTH < 500 )
> plot( ecdf( DF500$LENGTH )
>     , xlab = "DEL SIZE"
>     , ylab = "fraction of DEL"
>     , main = "LENGTH of DEL"
>     , col = "dark red"
>     )
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-2.png)
>
> # alternatively
> plot( ecdf( DF$LENGTH )
>     , xlab = "DEL SIZE"
>     , ylab = "fraction of DEL"
>     , main = "LENGTH of DEL"
>     , col = "dark red"
>     , xlim=c( 1, 1e9 )
>     , log="x"
>     )
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-3.png)
>
>
>
> #dev.off()
>
> ############################# display in GGPLOT2 :
>
> BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
>            1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
>
> barfill <- "#4271AE"
> barlines <- "#1F3552"
>
> #pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
> paper='special')
>
> # ggplot's limits behavior is enabling your false representation of the
> data, but it
> # warns you of the data removal
> ggplot(DF, aes(LENGTH)) +
>           stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>           scale_x_continuous(name = "LENGTH of DEL",
>                              breaks = BREAKS,
>                              limits=c(0, 500)
>                              ) +
>           scale_y_continuous(name = "FRACTION") +
>           ggtitle("ECDF of LENGTH") +
>           theme_bw() +
>           theme(legend.position = "bottom", legend.direction =
> "horizontal",
>                legend.box = "horizontal",
>                legend.key.size = unit(1, "cm"),
>                axis.title = element_text(size = 12),
>                legend.text = element_text(size = 9),
>                legend.title=element_text(face = "bold", size = 9))
> #> Warning: Removed 80 rows containing non-finite values (stat_ecdf).
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-4.png)
>
>
> # my recommendation
> ggplot(DF500, aes(LENGTH)) +
>   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>   scale_x_continuous(name = "LENGTH of DEL",
>                      breaks = BREAKS ) +
>   scale_y_continuous(name = "FRACTION") +
>   ggtitle("ECDF of LENGTH") +
>   theme_bw() +
>   theme(legend.position = "bottom", legend.direction = "horizontal",
>         legend.box = "horizontal",
>         legend.key.size = unit(1, "cm"),
>         axis.title = element_text(size = 12),
>         legend.text = element_text(size = 9),
>         legend.title=element_text(face = "bold", size = 9))
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-5.png)
>
> # or for the un-filtered data
> ggplot(DF, aes(LENGTH)) +
>   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>   scale_x_log10( name = "LENGTH of DEL") +
>   scale_y_continuous(name = "FRACTION") +
>   ggtitle("ECDF of LENGTH") +
>   theme_bw() +
>   theme(legend.position = "bottom", legend.direction = "horizontal",
>         legend.box = "horizontal",
>         legend.key.size = unit(1, "cm"),
>         axis.title = element_text(size = 12),
>         legend.text = element_text(size = 9),
>         legend.title=element_text(face = "bold", size = 9))
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-6.png)
>
>
> #dev.off()
>
> #' Created on 2018-07-09 by the [reprex package](http://reprex.tidyver
> se.org) (v0.2.0).
> #######
>
>
> On Sun, 8 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Jeff,
>> thank you for your email.
>>
>> Yes, in order to be more descriptive/comprehensive, please find attached
>> to
>> my email the following files (my apologies ... I am sending these as
>> attachments, as I do not have a web server running at this moment) :
>>
>> -- the R script (R_script_display_ECDF.R) that reads the file "LENGTH" and
>> outputs ECDF figure by using the standard R function or ggplot2.
>>
>> -- the display of ECDF by using standard R function
>> ("display.R.ecdf.LENGTH.pdf")
>>
>> -- the display of ECDF by using ggplot2 ("display.ggplot2.ecdf.LENGTH.
>> pdf")
>>
>> The ECDF over xlim(0,500) looks very different (contrasting plot(ecdf) vs
>> ggplot2).  Please would you advise why ? what shall I change in my ggplot2
>> code ?
>>
>> thanks a lot,
>>
>> - bogdan
>>
>> ps : the R code is also written below :
>>
>>        library("ggplot2")
>>
>>
>>       file <- read.delim("LENGTH", sep="\t", header=T,
>>       stringsAsFactors=F)
>>
>>
>>       ############################# display with PLOT FUNCTION:
>>
>>
>>       pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6,
>>       paper='special')
>>
>>
>>       plot(ecdf(file$LENGTH), xlab="DEL SIZE",
>>                            ylab="fraction of DEL",
>>                            main="LENGTH of DEL",
>>                            xlim=c(0,500),
>>                            col = "dark red", axes = FALSE)
>>
>>
>>       ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
>>
>>
>>       axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
>>
>>
>>       ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
>>
>>
>>       axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
>>
>>
>>       dev.off()
>>
>>
>>       ############################# display in GGPLOT2 :
>>
>>
>>       BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
>>       400, 500,
>>                  1000, 10000, 100000, 1000000, 10000000, 100000000,
>>       1000000000)
>>
>>
>>       barfill <- "#4271AE"
>>       barlines <- "#1F3552"
>>
>>
>>       pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
>>       paper='special')
>>
>>
>>       ggplot(file, aes(LENGTH)) +
>>                 stat_ecdf(geom = "point", colour = barlines, fill =
>>       barfill) +
>>                 scale_x_continuous(name = "LENGTH of DEL",
>>                                    breaks = BREAKS,
>>                                    limits=c(0, 500)) +
>>                 scale_y_continuous(name = "FRACTION") +
>>                 ggtitle("ECDF of LENGTH") +
>>                 theme_bw() +
>>                 theme(legend.position = "bottom", legend.direction =
>>       "horizontal",
>>                      legend.box = "horizontal",
>>                      legend.key.size = unit(1, "cm"),
>>                      axis.title = element_text(size = 12),
>>                      legend.text = element_text(size = 9),
>>                      legend.title=element_text(face = "bold", size =
>>       9))
>>
>>
>>       dev.off()
>>
>>
>>
>>
>>
>>
>>
>> On Sat, Jul 7, 2018 at 9:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>       It is a feature of ggplot that points excluded by limits raise
>>       warnings, while base graphics do not.
>>
>>       You may find that using coord_cartesian with the xlim=c(0,500)
>>       argument works better with ggplot by showing the consequences of
>>       points out of the limits on lines within the viewport.
>>
>>       There are other possible problems with your data that your
>>       non-reproducible example does not show, and sending R code in
>>       HTML-formatted email usually corrupts it.. so please follow the
>>       recommendations in the Posting Guide next time you post.
>>
>>       On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
>>       wrote:
>>       >Dear all,
>>       >
>>       >I would appreciate having your advice/suggestions/comments on
>>       the
>>       >following
>>       >:
>>       >
>>       >1 -- starting from a vector that contains LENGTHS (numerically,
>>       the
>>       >values
>>       >are from 1 to 10 000)
>>       >
>>       >2 -- shall I display the ECDF by using the R code and some
>>       "limits" :
>>       >
>>       >BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>>       300, 400,
>>       >500,
>>       >         1000, 10000, 100000, 1000000, 10000000, 100000000,
>>       1000000000)
>>       >
>>       >ggplot(x, aes(LENGTH)) +
>>       >          stat_ecdf(geom = "point") +
>>       >          scale_x_continuous(name = "LENGTH of DEL",
>>       >                             breaks = BREAKS,
>>       >                             limits=c(0, 500))
>>       >
>>       >3 -- I am getting the following warning message : "Warning
>>       message:
>>       >Removed
>>       >109 rows containing non-finite values (stat_ecdf)."
>>       >
>>       >The question is : are these 109 values removed from
>>       VISUALIZATION as i
>>       >set
>>       >up the "limits", or are these 109 values removed from
>>       statistical
>>       >CALCULATION?
>>       >
>>       >4 -- in contrast, shall I use the standard R functions
>>       plot(ecdf),
>>       >there is
>>       >no "warning mesage"
>>       >
>>       >plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
>>       >                     ylab="Fraction of DEL", main="DEL",
>>       xlim=c(0,500),
>>       >                     col = "dark red")
>>       >
>>       >Thanks a lot !
>>       >
>>       >-- bogdan
>>       >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>>
>>
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Jul  9 16:25:33 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 9 Jul 2018 07:25:33 -0700
Subject: [R] glmer won't allow quasi- distribution mixed models
In-Reply-To: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>
References: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>
Message-ID: <CAGxFJbTxh=i6U6Y9AT0HThyp1Pkeoadrbk6KzFSoPz+y=1PEnA@mail.gmail.com>

You should probably post this on the r-sig-mixed-models list instead, where
you are more likely to find the expertise to diagnose the problem and give
you a helpful response.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 6:34 AM, Luke Duncan <luke.mangaliso.duncan at gmail.com
> wrote:

> Dear R folk
>
> I am trying to run a series of models on distance data for three different
> species of animals. My data are not zero-inflated (distances were recorded
> for locomotion only and so if the animal didn't move, it wasn't recorded)
> and are Poisson distributed. However, all of the models that I run are
> horrifically over-dispersed and based on what I read online I thought that
> maybe I should consider using a quasi-Poisson distribution to attempt to
> account for the over-dispersion. All the online posts of others show that
> they do so successfully but for some reason, my lme4 package cannot use
> quasi-distributions. I have uninstalled and reinstalled R and the packages
> and I still get the same problem.
>
> I am
>
> a) at a loss as to how to deal with the over-dispersion I have and
> b) baffled by the fact that lme4 everywhere else can cope with
> quasi-distributions but mine can't.
>
> Any help would be appreciated!
>
> My code:
>
> library(lme4)
> woodlicedata<-read.csv("Woodlice.csv",header=T)
> attach(woodlicedata)
> names(woodlicedata)
> > ### This set of models examine whether there are differences in distances
> travelled.
> >
> distmodel<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.
> set/ID),family=poisson(link='log'))
> > summary(distmodel)  ### AIC= 42972.6
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>  Family: poisson  ( log )
> Formula: Distance ~ Treatment * Sex + (1 | ID) + (1 | Path.set/ID)
>
>      AIC      BIC   logLik deviance df.resid
>  42972.6  43007.3 -21479.3  42958.6     1038
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -11.853  -4.074  -1.656   2.146  38.035
>
> Random effects:
>  Groups      Name        Variance  Std.Dev.
>  ID:Path.set (Intercept) 6.485e-02 0.2546560
>  ID          (Intercept) 6.906e-02 0.2627973
>  Path.set    (Intercept) 1.368e-10 0.0000117
> Number of obs: 1045, groups:  ID:Path.set, 104; ID, 52; Path.set, 2
>
> Fixed effects:
>                             Estimate Std. Error z value Pr(>|z|)
> (Intercept)                  4.20814    0.07757  54.248  < 2e-16 ***
> TreatmentRestricted          0.10843    0.14359   0.755  0.45015
> SexMale                     -0.08408    0.11545  -0.728  0.46644
> TreatmentRestricted:SexMale -0.49300    0.18781  -2.625  0.00866 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) TrtmnR SexMal
> TrtmntRstrc -0.540
> SexMale     -0.672  0.363
> TrtmntRs:SM  0.413 -0.765 -0.615
>
> >
> distmodel2<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.
> set/ID),family=quasipoisson(link='log'))
> Error in lme4::glFormula(formula = Distance ~ Treatment * Sex + (1 | ID) +
> :
>   "quasi" families cannot be used in glmer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kevin@thorpe @ending from utoronto@c@  Mon Jul  9 16:42:00 2018
From: kevin@thorpe @ending from utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 14:42:00 +0000
Subject: [R] Using write.csv as a connection for read.csv
Message-ID: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>

Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

  Error in read.table(file = file, header = header, sep = sep, quote = quote,  : 
  'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
     

From ericjberger @ending from gm@il@com  Mon Jul  9 16:51:38 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 9 Jul 2018 17:51:38 +0300
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>

Hi Kevin,
It's good that you provided the background to the problem.
Rather than asking this list to "debug" your proposed solution, I think you
would be better off showing some of the "corrupted" data frame and ask for
suggestions how to deal with it.
(Suggestions may or may not match your initial attempt.)
Can you output a piece of your suspect data frame via the dput() function
and post to the list?

Best,
Eric


On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Hi.
>
> I have some data frames I created previously that seem to not be working
> correctly anymore. I *think* the problem is that some of the variables in
> the data frame are of a type called labelled. There are other attributes in
> the data frame as well. I thought that the easiest way to fix this was to
> convert to, say a csv and re-load.
>
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
> the error
>
>   Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> I guess there must be a way to send the output of write.csv to a
> connection that read.csv can use but I was mystified by the help page on
> connections, at least I could not determine how to achieve my desired
> result.
>
> I realize I could write to a file and read it back in, but that feels
> klunky somehow. Maybe my approach to convert my data to strip the "weird"
> stuff is wrong-headed and I would accept alternative strategies.
>
> I would like a more general solution to fix this because I expect to
> encounter it some more. For those wondering how I found myself in such a
> mess, the data frames were initially imported from SAS data sets through
> the haven package. I then did some standard manipulation and added some
> additional labels with the upData() function from Hmisc (both packages have
> been updated since initial creation of the data frames).
>
> Thanks,
>
> Kevin
>
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kevin@thorpe @ending from utoronto@c@  Mon Jul  9 17:17:44 2018
From: kevin@thorpe @ending from utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 15:17:44 +0000
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>,
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
Message-ID: <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>

Although your suggestion to provide the data is excellent and one I typically agree with, they data are currently unpublished and so should not be publicly available. I have tried to make a reproducible example in the past (when similar looking things happened), but was unable to. Maybe I'll try a small subset and see if that works.


Kevin


--
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Monday, July 9, 2018 10:51:38 AM
To: Kevin Thorpe
Cc: R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv

Hi Kevin,
It's good that you provided the background to the problem.
Rather than asking this list to "debug" your proposed solution, I think you would be better off showing some of the "corrupted" data frame and ask for suggestions how to deal with it.
(Suggestions may or may not match your initial attempt.)
Can you output a piece of your suspect data frame via the dput() function and post to the list?

Best,
Eric


On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>> wrote:
Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

  Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
  'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin

--
 Kevin E. Thorpe
 Head of Biostatistics,  Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>  Tel: 416.864.5776  Fax: 416.864.3016


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Mon Jul  9 17:28:22 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 9 Jul 2018 15:28:22 +0000
Subject: [R] R couldnt recognize US Pasific timezome
In-Reply-To: <alpine.BSF.2.00.1807090142300.18090@pedal.dcn.davis.ca.us>
References: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>
 <alpine.BSF.2.00.1807090142300.18090@pedal.dcn.davis.ca.us>
Message-ID: <25DE78EF-69BD-46E5-887E-573EAAEC370C@llnl.gov>

Or (perhaps preferably) "US/Pacific" for daylight savings time support.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/9/18, 1:46 AM, "R-help on behalf of Jeff Newmiller" <r-help-bounces at r-project.org on behalf of jdnewmil at dcn.davis.ca.us> wrote:

    Several of the "conventional" three letter timezone abbreviations actually 
    get re-used in different parts of the world, and not all operating system 
    support for timezones include the same shortcuts. The solution is to use 
    the correct timezone string rather than your familiar shortcut... you can 
    look through the vector returned by the OlsonNames() function in general, 
    but in your case just use "Etc/GMT+8" for standard time year-round. If you 
    wanted daylight savings time support, you would use "America/Los_Angeles".
    
    On Mon, 9 Jul 2018, Christofer Bogaso wrote:
    
    > Hi,
    >
    > I wanted to convert Epoch time to readable time with US Pacific Time Zone
    > using 'anytime' package, as below:
    >
    >> library(anytime)
    >> anytime(1417411980, tz = 'PST')
    > [1] "2014-12-01 05:33:00 GMT"
    > Warning message:
    > In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
    >
    >
    > However it appears that R couldn't recognize the PST as the short form of
    > Pacific time zone.
    >
    > Any help to correctly change Epoch time to corresponding pacific time would
    > be helpful.
    >
    > Thanks,
    >
    > 	[[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >
    
    ---------------------------------------------------------------------------
    Jeff Newmiller                        The     .....       .....  Go Live...
    DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                           Live:   OO#.. Dead: OO#..  Playing
    Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
    /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Mon Jul  9 17:40:55 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 9 Jul 2018 08:40:55 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
 <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbSLaLA+-1a5kVnhR5VVtEqD=ayD_Oi5LRcAyNB=oQovWQ@mail.gmail.com>

Can you not anonymize column names, add random noise to some of the
columns, etc. ?

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 8:17 AM, Kevin Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Although your suggestion to provide the data is excellent and one I
> typically agree with, they data are currently unpublished and so should not
> be publicly available. I have tried to make a reproducible example in the
> past (when similar looking things happened), but was unable to. Maybe I'll
> try a small subset and see if that works.
>
>
> Kevin
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> ________________________________
> From: Eric Berger <ericjberger at gmail.com>
> Sent: Monday, July 9, 2018 10:51:38 AM
> To: Kevin Thorpe
> Cc: R Help Mailing List
> Subject: Re: [R] Using write.csv as a connection for read.csv
>
> Hi Kevin,
> It's good that you provided the background to the problem.
> Rather than asking this list to "debug" your proposed solution, I think
> you would be better off showing some of the "corrupted" data frame and ask
> for suggestions how to deal with it.
> (Suggestions may or may not match your initial attempt.)
> Can you output a piece of your suspect data frame via the dput() function
> and post to the list?
>
> Best,
> Eric
>
>
> On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<
> mailto:kevin.thorpe at utoronto.ca>> wrote:
> Hi.
>
> I have some data frames I created previously that seem to not be working
> correctly anymore. I *think* the problem is that some of the variables in
> the data frame are of a type called labelled. There are other attributes in
> the data frame as well. I thought that the easiest way to fix this was to
> convert to, say a csv and re-load.
>
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
> the error
>
>   Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> I guess there must be a way to send the output of write.csv to a
> connection that read.csv can use but I was mystified by the help page on
> connections, at least I could not determine how to achieve my desired
> result.
>
> I realize I could write to a file and read it back in, but that feels
> klunky somehow. Maybe my approach to convert my data to strip the "weird"
> stuff is wrong-headed and I would accept alternative strategies.
>
> I would like a more general solution to fix this because I expect to
> encounter it some more. For those wondering how I found myself in such a
> mess, the data frames were initially imported from SAS data sets through
> the haven package. I then did some standard manipulation and added some
> additional labels with the upData() function from Hmisc (both packages have
> been updated since initial creation of the data frames).
>
> Thanks,
>
> Kevin
>
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>  Tel:
> 416.864.5776  Fax: 416.864.3016
>
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kevin@thorpe @ending from utoronto@c@  Mon Jul  9 17:44:30 2018
From: kevin@thorpe @ending from utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 15:44:30 +0000
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>,
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>,
 <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <YTOPR0101MB1769B641DDBE4A716AD082E995440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>

So, after I sent the initial email I quit that R session entirely. When I started it again to try an provide the example data, the original (that I had a problem with before) is now behaving itself. Grrr.

Now no one is going to believe I ever had a problem with the data. :-)

  
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
     



From: R-help <r-help-bounces at r-project.org> on behalf of Kevin Thorpe <kevin.thorpe at utoronto.ca>
Sent: Monday, July 9, 2018 11:17 AM
To: Eric Berger
Cc: R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv
? 

Although your suggestion to provide the data is excellent and one I typically agree with, they data are currently unpublished and so should not be publicly available. I have tried to make a reproducible example in the past (when similar  looking things happened), but was unable to. Maybe I'll try a small subset and see if that works.


Kevin


--
Kevin E. Thorpe
Head of Biostatistics,? Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016

________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Monday, July 9, 2018 10:51:38 AM
To: Kevin Thorpe
Cc: R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv

Hi Kevin,
It's good that you provided the background to the problem.
Rather than asking this list to "debug" your proposed solution, I think you would be better off showing some of the "corrupted" data frame and ask for suggestions how to deal with it.
(Suggestions may or may not match your initial attempt.)
Can you output a piece of your suspect data frame via the dput() function and post to the list?

Best,
Eric


On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>> wrote:
Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought  that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

? Error in read.table(file = file, header = header, sep = sep, quote = quote,? :
? 'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard  manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin

--
?Kevin E. Thorpe
?Head of Biostatistics,? Applied Health Research Centre (AHRC)
?Li Ka Shing Knowledge Institute of St. Michael's
?Assistant Professor, Dalla Lana School of Public Health
?University of Toronto
?email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>? Tel: 416.864.5776? Fax: 416.864.3016


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    

From dwin@emiu@ @ending from comc@@t@net  Mon Jul  9 17:57:53 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Mon, 9 Jul 2018 08:57:53 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769B641DDBE4A716AD082E995440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
 <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
 <YTOPR0101MB1769B641DDBE4A716AD082E995440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <4019952C-A261-4356-B774-F10925581C6C@comcast.net>


> On Jul 9, 2018, at 8:44 AM, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
> 
> So, after I sent the initial email I quit that R session entirely. When I started it again to try an provide the example data, the original (that I had a problem with before) is now behaving itself. Grrr.
> 
> Now no one is going to believe I ever had a problem with the data. :-)

Your initial code looked flawed to me.

You were passing the result of write.csv (which returns NULL) to read.csv

Perhaps you modified your code and that's the reason it now succeeds.

Best,
David
> 
> 
> 
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> 
> 
> 
> 
> From: R-help <r-help-bounces at r-project.org> on behalf of Kevin Thorpe <kevin.thorpe at utoronto.ca>
> Sent: Monday, July 9, 2018 11:17 AM
> To: Eric Berger
> Cc: R Help Mailing List
> Subject: Re: [R] Using write.csv as a connection for read.csv
>   
> 
> Although your suggestion to provide the data is excellent and one I typically agree with, they data are currently unpublished and so should not be publicly available. I have tried to make a reproducible example in the past (when similar  looking things happened), but was unable to. Maybe I'll try a small subset and see if that works.
> 
> 
> Kevin
> 
> 
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> ________________________________
> From: Eric Berger <ericjberger at gmail.com>
> Sent: Monday, July 9, 2018 10:51:38 AM
> To: Kevin Thorpe
> Cc: R Help Mailing List
> Subject: Re: [R] Using write.csv as a connection for read.csv
> 
> Hi Kevin,
> It's good that you provided the background to the problem.
> Rather than asking this list to "debug" your proposed solution, I think you would be better off showing some of the "corrupted" data frame and ask for suggestions how to deal with it.
> (Suggestions may or may not match your initial attempt.)
> Can you output a piece of your suspect data frame via the dput() function and post to the list?
> 
> Best,
> Eric
> 
> 
> On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>> wrote:
> Hi.
> 
> I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought  that the easiest way to fix this was to convert to, say a csv and re-load.
> 
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error
> 
>   Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
>   'file' must be a character string or connection
> 
> I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.
> 
> I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.
> 
> I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard  manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).
> 
> Thanks,
> 
> Kevin
> 
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>  Tel: 416.864.5776  Fax: 416.864.3016
> 
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From wdunl@p @ending from tibco@com  Mon Jul  9 18:07:38 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 9 Jul 2018 09:07:38 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcZHQghg0-BfdUW3m=P=5+ON7y7MrZnj+NWBbrppAd3P5A@mail.gmail.com>

 >I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
the error
>
>  Error in read.table(file = file, header = header, sep = sep, quote =
quote,  :
>  'file' must be a character string or connection

To diagnose this without reading the help(write.csv) look at the return
value of write.csv:
  > df <- data.frame(Col1=1:3, Col2=LETTERS[24:26])
  > tmp <- write.csv(df, row.names=FALSE)
  "Col1","Col2"
  1,"X"
  2,"Y"
  3,"Z"
  > tmp
  NULL

read.csv complains about reading from NULL:
  > read.csv(NULL)
  Error in read.table(file = file, header = header, sep = sep, quote =
quote,  :
    'file' must be a character string or connection




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jul 9, 2018 at 7:42 AM, Kevin Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Hi.
>
> I have some data frames I created previously that seem to not be working
> correctly anymore. I *think* the problem is that some of the variables in
> the data frame are of a type called labelled. There are other attributes in
> the data frame as well. I thought that the easiest way to fix this was to
> convert to, say a csv and re-load.
>
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
> the error
>
>   Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> I guess there must be a way to send the output of write.csv to a
> connection that read.csv can use but I was mystified by the help page on
> connections, at least I could not determine how to achieve my desired
> result.
>
> I realize I could write to a file and read it back in, but that feels
> klunky somehow. Maybe my approach to convert my data to strip the "weird"
> stuff is wrong-headed and I would accept alternative strategies.
>
> I would like a more general solution to fix this because I expect to
> encounter it some more. For those wondering how I found myself in such a
> mess, the data frames were initially imported from SAS data sets through
> the haven package. I then did some standard manipulation and added some
> additional labels with the upData() function from Hmisc (both packages have
> been updated since initial creation of the data frames).
>
> Thanks,
>
> Kevin
>
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jul  9 19:01:24 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Jul 2018 10:01:24 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <B365845E-56B0-40FF-8ED2-94D0AD303B90@dcn.davis.ca.us>

TL;DR: If you want to do this, go ahead and use a temporary file or text connection.

Others have pointed out that write.csv returns NULL rather than a file connection, but I haven't seen comments on your impulse to avoid the use of files.

*nix operating systems are admirably efficient with multitasking... such that shells can efficiently run multiple programs connected by pipes, pausing the producers to pause if they get ahead of the consumers and resuming them if the consumers run out of data, thus minimizing the amount of temporary disk space usage.

R does not presume this to be among the fundamental capabilities of the operating system, rather assuming single tasking capability by default. This means that even if you do connect write.csv to a pipe then it will run to completion before read.csv gets a chance to process any of the data. MSDOS used to simulate command line program chaining by writing all the data to a temporary file before running the consumer program. R is similar... and like MSDOS there is little reason to avoid temporary files in R.

set.seed( 42 )
DF <- data.frame( X=1:100, Y=rnorm( 100 ) )
frame <- tempfile()
write.csv( DF, file=fname, row.names=FALSE )
DF2 <- read.csv( file=fname )
all.equal( DF$X, DF2$X ) && all.equal( DF$Y, DF2$Y )
unlink( fname )


On July 9, 2018 7:42:00 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>Hi.
>
>I have some data frames I created previously that seem to not be
>working correctly anymore. I *think* the problem is that some of the
>variables in the data frame are of a type called labelled. There are
>other attributes in the data frame as well. I thought that the easiest
>way to fix this was to convert to, say a csv and re-load.
>
>I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
>the error
>
>Error in read.table(file = file, header = header, sep = sep, quote =
>quote,  : 
>  'file' must be a character string or connection
>
>I guess there must be a way to send the output of write.csv to a
>connection that read.csv can use but I was mystified by the help page
>on connections, at least I could not determine how to achieve my
>desired result.
>
>I realize I could write to a file and read it back in, but that feels
>klunky somehow. Maybe my approach to convert my data to strip the
>"weird" stuff is wrong-headed and I would accept alternative
>strategies.
>
>I would like a more general solution to fix this because I expect to
>encounter it some more. For those wondering how I found myself in such
>a mess, the data frames were initially imported from SAS data sets
>through the haven package. I then did some standard manipulation and
>added some additional labels with the upData() function from Hmisc
>(both packages have been updated since initial creation of the data
>frames).
>
>Thanks,
>
>Kevin
> 
>--
> Kevin E. Thorpe
> Head of Biostatistics,? Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
> 
>     
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kevin@thorpe @ending from utoronto@c@  Mon Jul  9 19:14:20 2018
From: kevin@thorpe @ending from utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 17:14:20 +0000
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <B365845E-56B0-40FF-8ED2-94D0AD303B90@dcn.davis.ca.us>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>,
 <B365845E-56B0-40FF-8ED2-94D0AD303B90@dcn.davis.ca.us>
Message-ID: <YTOPR0101MB1769C82E3B1CF5E0E3610A0C95440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>


Thanks Jeff and all others.

I will need to use the tempfile route I guess (I'm running in a Linux OS) for the time-being.

After I re-loaded the data frames that were broken before and they seemed fine, after using them for awhile they broke again.

I am trying to build my analysis with rmarkdown and tools. I have not been able to determine (yet) exactly what set of interactions are "breaking" things. I certainly don't expect the list to debug everything I'm doing.

The only thing is can say is that there appears to be some weird interaction between SAS data sets imported by haven and other packages. Note that I encountered (I think) related issues with an imported data set when I tried working with it in the tidyverse.

Maybe I'm getting too old to learn new stuff. :-)

Sorry I am not being much help with my own problem. I just have not been able to determine where things break. If can come up with a reproducible example that reliably breaks, I'll post it.

Kevin
  
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
     



From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Monday, July 9, 2018 1:01 PM
To: r-help at r-project.org; Kevin Thorpe; R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv
? 

TL;DR: If you want to do this, go ahead and use a temporary file or text connection.

Others have pointed out that write.csv returns NULL rather than a file connection, but I haven't seen comments on your impulse to avoid the use of files.

*nix operating systems are admirably efficient with multitasking... such that shells can efficiently run multiple programs connected by pipes, pausing the producers to pause if they get ahead of the consumers and resuming them if the consumers run out of data,  thus minimizing the amount of temporary disk space usage.

R does not presume this to be among the fundamental capabilities of the operating system, rather assuming single tasking capability by default. This means that even if you do connect write.csv to a pipe then it will run to completion before read.csv gets a  chance to process any of the data. MSDOS used to simulate command line program chaining by writing all the data to a temporary file before running the consumer program. R is similar... and like MSDOS there is little reason to avoid temporary files in R.

set.seed( 42 )
DF <- data.frame( X=1:100, Y=rnorm( 100 ) )
frame <- tempfile()
write.csv( DF, file=fname, row.names=FALSE )
DF2 <- read.csv( file=fname )
all.equal( DF$X, DF2$X ) && all.equal( DF$Y, DF2$Y )
unlink( fname )


On July 9, 2018 7:42:00 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>Hi.
>
>I have some data frames I created previously that seem to not be
>working correctly anymore. I *think* the problem is that some of the
>variables in the data frame are of a type called labelled. There are
>other attributes in the data frame as well. I thought that the easiest
>way to fix this was to convert to, say a csv and re-load.
>
>I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
>the error
>
>Error in read.table(file = file, header = header, sep = sep, quote =
>quote,? : 
>? 'file' must be a character string or connection
>
>I guess there must be a way to send the output of write.csv to a
>connection that read.csv can use but I was mystified by the help page
>on connections, at least I could not determine how to achieve my
>desired result.
>
>I realize I could write to a file and read it back in, but that feels
>klunky somehow. Maybe my approach to convert my data to strip the
>"weird" stuff is wrong-headed and I would accept alternative
>strategies.
>
>I would like a more general solution to fix this because I expect to
>encounter it some more. For those wondering how I found myself in such
>a mess, the data frames were initially imported from SAS data sets
>through the haven package. I then did some standard manipulation and
>added some additional labels with the upData() function from Hmisc
>(both packages have been updated since initial creation of the data
>frames).
>
>Thanks,
>
>Kevin
> 
>--
> Kevin E. Thorpe
> Head of Biostatistics,? Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
> 
>???? 
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.
    

From l@ur@@@teel @ending from m@gd@ox@@c@uk  Mon Jul  9 14:13:22 2018
From: l@ur@@@teel @ending from m@gd@ox@@c@uk (Laura Steel)
Date: Mon, 9 Jul 2018 12:13:22 +0000
Subject: [R] (no subject)
Message-ID: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>

I am a beginner to R and I need to map some Atlantic puffin migration routes
onto a map of the Northern Hemisphere. I have a latitude and longitude point
per bird, per day. I would like to be able to plot the routes of all my
birds on one map and ideally so that I can see at which date they are at
each location.

This is a shortened version of my data for one bird only.

Bird             Date              Latitude     Longitude
eb80976 16/07/2012      50.99   -5.85
eb80976 17/07/2012      52.09   -4.58
eb80976 18/07/2012      49.72   -5.56
eb80976 19/07/2012      51.59   -3.17
eb80976 20/07/2012      52.45   -2.03
eb80976 21/07/2012      56.015  -10.51

Any help would be much appreciated. I am not totally sure where to start!
Many thanks.


	[[alternative HTML version deleted]]


From polingwh @ending from y@hoo@com  Mon Jul  9 16:50:57 2018
From: polingwh @ending from y@hoo@com (William Poling, Ph.D., MPH)
Date: Mon, 9 Jul 2018 14:50:57 +0000 (UTC)
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <1911323376.1318967.1531147857428@mail.yahoo.com>

 Hi Kevin.
Maybe?
setwd("C:/RPractice")

write_csv(yourfile, path = "yourfile.csv")
yourfile <- read.csv("yourfile.csv")
HTH
WHP
    On Monday, July 9, 2018, 10:42:24 AM EDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:  
 
 Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

? Error in read.table(file = file, header = header, sep = sep, quote = quote,? : 
? 'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
? ? 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From interzone @ending from gm@il@com  Mon Jul  9 20:03:29 2018
From: interzone @ending from gm@il@com (Dylan Distasio)
Date: Mon, 9 Jul 2018 14:03:29 -0400
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CAJrqPH-CiQOR56vQXUDc=-QSPBFaBRaF131gixuhsSFVxk3iiw@mail.gmail.com>

You'll probably get a more detailed reply from someone with more expertise,
but have you looked at something like what this article proposes:

https://medium.com/fastah-project/a-quick-start-to-maps-in-r-b9f221f44ff3

On Mon, Jul 9, 2018 at 1:53 PM Laura Steel <laura.steel at magd.ox.ac.uk>
wrote:

> I am a beginner to R and I need to map some Atlantic puffin migration
> routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude
> point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Jul  9 20:43:49 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 9 Jul 2018 11:43:49 -0700
Subject: [R] (no subject)
In-Reply-To: <CAJrqPH-CiQOR56vQXUDc=-QSPBFaBRaF131gixuhsSFVxk3iiw@mail.gmail.com>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
 <CAJrqPH-CiQOR56vQXUDc=-QSPBFaBRaF131gixuhsSFVxk3iiw@mail.gmail.com>
Message-ID: <CAGxFJbQ8DJ5+fidsBa3XjR+i09QnT60xJNm5NYFzx3=8CDjMuA@mail.gmail.com>

Laura:

1. We generally do not do code for you; we expect you to show your efforts
first.

2. You might want to post this on the r-sig-geo list instead. They
specialize in such issues, so that you are more likely to find helpful
advice there.

3. There are many good R tutorials on the web. e.g. see here:
https://www.rstudio.com/online-learning/
As a "beginner," if you have not already done so, you should avail yourself
of them before posting further.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 11:03 AM, Dylan Distasio <interzone at gmail.com> wrote:

> You'll probably get a more detailed reply from someone with more expertise,
> but have you looked at something like what this article proposes:
>
> https://medium.com/fastah-project/a-quick-start-to-maps-in-r-b9f221f44ff3
>
> On Mon, Jul 9, 2018 at 1:53 PM Laura Steel <laura.steel at magd.ox.ac.uk>
> wrote:
>
> > I am a beginner to R and I need to map some Atlantic puffin migration
> > routes
> > onto a map of the Northern Hemisphere. I have a latitude and longitude
> > point
> > per bird, per day. I would like to be able to plot the routes of all my
> > birds on one map and ideally so that I can see at which date they are at
> > each location.
> >
> > This is a shortened version of my data for one bird only.
> >
> > Bird             Date              Latitude     Longitude
> > eb80976 16/07/2012      50.99   -5.85
> > eb80976 17/07/2012      52.09   -4.58
> > eb80976 18/07/2012      49.72   -5.56
> > eb80976 19/07/2012      51.59   -3.17
> > eb80976 20/07/2012      52.45   -2.03
> > eb80976 21/07/2012      56.015  -10.51
> >
> > Any help would be much appreciated. I am not totally sure where to start!
> > Many thanks.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h@@@n@diw@n @ending from gm@il@com  Mon Jul  9 21:40:15 2018
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Mon, 9 Jul 2018 12:40:15 -0700
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CAP+bYWBPgxFL_H5ba-L=hXWOhq=5qzW6m134MHsJ9h=27Y_HVg@mail.gmail.com>

https://imgur.com/a/0f72Fsz results from the following code:

ggplot()+borders("world", colour="gray50",
fill="gray50")+geom_line(aes(x=Longitude, y=Latitude), birds)

It's ugly, but it will give you a starting point. -- H
On Mon, 9 Jul 2018 at 10:53, Laura Steel <laura.steel at magd.ox.ac.uk> wrote:
>
> I am a beginner to R and I need to map some Atlantic puffin migration routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable


From J@n-Philipp@Werning @ending from whu@edu  Mon Jul  9 21:42:21 2018
From: J@n-Philipp@Werning @ending from whu@edu (Werning, Jan-Philipp)
Date: Mon, 9 Jul 2018 19:42:21 +0000
Subject: [R] (no subject)
Message-ID: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>

Dear all,


In the end I try to run a system dynamics simulation in R using the package deSolve.
Therefore I need an auxiliary list (auxs) the model can refer to when it the functions need an auxiliary value.

I used a manual list:

auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0 , aSplitLR2=1, aSplitSR3=0 , aSplitLR3=1, aSalesNR=0.92, aSalesRR=0.08, [?])

this way everything worked well.

Now I want to use a matrix with different values for each of the auxiliaries in order to run different scenarios. Therefore I created a csv document wich I read in:

csv1  <- read.csv("180713_Taguchi Robust Design Test_180709_1745.csv", sep = ";")

list_csv <- csv1[1,]

namesauxs <- names(list_csv)

 auxs1 <- as.numeric(list_csv)

 names(auxs1) <- namesauxs

 auxs <- auxs1


Looking at the global environment section in R studio, now both are the same, in the value section as "Numed num"

Yet, the model will not run using these values ultimately coming from the csv.

What am I doing wrong here?

It would be great if you could help.

Thanks a lot in advance

Yours

Jan





	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jul  9 22:25:18 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Jul 2018 13:25:18 -0700
Subject: [R] (no subject)
In-Reply-To: <CAP+bYWBPgxFL_H5ba-L=hXWOhq=5qzW6m134MHsJ9h=27Y_HVg@mail.gmail.com>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
 <CAP+bYWBPgxFL_H5ba-L=hXWOhq=5qzW6m134MHsJ9h=27Y_HVg@mail.gmail.com>
Message-ID: <B95556C7-4CEB-4467-B8B7-1CAABD20E04E@dcn.davis.ca.us>

perhaps geom_path rather than geom_line?

On July 9, 2018 12:40:15 PM PDT, Hasan Diwan <hasan.diwan at gmail.com> wrote:
>https://imgur.com/a/0f72Fsz results from the following code:
>
>ggplot()+borders("world", colour="gray50",
>fill="gray50")+geom_line(aes(x=Longitude, y=Latitude), birds)
>
>It's ugly, but it will give you a starting point. -- H
>On Mon, 9 Jul 2018 at 10:53, Laura Steel <laura.steel at magd.ox.ac.uk>
>wrote:
>>
>> I am a beginner to R and I need to map some Atlantic puffin migration
>routes
>> onto a map of the Northern Hemisphere. I have a latitude and
>longitude point
>> per bird, per day. I would like to be able to plot the routes of all
>my
>> birds on one map and ideally so that I can see at which date they are
>at
>> each location.
>>
>> This is a shortened version of my data for one bird only.
>>
>> Bird             Date              Latitude     Longitude
>> eb80976 16/07/2012      50.99   -5.85
>> eb80976 17/07/2012      52.09   -4.58
>> eb80976 18/07/2012      49.72   -5.56
>> eb80976 19/07/2012      51.59   -3.17
>> eb80976 20/07/2012      52.45   -2.03
>> eb80976 21/07/2012      56.015  -10.51
>>
>> Any help would be much appreciated. I am not totally sure where to
>start!
>> Many thanks.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @-dh@r @ending from northwe@tern@edu  Mon Jul  9 23:35:22 2018
From: @-dh@r @ending from northwe@tern@edu (Sumitrajit Dhar)
Date: Mon, 9 Jul 2018 21:35:22 +0000
Subject: [R] Something simple not working in group_by
Message-ID: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>

Hi Folks,

I am trying to get a group_by cumsum using:

R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

Here is an example of a simple construct that is not working.

m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )

m %>% group_by(id) %>% mutate(total = cumsum(score))

My output:

# A tibble: 6 x 3
# Groups:   id [3]
     id score total
  <int> <dbl> <dbl>
1     1     6     6
2     1     6    12
3     2     6    18
4     2     3    21
5     3     3    24
6     3     3    27

What am I missing? Thanks in advance.

Regards,
Sumit


From @@5505 @ending from cumc@columbi@@edu  Mon Jul  9 23:39:44 2018
From: @@5505 @ending from cumc@columbi@@edu (Sariya, Sanjeev)
Date: Mon, 9 Jul 2018 21:39:44 +0000
Subject: [R] Something simple not working in group_by
In-Reply-To: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
Message-ID: <BYAPR02MB4917A89C554BA4224779E12681440@BYAPR02MB4917.namprd02.prod.outlook.com>

Strange. Worked fine on:

R version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Commands:

m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )

as.data.frame(m %>% group_by(id) %>% mutate(total = cumsum(score)))

  id score total
1  1     6     6
2  1     6    12
3  2     6     6
4  2     3     9
5  3     3     3
6  3     3     6

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sumitrajit Dhar
Sent: Monday, July 9, 2018 5:35 PM
To: r-help at r-project.org
Subject: [R] Something simple not working in group_by

Hi Folks,

I am trying to get a group_by cumsum using:

R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

Here is an example of a simple construct that is not working.

m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )

m %>% group_by(id) %>% mutate(total = cumsum(score))

My output:

# A tibble: 6 x 3
# Groups:   id [3]
     id score total
  <int> <dbl> <dbl>
1     1     6     6
2     1     6    12
3     2     6    18
4     2     3    21
5     3     3    24
6     3     3    27

What am I missing? Thanks in advance.

Regards,
Sumit


From drjimlemon @ending from gm@il@com  Tue Jul 10 00:12:33 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 10 Jul 2018 08:12:33 +1000
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CA+8X3fX3arijdsXzHUXtGoWCtAY1DWgm6Eh_8F9Lgc8vtp0uGA@mail.gmail.com>

Hi Laura,
Here's a basic method:

lsdf<-read.table(text="Bird Date Latitude Longitude
eb80976 16/07/2012      50.99   -5.85
eb80976 17/07/2012      52.09   -4.58
eb80976 18/07/2012      49.72   -5.56
eb80976 19/07/2012      51.59   -3.17
eb80976 20/07/2012      52.45   -2.03
eb80976 21/07/2012      56.015  -10.51",
header=TRUE)
library(maps)
map("world",xlim=c(-20,10),ylim=c(45,60))
mtext(side=3,cex=1.5,text="Migration of puffin eb80976",line=2)
lines(lsdf$Longitude,lsdf$Latitude)
library(plotrix)
boxed.labels(lsdf$Longitude,lsdf$Latitude,lsdf$Date,border="white",cex=0.7)
box()
axis(1)
axis(2)

Jim


On Mon, Jul 9, 2018 at 10:13 PM, Laura Steel <laura.steel at magd.ox.ac.uk> wrote:
> I am a beginner to R and I need to map some Atlantic puffin migration routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Tue Jul 10 00:32:31 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 9 Jul 2018 15:32:31 -0700
Subject: [R] Something simple not working in group_by
In-Reply-To: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
Message-ID: <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>

Dunno.

But if I understand correctly, here's a base R way to do it:

(## using your m)

> m$total <- with(m,ave(score,id,FUN = cumsum))
> m
  id score total
1  1     6     6
2  1     6    12
3  2     6     6
4  2     3     9
5  3     3     3
6  3     3     6

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 2:35 PM, Sumitrajit Dhar <s-dhar at northwestern.edu>
wrote:

> Hi Folks,
>
> I am trying to get a group_by cumsum using:
>
> R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>
> Here is an example of a simple construct that is not working.
>
> m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )
>
> m %>% group_by(id) %>% mutate(total = cumsum(score))
>
> My output:
>
> # A tibble: 6 x 3
> # Groups:   id [3]
>      id score total
>   <int> <dbl> <dbl>
> 1     1     6     6
> 2     1     6    12
> 3     2     6    18
> 4     2     3    21
> 5     3     3    24
> 6     3     3    27
>
> What am I missing? Thanks in advance.
>
> Regards,
> Sumit
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From bh@@k@r@kolk@t@ @ending from gm@il@com  Tue Jul 10 00:35:01 2018
From: bh@@k@r@kolk@t@ @ending from gm@il@com (Bhaskar Mitra)
Date: Mon, 9 Jul 2018 17:35:01 -0500
Subject: [R] Help with creating subset of a data frame
Message-ID: <CAEGXkYWGyMdVaE9P8OvSYVqNyPOK21wYWY0sHEPo950gWM32ag@mail.gmail.com>

Hello Everyone,

I am trying to create a subset of a data frame (df1) based on the first
three
unique values in the first column (v1).

Here are my codes:

b <- unique(df1$v1)[1:3]
df2 <- subset(df1,df1$v1==b)

df1:
v1   v2    v3
1     a    b
1     a1   b1
2     a2   b2
2     a3   b3
3     a4   b4
3     a5   b5
3     a6   b6
4     a7   b7
4     a8   b8
4     a9   b9
5     a10  b10
5     a11  b11
5     a12  b12
5     a13  b13


Ideally, I want my new dataframe (df2) to look something like this:


df2:
v1   v2    v3
1     a    b
1     a1   b1
2     a2   b2
2     a3   b3
3     a4   b4
3     a5   b5
3     a6   b6



However, that doesn't seem to be the case and i am getting the following
warning message:

Warning message:
In df1$v1==b :  longer object length is not a multiple of shorter object
length


I would appreciate any help in this regard,

sincerely,
bhaskar

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Tue Jul 10 05:32:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 9 Jul 2018 20:32:09 -0700
Subject: [R] Help with creating subset of a data frame
In-Reply-To: <CAEGXkYWGyMdVaE9P8OvSYVqNyPOK21wYWY0sHEPo950gWM32ag@mail.gmail.com>
References: <CAEGXkYWGyMdVaE9P8OvSYVqNyPOK21wYWY0sHEPo950gWM32ag@mail.gmail.com>
Message-ID: <CAGxFJbQJkVTPqHZHRU+N8+wNn1a9bsvyEqqEXa1q5Jhr+r-N5Q@mail.gmail.com>

%in%  instead of ==

?"%in%"

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 3:35 PM, Bhaskar Mitra <bhaskar.kolkata at gmail.com>
wrote:

> Hello Everyone,
>
> I am trying to create a subset of a data frame (df1) based on the first
> three
> unique values in the first column (v1).
>
> Here are my codes:
>
> b <- unique(df1$v1)[1:3]
> df2 <- subset(df1,df1$v1==b)
>
> df1:
> v1   v2    v3
> 1     a    b
> 1     a1   b1
> 2     a2   b2
> 2     a3   b3
> 3     a4   b4
> 3     a5   b5
> 3     a6   b6
> 4     a7   b7
> 4     a8   b8
> 4     a9   b9
> 5     a10  b10
> 5     a11  b11
> 5     a12  b12
> 5     a13  b13
>
>
> Ideally, I want my new dataframe (df2) to look something like this:
>
>
> df2:
> v1   v2    v3
> 1     a    b
> 1     a1   b1
> 2     a2   b2
> 2     a3   b3
> 3     a4   b4
> 3     a5   b5
> 3     a6   b6
>
>
>
> However, that doesn't seem to be the case and i am getting the following
> warning message:
>
> Warning message:
> In df1$v1==b :  longer object length is not a multiple of shorter object
> length
>
>
> I would appreciate any help in this regard,
>
> sincerely,
> bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Tue Jul 10 09:00:55 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 10 Jul 2018 07:00:55 +0000
Subject: [R] (no subject)
In-Reply-To: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>
References: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>
Message-ID: <dcbc725d62bc438ba8bbcf508fc7632f@SRVEXCHCM1302.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Werning, Jan-
> Philipp
> Sent: Monday, July 9, 2018 9:42 PM
> To: r-help at r-project.org
> Subject: [R] (no subject)
>
> Dear all,
>
>
> In the end I try to run a system dynamics simulation in R using the package
> deSolve.
> Therefore I need an auxiliary list (auxs) the model can refer to when it the
> functions need an auxiliary value.
>
> I used a manual list:
>
> auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0 ,
> aSplitLR2=1, aSplitSR3=0 , aSplitLR3=1, aSalesNR=0.92, aSalesRR=0.08, [?])

This is vector not list.
> auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0)
> is.vector(auxs)
[1] TRUE
> is.list(auxs)
[1] FALSE
>
>
> this way everything worked well.
>
> Now I want to use a matrix with different values for each of the auxiliaries in
> order to run different scenarios. Therefore I created a csv document wich I read
> in:
>
> csv1  <- read.csv("180713_Taguchi Robust Design Test_180709_1745.csv", sep
> = ";")
>
> list_csv <- csv1[1,]

which is probably data frame

> test<-vec[1,]
> is.vector(test)
[1] FALSE
> is.list(test)
[1] TRUE
> is.data.frame(test)
[1] TRUE
>

>
> namesauxs <- names(list_csv)
>
>  auxs1 <- as.numeric(list_csv)
>
>  names(auxs1) <- namesauxs
>
>  auxs <- auxs1
>
>
> Looking at the global environment section in R studio, now both are the same,
> in the value section as "Numed num"

I do not know rstudio but you could check two objects by
?identical

>
> Yet, the model will not run using these values ultimately coming from the csv.

I wonder why do you use as.numeric in the first instance. You coud use

auxs1 <- unlist(csv1[1,])
and you should get named numeric vector. Maybe there are problems when reading numbers from csv file. You could check it e.g. by

str(auxs1)

>
> What am I doing wrong here?
>
> It would be great if you could help.
>
> Thanks a lot in advance
>
> Yours
>
> Jan
>
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From ericjberger @ending from gm@il@com  Tue Jul 10 09:48:13 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Tue, 10 Jul 2018 10:48:13 +0300
Subject: [R] Something simple not working in group_by
In-Reply-To: <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
 <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>
Message-ID: <CAGgJW77UBLakM80qb9BfzxctttaOAz7-kku4eGFSQJ-3n2fQ9g@mail.gmail.com>

Hi Sumit,
I was not able to reproduce this problem.
I tried it in both R 3.5.1 and R 3.4.4.
Both gave the expected output (which differs from yours.)

Eric


On Tue, Jul 10, 2018 at 1:32 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Dunno.
>
> But if I understand correctly, here's a base R way to do it:
>
> (## using your m)
>
> > m$total <- with(m,ave(score,id,FUN = cumsum))
> > m
>   id score total
> 1  1     6     6
> 2  1     6    12
> 3  2     6     6
> 4  2     3     9
> 5  3     3     3
> 6  3     3     6
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jul 9, 2018 at 2:35 PM, Sumitrajit Dhar <s-dhar at northwestern.edu>
> wrote:
>
> > Hi Folks,
> >
> > I am trying to get a group_by cumsum using:
> >
> > R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> > Copyright (C) 2018 The R Foundation for Statistical Computing
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> >
> > Here is an example of a simple construct that is not working.
> >
> > m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )
> >
> > m %>% group_by(id) %>% mutate(total = cumsum(score))
> >
> > My output:
> >
> > # A tibble: 6 x 3
> > # Groups:   id [3]
> >      id score total
> >   <int> <dbl> <dbl>
> > 1     1     6     6
> > 2     1     6    12
> > 3     2     6    18
> > 4     2     3    21
> > 5     3     3    24
> > 6     3     3    27
> >
> > What am I missing? Thanks in advance.
> >
> > Regards,
> > Sumit
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From J@n-Philipp@Werning @ending from whu@edu  Tue Jul 10 11:50:28 2018
From: J@n-Philipp@Werning @ending from whu@edu (Werning, Jan-Philipp)
Date: Tue, 10 Jul 2018 09:50:28 +0000
Subject: [R] (no subject)
In-Reply-To: <dcbc725d62bc438ba8bbcf508fc7632f@SRVEXCHCM1302.precheza.cz>
References: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>
 <dcbc725d62bc438ba8bbcf508fc7632f@SRVEXCHCM1302.precheza.cz>
Message-ID: <8048C6BF-3BE2-42E0-AFB8-BA718F213364@whu.edu>


Hi,

thanks a lot! Now it works.

Yours

Jan

Am 10.07.2018 um 09:00 schrieb PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>:

Hi

see in line

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Werning, Jan-
Philipp
Sent: Monday, July 9, 2018 9:42 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] (no subject)

Dear all,


In the end I try to run a system dynamics simulation in R using the package
deSolve.
Therefore I need an auxiliary list (auxs) the model can refer to when it the
functions need an auxiliary value.

I used a manual list:

auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0 ,
aSplitLR2=1, aSplitSR3=0 , aSplitLR3=1, aSalesNR=0.92, aSalesRR=0.08, [?])

This is vector not list.
auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0)
is.vector(auxs)
[1] TRUE
is.list(auxs)
[1] FALSE


this way everything worked well.

Now I want to use a matrix with different values for each of the auxiliaries in
order to run different scenarios. Therefore I created a csv document wich I read
in:

csv1  <- read.csv("180713_Taguchi Robust Design Test_180709_1745.csv", sep
= ";")

list_csv <- csv1[1,]

which is probably data frame

test<-vec[1,]
is.vector(test)
[1] FALSE
is.list(test)
[1] TRUE
is.data.frame(test)
[1] TRUE



namesauxs <- names(list_csv)

auxs1 <- as.numeric(list_csv)

names(auxs1) <- namesauxs

auxs <- auxs1


Looking at the global environment section in R studio, now both are the same,
in the value section as "Numed num"

I do not know rstudio but you could check two objects by
?identical


Yet, the model will not run using these values ultimately coming from the csv.

I wonder why do you use as.numeric in the first instance. You coud use

auxs1 <- unlist(csv1[1,])
and you should get named numeric vector. Maybe there are problems when reading numbers from csv file. You could check it e.g. by

str(auxs1)


What am I doing wrong here?

It would be great if you could help.

Thanks a lot in advance

Yours

Jan





[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/



	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Tue Jul 10 13:43:17 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Tue, 10 Jul 2018 11:43:17 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>,
 <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
Message-ID: <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I've gone through debug(update.snlcqn)  (update.snlcqn is the above function) and  I think the problem lies in read_excel returning a tibble...any suggestions on how to convert it to a regular data frame? Any other packages that read xls files as a regular data frame?

Very many thanks for your time and effort....
Yours sincerely,
AKSHAY M KULKARNI

________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Monday, July 9, 2018 12:15 PM
To: PIKAL Petr
Cc: akshay kulkarni; R help Mailing list
Subject: Re: [R] inconsistency in display of character vector....

>  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

??

Why not just always return snicqna ?


On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

You definitely should not use HTML formated mail. This is plain text mailing list for reason.

If you experience space between "NSE/" and pasted second part, you should read paste help page which states

paste (..., sep = " ", collapse = NULL)

so it has space as separator.

You should use paste0 if you want to get rid of separating space or axplicitely state
paste (..., sep = "")

> lneq <- c()
> for (i in 1:10) lneq[i] <- letters[i]
> lneq
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> snlcqna<-LETTERS[1:10]
> for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> snlcqna
 [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/ h"
 [9] "NSE/ i" "NSE/ j"
> for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> snlcqna
 [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h" "NSE/i"
[10] "NSE/j"

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of akshay
> kulkarni
> Sent: Sunday, July 8, 2018 2:38 PM
> To: R help Mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Fw: inconsistency in display of character vector....
>
> dear members,
>                              The mail is not showing the spaces between [192]
> "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces
[[elided Hotmail spam]]
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> on behalf of akshay kulkarni
> <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
>
> dear members,
>                             I have the following code to update the list of stocks:
>
> function (snlcqn)
> {
>                   lneq <- c()
>                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                   file.string <- tempfile()
>
>                   download.file(URL,file.string)
>
>                   IDT <- read_excel(file.string)
>
>                   leq <- IDT[,1]
>
>                   for(i in 1:length(leq)){
>                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
>
>                   for(j in 1:length(lneq)){
>                   snlcqna[j] <- paste("NSE/",lneq[j])}
>
>                   if(identical(snlcqn,snlcqna) == "FALSE"){
>                   return(snlcqna)                         }
>
>                   else                                    {
>                   return(snlcqn)                          }
>
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list,
> is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS
> instance):
>
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
>
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Tue Jul 10 13:57:43 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Tue, 10 Jul 2018 14:57:43 +0300
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>
 <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
 <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW76eB-PfY=+nj-KmJ5zbRfpkD+dGg8ZiNL=GUuvAggjORA@mail.gmail.com>

Hi Akshay,
Package "openxlsx" has function read.xlsx() which returns a data frame.

HTH,
Eric


On Tue, Jul 10, 2018 at 2:43 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                              I've gone through debug(update.snlcqn)
> (update.snlcqn is the above function) and  I think the problem lies in
> read_excel returning a tibble...any suggestions on how to convert it to a
> regular data frame? Any other packages that read xls files as a regular
> data frame?
>
> Very many thanks for your time and effort....
> Yours sincerely,
> AKSHAY M KULKARNI
>
> ------------------------------
> *From:* Eric Berger <ericjberger at gmail.com>
> *Sent:* Monday, July 9, 2018 12:15 PM
> *To:* PIKAL Petr
> *Cc:* akshay kulkarni; R help Mailing list
> *Subject:* Re: [R] inconsistency in display of character vector....
>
> >  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna
>
> ??
>
> Why not just always return snicqna ?
>
>
> On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> You definitely should not use HTML formated mail. This is plain text
> mailing list for reason.
>
> If you experience space between "NSE/" and pasted second part, you should
> read paste help page which states
>
> paste (..., sep = " ", collapse = NULL)
>
> so it has space as separator.
>
> You should use paste0 if you want to get rid of separating space or
> axplicitely state
> paste (..., sep = "")
>
> > lneq <- c()
> > for (i in 1:10) lneq[i] <- letters[i]
> > lneq
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> > snlcqna<-LETTERS[1:10]
> > for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/
> h"
>  [9] "NSE/ i" "NSE/ j"
> > for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h"
> "NSE/i"
> [10] "NSE/j"
>
> Cheers
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady
> -ochrany-osobnich-udaju/ | Information about processing and protection of
> business partner's personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of akshay
> > kulkarni
> > Sent: Sunday, July 8, 2018 2:38 PM
> > To: R help Mailing list <r-help at r-project.org>
> > Subject: [R] Fw: inconsistency in display of character vector....
> >
> > dear members,
> >                              The mail is not showing the spaces between
> [192]
> > "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty
> spaces
> > between the two.....!!!!!!
> >
> > ________________________________________
> > From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni
> > <akshay_e4 at hotmail.com>
> > Sent: Sunday, July 8, 2018 5:58 PM
> > To: R help Mailing  list
> > Subject: [R] inconsistency in display of character vector....
> >
> > dear members,
> >                             I have the following code to update the list
> of stocks:
> >
> > function (snlcqn)
> > {
> >                   lneq <- c()
> >                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
> >                   file.string <- tempfile()
> >
> >                   download.file(URL,file.string)
> >
> >                   IDT <- read_excel(file.string)
> >
> >                   leq <- IDT[,1]
> >
> >                   for(i in 1:length(leq)){
> >                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> >
> >                   for(j in 1:length(lneq)){
> >                   snlcqna[j] <- paste("NSE/",lneq[j])}
> >
> >                   if(identical(snlcqn,snlcqna) == "FALSE"){
> >                   return(snlcqna)                         }
> >
> >                   else                                    {
> >                   return(snlcqn)                          }
> >
> > }
> > snlcqn is the list of present stocks and snlcqna is the list of updated
> stocks.
> > The problem is the return object, instead of getting displayed in
> contiguous list,
> > is getting displayed with lots of spaces...( I am using R on a LINUX
> RHEL AWS
> > instance):
> >
> > [192] "NSE/YESBANK"
> > [193] "NSE/ZEEL"
> >
> > Why is this happening? How can I get the return object as a contiguous
> list?
> > Very many thanks for your time and effort...
> > yours sincerely,
> > AKSHAY M KULKARNI
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From @-dh@r @ending from northwe@tern@edu  Tue Jul 10 14:00:47 2018
From: @-dh@r @ending from northwe@tern@edu (Sumitrajit Dhar)
Date: Tue, 10 Jul 2018 12:00:47 +0000
Subject: [R] Something simple not working in group_by
In-Reply-To: <1ae329a5df6947a399481c8c2c0f7ab3@CHCSPMBX01.ads.northwestern.edu>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
 <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>
 <1ae329a5df6947a399481c8c2c0f7ab3@CHCSPMBX01.ads.northwestern.edu>
Message-ID: <601C2B86-E861-47D4-A9EC-83EB15951483@northwestern.edu>

Hello everyone,

I figured it out late last night. I was loading both dplyr and plyr and that was causing the problem. Loading plyr after dplyr leads to the faulty behavior. Just loading dplyr gives you expected behavior. Sorry for the confusion and false alarm.

Regards,
Sumit

> On Jul 10, 2018, at 2:48 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
> Hi Sumit,
> I was not able to reproduce this problem.
> I tried it in both R 3.5.1 and R 3.4.4. 
> Both gave the expected output (which differs from yours.)
> 
> Eric
> 
> 
> On Tue, Jul 10, 2018 at 1:32 AM, Bert Gunter <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
> Dunno.
> 
> But if I understand correctly, here's a base R way to do it:
> 
> (## using your m)
> 
> > m$total <- with(m,ave(score,id,FUN = cumsum))
> > m
>   id score total
> 1  1     6     6
> 2  1     6    12
> 3  2     6     6
> 4  2     3     9
> 5  3     3     3
> 6  3     3     6
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Jul 9, 2018 at 2:35 PM, Sumitrajit Dhar <s-dhar at northwestern.edu <mailto:s-dhar at northwestern.edu>>
> wrote:
> 
> > Hi Folks,
> >
> > I am trying to get a group_by cumsum using:
> >
> > R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> > Copyright (C) 2018 The R Foundation for Statistical Computing
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> >
> > Here is an example of a simple construct that is not working.
> >
> > m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )
> >
> > m %>% group_by(id) %>% mutate(total = cumsum(score))
> >
> > My output:
> >
> > # A tibble: 6 x 3
> > # Groups:   id [3]
> >      id score total
> >   <int> <dbl> <dbl>
> > 1     1     6     6
> > 2     1     6    12
> > 3     2     6    18
> > 4     2     3    21
> > 5     3     3    24
> > 6     3     3    27
> >
> > What am I missing? Thanks in advance.
> >
> > Regards,
> > Sumit
> >
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=r1iXOeVerM13vY8SJ43KMMSjoveKXYTCmHk2uqE9jwI&e=>
> > PLEASE do read the posting guide http://www.R-project.org/ <https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=Qs4zmrgW7sXjofqwf0VQmV1M7Slw3pS6Mv_TpLYipqQ&e=>
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=r1iXOeVerM13vY8SJ43KMMSjoveKXYTCmHk2uqE9jwI&e=>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=ZJbUb--ZGIsJv2dCTON31rOiQ-MQEv3DU1ZrWM_scss&e=>
> and provide commented, minimal, self-contained, reproducible code.
> 


From petr@pik@l @ending from prechez@@cz  Tue Jul 10 14:01:47 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 10 Jul 2018 12:01:47 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>,
 <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
 <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <6b8f36fd288c49fcac8f50586f4bd88c@SRVEXCHCM1302.precheza.cz>

Hi

What about

dat<-as.data.frame(tibble.dat)

Cheers
Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

From: akshay kulkarni [mailto:akshay_e4 at hotmail.com]
Sent: Tuesday, July 10, 2018 1:43 PM
To: Eric Berger <ericjberger at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz>
Cc: R help Mailing list <r-help at r-project.org>
Subject: Re: [R] inconsistency in display of character vector....

dear members,
                             I've gone through debug(update.snlcqn)  (update.snlcqn is the above function) and  I think the problem lies in read_excel returning a tibble...any suggestions on how to convert it to a regular data frame? Any other packages that read xls files as a regular data frame?

Very many thanks for your time and effort....
Yours sincerely,
AKSHAY M KULKARNI

________________________________
From: Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>>
Sent: Monday, July 9, 2018 12:15 PM
To: PIKAL Petr
Cc: akshay kulkarni; R help Mailing list
Subject: Re: [R] inconsistency in display of character vector....

>  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

??

Why not just always return snicqna ?


On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

You definitely should not use HTML formated mail. This is plain text mailing list for reason.

If you experience space between "NSE/" and pasted second part, you should read paste help page which states

paste (..., sep = " ", collapse = NULL)

so it has space as separator.

You should use paste0 if you want to get rid of separating space or axplicitely state
paste (..., sep = "")

> lneq <- c()
> for (i in 1:10) lneq[i] <- letters[i]
> lneq
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> snlcqna<-LETTERS[1:10]
> for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> snlcqna
 [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/ h"
 [9] "NSE/ i" "NSE/ j"
> for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> snlcqna
 [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h" "NSE/i"
[10] "NSE/j"

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of akshay
> kulkarni
> Sent: Sunday, July 8, 2018 2:38 PM
> To: R help Mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Fw: inconsistency in display of character vector....
>
> dear members,
>                              The mail is not showing the spaces between [192]
> "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces
> between the two.....!!!!!!
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> on behalf of akshay kulkarni
> <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
>
> dear members,
>                             I have the following code to update the list of stocks:
>
> function (snlcqn)
> {
>                   lneq <- c()
>                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                   file.string <- tempfile()
>
>                   download.file(URL,file.string)
>
>                   IDT <- read_excel(file.string)
>
>                   leq <- IDT[,1]
>
>                   for(i in 1:length(leq)){
>                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
>
>                   for(j in 1:length(lneq)){
>                   snlcqna[j] <- paste("NSE/",lneq[j])}
>
>                   if(identical(snlcqn,snlcqna) == "FALSE"){
>                   return(snlcqna)                         }
>
>                   else                                    {
>                   return(snlcqn)                          }
>
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list,
> is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS
> instance):
>
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
>
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @ggp@@ergei @ending from gm@il@com  Tue Jul 10 12:31:09 2018
From: @ggp@@ergei @ending from gm@il@com (Sergei Ko)
Date: Tue, 10 Jul 2018 11:31:09 +0100
Subject: [R] select.list cuts results to 100 characters on Win 10 when
 graphics = TRUE
Message-ID: <CAK2fHGfh8+0hW-dXxoEbbZUub5zeD+Nzzc8J=UwVB_X7NB_kHA@mail.gmail.com>

mstring1 <- c("123456789012345678901234567890123456789012345678901234567890
123456789012345678901234567890123456789012345678901234567890")

mstring2 <- c("123456789012345678901234567890123456789012345678901234567890
1234567890123456789012345678901234567890123456789012345678901234567890")


vec.in <- c(mstring1,mstring2)



res1 <- select.list(vec.in, graphics = TRUE)

res2 <- select.list(vec.in, graphics = FALSE)



nchar(res1)

nchar(res2)



platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          5.0
year           2018
month          04
day            23
svn rev        74626
language       R
version.string R version 3.5.0 (2018-04-23)
nickname       Joy in Playing

	[[alternative HTML version deleted]]


From d@vid@mi @ending from micro@oft@com  Wed Jul 11 01:19:49 2018
From: d@vid@mi @ending from micro@oft@com (David Smith (CDA))
Date: Tue, 10 Jul 2018 23:19:49 +0000
Subject: [R] Revolutions blog: June 2018 roundup
Message-ID: <DM5PR2101MB1048045C4E623807D8799465C85B0@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of June:

An animated visualization of global migration, created in R by Guy Abel:
http://blog.revolutionanalytics.com/2018/06/global-migration-animated-with-r.html

My take on the question, Should you learn R or Python for data science?
http://blog.revolutionanalytics.com/2018/06/python-or-r.html

The BBC and Financial Times use R -- without post-processing -- for publication
graphics: http://blog.revolutionanalytics.com/2018/06/ft-bbc-uses-r.html

"Handling Strings in R", a free e-book by Gaston Sanchez, has been updated:
http://blog.revolutionanalytics.com/2018/06/handling-strings-with-r.html

My AI, Machine Learning and Data Science roundup for June 2018:
http://blog.revolutionanalytics.com/2018/06/ai-roundup-june-2018.html

The PYPL Popularity of Languages Index ranks R as the 7th most popular
programming language: 
http://blog.revolutionanalytics.com/2018/06/pypl-programming-language-trends.html

The "lime" package provides tools for interpreting machine learning models in R:
http://blog.revolutionanalytics.com/2018/06/lime-package.html

An R vignette by Paige Bailey on detecting unconscious bias in predictive
models: http://blog.revolutionanalytics.com/2018/06/understanding-bias.html

Microsoft R Open 3.5.0 has been released
http://blog.revolutionanalytics.com/2018/06/microsoft-r-open-350-now-available.html
(with a subsequent fix for Debian systems:
http://blog.revolutionanalytics.com/2018/06/hotfix-for-mro-350-on-linux.html)

Slides from the webinar, What's New in Azure for Machine Learning and AI:
http://blog.revolutionanalytics.com/2018/06/whats-new-in-azure-for-machine-learning-and-ai.html

And some general interest stories (not necessarily related to R):

* The Curvature Blindness Illusion:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-wavy-lines.html

* Lioness v Wrestlers in tug-of-war:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-the-lioness-sleeps-tonight.html

* A comedian imagines an AI writing a TV commercial:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-olive-garden.html

* A fur seal, transcribed:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-sealese.html

* An architecture error and a near-disaster in NYC:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-buildings-shake.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From nell@redu @ending from hotm@il@fr  Wed Jul 11 02:11:19 2018
From: nell@redu @ending from hotm@il@fr (Nelly Reduan)
Date: Wed, 11 Jul 2018 00:11:19 +0000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>,
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
Message-ID: <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>

Thank you very much for your reply.


By omitting the probability, the expected results could be:


c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)


c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)


If I omit the probability, I would like to generate N random positive integers that sum to M and the integers would be selected from a uniform distribution.


Many thanks for your time

Nell


________________________________
De : Rolf Turner <r.turner at auckland.ac.nz>
Envoy? : mercredi 4 juillet 2018 16:11:11
? : Nelly Reduan
Cc : r-help at r-project.org
Objet : Re: [R] Generate N random numbers with a given probability and condition


On 05/07/18 10:21, Nelly Reduan wrote:

> Dear all,
>
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
>
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
>
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time.

Your thinking requires considerable clarification.

(1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.

(2) Hence length(seq(0,10,1)) is 11.

(3) Likewise max(seq(0,10,1)) is 10.

(4) Your prob vector is *constant* --- so specifying "prob" makes
     no difference --- the result is the same as if you omitted "prob".

(5) You need to think carefully about what you really mean by "random".
     In what way do you want the final result to be "random"?

I expect that the lecturer who assigned this problem to you  needs to
clarify his/her thinking as well.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Wed Jul 11 02:46:17 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Wed, 11 Jul 2018 10:46:17 +1000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>

Hi Nell,
I may not have the right idea about this, but I think you need to do
this in two steps if it can be done. Let's say you want a sequence of
20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
the monotonically increasing sequences like this:

c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
...
c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)

So if you select one of these sequences at random, there will be a
further set of sequences that are permutations of it. By randomly
selecting one of those permutations, I think you can solve your
problem. However, this is going to be computationally intensive, with
the set of permutations being very large for large N. Here is an
example using N = M = 5:

# enumerate the sequences = M
rs5<-list(c(1,1,1,1,1),c(0,1,1,1,2),c(0,0,1,1,3),c(0,0,0,1,4),
 c(0,0,1,2,2),c(0,0,0,2,3),c(0,0,0,0,5))
library(crank)
# generate the permutations for one sequence (120 in this case)
rs5_s1<-permute(rs5[[sample(1:length(rs5),1)]])
# select one of the permutations at random
rs5_s1[sample(1:dim(rs5_s1)[1],1),]
[1] 4 0 1 0 0

Jim

On Wed, Jul 11, 2018 at 10:11 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Thank you very much for your reply.
>
>
> By omitting the probability, the expected results could be:
>
>
> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>
>
> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>
>
> If I omit the probability, I would like to generate N random positive integers that sum to M and the integers would be selected from a uniform distribution.
>
>
> Many thanks for your time
>
> Nell
>
>
> ________________________________
> De : Rolf Turner <r.turner at auckland.ac.nz>
> Envoy? : mercredi 4 juillet 2018 16:11:11
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Generate N random numbers with a given probability and condition
>
>
> On 05/07/18 10:21, Nelly Reduan wrote:
>
>> Dear all,
>>
>> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
>> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
>>
>> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
>>
>> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>> Many thanks for your time.
>
> Your thinking requires considerable clarification.
>
> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>
> (2) Hence length(seq(0,10,1)) is 11.
>
> (3) Likewise max(seq(0,10,1)) is 10.
>
> (4) Your prob vector is *constant* --- so specifying "prob" makes
>      no difference --- the result is the same as if you omitted "prob".
>
> (5) You need to think carefully about what you really mean by "random".
>      In what way do you want the final result to be "random"?
>
> I expect that the lecturer who assigned this problem to you  needs to
> clarify his/her thinking as well.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @ending from gm@il@com  Wed Jul 11 03:44:37 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 10 Jul 2018 18:44:37 -0700
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbQE8hZ0OxS8FWqKb_mOhP1NKxXyds2wdG7h7xweX1L_aQ@mail.gmail.com>

You need to heed Rolf's advice.

N random integers by definition cannot have a fixed sum.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 10, 2018 at 5:11 PM, Nelly Reduan <nell.redu at hotmail.fr> wrote:

> Thank you very much for your reply.
>
>
> By omitting the probability, the expected results could be:
>
>
> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>
>
> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>
>
> If I omit the probability, I would like to generate N random positive
> integers that sum to M and the integers would be selected from a uniform
> distribution.
>
>
> Many thanks for your time
>
> Nell
>
>
> ________________________________
> De : Rolf Turner <r.turner at auckland.ac.nz>
> Envoy? : mercredi 4 juillet 2018 16:11:11
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Generate N random numbers with a given probability and
> condition
>
>
> On 05/07/18 10:21, Nelly Reduan wrote:
>
> > Dear all,
> >
> > I would like to generate N random numbers with a given probability and
> condition but I'm not sure how to do this.
> > For example, I have N = 20 and the vector from which to choose is seq(0,
> 10, 1). I have tested:
> >
> > x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28,
> times=length(seq(0, 10, 1))))
> >
> > But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> > Many thanks for your time.
>
> Your thinking requires considerable clarification.
>
> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>
> (2) Hence length(seq(0,10,1)) is 11.
>
> (3) Likewise max(seq(0,10,1)) is 10.
>
> (4) Your prob vector is *constant* --- so specifying "prob" makes
>      no difference --- the result is the same as if you omitted "prob".
>
> (5) You need to think carefully about what you really mean by "random".
>      In what way do you want the final result to be "random"?
>
> I expect that the lecturer who assigned this problem to you  needs to
> clarify his/her thinking as well.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dulc@lm@ @ending from bigpond@com  Wed Jul 11 06:04:11 2018
From: dulc@lm@ @ending from bigpond@com (Duncan Mackay)
Date: Wed, 11 Jul 2018 14:04:11 +1000
Subject: [R] ASExtras library
In-Reply-To: <MAXPR0101MB17851D0974DC6B6A28A868C4CB410@MAXPR0101MB1785.INDPRD01.PROD.OUTLOOK.COM>
References: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>,
 <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>
 <MAXPR0101MB17851D0974DC6B6A28A868C4CB410@MAXPR0101MB1785.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <000301d418cc$399247f0$acb6d7d0$@bigpond.com>

Hi

I was trying to find a file on my computer when the ASReml directory showed
up on the directory tree. 

The ASExtras may be part of the R interface/standalone of ASReml available
in Splus as well.
I think the interface to Splus came first

>From what I can remember ASReml R extra packages had a different name than
ASExtras. Is it the Splus distributed package name?
There is an asremlPlus package that is still valid 

Regards

Duncan 

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of radmuzom .
Sent: Thursday, 5 July 2018 07:34
To: David Winsemius; Mehrshad Barary; r-help at r-project.org
Subject: Re: [R] ASExtras library

The package appears to be referenced in the package "agridat" -
ftp://cran.r-project.org/pub/R/web/packages/agridat/agridat.pdf (Pg 55).
However, even I tried searching for it and there seems to be no reference
other than this source.

Regards,
radmuzom

From: R-help <r-help-bounces at r-project.org> on behalf of David Winsemius
<dwinsemius at comcast.net>
Sent: Wednesday, July 4, 2018 9:22 PM
To: Mehrshad Barary
Cc: r-help at r-project.org
Subject: Re: [R] ASExtras library
? 


> On Jul 3, 2018, at 6:34 PM, Mehrshad Barary <bararym at gmail.com> wrote:
> 
> Hi Everyone,
> 
> Does anybody know how I can get ASExtras library?

It would be helpful if you would provide information about your reasons for
assuming this package's existence. Cannot find it in CRAN (including a
search for 'ASExtra'), BioConductor, GitHub, or the Archives, or even with
Google for that matter.

https://cran.r-project.org/src/contrib/Archive/

And within R parlance 'library' not a synonym for 'package'. Libraries are
where you store packages. And `library('pkg_name')` is a command for loading
a package.


> Thanks
> Mehrshad
> 
> -- 
> Mehrshad Barary
> Senior Lecturer in Crop Ecophysiology
> Department of Agronomy and Plant Breeding
> Faculty of Agriculture
> Ilam University
> Tel: (+98)8412227019-21
> Fax: (+98)8412227015
> 
>??????? [[alternative HTML version deleted]]

And R help is a plain-text mailing list. Please read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'??
-Gehm's Corollary to Clarke's Third Law

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Wed Jul 11 12:23:35 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Wed, 11 Jul 2018 22:23:35 +1200
Subject: [R] 
 [FORGED] Re: Generate N random numbers with a given probability
 and condition
In-Reply-To: <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>
Message-ID: <fe13c2df-99f1-b7f3-3120-013024c79b48@auckland.ac.nz>

On 11/07/18 12:46, Jim Lemon wrote:
> Hi Nell,
> I may not have the right idea about this, but I think you need to do
> this in two steps if it can be done. Let's say you want a sequence of
> 20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
> the monotonically increasing sequences like this:
> 
> c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
> c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
> ...
> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)

<SNIP>

Jim:  You should *not* do people's homework for them!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bori@@@teipe @ending from utoronto@c@  Wed Jul 11 12:53:59 2018
From: bori@@@teipe @ending from utoronto@c@ (Boris Steipe)
Date: Wed, 11 Jul 2018 06:53:59 -0400
Subject: [R] 
 [FORGED] Re: Generate N random numbers with a given probability
 and condition
In-Reply-To: <fe13c2df-99f1-b7f3-3120-013024c79b48@auckland.ac.nz>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>
 <fe13c2df-99f1-b7f3-3120-013024c79b48@auckland.ac.nz>
Message-ID: <9674C150-BF6D-4C63-A06B-0F389E5DD874@utoronto.ca>

Wasn't there also the requirement that the numbers be drawn from a uniform distribution? These sequences are not. I wonder whether this can for all practical purposes be simplified to consider only the sequence with maximum entropy.

B.




> On 2018-07-11, at 06:23, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 11/07/18 12:46, Jim Lemon wrote:
>> Hi Nell,
>> I may not have the right idea about this, but I think you need to do
>> this in two steps if it can be done. Let's say you want a sequence of
>> 20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
>> the monotonically increasing sequences like this:
>> c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
>> c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
>> ...
>> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)
> 
> <SNIP>
> 
> Jim:  You should *not* do people's homework for them!
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@cqueen1 @ending from llnl@gov  Wed Jul 11 16:43:35 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 11 Jul 2018 14:43:35 +0000
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <AF7FD38F-5775-47CE-B464-675A82551DC3@llnl.gov>

Maybe I missed it, but I didn't see anyone suggest a visit to the CRAN Spatial task view. This would be a good place to start learning how to work with spatial data in R.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/9/18, 5:13 AM, "R-help on behalf of Laura Steel" <r-help-bounces at r-project.org on behalf of laura.steel at magd.ox.ac.uk> wrote:

    I am a beginner to R and I need to map some Atlantic puffin migration routes
    onto a map of the Northern Hemisphere. I have a latitude and longitude point
    per bird, per day. I would like to be able to plot the routes of all my
    birds on one map and ideally so that I can see at which date they are at
    each location.
    
    This is a shortened version of my data for one bird only.
    
    Bird             Date              Latitude     Longitude
    eb80976 16/07/2012      50.99   -5.85
    eb80976 17/07/2012      52.09   -4.58
    eb80976 18/07/2012      49.72   -5.56
    eb80976 19/07/2012      51.59   -3.17
    eb80976 20/07/2012      52.45   -2.03
    eb80976 21/07/2012      56.015  -10.51
    
    Any help would be much appreciated. I am not totally sure where to start!
    Many thanks.
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From nell@redu @ending from hotm@il@fr  Wed Jul 11 19:14:49 2018
From: nell@redu @ending from hotm@il@fr (Nelly Reduan)
Date: Wed, 11 Jul 2018 17:14:49 +0000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <CA+8X3fV2USjzQE4Sh7ssAsJof=eNtBP74j38TqVisUuCD7+fvg@mail.gmail.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>,
 <CA+8X3fV2USjzQE4Sh7ssAsJof=eNtBP74j38TqVisUuCD7+fvg@mail.gmail.com>
Message-ID: <DM5PR05MB2793345795F3B490E78839B2995A0@DM5PR05MB2793.namprd05.prod.outlook.com>

Many thanks Jim for your help. I am trying to apply the permutations with a sequence of 20 but I obtain the error message:


Error in matrix(NA, nrow = nrows, ncol = lenx) :
  invalid 'nrow' value (too large or NA)
In addition: Warning message:
In matrix(NA, nrow = nrows, ncol = lenx) :
  NAs introduced by coercion to integer range


Here is the code:

library(partitions)
library(crank)
r <- t(restrictedparts(10, 20))
r <- split(r, seq(nrow(r)))
rp <- crank::permute(r[[sample(1:length(r), 1)]])
rp[sample(1:dim(rp)[1],1),]


In this case, Is it correct to permute the elements of a vector rather than to permute a vector ?


Many thanks for your time.

Have a nice day

Nell


________________________________
De : Jim Lemon <drjimlemon at gmail.com>
Envoy? : mardi 10 juillet 2018 17:44:13
? : Nelly Reduan
Objet : Re: [R] Generate N random numbers with a given probability and condition

Hi Nell,
I may not have the right idea about this, but I think you need to do
this in two steps if it can be done. Let's say you want a sequence of
20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
the monotonically increasing sequences like this:

c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
...
c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)

So if you select one of these sequences at random, there will be a
further set of sequences that are permutations of it. By randomly
selecting one of those permutations, I think you can solve your
problem. However, this is going to be computationally intensive, with
the set of permutations being very large for large N. Here is an
example using N = M = 5:

# enumerate the sequences = M
rs5<-list(c(1,1,1,1,1),c(0,1,1,1,2),c(0,0,1,1,3),c(0,0,0,1,4),
 c(0,0,1,2,2),c(0,0,0,2,3),c(0,0,0,0,5))
library(crank)
# generate the permutations for one sequence (120 in this case)
rs5_s1<-permute(rs5[[sample(1:length(rs5),1)]])
# select one of the permutations at random
rs5_s1[sample(1:dim(rs5_s1)[1],1),]
[1] 4 0 1 0 0

Jim

On Wed, Jul 11, 2018 at 10:11 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Thank you very much for your reply.
>
>
> By omitting the probability, the expected results could be:
>
>
> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>
>
> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>
>
> If I omit the probability, I would like to generate N random positive integers that sum to M and the integers would be selected from a uniform distribution.
>
>
> Many thanks for your time
>
> Nell
>
>
> ________________________________
> De : Rolf Turner <r.turner at auckland.ac.nz>
> Envoy? : mercredi 4 juillet 2018 16:11:11
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Generate N random numbers with a given probability and condition
>
>
> On 05/07/18 10:21, Nelly Reduan wrote:
>
>> Dear all,
>>
>> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
>> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
>>
>> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
>>
>> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>> Many thanks for your time.
>
> Your thinking requires considerable clarification.
>
> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>
> (2) Hence length(seq(0,10,1)) is 11.
>
> (3) Likewise max(seq(0,10,1)) is 10.
>
> (4) Your prob vector is *constant* --- so specifying "prob" makes
>      no difference --- the result is the same as if you omitted "prob".
>
> (5) You need to think carefully about what you really mean by "random".
>      In what way do you want the final result to be "random"?
>
> I expect that the lecturer who assigned this problem to you  needs to
> clarify his/her thinking as well.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Wed Jul 11 23:59:58 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 12 Jul 2018 07:59:58 +1000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB2793345795F3B490E78839B2995A0@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CA+8X3fV2USjzQE4Sh7ssAsJof=eNtBP74j38TqVisUuCD7+fvg@mail.gmail.com>
 <DM5PR05MB2793345795F3B490E78839B2995A0@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CA+8X3fWs_Df5q3Avd5ofrtH6ny+k2-Xrm7Qn1_1KW8YnbR4Luw@mail.gmail.com>

Hi Nell,
As I said, the number of permutations increases rapidly with the
number of values to be permuted. Using the package "permute", which is
much more sophisticated than the basic function in the crank package,
a vector of length 20 has 2.432902e+18 possible permutations. While
your problem can be solved for small vectors by simply generating all
the permutations and then sampling that set, it is not a general
solution. You may be able to use the functions in the permute package
to handle a 20 element vector, but I am not familiar enough with the
functions to tell you how.

Jim


On Thu, Jul 12, 2018 at 3:14 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Many thanks Jim for your help. I am trying to apply the permutations with a
> sequence of 20 but I obtain the error message:
>
>
> Error in matrix(NA, nrow = nrows, ncol = lenx) :
>   invalid 'nrow' value (too large or NA)
> In addition: Warning message:
> In matrix(NA, nrow = nrows, ncol = lenx) :
>   NAs introduced by coercion to integer range
>
> Here is the code:
>
> library(partitions)
> library(crank)
> r <- t(restrictedparts(10, 20))
> r <- split(r, seq(nrow(r)))
> rp <- crank::permute(r[[sample(1:length(r), 1)]])
> rp[sample(1:dim(rp)[1],1),]
>
> In this case, Is it correct to permute the elements of a vector rather than
> to permute a vector ?
>
>
> Many thanks for your time.
>
> Have a nice day
>
> Nell
>
>
> ________________________________
> De : Jim Lemon <drjimlemon at gmail.com>
> Envoy? : mardi 10 juillet 2018 17:44:13
> ? : Nelly Reduan
> Objet : Re: [R] Generate N random numbers with a given probability and
> condition
>
> Hi Nell,
> I may not have the right idea about this, but I think you need to do
> this in two steps if it can be done. Let's say you want a sequence of
> 20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
> the monotonically increasing sequences like this:
>
> c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
> c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
> ...
> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)
>
> So if you select one of these sequences at random, there will be a
> further set of sequences that are permutations of it. By randomly
> selecting one of those permutations, I think you can solve your
> problem. However, this is going to be computationally intensive, with
> the set of permutations being very large for large N. Here is an
> example using N = M = 5:
>
> # enumerate the sequences = M
> rs5<-list(c(1,1,1,1,1),c(0,1,1,1,2),c(0,0,1,1,3),c(0,0,0,1,4),
>  c(0,0,1,2,2),c(0,0,0,2,3),c(0,0,0,0,5))
> library(crank)
> # generate the permutations for one sequence (120 in this case)
> rs5_s1<-permute(rs5[[sample(1:length(rs5),1)]])
> # select one of the permutations at random
> rs5_s1[sample(1:dim(rs5_s1)[1],1),]
> [1] 4 0 1 0 0
>
> Jim
>
> On Wed, Jul 11, 2018 at 10:11 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
>> Thank you very much for your reply.
>>
>>
>> By omitting the probability, the expected results could be:
>>
>>
>> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>>
>>
>> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>>
>>
>> If I omit the probability, I would like to generate N random positive
>> integers that sum to M and the integers would be selected from a uniform
>> distribution.
>>
>>
>> Many thanks for your time
>>
>> Nell
>>
>>
>> ________________________________
>> De : Rolf Turner <r.turner at auckland.ac.nz>
>> Envoy? : mercredi 4 juillet 2018 16:11:11
>> ? : Nelly Reduan
>> Cc : r-help at r-project.org
>> Objet : Re: [R] Generate N random numbers with a given probability and
>> condition
>>
>>
>> On 05/07/18 10:21, Nelly Reduan wrote:
>>
>>> Dear all,
>>>
>>> I would like to generate N random numbers with a given probability and
>>> condition but I'm not sure how to do this.
>>> For example, I have N = 20 and the vector from which to choose is seq(0,
>>> 10, 1). I have tested:
>>>
>>> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28,
>>> times=length(seq(0, 10, 1))))
>>>
>>> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>>> Many thanks for your time.
>>
>> Your thinking requires considerable clarification.
>>
>> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>>
>> (2) Hence length(seq(0,10,1)) is 11.
>>
>> (3) Likewise max(seq(0,10,1)) is 10.
>>
>> (4) Your prob vector is *constant* --- so specifying "prob" makes
>>      no difference --- the result is the same as if you omitted "prob".
>>
>> (5) You need to think carefully about what you really mean by "random".
>>      In what way do you want the final result to be "random"?
>>
>> I expect that the lecturer who assigned this problem to you  needs to
>> clarify his/her thinking as well.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @ending from gm@il@com  Thu Jul 12 02:13:47 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 11 Jul 2018 20:13:47 -0400
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <a27f35f6-1f2d-e20d-f111-c25882262d9a@gmail.com>

On 04/07/2018 6:21 PM, Nelly Reduan wrote:
> Dear all,
> 
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
> 
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
> 
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time

I'd recommend an MCMC solution to this problem.  Set up a distribution 
that is uniform on vectors that satisfy the conditions, with penalties 
on vectors that don't.  Use the Metropolis algorithm with proposals that 
pick a pair of entries and increase one, decrease the other, then let 
MCMC run.  At the end, filter out the cases that violate the conditions.

The hard part is knowing how long to let it run for a satisfactory 
sample, and how correlated later draws will be.  Propp and Wilson's 
perfect sampling algorithm might allow an exact draw, though I don't 
quite see how, and I'm not sure it would be worth the trouble.  Just run 
for a few thousand steps and it should be fine.

Duncan Murdoch


From gor@n@bro@trom @ending from umu@@e  Thu Jul 12 09:44:06 2018
From: gor@n@bro@trom @ending from umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Thu, 12 Jul 2018 09:44:06 +0200
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <feb770ae-f396-cd04-dc18-93fa9832c685@umu.se>



On 2018-07-05 00:21, Nelly Reduan wrote:
> Dear all,
> 
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
> 
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
> 
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time
> Nell

Maybe the paper "Acceptance?Rejection Sampling from the Conditional 
Distribution of Independent Discrete Random Variables, given their Sum", 
Statistics 34, pages 247-257, by Leif Nilsson and myself (2000) is relevant?

G?ran

> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Bill@Poling @ending from zeli@@com  Thu Jul 12 17:17:38 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 12 Jul 2018 15:17:38 +0000
Subject: [R] Help with replace()
Message-ID: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>


R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

Hi.

I have data set with day month year integers. I am creating a date column from those using lubridate.

a hundred or so rows failed to parse.

The problem is April and September have day = 31.

paste(df1$year, df1$month, df1$day, sep = "-")

ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial

#The resulting Date vector can be added to df1 as a new column called date:
df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning


head(df1)
sapply(df1$date,class) #"date"
summary(df1$date)
# Min.      1st Qu.       Median         Mean      3rd Qu.         Max.         NA's
#"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31"        "129"

is_missing_date <- is.na(df1$date)
View(is_missing_date)

date_columns <- c("year", "month", "day")
missing_dates <- df1[is_missing_date,  date_columns]

head(missing_dates)
#      year month day
# 3144 2000     9  31
# 3817 2000     4  31
# 3818 2000     4  31
# 3819 2000     4  31
# 3820 2000     4  31
# 3856 2000     9  31

I am trying to replace those with 30.

I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.

https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace
https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument
The following are screwy attempts at this simple repair,

??mutate_if

??replace

is_missing_date <- is.na(df1$date)
View(is_missing_date)

date_columns <- c("year", "month", "day")
missing_dates <- df1[is_missing_date,  date_columns]

head(missing_dates)
#year month day
# 3144 2000     9  31
# 3817 2000     4  31
# 3818 2000     4  31
# 3819 2000     4  31
# 3820 2000     4  31
# 3856 2000     9  31

#So need those months with 30 days that are 31 to be 30
View(missing_dates)

install.packages("dplyr")
library(dplyr)


View(missing_dates)
# ..those were the values you're going to replace

I thought this function from stackover would work, but get error when I try to add filter

#https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
  .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
  return(.data_Frame)
}

df.Rep(missing_dates, 3, 31, 30)

#--So I should be able to apply this to the complete df1 data somehow?
head(df1)
df.Rep(df1, filter(month == c(4,9)), 31, 30)
#Error in month == c(4, 9)  :   comparison (1) is possible only for atomic and list types


Other screwy attempts:


select(df1, month, day, year)
str(df1)
#'data.frame':   34786 obs. of  14 variables:
#To choose rows, use filter():

#mutate_if(df1, month =4,9), day = 30)


filter(df1, month == c(4,9), day == 31)

df1 %>%
  group_by(month == c(4,9), day == 31) %>%
  tally()
# 1 FALSE              FALSE       31161
# 2 FALSE              TRUE          576
# 3 TRUE               FALSE        2981
# 4 TRUE               TRUE           68

  df1 %>%
  mutate(day=replace(day, month == c(4,9), 30)) %>%
  as.data.frame()
  View(as.list(df1, month == 4))
  View(df1, month == c(4,9), day == 31)


df1 %>%
  group_by(month == c(4,9), day == 31) %>%
  tally()
View(df1, month == c(4,9))

# df1 %>%
#   group_by(month == c(4,9), day == 30) %>%


I know there is a simple solution  and it is driving me mad that it eludes me, despite being new to R.

Thank you for any advice.

WHP





















Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 12 17:22:08 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 12 Jul 2018 08:22:08 -0700
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <feb770ae-f396-cd04-dc18-93fa9832c685@umu.se>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <feb770ae-f396-cd04-dc18-93fa9832c685@umu.se>
Message-ID: <92556B41-5410-4FAB-990D-6D254AB5B2DA@comcast.net>


> On Jul 12, 2018, at 12:44 AM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
> 
> "Acceptance?Rejection Sampling from the Conditional Distribution of Independent Discrete Random Variables, given their Sum", Statistics 34, pages 247-257

Dear Go:ran;

I'm fully retired with no subscriber academic library that I can easily access. I've done a good faith search and can find no pdf's and the publisher website is apparently unable to deliver paid copies at this time. I wonder if you would be so kind as to send a preprint or other form of that article? I'm not so much interested in the the statistics as I am to see the two mentioned applications.

Best regards;

David Winsemius
Alameda, CA, USA


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 12 17:28:48 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 12 Jul 2018 08:28:48 -0700
Subject: [R] Help with replace()
In-Reply-To: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>


> On Jul 12, 2018, at 8:17 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> Hi.
> 
> I have data set with day month year integers. I am creating a date column from those using lubridate.
> 
> a hundred or so rows failed to parse.
> 
> The problem is April and September have day = 31.
> 
> paste(df1$year, df1$month, df1$day, sep = "-")
> 
> ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial
> 
> #The resulting Date vector can be added to df1 as a new column called date:
> df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning
> 
> 
> head(df1)
> sapply(df1$date,class) #"date"
> summary(df1$date)
> # Min.      1st Qu.       Median         Mean      3rd Qu.         Max.         NA's
> #"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31"        "129"
> 
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
> 
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date,  date_columns]
> 
> head(missing_dates)
> #      year month day
> # 3144 2000     9  31
> # 3817 2000     4  31
> # 3818 2000     4  31
> # 3819 2000     4  31
> # 3820 2000     4  31
> # 3856 2000     9  31
> 
> I am trying to replace those with 30.

Seems like a fairly straightforward application of "[<-" with a conditional argument. (No need for tidyverse.)

 missing_dates$day[ missing_dates$day==31 & ( missing_dates$month %in% c(4,9) )] <- 30


> missing_dates
     year month day
3144 2000     9  30
3817 2000     4  30
3818 2000     4  30
3819 2000     4  30
3820 2000     4  30
3856 2000     9  30

Best;
David.

> 
> I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.
> 
> https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
> https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace
> https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument
> The following are screwy attempts at this simple repair,
> 
> ??mutate_if
> 
> ??replace
> 
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
> 
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date,  date_columns]
> 
> head(missing_dates)
> #year month day
> # 3144 2000     9  31
> # 3817 2000     4  31
> # 3818 2000     4  31
> # 3819 2000     4  31
> # 3820 2000     4  31
> # 3856 2000     9  31
> 
> #So need those months with 30 days that are 31 to be 30
> View(missing_dates)
> 
> install.packages("dplyr")
> library(dplyr)
> 
> 
> View(missing_dates)
> # ..those were the values you're going to replace
> 
> I thought this function from stackover would work, but get error when I try to add filter
> 
> #https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
> df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
>  .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
>  return(.data_Frame)
> }
> 
> df.Rep(missing_dates, 3, 31, 30)
> 
> #--So I should be able to apply this to the complete df1 data somehow?
> head(df1)
> df.Rep(df1, filter(month == c(4,9)), 31, 30)
> #Error in month == c(4, 9)  :   comparison (1) is possible only for atomic and list types
> 
> 
> Other screwy attempts:
> 
> 
> select(df1, month, day, year)
> str(df1)
> #'data.frame':   34786 obs. of  14 variables:
> #To choose rows, use filter():
> 
> #mutate_if(df1, month =4,9), day = 30)
> 
> 
> filter(df1, month == c(4,9), day == 31)
> 
> df1 %>%
>  group_by(month == c(4,9), day == 31) %>%
>  tally()
> # 1 FALSE              FALSE       31161
> # 2 FALSE              TRUE          576
> # 3 TRUE               FALSE        2981
> # 4 TRUE               TRUE           68
> 
>  df1 %>%
>  mutate(day=replace(day, month == c(4,9), 30)) %>%
>  as.data.frame()
>  View(as.list(df1, month == 4))
>  View(df1, month == c(4,9), day == 31)
> 
> 
> df1 %>%
>  group_by(month == c(4,9), day == 31) %>%
>  tally()
> View(df1, month == c(4,9))
> 
> # df1 %>%
> #   group_by(month == c(4,9), day == 30) %>%
> 
> 
> I know there is a simple solution  and it is driving me mad that it eludes me, despite being new to R.
> 
> Thank you for any advice.
> 
> WHP
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From m@rine@regi@ @ending from hotm@il@fr  Thu Jul 12 17:34:50 2018
From: m@rine@regi@ @ending from hotm@il@fr (Marine Regis)
Date: Thu, 12 Jul 2018 15:34:50 +0000
Subject: [R] Simplify the loop over the 3rd dimension of a 3D array
Message-ID: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>

Hello all,


Is there an efficient way to simplify the loop over the 3rd dimension of a 3D array ? I want to keep the loop over the "time". Here is the code:


set.seed(12345)
ind <- 10
time_seq <- seq(0, 8, 1)
col_array <- c(paste("time_", time_seq, sep=""))
tab <- array(0, dim=c(length(time_seq) , length(col_array), ind), dimnames=list(NULL, col_array, as.character(seq(1, ind, 1))))
print(tab)

tab[1,c("time_0"),] <- round(runif(ind, 0, 100))
print(tab)


for(time in 1:(length(time_seq) - 1)){
  for(i in 1:ind){
    tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
    tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
    tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
    tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
    tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
    tab[time + 1,c("time_5"),i] <- tab[time,c("time_4"),i]
    tab[time + 1,c("time_6"),i] <- tab[time,c("time_5"),i]
    tab[time + 1,c("time_7"),i] <- tab[time,c("time_6"),i]
    tab[time + 1,c("time_8"),i] <- tab[time,c("time_7"),i]
  }
}

print(tab)



In fact, the array has 800000 observations for the 3rd dimension.


Many thanks for your time

Have a great day

Marine

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Thu Jul 12 18:09:56 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 12 Jul 2018 16:09:56 +0000
Subject: [R] Help with replace()
In-Reply-To: <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>
References: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>
Message-ID: <CY1PR0201MB1834D4BB41F45B86B58412C5EA590@CY1PR0201MB1834.namprd02.prod.outlook.com>

Yes, that's got it! (20 years from now I'll have it all figured out UGH!), lol!

Thank you David

Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
"1977-07-16" "1984-03-13" "1990-08-16" "1990-12-28" "1997-07-29" "2002-12-31"

WHP




From: David Winsemius [mailto:dwinsemius at comcast.net]
Sent: Thursday, July 12, 2018 11:29 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with replace()


> On Jul 12, 2018, at 8:17 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
>
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Hi.
>
> I have data set with day month year integers. I am creating a date column from those using lubridate.
>
> a hundred or so rows failed to parse.
>
> The problem is April and September have day = 31.
>
> paste(df1$year, df1$month, df1$day, sep = "-")
>
> ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial
>
> #The resulting Date vector can be added to df1 as a new column called date:
> df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning
>
>
> head(df1)
> sapply(df1$date,class) #"date"
> summary(df1$date)
> # Min. 1st Qu. Median Mean 3rd Qu. Max. NA's
> #"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31" "129"
>
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
>
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date, date_columns]
>
> head(missing_dates)
> # year month day
> # 3144 2000 9 31
> # 3817 2000 4 31
> # 3818 2000 4 31
> # 3819 2000 4 31
> # 3820 2000 4 31
> # 3856 2000 9 31
>
> I am trying to replace those with 30.

Seems like a fairly straightforward application of "[<-" with a conditional argument. (No need for tidyverse.)

missing_dates$day[ missing_dates$day==31 & ( missing_dates$month %in% c(4,9) )] <- 30


> missing_dates
year month day
3144 2000 9 30
3817 2000 4 30
3818 2000 4 30
3819 2000 4 30
3820 2000 4 30
3856 2000 9 30

Best;
David.

>
> I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.
>
> https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
> https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace<https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace>
> https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument<https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument>
> The following are screwy attempts at this simple repair,
>
> ??mutate_if
>
> ??replace
>
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
>
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date, date_columns]
>
> head(missing_dates)
> #year month day
> # 3144 2000 9 31
> # 3817 2000 4 31
> # 3818 2000 4 31
> # 3819 2000 4 31
> # 3820 2000 4 31
> # 3856 2000 9 31
>
> #So need those months with 30 days that are 31 to be 30
> View(missing_dates)
>
> install.packages("dplyr")
> library(dplyr)
>
>
> View(missing_dates)
> # ..those were the values you're going to replace
>
> I thought this function from stackover would work, but get error when I try to add filter
>
> #https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
> df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
> .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
> return(.data_Frame)
> }
>
> df.Rep(missing_dates, 3, 31, 30)
>
> #--So I should be able to apply this to the complete df1 data somehow?
> head(df1)
> df.Rep(df1, filter(month == c(4,9)), 31, 30)
> #Error in month == c(4, 9) : comparison (1) is possible only for atomic and list types
>
>
> Other screwy attempts:
>
>
> select(df1, month, day, year)
> str(df1)
> #'data.frame': 34786 obs. of 14 variables:
> #To choose rows, use filter():
>
> #mutate_if(df1, month =4,9), day = 30)
>
>
> filter(df1, month == c(4,9), day == 31)
>
> df1 %>%
> group_by(month == c(4,9), day == 31) %>%
> tally()
> # 1 FALSE FALSE 31161
> # 2 FALSE TRUE 576
> # 3 TRUE FALSE 2981
> # 4 TRUE TRUE 68
>
> df1 %>%
> mutate(day=replace(day, month == c(4,9), 30)) %>%
> as.data.frame()
> View(as.list(df1, month == 4))
> View(df1, month == c(4,9), day == 31)
>
>
> df1 %>%
> group_by(month == c(4,9), day == 31) %>%
> tally()
> View(df1, month == c(4,9))
>
> # df1 %>%
> # group_by(month == c(4,9), day == 30) %>%
>
>
> I know there is a simple solution and it is driving me mad that it eludes me, despite being new to R.
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law




Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From murdoch@dunc@n @ending from gm@il@com  Thu Jul 12 18:40:42 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Thu, 12 Jul 2018 12:40:42 -0400
Subject: [R] Simplify the loop over the 3rd dimension of a 3D array
In-Reply-To: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>
References: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>
Message-ID: <65e1c96a-b1dd-68de-caf4-822a55012d03@gmail.com>

On 12/07/2018 11:34 AM, Marine Regis wrote:
> Hello all,
> 
> 
> Is there an efficient way to simplify the loop over the 3rd dimension of a 3D array ? I want to keep the loop over the "time". Here is the code:
> 
> 
> set.seed(12345)
> ind <- 10
> time_seq <- seq(0, 8, 1)
> col_array <- c(paste("time_", time_seq, sep=""))
> tab <- array(0, dim=c(length(time_seq) , length(col_array), ind), dimnames=list(NULL, col_array, as.character(seq(1, ind, 1))))
> print(tab)
> 
> tab[1,c("time_0"),] <- round(runif(ind, 0, 100))
> print(tab)
> 
> 
> for(time in 1:(length(time_seq) - 1)){
>    for(i in 1:ind){
>      tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
>      tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
>      tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
>      tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
>      tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
>      tab[time + 1,c("time_5"),i] <- tab[time,c("time_4"),i]
>      tab[time + 1,c("time_6"),i] <- tab[time,c("time_5"),i]
>      tab[time + 1,c("time_7"),i] <- tab[time,c("time_6"),i]
>      tab[time + 1,c("time_8"),i] <- tab[time,c("time_7"),i]
>    }
> }

It looks as though you are setting all entries to the same value.  A 
simpler way to do that would be this loop:

for(time in 1:(length(time_seq) - 1)){
   for(i in 1:ind){
     tab[time + 1,,i] <- round(runif(1, 0, 100))
   }
}

You could also do away with the inner loop by generating ind random 
values all at once.  You have to be a little careful with the ordering; 
I think this gets it right:

for(time in 1:(length(time_seq) - 1)){
   tab[time + 1,,] <- t(matrix(round(runif(ind, 0, 100)), ind, 9))
}

And then you can do away with the loop entirely, since none of the 
values depend on earlier calculations.  Just generate 
ind*length(time_seq) uniforms, and put them in the array in the right 
order.  You could use aperm() to do this instead of t(), but be careful, 
it's easy to get the permutation wrong.  (I'm not even going to try now. 
:-).

Duncan Murdoch

> 
> print(tab)
> 
> 
> 
> In fact, the array has 800000 observations for the 3rd dimension.
> 
> 
> Many thanks for your time
> 
> Have a great day
> 
> Marine
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 12 20:21:53 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 12 Jul 2018 11:21:53 -0700
Subject: [R] Simplify the loop over the 3rd dimension of a 3D array
In-Reply-To: <65e1c96a-b1dd-68de-caf4-822a55012d03@gmail.com>
References: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>
 <65e1c96a-b1dd-68de-caf4-822a55012d03@gmail.com>
Message-ID: <2F6354ED-AFC7-4990-A82E-5899841EB4B9@comcast.net>


> On Jul 12, 2018, at 9:40 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 12/07/2018 11:34 AM, Marine Regis wrote:
>> Hello all,
>> Is there an efficient way to simplify the loop over the 3rd dimension of a 3D array ? I want to keep the loop over the "time". Here is the code:
>> set.seed(12345)
>> ind <- 10
>> time_seq <- seq(0, 8, 1)
>> col_array <- c(paste("time_", time_seq, sep=""))
>> tab <- array(0, dim=c(length(time_seq) , length(col_array), ind), dimnames=list(NULL, col_array, as.character(seq(1, ind, 1))))
>> print(tab)
>> tab[1,c("time_0"),] <- round(runif(ind, 0, 100))
>> print(tab)
>> for(time in 1:(length(time_seq) - 1)){
>>   for(i in 1:ind){
>>     tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
>>     tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
>>     tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
>>     tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
>>     tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
>>     tab[time + 1,c("time_5"),i] <- tab[time,c("time_4"),i]
>>     tab[time + 1,c("time_6"),i] <- tab[time,c("time_5"),i]
>>     tab[time + 1,c("time_7"),i] <- tab[time,c("time_6"),i]
>>     tab[time + 1,c("time_8"),i] <- tab[time,c("time_7"),i]
>>   }
>> }
> 
> It looks as though you are setting all entries to the same value.

I agree that it looked like that to me as well but in testing with a slight smaller version of the array I found that it was not so simple. I shortended the arrae to be dim = c(3,5,5) so that I could see it on one page, and then ran the code:

> for(time in 1:(length(time_seq) - 1)){
+  for(i in 1:ind){
+    tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
+    tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
+    tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
+    tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
+    tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
+    
+  }
+ }
> 
> print(tab)
, , 1

     time_0 time_1 time_2 time_3 time_4
[1,]     72      0      0      0      0
[2,]     89     72      0      0      0
[3,]     33     89     72      0      0
[4,]     99     33     89     72      0
[5,]     74     99     33     89     72

, , 2

     time_0 time_1 time_2 time_3 time_4
[1,]     88      0      0      0      0
[2,]     46     88      0      0      0
[3,]     51     46     88      0      0
[4,]      3     51     46     88      0
[5,]      0      3     51     46     88

, , 3

     time_0 time_1 time_2 time_3 time_4
[1,]     76      0      0      0      0
[2,]     17     76      0      0      0
[3,]     73     17     76      0      0
[4,]     15     73     17     76      0
[5,]     39     15     73     17     76


So the code was filling in the diagonal and a shifter version of the diagonal values. Whether that was the intent of the OP was not clear from the original email. The practice of throwing code as the only description of the problem is a common source of confusion.





> A simpler way to do that would be this loop:
> 
> for(time in 1:(length(time_seq) - 1)){
>  for(i in 1:ind){
>    tab[time + 1,,i] <- round(runif(1, 0, 100))
>  }
> }
> 
> You could also do away with the inner loop by generating ind random values all at once.  You have to be a little careful with the ordering; I think this gets it right:
> 
> for(time in 1:(length(time_seq) - 1)){
>  tab[time + 1,,] <- t(matrix(round(runif(ind, 0, 100)), ind, 9))
> }
> 
> And then you can do away with the loop entirely, since none of the values depend on earlier calculations.  Just generate ind*length(time_seq) uniforms, and put them in the array in the right order.  You could use aperm() to do this instead of t(), but be careful, it's easy to get the permutation wrong.  (I'm not even going to try now. :-).
> 
> Duncan Murdoch
> 
>> print(tab)
>> In fact, the array has 800000 observations for the 3rd dimension.
>> Many thanks for your time
>> Have a great day
>> Marine
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From kum@r@@mit@bh1 @ending from y@hoo@com  Fri Jul 13 03:46:37 2018
From: kum@r@@mit@bh1 @ending from y@hoo@com (Amitabh Kumar)
Date: Fri, 13 Jul 2018 01:46:37 +0000 (UTC)
Subject: [R] Forecasting methods in R
References: <25966788.3693631.1531446397452.ref@mail.yahoo.com>
Message-ID: <25966788.3693631.1531446397452@mail.yahoo.com>

Hi,
I am learning R for forecasting. Is there any document where I can learn how to apply R in forecasting time series using Holt-Winters method and ARIMA modelling?
Thanks,Amitabh
	[[alternative HTML version deleted]]


From @ez@reb@ki @ending from gm@il@com  Fri Jul 13 04:21:52 2018
From: @ez@reb@ki @ending from gm@il@com (Alex Zarebski)
Date: Fri, 13 Jul 2018 12:21:52 +1000
Subject: [R] Forecasting methods in R
In-Reply-To: <25966788.3693631.1531446397452@mail.yahoo.com>
References: <25966788.3693631.1531446397452.ref@mail.yahoo.com>
 <25966788.3693631.1531446397452@mail.yahoo.com>
Message-ID: <CAKsw2nF=tup0ERgxG=uyxhB3cMSZj4jNmAJ-n0+ubmYuPRttbQ@mail.gmail.com>

Hey,

You should probably check out the =forecast= package which is pretty close
to a default solution as you'll find.

https://cran.r-project.org/web/packages/forecast/

If you google around this you should find some useful stuff.

Cheers,
Alex

On Fri, Jul 13, 2018 at 12:15 PM Amitabh Kumar via R-help <
r-help at r-project.org> wrote:

> Hi,
> I am learning R for forecasting. Is there any document where I can learn
> how to apply R in forecasting time series using Holt-Winters method and
> ARIMA modelling?
> Thanks,Amitabh
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Jul 13 04:24:10 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 12 Jul 2018 19:24:10 -0700
Subject: [R] Forecasting methods in R
In-Reply-To: <25966788.3693631.1531446397452@mail.yahoo.com>
References: <25966788.3693631.1531446397452.ref@mail.yahoo.com>
 <25966788.3693631.1531446397452@mail.yahoo.com>
Message-ID: <CAGxFJbRFMqKa=NtWyU6vn2Y9iufuQumXCidJqyXU7agR5qnYhA@mail.gmail.com>

1. https://cran.r-project.org/web/views/TimeSeries.html

2. Google!

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 12, 2018 at 6:46 PM, Amitabh Kumar via R-help <
r-help at r-project.org> wrote:

> Hi,
> I am learning R for forecasting. Is there any document where I can learn
> how to apply R in forecasting time series using Holt-Winters method and
> ARIMA modelling?
> Thanks,Amitabh
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fbecerr@ @ending from mdp@edu@@r  Fri Jul 13 20:43:38 2018
From: fbecerr@ @ending from mdp@edu@@r (Federico Becerra)
Date: Fri, 13 Jul 2018 15:43:38 -0300
Subject: [R] optim function
Message-ID: <798044dea49eba9f7059cf0115b9e370@mdp.edu.ar>

Good afternoon,

I am a Biology researcher working on Functional Morphology and Behaviour 
in mammals. Nowadays, I have a series of morphological data that I would 
like to test against different models for which I would need to optimize 
them -namely, "randomly manipulating" all models parameters in order to 
find the model that fit best upon my data.

I've been told that the function "optim" is THE function for me, but 
I've been having problems to program it and set all constraints.

Is there anything you could help me (guide me) with? I've asked already 
several "experts" in the internet but noone gave me a real solution.

Thanks a lot, have a nice day,
Federico

-- 
Dr. Federico Becerra
Morfolog?a Funcional y Comportamiento
Instituto de Investigaciones Marinas y Costeras
Univ. Nac. Mar del Plata - CONICET
CC 1245. Dean Funes 3250.(7600) Mar del Plata. Argentina
Tel: +54 (0223)475-3554 / 475-2426 Int. 297
* For large files, please send it to fedebec at hotmail.com (and please 
notify me here so I check that out).


From yzh@o17 @ending from uoregon@edu  Fri Jul 13 23:24:40 2018
From: yzh@o17 @ending from uoregon@edu (Yufei Zhao)
Date: Fri, 13 Jul 2018 14:24:40 -0700
Subject: [R] Rmpi fails to install
Message-ID: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>

Hello!

I try to install Rmpi with install.packages(?Rmpi?), but it fails:

> install.packages("Rmpi")
Package which is only available in source form, and may need compilation of C/C++/Fortran: ?Rmpi?
Do you want to attempt to install these from sources? (Yes/no/cancel) yes
installing the source package ?Rmpi?

trying URL 'https://cran.rstudio.com/src/contrib/Rmpi_0.6-7.tar.gz'
Content type 'application/x-gzip' length 106869 bytes (104 KB)
==================================================
downloaded 104 KB

* installing *source* package ?Rmpi? ...
** package ?Rmpi? successfully unpacked and MD5 sums checked
checking for gcc... clang
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether clang accepts -g... yes
checking for clang option to accept ISO C89... none needed
checking for pkg-config... no
checking how to run the C preprocessor... clang -E
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for ANSI C header files... rm: conftest.dSYM: is a directory
rm: conftest.dSYM: is a directory
yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking mpi.h usability... no
checking mpi.h presence... no
checking for mpi.h... no
configure: error: "Cannot find mpi.h header file"
ERROR: configuration failed for package ?Rmpi?
* removing ?/Library/Frameworks/R.framework/Versions/3.5/Resources/library/Rmpi?
Warning in install.packages :
  installation of package ?Rmpi? had non-zero exit status

The downloaded source packages are in
	?/private/var/folders/wd/5x8p9n_j1kx7sqqv2hk23vvm0000gs/T/RtmpKZ1waO/downloaded_packages?


The systems is MacOS High Sierra 10.13.3.

Thanks in advance!

Best,
Yufei

From erinm@hodge@@ @ending from gm@il@com  Fri Jul 13 23:31:04 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Fri, 13 Jul 2018 16:31:04 -0500
Subject: [R] Rmpi fails to install
In-Reply-To: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
References: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
Message-ID: <CACxE24=r1S8+QxVA=U2vNFwtEMQb3qT22q9eMA59QGRRtdkhow@mail.gmail.com>

Hi!

You need to have MPI in your path.

Thanks,
Erin

On Fri, Jul 13, 2018 at 4:29 PM Yufei Zhao <yzhao17 at uoregon.edu> wrote:

> Hello!
>
> I try to install Rmpi with install.packages(?Rmpi?), but it fails:
>
> > install.packages("Rmpi")
> Package which is only available in source form, and may need compilation
> of C/C++/Fortran: ?Rmpi?
> Do you want to attempt to install these from sources? (Yes/no/cancel) yes
> installing the source package ?Rmpi?
>
> trying URL 'https://cran.rstudio.com/src/contrib/Rmpi_0.6-7.tar.gz'
> Content type 'application/x-gzip' length 106869 bytes (104 KB)
> ==================================================
> downloaded 104 KB
>
> * installing *source* package ?Rmpi? ...
> ** package ?Rmpi? successfully unpacked and MD5 sums checked
> checking for gcc... clang
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether clang accepts -g... yes
> checking for clang option to accept ISO C89... none needed
> checking for pkg-config... no
> checking how to run the C preprocessor... clang -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... rm: conftest.dSYM: is a directory
> rm: conftest.dSYM: is a directory
> yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking mpi.h usability... no
> checking mpi.h presence... no
> checking for mpi.h... no
> configure: error: "Cannot find mpi.h header file"
> ERROR: configuration failed for package ?Rmpi?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.5/Resources/library/Rmpi?
> Warning in install.packages :
>   installation of package ?Rmpi? had non-zero exit status
>
> The downloaded source packages are in
>
> ?/private/var/folders/wd/5x8p9n_j1kx7sqqv2hk23vvm0000gs/T/RtmpKZ1waO/downloaded_packages?
>
>
> The systems is MacOS High Sierra 10.13.3.
>
> Thanks in advance!
>
> Best,
> Yufei
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Jul 13 23:34:32 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 13 Jul 2018 14:34:32 -0700
Subject: [R] Rmpi fails to install
In-Reply-To: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
References: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
Message-ID: <CAGxFJbT=vvvKmM_-qYs7ShmRnaeSWFyba1h13CbgdU0V4GrLQA@mail.gmail.com>

I cannot specifically help, but you may wish to post this on the r-sig-mac
list where there may be the expertise you need.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 13, 2018 at 2:24 PM, Yufei Zhao <yzhao17 at uoregon.edu> wrote:

> Hello!
>
> I try to install Rmpi with install.packages(?Rmpi?), but it fails:
>
> > install.packages("Rmpi")
> Package which is only available in source form, and may need compilation
> of C/C++/Fortran: ?Rmpi?
> Do you want to attempt to install these from sources? (Yes/no/cancel) yes
> installing the source package ?Rmpi?
>
> trying URL 'https://cran.rstudio.com/src/contrib/Rmpi_0.6-7.tar.gz'
> Content type 'application/x-gzip' length 106869 bytes (104 KB)
> ==================================================
> downloaded 104 KB
>
> * installing *source* package ?Rmpi? ...
> ** package ?Rmpi? successfully unpacked and MD5 sums checked
> checking for gcc... clang
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether clang accepts -g... yes
> checking for clang option to accept ISO C89... none needed
> checking for pkg-config... no
> checking how to run the C preprocessor... clang -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... rm: conftest.dSYM: is a directory
> rm: conftest.dSYM: is a directory
> yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking mpi.h usability... no
> checking mpi.h presence... no
> checking for mpi.h... no
> configure: error: "Cannot find mpi.h header file"
> ERROR: configuration failed for package ?Rmpi?
> * removing ?/Library/Frameworks/R.framework/Versions/3.5/
> Resources/library/Rmpi?
> Warning in install.packages :
>   installation of package ?Rmpi? had non-zero exit status
>
> The downloaded source packages are in
>         ?/private/var/folders/wd/5x8p9n_j1kx7sqqv2hk23vvm0000gs/T/
> RtmpKZ1waO/downloaded_packages?
>
>
> The systems is MacOS High Sierra 10.13.3.
>
> Thanks in advance!
>
> Best,
> Yufei
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Sat Jul 14 01:05:06 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 13 Jul 2018 23:05:06 +0000
Subject: [R] optim function
In-Reply-To: <798044dea49eba9f7059cf0115b9e370@mdp.edu.ar>
References: <798044dea49eba9f7059cf0115b9e370@mdp.edu.ar>
Message-ID: <50B1F81D-857D-4909-88A7-DA6952B504C9@llnl.gov>

There's a CRAN Task View on optimization. There might be something useful there.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/13/18, 11:43 AM, "R-help on behalf of Federico Becerra" <r-help-bounces at r-project.org on behalf of fbecerra at mdp.edu.ar> wrote:

    Good afternoon,
    
    I am a Biology researcher working on Functional Morphology and Behaviour 
    in mammals. Nowadays, I have a series of morphological data that I would 
    like to test against different models for which I would need to optimize 
    them -namely, "randomly manipulating" all models parameters in order to 
    find the model that fit best upon my data.
    
    I've been told that the function "optim" is THE function for me, but 
    I've been having problems to program it and set all constraints.
    
    Is there anything you could help me (guide me) with? I've asked already 
    several "experts" in the internet but noone gave me a real solution.
    
    Thanks a lot, have a nice day,
    Federico
    
    -- 
    Dr. Federico Becerra
    Morfolog?a Funcional y Comportamiento
    Instituto de Investigaciones Marinas y Costeras
    Univ. Nac. Mar del Plata - CONICET
    CC 1245. Dean Funes 3250.(7600) Mar del Plata. Argentina
    Tel: +54 (0223)475-3554 / 475-2426 Int. 297
    * For large files, please send it to fedebec at hotmail.com (and please 
    notify me here so I check that out).
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jmh@nnon@ucd@vi@ @ending from gm@il@com  Sat Jul 14 02:51:06 2018
From: jmh@nnon@ucd@vi@ @ending from gm@il@com (Michael Hannon)
Date: Fri, 13 Jul 2018 17:51:06 -0700
Subject: [R] Making objects global in a package
Message-ID: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>

Greetings.  I'm putting together a small package in which I use
`dplyr::read_csv()` to read CSV files from several different sources.  I do
this in several different files, but with various kinds of subsequent
processing, depending on the file.

I find it useful to specify column types, as the apparent data type of a given
column sometimes changes unexpectedly deep into the file.  I.e., a field that
consistently looks like an integer, suddenly becomes a fraction:

    1, 1, ..., 1, 1/2, 1, ...

Hence, the column type has to be treated as a character, rather than as an
integer (with the possibility of later conversion to double, if necessary).
(This is just an example.)

Therefore I use the `col_types` argument in all of the calls to `read_csv()`.

These calls are spread over several files, but I want the keep all of the
column types in a single place, yet have them available in each of the several
files.  This is just for the sake of maintainability.

At the moment I do this by putting the column-type definitions into a single,
file:

    000_define_data_attributes.R

that:

    (1) is named so that it's parsed first by `devtools::build()`
    (2) sets up an environment and stuffs the column types into it:

            data_env <- new.env(parent=emptyenv())
            data_env$col_types_alpha <- list(
                Date = col_date(),
                var1 = col_double(),
                ...
            )

There are a few other things that go into the file as well.

Then I pick off the appropriate stuff from the environment in the other files:

    foo_alpha <- read_csv("alpha.csv", col_types = data_env$col_types_alpha)

This seems to work, but it doesn't "feel" right to me.  (If this were Python,
people would accuse me of being "non-pythonic").

Hence, I'm seeking suggestions for the best practice for this kind of thing.

BTW, I note that both the sources of data ("alpha", etc.) and the column types
are more or less guaranteed to be static for the foreseeable future.  Hence,
there really isn't much danger in just replicating the column-type definitions
in each of the various files, which would obviate the need for the "000..."
file.  In other words, this is mostly a style thing.

Thanks for any advice you can provide.

-- Mike


From rm@h@rp @ending from me@com  Sat Jul 14 03:13:23 2018
From: rm@h@rp @ending from me@com (R. Mark Sharp)
Date: Fri, 13 Jul 2018 20:13:23 -0500
Subject: [R] Making objects global in a package
In-Reply-To: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
Message-ID: <2366CD86-39DF-4B2C-97F9-62E3AC2CB95B@me.com>

I would usually use a function for this. It may not be more R like, but it is more readable to me. If you want, to keep the columns in a file, you could have the function initialize itself on the first call. 

Mark
R. Mark Sharp, Ph.D.
Data Scientist and Biomedical Statistical Consultant
7526 Meadow Green St.
San Antonio, TX 78251
mobile: 210-218-2868
rmsharp at me.com











> On Jul 13, 2018, at 7:51 PM, Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
> 
> Greetings.  I'm putting together a small package in which I use
> `dplyr::read_csv()` to read CSV files from several different sources.  I do
> this in several different files, but with various kinds of subsequent
> processing, depending on the file.
> 
> I find it useful to specify column types, as the apparent data type of a given
> column sometimes changes unexpectedly deep into the file.  I.e., a field that
> consistently looks like an integer, suddenly becomes a fraction:
> 
>    1, 1, ..., 1, 1/2, 1, ...
> 
> Hence, the column type has to be treated as a character, rather than as an
> integer (with the possibility of later conversion to double, if necessary).
> (This is just an example.)
> 
> Therefore I use the `col_types` argument in all of the calls to `read_csv()`.
> 
> These calls are spread over several files, but I want the keep all of the
> column types in a single place, yet have them available in each of the several
> files.  This is just for the sake of maintainability.
> 
> At the moment I do this by putting the column-type definitions into a single,
> file:
> 
>    000_define_data_attributes.R
> 
> that:
> 
>    (1) is named so that it's parsed first by `devtools::build()`
>    (2) sets up an environment and stuffs the column types into it:
> 
>            data_env <- new.env(parent=emptyenv())
>            data_env$col_types_alpha <- list(
>                Date = col_date(),
>                var1 = col_double(),
>                ...
>            )
> 
> There are a few other things that go into the file as well.
> 
> Then I pick off the appropriate stuff from the environment in the other files:
> 
>    foo_alpha <- read_csv("alpha.csv", col_types = data_env$col_types_alpha)
> 
> This seems to work, but it doesn't "feel" right to me.  (If this were Python,
> people would accuse me of being "non-pythonic").
> 
> Hence, I'm seeking suggestions for the best practice for this kind of thing.
> 
> BTW, I note that both the sources of data ("alpha", etc.) and the column types
> are more or less guaranteed to be static for the foreseeable future.  Hence,
> there really isn't much danger in just replicating the column-type definitions
> in each of the various files, which would obviate the need for the "000..."
> file.  In other words, this is mostly a style thing.
> 
> Thanks for any advice you can provide.
> 
> -- Mike
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 14 03:17:55 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 13 Jul 2018 18:17:55 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
Message-ID: <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>

a) There is a mailing list for package development questions: R-package-devel.

b) This seems like a job for the sysdata.rda file... no explicit environments needed. See the Writing R Extensions manual.

On July 13, 2018 5:51:06 PM PDT, Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
>Greetings.  I'm putting together a small package in which I use
>`dplyr::read_csv()` to read CSV files from several different sources. 
>I do
>this in several different files, but with various kinds of subsequent
>processing, depending on the file.
>
>I find it useful to specify column types, as the apparent data type of
>a given
>column sometimes changes unexpectedly deep into the file.  I.e., a
>field that
>consistently looks like an integer, suddenly becomes a fraction:
>
>    1, 1, ..., 1, 1/2, 1, ...
>
>Hence, the column type has to be treated as a character, rather than as
>an
>integer (with the possibility of later conversion to double, if
>necessary).
>(This is just an example.)
>
>Therefore I use the `col_types` argument in all of the calls to
>`read_csv()`.
>
>These calls are spread over several files, but I want the keep all of
>the
>column types in a single place, yet have them available in each of the
>several
>files.  This is just for the sake of maintainability.
>
>At the moment I do this by putting the column-type definitions into a
>single,
>file:
>
>    000_define_data_attributes.R
>
>that:
>
>    (1) is named so that it's parsed first by `devtools::build()`
>    (2) sets up an environment and stuffs the column types into it:
>
>            data_env <- new.env(parent=emptyenv())
>            data_env$col_types_alpha <- list(
>                Date = col_date(),
>                var1 = col_double(),
>                ...
>            )
>
>There are a few other things that go into the file as well.
>
>Then I pick off the appropriate stuff from the environment in the other
>files:
>
>foo_alpha <- read_csv("alpha.csv", col_types =
>data_env$col_types_alpha)
>
>This seems to work, but it doesn't "feel" right to me.  (If this were
>Python,
>people would accuse me of being "non-pythonic").
>
>Hence, I'm seeking suggestions for the best practice for this kind of
>thing.
>
>BTW, I note that both the sources of data ("alpha", etc.) and the
>column types
>are more or less guaranteed to be static for the foreseeable future. 
>Hence,
>there really isn't much danger in just replicating the column-type
>definitions
>in each of the various files, which would obviate the need for the
>"000..."
>file.  In other words, this is mostly a style thing.
>
>Thanks for any advice you can provide.
>
>-- Mike
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wdunl@p @ending from tibco@com  Sat Jul 14 03:50:31 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 13 Jul 2018 18:50:31 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
 <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
Message-ID: <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>

What the OP is doing looks fine to me.

The environment holding the data vectors is not necessary, but it helps
organize things - you know where to look for this sort of data vector.

I would avoid the *.rda file, since it is not text, hence not readily
editable
or trackable with most source control systems.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 13, 2018 at 6:17 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> a) There is a mailing list for package development questions:
> R-package-devel.
>
> b) This seems like a job for the sysdata.rda file... no explicit
> environments needed. See the Writing R Extensions manual.
>
> On July 13, 2018 5:51:06 PM PDT, Michael Hannon <
> jmhannon.ucdavis at gmail.com> wrote:
> >Greetings.  I'm putting together a small package in which I use
> >`dplyr::read_csv()` to read CSV files from several different sources.
> >I do
> >this in several different files, but with various kinds of subsequent
> >processing, depending on the file.
> >
> >I find it useful to specify column types, as the apparent data type of
> >a given
> >column sometimes changes unexpectedly deep into the file.  I.e., a
> >field that
> >consistently looks like an integer, suddenly becomes a fraction:
> >
> >    1, 1, ..., 1, 1/2, 1, ...
> >
> >Hence, the column type has to be treated as a character, rather than as
> >an
> >integer (with the possibility of later conversion to double, if
> >necessary).
> >(This is just an example.)
> >
> >Therefore I use the `col_types` argument in all of the calls to
> >`read_csv()`.
> >
> >These calls are spread over several files, but I want the keep all of
> >the
> >column types in a single place, yet have them available in each of the
> >several
> >files.  This is just for the sake of maintainability.
> >
> >At the moment I do this by putting the column-type definitions into a
> >single,
> >file:
> >
> >    000_define_data_attributes.R
> >
> >that:
> >
> >    (1) is named so that it's parsed first by `devtools::build()`
> >    (2) sets up an environment and stuffs the column types into it:
> >
> >            data_env <- new.env(parent=emptyenv())
> >            data_env$col_types_alpha <- list(
> >                Date = col_date(),
> >                var1 = col_double(),
> >                ...
> >            )
> >
> >There are a few other things that go into the file as well.
> >
> >Then I pick off the appropriate stuff from the environment in the other
> >files:
> >
> >foo_alpha <- read_csv("alpha.csv", col_types =
> >data_env$col_types_alpha)
> >
> >This seems to work, but it doesn't "feel" right to me.  (If this were
> >Python,
> >people would accuse me of being "non-pythonic").
> >
> >Hence, I'm seeking suggestions for the best practice for this kind of
> >thing.
> >
> >BTW, I note that both the sources of data ("alpha", etc.) and the
> >column types
> >are more or less guaranteed to be static for the foreseeable future.
> >Hence,
> >there really isn't much danger in just replicating the column-type
> >definitions
> >in each of the various files, which would obviate the need for the
> >"000..."
> >file.  In other words, this is mostly a style thing.
> >
> >Thanks for any advice you can provide.
> >
> >-- Mike
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 14 03:54:02 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 13 Jul 2018 18:54:02 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
 <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
 <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>
Message-ID: <FAD0DE73-F0A8-4D39-B8DF-936549423293@dcn.davis.ca.us>

Avoiding rda files because they don't track well with version control seems weak to me, since you should be creating the rda with an R file in the tools directory.

On July 13, 2018 6:50:31 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>What the OP is doing looks fine to me.
>
>The environment holding the data vectors is not necessary, but it helps
>organize things - you know where to look for this sort of data vector.
>
>I would avoid the *.rda file, since it is not text, hence not readily
>editable
>or trackable with most source control systems.
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Fri, Jul 13, 2018 at 6:17 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> a) There is a mailing list for package development questions:
>> R-package-devel.
>>
>> b) This seems like a job for the sysdata.rda file... no explicit
>> environments needed. See the Writing R Extensions manual.
>>
>> On July 13, 2018 5:51:06 PM PDT, Michael Hannon <
>> jmhannon.ucdavis at gmail.com> wrote:
>> >Greetings.  I'm putting together a small package in which I use
>> >`dplyr::read_csv()` to read CSV files from several different
>sources.
>> >I do
>> >this in several different files, but with various kinds of
>subsequent
>> >processing, depending on the file.
>> >
>> >I find it useful to specify column types, as the apparent data type
>of
>> >a given
>> >column sometimes changes unexpectedly deep into the file.  I.e., a
>> >field that
>> >consistently looks like an integer, suddenly becomes a fraction:
>> >
>> >    1, 1, ..., 1, 1/2, 1, ...
>> >
>> >Hence, the column type has to be treated as a character, rather than
>as
>> >an
>> >integer (with the possibility of later conversion to double, if
>> >necessary).
>> >(This is just an example.)
>> >
>> >Therefore I use the `col_types` argument in all of the calls to
>> >`read_csv()`.
>> >
>> >These calls are spread over several files, but I want the keep all
>of
>> >the
>> >column types in a single place, yet have them available in each of
>the
>> >several
>> >files.  This is just for the sake of maintainability.
>> >
>> >At the moment I do this by putting the column-type definitions into
>a
>> >single,
>> >file:
>> >
>> >    000_define_data_attributes.R
>> >
>> >that:
>> >
>> >    (1) is named so that it's parsed first by `devtools::build()`
>> >    (2) sets up an environment and stuffs the column types into it:
>> >
>> >            data_env <- new.env(parent=emptyenv())
>> >            data_env$col_types_alpha <- list(
>> >                Date = col_date(),
>> >                var1 = col_double(),
>> >                ...
>> >            )
>> >
>> >There are a few other things that go into the file as well.
>> >
>> >Then I pick off the appropriate stuff from the environment in the
>other
>> >files:
>> >
>> >foo_alpha <- read_csv("alpha.csv", col_types =
>> >data_env$col_types_alpha)
>> >
>> >This seems to work, but it doesn't "feel" right to me.  (If this
>were
>> >Python,
>> >people would accuse me of being "non-pythonic").
>> >
>> >Hence, I'm seeking suggestions for the best practice for this kind
>of
>> >thing.
>> >
>> >BTW, I note that both the sources of data ("alpha", etc.) and the
>> >column types
>> >are more or less guaranteed to be static for the foreseeable future.
>> >Hence,
>> >there really isn't much danger in just replicating the column-type
>> >definitions
>> >in each of the various files, which would obviate the need for the
>> >"000..."
>> >file.  In other words, this is mostly a style thing.
>> >
>> >Thanks for any advice you can provide.
>> >
>> >-- Mike
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

-- 
Sent from my phone. Please excuse my brevity.


From ligge@ @ending from @t@ti@tik@tu-dortmund@de  Sat Jul 14 08:55:32 2018
From: ligge@ @ending from @t@ti@tik@tu-dortmund@de (Uwe Ligges)
Date: Sat, 14 Jul 2018 08:55:32 +0200
Subject: [R] Help with replace()
In-Reply-To: <CY1PR0201MB1834D4BB41F45B86B58412C5EA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>
 <CY1PR0201MB1834D4BB41F45B86B58412C5EA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <51e8e50a-d1ee-d060-17db-080c2273f838@statistik.tu-dortmund.de>



On 12.07.2018 18:09, Bill Poling wrote:
> Yes, that's got it! (20 years from now I'll have it all figured out UGH!), lol!

Using R for 20 years myself now I can only tell that it takes much longer.

Best,
Uwe Ligges


> Thank you David
> 
> Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
> "1977-07-16" "1984-03-13" "1990-08-16" "1990-12-28" "1997-07-29" "2002-12-31"
> 
> WHP
> 
> 
> 
> 
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Thursday, July 12, 2018 11:29 AM
> To: Bill Poling <Bill.Poling at zelis.com>
> Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
> Subject: Re: [R] Help with replace()
> 
> 
>> On Jul 12, 2018, at 8:17 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>>
>>
>> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> Hi.
>>
>> I have data set with day month year integers. I am creating a date column from those using lubridate.
>>
>> a hundred or so rows failed to parse.
>>
>> The problem is April and September have day = 31.
>>
>> paste(df1$year, df1$month, df1$day, sep = "-")
>>
>> ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial
>>
>> #The resulting Date vector can be added to df1 as a new column called date:
>> df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning
>>
>>
>> head(df1)
>> sapply(df1$date,class) #"date"
>> summary(df1$date)
>> # Min. 1st Qu. Median Mean 3rd Qu. Max. NA's
>> #"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31" "129"
>>
>> is_missing_date <- is.na(df1$date)
>> View(is_missing_date)
>>
>> date_columns <- c("year", "month", "day")
>> missing_dates <- df1[is_missing_date, date_columns]
>>
>> head(missing_dates)
>> # year month day
>> # 3144 2000 9 31
>> # 3817 2000 4 31
>> # 3818 2000 4 31
>> # 3819 2000 4 31
>> # 3820 2000 4 31
>> # 3856 2000 9 31
>>
>> I am trying to replace those with 30.
> 
> Seems like a fairly straightforward application of "[<-" with a conditional argument. (No need for tidyverse.)
> 
> missing_dates$day[ missing_dates$day==31 & ( missing_dates$month %in% c(4,9) )] <- 30
> 
> 
>> missing_dates
> year month day
> 3144 2000 9 30
> 3817 2000 4 30
> 3818 2000 4 30
> 3819 2000 4 30
> 3820 2000 4 30
> 3856 2000 9 30
> 
> Best;
> David.
> 
>>
>> I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.
>>
>> https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
>> https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace<https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace>
>> https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument<https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument>
>> The following are screwy attempts at this simple repair,
>>
>> ??mutate_if
>>
>> ??replace
>>
>> is_missing_date <- is.na(df1$date)
>> View(is_missing_date)
>>
>> date_columns <- c("year", "month", "day")
>> missing_dates <- df1[is_missing_date, date_columns]
>>
>> head(missing_dates)
>> #year month day
>> # 3144 2000 9 31
>> # 3817 2000 4 31
>> # 3818 2000 4 31
>> # 3819 2000 4 31
>> # 3820 2000 4 31
>> # 3856 2000 9 31
>>
>> #So need those months with 30 days that are 31 to be 30
>> View(missing_dates)
>>
>> install.packages("dplyr")
>> library(dplyr)
>>
>>
>> View(missing_dates)
>> # ..those were the values you're going to replace
>>
>> I thought this function from stackover would work, but get error when I try to add filter
>>
>> #https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
>> df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
>> .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
>> return(.data_Frame)
>> }
>>
>> df.Rep(missing_dates, 3, 31, 30)
>>
>> #--So I should be able to apply this to the complete df1 data somehow?
>> head(df1)
>> df.Rep(df1, filter(month == c(4,9)), 31, 30)
>> #Error in month == c(4, 9) : comparison (1) is possible only for atomic and list types
>>
>>
>> Other screwy attempts:
>>
>>
>> select(df1, month, day, year)
>> str(df1)
>> #'data.frame': 34786 obs. of 14 variables:
>> #To choose rows, use filter():
>>
>> #mutate_if(df1, month =4,9), day = 30)
>>
>>
>> filter(df1, month == c(4,9), day == 31)
>>
>> df1 %>%
>> group_by(month == c(4,9), day == 31) %>%
>> tally()
>> # 1 FALSE FALSE 31161
>> # 2 FALSE TRUE 576
>> # 3 TRUE FALSE 2981
>> # 4 TRUE TRUE 68
>>
>> df1 %>%
>> mutate(day=replace(day, month == c(4,9), 30)) %>%
>> as.data.frame()
>> View(as.list(df1, month == 4))
>> View(df1, month == c(4,9), day == 31)
>>
>>
>> df1 %>%
>> group_by(month == c(4,9), day == 31) %>%
>> tally()
>> View(df1, month == c(4,9))
>>
>> # df1 %>%
>> # group_by(month == c(4,9), day == 30) %>%
>>
>>
>> I know there is a simple solution and it is driving me mad that it eludes me, despite being new to R.
>>
>> Thank you for any advice.
>>
>> WHP
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From profjcn@@h @ending from gm@il@com  Sat Jul 14 13:18:36 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Sat, 14 Jul 2018 07:18:36 -0400
Subject: [R] optim function
In-Reply-To: <d3ccf5f0-d613-2f6c-6c21-8ed323e25ebd@gmail.com>
References: <d3ccf5f0-d613-2f6c-6c21-8ed323e25ebd@gmail.com>
Message-ID: <dba1a0ad-17f9-738e-8a8d-03c0d9b2bac6@gmail.com>


Subject: Re: [R] optim function
Date: Fri, 13 Jul 2018 17:06:56 -0400
From: J C Nash <profjcnash at gmail.com>
To: Federico Becerra <fbecerra at mdp.edu.ar>

Though I wrote the original codes for 3 of the 5 solvers in optim(), I now suggest using more recent ones, some
of which I have packaged. optimx on R-forge (not the one on CRAN yet) has optimr() function that has same
syntax as optim but more options. See https://r-forge.r-project.org/projects/optimizer/.

You need an objective function  myobj(parameters, other_data) that is smaller the better the model fit.

Then solution <- optimr(startparameters, myobj, method="chosen-method")

will try to optimize. If you can supply a gradient function, then you will usually do much better.

My book, Nonlinear Parameter Optimization Using R Tools (2014) gives quite a few examples, but doesn't
have the optimr() function -- it's more recent.

And do -- repeat do -- check your function VERY carefully. It is worth it. If the objective is in any
way wrong, badly scaled, etc. you WILL get into trouble.

John Nash




On 2018-07-13 02:43 PM, Federico Becerra wrote:
> Good afternoon,
> 
> I am a Biology researcher working on Functional Morphology and Behaviour in mammals. Nowadays, I have a series of
> morphological data that I would like to test against different models for which I would need to optimize them -namely,
> "randomly manipulating" all models parameters in order to find the model that fit best upon my data.
> 
> I've been told that the function "optim" is THE function for me, but I've been having problems to program it and set all
> constraints.
> 
> Is there anything you could help me (guide me) with? I've asked already several "experts" in the internet but noone gave
> me a real solution.
> 
> Thanks a lot, have a nice day,
> Federico
>


From f@bbropietro @ending from y@hoo@it  Sat Jul 14 11:40:57 2018
From: f@bbropietro @ending from y@hoo@it (P95 F95)
Date: Sat, 14 Jul 2018 11:40:57 +0200
Subject: [R] Custom Indicator Quantstrat Problem
Message-ID: <24DBB882-6991-4DED-93A2-6DAA97F63304@yahoo.it>

Hi. 

I am new in the forum and in R, I would like to ask for help. 
I am trying to add a custom indicator in quantstrat for my trading strategy 
but something does not work. 

When I insert the command: 

#out <- applyStrategy(strategy=strategy.st <http://strategy.st/>,portfolios=portfolio.st <http://portfolio.st/>) 

I get: 

#Error in .xts(e, .index(e1), .indexCLASS = indexClass(e1), .indexFORMAT = 
#indexFormat(e1),  : 
#index length must match number of observations 
#Inoltre: Warning messages: 
#1: In match.names(column, colnames(data)) : 
#all columns not located in CNOwma for RUT.Open RUT.High RUT.Low RUT.Close 
#RUT.Volume RUT.Adjusted X1.Channel.Normalization.Operator.smoothed.by.a.LWMA 
#2: In min(j, na.rm = TRUE) : 
#no non-missing arguments to min; returning Inf 
#3: In max(j, na.rm = TRUE) : 
#no non-missing arguments to max; returning -Inf 

The coding of the indicator is: 

#wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
#wmamaxt <- rollmaxr(wma, 30, fill = NA) 
#wmamint <- - rollmaxr(- wma, 30, fill = NA) 
#CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - 
#wmamint)} 


The add.indicator function is: 



#add.indicator(strategy = strategy.st <http://strategy.st/>, 
#name = 'CNOwma', 
#arguments = list(quote(Cl(mktdata)[,1]), n=4), 
#label = 'Channel Normalization Operator smoothed by a LWMA') 




The first 32 elements of CNOwma(mktdata) are NA. Could this explain the 
problem?

Thank you,

Best regards,


Pietro Fabbro
	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 14 14:18:18 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 05:18:18 -0700
Subject: [R] Custom Indicator Quantstrat Problem
In-Reply-To: <24DBB882-6991-4DED-93A2-6DAA97F63304@yahoo.it>
References: <24DBB882-6991-4DED-93A2-6DAA97F63304@yahoo.it>
Message-ID: <1BF41FB9-78E2-4948-B7B2-684871617886@dcn.davis.ca.us>

This mailing list is plain text only (read the Posting Guide). When you send HTML-formatted email, what we see is often not what you saw. The solution is for you to figure out how to send your email in plain text format to begin with. Since the syntax in your code below is not valid, I am guessing your message has been corrupted by posting HTML format.

Also, at least half the time your troubles start with the data you have, so it is important to supply enough example data to let the us run your code ourselves and trigger any problem you are having. See any or all of [1][2][3] for advice on how to create a reproducible example.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)


On July 14, 2018 2:40:57 AM PDT, P95 F95 via R-help <r-help at r-project.org> wrote:
>Hi. 
>
>I am new in the forum and in R, I would like to ask for help. 
>I am trying to add a custom indicator in quantstrat for my trading
>strategy 
>but something does not work. 
>
>When I insert the command: 
>
>#out <- applyStrategy(strategy=strategy.st
><http://strategy.st/>,portfolios=portfolio.st <http://portfolio.st/>) 
>
>I get: 
>
>#Error in .xts(e, .index(e1), .indexCLASS = indexClass(e1),
>.indexFORMAT = 
>#indexFormat(e1),  : 
>#index length must match number of observations 
>#Inoltre: Warning messages: 
>#1: In match.names(column, colnames(data)) : 
>#all columns not located in CNOwma for RUT.Open RUT.High RUT.Low
>RUT.Close 
>#RUT.Volume RUT.Adjusted
>X1.Channel.Normalization.Operator.smoothed.by.a.LWMA 
>#2: In min(j, na.rm = TRUE) : 
>#no non-missing arguments to min; returning Inf 
>#3: In max(j, na.rm = TRUE) : 
>#no non-missing arguments to max; returning -Inf 
>
>The coding of the indicator is: 
>
>#wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
>#wmamaxt <- rollmaxr(wma, 30, fill = NA) 
>#wmamint <- - rollmaxr(- wma, 30, fill = NA) 
>#CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) /
>(wmamaxt - 
>#wmamint)} 
>
>
>The add.indicator function is: 
>
>
>
>#add.indicator(strategy = strategy.st <http://strategy.st/>, 
>#name = 'CNOwma', 
>#arguments = list(quote(Cl(mktdata)[,1]), n=4), 
>#label = 'Channel Normalization Operator smoothed by a LWMA') 
>
>
>
>
>The first 32 elements of CNOwma(mktdata) are NA. Could this explain the
>
>problem?
>
>Thank you,
>
>Best regards,
>
>
>Pietro Fabbro
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From f@bbropietro @ending from y@hoo@it  Sat Jul 14 15:02:08 2018
From: f@bbropietro @ending from y@hoo@it (Pietro Fabbro)
Date: Sat, 14 Jul 2018 13:02:08 +0000 (UTC)
Subject: [R] Quantstrat custom indicator colnames error
References: <1074225301.3980976.1531573328594.ref@mail.yahoo.com>
Message-ID: <1074225301.3980976.1531573328594@mail.yahoo.com>

I apologize if the data I will insert will not be enough.

So, I am trying to run a strategy through the package Quantstrat.

install.packages("quantstrat")


My problem is that I get the following error
Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
attempt to set 'colnames' on an object with less than two dimensions

when I try to run the following command:

> out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
I do not have this problem if I use, as indicator, one or more indicators, which are already defined by the package TTR.

I have this error only when I try to use a custom indicator. Here is the code for the custom indicator that I use:

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
Please refer to the following code:

library(devtools)
library(quantmod)
library(quantstrat)
library(TTR)
library(png)
library(IKTrading)

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
initdate <- "2010-01-01"
from <- "2012-01-01" #start of backtest
to <- "2017-31-12" #end of backtest

Sys.setenv(TZ= "EST") #Set up environment for timestamps

currency("USD") #Set up environment for currency to be used

symbols <- c("RUT", "IXIC") #symbols used in our backtest
getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust = TRUE) #receive data from google finance,  adjusted for splits/dividends

stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use

tradesize <-10000 #default trade size
initeq <- 100000 #default initial equity in our portfolio

strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account

#removes old portfolio and strategy from environment
rm.strat(portfolio.st)
rm.strat(strategy.st) 

#initialize portfolio, account, orders and strategy objects
initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")

initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)

initOrders(portfolio.st, initDate = initdate)
strategy(strategy.st, store=TRUE)

add.indicator(strategy = strategy.st,
name = 'CNOwma',
arguments = list(x = quote(Cl(mktdata)), n=4),
label = 'CNOwma4')





add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "gt", cross = TRUE),
label = "longthreshold")


add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "lt", cross = TRUE),
label = "shortthreshold")




add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "enter")


add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "exit")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "enter")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "exit")



out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)


When I run the traceback() of the error, this is what I get:
> traceback()
4: stop("attempt to set 'colnames' on an object with less than two dimensions")
3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters = parameters, 
...)
1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st


From f@bbropietro @ending from y@hoo@it  Sat Jul 14 15:04:07 2018
From: f@bbropietro @ending from y@hoo@it (Pietro Fabbro)
Date: Sat, 14 Jul 2018 13:04:07 +0000 (UTC)
Subject: [R] Error custom indicator Quantstrat colnames
References: <597390662.3985563.1531573447687.ref@mail.yahoo.com>
Message-ID: <597390662.3985563.1531573447687@mail.yahoo.com>

I will try to be as clear as possible as I have been rebuked by some users. I deleted the last questions and I will try to be sufficiently explicative in this one. I apologize if the data I will insert will not be enough.

So, I am trying to run a strategy through the package Quantstrat.

install.packages("quantstrat")
My problem is that I get the following error

Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
attempt to set 'colnames' on an object with less than two dimensions

when I try to run the following command:

> out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
I do not have this problem if I use, as indicator, one or more indicators, which are already defined by the package TTR.

I have this error only when I try to use a custom indicator. Here is the code for the custom indicator that I use:

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
Please refer to the following code:

library(devtools)
library(quantmod)
library(quantstrat)
library(TTR)
library(png)
library(IKTrading)

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
initdate <- "2010-01-01"
from <- "2012-01-01" #start of backtest
to <- "2017-31-12" #end of backtest

Sys.setenv(TZ= "EST") #Set up environment for timestamps

currency("USD") #Set up environment for currency to be used

symbols <- c("RUT", "IXIC") #symbols used in our backtest
getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust = TRUE) #receive data from google finance,  adjusted for splits/dividends

stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use

tradesize <-10000 #default trade size
initeq <- 100000 #default initial equity in our portfolio

strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account

#removes old portfolio and strategy from environment
rm.strat(portfolio.st)
rm.strat(strategy.st) 

#initialize portfolio, account, orders and strategy objects
initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")

initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)

initOrders(portfolio.st, initDate = initdate)
strategy(strategy.st, store=TRUE)

add.indicator(strategy = strategy.st,
name = 'CNOwma',
arguments = list(x = quote(Cl(mktdata)), n=4),
label = 'CNOwma4')





add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "gt", cross = TRUE),
label = "longthreshold")


add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "lt", cross = TRUE),
label = "shortthreshold")




add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "enter")


add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "exit")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "enter")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "exit")



out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
When I run the traceback() of the error, this is what I get:

> traceback()
4: stop("attempt to set 'colnames' on an object with less than two dimensions")
3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters = parameters, 
...)
1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st)


From ted@h@rding @ending from wl@ndre@@net  Sat Jul 14 18:05:27 2018
From: ted@h@rding @ending from wl@ndre@@net (Ted Harding)
Date: Sat, 14 Jul 2018 17:05:27 +0100
Subject: [R] Error custom indicator Quantstrat colnames
In-Reply-To: <597390662.3985563.1531573447687@mail.yahoo.com>
References: <597390662.3985563.1531573447687.ref@mail.yahoo.com>
 <597390662.3985563.1531573447687@mail.yahoo.com>
Message-ID: <1531584327.3808.32.camel@deb2.fort.knox.uk>

Pietro,
Please post this to r-help at r-project.org
not to r-help-owner at r-project.org
which is a mailing liat concerned with list management, and
does not deal with questions regarding the use of R.
Best wishes,
Ted.

On Sat, 2018-07-14 at 13:04 +0000, Pietro Fabbro via R-help wrote:
> I will try to be as clear as possible as I have been rebuked by some users. I deleted the last questions and I will try to be sufficiently explicative in this one. I apologize if the data I will insert will not be enough.
> 
> So, I am trying to run a strategy through the package Quantstrat.
> 
> install.packages("quantstrat")
> My problem is that I get the following error
> 
> Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
> attempt to set 'colnames' on an object with less than two dimensions
> 
> when I try to run the following command:
> 
> > out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
> I do not have this problem if I use, as indicator, one or more indicators, which are already defined by the package TTR.
> 
> I have this error only when I try to use a custom indicator. Here is the code for the custom indicator that I use:
> 
> wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
> wmamaxt <- rollmaxr(wma, 30, fill = NA)
> wmamint <- - rollmaxr(- wma, 30, fill = NA)
> CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
> Please refer to the following code:
> 
> library(devtools)
> library(quantmod)
> library(quantstrat)
> library(TTR)
> library(png)
> library(IKTrading)
> 
> wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
> wmamaxt <- rollmaxr(wma, 30, fill = NA)
> wmamint <- - rollmaxr(- wma, 30, fill = NA)
> CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
> initdate <- "2010-01-01"
> from <- "2012-01-01" #start of backtest
> to <- "2017-31-12" #end of backtest
> 
> Sys.setenv(TZ= "EST") #Set up environment for timestamps
> 
> currency("USD") #Set up environment for currency to be used
> 
> symbols <- c("RUT", "IXIC") #symbols used in our backtest
> getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust = TRUE) #receive data from google finance,  adjusted for splits/dividends
> 
> stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use
> 
> tradesize <-10000 #default trade size
> initeq <- 100000 #default initial equity in our portfolio
> 
> strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account
> 
> #removes old portfolio and strategy from environment
> rm.strat(portfolio.st)
> rm.strat(strategy.st) 
> 
> #initialize portfolio, account, orders and strategy objects
> initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")
> 
> initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)
> 
> initOrders(portfolio.st, initDate = initdate)
> strategy(strategy.st, store=TRUE)
> 
> add.indicator(strategy = strategy.st,
> name = 'CNOwma',
> arguments = list(x = quote(Cl(mktdata)), n=4),
> label = 'CNOwma4')
> 
> 
> 
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "gt", cross = TRUE),
> label = "longthreshold")
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "lt", cross = TRUE),
> label = "shortthreshold")
> 
> 
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"),
> type = "enter")
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),
> type = "enter")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> 
> 
> out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
> When I run the traceback() of the error, this is what I get:
> 
> > traceback()
> 4: stop("attempt to set 'colnames' on an object with less than two dimensions")
> 3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
> 2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters = parameters, 
> ...)
> 1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 14 19:13:21 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 10:13:21 -0700
Subject: [R] Quantstrat custom indicator colnames error
In-Reply-To: <1074225301.3980976.1531573328594@mail.yahoo.com>
References: <1074225301.3980976.1531573328594.ref@mail.yahoo.com>
 <1074225301.3980976.1531573328594@mail.yahoo.com>
Message-ID: <132EE7A3-D9DA-48D6-BA78-87A30639A108@dcn.davis.ca.us>

Thank you for for reposting a readable question, though the origin of quantstrat and IKTrading on github still took some study, and I cannot see where mktdata was supposed to come from.

If you get no expert response here, you might get a more appropriate set of users if you ask this question on the R-Sig-finance mailing list (where readers might actually recognize the issue offhand), or by asking your question at the quantstrat issues forum [1]. Packages that don't build clean enough to install from CRAN can really lead to wild goose chases debugging the package rather than helping someone understand R (the topic of this mailing list).

No matter where you ask this question, getting the code to be internally complete including data (study up on the dput function in the links I pointed you at
to before) will really help your helpers and you will learn more about R yourself. The reprex package I mentioned makes it easy to confirm that others have a good chance to see the behavior you saw when they run your example.

[1] https://github.com/Braddock/quantstrat

On July 14, 2018 6:02:08 AM PDT, Pietro Fabbro via R-help <r-help at r-project.org> wrote:
>I apologize if the data I will insert will not be enough.
>
>So, I am trying to run a strategy through the package Quantstrat.
>
>install.packages("quantstrat")
>
>
>My problem is that I get the following error
>Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
>attempt to set 'colnames' on an object with less than two dimensions
>
>when I try to run the following command:
>
>> out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
>I do not have this problem if I use, as indicator, one or more
>indicators, which are already defined by the package TTR.
>
>I have this error only when I try to use a custom indicator. Here is
>the code for the custom indicator that I use:
>
>wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
>wmamaxt <- rollmaxr(wma, 30, fill = NA)
>wmamint <- - rollmaxr(- wma, 30, fill = NA)
>CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) /
>(wmamaxt - wmamint)}
>Please refer to the following code:
>
>library(devtools)
>library(quantmod)
>library(quantstrat)
>library(TTR)
>library(png)
>library(IKTrading)
>
>wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
>wmamaxt <- rollmaxr(wma, 30, fill = NA)
>wmamint <- - rollmaxr(- wma, 30, fill = NA)
>CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) /
>(wmamaxt - wmamint)}
>initdate <- "2010-01-01"
>from <- "2012-01-01" #start of backtest
>to <- "2017-31-12" #end of backtest
>
>Sys.setenv(TZ= "EST") #Set up environment for timestamps
>
>currency("USD") #Set up environment for currency to be used
>
>symbols <- c("RUT", "IXIC") #symbols used in our backtest
>getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust
>= TRUE) #receive data from google finance,  adjusted for
>splits/dividends
>
>stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what
>instruments present and what currency to use
>
>tradesize <-10000 #default trade size
>initeq <- 100000 #default initial equity in our portfolio
>
>strategy.st <- portfolio.st <- account.st <- "firststrat" #naming
>strategy, portfolio and account
>
>#removes old portfolio and strategy from environment
>rm.strat(portfolio.st)
>rm.strat(strategy.st) 
>
>#initialize portfolio, account, orders and strategy objects
>initPortf(portfolio.st, symbols = symbols, initDate = initdate,
>currency = "USD")
>
>initAcct(account.st, portfolios = portfolio.st, initDate = initdate,
>currency = "USD", initEq = initeq)
>
>initOrders(portfolio.st, initDate = initdate)
>strategy(strategy.st, store=TRUE)
>
>add.indicator(strategy = strategy.st,
>name = 'CNOwma',
>arguments = list(x = quote(Cl(mktdata)), n=4),
>label = 'CNOwma4')
>
>
>
>
>
>add.signal(strategy.st, name = "sigThreshold",
>arguments = list(column = "CNOwma4", threshold = 0.6,
>relationship = "gt", cross = TRUE),
>label = "longthreshold")
>
>
>add.signal(strategy.st, name = "sigThreshold",
>arguments = list(column = "CNOwma4", threshold = 0.6,
>relationship = "lt", cross = TRUE),
>label = "shortthreshold")
>
>
>
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "longthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "long", replace = FALSE,
>prefer = "Open"),
>type = "enter")
>
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "shortthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "long", replace = FALSE,
>prefer = "Open"),
>type = "exit")
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "shortthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "short", replace = FALSE,
>prefer = "Open"),
>type = "enter")
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "longthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "short", replace = FALSE,
>prefer = "Open"),
>type = "exit")
>
>
>
>out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
>
>
>When I run the traceback() of the error, this is what I get:
>> traceback()
>4: stop("attempt to set 'colnames' on an object with less than two
>dimensions")
>3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
>2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters =
>parameters, 
>...)
>1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From f@bbropietro @ending from y@hoo@it  Sat Jul 14 19:41:30 2018
From: f@bbropietro @ending from y@hoo@it (Pietro Fabbro)
Date: Sat, 14 Jul 2018 17:41:30 +0000 (UTC)
Subject: [R] No transactions/positions to chart in Quantstrat
References: <1510027455.4077501.1531590090832.ref@mail.yahoo.com>
Message-ID: <1510027455.4077501.1531590090832@mail.yahoo.com>

Hello.
I get the error message that there are no transactions/positions to chart despite the signals and rules that I inserted.
Can someone please help?

rm(list = ls(.blotter), envir = .blotter)
initdate <- "2010-01-01"
from <- "2012-01-01" #start of backtest
to <- "2017-31-12" #end of backtest

Sys.setenv(TZ= "EST") #Set up environment for timestamps

currency("USD") #Set up environment for currency to be used

symbols <- c("RUT") #symbols used in our backtest
getSymbols("^RUT",src="yahoo", from="2012-01-01", to="2017-12-31", periodicity="daily")

stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use

n <- 30

wma <-  WMA(Cl(RUT), n=4, wts=c(1:4))
wmamaxt <-  rollmaxr(wma, n, fill = NA)
wmamint <- - rollmaxr(- wma, n, fill = NA)
CNOwma <- function (RUT) {(wma - wmamint) / (wmamaxt - wmamint)}

tradesize <-10000 #default trade size
initeq <- 100000 #default initial equity in our portfolio

strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account

#removes old portfolio and strategy from environment
rm.strat(portfolio.st)
rm.strat(strategy.st) 

#initialize portfolio, account, orders and strategy objects
initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")

initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)

initOrders(portfolio.st, initDate = initdate)
strategy(strategy.st, store=TRUE)

add.indicator(strategy = strategy.st,
name = 'CNOwma',
arguments = list(x = quote(Cl(mktdata)), n=4),
label = 'CNOwma4')





add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "gt", cross = TRUE),
label = "longthreshold")


add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "lt", cross = TRUE),
label = "shortthreshold")




add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"), osFUN = IKTrading::osMaxDollar,
tradeSize = tradesize, maxSize = tradesize, type = "enter")


add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "exit")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),osFUN = IKTrading::osMaxDollar, 
tradeSize = tradesize, maxSize = tradesize, type = "enter")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "exit")



out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
updatePortf(portfolio.st)
daterange <- time(getPortfolio(portfolio.st)$summary)[-1]

updateAcct(account.st, daterange)
updateEndEq(account.st)


for(symbol in symbols){

chart.Posn(Portfolio = portfolio.st, Symbol = symbol, 
TA= c("add_SMA(n=50, col='blue')", "add_SMA(n=200, col='red')"))
}


From dwin@emiu@ @ending from comc@@t@net  Sun Jul 15 04:23:18 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sat, 14 Jul 2018 19:23:18 -0700
Subject: [R] No transactions/positions to chart in Quantstrat
In-Reply-To: <1510027455.4077501.1531590090832@mail.yahoo.com>
References: <1510027455.4077501.1531590090832.ref@mail.yahoo.com>
 <1510027455.4077501.1531590090832@mail.yahoo.com>
Message-ID: <9A695495-B8F2-4CD9-A727-CAD985DD7AEA@comcast.net>


> On Jul 14, 2018, at 10:41 AM, Pietro Fabbro via R-help <r-help at r-project.org> wrote:
> 
> Hello.
> I get the error message that there are no transactions/positions to chart despite the signals and rules that I inserted.

This might or might not be on-topic for Rhelp. If there is a particular form for  a strategy" that the unnamed packages with these function in them that you have misread, tehre might be a purely R answer to this. However, I think you should consider posting at the Quantitative Finance forum at stackexchange.com.

-- 
David.


> Can someone please help?
> 
> rm(list = ls(.blotter), envir = .blotter)
> initdate <- "2010-01-01"
> from <- "2012-01-01" #start of backtest
> to <- "2017-31-12" #end of backtest
> 
> Sys.setenv(TZ= "EST") #Set up environment for timestamps
> 
> currency("USD") #Set up environment for currency to be used
> 
> symbols <- c("RUT") #symbols used in our backtest
> getSymbols("^RUT",src="yahoo", from="2012-01-01", to="2017-12-31", periodicity="daily")
> 
> stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use
> 
> n <- 30
> 
> wma <-  WMA(Cl(RUT), n=4, wts=c(1:4))
> wmamaxt <-  rollmaxr(wma, n, fill = NA)
> wmamint <- - rollmaxr(- wma, n, fill = NA)
> CNOwma <- function (RUT) {(wma - wmamint) / (wmamaxt - wmamint)}
> 
> tradesize <-10000 #default trade size
> initeq <- 100000 #default initial equity in our portfolio
> 
> strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account
> 
> #removes old portfolio and strategy from environment
> rm.strat(portfolio.st)
> rm.strat(strategy.st) 
> 
> #initialize portfolio, account, orders and strategy objects
> initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")
> 
> initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)
> 
> initOrders(portfolio.st, initDate = initdate)
> strategy(strategy.st, store=TRUE)
> 
> add.indicator(strategy = strategy.st,
> name = 'CNOwma',
> arguments = list(x = quote(Cl(mktdata)), n=4),
> label = 'CNOwma4')
> 
> 
> 
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "gt", cross = TRUE),
> label = "longthreshold")
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "lt", cross = TRUE),
> label = "shortthreshold")
> 
> 
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"), osFUN = IKTrading::osMaxDollar,
> tradeSize = tradesize, maxSize = tradesize, type = "enter")
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),osFUN = IKTrading::osMaxDollar, 
> tradeSize = tradesize, maxSize = tradesize, type = "enter")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> 
> 
> out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
> updatePortf(portfolio.st)
> daterange <- time(getPortfolio(portfolio.st)$summary)[-1]
> 
> updateAcct(account.st, daterange)
> updateEndEq(account.st)
> 
> 
> for(symbol in symbols){
> 
> chart.Posn(Portfolio = portfolio.st, Symbol = symbol, 
> TA= c("add_SMA(n=50, col='blue')", "add_SMA(n=200, col='red')"))
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From juli@ni@moon @ending from gm@il@com  Sun Jul 15 04:19:19 2018
From: juli@ni@moon @ending from gm@il@com (Julianony M)
Date: Sat, 14 Jul 2018 21:19:19 -0500
Subject: [R] get "massdist" in R
Message-ID: <CAK6qzcks-cCjXQwstONph2=XXnaxwuAy9H21+GC+Z2bioO5hyA@mail.gmail.com>

I encounter a problem when I ran an R script that's been working for years:

> Rscript kernel_density_script

it complains: "massdist" not available for .C() for package "stats"

I thought an update of R could help, so I did:

> sudo yum update R ... it says: No packages marked for update

Could someone suggest how can I get the R "massdist" installed? (this is a
RHEL7 system)

Thanks in advance!

j

	[[alternative HTML version deleted]]


From t@n@@@ @ending from gm@il@com  Sun Jul 15 07:16:36 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sat, 14 Jul 2018 22:16:36 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
Message-ID: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>

Dear all,

please would you advise on how I could make an even display of unevenly
spaced number on a graph in R. For example, considering the code below :

BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
400, 500)

a <- seq(0,100,0.1)
b <- seq(0,1000,0.1)

plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)

I would like to show on X axis (0, 0.1, 1 and 10) spaced in an equal/even
manner.

thanks !

bogdan

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul 15 07:17:55 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 22:17:55 -0700
Subject: [R] get "massdist" in R
In-Reply-To: <CAK6qzcks-cCjXQwstONph2=XXnaxwuAy9H21+GC+Z2bioO5hyA@mail.gmail.com>
References: <CAK6qzcks-cCjXQwstONph2=XXnaxwuAy9H21+GC+Z2bioO5hyA@mail.gmail.com>
Message-ID: <2DE99FC9-5344-4F42-BB1F-A571A4594B6E@dcn.davis.ca.us>

Roll back your version of R, or find another way to accomplish that calculation. This "abuse" of undocumented functions inside base R has been warned against for a long time [1], so the real puzzle is how you managed to get this far.

[1] http://lists.r-forge.r-project.org/pipermail/vegan-devel/2012-October/000279.html

On July 14, 2018 7:19:19 PM PDT, Julianony M <juliani.moon at gmail.com> wrote:
>I encounter a problem when I ran an R script that's been working for
>years:
>
>> Rscript kernel_density_script
>
>it complains: "massdist" not available for .C() for package "stats"
>
>I thought an update of R could help, so I did:
>
>> sudo yum update R ... it says: No packages marked for update
>
>Could someone suggest how can I get the R "massdist" installed? (this
>is a
>RHEL7 system)
>
>Thanks in advance!
>
>j
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul 15 07:25:41 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 22:25:41 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
Message-ID: <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>

Isn't this what I showed you how to do in [1]?

[1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html

On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear all,
>
>please would you advise on how I could make an even display of unevenly
>spaced number on a graph in R. For example, considering the code below
>:
>
>BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>300,
>400, 500)
>
>a <- seq(0,100,0.1)
>b <- seq(0,1000,0.1)
>
>plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
>plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
>
>I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
>equal/even
>manner.
>
>thanks !
>
>bogdan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From t@n@@@ @ending from gm@il@com  Sun Jul 15 07:34:32 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sat, 14 Jul 2018 22:34:32 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
 <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
Message-ID: <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>

Dear Jeff,

thank you for your prompt reply and kind help.

During our previous conversation, we worked on a different topic, namely
subsetting the dataframe before using ecdf() function in ggplot2.

Now, i would like to know, how I could evenly space on the x axis the
values (0, 0.01, 0.1, 1, 10). Thanks again, and happy weekend ;) !

-- bogdan


On Sat, Jul 14, 2018 at 10:25 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Isn't this what I showed you how to do in [1]?
>
> [1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html
>
> On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >Dear all,
> >
> >please would you advise on how I could make an even display of unevenly
> >spaced number on a graph in R. For example, considering the code below
> >:
> >
> >BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
> >300,
> >400, 500)
> >
> >a <- seq(0,100,0.1)
> >b <- seq(0,1000,0.1)
> >
> >plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
> >plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
> >
> >I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
> >equal/even
> >manner.
> >
> >thanks !
> >
> >bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul 15 08:07:21 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 23:07:21 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
 <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
 <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>
Message-ID: <F244A55A-F233-4E8D-B0BB-6E13DE0C47A4@dcn.davis.ca.us>

But did you run the code? Apparently not.

On July 14, 2018 10:34:32 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear Jeff,
>
>thank you for your prompt reply and kind help.
>
>During our previous conversation, we worked on a different topic,
>namely
>subsetting the dataframe before using ecdf() function in ggplot2.
>
>Now, i would like to know, how I could evenly space on the x axis the
>values (0, 0.01, 0.1, 1, 10). Thanks again, and happy weekend ;) !
>
>-- bogdan
>
>
>On Sat, Jul 14, 2018 at 10:25 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Isn't this what I showed you how to do in [1]?
>>
>> [1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html
>>
>> On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
>wrote:
>> >Dear all,
>> >
>> >please would you advise on how I could make an even display of
>unevenly
>> >spaced number on a graph in R. For example, considering the code
>below
>> >:
>> >
>> >BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>> >300,
>> >400, 500)
>> >
>> >a <- seq(0,100,0.1)
>> >b <- seq(0,1000,0.1)
>> >
>> >plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
>> >plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
>> >
>> >I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
>> >equal/even
>> >manner.
>> >
>> >thanks !
>> >
>> >bogdan
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From drjimlemon @ending from gm@il@com  Sun Jul 15 09:43:27 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sun, 15 Jul 2018 17:43:27 +1000
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
Message-ID: <CA+8X3fU-zhLotEq4dNiKg+eBtFrf1DoMDrZNPAAc=G1MzSpmaw@mail.gmail.com>

Hi Bogdan,
There seem to be three problems. One is that if you want a logarithmic
x axis you shouldn't have a zero (or a negative number) in your data.
The second is that you have to ask for a logarithmic axis. The third
is that you have limited your x axis to less than the range of the
data in "b"::

plot(ecdf(b),xlim=c(0.1,1000),col="red",main=NA,log="x")
plot(ecdf(a),col="green",add=TRUE)

Jim

On Sun, Jul 15, 2018 at 3:16 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear all,
>
> please would you advise on how I could make an even display of unevenly
> spaced number on a graph in R. For example, considering the code below :
>
> BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
> 400, 500)
>
> a <- seq(0,100,0.1)
> b <- seq(0,1000,0.1)
>
> plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
> plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
>
> I would like to show on X axis (0, 0.1, 1 and 10) spaced in an equal/even
> manner.
>
> thanks !
>
> bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From t@n@@@ @ending from gm@il@com  Sun Jul 15 14:22:22 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sun, 15 Jul 2018 05:22:22 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <F244A55A-F233-4E8D-B0BB-6E13DE0C47A4@dcn.davis.ca.us>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
 <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
 <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>
 <F244A55A-F233-4E8D-B0BB-6E13DE0C47A4@dcn.davis.ca.us>
Message-ID: <CA+JEM00dmWjVWPVhR6T6Pfh5EC3T=Xm0d0hKWnvaNG+F8YrEXg@mail.gmail.com>

Hi Jeff,

thank you again for your help, and for your suggestion to subset the data :

DF500 <- subset( DF, LENGTH < 500 )

yes, I did run the code, and I believe that it is easier to present/defend
the results, after using "subset".

-- bogdan

On Sat, Jul 14, 2018 at 11:07 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> But did you run the code? Apparently not.
>
> On July 14, 2018 10:34:32 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >Dear Jeff,
> >
> >thank you for your prompt reply and kind help.
> >
> >During our previous conversation, we worked on a different topic,
> >namely
> >subsetting the dataframe before using ecdf() function in ggplot2.
> >
> >Now, i would like to know, how I could evenly space on the x axis the
> >values (0, 0.01, 0.1, 1, 10). Thanks again, and happy weekend ;) !
> >
> >-- bogdan
> >
> >
> >On Sat, Jul 14, 2018 at 10:25 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Isn't this what I showed you how to do in [1]?
> >>
> >> [1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html
> >>
> >> On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
> >wrote:
> >> >Dear all,
> >> >
> >> >please would you advise on how I could make an even display of
> >unevenly
> >> >spaced number on a graph in R. For example, considering the code
> >below
> >> >:
> >> >
> >> >BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
> >> >300,
> >> >400, 500)
> >> >
> >> >a <- seq(0,100,0.1)
> >> >b <- seq(0,1000,0.1)
> >> >
> >> >plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
> >> >plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
> >> >
> >> >I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
> >> >equal/even
> >> >manner.
> >> >
> >> >thanks !
> >> >
> >> >bogdan
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From nel@on@ibb@78 @ending from y@hoo@com  Sun Jul 15 14:25:50 2018
From: nel@on@ibb@78 @ending from y@hoo@com (Nelson Sibanda)
Date: Sun, 15 Jul 2018 12:25:50 +0000 (UTC)
Subject: [R] (no subject)
References: <225966679.4291596.1531657550430.ref@mail.yahoo.com>
Message-ID: <225966679.4291596.1531657550430@mail.yahoo.com>

UNSCRIBE
	[[alternative HTML version deleted]]


From m@notembe @ending from gm@il@com  Sun Jul 15 15:25:43 2018
From: m@notembe @ending from gm@il@com (Atanasio Alberto Tembe Tembe)
Date: Sun, 15 Jul 2018 22:25:43 +0900
Subject: [R] (no subject)
Message-ID: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>

Hello!

Is there anyone who can help me to this the error bellow? Ijust
started using R recently. Thank you


while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol in "while
sum">     >     k=K+1>     >     for(i in 1:nrow(c1)){+         +
   for(j in 1:ncol(c1)){+             +             if(Sb!=0){+
         +                 T2=D*T/Sa+                 +
}else {+                 +                 T2=0       +
 +             }+             +             Sc=sum(t(T))+
+             if(Sc!=0){+                 +
T3=Pi*T2/Sc+                 +             }else {+                 +
               T3=0+                 +             }+
Sb=sum(T)+             +         }+     }>     >     K[1] 0

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul 15 18:02:55 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 15 Jul 2018 09:02:55 -0700
Subject: [R] (no subject)
In-Reply-To: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
References: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
Message-ID: <0BC4561F-853E-46DD-B6A6-483B49FBCFD5@dcn.davis.ca.us>

I think you are missing a parenthesis around your condition [1][2].

For future reference:
a) You should post the code you ran as well as the error message... it is unusual for the error message alone to be enough to figure out the problem. In fact, try to make a "reproducible example" [3][4][5]... you will increase your chances of getting an answer.
b) Your message was garbled... in some cases this can completely obscure your question. You can prevent that from happening by setting your email program to create a plain text email whenever you post here.
c) Remember to put a subject line on your email.

[1] https://stat.ethz.ch/R-manual/R-devel/library/base/html/Control.html
[2] https://www-r--bloggers-com.cdn.ampproject.org/v/s/www.r-bloggers.com/control-structures-loops-in-r/
[3] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[4] http://adv-r.had.co.nz/Reproducibility.html

[5] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On July 15, 2018 6:25:43 AM PDT, Atanasio Alberto Tembe Tembe <manotembe at gmail.com> wrote:
>Hello!
>
>Is there anyone who can help me to this the error bellow? Ijust
>started using R recently. Thank you
>
>
>while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol in "while
>sum">     >     k=K+1>     >     for(i in 1:nrow(c1)){+         +
>   for(j in 1:ncol(c1)){+             +             if(Sb!=0){+
>         +                 T2=D*T/Sa+                 +
>}else {+                 +                 T2=0       +
> +             }+             +             Sc=sum(t(T))+
>+             if(Sc!=0){+                 +
>T3=Pi*T2/Sc+                 +             }else {+                 +
>               T3=0+                 +             }+
>Sb=sum(T)+             +         }+     }>     >     K[1] 0
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From btyner @ending from gm@il@com  Mon Jul 16 04:25:27 2018
From: btyner @ending from gm@il@com (Benjamin Tyner)
Date: Sun, 15 Jul 2018 22:25:27 -0400
Subject: [R] undo compile? (or: remove bytecode from closure)
Message-ID: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>

Hi

Given a closure which has been compiled, what's the recommended way to 
recover the original? For example,

 ??? > f <- function(x) x+1
 ??? > fc <- cmpfun(f)
 ??? > rm(f)
 ??? > fc
 ??? function(x) x+1
 ??? <bytecode: 0x41d9228>

what's the best way to recover f from fc ?

Regards

Ben


From ntfredo @ending from gm@il@com  Mon Jul 16 08:42:10 2018
From: ntfredo @ending from gm@il@com (Frederic Ntirenganya)
Date: Mon, 16 Jul 2018 09:42:10 +0300
Subject: [R] Help in debugging a script
Message-ID: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>

Dear Friends,

I would like to ask for help.
I am plotting monthly data as seasonal by adding particular months but I am
getting an unexpected graph. What I want is why and what can be another
alternative?

Here is the data and R script

busoro <- read.csv("G:/Fredo/PAPER/Malaria climate paper/data/NYANZA
DATA/busoro2.csv", header=T)

# x axis
y = 2012:2017
#plot
plot(y,busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
busoro[,"Dec"],type="b",
     ylab="Malaria Cases",xlab="Year")

grid(10,10,lwd=2)

dput((head(busoro)))structure(list(X = 2012:2017, Jan = c(73L, 754L,
1016L, 2651L,
1201L, 3405L), Feb = c(129L, 959L, 1276L, 3917L, 1262L, 3715L
), Mar = c(238L, 770L, 1670L, 3975L, 1379L, 3571L), Apr = c(705L,
875L, 1117L, 3549L, 1021L, 2789L), May = c(915L, 1034L, 1379L,
3092L, 2091L, 3487L), Jun = c(985L, 741L, 1612L, 4351L, 1599L,
1662L), Jul = c(402L, 115L, 901L, 3394L, 623L, 817L), Aug = c(337L,
218L, 966L, 1002L, 732L, 755L), Sep = c(353L, 580L, 2284L, 2427L,
2033L, 1134L), Oct = c(1016L, 1243L, 2788L, 3571L, 2940L, 1763L
), Nov = c(682L, 1336L, 2229L, 2730L, 2866L, 1469L), Dec = c(641L,
1049L, 1701L, 1380L, 2153L, 1321L)), .Names = c("X", "Jan", "Feb",
"Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov",
"Dec"), row.names = c(NA, 6L), class = "data.frame")


Thanks in advance.


Frederic Ntirenganya
Nyanza District,
Data Mnager.
Mobile:(+250)788757619
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Mon Jul 16 08:49:17 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 16 Jul 2018 08:49:17 +0200
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CAJuCY5zSMp3xBhKX2rgHPa2NyHruuMMESwiWDDpCFDrXrGYeWg@mail.gmail.com>

Dear Laura,

I came across the anipaths package
(https://cran.r-project.org/web/packages/anipaths/vignettes/anipaths.html)
It might be useful for you.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-07-09 14:13 GMT+02:00 Laura Steel <laura.steel at magd.ox.ac.uk>:
> I am a beginner to R and I need to map some Atlantic puffin migration routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipb@rr@d@@ @ending from @@po@pt  Mon Jul 16 11:22:02 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Mon, 16 Jul 2018 10:22:02 +0100
Subject: [R] (no subject)
In-Reply-To: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
References: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
Message-ID: <aa3fbed7-6be7-3076-89f6-40bbee33046f@sapo.pt>

Hello,

Please repost in plain text, NO HTML formating.

Also, you are missing an open parenthesis right after while:

while( sum(abs(Sb-D-Sc-t(Pi))>1E-5)){


Hope this helps,

Rui Barradas

?s 14:25 de 15-07-2018, Atanasio Alberto Tembe Tembe escreveu:
> Hello!
> 
> Is there anyone who can help me to this the error bellow? Ijust
> started using R recently. Thank you
> 
> 
> while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol in "while
> sum">     >     k=K+1>     >     for(i in 1:nrow(c1)){+         +
>     for(j in 1:ncol(c1)){+             +             if(Sb!=0){+
>           +                 T2=D*T/Sa+                 +
> }else {+                 +                 T2=0       +
>   +             }+             +             Sc=sum(t(T))+
> +             if(Sc!=0){+                 +
> T3=Pi*T2/Sc+                 +             }else {+                 +
>                 T3=0+                 +             }+
> Sb=sum(T)+             +         }+     }>     >     K[1] 0
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipb@rr@d@@ @ending from @@po@pt  Mon Jul 16 11:31:13 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Mon, 16 Jul 2018 10:31:13 +0100
Subject: [R] undo compile? (or: remove bytecode from closure)
In-Reply-To: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
References: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
Message-ID: <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>

Hello,

Maybe the following is not the recommended way but it works
(and I believe makes sense).


f <- function(){}
formals(f) <- formals(fc)
body(f) <- body(fc)

f
#function (x)
#{
#  x <- x + 1
#  pi * x
#}

f(1)
#[1] 6.283185


Hope this helps,

Rui Barradas

?s 03:25 de 16-07-2018, Benjamin Tyner escreveu:
> Hi
> 
> Given a closure which has been compiled, what's the recommended way to 
> recover the original? For example,
> 
>  ??? > f <- function(x) x+1
>  ??? > fc <- cmpfun(f)
>  ??? > rm(f)
>  ??? > fc
>  ??? function(x) x+1
>  ??? <bytecode: 0x41d9228>
> 
> what's the best way to recover f from fc ?
> 
> Regards
> 
> Ben
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon @ending from gm@il@com  Mon Jul 16 12:00:33 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Mon, 16 Jul 2018 20:00:33 +1000
Subject: [R] Help in debugging a script
In-Reply-To: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>
References: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>
Message-ID: <CA+8X3fVGy2GB=fyxKjnJvXEtnC2biJcxbWxZgoSXThNb1ahKUQ@mail.gmail.com>

Hi Frederic,
You are asking for the sum of cases in the months September to
December for the years 2012 to 2017. I get a plot that shows that
from:

plot(busoro[,"X"],busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
busoro[,"Dec"],type="b",ylab="Malaria Cases",xlab="Year")

What sort of plot were you expecting?

Jim

On Mon, Jul 16, 2018 at 4:42 PM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> Dear Friends,
>
> I would like to ask for help.
> I am plotting monthly data as seasonal by adding particular months but I am
> getting an unexpected graph. What I want is why and what can be another
> alternative?
>
> Here is the data and R script
>
> busoro <- read.csv("G:/Fredo/PAPER/Malaria climate paper/data/NYANZA
> DATA/busoro2.csv", header=T)
>
> # x axis
> y = 2012:2017
> #plot
> plot(y,busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
> busoro[,"Dec"],type="b",
>      ylab="Malaria Cases",xlab="Year")
>
> grid(10,10,lwd=2)
>
> dput((head(busoro)))structure(list(X = 2012:2017, Jan = c(73L, 754L,
> 1016L, 2651L,
> 1201L, 3405L), Feb = c(129L, 959L, 1276L, 3917L, 1262L, 3715L
> ), Mar = c(238L, 770L, 1670L, 3975L, 1379L, 3571L), Apr = c(705L,
> 875L, 1117L, 3549L, 1021L, 2789L), May = c(915L, 1034L, 1379L,
> 3092L, 2091L, 3487L), Jun = c(985L, 741L, 1612L, 4351L, 1599L,
> 1662L), Jul = c(402L, 115L, 901L, 3394L, 623L, 817L), Aug = c(337L,
> 218L, 966L, 1002L, 732L, 755L), Sep = c(353L, 580L, 2284L, 2427L,
> 2033L, 1134L), Oct = c(1016L, 1243L, 2788L, 3571L, 2940L, 1763L
> ), Nov = c(682L, 1336L, 2229L, 2730L, 2866L, 1469L), Dec = c(641L,
> 1049L, 1701L, 1380L, 2153L, 1321L)), .Names = c("X", "Jan", "Feb",
> "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov",
> "Dec"), row.names = c(NA, 6L), class = "data.frame")
>
>
> Thanks in advance.
>
>
> Frederic Ntirenganya
> Nyanza District,
> Data Mnager.
> Mobile:(+250)788757619
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ntfredo @ending from gm@il@com  Mon Jul 16 12:07:33 2018
From: ntfredo @ending from gm@il@com (Frederic Ntirenganya)
Date: Mon, 16 Jul 2018 13:07:33 +0300
Subject: [R] Help in debugging a script
In-Reply-To: <CA+8X3fVGy2GB=fyxKjnJvXEtnC2biJcxbWxZgoSXThNb1ahKUQ@mail.gmail.com>
References: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>
 <CA+8X3fVGy2GB=fyxKjnJvXEtnC2biJcxbWxZgoSXThNb1ahKUQ@mail.gmail.com>
Message-ID: <CAGh51gS-M5g=x5=XhFxizj2eg_mwk722dwqzroKQhXT5kbP6UQ@mail.gmail.com>

Dear Jim,

I am asking the sum of malaria cases from Sep to Dec. I am also getting the
plot but which has false values.

After going through them, I found that the script is giving the right
results.

Thanks alot.

Frederic Ntirenganya
Nyanza District,
Data Mnager.
Mobile:(+250)788757619
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Mon, Jul 16, 2018 at 1:00 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Frederic,
> You are asking for the sum of cases in the months September to
> December for the years 2012 to 2017. I get a plot that shows that
> from:
>
> plot(busoro[,"X"],busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
> busoro[,"Dec"],type="b",ylab="Malaria Cases",xlab="Year")
>
> What sort of plot were you expecting?
>
> Jim
>
> On Mon, Jul 16, 2018 at 4:42 PM, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
> > Dear Friends,
> >
> > I would like to ask for help.
> > I am plotting monthly data as seasonal by adding particular months but I
> am
> > getting an unexpected graph. What I want is why and what can be another
> > alternative?
> >
> > Here is the data and R script
> >
> > busoro <- read.csv("G:/Fredo/PAPER/Malaria climate paper/data/NYANZA
> > DATA/busoro2.csv", header=T)
> >
> > # x axis
> > y = 2012:2017
> > #plot
> > plot(y,busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
> > busoro[,"Dec"],type="b",
> >      ylab="Malaria Cases",xlab="Year")
> >
> > grid(10,10,lwd=2)
> >
> > dput((head(busoro)))structure(list(X = 2012:2017, Jan = c(73L, 754L,
> > 1016L, 2651L,
> > 1201L, 3405L), Feb = c(129L, 959L, 1276L, 3917L, 1262L, 3715L
> > ), Mar = c(238L, 770L, 1670L, 3975L, 1379L, 3571L), Apr = c(705L,
> > 875L, 1117L, 3549L, 1021L, 2789L), May = c(915L, 1034L, 1379L,
> > 3092L, 2091L, 3487L), Jun = c(985L, 741L, 1612L, 4351L, 1599L,
> > 1662L), Jul = c(402L, 115L, 901L, 3394L, 623L, 817L), Aug = c(337L,
> > 218L, 966L, 1002L, 732L, 755L), Sep = c(353L, 580L, 2284L, 2427L,
> > 2033L, 1134L), Oct = c(1016L, 1243L, 2788L, 3571L, 2940L, 1763L
> > ), Nov = c(682L, 1336L, 2229L, 2730L, 2866L, 1469L), Dec = c(641L,
> > 1049L, 1701L, 1380L, 2153L, 1321L)), .Names = c("X", "Jan", "Feb",
> > "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov",
> > "Dec"), row.names = c(NA, 6L), class = "data.frame")
> >
> >
> > Thanks in advance.
> >
> >
> > Frederic Ntirenganya
> > Nyanza District,
> > Data Mnager.
> > Mobile:(+250)788757619
> > Email: fredo at aims.ac.za
> > https://sites.google.com/a/aims.ac.za/fredo/
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Mon Jul 16 12:57:45 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Mon, 16 Jul 2018 10:57:45 +0000
Subject: [R] R and Logistic Regression Classifier for ML
Message-ID: <CY1PR0201MB1834CFBC9D9AE98237261D04EA5D0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning.

I am looking for an R package and possibly at tutorial using Logistic Regression as the classifier in a ML algorithm.
I located this URL for use with R pkg "e1071" and the SVM classifier which seems splendid, however, I cannot locate a comparable reference similarly for Logistic Regression.
https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification/SVM

Admittedly I am a novice with ML and trying to teach myself using R (for which I am still quite a novice as well, lol)

Thank you for any direction.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From murdoch@dunc@n @ending from gm@il@com  Mon Jul 16 12:58:31 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Mon, 16 Jul 2018 06:58:31 -0400
Subject: [R] undo compile? (or: remove bytecode from closure)
In-Reply-To: <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>
References: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
 <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>
Message-ID: <ddd3aa5f-81f6-629e-56aa-d4bae35a0311@gmail.com>

On 16/07/2018 5:31 AM, Rui Barradas wrote:
> Hello,
> 
> Maybe the following is not the recommended way but it works
> (and I believe makes sense).
> 
> 
> f <- function(){}
> formals(f) <- formals(fc)
> body(f) <- body(fc)

That's not quite right:  it might lose the environment of fc, if it 
isn't the environment where this took place.  But a simpler solution is just

f <- fc
body(f) <- body(f)

because any assignment to the body of a function causes the bytecode to 
be dropped.

Both of our approaches will also cause the source references to be 
dropped.  If you want to save those, you need more steps:

f <- fc
body(f) <- body(f)
attr(f, "srcref") <- getSrcref(fc)

Duncan Murdoch

> 
> f
> #function (x)
> #{
> #  x <- x + 1
> #  pi * x
> #}
> 
> f(1)
> #[1] 6.283185
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 03:25 de 16-07-2018, Benjamin Tyner escreveu:
>> Hi
>>
>> Given a closure which has been compiled, what's the recommended way to
>> recover the original? For example,
>>
>>   ??? > f <- function(x) x+1
>>   ??? > fc <- cmpfun(f)
>>   ??? > rm(f)
>>   ??? > fc
>>   ??? function(x) x+1
>>   ??? <bytecode: 0x41d9228>
>>
>> what's the best way to recover f from fc ?
>>
>> Regards
>>
>> Ben
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From llewmill@ @ending from gm@il@com  Mon Jul 16 14:23:57 2018
From: llewmill@ @ending from gm@il@com (Llew Mills)
Date: Mon, 16 Jul 2018 22:23:57 +1000
Subject: [R] Hierarchical Version of Bayesian Change Detection Model in JAGS
Message-ID: <CA+9mOqoxY8bU1mSpS9nKJ5cbD3_uyrJh5GmGxGdWQ0QwbB2u8Q@mail.gmail.com>

I am trying to create a hierarchical changepoint detection model in JAGS,
estimating group difference in changepoint based on individual changepoints
in scores for an outcome variable (fictional in this case). I can run a
non-hierarchical version of this same analysis, based on a single set of
scores, but am having trouble with the hierarchical structure in JAGS.

Here is code for creating the toy data. score is a fictional outcome
variable measured on each of 84 days (tracked by variable days) for forty
individuals ( variable id) divided equally among two groups (tracked by
variable group). Data is created so the individuals in group A tend to have
a later breakpoint (around day 34) than those in group B (around day 15).

Here is code for toy data.

    breakpointG1 <- NA
    for (i in 1:20) { breakpointG1[i] <- round(rnorm(1, 34, 5)) }
    breakpointG2 <- NA
    for (i in 1:20) { breakpointG2[i] <- round(rnorm(1, 15, 5)) }
    bps <- c(breakpointG1, breakpointG2)
    group <- rep(c("A", "B"), each = 20)
    df <- data.frame(id = NA, days = NA, group = NA, score = NA)
    for ( i in 1:length(bps) ) {
    pre <- rnorm(bps[i], 40, 3) #
    post <- rnorm(84-bps[i], 25, 3)
    dfi <- data.frame(id = i, days = 1:84, group = rep(group[i], 84), score
= c(pre, post))
    df <- rbind(df, dfi)
    }
    df <- df[-1,]

Plot all participants in one graph, but with a separate loess-smoothed line
for each group.

    ggplot(df, aes(x = days, y = score)) +
           geom_point(aes(colour = factor(id))) +
           geom_smooth(aes(group = group, linetype = group), colour =
"black", span = 0.5, se = F) + guides(colour = F)

The difference in group change thresholds is clearly visible on this graph.
Now for the Bayesian analysis verifying what we can see with our eyes.
First step is to create the data list from the dataframe.

    y <- df$score
    sdY <- sd(y)
    sid <- df$id
    days <- df$days
    nTotal <- nrow(df)
    nDays <- max(df$days)
    nID <- length(unique(sid))
    nG <- length(unique(g))

We also need a vector where each element is the group number of the subject
in question (i.e. there will be 40 elements in this vector)

    groupOfSubject = NULL
    for ( sIdx in 1:nID ) {
      groupOfSubject = c( groupOfSubject , unique(g[sid==sIdx]) )
    }

    dataList = list(y = y,
                    sdY = sdY,
                    g = g,
                    days = days,
                    sid = sid,
                    nTotal = nTotal,
                    nDays = nDays,
                    nID = nID,
                    nG = nG,
                    groupOfSubject = groupOfSubject)


Now the model string for jags. The main things I am interested in
estimating are the group changepoints `muChng[]` and the `muB[]`s for pre-
and post-breakpoint `score`. I have used nested indexing but I must confess
I am out of my depth here.

    cat("
        model{

        # likelihood
        for (oIdx in 1:nTotal) {
        y[oIdx] ~ dnorm(mu[sid[oIdx]], 1/sigma^2)
        mu[sid[oIdx]] <- b1[sid[oIdx]] + step(days[oIdx] -
chng[sid[oIdx]])*b2[sid[oIdx]]
        }

        # priors
            # on subject-level id for b
            for (sIdx in 1:nID) {
                 b1[sIdx] ~ dnorm( muB1[groupOfSubject[sIdx]], 1/10^2 )
                 b2[sIdx] ~ dnorm( muB2[groupOfSubject[sIdx]], 1/10^2 )
                 chng[sIdx] ~ dnorm( muChng[groupOfSubject[sIdx]], 1/10^2 )
                 }

                # prior on group
                for (gIdx in 1:nG) {
                     muB1[gIdx] ~ dnorm(0, 1e-6)
                     muB2[gIdx] ~ dnorm(0, 1e-6)
                     muChng[gIdx] ~ dunif(1,nDays)
                     }

        # prior on Sigma
        sigma ~ dunif(1/sdY*10,sdY*10)

        }", file = "temp.jag")

Next adapt the mcmc chains using `rjags::jags.model()`.

    library(rjags)
    jagsModel <- jags.model(file = "temp.jag",
                            data = dataList,
                            n.chains = 3,
                            n.adapt = 1000)

But the model doesn't run, returning the message

    Error in jags.model(file = "temp.jag", data = dataList, n.chains = 3,
:
      RUNTIME ERROR:
    Compilation error on line 7.
    Attempt to redefine node mu[1]

I am not as familiar with breakpoint models as with the general linear
model so am not sure where I am going wrong. Something to do with the
nested indexing in the definition of `mu[]` in the likelihood function I
think, but I can't see where, and none of the alternatives I have tried
seem to work. I am stuck. Will take any suggestions, from small to a
complete overhaul or a different method. Any help much appreciated.

	[[alternative HTML version deleted]]


From b@mith030465 @ending from gm@il@com  Mon Jul 16 19:46:20 2018
From: b@mith030465 @ending from gm@il@com (Brian Smith)
Date: Mon, 16 Jul 2018 13:46:20 -0400
Subject: [R] grep
Message-ID: <CAEQKoCG0zB6LnS6SE+Gc2a8igBb3wwCSc5Km7Gefc6YMpUTrFg@mail.gmail.com>

Hi,

I was trying to find a pattern ("ABHD14A") in a character string ('xgen' in
example below) using grepl. Note that the individual members may be
separated by a semi-colon.

The correct answer should return:

"ABHD-ACY1 ; ABHD14A" "ABHD14A ; YYY"

I have tried three approaches, but still seem a bit off. Attempt 2 below
gets closest, but it also returns a hit where my pattern is a substring.
Here is my code:

===========


  xgen <- c("XYZ","ABHD-ACY1 ; ABHD14A","ABHD14AXX","ABHD14A ; YYY")
  ga <- "ABHD14A"

  # 1.
  kx <- grepl(paste0("^",ga,"$"),xgen)
  xgen[kx]

  # 2.
  ky <- grepl(ga,xgen)
  xgen[ky]


==============

What do I need to add/change in #2 above?

many thanks!

	[[alternative HTML version deleted]]


From i@t@z@hn @ending from gm@il@com  Mon Jul 16 19:57:34 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Mon, 16 Jul 2018 13:57:34 -0400
Subject: [R] grep
In-Reply-To: <CAEQKoCG0zB6LnS6SE+Gc2a8igBb3wwCSc5Km7Gefc6YMpUTrFg@mail.gmail.com>
References: <CAEQKoCG0zB6LnS6SE+Gc2a8igBb3wwCSc5Km7Gefc6YMpUTrFg@mail.gmail.com>
Message-ID: <CA+vqiLEROQT0c2B3rfZqGH-ZYMaT8NV5odb=k0bwhD25FgVfCw@mail.gmail.com>

grep("(^| )ABHD14A( ;|$)",xgen, value = TRUE)

maybe.

On Mon, Jul 16, 2018 at 1:46 PM, Brian Smith <bsmith030465 at gmail.com> wrote:
> Hi,
>
> I was trying to find a pattern ("ABHD14A") in a character string ('xgen' in
> example below) using grepl. Note that the individual members may be
> separated by a semi-colon.
>
> The correct answer should return:
>
> "ABHD-ACY1 ; ABHD14A" "ABHD14A ; YYY"
>
> I have tried three approaches, but still seem a bit off. Attempt 2 below
> gets closest, but it also returns a hit where my pattern is a substring.
> Here is my code:
>
> ===========
>
>
>   xgen <- c("XYZ","ABHD-ACY1 ; ABHD14A","ABHD14AXX","ABHD14A ; YYY")
>   ga <- "ABHD14A"
>
>   # 1.
>   kx <- grepl(paste0("^",ga,"$"),xgen)
>   xgen[kx]
>
>   # 2.
>   ky <- grepl(ga,xgen)
>   xgen[ky]
>
>
> ==============
>
> What do I need to add/change in #2 above?
>
> many thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chri@ti@n @ending from echoffm@nn@ch  Mon Jul 16 17:13:31 2018
From: chri@ti@n @ending from echoffm@nn@ch (Christian)
Date: Mon, 16 Jul 2018 17:13:31 +0200
Subject: [R] Where does ' Setting LC_CTYPE failed, using "C" ' come from?
Message-ID: <17fa001d-2891-2d8e-2dfc-9c3c387ee7b0@echoffmann.ch>

Hi,

I am fighting to get rid of the messages like:

During startup - Warning messages:
Setting LC_CTYPE failed, using "C"
Setting LC_COLLATE failed, using "C"

This is annoying, because when building a package using R CMD, This 
message keeps cropping up.

Here my R:
Sys.getlocale()
[1] "C"

Sys.getenv()
Apple_PubSub_Socket_Render
                         /private/tmp/com.apple.launchd.QGvw3T6OWU/Render
COLUMNS                 86
COMMAND_MODE            unix2003
DISPLAY                 :0
DYLD_FALLBACK_LIBRARY_PATH
 
/Library/Frameworks/R.framework/Resources/lib:/Library/Java/JavaVirtualMachines/jdk-9.jdk/Contents/Home/lib/server
EDITOR                  vi
HOME                    /Users/hoffmannc
INSIDE_EMACS            25.1.1,comint
LANG                    en_CH.UTF-8
LANGUAGE                en
LN_S                    ln -s
LOGNAME                 hoffmannc
MAKE                    make
PAGER                   cat
PATH 
/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/opt/X11/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/texbin:/Library/TeX/texbin:/usr/local/texlive/2016/bin
PWD                     /Users/hoffmannc/Rtest
R_ARCH
R_BROWSER               /usr/bin/open
R_BZIPCMD               /usr/bin/bzip2
R_DOC_DIR               /Library/Frameworks/R.framework/Resources/doc
R_GZIPCMD               /usr/bin/gzip
R_HOME                  /Library/Frameworks/R.framework/Resources
R_INCLUDE_DIR           /Library/Frameworks/R.framework/Resources/include
R_LIBS_SITE
R_LIBS_USER             ~/Library/R/3.5/library
R_PAPERSIZE             a4
R_PDFVIEWER             /usr/bin/open
R_PLATFORM              x86_64-apple-darwin15.6.0
R_PRINTCMD              lpr
R_QPDF                  /Library/Frameworks/R.framework/Resources/bin/qpdf
R_RD4PDF                times,inconsolata,hyper
R_SESSION_TMPDIR 
/var/folders/rm/pd12qdtn55qc3vc0vg5v0_y40000gn/T//RtmpyBHBm8
R_SHARE_DIR             /Library/Frameworks/R.framework/Resources/share
R_SYSTEM_ABI            osx,gcc,gxx,gfortran,?
R_TEXI2DVICMD           /usr/local/bin/texi2dvi
R_UNZIPCMD              /usr/bin/unzip
R_ZIPCMD                /usr/bin/zip
SECURITYSESSIONID       186a9
SED                     /usr/bin/sed
SHELL                   /bin/bash
SHLVL                   1
SSH_AUTH_SOCK           /private/tmp/com.apple.launchd.z3z87lwMDc/Listeners
STATATERM               emacs
TAR                     /usr/bin/tar
TERM                    dumb
TERMCAP
TMPDIR                  /var/folders/rm/pd12qdtn55qc3vc0vg5v0_y40000gn/T/
USER                    hoffmannc
XPC_FLAGS               0x0
XPC_SERVICE_NAME        0
__CF_USER_TEXT_ENCODING
                         0x1F5:0:0

Pointers are welcome
C.

-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853


From kekwu @ending from ucd@vi@@edu  Mon Jul 16 20:46:06 2018
From: kekwu @ending from ucd@vi@@edu (Kelly Wu)
Date: Mon, 16 Jul 2018 11:46:06 -0700
Subject: [R] How to try different effect sizes for Fisher's exact test?
Message-ID: <4E27D114-DF52-4FCE-A8E3-E5DDCDF793CE@ucdavis.edu>

I am currently working on a simulation, and I would like to see what happens with various effect sizes. How would I test out different effect sizes for the Fisher's exact test with my current code?

  set.seed(23)
  # p1<-response in controls
  # p2<-response in treated
  # Generating random deviates from a Uniform(0,1) distribution
  control.year1<-(runif(16, min = 0, max = 1))
  treat.year1<-(runif(16, min = 0, max = 1))
  
  #Generating dichotomous response variables for each group
  control.respond1<-ifelse(control.year1<=0.05,1,0)
  treat.respond1<-ifelse(treat.year1<=0.30,1,0)
  
  #Summing number of responses from each group
  control.no1<-sum(control.respond1==0)
  control.yes1<-sum(control.respond1==1)
  treat.no1<-sum(treat.respond1==0)
  treat.yes1<-sum(treat.respond1==1)
  
  #Perform the Fisher's exact test (one sided) with p<=0.01
  fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
  f<-fisher.test(fisher,alternative = "greater?) 


Thanks,
Kelly
	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @ending from gm@il@com  Mon Jul 16 22:19:21 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Mon, 16 Jul 2018 13:19:21 -0700
Subject: [R] scale_y_continuous with sec.axis
Message-ID: <52c18b6d-53bb-4e99-8a07-43f19f1634cf@gmail.com>

Hi, I'm using?scale_y_continuous with sec.axis and it's doing what I need but I don't understand how it picks which of the two series becomes the secondary. 

Does anyone have any insight into this? 

Thanks!


From jmh@nnon@ucd@vi@ @ending from gm@il@com  Mon Jul 16 23:16:43 2018
From: jmh@nnon@ucd@vi@ @ending from gm@il@com (Michael Hannon)
Date: Mon, 16 Jul 2018 14:16:43 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <FAD0DE73-F0A8-4D39-B8DF-936549423293@dcn.davis.ca.us>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
 <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
 <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>
 <FAD0DE73-F0A8-4D39-B8DF-936549423293@dcn.davis.ca.us>
Message-ID: <CACdH2ZZXO7-j8CWBRE7-tOsRziaOMBFpdj0f9m6jiGc6B52SAA@mail.gmail.com>

Thanks to all for your replies.  So far as I can see, there was
nothing wrong with my original approach, but I've decided to stuff all
the relevant definitions into a function (or functions), as this seems
to make "devtools::check()" happier.

-- Mike


On Fri, Jul 13, 2018 at 6:54 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Avoiding rda files because they don't track well with version control seems weak to me, since you should be creating the rda with an R file in the tools directory.
>
> On July 13, 2018 6:50:31 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>>What the OP is doing looks fine to me.
>>
>>The environment holding the data vectors is not necessary, but it helps
>>organize things - you know where to look for this sort of data vector.
>>
>>I would avoid the *.rda file, since it is not text, hence not readily
>>editable
>>or trackable with most source control systems.
>>
>>
>>Bill Dunlap
>>TIBCO Software
>>wdunlap tibco.com
>>
>>On Fri, Jul 13, 2018 at 6:17 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us>
>>wrote:
>>
>>> a) There is a mailing list for package development questions:
>>> R-package-devel.
>>>
>>> b) This seems like a job for the sysdata.rda file... no explicit
>>> environments needed. See the Writing R Extensions manual.
>>>
>>> On July 13, 2018 5:51:06 PM PDT, Michael Hannon <
>>> jmhannon.ucdavis at gmail.com> wrote:
>>> >Greetings.  I'm putting together a small package in which I use
>>> >`dplyr::read_csv()` to read CSV files from several different
>>sources.
>>> >I do
>>> >this in several different files, but with various kinds of
>>subsequent
>>> >processing, depending on the file.
>>> >
>>> >I find it useful to specify column types, as the apparent data type
>>of
>>> >a given
>>> >column sometimes changes unexpectedly deep into the file.  I.e., a
>>> >field that
>>> >consistently looks like an integer, suddenly becomes a fraction:
>>> >
>>> >    1, 1, ..., 1, 1/2, 1, ...
>>> >
>>> >Hence, the column type has to be treated as a character, rather than
>>as
>>> >an
>>> >integer (with the possibility of later conversion to double, if
>>> >necessary).
>>> >(This is just an example.)
>>> >
>>> >Therefore I use the `col_types` argument in all of the calls to
>>> >`read_csv()`.
>>> >
>>> >These calls are spread over several files, but I want the keep all
>>of
>>> >the
>>> >column types in a single place, yet have them available in each of
>>the
>>> >several
>>> >files.  This is just for the sake of maintainability.
>>> >
>>> >At the moment I do this by putting the column-type definitions into
>>a
>>> >single,
>>> >file:
>>> >
>>> >    000_define_data_attributes.R
>>> >
>>> >that:
>>> >
>>> >    (1) is named so that it's parsed first by `devtools::build()`
>>> >    (2) sets up an environment and stuffs the column types into it:
>>> >
>>> >            data_env <- new.env(parent=emptyenv())
>>> >            data_env$col_types_alpha <- list(
>>> >                Date = col_date(),
>>> >                var1 = col_double(),
>>> >                ...
>>> >            )
>>> >
>>> >There are a few other things that go into the file as well.
>>> >
>>> >Then I pick off the appropriate stuff from the environment in the
>>other
>>> >files:
>>> >
>>> >foo_alpha <- read_csv("alpha.csv", col_types =
>>> >data_env$col_types_alpha)
>>> >
>>> >This seems to work, but it doesn't "feel" right to me.  (If this
>>were
>>> >Python,
>>> >people would accuse me of being "non-pythonic").
>>> >
>>> >Hence, I'm seeking suggestions for the best practice for this kind
>>of
>>> >thing.
>>> >
>>> >BTW, I note that both the sources of data ("alpha", etc.) and the
>>> >column types
>>> >are more or less guaranteed to be static for the foreseeable future.
>>> >Hence,
>>> >there really isn't much danger in just replicating the column-type
>>> >definitions
>>> >in each of the various files, which would obviate the need for the
>>> >"000..."
>>> >file.  In other words, this is mostly a style thing.
>>> >
>>> >Thanks for any advice you can provide.
>>> >
>>> >-- Mike
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
> --
> Sent from my phone. Please excuse my brevity.


From btyner @ending from gm@il@com  Tue Jul 17 02:23:13 2018
From: btyner @ending from gm@il@com (Benjamin Tyner)
Date: Mon, 16 Jul 2018 20:23:13 -0400
Subject: [R] undo compile? (or: remove bytecode from closure)
In-Reply-To: <ddd3aa5f-81f6-629e-56aa-d4bae35a0311@gmail.com>
References: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
 <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>
 <ddd3aa5f-81f6-629e-56aa-d4bae35a0311@gmail.com>
Message-ID: <b479d1c3-46cb-9635-f903-f06258b7d36c@gmail.com>

Thanks Rui and Duncan, this is most helpful.


On 07/16/2018 06:58 AM, Duncan Murdoch wrote:
> On 16/07/2018 5:31 AM, Rui Barradas wrote:
>> Hello,
>>
>> Maybe the following is not the recommended way but it works
>> (and I believe makes sense).
>>
>>
>> f <- function(){}
>> formals(f) <- formals(fc)
>> body(f) <- body(fc)
>
> That's not quite right:? it might lose the environment of fc, if it 
> isn't the environment where this took place.? But a simpler solution 
> is just
>
> f <- fc
> body(f) <- body(f)
>
> because any assignment to the body of a function causes the bytecode 
> to be dropped.
>
> Both of our approaches will also cause the source references to be 
> dropped.? If you want to save those, you need more steps:
>
> f <- fc
> body(f) <- body(f)
> attr(f, "srcref") <- getSrcref(fc)
>
> Duncan Murdoch
>
>>
>> f
>> #function (x)
>> #{
>> #? x <- x + 1
>> #? pi * x
>> #}
>>
>> f(1)
>> #[1] 6.283185
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 03:25 de 16-07-2018, Benjamin Tyner escreveu:
>>> Hi
>>>
>>> Given a closure which has been compiled, what's the recommended way to
>>> recover the original? For example,
>>>
>>> ? ??? > f <- function(x) x+1
>>> ? ??? > fc <- cmpfun(f)
>>> ? ??? > rm(f)
>>> ? ??? > fc
>>> ? ??? function(x) x+1
>>> ? ??? <bytecode: 0x41d9228>
>>>
>>> what's the best way to recover f from fc ?
>>>
>>> Regards
>>>
>>> Ben
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From mich@el@thomp@on @ending from m@nuk@u@@c@nz  Tue Jul 17 06:53:17 2018
From: mich@el@thomp@on @ending from m@nuk@u@@c@nz (Michael Thompson)
Date: Tue, 17 Jul 2018 04:53:17 +0000
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <1531802918272-0.post@n4.nabble.com>
References: <1531802918272-0.post@n4.nabble.com>
Message-ID: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>

Hi,
I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
of the model to non-DS people?
So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
Michael


From chri@ti@n @ending from echoffm@nn@ch  Tue Jul 17 08:32:49 2018
From: chri@ti@n @ending from echoffm@nn@ch (Christian)
Date: Tue, 17 Jul 2018 08:32:49 +0200
Subject: [R] Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
Message-ID: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>

Hi,

I am fighting to get rid of the messages like:

During startup - Warning messages:
Setting LC_CTYPE failed, using "C"
Setting LC_COLLATE failed, using "C"

This is annoying, because when building a package using R CMD, This 
message keeps cropping up.

Here my R:
Sys.getlocale()
[1] "C"
...................

Executing

     Open Terminal
     Write or paste in: defaults write org.R-project.R force.LANG 
en_US.UTF-8
     Close Terminal
     Start R

as suggested on the Net, did not help :-(

Pointers are welcome
C.

-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853


From @ez@reb@ki @ending from gm@il@com  Tue Jul 17 09:13:09 2018
From: @ez@reb@ki @ending from gm@il@com (Alex Zarebski)
Date: Tue, 17 Jul 2018 17:13:09 +1000
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
References: <1531802918272-0.post@n4.nabble.com>
 <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
Message-ID: <CAKsw2nEuVUyuuYk4XiurH81zpcLv6QQWuZPG_hOfU-+KHuyKAA@mail.gmail.com>

Hey,

Nice question, I'm interested to see what others have to say on this.
I'd like to point out a couple of algorithmic points:

- If you are using regularisation the scaling /will/ lead to different
results.
- If you are using an iterative method to estimate something, (yes very
vague but you get the gist), it can be very useful to know the data is
scaled in a particular way, i.e., it can inform an initial guess for the
iterative method.

On a pedagogical note, it might be interesting to point out to your
students that the act of choosing an scaling/transformation/preprocessing
can be useful as a way of understanding your data better.

Cheers,
Alex

On Tue, Jul 17, 2018 at 4:58 PM Michael Thompson <
michael.thompson at manukau.ac.nz> wrote:

> Hi,
> I seem to remember from classes that one effect of scaling / standardising
> data was to get better results in any analysis. But what I'm seeing when I
> study various explanations on scaling is that we get exactly the same
> results, just that when we look at standardised data it's easier to see
> proportionate effects.
> This is all very well for the data scientist to further investigate, but
> from a practical point of view, (especially IF it doesn't improve the
> accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while
> eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy
> story based on my misunderstanding. Hope you can help with this.
> Michael
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Tue Jul 17 09:39:18 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Tue, 17 Jul 2018 09:39:18 +0200
Subject: [R] scale_y_continuous with sec.axis
In-Reply-To: <52c18b6d-53bb-4e99-8a07-43f19f1634cf@gmail.com>
References: <52c18b6d-53bb-4e99-8a07-43f19f1634cf@gmail.com>
Message-ID: <CAJuCY5ytvW0Z2TmCJo6RH4Uovm2_oGdmMi5qC1yQ0faMnpz5XA@mail.gmail.com>

Dear Anonymous,

Please do read the help file:
https://ggplot2.tidyverse.org/reference/sec_axis.html If you read it
carefully you'll understand that is doesn't pick a time series.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-07-16 22:19 GMT+02:00 Stats Student <stats.student4647 at gmail.com>:
> Hi, I'm using scale_y_continuous with sec.axis and it's doing what I need but I don't understand how it picks which of the two series becomes the secondary.
>
> Does anyone have any insight into this?
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rkoenker @ending from illinoi@@edu  Tue Jul 17 10:02:15 2018
From: rkoenker @ending from illinoi@@edu (Roger Koenker)
Date: Tue, 17 Jul 2018 09:02:15 +0100
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
References: <1531802918272-0.post@n4.nabble.com>
 <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
Message-ID: <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>

In certain fields this sort of standardization has become customary based on some sort of (misguided) notion that it
induces ?normality.?  For example, in anthropometric studies based on the international Demographic and Health
Surveys (DHS) childrens? heights are often transformed to Z-scores prior to subsequent analysis under the dubious
presumption that variability around the Z-scores at various ages will be Gaussian.  In my experience this is rarely
justified, and analysts would be better off modeling the original data rather than doing the preliminary transformation.
This is discussed in further detail here:  https://projecteuclid.org/euclid.bjps/1313973394.

> On Jul 17, 2018, at 5:53 AM, Michael Thompson <michael.thompson at manukau.ac.nz> wrote:
> 
> Hi,
> I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
> This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
> Michael
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jul 17 14:46:50 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Jul 2018 05:46:50 -0700
Subject: [R] 
 Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
Message-ID: <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>

I an sorry that I cannot answer your question, but you don't seem to be very effective in your use of this resource. 

While sometimes you might get responses to this kind of question here, you really ought to read the Posting Guide:

"Questions likely to prompt discussion unintelligible to non-programmers should rather go to R-devel than R-help. Questions about?package development, however, e.g., passing?R CMD check?should go to R-package-devel rather than R-devel." You might also consider R-sig-mac... this might be related to your development environment.

... and re starting a new thread with exactly the same question is poor nettiquette in any forum. Reply-all to previous messages on the same topic to maintain the subject thread.

Oh, and offering "the net" as a reference source is a joke in poor taste... that was from the R for Mac OS FAQ which is another clue that your problem might need more specialized help.

On July 16, 2018 11:32:49 PM PDT, Christian <christian at echoffmann.ch> wrote:
>Hi,
>
>I am fighting to get rid of the messages like:
>
>During startup - Warning messages:
>Setting LC_CTYPE failed, using "C"
>Setting LC_COLLATE failed, using "C"
>
>This is annoying, because when building a package using R CMD, This 
>message keeps cropping up.
>
>Here my R:
>Sys.getlocale()
>[1] "C"
>...................
>
>Executing
>
>     Open Terminal
>     Write or paste in: defaults write org.R-project.R force.LANG 
>en_US.UTF-8
>     Close Terminal
>     Start R
>
>as suggested on the Net, did not help :-(
>
>Pointers are welcome
>C.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Tue Jul 17 17:02:26 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 17 Jul 2018 08:02:26 -0700
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>
References: <1531802918272-0.post@n4.nabble.com>
 <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
 <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>
Message-ID: <CAGxFJbT1ze8DQiHO7sbGBEUXg-XME6rT13kSw53USSrgBCvNJQ@mail.gmail.com>

Prof. Koenker's response probably settles the matter, but if not, this
thread should really be taken offlist, as it is primarily about statistics
and not R programming.
stats.stackexchange.com might be an alternative place to post; indeed, I
suspect the issue has already been addressed in their archives.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 17, 2018 at 1:02 AM, Roger Koenker <rkoenker at illinois.edu>
wrote:

> In certain fields this sort of standardization has become customary based
> on some sort of (misguided) notion that it
> induces ?normality.?  For example, in anthropometric studies based on the
> international Demographic and Health
> Surveys (DHS) childrens? heights are often transformed to Z-scores prior
> to subsequent analysis under the dubious
> presumption that variability around the Z-scores at various ages will be
> Gaussian.  In my experience this is rarely
> justified, and analysts would be better off modeling the original data
> rather than doing the preliminary transformation.
> This is discussed in further detail here:  https://projecteuclid.org/
> euclid.bjps/1313973394.
>
> > On Jul 17, 2018, at 5:53 AM, Michael Thompson <
> michael.thompson at manukau.ac.nz> wrote:
> >
> > Hi,
> > I seem to remember from classes that one effect of scaling /
> standardising data was to get better results in any analysis. But what I'm
> seeing when I study various explanations on scaling is that we get exactly
> the same results, just that when we look at standardised data it's easier
> to see proportionate effects.
> > This is all very well for the data scientist to further investigate, but
> from a practical point of view, (especially IF it doesn't improve the
> accuracy of the result) surely it adds complication to 'telling the story'
> > of the model to non-DS people?
> > So, is scaling a technique for the DS to use to find effects, while
> eventually delivering a non-scaled version to the users?
> > I'd like to be able to give the true story to my students, not some
> fairy story based on my misunderstanding. Hope you can help with this.
> > Michael
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @y@@d@kdouki @ending from live@com  Tue Jul 17 14:09:48 2018
From: @y@@d@kdouki @ending from live@com (Aya Dakdouki)
Date: Tue, 17 Jul 2018 12:09:48 +0000
Subject: [R] help erroer solnp
In-Reply-To: <AM4PR1001MB136252CDA7C4605C8BFCF4E5E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
References: <AM4PR1001MB136252CDA7C4605C8BFCF4E5E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <AM4PR1001MB136222EC8C350A4822D56578E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>

Hello,


I am trying to solve a nonlinear optimization problem using the solnp function. I receive an error message saying:


Warning message:
In p0 * vscale [(neq + 2) :( nc + np + 1)]:
   the size of a longer object is not multiple of the size of a shorter object

Can you help me please.

Thank you in advance for your help.

Regards,
Aya




	[[alternative HTML version deleted]]


From chri@ti@n @ending from echoffm@nn@ch  Tue Jul 17 16:36:14 2018
From: chri@ti@n @ending from echoffm@nn@ch (Christian)
Date: Tue, 17 Jul 2018 16:36:14 +0200
Subject: [R] Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
 <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
Message-ID: <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>

Another try, I am sorry.

On 17.07.18 14:46, Jeff Newmiller wrote:
> I an sorry that I cannot answer your question, but you don't seem to be very effective in your use of this resource.
> 
>> Hi,
>>
>> I am fighting to get rid of the messages like:
>>
>> During startup - Warning messages:
>> Setting LC_CTYPE failed, using "C"
>> Setting LC_COLLATE failed, using "C"
>>
>> This is annoying, because when building a package using R CMD, This
>> message keeps cropping up.
>>
>> Here my R:
>> Sys.getlocale()
>> [1] "C"
>> ...................
>>
>> Executing
>>
>>      Open Terminal
>>      Write or paste in: defaults write org.R-project.R force.LANG
>> en_US.UTF-8
>>      Close Terminal
>>      Start R
>>
>> as suggested on 

https://stackoverflow.com/questions/9689104/installing-r-on-mac-warning-messages-setting-lc-ctype-failed-using-c,

  did not help :-(

Pointers are welcome
C.

-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jul 17 17:24:56 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Jul 2018 08:24:56 -0700
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
References: <1531802918272-0.post@n4.nabble.com>
 <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
Message-ID: <D6539009-3E83-4B80-8D52-E887B4D91ED4@dcn.davis.ca.us>

This question is interesting, but sadly off-topic here as there is nothing specific to R in it. Fortunately there are many resources for getting an answer... e.g. a quick search with Google finds [1] which addresses both centering and scaling.

[1] https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia

On July 16, 2018 9:53:17 PM PDT, Michael Thompson <michael.thompson at manukau.ac.nz> wrote:
>Hi,
>I seem to remember from classes that one effect of scaling /
>standardising data was to get better results in any analysis. But what
>I'm seeing when I study various explanations on scaling is that we get
>exactly the same results, just that when we look at standardised data
>it's easier to see proportionate effects.
>This is all very well for the data scientist to further investigate,
>but from a practical point of view, (especially IF it doesn't improve
>the accuracy of the result) surely it adds complication to 'telling the
>story'
>of the model to non-DS people?
>So, is scaling a technique for the DS to use to find effects, while
>eventually delivering a non-scaled version to the users?
>I'd like to be able to give the true story to my students, not some
>fairy story based on my misunderstanding. Hope you can help with this.
>Michael
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jul 17 17:42:31 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Jul 2018 08:42:31 -0700
Subject: [R] help erroer solnp
In-Reply-To: <AM4PR1001MB136222EC8C350A4822D56578E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
References: <AM4PR1001MB136252CDA7C4605C8BFCF4E5E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
 <AM4PR1001MB136222EC8C350A4822D56578E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <EBB974FD-41B8-46D4-8841-75C2321BCA96@dcn.davis.ca.us>

It is hard to help you do the right thing when you don't tell us what you did or what you wanted to do or what data you had to work with. See [1][2] as [3] for help on how to ask a question regarding R.

Also, "solnp" is not part of R... such a function exists in the Rsoln contributed package, but you should not assume we will know that as there are over 10000 contributed packages in CRAN and many more elsewhere on the Internet.

Also beware that this is a plain text mailing list... if you post HTML formatted text then your email will have the formatting stripped with varying degrees of damage, sometimes to the point of making it unreadable. Set your email program to send plain text when you post here.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

On July 17, 2018 5:09:48 AM PDT, Aya Dakdouki <aya.dakdouki at live.com> wrote:
>Hello,
>
>
>I am trying to solve a nonlinear optimization problem using the solnp
>function. I receive an error message saying:
>
>
>Warning message:
>In p0 * vscale [(neq + 2) :( nc + np + 1)]:
>the size of a longer object is not multiple of the size of a shorter
>object
>
>Can you help me please.
>
>Thank you in advance for your help.
>
>Regards,
>Aya
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dwin@emiu@ @ending from comc@@t@net  Tue Jul 17 18:18:17 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Tue, 17 Jul 2018 09:18:17 -0700
Subject: [R] 
 Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
 <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
 <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>
Message-ID: <9C4FD8C1-6968-4FE7-B6B5-2CC3586FA903@comcast.net>


> On Jul 17, 2018, at 7:36 AM, Christian <christian at echoffmann.ch> wrote:
> 
> Another try, I am sorry.
> 
> On 17.07.18 14:46, Jeff Newmiller wrote:
>> I an sorry that I cannot answer your question, but you don't seem to be very effective in your use of this resource.
>>> Hi,
>>> 
>>> I am fighting to get rid of the messages like:
>>> 
>>> During startup - Warning messages:
>>> Setting LC_CTYPE failed, using "C"
>>> Setting LC_COLLATE failed, using "C"
>>> 
>>> This is annoying, because when building a package using R CMD, This
>>> message keeps cropping up.
>>> 
>>> Here my R:
>>> Sys.getlocale()
>>> [1] "C"
>>> ...................
>>> 
>>> Executing
>>> 
>>>     Open Terminal
>>>     Write or paste in: defaults write org.R-project.R force.LANG
>>> en_US.UTF-8
>>>     Close Terminal
>>>     Start R
>>> 
>>> as suggested on 
> 
> https://stackoverflow.com/questions/9689104/installing-r-on-mac-warning-messages-setting-lc-ctype-failed-using-c,
> 
> did not help :-(

Sigh, claiming that something "did not help" usually ...does not help. You need a clear unambigous description of everything that was in place and exactly what was being done when the unexpected behavior occurred. 

And you need to post that description in the right venue which you have already been advised is not rhelp. I see that you have (probably unsuccessfully) attempted cross-posting to the right venue, r-sig-mac. Cross-posting to multiple r lists is deprecated by the Posting Guide which you should now read. 

Then you should subscribe to r-sig-mac using the web interface and only afterwards post to the correct venue: r-sig-mac at r-project.org. As always with first time posting you will see your first post held up in the queue for moderation, so don't send any additional queries until your post appears in that list's archive: https://stat.ethz.ch/pipermail/r-sig-mac/
> 
> Pointers are welcome
> C.
> 
> -- 
> Christian Hoffmann
> Rigiblickstrasse 15b
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From rmh @ending from temple@edu  Tue Jul 17 18:29:11 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Tue, 17 Jul 2018 12:29:11 -0400
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
References: <1531802918272-0.post@n4.nabble.com>
 <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
Message-ID: <CAGx1TMC=1NiiGZSnX+sqJ6qqeshWXQ-U4zYsL2YCQHNY3C73kg@mail.gmail.com>

This is a variant of FAQ 7.31 on rounding.

For hand arithmetic, for example the variance of c(29,30,31), it was
easier to subtract the mean and work with c(-1,0,1).
For limited precision computers working directly with many-digit
numbers could lead to rounding in intermediate steps and catastrophic
cancellation.

For more information see FAQ 7.31 in file
system.file("../../doc/FAQ")
on your computer.  Open in your favorite text editor.

Here is a simple example using 5-bit arithmetic (rather than the R
standard double precision with 53 bits)  that shows catastrophic
cancellation.

library(Rmpfr)

NN <- 29:31
NN
NN^2
formatBin(NN)
formatBin(NN^2)

## 53 bit precision (double precision)
SSq <- NN[1]^2 +NN[2]^2 + NN[3]^2
SSq
CorrSSq <- SSq - ((NN[1]+NN[2]+NN[3])^2)/3
CorrSSq ## right answer
formatBin(CorrSSq)

## 5 bit precision
ONE <- mpfr(1, precBits=5)
NNO <- NN*ONE
NNO
NNO^2 ## note loss of precision
formatBin(NNO) ## 5-bit numbers.  Their squares require 10 bits.
formatBin(NNO^2) ## 10-bit squares rounded to 5 bits

SSqO <- NNO[1]^2 +NNO[2]^2 + NNO[3]^2
SSqO
CorrSSqO <- SSqO - ((NNO[1]+NNO[2]+NNO[3])^2)/3
CorrSSqO ## very wrong answer from catastrophic cancellation
formatBin(CorrSSqO)

## "normalizing" NNO  5 bit precision
NNOm30 <- NNO-30
NNOm30
NNOm30^2
SSqOm30 <- NNOm30[1]^2 +NNOm30[2]^2 + NNOm30[3]^2  ## 5 bit precision
SSqOm30 ## right answer, even with low-precision arithmetic
formatBin(SSqOm30)

formatBin(NNOm30)
formatBin(NNOm30^2)

On Tue, Jul 17, 2018 at 12:53 AM, Michael Thompson
<michael.thompson at manukau.ac.nz> wrote:
> Hi,
> I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
> This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
> Michael
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mich@el@thomp@on @ending from m@nuk@u@@c@nz  Wed Jul 18 07:36:02 2018
From: mich@el@thomp@on @ending from m@nuk@u@@c@nz (Michael Thompson)
Date: Wed, 18 Jul 2018 05:36:02 +0000
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <CAGxFJbT1ze8DQiHO7sbGBEUXg-XME6rT13kSw53USSrgBCvNJQ@mail.gmail.com>
References: <1531802918272-0.post@n4.nabble.com>
 <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
 <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>
 <CAGxFJbT1ze8DQiHO7sbGBEUXg-XME6rT13kSw53USSrgBCvNJQ@mail.gmail.com>
Message-ID: <B09F0E65D2208E4FB3924C20489A4B0801784C63EC@otav-win-mbx-04.manukau.ac.nz>

My thanks to all contributors, and while I was not in the right place, I certainly got the answers I needed. My students will benefit, so thank you all.

Regards,
Michael Thompson M.Prof.Studies Data Science
09 975 4678
Senior Lecturer, Digital Technologies
Manukau Campus
We all, like sheep, have gone astray Isaiah 53
Personal profile: https://www.manukau.ac.nz/about/faculties-schools/business-and-information-technology/more-information-for-students/lecturer-profiles/michael-thompson

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Wednesday, 18 July 2018 3:02 AM
To: Roger Koenker <rkoenker at illinois.edu>
Cc: Michael Thompson <michael.thompson at manukau.ac.nz>; r-help at r-project.org
Subject: Re: [R] Scaling - does it get any better results than not scaling?

Prof. Koenker's response probably settles the matter, but if not, this thread should really be taken offlist, as it is primarily about statistics and not R programming.
stats.stackexchange.com<http://stats.stackexchange.com> might be an alternative place to post; indeed, I suspect the issue has already been addressed in their archives.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 17, 2018 at 1:02 AM, Roger Koenker <rkoenker at illinois.edu<mailto:rkoenker at illinois.edu>> wrote:
In certain fields this sort of standardization has become customary based on some sort of (misguided) notion that it
induces ?normality.?  For example, in anthropometric studies based on the international Demographic and Health
Surveys (DHS) childrens? heights are often transformed to Z-scores prior to subsequent analysis under the dubious
presumption that variability around the Z-scores at various ages will be Gaussian.  In my experience this is rarely
justified, and analysts would be better off modeling the original data rather than doing the preliminary transformation.
This is discussed in further detail here:  https://projecteuclid.org/euclid.bjps/1313973394.

> On Jul 17, 2018, at 5:53 AM, Michael Thompson <michael.thompson at manukau.ac.nz<mailto:michael.thompson at manukau.ac.nz>> wrote:
>
> Hi,
> I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
> This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
> Michael
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Wed Jul 18 18:33:55 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 18 Jul 2018 16:33:55 +0000
Subject: [R] Help with knitr pkg
Message-ID: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi,
I worked through this excellent tutorial:
#Elegant regression results tables and plots in R: the finalfit package
https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/



Now I am applying it to my own data.

In the tutorial there is mention of:

# Tables can be knitted to PDF, Word or html documents. We do this in
# RStudio from a .Rmd document. Example chunk:
#   ```{r, echo = FALSE, results='asis'}
# knitr::kable(example_table, row.names=FALSE,
#              align=c("l", "l", "r", "r", "r", "r"))
# ```

I am having a difficult time understanding how this works?

I have read through the help:

?knitr
#"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
#It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
#The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."

install.packages("knitr")
library(knitr)
?knit
?stitch
install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
?spin
install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages :  Perhaps you meant 'SPIn' ?

I have also looked at the github and knitr author's links

https://github.com/yihui/knitr

https://yihui.name/knitr/demo/stitch/

https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd


If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?

I also tried writing out directly to pdf and png with no success.

#pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
#png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
#opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?

#This is the script I would like the output placed in PDF
explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
dependent = "AppealOverturned" # Appeals Status
appdf1DT2 %>%
  summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)

#dev.off()


str(appdf1DT2)
# Classes 'data.table' and 'data.frame':   3983 obs. of  21 variables:
#   $ ClaimServiceID   : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
# $ LineNumber       : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
# $ claimStatusId    : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
# $ PatientGender    : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
# $ PayorID          : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
# $ AppealID         : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
# $ ZipCode          : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
# $ EditID           : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
# $ CurrentBilled    : num  14394 14394 14394 14394 14394 ...
# $ ClaimLineSavings : num  0 0 0 0 0 ...
# $ StatusChangeMo   : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
# $ Grouping         : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
# $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
# $ PrimaryDX        : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
# $ RevCodeCats      : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
# $ AgeCat           : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
# $ ClaimLevelSavings: num  0 0 0 0 0 ...
# - attr(*, ".internal.selfref")=<externalptr>

head(appdf1DT2)
   ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode        TIN EditID
1:       51318639          1             3             M     000     149385    79765              33904      0
2:       51318640          2             3             M     000     149385    79765              33904    022
3:       51318642          4             3             M     000     149385    79765              33904   00504
4:       51318641          3             3             M     000     149385    79765              33904     022
5:       51318643          5             3             M     000     149385    79765              33904   00504
6:       85833537          7             2             F     000    3240182   116998              46635   00504
   CurrentBilled ClaimLineSavings StatusChangeMo                                 Grouping AppealOverturned PrimaryDX        RevCodeCats
1:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
2:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
3:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
4:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
5:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
6:      23472.92                0        2018-04  Ambulatory Health Care Facilities                1     M1712 MedSurgSuppandDevs
    AgeCat ClaimLevelSavings
1: [31-40]              0.00
2: [31-40]              0.00
3: [31-40]              0.00
4: [31-40]              0.00
5: [31-40]              0.00
6: [61-70]            296.25


Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.

Thank you.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From fr@nce@c@@p@ncotto @ending from gm@il@com  Wed Jul 18 18:47:40 2018
From: fr@nce@c@@p@ncotto @ending from gm@il@com (Francesca)
Date: Wed, 18 Jul 2018 18:47:40 +0200
Subject: [R] GGPlot plot
In-Reply-To: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
Message-ID: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>

Dear R help,

I am new to ggplot so I apologize if my question is a bit obvious.

I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.

The variable PASP is discrete and only takes values 0,4,8..

My data are as following:

 

PASP   SUBJC

 

0          0

4          1

0          0

8          0

4          0

0          1

0          1

.           .

.           .

.           .




I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:





I hope my request is clear. Thanks for any help you can provide.

Francesca




From ruipb@rr@d@@ @ending from @@po@pt  Wed Jul 18 20:32:00 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Wed, 18 Jul 2018 19:32:00 +0100
Subject: [R] GGPlot plot
In-Reply-To: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
Message-ID: <9ff1d20f-5f0b-a587-aa3d-90dda8811b11@sapo.pt>

Hello,

Your request is not entirely clear.

What kind of a graph do you want? A bar graph with a bar of the fraction 
of positive levels of PASP per each level of SUBJC?
You need to be more specific.

Also, please post data like this:

# post the output of this command in your next mail
dput(head(data, 30))


Hope this helps,

Rui Barradas


?s 17:47 de 18-07-2018, Francesca escreveu:
> Dear R help,
> 
> I am new to ggplot so I apologize if my question is a bit obvious.
> 
> I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.
> 
> The variable PASP is discrete and only takes values 0,4,8..
> 
> My data are as following:
> 
>   
> 
> PASP   SUBJC
> 
>   
> 
> 0          0
> 
> 4          1
> 
> 0          0
> 
> 8          0
> 
> 4          0
> 
> 0          1
> 
> 0          1
> 
> .           .
> 
> .           .
> 
> .           .
> 
> 
> 
> 
> I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:
> 
> 
> 
> 
> 
> I hope my request is clear. Thanks for any help you can provide.
> 
> Francesca
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jul 18 21:53:45 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Jul 2018 12:53:45 -0700 (PDT)
Subject: [R] GGPlot plot
In-Reply-To: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
Message-ID: <alpine.BSF.2.00.1807181205200.23901@pedal.dcn.davis.ca.us>

On Wed, 18 Jul 2018, Francesca wrote:

> Dear R help,
>

> I am new to ggplot so I apologize if my question is a bit obvious.

Or perhaps not, as this is the "R-help" mailing list, not the 
"Ggplot-help" mailing list. Fortunately for you, what you really need to 
learn is R, and then ggplot will be much easier to get along with.

> I would like to create a plot where a compare the fraction of the values 
> of a variable called PASP out of the number of subjects, for two groups 
> of subject codified with a dummy variable called SUBJC.
>
> The variable PASP is discrete and only takes values 0,4,8..
>
> My data are as following:
>
> PASP   SUBJC
> 
> 0          0
>
> 4          1
>
> 0          0
>
> 8          0
>
> 4          0
>
> 0          1
>
> 0          1
>
> .           .
>
> .           .
>
> .           .
>
>
>
>
> I would like to calculate the fraction of positive levels of PASP out of 
> the total number of observations, divided per values of SUBJ=0 and 1. I 
> am new to the use of GGPlot and I do not know how to organize the data 
> and what to use to summarize these data as to obtain a picture as 
> follows:
>
>
>
>
>
> I hope my request is clear. Thanks for any help you can provide.

The funky text formatting and reference to "picture as follows" of the 
above makes me think you composed this in HTML and then converted it to 
plain text without looking at the result.

* We got no picture.. this is a plain-text-only mailing list.
* HTML makes terrible plain text.

The following is an example of how you can send us sample data and code in 
the body of your email that will survive these plain-text-only 
limitations. Note that writing R code is the key to communicating 
unambiguously.

You can start by preparing a sample of your data (usually not all of 
it)doing something like

dput(head(mydta,100))

and inserting the "dta <- " with the output so you get a line of R code 
that we can execute and have some rows of your data:

-----
dta <- structure(list(PASP = c(0, 12, 8, 0, 12, 12, 12, 8, 12, 8, 8,
8, 8, 4, 0, 12, 12, 0, 12, 0, 0, 12, 4, 8, 12, 8, 4, 4, 4, 4,
8, 8, 8, 12, 12, 12, 8, 0, 12, 12, 0, 12, 12, 8, 0, 4, 4, 12,
8, 8, 12, 8, 0, 12, 0, 0, 4, 0, 0, 4, 4, 12, 0, 4, 8, 8, 8, 4,
0, 0, 4, 0, 12, 4, 12, 12, 8, 0, 0, 0, 4, 8, 8, 0, 4, 0, 12,
4, 12, 0, 4, 12, 8, 0, 4, 0, 0, 12, 12, 8), SUBJC = c(0L, 1L,
0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L)), .Names = c("PASP", "SUBJC"), row.names = c(NA, -100L
), class = "data.frame")
-----

and then ideally you would tell us the results of a sample of the 
calculation you expect to see, though in this case you might not have 
thought to present them organized as below:

-----
result <- read.table( text =
" PASP SUBJC  Fraction
     0     0      0.279
     4     0      0.186
     8     0      0.395
    12     0      0.140
     0     1      0.263
     4     1      0.211
     8     1      0.123
    12     1      0.404
", header=TRUE)
-----

And with your existing text, we might come up with something like:

-----
library(ggplot2)

dta <- structure(list(PASP = c(0, 12, 8, 0, 12, 12, 12, 8, 12, 8, 8,
8, 8, 4, 0, 12, 12, 0, 12, 0, 0, 12, 4, 8, 12, 8, 4, 4, 4, 4,
8, 8, 8, 12, 12, 12, 8, 0, 12, 12, 0, 12, 12, 8, 0, 4, 4, 12,
8, 8, 12, 8, 0, 12, 0, 0, 4, 0, 0, 4, 4, 12, 0, 4, 8, 8, 8, 4,
0, 0, 4, 0, 12, 4, 12, 12, 8, 0, 0, 0, 4, 8, 8, 0, 4, 0, 12,
4, 12, 0, 4, 12, 8, 0, 4, 0, 0, 12, 12, 8), SUBJC = c(0L, 1L,
0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L)), .Names = c("PASP", "SUBJC"), row.names = c(NA, -100L

         ), class = "data.frame")
table(dta)
#>     SUBJC
#> PASP  0  1
#>   0  12 15
#>   4   8 12
#>   8  17  7
#>   12  6 23

dtasum <- aggregate( list( Count = rep(1,100) )
                    , dta
                    , FUN = sum
                    )

dtasum$Fraction <- ave( dtasum$Count
                       , dtasum$SUBJC
                       , FUN = function(x) ( x/sum(x) )
                       )
dtasum$PASPfactor <- factor( dtasum$PASP )
dtasum$SUBJCfactor <- factor( dtasum$SUBJC )
dtasum
#>   PASP SUBJC Count  Fraction PASPfactor SUBJCfactor
#> 1    0     0    12 0.2790698          0           0
#> 2    4     0     8 0.1860465          4           0
#> 3    8     0    17 0.3953488          8           0
#> 4   12     0     6 0.1395349         12           0
#> 5    0     1    15 0.2631579          0           1
#> 6    4     1    12 0.2105263          4           1
#> 7    8     1     7 0.1228070          8           1
#> 8   12     1    23 0.4035088         12           1

ggplot( dtasum
       , aes( x=SUBJCfactor
            , y=Fraction
            , fill=PASPfactor
            )
       ) +
   geom_bar( stat = "identity" ) +
   xlab( "SUBJ" ) +
   scale_fill_discrete( name = "PASP" )

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
-----

Obviously, since I never saw the figure you thought I was going to see, 
the plot I made may not be the one you had in mind, but you should at 
least have some example code to compare with the "Introduction to R" 
document that comes with R, and some functions to look up help pages on, 
e.g.

?aggregate
?ave

and you can execute pieces of code to see what they create:

rep(1,100)

You should read he Posting Guide carefully, as there are hints in it as to 
how to do much of this.

>
> Francesca
>
>
>
> ______________________________________________

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 18 22:55:19 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 13:55:19 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
Message-ID: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>

   I have daily precipitation data for 58 locations from 2005-01-01 through
2018-06-18. Among other plots and analyses I want to apply lattice's
xyplot() to illustrate the abundance and patterns of the data.

   I've used a vector of colors (and a key) when there were only eight
weather stations and the date range was three months. This was very
effective in communicating the amounts and patterns.

   I'm asking for ideas on how to best present these data in a scatter plot.

Regards,

Rich


From dwin@emiu@ @ending from comc@@t@net  Wed Jul 18 23:21:14 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 18 Jul 2018 14:21:14 -0700
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
Message-ID: <DBDAB061-E753-4FE7-A085-5F96E906DDEF@comcast.net>


> On Jul 18, 2018, at 1:55 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have daily precipitation data for 58 locations from 2005-01-01 through
> 2018-06-18. Among other plots and analyses I want to apply lattice's
> xyplot() to illustrate the abundance and patterns of the data.
> 
>  I've used a vector of colors (and a key) when there were only eight
> weather stations and the date range was three months. This was very
> effective in communicating the amounts and patterns.
> 
>  I'm asking for ideas on how to best present these data in a scatter plot.

Monthly contour plots in a 3x4 layout or put tiny histograms of monthly rainfall atop a tilted map of your locations. See section 13.5.1 in Sarkar's "Lattice".


> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From f@bih@6074 @ending from gm@il@com  Wed Jul 18 21:16:39 2018
From: f@bih@6074 @ending from gm@il@com (Fabiha Binte Farooq)
Date: Thu, 19 Jul 2018 01:16:39 +0600
Subject: [R] Query regarding simulating weibull aft model with predefined
 censoring rate
Message-ID: <CAFLSYUnjt=iFxVnh74FOxznyDaBp0s+BY65=5h_vo4ULo-EDqQ@mail.gmail.com>

Hi there,
I am an MS student from Bangladesh. I am doing thesis in my MS degree. In
my research, I am generating data from weibull distribution and my model is
accelerated failure time (AFT) model. I am considering right censoring as
well as covariates. Now I have been facing difficulties to generate
censoring time controlling censoring proportion. I am attaching my codes
here.

Problem. I have generated censoring time using a relationship between scale
and covariates from an article for PH model. But my model is AFT. Is it
authentic to use it here? Please help!!!

Sincerely,
Fabiha

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: 1531941100067_weibull model.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180719/0fbf8d94/attachment.txt>

From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 18 23:50:46 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 14:50:46 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
Message-ID: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>

   A set of data files have this format:

date,time,elev
1988-10-01,00:30,87.6849
1988-10-01,01:00,87.6849
1988-10-01,01:30,87.6849
1988-10-01,02:00,87.6879
1988-10-01,02:30,87.6879
1988-10-01,03:00,87.691
1988-10-01,03:30,87.694

Importing it with this command:

allyears <- read.table('allyears.dat', header = T, sep = ',')

produces this structure:

str(allyears)
'data.frame':	402414 obs. of  3 variables:
  $ date: Factor w/ 10230 levels "'data'","'date'",..:
  $ time: Factor w/ 1441 levels "'time'","00:00",..:
  $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:

   Applying,
allyears$date <- as.Date(as.character(allyears$date))
changes the structure to
str(allyears)
'data.frame':	402414 obs. of  3 variables:
  $ date: Date, format: "1988-10-01" "1988-10-01" ...
  $ time: Factor w/ 1441 levels "'time'","00:00",..:
  $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:

   I've not found the proper syntax to change time to a POSIXct time format
nor the elev to a numeric format.

allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%M))
Error: unexpected SPECIAL in "allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%"

and

allyears$elev <- as.Numeric(allyears$elev)
Error in as.Numeric(allyears$elev) : could not find function "as.Numeric"

   I've read ?read.table and looked on the web but I'm not finding how to
properly change the time and elev factors to H:M and fractional feet. A
pointer to a resource is much appreciated.

Rich


From t@n@@@ @ending from gm@il@com  Thu Jul 19 00:12:15 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 15:12:15 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
Message-ID: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>

Dear all,

please may I ask for a piece of advise regarding merging two dataframes :

A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))

B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))

function of the criteria :

if "the elements in the 1st column of A could be found among the elements
of the 1st column of B" i.e.

for the example above, we shall combine in the results only the row with
"a*b" of A with the row with "a*b::x*y" of B.

thank you,

bogdan

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 19 00:17:11 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 18 Jul 2018 15:17:11 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
Message-ID: <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>


> On Jul 18, 2018, at 2:50 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  A set of data files have this format:
> 
> date,time,elev
> 1988-10-01,00:30,87.6849
> 1988-10-01,01:00,87.6849
> 1988-10-01,01:30,87.6849
> 1988-10-01,02:00,87.6879
> 1988-10-01,02:30,87.6879
> 1988-10-01,03:00,87.691
> 1988-10-01,03:30,87.694
> 
> Importing it with this command:
> 
> allyears <- read.table('allyears.dat', header = T, sep = ',')
> 
> produces this structure:
> 
> str(allyears)
> 'data.frame':	402414 obs. of  3 variables:
> $ date: Factor w/ 10230 levels "'data'","'date'",..:
> $ time: Factor w/ 1441 levels "'time'","00:00",..:
> $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:
> 
>  Applying,
> allyears$date <- as.Date(as.character(allyears$date))
> changes the structure to
> str(allyears)
> 'data.frame':	402414 obs. of  3 variables:
> $ date: Date, format: "1988-10-01" "1988-10-01" ...
> $ time: Factor w/ 1441 levels "'time'","00:00",..:
> $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:
> 
>  I've not found the proper syntax to change time to a POSIXct time format
> nor the elev to a numeric format.

I would not destroy the possibility of using the original values:

> allyears$myDate <- as.Date(as.character(allyears$date))
> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))
> allyears
        date  time    elev     myDate              myTime
1 1988-10-01 00:30 87.6849 1988-10-01 1988-10-01 00:30:00
2 1988-10-01 01:00 87.6849 1988-10-01 1988-10-01 01:00:00
3 1988-10-01 01:30 87.6849 1988-10-01 1988-10-01 01:30:00
4 1988-10-01 02:00 87.6879 1988-10-01 1988-10-01 02:00:00
5 1988-10-01 02:30 87.6879 1988-10-01 1988-10-01 02:30:00
6 1988-10-01 03:00  87.691 1988-10-01 1988-10-01 03:00:00
7 1988-10-01 03:30 87.694t 1988-10-01 1988-10-01 03:30:00

> 


> allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%M))
> Error: unexpected SPECIAL in "allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%"
> 
> and
> 
> allyears$elev <- as.Numeric(allyears$elev)
> Error in as.Numeric(allyears$elev) : could not find function "as.Numeric"

It's spelled `as.numeric`, but I'm having difficulty thinking about what sort of elevation (or would that be "depth") would be be measured by "-3762938880000000369098752".


> 
>  I've read ?read.table and looked on the web but I'm not finding how to
> properly change the time and elev factors to H:M and fractional feet. A
> pointer to a resource is much appreciated.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From SW@y @ending from meco@com  Thu Jul 19 00:53:34 2018
From: SW@y @ending from meco@com (Shawn Way)
Date: Wed, 18 Jul 2018 22:53:34 +0000
Subject: [R] xtable does not print out units of a variable
Message-ID: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>

I have a dataframe that contains units using the units package.  Unfortunately, I really need the units for reporting.  I'm assuming that's because the data is in a class units and xtable doesn't know what to do with this.

The following is a MWE:

    library(xtable)
    library(units)
    data <- data.frame(x=c(as_units(12,"ft")))
    xtable(data)

    % latex table generated in R 3.5.1 by xtable 1.8-2 package
    % Wed Jul 18 17:31:44 2018
    \begin{table}[ht]
    \centering
    \begin{tabular}{rr}
      \hline
     & x \\ 
      \hline
    1 & 12.00 \\ 
      \hline
    \end{tabular} 
    \end{table}

What I'm looking for is the line

    1 & 12.00 \\

to be 

    1 & 12.00 $ft$\\

Can someone point me in the correct direction to make this happen?  Since units are used extensively in engineering calculations, being able to handle this class would be extremely beneficial to engineers that are using R with knitr to generate engineering documents.

Shawn Way


From t@n@@@ @ending from gm@il@com  Thu Jul 19 01:00:18 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 16:00:18 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
Message-ID: <CA+JEM032PeGoO7__v_-trA0YdcnG0EDjyDH+ECMjrH+FQ6Kxbw@mail.gmail.com>

Dear Riley,

thank you very much for your help and solution. I got some inspiration from
stackoverflow website,

and I did use sqldf library. It looks that the formula below works too.
Thanks a lot !

sqldf("select B.*, A.* from B left join A on instr(B.z,  A.z)")


On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:

> please may I ask for a piece of advise regarding merging two dataframes :
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>> function of the criteria :
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>
>
> This may be what you are looking for:
>
> library(fuzzyjoin)
>
> The inner join returns just the one row where the string matches.
> B %>%
>   regex_inner_join(A, by = c(z = 'z'))
>
> While the full join returns NA's where the string does not match.
> B %>%
>   regex_full_join(A, by = c(z = 'z'))
>
> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
>> Dear all,
>>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>
>> function of the criteria :
>>
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>>
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>>
>> thank you,
>>
>> bogdan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From t@n@@@ @ending from gm@il@com  Thu Jul 19 01:03:12 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 16:03:12 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
Message-ID: <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>

Thanks a lot ! It looks that I am getting the same results with :

B %>% regex_left_join(A, by = c(z = 'z'))

On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:

> please may I ask for a piece of advise regarding merging two dataframes :
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>> function of the criteria :
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>
>
> This may be what you are looking for:
>
> library(fuzzyjoin)
>
> The inner join returns just the one row where the string matches.
> B %>%
>   regex_inner_join(A, by = c(z = 'z'))
>
> While the full join returns NA's where the string does not match.
> B %>%
>   regex_full_join(A, by = c(z = 'z'))
>
> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
>> Dear all,
>>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>
>> function of the criteria :
>>
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>>
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>>
>> thank you,
>>
>> bogdan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Thu Jul 19 01:04:54 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 19 Jul 2018 09:04:54 +1000
Subject: [R] GGPlot plot
In-Reply-To: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
Message-ID: <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>

Hi Francesca,
This looks like a fairly simple task. Try this:

fpdf<-read.table(text="PASP   SUBJC
 0          0
 4          1
 0          0
 8          0
 4          0
 0          1
 0          1",
 header=TRUE)
# get the number of positive PASP results by group
ppos<-by(fpdf$SUBJC,fpdf$PASPpos,sum)
# get the number of subjects per group
spg<-c(sum(fpdf$SUBJC==0),sum(fpdf$SUBJC==1))
barplot(ppos/spg,names.arg=c(0,1),xlab="Group",
 ylab="Proportion PASP > 0",main="Proportion of PASP positive by group")

Jim

On Thu, Jul 19, 2018 at 2:47 AM, Francesca <francesca.pancotto at gmail.com> wrote:
> Dear R help,
>
> I am new to ggplot so I apologize if my question is a bit obvious.
>
> I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.
>
> The variable PASP is discrete and only takes values 0,4,8..
>
> My data are as following:
>
>
>
> PASP   SUBJC
>
>
>
> 0          0
>
> 4          1
>
> 0          0
>
> 8          0
>
> 4          0
>
> 0          1
>
> 0          1
>
> .           .
>
> .           .
>
> .           .
>
>
>
>
> I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:
>
>
>
>
>
> I hope my request is clear. Thanks for any help you can provide.
>
> Francesca
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 01:07:18 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 16:07:18 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
Message-ID: <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>

On Wed, 18 Jul 2018, David Winsemius wrote:

> I would not destroy the possibility of using the original values:

David,

   What are the benefits of keeping date and time as factors?

>> allyears$myDate <- as.Date(as.character(allyears$date))
>> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))

   The latter command is not working on the full (402415 rows in the allyears
data set):

allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))
Error in as.POSIXlt.character(x, tz, ...) :
   character string is not in a standard unambiguous format

> It's spelled `as.numeric`,

   Ah, I missed that. Thank you.

> ... but I'm having difficulty thinking about what sort of elevation (or would
> that be "depth") would be be measured by "-3762938880000000369098752".

   I also was curious about that figure and grep doesn't find it in the
original data file so I've no idea where R-3.5.0 came up with it.

   I'll read more about the POSIX datetime functions.

Thanks again,

Rich


From drjimlemon @ending from gm@il@com  Thu Jul 19 01:10:38 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 19 Jul 2018 09:10:38 +1000
Subject: [R] GGPlot plot
In-Reply-To: <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
 <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
Message-ID: <CA+8X3fVtDvBAz=kEDbs7Wi3qcAAQu0PLxtkAnLzY3RfaFteGVg@mail.gmail.com>

Hi again,
Sorry, forgot this line:

 fpdf$PASPpos<-fpdf$PASP > 0

just after reading in the data frame.

Jim


On Thu, Jul 19, 2018 at 9:04 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Francesca,
> This looks like a fairly simple task. Try this:
>
> fpdf<-read.table(text="PASP   SUBJC
>  0          0
>  4          1
>  0          0
>  8          0
>  4          0
>  0          1
>  0          1",
>  header=TRUE)
> # get the number of positive PASP results by group
> ppos<-by(fpdf$SUBJC,fpdf$PASPpos,sum)
> # get the number of subjects per group
> spg<-c(sum(fpdf$SUBJC==0),sum(fpdf$SUBJC==1))
> barplot(ppos/spg,names.arg=c(0,1),xlab="Group",
>  ylab="Proportion PASP > 0",main="Proportion of PASP positive by group")
>
> Jim
>
> On Thu, Jul 19, 2018 at 2:47 AM, Francesca <francesca.pancotto at gmail.com> wrote:
>> Dear R help,
>>
>> I am new to ggplot so I apologize if my question is a bit obvious.
>>
>> I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.
>>
>> The variable PASP is discrete and only takes values 0,4,8..
>>
>> My data are as following:
>>
>>
>>
>> PASP   SUBJC
>>
>>
>>
>> 0          0
>>
>> 4          1
>>
>> 0          0
>>
>> 8          0
>>
>> 4          0
>>
>> 0          1
>>
>> 0          1
>>
>> .           .
>>
>> .           .
>>
>> .           .
>>
>>
>>
>>
>> I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:
>>
>>
>>
>>
>>
>> I hope my request is clear. Thanks for any help you can provide.
>>
>> Francesca
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 19 01:32:28 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 18 Jul 2018 16:32:28 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
Message-ID: <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>


> On Jul 18, 2018, at 4:07 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Wed, 18 Jul 2018, David Winsemius wrote:
> 
>> I would not destroy the possibility of using the original values:
> 
> David,
> 
>  What are the benefits of keeping date and time as factors?
> 
>>> allyears$myDate <- as.Date(as.character(allyears$date))
>>> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))


It's not so much as factors but rather in a form that paste() will coerce to character so you cna get the automatic format

> 
>  The latter command is not working on the full (402415 rows in the allyears
> data set):
> 
> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))
> Error in as.POSIXlt.character(x, tz, ...) :
>  character string is not in a standard unambiguous format

Maybe you need to add a format string. It might force some of your pasted date+time values to NA but at least you would be able to identify the original values and perhaps fix errors.

You really should include a large snapshot of data that will allow reproducibility.


> 
>> It's spelled `as.numeric`,
> 
>  Ah, I missed that. Thank you.
> 
>> ... but I'm having difficulty thinking about what sort of elevation (or would
>> that be "depth") would be be measured by "-3762938880000000369098752".
> 
>  I also was curious about that figure and grep doesn't find it in the
> original data file so I've no idea where R-3.5.0 came up with it.
> 
>  I'll read more about the POSIX datetime functions.
> 
> Thanks again,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From bgunter@4567 @ending from gm@il@com  Thu Jul 19 01:34:03 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 18 Jul 2018 16:34:03 -0700
Subject: [R] 
 Query regarding simulating weibull aft model with predefined
 censoring rate
In-Reply-To: <CAFLSYUnjt=iFxVnh74FOxznyDaBp0s+BY65=5h_vo4ULo-EDqQ@mail.gmail.com>
References: <CAFLSYUnjt=iFxVnh74FOxznyDaBp0s+BY65=5h_vo4ULo-EDqQ@mail.gmail.com>
Message-ID: <CAGxFJbQLQ+xTRmWYZVjHPTZ1fBiSJmMn6LGUvceMFWuq7=dn3A@mail.gmail.com>

Off topic for r-help (see posting guide linked below).

Suggest Posting on stats.stackexchange.com instead..

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 18, 2018 at 12:16 PM, Fabiha Binte Farooq <fabiha6074 at gmail.com>
wrote:

> Hi there,
> I am an MS student from Bangladesh. I am doing thesis in my MS degree. In
> my research, I am generating data from weibull distribution and my model is
> accelerated failure time (AFT) model. I am considering right censoring as
> well as covariates. Now I have been facing difficulties to generate
> censoring time controlling censoring proportion. I am attaching my codes
> here.
>
> Problem. I have generated censoring time using a relationship between scale
> and covariates from an article for PH model. But my model is AFT. Is it
> authentic to use it here? Please help!!!
>
> Sincerely,
> Fabiha
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 02:54:18 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 17:54:18 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
Message-ID: <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>

On Wed, 18 Jul 2018, David Winsemius wrote:

> It's not so much as factors but rather in a form that paste() will coerce
> to character so you cna get the automatic format

David,

   Now I understand.

> Maybe you need to add a format string. It might force some of your pasted
> date+time values to NA but at least you would be able to identify the
> original values and perhaps fix errors.

   Thinking about the data I realize that rather than separate date and time
columns what's needed is a datetime string. I'll add the format string in
the morning and work on this.

> You really should include a large snapshot of data that will allow
> reproducibility.

   I'll certainly do this. With hourly and half-hourly data from 1989-June
2018 (but missing all of 1992) there are more than 400K rows in the raw data
file. If you would suggest how many would be an acceptably large number I'll
be happy to put that on a 'cloud' sharing site and provide the URL to it.

Best regards,

Rich


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jul 19 04:25:34 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Jul 2018 19:25:34 -0700 (PDT)
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.  I'm assuming 
> that's because the data is in a class units and xtable doesn't know what 
> to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to 
communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be 
patient, and consider figuring out what code changes they need to make so 
it will work.

More below.

> The following is a MWE:
>
>    library(xtable)
>    library(units)
>    data <- data.frame(x=c(as_units(12,"ft")))
>    xtable(data)
>
>    % latex table generated in R 3.5.1 by xtable 1.8-2 package
>    % Wed Jul 18 17:31:44 2018
>    \begin{table}[ht]
>    \centering
>    \begin{tabular}{rr}
>      \hline
>     & x \\
>      \hline
>    1 & 12.00 \\
>      \hline
>    \end{tabular}
>    \end{table}
>
> What I'm looking for is the line
>
>    1 & 12.00 \\
>
> to be
>
>    1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being able 
> to handle this class would be extremely beneficial to engineers that are 
> using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within 
columns, not rows, so putting the units into the body of the table is kind 
of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits
data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
                       , " ($"
                       , deparse_unit( datax[[1]] )
                       , "$)"
                       )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package
#> % Wed Jul 18 19:13:29 2018
#> \begin{table}[ht]
#> \centering
#> \begin{tabular}{rr}
#>   \hline
#>  & x (\$ft\$) \\
#>   \hline
#> 1 & 12.00 \\
#>   2 & 13.00 \\
#>    \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, 
then you will probably arrive at that information a single-row, many 
column data frame. I usually transpose this into a three-column data frame 
with a description column, a value column, and a units column. I don't use 
the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jul 19 04:51:27 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Jul 2018 19:51:27 -0700 (PDT)
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
 <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807181927410.37700@pedal.dcn.davis.ca.us>

The traditional (SQL) way to attack this problem is to make the data 
structure simpler so that faster comparisons can be utilized:

################
A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))

library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)
Bx <- (   B
       %>% mutate( z_B = as.character( z ) )
       %>% rename( t_B = t )
       %>% separate_rows( z, sep="::" )
       )
Bx
#>     z t_B      z_B
#> 1 a*b   1 a*b::x*y
#> 2 x*y   1 a*b::x*y
#> 3   c   2        c
#> 4       3
#> 5 g*h   4      g*h
result <- (   A
           %>% mutate( z = as.character( z ) )
           %>% rename( t_A = t )
           %>% inner_join( Bx, by="z" )
           )
result
#>     z t_A t_B      z_B
#> 1 a*b   1   1 a*b::x*y

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
################

Note that this is preferable if you can avoid ever creating the 
complex data z in B, but Bx is much more flexible and less error prone 
than B. (Especially if you don't have to create B$z_B at all, but have 
some other unique identifier(s) for the groupings represented by each row 
in B.)

On Wed, 18 Jul 2018, Bogdan Tanasa wrote:

> Thanks a lot ! It looks that I am getting the same results with :
>
> B %>% regex_left_join(A, by = c(z = 'z'))
>
> On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:
>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>> function of the criteria :
>>> if "the elements in the 1st column of A could be found among the elements
>>> of the 1st column of B" i.e.
>>> for the example above, we shall combine in the results only the row with
>>> "a*b" of A with the row with "a*b::x*y" of B.
>>
>>
>> This may be what you are looking for:
>>
>> library(fuzzyjoin)
>>
>> The inner join returns just the one row where the string matches.
>> B %>%
>>   regex_inner_join(A, by = c(z = 'z'))
>>
>> While the full join returns NA's where the string does not match.
>> B %>%
>>   regex_full_join(A, by = c(z = 'z'))
>>
>> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> please may I ask for a piece of advise regarding merging two dataframes :
>>>
>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>>
>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>>
>>> function of the criteria :
>>>
>>> if "the elements in the 1st column of A could be found among the elements
>>> of the 1st column of B" i.e.
>>>
>>> for the example above, we shall combine in the results only the row with
>>> "a*b" of A with the row with "a*b::x*y" of B.
>>>
>>> thank you,
>>>
>>> bogdan
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From t@n@@@ @ending from gm@il@com  Thu Jul 19 04:50:56 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 19:50:56 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <alpine.BSF.2.00.1807181927410.37700@pedal.dcn.davis.ca.us>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
 <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>
 <alpine.BSF.2.00.1807181927410.37700@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM00n78mMa+jBxex04WeeFStACHSfMDJpP8EfN-DP2EKhVg@mail.gmail.com>

it looks great, thank you very much Jeff for your time and kind help !

On Wed, Jul 18, 2018 at 7:51 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The traditional (SQL) way to attack this problem is to make the data
> structure simpler so that faster comparisons can be utilized:
>
> ################
> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>     filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>     intersect, setdiff, setequal, union
> library(tidyr)
> Bx <- (   B
>       %>% mutate( z_B = as.character( z ) )
>       %>% rename( t_B = t )
>       %>% separate_rows( z, sep="::" )
>       )
> Bx
> #>     z t_B      z_B
> #> 1 a*b   1 a*b::x*y
> #> 2 x*y   1 a*b::x*y
> #> 3   c   2        c
> #> 4       3
> #> 5 g*h   4      g*h
> result <- (   A
>           %>% mutate( z = as.character( z ) )
>           %>% rename( t_A = t )
>           %>% inner_join( Bx, by="z" )
>           )
> result
> #>     z t_A t_B      z_B
> #> 1 a*b   1   1 a*b::x*y
>
> #' Created on 2018-07-18 by the [reprex package](http://reprex.tidyver
> se.org) (v0.2.0).
> ################
>
> Note that this is preferable if you can avoid ever creating the complex
> data z in B, but Bx is much more flexible and less error prone than B.
> (Especially if you don't have to create B$z_B at all, but have some other
> unique identifier(s) for the groupings represented by each row in B.)
>
>
> On Wed, 18 Jul 2018, Bogdan Tanasa wrote:
>
> Thanks a lot ! It looks that I am getting the same results with :
>>
>> B %>% regex_left_join(A, by = c(z = 'z'))
>>
>> On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:
>>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>>
>>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>>> function of the criteria :
>>>> if "the elements in the 1st column of A could be found among the
>>>> elements
>>>> of the 1st column of B" i.e.
>>>> for the example above, we shall combine in the results only the row with
>>>> "a*b" of A with the row with "a*b::x*y" of B.
>>>>
>>>
>>>
>>> This may be what you are looking for:
>>>
>>> library(fuzzyjoin)
>>>
>>> The inner join returns just the one row where the string matches.
>>> B %>%
>>>   regex_inner_join(A, by = c(z = 'z'))
>>>
>>> While the full join returns NA's where the string does not match.
>>> B %>%
>>>   regex_full_join(A, by = c(z = 'z'))
>>>
>>> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>
>>> Dear all,
>>>>
>>>> please may I ask for a piece of advise regarding merging two dataframes
>>>> :
>>>>
>>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>>>
>>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>>>
>>>> function of the criteria :
>>>>
>>>> if "the elements in the 1st column of A could be found among the
>>>> elements
>>>> of the 1st column of B" i.e.
>>>>
>>>> for the example above, we shall combine in the results only the row with
>>>> "a*b" of A with the row with "a*b::x*y" of B.
>>>>
>>>> thank you,
>>>>
>>>> bogdan
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From fr@nce@c@@p@ncotto @ending from gm@il@com  Thu Jul 19 06:24:10 2018
From: fr@nce@c@@p@ncotto @ending from gm@il@com (Francesca)
Date: Thu, 19 Jul 2018 06:24:10 +0200
Subject: [R] GGPlot plot
In-Reply-To: <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
 <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
Message-ID: <CAKFaUKhOA6CWmmTSnZopS_bMQiKv9Ze3XBTyJNOcJ6gcUTfJEA@mail.gmail.com>

Thanks for the answer.

Il gio 19 lug 2018, 01:04 Jim Lemon <drjimlemon at gmail.com> ha scritto:

> Hi Francesca,
> This looks like a fairly simple task. Try this:
>
> fpdf<-read.table(text="PASP   SUBJC
>  0          0
>  4          1
>  0          0
>  8          0
>  4          0
>  0          1
>  0          1",
>  header=TRUE)
> # get the number of positive PASP results by group
> ppos<-by(fpdf$SUBJC,fpdf$PASPpos,sum)
> # get the number of subjects per group
> spg<-c(sum(fpdf$SUBJC==0),sum(fpdf$SUBJC==1))
> barplot(ppos/spg,names.arg=c(0,1),xlab="Group",
>  ylab="Proportion PASP > 0",main="Proportion of PASP positive by group")
>
> Jim
>
> On Thu, Jul 19, 2018 at 2:47 AM, Francesca <francesca.pancotto at gmail.com>
> wrote:
> > Dear R help,
> >
> > I am new to ggplot so I apologize if my question is a bit obvious.
> >
> > I would like to create a plot where a compare the fraction of the values
> of a variable called PASP out of the number of subjects, for two groups of
> subject codified with a dummy variable called SUBJC.
> >
> > The variable PASP is discrete and only takes values 0,4,8..
> >
> > My data are as following:
> >
> >
> >
> > PASP   SUBJC
> >
> >
> >
> > 0          0
> >
> > 4          1
> >
> > 0          0
> >
> > 8          0
> >
> > 4          0
> >
> > 0          1
> >
> > 0          1
> >
> > .           .
> >
> > .           .
> >
> > .           .
> >
> >
> >
> >
> > I would like to calculate the fraction of positive levels of PASP out of
> the total number of observations, divided per values of SUBJ=0 and 1. I am
> new to the use of GGPlot and I do not know how to organize the data and
> what to use to summarize these data as to obtain a picture as follows:
> >
> >
> >
> >
> >
> > I hope my request is clear. Thanks for any help you can provide.
> >
> > Francesca
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e@ @ending from enrico@chum@nn@net  Thu Jul 19 08:55:52 2018
From: e@ @ending from enrico@chum@nn@net (Enrico Schumann)
Date: Thu, 19 Jul 2018 08:55:52 +0200
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
In-Reply-To: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
 (Christofer Bogaso's message of "Mon, 9 Jul 2018 15:52:02 +0530")
References: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
Message-ID: <87pnzjhfyf.fsf@enricoschumann.net>

On Mon, 09 Jul 2018, Christofer Bogaso writes:

> Hi,
>
> Below is my code :
>
> library(zoo)
> Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
>
> merge(Dat1, Dat2)
>
>                         Dat1     Dat2
> 2017-12-07 22:09:00 17890.00 15804.28
> 2017-12-07 22:10:00 17770.01 15720.61
> 2017-12-07 22:11:00 17600.00 15770.00
> 2017-12-07 22:12:00 17593.00 15750.00
> 2017-12-07 22:13:00 17630.01 15770.00
>
>
> So, after merging the TZ of the original series got changed.
>
> Appreciate if someone points what went wrong
>

Nothing went wrong. Only 'merge.zoo' drops the
time-zone attribute.  But note that it did not change
the actual times:

  unclass(index(Dat1))
  ## [1] 1512664740 1512664800 1512664860 1512664920 1512664980
  ## attr(,"tzone")
  ## [1] "America/Los_Angeles"

  unclass(index(merge(Dat1, Dat2)))
  ## [1] 1512664740 1512664800 1512664860 1512664920 1512664980

  all(unclass(index(Dat1)) == unclass(index(merge(Dat1, Dat2))))
  ## [1] TRUE

  M <- merge(Dat1, Dat2)
  attr(index(M), "tzone") <- attr(index(Dat1), "tzone")
  M
  ##                         Dat1     Dat2
  ## 2017-12-07 08:39:00 17890.00 15804.28
  ## 2017-12-07 08:40:00 17770.01 15720.61
  ## 2017-12-07 08:41:00 17600.00 15770.00
  ## 2017-12-07 08:42:00 17593.00 15750.00
  ## 2017-12-07 08:43:00 17630.01 15770.00


See Ripley, B. D. and Hornik, K. (2001) Date-time
classes. R News, 1/2,
8?11. https://www.r-project.org/doc/Rnews/Rnews_2001-2.pdf



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From rhurlin @ending from gwdg@de  Thu Jul 19 09:44:33 2018
From: rhurlin @ending from gwdg@de (Rainer Hurling)
Date: Thu, 19 Jul 2018 09:44:33 +0200
Subject: [R] Help with knitr pkg
In-Reply-To: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <05c77898-b4b8-bd00-d954-10f1bd594ded@gwdg.de>

Hi Bill,

Am 18.07.18 um 18:33 schrieb Bill Poling:
> Hi,
> I worked through this excellent tutorial:
> #Elegant regression results tables and plots in R: the finalfit package
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
> 
> 
> 
> Now I am applying it to my own data.
> 
> In the tutorial there is mention of:
> 
> # Tables can be knitted to PDF, Word or html documents. We do this in
> # RStudio from a .Rmd document. Example chunk:
> #   ```{r, echo = FALSE, results='asis'}
> # knitr::kable(example_table, row.names=FALSE,
> #              align=c("l", "l", "r", "r", "r", "r"))
> # ```
> 
> I am having a difficult time understanding how this works?
> 
> I have read through the help:
> 
> ?knitr
> #"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
> #It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
> #The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."
> 
> install.packages("knitr")
> library(knitr)
> ?knit
> ?stitch
> install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
> ?spin
> install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages :  Perhaps you meant 'SPIn' ?
> 
> I have also looked at the github and knitr author's links
> 
> https://github.com/yihui/knitr
> 
> https://yihui.name/knitr/demo/stitch/
> 
> https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd
> 
> 
> If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?
> 
> I also tried writing out directly to pdf and png with no success.
> 
> #pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
> #png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
> #opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?
> 
> #This is the script I would like the output placed in PDF
> explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
> dependent = "AppealOverturned" # Appeals Status
> appdf1DT2 %>%
>    summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)
> 
> #dev.off()
> 
> 
> str(appdf1DT2)
> # Classes 'data.table' and 'data.frame':   3983 obs. of  21 variables:
> #   $ ClaimServiceID   : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
> # $ LineNumber       : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
> # $ claimStatusId    : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PatientGender    : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PayorID          : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
> # $ AppealID         : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
> # $ ZipCode          : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
> # $ EditID           : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
> # $ CurrentBilled    : num  14394 14394 14394 14394 14394 ...
> # $ ClaimLineSavings : num  0 0 0 0 0 ...
> # $ StatusChangeMo   : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ Grouping         : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PrimaryDX        : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
> # $ RevCodeCats      : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
> # $ AgeCat           : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
> # $ ClaimLevelSavings: num  0 0 0 0 0 ...
> # - attr(*, ".internal.selfref")=<externalptr>
> 
> head(appdf1DT2)
>     ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode        TIN EditID
> 1:       51318639          1             3             M     000     149385    79765              33904      0
> 2:       51318640          2             3             M     000     149385    79765              33904    022
> 3:       51318642          4             3             M     000     149385    79765              33904   00504
> 4:       51318641          3             3             M     000     149385    79765              33904     022
> 5:       51318643          5             3             M     000     149385    79765              33904   00504
> 6:       85833537          7             2             F     000    3240182   116998              46635   00504
>     CurrentBilled ClaimLineSavings StatusChangeMo                                 Grouping AppealOverturned PrimaryDX        RevCodeCats
> 1:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 2:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 3:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 4:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 5:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 6:      23472.92                0        2018-04  Ambulatory Health Care Facilities                1     M1712 MedSurgSuppandDevs
>      AgeCat ClaimLevelSavings
> 1: [31-40]              0.00
> 2: [31-40]              0.00
> 3: [31-40]              0.00
> 4: [31-40]              0.00
> 5: [31-40]              0.00
> 6: [61-70]            296.25
> 
> 
> Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.
> 
> Thank you.
> 
> WHP
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 


Not sure, if I get you right. Seems, that you use knitr:: and code 
chunks without the necessary context?

Please have a look at https://rmarkdown.rstudio.com/ to get a more 
general understanding about using knitr within RMarkdown context.

HTH,
Rainer Hurling


From thierry@onkelinx @ending from inbo@be  Thu Jul 19 11:10:09 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Thu, 19 Jul 2018 11:10:09 +0200
Subject: [R] Help with knitr pkg
In-Reply-To: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAJuCY5wSGgYTEhkpPBK3-F6SGHH8uHC3W0O+Jwx=CtRTT4Fo7g@mail.gmail.com>

Dear Bill,

It seems like you are looking at the wrong help files. The code in the
tutorial uses the package::function() syntax. So knitr::kable()
translates into use the function kable() from the knitr package. The
help file you are looking for is ?kable (when knitr is loaded) or
?knitr::kable (when knitr is not loaded).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-07-18 18:33 GMT+02:00 Bill Poling <Bill.Poling at zelis.com>:
> Hi,
> I worked through this excellent tutorial:
> #Elegant regression results tables and plots in R: the finalfit package
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>
>
>
> Now I am applying it to my own data.
>
> In the tutorial there is mention of:
>
> # Tables can be knitted to PDF, Word or html documents. We do this in
> # RStudio from a .Rmd document. Example chunk:
> #   ```{r, echo = FALSE, results='asis'}
> # knitr::kable(example_table, row.names=FALSE,
> #              align=c("l", "l", "r", "r", "r", "r"))
> # ```
>
> I am having a difficult time understanding how this works?
>
> I have read through the help:
>
> ?knitr
> #"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
> #It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
> #The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."
>
> install.packages("knitr")
> library(knitr)
> ?knit
> ?stitch
> install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
> ?spin
> install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages :  Perhaps you meant 'SPIn' ?
>
> I have also looked at the github and knitr author's links
>
> https://github.com/yihui/knitr
>
> https://yihui.name/knitr/demo/stitch/
>
> https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd
>
>
> If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?
>
> I also tried writing out directly to pdf and png with no success.
>
> #pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
> #png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
> #opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?
>
> #This is the script I would like the output placed in PDF
> explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
> dependent = "AppealOverturned" # Appeals Status
> appdf1DT2 %>%
>   summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)
>
> #dev.off()
>
>
> str(appdf1DT2)
> # Classes 'data.table' and 'data.frame':   3983 obs. of  21 variables:
> #   $ ClaimServiceID   : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
> # $ LineNumber       : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
> # $ claimStatusId    : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PatientGender    : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PayorID          : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
> # $ AppealID         : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
> # $ ZipCode          : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
> # $ EditID           : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
> # $ CurrentBilled    : num  14394 14394 14394 14394 14394 ...
> # $ ClaimLineSavings : num  0 0 0 0 0 ...
> # $ StatusChangeMo   : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ Grouping         : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PrimaryDX        : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
> # $ RevCodeCats      : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
> # $ AgeCat           : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
> # $ ClaimLevelSavings: num  0 0 0 0 0 ...
> # - attr(*, ".internal.selfref")=<externalptr>
>
> head(appdf1DT2)
>    ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode        TIN EditID
> 1:       51318639          1             3             M     000     149385    79765              33904      0
> 2:       51318640          2             3             M     000     149385    79765              33904    022
> 3:       51318642          4             3             M     000     149385    79765              33904   00504
> 4:       51318641          3             3             M     000     149385    79765              33904     022
> 5:       51318643          5             3             M     000     149385    79765              33904   00504
> 6:       85833537          7             2             F     000    3240182   116998              46635   00504
>    CurrentBilled ClaimLineSavings StatusChangeMo                                 Grouping AppealOverturned PrimaryDX        RevCodeCats
> 1:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 2:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 3:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 4:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 5:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 6:      23472.92                0        2018-04  Ambulatory Health Care Facilities                1     M1712 MedSurgSuppandDevs
>     AgeCat ClaimLevelSavings
> 1: [31-40]              0.00
> 2: [31-40]              0.00
> 3: [31-40]              0.00
> 4: [31-40]              0.00
> 5: [31-40]              0.00
> 6: [61-70]            296.25
>
>
> Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.
>
> Thank you.
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Bill@Poling @ending from zeli@@com  Thu Jul 19 12:22:19 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 19 Jul 2018 10:22:19 +0000
Subject: [R] Help with knitr pkg
In-Reply-To: <05c77898-b4b8-bd00-d954-10f1bd594ded@gwdg.de>
References: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <05c77898-b4b8-bd00-d954-10f1bd594ded@gwdg.de>
Message-ID: <CY1PR0201MB183410C5858B2EFFA0397080EA520@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi Rainer:

Thank you I will have a look at the link you provide.
As I mentioned,
?#opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work??

Hopefully your reference has an example I can follow, will let you know, cheers.

WHP


>>Not sure, if I get you right. Seems, that you use knitr:: and code
chunks without the necessary context?

Please have a look at https://rmarkdown.rstudio.com/<https://rmarkdown.rstudio.com/> to get a more
general understanding about using knitr within RMarkdown context.<<<<



From: Rainer Hurling <rhurlin at gwdg.de>
Sent: Thursday, July 19, 2018 3:45 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with knitr pkg

Hi Bill,

Am 18.07.18 um 18:33 schrieb Bill Poling:
> Hi,
> I worked through this excellent tutorial:
> #Elegant regression results tables and plots in R: the finalfit package
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/<https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/>
>
>
>
> Now I am applying it to my own data.
>
> In the tutorial there is mention of:
>
> # Tables can be knitted to PDF, Word or html documents. We do this in
> # RStudio from a .Rmd document. Example chunk:
> # ```{r, echo = FALSE, results='asis'}
> # knitr::kable(example_table, row.names=FALSE,
> # align=c("l", "l", "r", "r", "r", "r"))
> # ```
>
> I am having a difficult time understanding how this works?
>
> I have read through the help:
>
> ?knitr
> #"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
> #It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
> #The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."
>
> install.packages("knitr")
> library(knitr)
> ?knit
> ?stitch
> install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
> ?spin
> install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages : Perhaps you meant 'SPIn' ?
>
> I have also looked at the github and knitr author's links
>
> https://github.com/yihui/knitr<https://github.com/yihui/knitr>
>
> https://yihui.name/knitr/demo/stitch/<https://yihui.name/knitr/demo/stitch/>
>
> https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd<https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd>
>
>
> If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?
>
> I also tried writing out directly to pdf and png with no success.
>
> #pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
> #png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
> #opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?
>
> #This is the script I would like the output placed in PDF
> explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
> dependent = "AppealOverturned" # Appeals Status
> appdf1DT2 %>%
> summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)
>
> #dev.off()
>
>
> str(appdf1DT2)
> # Classes 'data.table' and 'data.frame': 3983 obs. of 21 variables:
> # $ ClaimServiceID : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
> # $ LineNumber : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
> # $ claimStatusId : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PatientGender : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PayorID : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
> # $ AppealID : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
> # $ ZipCode : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
> # $ EditID : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
> # $ CurrentBilled : num 14394 14394 14394 14394 14394 ...
> # $ ClaimLineSavings : num 0 0 0 0 0 ...
> # $ StatusChangeMo : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ Grouping : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PrimaryDX : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
> # $ RevCodeCats : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
> # $ AgeCat : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
> # $ ClaimLevelSavings: num 0 0 0 0 0 ...
> # - attr(*, ".internal.selfref")=<externalptr>
>
> head(appdf1DT2)
> ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode TIN EditID
> 1: 51318639 1 3 M 000 149385 79765 33904 0
> 2: 51318640 2 3 M 000 149385 79765 33904 022
> 3: 51318642 4 3 M 000 149385 79765 33904 00504
> 4: 51318641 3 3 M 000 149385 79765 33904 022
> 5: 51318643 5 3 M 000 149385 79765 33904 00504
> 6: 85833537 7 2 F 000 3240182 116998 46635 00504
> CurrentBilled ClaimLineSavings StatusChangeMo Grouping AppealOverturned PrimaryDX RevCodeCats
> 1: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 AmbSurgCare
> 2: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 AmbSurgCare
> 3: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 MedSurgSuppandDevs
> 4: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 AmbSurgCare
> 5: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 MedSurgSuppandDevs
> 6: 23472.92 0 2018-04 Ambulatory Health Care Facilities 1 M1712 MedSurgSuppandDevs
> AgeCat ClaimLevelSavings
> 1: [31-40] 0.00
> 2: [31-40] 0.00
> 3: [31-40] 0.00
> 4: [31-40] 0.00
> 5: [31-40] 0.00
> 6: [61-70] 296.25
>
>
> Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.
>
> Thank you.
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>


Not sure, if I get you right. Seems, that you use knitr:: and code
chunks without the necessary context?

Please have a look at https://rmarkdown.rstudio.com/<https://rmarkdown.rstudio.com/> to get a more
general understanding about using knitr within RMarkdown context.

HTH,
Rainer Hurling

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From SW@y @ending from meco@com  Thu Jul 19 13:52:46 2018
From: SW@y @ending from meco@com (Shawn Way)
Date: Thu, 19 Jul 2018 11:52:46 +0000
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
Message-ID: <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>

Thank you for the example you posted.  I'll try to make a go of it from there.

I understand and actually use columns with consistent information, however, it's the reporting of the variables and their units that is the crux of the situation.  The units package is extremely useful in automatic conversion between units, something necessary for us engineering folks.

Thank you kindly!

Shawn Way, PE

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, July 18, 2018 9:26 PM
To: Shawn Way <SWay at meco.com>
Cc: r-help at r-project.org
Subject: Re: [R] xtable does not print out units of a variable

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.  I'm assuming 
> that's because the data is in a class units and xtable doesn't know 
> what to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.

More below.

> The following is a MWE:
>
>    library(xtable)
>    library(units)
>    data <- data.frame(x=c(as_units(12,"ft")))
>    xtable(data)
>
>    % latex table generated in R 3.5.1 by xtable 1.8-2 package
>    % Wed Jul 18 17:31:44 2018
>    \begin{table}[ht]
>    \centering
>    \begin{tabular}{rr}
>      \hline
>     & x \\
>      \hline
>    1 & 12.00 \\
>      \hline
>    \end{tabular}
>    \end{table}
>
> What I'm looking for is the line
>
>    1 & 12.00 \\
>
> to be
>
>    1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being 
> able to handle this class would be extremely beneficial to engineers 
> that are using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
                       , " ($"
                       , deparse_unit( datax[[1]] )
                       , "$)"
                       )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
#>   \hline
#>  & x (\$ft\$) \\
#>   \hline
#> 1 & 12.00 \\
#>   2 & 13.00 \\
#>    \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jrkride@u @ending from y@hoo@c@  Thu Jul 19 14:40:00 2018
From: jrkride@u @ending from y@hoo@c@ (John Kane)
Date: Thu, 19 Jul 2018 12:40:00 +0000 (UTC)
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
 <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <1676236527.753639.1532004000762@mail.yahoo.com>

 ?I wonder if the problem may be that xtable is not designed to deal with an object of class "object" 

> dat1 <- data.frame(? x=c(as_units(12,"ft")))
> str(dat1)
'data.frame':?? ?1 obs. of? 1 variable:
?$ x:Object of class units:
?atomic? 12
? ..- attr(*, "units")=List of 2
? .. ..$ numerator? : chr "ft"
? .. ..$ denominator: chr 
? .. ..- attr(*, "class")= chr "symbolic_units"



   On Thursday, July 19, 2018, 7:53:09 a.m. EDT, Shawn Way <SWay at meco.com> wrote:  
 
 Thank you for the example you posted.? I'll try to make a go of it from there.

I understand and actually use columns with consistent information, however, it's the reporting of the variables and their units that is the crux of the situation.? The units package is extremely useful in automatic conversion between units, something necessary for us engineering folks.

Thank you kindly!

Shawn Way, PE

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, July 18, 2018 9:26 PM
To: Shawn Way <SWay at meco.com>
Cc: r-help at r-project.org
Subject: Re: [R] xtable does not print out units of a variable

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.? I'm assuming 
> that's because the data is in a class units and xtable doesn't know 
> what to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.

More below.

> The following is a MWE:
>
>? ? library(xtable)
>? ? library(units)
>? ? data <- data.frame(x=c(as_units(12,"ft")))
>? ? xtable(data)
>
>? ? % latex table generated in R 3.5.1 by xtable 1.8-2 package
>? ? % Wed Jul 18 17:31:44 2018
>? ? \begin{table}[ht]
>? ? \centering
>? ? \begin{tabular}{rr}
>? ? ? \hline
>? ? & x \\
>? ? ? \hline
>? ? 1 & 12.00 \\
>? ? ? \hline
>? ? \end{tabular}
>? ? \end{table}
>
> What I'm looking for is the line
>
>? ? 1 & 12.00 \\
>
> to be
>
>? ? 1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being 
> able to handle this class would be extremely beneficial to engineers 
> that are using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
? ? ? ? ? ? ? ? ? ? ? , " ($"
? ? ? ? ? ? ? ? ? ? ? , deparse_unit( datax[[1]] )
? ? ? ? ? ? ? ? ? ? ? , "$)"
? ? ? ? ? ? ? ? ? ? ? )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
#>? \hline
#>? & x (\$ft\$) \\
#>? \hline
#> 1 & 12.00 \\
#>? 2 & 13.00 \\
#>? ? \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 15:35:03 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 06:35:03 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>

On Wed, 18 Jul 2018, Rich Shepard wrote:

> If you would suggest how many would be an acceptably large number I'll be
> happy to put that on a 'cloud' sharing site and provide the URL to it.

   I put a zipped data file at this URL:
<http://www.fileconvoy.com/dfl.php?id=g61a366bb8947de43100009863935141c96f82092d4>

   It will stay there for 5 days.

Rich


From dulc@lm@ @ending from bigpond@com  Thu Jul 19 15:37:56 2018
From: dulc@lm@ @ending from bigpond@com (Duncan Mackay)
Date: Thu, 19 Jul 2018 23:37:56 +1000
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
Message-ID: <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>

Hi Rich

Try something like this

set.seed(1)
xy <- 
data.frame(x = rnorm(108),
           y = rnorm(108),
           gp = rep(1:9, ea = 12))


xyplot(y~x|gp, xy,
       as.table = TRUE,
       strip = F,
       strip.left = F,
       layout = c(3,3),
       par.settings= list(layout.heights = list(main = 0,
                                          axis.top = 0.3),
                          plot.symbol = list(pch = ".",
			                     col = "#000000",
			                     cex = 3)
	           ),
       scales = list(x = list(alternating = FALSE,
                              relation    = "same"),
                     y = list(alternating = FALSE,
                              relation    = "same")
                 ),
       panel = function(x,y, ...){

                 panel.xyplot(x,y, ...)
                 panel.text(-1, 2, paste("Group", 1:9)[which.packet()])

               }
)

I have put over 60 panels on an A4 page.
You may have to put an if statement for the group names if they overlap
data.
Space is a premium - you can reduce the right margin similar to the top see
?trellis.par.get()

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350
 



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Thursday, 19 July 2018 06:55
To: r-help at r-project.org
Subject: [R] Suggestions for scatter plot of many data

   I have daily precipitation data for 58 locations from 2005-01-01 through
2018-06-18. Among other plots and analyses I want to apply lattice's
xyplot() to illustrate the abundance and patterns of the data.

   I've used a vector of colors (and a key) when there were only eight
weather stations and the date range was three months. This was very
effective in communicating the amounts and patterns.

   I'm asking for ideas on how to best present these data in a scatter plot.

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@rc_@chw@rtz @ending from me@com  Thu Jul 19 15:38:57 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Thu, 19 Jul 2018 09:38:57 -0400
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
 <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <0EA067C6-F588-4FEC-9373-08AA8DD57D41@me.com>

Hi,

Just to throw in an alternative possibility, you may want to look at Frank's Hmisc package on CRAN:

  https://cran.r-project.org/web/packages/Hmisc/index.html

and note the label(), latex() and units() functions therein.

They may or may not work for what you are looking to do here.

As Jeff has noted, you may need to do some pre-processing of the output to the LaTeX table to get what you want, before calling any of the LaTeX output functions, in the absence of direct support for specific classes of object, such as 'units'. Keep in mind, that all of the output to LaTeX is character based, so you can create any formatted character string you need, then generate the LaTeX output.

Regards,

Marc Schwartz


> On Jul 19, 2018, at 7:52 AM, Shawn Way <SWay at meco.com> wrote:
> 
> Thank you for the example you posted.  I'll try to make a go of it from there.
> 
> I understand and actually use columns with consistent information, however, it's the reporting of the variables and their units that is the crux of the situation.  The units package is extremely useful in automatic conversion between units, something necessary for us engineering folks.
> 
> Thank you kindly!
> 
> Shawn Way, PE
> 
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
> Sent: Wednesday, July 18, 2018 9:26 PM
> To: Shawn Way <SWay at meco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] xtable does not print out units of a variable
> 
>> On Wed, 18 Jul 2018, Shawn Way wrote:
>> 
>> I have a dataframe that contains units using the units package. 
>> Unfortunately, I really need the units for reporting.  I'm assuming 
>> that's because the data is in a class units and xtable doesn't know 
>> what to do with this.
> 
> If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:
> 
> maintainer( "xtable" )
> 
> Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.
> 
> More below.
> 
>> The following is a MWE:
>> 
>>   library(xtable)
>>   library(units)
>>   data <- data.frame(x=c(as_units(12,"ft")))
>>   xtable(data)
>> 
>>   % latex table generated in R 3.5.1 by xtable 1.8-2 package
>>   % Wed Jul 18 17:31:44 2018
>>   \begin{table}[ht]
>>   \centering
>>   \begin{tabular}{rr}
>>     \hline
>>    & x \\
>>     \hline
>>   1 & 12.00 \\
>>     \hline
>>   \end{tabular}
>>   \end{table}
>> 
>> What I'm looking for is the line
>> 
>>   1 & 12.00 \\
>> 
>> to be
>> 
>>   1 & 12.00 $ft$\\
>> 
>> Can someone point me in the correct direction to make this happen? 
>> Since units are used extensively in engineering calculations, being 
>> able to handle this class would be extremely beneficial to engineers 
>> that are using R with knitr to generate engineering documents.
>> 
>> Shawn Way
> 
> I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:
> 
> ####################
> library(xtable)
> library(units)
> #> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
> datax <- xtable(data)
> names(datax) <- paste0( names(datax)[1]
>                       , " ($"
>                       , deparse_unit( datax[[1]] )
>                       , "$)"
>                       )
> datax
> #> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
> #>   \hline
> #>  & x (\$ft\$) \\
> #>   \hline
> #> 1 & 12.00 \\
> #>   2 & 13.00 \\
> #>    \hline
> #> \end{tabular}
> #> \end{table}
> 
> #' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
> ####################
> 
> If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 16:18:17 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 07:18:17 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
Message-ID: <alpine.LNX.2.20.1807190714460.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Duncan Mackay wrote:

> Try something like this

   ...

Duncan,

   That's impressive and well beyond anything I've done in the past. I'll
study it to fully understand it and make it work for me.

> I have put over 60 panels on an A4 page.
> Space is a premium - you can reduce the right margin similar to the top see
> ?trellis.par.get()

   On the smaller letter size page I may need to create two sets of plots if
each panel is too small.

   Thank you for the valuable lesson.

Best regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 18:10:06 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 09:10:06 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Rich Shepard wrote:

>  I put a zipped data file at this URL:
> <http://www.fileconvoy.com/dfl.php?id=g61a366bb8947de43100009863935141c96f82092d4>

   Since then I reformatted the file to two fields: date-time and elevation.
If anyone wants a copy send me a message off the list and I'll respond with
the modified file attached.

   Because time zone doesn't matter for a single location I'm looking at how
to use chron(). I've downloaded the PDF from CRAN and am trying to apply it
correctly so the dataframe contains two columns: date-time and elevation.
Will probably be asking for help in correctly using chron().

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 19:02:07 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 10:02:07 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Rich Shepard wrote:

> Since then I reformatted the file to two fields: date-time and elevation.
> If anyone wants a copy send me a message off the list and I'll respond with
> the modified file attached.

   This is a mistake. The file needs commas separating each field.

   I have the date and elev columns converted from factors to date and
numeric, respectively, but still have not learned how to convert the time.

   The source data file (head):
date,time,elev
2017-10-01,00:00,290.298
2017-10-01,00:30,290.301
2017-10-01,01:00,290.304
2017-10-01,01:30,290.295
2017-10-01,02:00,290.292
2017-10-01,02:30,290.289
2017-10-01,03:00,290.289
2017-10-01,03:30,290.289
2017-10-01,04:00,290.28

   These commands read the file and convert the date and elev columns:
wy2018 <- read.table('sh-2018.dat', header = T, sep = ',')
wy2018$date <- as.Date(as.character(wy2018$date, format='y-m-d'))
head(wy2018)
         date time    elev
1 2017-10-01   01 290.298
2 2017-10-01   01 290.301
3 2017-10-01   01 290.304
4 2017-10-01   01 290.295
5 2017-10-01   01 290.292
6 2017-10-01   01 290.289

   My attempts using chron() for the time column keep failing; e.g., 
wy2018$time <- chron(wy2018$time, format='h:m')
str(wy2018)
'data.frame':	12592 obs. of  3 variables:
  $ date: Date, format: "2017-10-01" "2017-10-01" ...
  $ time: 'dates' num  01 01 01 01 01 01 01 01 01 01 ...
   ..- attr(*, "format")= chr "h:m"
   ..- attr(*, "origin")= Named num  1 1 1970
   .. ..- attr(*, "names")= chr  "month" "day" "year"
  $ elev: num  290 290 290 290 290 ...

   Also, when I tried to use chron() for both the date and time columns of
the dataframe these failed, too.

   Please teach me how to read the data sources and produce dataframe columns
of date, time, and numeric.

Rich


From ccberry @ending from uc@d@edu  Thu Jul 19 21:10:47 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Thu, 19 Jul 2018 19:10:47 +0000
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
Message-ID: <1C451422-B23A-4760-ACDD-7BCE6BDBD51A@ucsd.edu>



> On Jul 18, 2018, at 1:55 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have daily precipitation data for 58 locations from 2005-01-01 through
> 2018-06-18.

So roughly 5000 observations of latitiude, longitude, elevation(?), and amount.

Maybe something dynamic like Hans Rosling does:

https://towardsdatascience.com/how-to-build-animated-charts-like-hans-rosling-doing-it-all-in-r-570efc6ba382

possibly smoothing temporally.

Googling `Hans Rosling R' and 'Dynamic Graphics in R' should get you some other hits including the Graphics Task View.

HTH,

Chuck

From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 21:26:36 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 12:26:36 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <1C451422-B23A-4760-ACDD-7BCE6BDBD51A@ucsd.edu>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <1C451422-B23A-4760-ACDD-7BCE6BDBD51A@ucsd.edu>
Message-ID: <alpine.LNX.2.20.1807191225300.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Berry, Charles wrote:

> So roughly 5000 observations of latitiude, longitude, elevation(?), and
> amount.
>
> Maybe something dynamic like Hans Rosling does:
>
> https://towardsdatascience.com/how-to-build-animated-charts-like-hans-rosling-doing-it-all-in-r-570efc6ba382
>
> possibly smoothing temporally.
>
> Googling `Hans Rosling R' and 'Dynamic Graphics in R' should get you some
> other hits including the Graphics Task View.

Chuck,

   Thanks for the suggestion. I'll read the web page and look at the other
references you recommend.

Regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 21:33:11 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 12:33:11 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807191227100.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Rich Shepard wrote:

> I have the date and elev columns converted from factors to date and
> numeric, respectively, but still have not learned how to convert the time.

   With this dataframe structure,

str(wy2018)
'data.frame':	12592 obs. of  3 variables:
  $ date: Date, format: "2017-10-01" "2017-10-01" ...
  $ time: chr  "00:00" "00:30" "01:00" "01:30" ...
  $ elev: num  290 290 290 290 290 ...

what is my syntax error using chron() to convert the time column?

wy2018$time <- chron(times=wy2018$time)
Error in convert.times(times., fmt) : format h:m:s may be incorrect
In addition: Warning message:
In unpaste(times, sep = fmt$sep, fnames = fmt$periods, nfields = 3) :
   12592 entries set to NA due to wrong number of fields


   Adding a format as either %h:%m or just h:m makes no difference.

Rich


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 19 22:10:38 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 13:10:38 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
Message-ID: <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>


> On Jul 19, 2018, at 10:02 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 19 Jul 2018, Rich Shepard wrote:
> 
>> Since then I reformatted the file to two fields: date-time and elevation.
>> If anyone wants a copy send me a message off the list and I'll respond with
>> the modified file attached.
> 
>  This is a mistake. The file needs commas separating each field.
> 
>  I have the date and elev columns converted from factors to date and
> numeric, respectively, but still have not learned how to convert the time.
> 
>  The source data file (head):
> date,time,elev
> 2017-10-01,00:00,290.298
> 2017-10-01,00:30,290.301
> 2017-10-01,01:00,290.304
> 2017-10-01,01:30,290.295
> 2017-10-01,02:00,290.292
> 2017-10-01,02:30,290.289
> 2017-10-01,03:00,290.289
> 2017-10-01,03:30,290.289
> 2017-10-01,04:00,290.28

I took the code that I offered earlier and replaced allyears with wy2018:

> txt <- "date,time,elev
+ 2017-10-01,00:00,290.298
+ 2017-10-01,00:30,290.301
+ 2017-10-01,01:00,290.304
+ 2017-10-01,01:30,290.295
+ 2017-10-01,02:00,290.292
+ 2017-10-01,02:30,290.289
+ 2017-10-01,03:00,290.289
+ 2017-10-01,03:30,290.289

+ 2017-10-01,04:00,290.28"
> wy2018 <- read.table(text=txt, header = T, sep = ',')

> wy2018 $myDate <- as.Date(as.character(wy2018 $date))
> wy2018 $myTime <- as.POSIXct(paste(wy2018 $date, wy2018 $time))
> wy2018
        date  time    elev     myDate              myTime
1 2017-10-01 00:00 290.298 2017-10-01 2017-10-01 00:00:00
2 2017-10-01 00:30 290.301 2017-10-01 2017-10-01 00:30:00
3 2017-10-01 01:00 290.304 2017-10-01 2017-10-01 01:00:00
4 2017-10-01 01:30 290.295 2017-10-01 2017-10-01 01:30:00
5 2017-10-01 02:00 290.292 2017-10-01 2017-10-01 02:00:00
6 2017-10-01 02:30 290.289 2017-10-01 2017-10-01 02:30:00
7 2017-10-01 03:00 290.289 2017-10-01 2017-10-01 03:00:00
8 2017-10-01 03:30 290.289 2017-10-01 2017-10-01 03:30:00
9 2017-10-01 04:00 290.280 2017-10-01 2017-10-01 04:00:00

> str(wy2018)
'data.frame':	9 obs. of  5 variables:
 $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
 $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
 $ elev  : num  290 290 290 290 290 ...
 $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
 $ myTime: POSIXct, format: "2017-10-01 00:00:00" "2017-10-01 00:30:00" ...

> 
>  These commands read the file and convert the date and elev columns:
> wy2018 <- read.table('sh-2018.dat', header = T, sep = ',')
> wy2018$date <- as.Date(as.character(wy2018$date, format='y-m-d'))
> head(wy2018)
>        date time    elev
> 1 2017-10-01   01 290.298
> 2 2017-10-01   01 290.301
> 3 2017-10-01   01 290.304
> 4 2017-10-01   01 290.295
> 5 2017-10-01   01 290.292
> 6 2017-10-01   01 290.289
> 
>  My attempts using chron() for the time column keep failing; e.g., wy2018$time <- chron(wy2018$time, format='h:m')
> str(wy2018)
> 'data.frame':	12592 obs. of  3 variables:
> $ date: Date, format: "2017-10-01" "2017-10-01" ...
> $ time: 'dates' num  01 01 01 01 01 01 01 01 01 01 ...
>  ..- attr(*, "format")= chr "h:m"
>  ..- attr(*, "origin")= Named num  1 1 1970
>  .. ..- attr(*, "names")= chr  "month" "day" "year"
> $ elev: num  290 290 290 290 290 ...
> 
>  Also, when I tried to use chron() for both the date and time columns of
> the dataframe these failed, too.
> 
>  Please teach me how to read the data sources and produce dataframe columns
> of date, time, and numeric.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 19 22:20:36 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 13:20:36 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807191227100.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807191227100.15936@salmo.appl-ecosys.com>
Message-ID: <082D84D0-A9D0-487D-BAB7-1205B2784116@comcast.net>


> On Jul 19, 2018, at 12:33 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 19 Jul 2018, Rich Shepard wrote:
> 
>> I have the date and elev columns converted from factors to date and
>> numeric, respectively, but still have not learned how to convert the time.
> 
>  With this dataframe structure,
> 
> str(wy2018)
> 'data.frame':	12592 obs. of  3 variables:
> $ date: Date, format: "2017-10-01" "2017-10-01" ...
> $ time: chr  "00:00" "00:30" "01:00" "01:30" ...
> $ elev: num  290 290 290 290 290 ...
> 
> what is my syntax error using chron() to convert the time column?

I have no idea. I think reaching for chron is not needed.
> 
> wy2018$time <- chron(times=wy2018$time)
> Error in convert.times(times., fmt) : format h:m:s may be incorrect
> In addition: Warning message:
> In unpaste(times, sep = fmt$sep, fnames = fmt$periods, nfields = 3) :
>  12592 entries set to NA due to wrong number of fields

That error suggests you needed either to add ":00" on hte end of your hh:mm formated data or provide a format string.

> wy2018$myTime <- chron(times= paste(wy2018$time, ":00") )


> str(wy2018)
'data.frame':	9 obs. of  5 variables:
 $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
 $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
 $ elev  : num  290 290 290 290 290 ...
 $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
 $ myTime: 'times' num  00:00:00 00:30:00 01:00:00 01:30:00 02:00:00 ...
  ..- attr(*, "format")= chr "h:m:s"

But I think that is not the right way to go.

> 
> 
>  Adding a format as either %h:%m or just h:m makes no difference.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 22:21:54 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 13:21:54 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors [RESOLVED]
In-Reply-To: <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
Message-ID: <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, David Winsemius wrote:

> I took the code that I offered earlier and replaced allyears with wy2018:

>        date  time    elev     myDate              myTime
> 1 2017-10-01 00:00 290.298 2017-10-01 2017-10-01 00:00:00
> 2 2017-10-01 00:30 290.301 2017-10-01 2017-10-01 00:30:00
> 3 2017-10-01 01:00 290.304 2017-10-01 2017-10-01 01:00:00
> 4 2017-10-01 01:30 290.295 2017-10-01 2017-10-01 01:30:00
> 5 2017-10-01 02:00 290.292 2017-10-01 2017-10-01 02:00:00
> 6 2017-10-01 02:30 290.289 2017-10-01 2017-10-01 02:30:00
> 7 2017-10-01 03:00 290.289 2017-10-01 2017-10-01 03:00:00
> 8 2017-10-01 03:30 290.289 2017-10-01 2017-10-01 03:30:00
> 9 2017-10-01 04:00 290.280 2017-10-01 2017-10-01 04:00:00
>
>> str(wy2018)
> 'data.frame':	9 obs. of  5 variables:
> $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
> $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
> $ elev  : num  290 290 290 290 290 ...
> $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
> $ myTime: POSIXct, format: "2017-10-01 00:00:00" "2017-10-01 00:30:00" ...

David,

   Thank you. I see the results in the dataframe structure although I still
don't understand all the reasons. The 'myTime' column confirms what I
thought: that there is no separate time data type. I'll use what you taught
me an move on with the analyses.

Best regards,

Rich


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 19 23:01:33 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 14:01:33 -0700
Subject: [R] Read in data table, change columns from factors [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
 <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>
Message-ID: <ACBD0687-331F-4839-9DD3-4EB32BF634F3@comcast.net>


> On Jul 19, 2018, at 1:21 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 19 Jul 2018, David Winsemius wrote:
> 
>> I took the code that I offered earlier and replaced allyears with wy2018:
> 
>>       date  time    elev     myDate              myTime
>> 1 2017-10-01 00:00 290.298 2017-10-01 2017-10-01 00:00:00
>> 2 2017-10-01 00:30 290.301 2017-10-01 2017-10-01 00:30:00
>> 3 2017-10-01 01:00 290.304 2017-10-01 2017-10-01 01:00:00
>> 4 2017-10-01 01:30 290.295 2017-10-01 2017-10-01 01:30:00
>> 5 2017-10-01 02:00 290.292 2017-10-01 2017-10-01 02:00:00
>> 6 2017-10-01 02:30 290.289 2017-10-01 2017-10-01 02:30:00
>> 7 2017-10-01 03:00 290.289 2017-10-01 2017-10-01 03:00:00
>> 8 2017-10-01 03:30 290.289 2017-10-01 2017-10-01 03:30:00
>> 9 2017-10-01 04:00 290.280 2017-10-01 2017-10-01 04:00:00
>> 
>>> str(wy2018)
>> 'data.frame':	9 obs. of  5 variables:
>> $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
>> $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
>> $ elev  : num  290 290 290 290 290 ...
>> $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
>> $ myTime: POSIXct, format: "2017-10-01 00:00:00" "2017-10-01 00:30:00" ...
> 
> David,
> 
>  Thank you. I see the results in the dataframe structure although I still
> don't understand all the reasons. The 'myTime' column confirms what I
> thought: that there is no separate time data type. I'll use what you taught
> me an move on with the analyses.

You can use format to only display the time portion of a datetime object. 

format( Sys.time(), "%H:%M")
[1] "13:57"

You can append the current date to a "time-only" character value and as.POSIXct will do that for you:

as.POSIXct("00:00", format="%H:%M")
[1] "2018-07-19 PDT"

> as.POSIXct(c("00:00", "00:01"), format="%H:%M")
[1] "2018-07-19 00:00:00 PDT" "2018-07-19 00:01:00 PDT"

There is a difftime-class in base R


And the lubridate package defines a duration class. It's not a package I use, and I cannot tell off the top of my head what it thinks the difference might be between a "time-span" and a "duration".

Best of luck.

> 
> Best regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 19 23:13:33 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 14:13:33 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors [RESOLVED]
In-Reply-To: <ACBD0687-331F-4839-9DD3-4EB32BF634F3@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
 <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>
 <ACBD0687-331F-4839-9DD3-4EB32BF634F3@comcast.net>
Message-ID: <alpine.LNX.2.20.1807191408580.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, David Winsemius wrote:

> You can use format to only display the time portion of a datetime object.
> format( Sys.time(), "%H:%M")
> [1] "13:57"
> You can append the current date to a "time-only" character value and as.POSIXct will do that for you:
> as.POSIXct("00:00", format="%H:%M")
> [1] "2018-07-19 PDT"
> as.POSIXct(c("00:00", "00:01"), format="%H:%M")
> [1] "2018-07-19 00:00:00 PDT" "2018-07-19 00:01:00 PDT"

David,

   I read about these in my R books and on web pages. I kept looking for a
time data type analogous to as.Date, as.character, and as.numeric. That's
what sent me in the wrong direction.

> There is a difftime-class in base R And the lubridate package defines a
> duration class. It's not a package I use, and I cannot tell off the top of
> my head what it thinks the difference might be between a "time-span" and a
> "duration".

   Good to know for the future.

   BTW, in a much earlier response you questioned why there were highly
negative elevations. Good question, because those should have been NAs and I
don't know how I let them in the data I manually extracted from PDF reports
from the USGS.

Best regards,

Rich


From SW@y @ending from meco@com  Thu Jul 19 23:34:37 2018
From: SW@y @ending from meco@com (Shawn Way)
Date: Thu, 19 Jul 2018 21:34:37 +0000
Subject: [R] Solved: RE:  xtable does not print out units of a variable
Message-ID: <346b5d88bfa948248acfc2ba237a74ba@CTC-HOU-EXMB-02.ctcloud.local>

Jeff, John, 

Thanks for pointing out the information.  I found that the following works:


New function for deparsing the data:

deparse_unit_latex <- function(x,frac=TRUE,xtable.frac=FALSE)
{
    stopifnot(inherits(x, "units"))
    u = units(x)
    tn = table(u$numerator)
    nm1 = names(tn)
    vals1 = as.character(tn)
    vals1 <- paste("^",vals1,sep="")
    vals1[vals1 == "^1"] = ""
    td = table(u$denominator)
    nm2 = names(td)
    vals2 = as.character(td)
    vals2 <- paste("^",vals2,sep="")
    vals2[vals2 == "^1"] = ""
    if(frac == TRUE) {
        if (xtable.frac==FALSE) {
            if(is.null(nm1)) {
                res <- cat(paste(c("$\\frac{}{",paste0(nm2, vals2),"}$"), collapse = " "))
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- cat(paste(c("$\\frac{",paste0(nm1, vals1),"}{",paste0(nm2, vals2),"}$"), collapse = " ")) 
            }
        }
        if (xtable.frac == TRUE) {
            if(is.null(nm1)) {
                res <- paste(paste0("$\\frac{}{",paste0(nm2, vals2),"}$"), collapse = " ")
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- paste(paste0("$\\frac{",paste0(nm1, vals1),"}{",paste0(nm2, vals2),"}$"), collapse = " ") 
            }
        }
    }
    if(frac == FALSE) {
        if(xtable.frac == TRUE){
            if(is.null(nm1)) {
                res <- paste(c("$/",paste0(nm2, vals2),"$"), collapse = " ")
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- paste(c("$",paste0(nm1, vals1),"/",paste0(nm2, vals2),"$"), collapse = " ") 
            }
        }
        if(xtable.frac == FALSE){
            if(is.null(nm1)) {
                res <- paste(c("$/",paste0(nm2, vals2),"$"), collapse = " ")
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- paste(c("$",paste0(nm1, vals1),"/",paste0(nm2, vals2),"$"), collapse = " ") 
            }
        }
    }
    res
}

Modification to xtable:

xtable <- function(x, ...) {
    for (i in which(sapply(x, function(y) !all(is.na(match(c("POSIXt","Date"),class(y))))))) x[[i]] <- as.character(x[[i]])
    for (i in which(sapply(x, function(y) !all(is.na(match(c("units"),class(y))))))) x[[i]] <- as.character(paste(as.character(x[[i]]),deparse_unit_latex(x[[i]],...)))
    xtable::xtable(x, ...)
}

Finally:

data <- data.frame(x=c(as_units(12,"kg/(m*sec^2)")),y=c(as_units(13,"kg/sec")),z=c(as_units(13,"ft^2")),zz=c(as_units(13,"sec-1")))

print(xtable(data,frac=FALSE,xtable.frac=TRUE),sanitize.text.function = function(x){x})

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Thu Jul 19 16:30:17 2018
\begin{table}[ht]
\centering
\begin{tabular}{rllll}
  \hline
 & x & y & z & zz \\ 
  \hline
1 & 12 $ kg / m s^2 $ & 13 $ kg / s $ & 13 $ ft^2 $ & 13 $/ s $ \\ 
   \hline
\end{tabular}
\end{table}
>


Or

> print(xtable(data,frac=TRUE,xtable.frac=TRUE),sanitize.text.function = function(x){x})
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Thu Jul 19 16:33:41 2018
\begin{table}[ht]
\centering
\begin{tabular}{rllll}
  \hline
 & x & y & z & zz \\ 
  \hline
1 & 12 $\frac{kg}{m}$ $\frac{kg}{s^2}$ & 13 $\frac{kg}{s}$ & 13 $ ft^2 $ & 13 $\frac{}{s}$ \\ 
   \hline
\end{tabular}
\end{table}
>


Thanks for all your help.

Shawn Way, PE


-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, July 18, 2018 9:26 PM
To: Shawn Way <SWay at meco.com>
Cc: r-help at r-project.org
Subject: Re: [R] xtable does not print out units of a variable

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.  I'm assuming 
> that's because the data is in a class units and xtable doesn't know 
> what to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.

More below.

> The following is a MWE:
>
>    library(xtable)
>    library(units)
>    data <- data.frame(x=c(as_units(12,"ft")))
>    xtable(data)
>
>    % latex table generated in R 3.5.1 by xtable 1.8-2 package
>    % Wed Jul 18 17:31:44 2018
>    \begin{table}[ht]
>    \centering
>    \begin{tabular}{rr}
>      \hline
>     & x \\
>      \hline
>    1 & 12.00 \\
>      \hline
>    \end{tabular}
>    \end{table}
>
> What I'm looking for is the line
>
>    1 & 12.00 \\
>
> to be
>
>    1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being 
> able to handle this class would be extremely beneficial to engineers 
> that are using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
                       , " ($"
                       , deparse_unit( datax[[1]] )
                       , "$)"
                       )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
#>   \hline
#>  & x (\$ft\$) \\
#>   \hline
#> 1 & 12.00 \\
#>   2 & 13.00 \\
#>    \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 00:04:39 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 15:04:39 -0700 (PDT)
Subject: [R] Scripting a repeating work flow
Message-ID: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>

   I have 30 data files that all need to be read into R, formatted, and have
scatter plots prepared. This process can be done in a short script. I would
like to generalize the script so that variables (such as data file names)
can be read from another file and all files processed sequentially, similar
to a bash shell script repeating commands for all files in a directory.

   Looking at my R programming books I don't find a way to do this and would
appreciate pointers to multi-file script writing that can be run within R
using the source() function.

Rich


From dwin@emiu@ @ending from comc@@t@net  Fri Jul 20 00:14:38 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 15:14:38 -0700
Subject: [R] Scripting a repeating work flow
In-Reply-To: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>
Message-ID: <0BB94E46-E77C-492D-860C-AB07EE3C5668@comcast.net>


> On Jul 19, 2018, at 3:04 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have 30 data files that all need to be read into R, formatted, and have
> scatter plots prepared. This process can be done in a short script. I would
> like to generalize the script so that variables (such as data file names)
> can be read from another file and all files processed sequentially, similar
> to a bash shell script repeating commands for all files in a directory.
> 
>  Looking at my R programming books I don't find a way to do this and would
> appreciate pointers to multi-file script writing that can be run within R
> using the source() function.

https://markmail.org/search/?q=list%3Aorg.r-project.r-help+script+process+multiple+csv+files

https://stackoverflow.com/questions/11433432/importing-multiple-csv-files-into-r

https://www.google.com/search?q=use+r+to+process+multiple+csv+files&oq=use+r+to+process+multiple+csv+files

> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From wjm1 @ending from c@@@columbi@@edu  Fri Jul 20 00:17:28 2018
From: wjm1 @ending from c@@@columbi@@edu (William Michels)
Date: Thu, 19 Jul 2018 15:17:28 -0700
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
Message-ID: <CAA99HCw4yCauPffuEndQ6vL48t506hcNv00H_-Xk+cB-gfjObA@mail.gmail.com>

Hello, In addition to Duncan Mackay's excellent suggestion, I would
recommend Bert Gunter's "stripless" package, for high-density
Trellis-type conditioning plots. See the vignette for examples, and
try out the code for "earthquake" and "barley" plots from the
reference manual.

https://CRAN.R-project.org/package=stripless
https://cran.r-project.org/web/packages/stripless/vignettes/stripless_vignette.html

Sincerely,

W. Michels, Ph.D.

On Thu, Jul 19, 2018 at 6:37 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Rich
>
> Try something like this
>
> set.seed(1)
> xy <-
> data.frame(x = rnorm(108),
>            y = rnorm(108),
>            gp = rep(1:9, ea = 12))
>
>
> xyplot(y~x|gp, xy,
>        as.table = TRUE,
>        strip = F,
>        strip.left = F,
>        layout = c(3,3),
>        par.settings= list(layout.heights = list(main = 0,
>                                           axis.top = 0.3),
>                           plot.symbol = list(pch = ".",
>                                              col = "#000000",
>                                              cex = 3)
>                    ),
>        scales = list(x = list(alternating = FALSE,
>                               relation    = "same"),
>                      y = list(alternating = FALSE,
>                               relation    = "same")
>                  ),
>        panel = function(x,y, ...){
>
>                  panel.xyplot(x,y, ...)
>                  panel.text(-1, 2, paste("Group", 1:9)[which.packet()])
>
>                }
> )
>
> I have put over 60 panels on an A4 page.
> You may have to put an if statement for the group names if they overlap
> data.
> Space is a premium - you can reduce the right margin similar to the top see
> ?trellis.par.get()
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2350
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
> Sent: Thursday, 19 July 2018 06:55
> To: r-help at r-project.org
> Subject: [R] Suggestions for scatter plot of many data
>
>    I have daily precipitation data for 58 locations from 2005-01-01 through
> 2018-06-18. Among other plots and analyses I want to apply lattice's
> xyplot() to illustrate the abundance and patterns of the data.
>
>    I've used a vector of colors (and a key) when there were only eight
> weather stations and the date range was three months. This was very
> effective in communicating the amounts and patterns.
>
>    I'm asking for ideas on how to best present these data in a scatter plot.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 00:53:19 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 15:53:19 -0700 (PDT)
Subject: [R] Scripting a repeating work flow
In-Reply-To: <0BB94E46-E77C-492D-860C-AB07EE3C5668@comcast.net>
References: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>
 <0BB94E46-E77C-492D-860C-AB07EE3C5668@comcast.net>
Message-ID: <alpine.LNX.2.20.1807191552310.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, David Winsemius wrote:

> https://markmail.org/search/?q=list%3Aorg.r-project.r-help+script+process+multiple+csv+files
> https://stackoverflow.com/questions/11433432/importing-multiple-csv-files-into-r
> https://www.google.com/search?q=use+r+to+process+multiple+csv+files&oq=use+r+to+process+multiple+csv+files

   Thanks, David. My search terms missed these.

Best regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 00:55:09 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 15:55:09 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <CAA99HCw4yCauPffuEndQ6vL48t506hcNv00H_-Xk+cB-gfjObA@mail.gmail.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
 <CAA99HCw4yCauPffuEndQ6vL48t506hcNv00H_-Xk+cB-gfjObA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807191554020.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, William Michels wrote:

> Hello, In addition to Duncan Mackay's excellent suggestion, I would
> recommend Bert Gunter's "stripless" package, for high-density Trellis-type
> conditioning plots. See the vignette for examples, and try out the code
> for "earthquake" and "barley" plots from the reference manual.
>
> https://CRAN.R-project.org/package=stripless
> https://cran.r-project.org/web/packages/stripless/vignettes/stripless_vignette.html

William,

   Very much appreciated. I'll certainly look closely at the package.

Best regards,

Rich


From t@vib@r @ending from gm@il@com  Fri Jul 20 12:15:23 2018
From: t@vib@r @ending from gm@il@com (Micha Silver)
Date: Fri, 20 Jul 2018 13:15:23 +0300
Subject: [R] scatter plot coloring problem
Message-ID: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>

Hello:

I have two data frames (subsetted from a larger one). I am plotting 
scatterplots with ggplot2 and coloring by different variables. When 
using one of the variables "Error" with one of the dataframes "conv_df" 
only a single color is displayed. All the other variables show colors as 
expected, and when applying the same ggplot() functions to the second 
dataframe, colors are correctly applied for all variables.

I'm scratching me head over this for some time. Maybe someone can see 
what I'm missing?

My repex is attached

Thanks

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From bgunter@4567 @ending from gm@il@com  Fri Jul 20 12:28:25 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 20 Jul 2018 03:28:25 -0700
Subject: [R] scatter plot coloring problem
In-Reply-To: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
Message-ID: <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>

Nothing attached. The mail server strips most attachments for security.

See the posting guide below and ?dput for how to include data.
+ We need your faulty code also, of course.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 20, 2018 at 3:15 AM, Micha Silver <tsvibar at gmail.com> wrote:

> Hello:
>
> I have two data frames (subsetted from a larger one). I am plotting
> scatterplots with ggplot2 and coloring by different variables. When using
> one of the variables "Error" with one of the dataframes "conv_df" only a
> single color is displayed. All the other variables show colors as expected,
> and when applying the same ggplot() functions to the second dataframe,
> colors are correctly applied for all variables.
>
> I'm scratching me head over this for some time. Maybe someone can see what
> I'm missing?
>
> My repex is attached
>
> Thanks
>
> --
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From t@vib@r @ending from gm@il@com  Fri Jul 20 13:01:33 2018
From: t@vib@r @ending from gm@il@com (Micha Silver)
Date: Fri, 20 Jul 2018 14:01:33 +0300
Subject: [R] scatter plot coloring problem
In-Reply-To: <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
 <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
Message-ID: <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>



On 07/20/2018 01:28 PM, Bert Gunter wrote:
> Nothing attached. The mail server strips most attachments for security.

Here is my repex, inline:

library(ggplot2)

conv_df <- structure(list(Adjustment = structure(c(1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 
1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????? 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L,
 ??????????????????????????????????????? 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 
1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????? 5L), .Label = c("Radar", 
"MeanFieldBias", "Multiplicative", "Mixed",
"ConditionalMerge"), class = "factor"), Struct = c("Bias only",
"Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error")), .Names = c("Adjustment",
"Struct", "Error"), row.names = c(1L, 3L, 4L, 5L, 6L, 11L, 13L,
14L, 15L, 16L, 21L, 23L, 24L, 25L, 26L, 31L, 33L, 34L, 35L, 36L,
41L, 43L, 44L, 45L, 46L, 51L, 53L, 54L, 55L, 56L, 61L, 63L, 64L,
65L, 66L, 71L, 73L, 74L, 75L, 76L, 81L, 83L, 84L, 85L, 86L, 91L,
93L, 94L, 95L, 96L, 101L, 103L, 104L, 105L, 106L, 111L, 113L,
114L, 115L, 116L, 121L, 123L, 124L, 125L, 126L, 131L, 133L, 134L,
135L, 136L, 141L, 143L, 144L, 145L, 146L, 151L, 153L, 154L, 155L,
156L, 161L, 163L, 164L, 165L, 166L, 171L, 173L, 174L, 175L, 176L,
181L, 183L, 184L, 185L, 186L, 191L, 193L, 194L, 195L, 196L, 201L,
203L, 204L, 205L, 206L, 211L, 213L, 214L, 215L, 216L, 221L, 223L,
224L, 225L, 226L, 231L, 233L, 234L, 235L, 236L, 241L, 243L, 244L,
245L, 246L, 251L, 253L, 254L, 255L, 256L, 261L, 263L, 264L, 265L,
266L), class = "data.frame")

strat_df <- structure(list(Adjustment = structure(c(1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????????????????? 5L, 1L, 2L, 3L, 4L, 
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L,
 ??????????????????????????????????????????????????? 1L, 2L, 3L, 4L, 5L, 
1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????????????????? 5L), .Label = 
c("Radar", "MeanFieldBias", "Multiplicative", "Mixed",
"ConditionalMerge"), class = "factor"), Struct = c("Bias only",
"Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error")), .Names = c("Adjustment",
"Struct", "Error"), row.names = c(2L, 7L, 8L, 9L, 10L, 12L, 17L,
18L, 19L, 20L, 22L, 27L, 28L, 29L, 30L, 32L, 37L, 38L, 39L, 40L,
42L, 47L, 48L, 49L, 50L, 52L, 57L, 58L, 59L, 60L, 62L, 67L, 68L,
69L, 70L, 72L, 77L, 78L, 79L, 80L, 82L, 87L, 88L, 89L, 90L, 92L,
97L, 98L, 99L, 100L, 102L, 107L, 108L, 109L, 110L, 112L, 117L,
118L, 119L, 120L, 122L, 127L, 128L, 129L, 130L, 132L, 137L, 138L,
139L, 140L, 142L, 147L, 148L, 149L, 150L, 152L, 157L, 158L, 159L,
160L, 162L, 167L, 168L, 169L, 170L, 172L, 177L, 178L, 179L, 180L,
182L, 187L, 188L, 189L, 190L, 192L, 197L, 198L, 199L, 200L, 202L,
207L, 208L, 209L, 210L, 212L, 217L, 218L, 219L, 220L, 222L, 227L,
228L, 229L, 230L, 232L, 237L, 238L, 239L, 240L, 242L, 247L, 248L,
249L, 250L, 252L, 257L, 258L, 259L, 260L, 262L, 267L, 268L, 269L,
270L), class = "data.frame")

ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct, shape=Adjustment), size=6)

ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error, shape=Adjustment), size=6)

ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct, shape=Adjustment), size=6)

ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error, shape=Adjustment), size=6)


>
> See the posting guide below and ?dput for how to include data.
> + We need your faulty code also, of course.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Jul 20, 2018 at 3:15 AM, Micha Silver <tsvibar at gmail.com 
> <mailto:tsvibar at gmail.com>> wrote:
>
>     Hello:
>
>     I have two data frames (subsetted from a larger one). I am
>     plotting scatterplots with ggplot2 and coloring by different
>     variables. When using one of the variables "Error" with one of the
>     dataframes "conv_df" only a single color is displayed. All the
>     other variables show colors as expected, and when applying the
>     same ggplot() functions to the second dataframe, colors are
>     correctly applied for all variables.
>
>     I'm scratching me head over this for some time. Maybe someone can
>     see what I'm missing?
>
>     My repex is attached
>
>     Thanks
>
>     -- 
>     Micha Silver
>     Ben Gurion Univ.
>     Sde Boker, Remote Sensing Lab
>     cell: +972-523-665918
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From t@vib@r @ending from gm@il@com  Fri Jul 20 13:27:36 2018
From: t@vib@r @ending from gm@il@com (Micha Silver)
Date: Fri, 20 Jul 2018 14:27:36 +0300
Subject: [R] scatter plot coloring problem
In-Reply-To: <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
 <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
 <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>
Message-ID: <073a0ba1-f267-b7f2-7fa5-83c237e44db1@gmail.com>



On 07/20/2018 02:01 PM, Micha Silver wrote:
>
>
> On 07/20/2018 01:28 PM, Bert Gunter wrote:
>> Nothing attached. The mail server strips most attachments for security.

Here is a (slightly shorter) repex.
The fourth plot shows the problem. The first three are as expected.

library(ggplot2)

strat_df <- structure(list(Slope = c(1.15639473681994, 0.972278300619073,
 ???????????????????????????????????? 1.14313365332712, 
1.14399372216612, 1.22529134790727, 2.14326711679831,
 ???????????????????????????????????? 0.54859156211142, 
1.17046713623601, 1.17453878322687, 3.31323770780669,
 ???????????????????????????????????? 0.966673750291528, 
0.746319725592914, 1.02480114419885, 1.0229752524756,
 ???????????????????????????????????? 1.00132723720128, 
1.15639473681994, 0.972278300619073, 1.14313365332712,
 ???????????????????????????????????? 1.14399372216612, 
1.22529134790727, 2.14326711679831, 0.54859156211142,
 ???????????????????????????????????? 1.17046713623601, 
1.17453878322687, 3.31323770780669, 0.966673750291528,
 ???????????????????????????????????? 0.746319725592914, 
1.02480114419885, 1.0229752524756, 1.00132723720128,
 ???????????????????????????????????? 1.15639473681994, 
0.972278300619073, 1.14313365332712, 1.14399372216612,
 ???????????????????????????????????? 1.22529134790727, 
2.14326711679831, 0.54859156211142, 1.17046713623601,
 ???????????????????????????????????? 1.17453878322687, 
3.31323770780669, 0.966673750291528, 0.746319725592914,
 ???????????????????????????????????? 1.02480114419885, 1.0229752524756, 
1.00132723720128, 1.00564012971235,
 ???????????????????????????????????? 0.781822304249351, 
0.793232303666035, 0.798538338102623, 1.20657643535607,
 ???????????????????????????????????? 2.16318241002351, 
1.42268702026443, 0.812412401599228, 0.817089629984966,
 ???????????????????????????????????? 3.27413789688355, 
0.840735716836696, 0.629583577106973, 0.710708013029288,
 ???????????????????????????????????? 0.714002133616219, 
0.985501434987176, 1.03494070727933, 0.956962513783496,
 ???????????????????????????????????? 0.793549829222589, 
0.798851646709461, 1.20660885706037, 2.18674952848921,
 ???????????????????????????????????? 1.5634217520085, 0.81273050967827, 
0.817407079251797, 3.27417031858785,
 ???????????????????????????????????? 0.877344267863596, 
0.848664941338144, 0.710978765510023, 0.714268901361411,
 ???????????????????????????????????? 0.985533856691474, 
1.03983096388345, 0.985084623809766, 0.794138608594684,
 ???????????????????????????????????? 0.79943259180892, 
1.20665856218731, 2.21336885559571, 1.72189603514386,
 ???????????????????????????????????? 0.813327118056704, 
0.818002445250057, 3.27422002371479, 0.877473770321168,
 ???????????????????????????????????? 0.848389484199237, 
0.711483989718558, 0.714766443910276, 0.985583561818414
), Intercept = c(-1.0892464119326, 0.246565490954958, -1.1639008288321,
 ???????????????? -1.17146025612969, -1.93566050996642, 
-3.96706179209372, 3.9202695728101,
 ???????????????? -1.04771345550341, -1.07809518302298, 
-19.7820283549024, 0.36822137463493,
 ???????????????? 2.207658818211, -0.016876438597312, 
-0.00842619567899302, 0.0306144651329568,
 ???????????????? -1.0892464119326, 0.246565490954958, -1.1639008288321, 
-1.17146025612969,
 ???????????????? -1.93566050996642, -3.96706179209372, 3.9202695728101, 
-1.04771345550341,
 ???????????????? -1.07809518302298, -19.7820283549024, 
0.36822137463493, 2.207658818211,
 ???????????????? -0.016876438597312, -0.00842619567899302, 
0.0306144651329568,
 ???????????????? -1.0892464119326, 0.246565490954958, -1.1639008288321, 
-1.17146025612969,
 ???????????????? -1.93566050996642, -3.96706179209372, 3.9202695728101, 
-1.04771345550341,
 ???????????????? -1.07809518302298, -19.7820283549024, 
0.36822137463493, 2.207658818211,
 ???????????????? -0.016876438597312, -0.00842619567899302, 
0.0306144651329568,
 ???????????????? -1.42588814587741, -0.0938807577163176, 
-0.760427987439108, -0.802681471353857,
 ???????????????? -4.38731629113287, -4.72258266663199, 
1.08443985346667, -0.679055757307681,
 ???????????????? -0.713928732007598, -22.2121480319997, 
-0.187477151457156, 1.28512191810652,
 ???????????????? 0.0386762170827232, 0.00928219285158222, 
-2.45430083552569, -1.5052623193495,
 ???????????????? -0.571094020563348, -0.760898951384971, 
-0.80312079180565, -4.38543778472072,
 ???????????????? -4.74043340113669, 0.976337655364814, 
-0.679498378418568, -0.714366826235178,
 ???????????????? -22.2102695255875, -0.264069816907669, 
0.823783304969757, 0.0386132206604378,
 ???????????????? 0.00924930329540931, -2.45242232911355, 
-1.5204762452006, -0.664489263100851,
 ???????????????? -0.761704010560802, -0.803866601426402, 
-4.38177522849324, -4.78366916314869,
 ???????????????? 0.714779631860822, -0.68026224065537, 
-0.715122068793879, -22.20660696936,
 ???????????????? -0.262931522643713, 0.827039881514761, 
0.0385397097353969, 0.00923344703169212,
 ???????????????? -2.44875977288606), Struct = c("Bias only", "Bias 
only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"Bias only", "Bias only", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Lognormal 
error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct."), 
Error = c("Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error"
 ??????????????????????????????????????????????? )), .Names = c("Slope", 
"Intercept", "Struct", "Error"), row.names = c(2L,
7L, 8L, 9L, 10L, 12L, 17L, 18L, 19L, 20L, 22L, 27L, 28L, 29L,
30L, 32L, 37L, 38L, 39L, 40L, 42L, 47L, 48L, 49L, 50L, 52L, 57L,
58L, 59L, 60L, 62L, 67L, 68L, 69L, 70L, 72L, 77L, 78L, 79L, 80L,
82L, 87L, 88L, 89L, 90L, 92L, 97L, 98L, 99L, 100L, 102L, 107L,
108L, 109L, 110L, 112L, 117L, 118L, 119L, 120L, 122L, 127L, 128L,
129L, 130L, 132L, 137L, 138L, 139L, 140L, 142L, 147L, 148L, 149L,
150L, 152L, 157L, 158L, 159L, 160L, 162L, 167L, 168L, 169L, 170L,
172L, 177L, 178L, 179L, 180L), class = "data.frame")
conv_df <- structure(list(Slope = c(1.04807118675076, 0.998948448847309,
 ??????????????????????????????????? 0.999431048648743, 
1.06271129629311, 1.07572617384751, 2.22760090861169,
 ??????????????????????????????????? 0.932482182264868, 
1.02936746325801, 2.52988042582817, 2.95633562179131,
 ??????????????????????????????????? 18.8227507300988, 
0.974588681842621, 108.07393074932, 0.870832606501646,
 ??????????????????????????????????? 1.00567956715787, 1.04807118675076, 
0.998948448847309, 0.999431048648743,
 ??????????????????????????????????? 1.06271129629311, 1.07572617384751, 
2.22760090861169, 0.932482182264868,
 ??????????????????????????????????? 1.02936746325801, 2.52988042582817, 
2.95633562179131, 18.8227507300988,
 ??????????????????????????????????? 0.974588681842621, 108.07393074932, 
0.870832606501646, 1.00567956715787,
 ??????????????????????????????????? 1.04807118675076, 
0.998948448847309, 0.999431048648743, 1.06271129629311,
 ??????????????????????????????????? 1.07572617384751, 2.22760090861169, 
0.932482182264868, 1.02936746325801,
 ??????????????????????????????????? 2.52988042582817, 2.95633562179131, 
18.8227507300988, 0.974588681842621,
 ??????????????????????????????????? 108.07393074932, 0.870832606501646, 
1.00567956715787, 0.938306957617447,
 ??????????????????????????????????? 0.696202687574185, 
0.698287792550519, 1.01157976748338, 1.07216134522869,
 ??????????????????????????????????? 2.11775044458303, 
0.658564756192898, 0.718936009019651, 2.46328731519796,
 ??????????????????????????????????? 2.94817482855984, 13.4010203977042, 
0.758075017209242, 75.8087725102359,
 ??????????????????????????????????? 0.825432059460383, 
1.00237002354864, 0.93840246618556, 0.696484580425202,
 ??????????????????????????????????? 0.698549805163105, 
1.01161728893021, 1.07215296972693, 2.11785160868381,
 ??????????????????????????????????? 0.658846969311393, 
0.719217656820784, 2.46333881438479, 2.94816645305808,
 ??????????????????????????????????? 13.4028764261544, 
0.758261665458076, 75.8196908351967, 0.82547163245355,
 ??????????????????????????????????? 1.00236164804689, 
0.938596807939808, 0.697064148960971, 0.699062697365857,
 ??????????????????????????????????? 1.01169996923602, 1.07214387920809, 
2.11805571501552, 0.659427992302351,
 ??????????????????????????????????? 0.719759915668507, 
2.46344926105519, 2.94815736253924, 13.4060642247861,
 ??????????????????????????????????? 0.758655662542348, 
75.8383487496718, 0.825555603203494, 1.00235255752804
), Intercept = c(-0.017716276271862, 0.000961091319158938, 
-0.000703510322277703,
 ???????????????? -0.00845866525088005, -0.0966678762281092, 
-0.389386368120609,
 ???????????????? 0.068730059320282, 0.0367676804603267, 
-0.0134454494180847, -2.61898714802878,
 ???????????????? -7.30136425060206, -0.21274280699377, 
-43.1291289782452, -0.125688969456484,
 ???????????????? -0.307472718728007, -0.017716276271862, 
0.000961091319158938,
 ???????????????? -0.000703510322277703, -0.00845866525088005, 
-0.0966678762281092,
 ???????????????? -0.389386368120609, 0.068730059320282, 
0.0367676804603267, -0.0134454494180847,
 ???????????????? -2.61898714802878, -7.30136425060206, 
-0.21274280699377, -43.1291289782452,
 ???????????????? -0.125688969456484, -0.307472718728007, 
-0.017716276271862, 0.000961091319158938,
 ???????????????? -0.000703510322277703, -0.00845866525088005, 
-0.0966678762281092,
 ???????????????? -0.389386368120609, 0.068730059320282, 
0.0367676804603267, -0.0134454494180847,
 ???????????????? -2.61898714802878, -7.30136425060206, 
-0.21274280699377, -43.1291289782452,
 ???????????????? -0.125688969456484, -0.307472718728007, 
-0.0859314660447012,
 ???????????????? 0.0135310033957625, -3.43619764283222e-05, 
-0.0523622551444108,
 ???????????????? -0.475294485394066, -0.460272581935994, 
0.0625183970346825, 0.0262518388075903,
 ???????????????? -0.0839509467307793, -2.95707142967006, 
-5.52875677718304, -0.152998423411686,
 ???????????????? -32.1368671911073, -0.164063261306885, 
-0.685459757083477, -0.0858163634696177,
 ???????????????? 0.01352935620949, 9.46328483051025e-05, 
-0.052203322505647, -0.47489015022079,
 ???????????????? -0.460135002763724, 0.0626429365104076, 
0.02640499766902, -0.0838075052075929,
 ???????????????? -2.95666709449679, -5.52852300483326, 
-0.153159000797531, -32.135862357057,
 ???????????????? -0.163909219046001, -0.685055421910201, 
-0.0856060516008676,
 ???????????????? 0.0135479894875152, 0.000302270025863519, 
-0.0519314642867551,
 ???????????????? -0.474126407682765, -0.45988984866136, 
0.0628609678242435, 0.026651390571036,
 ???????????????? -0.0835647473472818, -2.95590335195876, 
-5.52851009407545, -0.153425312176928,
 ???????????????? -32.1365449540903, -0.163646588624356, 
-0.684291679372176), Struct = c("Bias only",
"Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error")), .Names = c("Slope", "Intercept", "Struct",
"Error"), row.names = c(1L, 3L, 4L, 5L, 6L, 11L, 13L, 14L, 15L,
16L, 21L, 23L, 24L, 25L, 26L, 31L, 33L, 34L, 35L, 36L, 41L, 43L,
44L, 45L, 46L, 51L, 53L, 54L, 55L, 56L, 61L, 63L, 64L, 65L, 66L,
71L, 73L, 74L, 75L, 76L, 81L, 83L, 84L, 85L, 86L, 91L, 93L, 94L,
95L, 96L, 101L, 103L, 104L, 105L, 106L, 111L, 113L, 114L, 115L,
116L, 121L, 123L, 124L, 125L, 126L, 131L, 133L, 134L, 135L, 136L,
141L, 143L, 144L, 145L, 146L, 151L, 153L, 154L, 155L, 156L, 161L,
163L, 164L, 165L, 166L, 171L, 173L, 174L, 175L, 176L), class = "data.frame")


pl.strat.1 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct),size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

pl.strat.2 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error), size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

pl.conv.1 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct), size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

pl.conv.2 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error), size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

print(pl.strat.1)
print(pl.strat.2)
print(pl.conv.1)
print(pl.conv.2)


>
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From petr@pik@l @ending from prechez@@cz  Fri Jul 20 14:16:04 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 20 Jul 2018 12:16:04 +0000
Subject: [R] scatter plot coloring problem
In-Reply-To: <073a0ba1-f267-b7f2-7fa5-83c237e44db1@gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
 <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
 <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>
 <073a0ba1-f267-b7f2-7fa5-83c237e44db1@gmail.com>
Message-ID: <49b19ebf86a84211ba1f1aa01916756e@SRVEXCHCM1302.precheza.cz>

Hi

Values in conv_df are almost same for each Error level

> aggregate(conv_df$Intercept, list(conv_df$Error), mean)
         Group.1         x
1 High CML error -3.226313
2  Low CML error -3.226536
3  Med CML error -3.226422
> aggregate(conv_df$Slope, list(conv_df$Error), mean)
         Group.1        x
1 High CML error 8.325558
2  Low CML error 8.324242
3  Med CML error 8.324721
> boxplot(split(conv_df$Slope, conv_df$Error))
> boxplot(split(conv_df$Intercept, conv_df$Error))
>

so points in ggplot are overplotted and only colour for last plotted level is visible.

Cheers
Petr

> On 07/20/2018 02:01 PM, Micha Silver wrote:
> >
> >
> > On 07/20/2018 01:28 PM, Bert Gunter wrote:
> >> Nothing attached. The mail server strips most attachments for security.
>
> Here is a (slightly shorter) repex.
> The fourth plot shows the problem. The first three are as expected.
>
> library(ggplot2)
>
> strat_df <- structure(list(Slope = c(1.15639473681994, 0.972278300619073,
>                                       1.14313365332712,
> 1.14399372216612, 1.22529134790727, 2.14326711679831,
>                                       0.54859156211142,
> 1.17046713623601, 1.17453878322687, 3.31323770780669,
>                                       0.966673750291528,
> 0.746319725592914, 1.02480114419885, 1.0229752524756,
>                                       1.00132723720128,
> 1.15639473681994, 0.972278300619073, 1.14313365332712,
>                                       1.14399372216612,
> 1.22529134790727, 2.14326711679831, 0.54859156211142,
>                                       1.17046713623601,
> 1.17453878322687, 3.31323770780669, 0.966673750291528,
>                                       0.746319725592914,
> 1.02480114419885, 1.0229752524756, 1.00132723720128,
>                                       1.15639473681994,
> 0.972278300619073, 1.14313365332712, 1.14399372216612,
>                                       1.22529134790727,
> 2.14326711679831, 0.54859156211142, 1.17046713623601,
>                                       1.17453878322687,
> 3.31323770780669, 0.966673750291528, 0.746319725592914,
>                                       1.02480114419885, 1.0229752524756,
> 1.00132723720128, 1.00564012971235,
>                                       0.781822304249351,
> 0.793232303666035, 0.798538338102623, 1.20657643535607,
>                                       2.16318241002351,
> 1.42268702026443, 0.812412401599228, 0.817089629984966,
>                                       3.27413789688355,
> 0.840735716836696, 0.629583577106973, 0.710708013029288,
>                                       0.714002133616219,
> 0.985501434987176, 1.03494070727933, 0.956962513783496,
>                                       0.793549829222589,
> 0.798851646709461, 1.20660885706037, 2.18674952848921,
>                                       1.5634217520085, 0.81273050967827,
> 0.817407079251797, 3.27417031858785,
>                                       0.877344267863596,
> 0.848664941338144, 0.710978765510023, 0.714268901361411,
>                                       0.985533856691474,
> 1.03983096388345, 0.985084623809766, 0.794138608594684,
>                                       0.79943259180892,
> 1.20665856218731, 2.21336885559571, 1.72189603514386,
>                                       0.813327118056704,
> 0.818002445250057, 3.27422002371479, 0.877473770321168,
>                                       0.848389484199237,
> 0.711483989718558, 0.714766443910276, 0.985583561818414
> ), Intercept = c(-1.0892464119326, 0.246565490954958, -1.1639008288321,
>                   -1.17146025612969, -1.93566050996642,
> -3.96706179209372, 3.9202695728101,
>                   -1.04771345550341, -1.07809518302298,
> -19.7820283549024, 0.36822137463493,
>                   2.207658818211, -0.016876438597312,
> -0.00842619567899302, 0.0306144651329568,
>                   -1.0892464119326, 0.246565490954958, -1.1639008288321,
> -1.17146025612969,
>                   -1.93566050996642, -3.96706179209372, 3.9202695728101,
> -1.04771345550341,
>                   -1.07809518302298, -19.7820283549024,
> 0.36822137463493, 2.207658818211,
>                   -0.016876438597312, -0.00842619567899302,
> 0.0306144651329568,
>                   -1.0892464119326, 0.246565490954958, -1.1639008288321,
> -1.17146025612969,
>                   -1.93566050996642, -3.96706179209372, 3.9202695728101,
> -1.04771345550341,
>                   -1.07809518302298, -19.7820283549024,
> 0.36822137463493, 2.207658818211,
>                   -0.016876438597312, -0.00842619567899302,
> 0.0306144651329568,
>                   -1.42588814587741, -0.0938807577163176,
> -0.760427987439108, -0.802681471353857,
>                   -4.38731629113287, -4.72258266663199,
> 1.08443985346667, -0.679055757307681,
>                   -0.713928732007598, -22.2121480319997,
> -0.187477151457156, 1.28512191810652,
>                   0.0386762170827232, 0.00928219285158222,
> -2.45430083552569, -1.5052623193495,
>                   -0.571094020563348, -0.760898951384971,
> -0.80312079180565, -4.38543778472072,
>                   -4.74043340113669, 0.976337655364814,
> -0.679498378418568, -0.714366826235178,
>                   -22.2102695255875, -0.264069816907669,
> 0.823783304969757, 0.0386132206604378,
>                   0.00924930329540931, -2.45242232911355,
> -1.5204762452006, -0.664489263100851,
>                   -0.761704010560802, -0.803866601426402,
> -4.38177522849324, -4.78366916314869,
>                   0.714779631860822, -0.68026224065537,
> -0.715122068793879, -22.20660696936,
>                   -0.262931522643713, 0.827039881514761,
> 0.0385397097353969, 0.00923344703169212,
>                   -2.44875977288606), Struct = c("Bias only", "Bias
> only", "Bias only",
>                                                  "Bias only", "Bias
> only", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only",
>                                                  "Bias only", "Bias
> only", "Bias only", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "Bias only", "Bias
> only", "Bias only", "Bias only", "Bias only",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "Bias only", "Bias only", "Bias only", "Bias only",
>                                                  "Bias only", "Lognormal
> error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only",
>                                                  "Bias only", "Bias
> only", "Bias only", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "Bias only", "Bias
> only", "Bias only", "Bias only", "Bias only",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct."),
> Error = c("Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error"
>                                                  )), .Names = c("Slope",
> "Intercept", "Struct", "Error"), row.names = c(2L,
> 7L, 8L, 9L, 10L, 12L, 17L, 18L, 19L, 20L, 22L, 27L, 28L, 29L,
> 30L, 32L, 37L, 38L, 39L, 40L, 42L, 47L, 48L, 49L, 50L, 52L, 57L,
> 58L, 59L, 60L, 62L, 67L, 68L, 69L, 70L, 72L, 77L, 78L, 79L, 80L,
> 82L, 87L, 88L, 89L, 90L, 92L, 97L, 98L, 99L, 100L, 102L, 107L,
> 108L, 109L, 110L, 112L, 117L, 118L, 119L, 120L, 122L, 127L, 128L,
> 129L, 130L, 132L, 137L, 138L, 139L, 140L, 142L, 147L, 148L, 149L,
> 150L, 152L, 157L, 158L, 159L, 160L, 162L, 167L, 168L, 169L, 170L,
> 172L, 177L, 178L, 179L, 180L), class = "data.frame")
> conv_df <- structure(list(Slope = c(1.04807118675076, 0.998948448847309,
>                                      0.999431048648743,
> 1.06271129629311, 1.07572617384751, 2.22760090861169,
>                                      0.932482182264868,
> 1.02936746325801, 2.52988042582817, 2.95633562179131,
>                                      18.8227507300988,
> 0.974588681842621, 108.07393074932, 0.870832606501646,
>                                      1.00567956715787, 1.04807118675076,
> 0.998948448847309, 0.999431048648743,
>                                      1.06271129629311, 1.07572617384751,
> 2.22760090861169, 0.932482182264868,
>                                      1.02936746325801, 2.52988042582817,
> 2.95633562179131, 18.8227507300988,
>                                      0.974588681842621, 108.07393074932,
> 0.870832606501646, 1.00567956715787,
>                                      1.04807118675076,
> 0.998948448847309, 0.999431048648743, 1.06271129629311,
>                                      1.07572617384751, 2.22760090861169,
> 0.932482182264868, 1.02936746325801,
>                                      2.52988042582817, 2.95633562179131,
> 18.8227507300988, 0.974588681842621,
>                                      108.07393074932, 0.870832606501646,
> 1.00567956715787, 0.938306957617447,
>                                      0.696202687574185,
> 0.698287792550519, 1.01157976748338, 1.07216134522869,
>                                      2.11775044458303,
> 0.658564756192898, 0.718936009019651, 2.46328731519796,
>                                      2.94817482855984, 13.4010203977042,
> 0.758075017209242, 75.8087725102359,
>                                      0.825432059460383,
> 1.00237002354864, 0.93840246618556, 0.696484580425202,
>                                      0.698549805163105,
> 1.01161728893021, 1.07215296972693, 2.11785160868381,
>                                      0.658846969311393,
> 0.719217656820784, 2.46333881438479, 2.94816645305808,
>                                      13.4028764261544,
> 0.758261665458076, 75.8196908351967, 0.82547163245355,
>                                      1.00236164804689,
> 0.938596807939808, 0.697064148960971, 0.699062697365857,
>                                      1.01169996923602, 1.07214387920809,
> 2.11805571501552, 0.659427992302351,
>                                      0.719759915668507,
> 2.46344926105519, 2.94815736253924, 13.4060642247861,
>                                      0.758655662542348,
> 75.8383487496718, 0.825555603203494, 1.00235255752804
> ), Intercept = c(-0.017716276271862, 0.000961091319158938,
> -0.000703510322277703,
>                   -0.00845866525088005, -0.0966678762281092,
> -0.389386368120609,
>                   0.068730059320282, 0.0367676804603267,
> -0.0134454494180847, -2.61898714802878,
>                   -7.30136425060206, -0.21274280699377,
> -43.1291289782452, -0.125688969456484,
>                   -0.307472718728007, -0.017716276271862,
> 0.000961091319158938,
>                   -0.000703510322277703, -0.00845866525088005,
> -0.0966678762281092,
>                   -0.389386368120609, 0.068730059320282,
> 0.0367676804603267, -0.0134454494180847,
>                   -2.61898714802878, -7.30136425060206,
> -0.21274280699377, -43.1291289782452,
>                   -0.125688969456484, -0.307472718728007,
> -0.017716276271862, 0.000961091319158938,
>                   -0.000703510322277703, -0.00845866525088005,
> -0.0966678762281092,
>                   -0.389386368120609, 0.068730059320282,
> 0.0367676804603267, -0.0134454494180847,
>                   -2.61898714802878, -7.30136425060206,
> -0.21274280699377, -43.1291289782452,
>                   -0.125688969456484, -0.307472718728007,
> -0.0859314660447012,
>                   0.0135310033957625, -3.43619764283222e-05,
> -0.0523622551444108,
>                   -0.475294485394066, -0.460272581935994,
> 0.0625183970346825, 0.0262518388075903,
>                   -0.0839509467307793, -2.95707142967006,
> -5.52875677718304, -0.152998423411686,
>                   -32.1368671911073, -0.164063261306885,
> -0.685459757083477, -0.0858163634696177,
>                   0.01352935620949, 9.46328483051025e-05,
> -0.052203322505647, -0.47489015022079,
>                   -0.460135002763724, 0.0626429365104076,
> 0.02640499766902, -0.0838075052075929,
>                   -2.95666709449679, -5.52852300483326,
> -0.153159000797531, -32.135862357057,
>                   -0.163909219046001, -0.685055421910201,
> -0.0856060516008676,
>                   0.0135479894875152, 0.000302270025863519,
> -0.0519314642867551,
>                   -0.474126407682765, -0.45988984866136,
> 0.0628609678242435, 0.026651390571036,
>                   -0.0835647473472818, -2.95590335195876,
> -5.52851009407545, -0.153425312176928,
>                   -32.1365449540903, -0.163646588624356,
> -0.684291679372176), Struct = c("Bias only",
> "Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
> "Bias only", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
> "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
> "Bias only", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error")), .Names = c("Slope", "Intercept", "Struct",
> "Error"), row.names = c(1L, 3L, 4L, 5L, 6L, 11L, 13L, 14L, 15L,
> 16L, 21L, 23L, 24L, 25L, 26L, 31L, 33L, 34L, 35L, 36L, 41L, 43L,
> 44L, 45L, 46L, 51L, 53L, 54L, 55L, 56L, 61L, 63L, 64L, 65L, 66L,
> 71L, 73L, 74L, 75L, 76L, 81L, 83L, 84L, 85L, 86L, 91L, 93L, 94L,
> 95L, 96L, 101L, 103L, 104L, 105L, 106L, 111L, 113L, 114L, 115L,
> 116L, 121L, 123L, 124L, 125L, 126L, 131L, 133L, 134L, 135L, 136L,
> 141L, 143L, 144L, 145L, 146L, 151L, 153L, 154L, 155L, 156L, 161L,
> 163L, 164L, 165L, 166L, 171L, 173L, 174L, 175L, 176L), class = "data.frame")
>
>
> pl.strat.1 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Struct),size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> pl.strat.2 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Error), size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> pl.conv.1 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Struct), size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> pl.conv.2 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Error), size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> print(pl.strat.1)
> print(pl.strat.2)
> print(pl.conv.1)
> print(pl.conv.2)
>
>
> >
> >
>
> --
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 14:36:20 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 05:36:20 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <000101d41fd0$d83249e0$8896dda0$@bigpond.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
 <alpine.LNX.2.20.1807190714460.15936@salmo.appl-ecosys.com>
 <000101d41fd0$d83249e0$8896dda0$@bigpond.com>
Message-ID: <alpine.LNX.2.20.1807200535070.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, Duncan Mackay wrote:

> If you have to make several plots you can subset your data

Duncan,

   That's what I thought I should do.

> xyplot(... data = subset(x, condition), ...)
> or
> XYn <- xyplot(... data = x[row1:row2, ], ...)
> in a loop
>
> have a look a ? print.trellis
>
> if you want to put several on a page
>
> if you need strips on left and top see
> ?latticeExtra:::useOuterStrips

Thanks again,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 19:43:55 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 10:43:55 -0700 (PDT)
Subject: [R] Locating data source error in large file
Message-ID: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>

   The structure of the dataframe is

str(wy2016)
'data.frame':	8784 obs. of  4 variables:
  $ date  : chr  "2015-10-01" "2015-10-01" "2015-10-01" "2015-10-01" ...
  $ time  : chr  "00:00" "01:00" "02:00" "03:00" ...
  $ elev  : num  90.7 90.7 90.7 90.7 90.7 ...
  $ myDate: Date, format: "2015-10-01" "2015-10-01" ...

   The command and results on this dataframe is:
wy2016$myTime <- as.POSIXct(paste(wy2016$date, wy2016$time))
Error in as.POSIXlt.character(x, tz, ...) :
   character string is not in a standard unambiguous format

   Data for other water years do not throw this error. How can I identify
which row(s) among the 8784 have a date or time formatting error?

Rich


From wdunl@p @ending from tibco@com  Fri Jul 20 20:21:54 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 20 Jul 2018 11:21:54 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>

The problem occurs because no commonly used format works on
all your date strings.  If you give as.POSIXlt the format you want to
use then items that don't match the format will be treated as NA's.
Use is.na() to find them.

> d <- c("2017-12-25", "2018-01-01", "10/31/2018")
> as.POSIXlt(d)
Error in as.POSIXlt.character(d) :
  character string is not in a standard unambiguous format
> as.POSIXlt(d, format="%Y-%m-%d")
[1] "2017-12-25 PST" "2018-01-01 PST" NA
> as.POSIXlt(d, format="%m/%d/%Y")
[1] NA               NA               "2018-10-31 PDT"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 10:43 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   The structure of the dataframe is
>
> str(wy2016)
> 'data.frame':   8784 obs. of  4 variables:
>  $ date  : chr  "2015-10-01" "2015-10-01" "2015-10-01" "2015-10-01" ...
>  $ time  : chr  "00:00" "01:00" "02:00" "03:00" ...
>  $ elev  : num  90.7 90.7 90.7 90.7 90.7 ...
>  $ myDate: Date, format: "2015-10-01" "2015-10-01" ...
>
>   The command and results on this dataframe is:
> wy2016$myTime <- as.POSIXct(paste(wy2016$date, wy2016$time))
> Error in as.POSIXlt.character(x, tz, ...) :
>   character string is not in a standard unambiguous format
>
>   Data for other water years do not throw this error. How can I identify
> which row(s) among the 8784 have a date or time formatting error?
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 20:58:19 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 11:58:19 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> The problem occurs because no commonly used format works on all your date
> strings. If you give as.POSIXlt the format you want to use then items that
> don't match the format will be treated as NA's. Use is.na() to find them.

Bill,

   No NAs found using both is.na() and scrolling through the source file.
That's why I asked for help: I saw nothing different in the dates or times.

Regards,

Rich


From ericjberger @ending from gm@il@com  Fri Jul 20 21:18:48 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Fri, 20 Jul 2018 22:18:48 +0300
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
Message-ID: <CAGgJW76WDsP3oYXj=mKpdKtoKMgLAuz9ztcm2fp6GUgGjPEaqg@mail.gmail.com>

Hi Rich,
This may not be the most efficient but it will identify the offenders.

>  foo <-  paste(wy2016$date, wy2016$time))
> uu <- sapply(1:length(foo),
             function(i) { a <- try(as.POSIXct(foo[i]),silent=TRUE)
             "POSIXct" %in% class(a) })
> which(!uu)

HTH,
Eric



On Fri, Jul 20, 2018 at 9:58 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, William Dunlap wrote:
>
> The problem occurs because no commonly used format works on all your date
>> strings. If you give as.POSIXlt the format you want to use then items that
>> don't match the format will be treated as NA's. Use is.na() to find them.
>>
>
> Bill,
>
>   No NAs found using both is.na() and scrolling through the source file.
> That's why I asked for help: I saw nothing different in the dates or times.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Jul 20 21:59:40 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 20 Jul 2018 12:59:40 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>

Which format did you use when you used is.na on the output of
   as.POSIXlt(strings, format=someFormat)
and found none?  Did the resulting dates look OK?  Perhaps
all is well.

Note the the common American format month/day/year is not
one that is tested when you don't supply a format - xx/yy/zzzz
is treated as year/month/day (and it changes the time zone,
presumable because US/Pacific time was not used in the year
10 CE).
  > as.POSIXlt("10/7/1962")
  [1] "0010-07-19 LMT"
  > as.POSIXlt("3/17/1962")
  Error in as.POSIXlt.character("3/17/1962") :
    character string is not in a standard unambiguous format


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 11:58 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, William Dunlap wrote:
>
> The problem occurs because no commonly used format works on all your date
>> strings. If you give as.POSIXlt the format you want to use then items that
>> don't match the format will be treated as NA's. Use is.na() to find them.
>>
>
> Bill,
>
>   No NAs found using both is.na() and scrolling through the source file.
> That's why I asked for help: I saw nothing different in the dates or times.
>
> Regards,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Fri Jul 20 22:01:51 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 20 Jul 2018 13:01:51 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
Message-ID: <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>


> On Jul 20, 2018, at 11:58 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Fri, 20 Jul 2018, William Dunlap wrote:
> 
>> The problem occurs because no commonly used format works on all your date
>> strings. If you give as.POSIXlt the format you want to use then items that
>> don't match the format will be treated as NA's. Use is.na() to find them.
> 
> Bill,
> 
>  No NAs found using both is.na() and scrolling through the source file.
> That's why I asked for help: I saw nothing different in the dates or times.
> 
> Regards,
> 
> Rich

I don't think you read Bill's message properly. He was not saying that there were NA's; he was telling you to use a format specification in your as.POSIXct call and the the result of that call would have NA's.

wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format= "%Y-%m-%d %H:%M") )

David.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 22:24:49 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:24:49 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> Which format did you use when you used is.na on the output of
>   as.POSIXlt(strings, format=someFormat)
> and found none?  Did the resulting dates look OK?  Perhaps
> all is well.

Bill,

   All dates here are kept as yyyy-mm-dd.

   And each dataframe row has this format:
2015-10-01,00:00,90.6689
2015-10-01,01:00,90.6506
2015-10-01,02:00,90.6719
2015-10-01,03:00,90.6506

Thanks,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 22:30:45 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:30:45 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
Message-ID: <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, David Winsemius wrote:

> I don't think you read Bill's message properly.

David,

   Obviously not.

> He was not saying that there were NA's; he was telling you to use a format
> specification in your as.POSIXct call and the the result of that call
> would have NA's.
>
> wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format= "%Y-%m-%d %H:%M") )

   Thank you. This found 24 TRUEs; now to find them in the file.

Thanks,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 22:31:46 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:31:46 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAGgJW76WDsP3oYXj=mKpdKtoKMgLAuz9ztcm2fp6GUgGjPEaqg@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAGgJW76WDsP3oYXj=mKpdKtoKMgLAuz9ztcm2fp6GUgGjPEaqg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201331030.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, Eric Berger wrote:

> This may not be the most efficient but it will identify the offenders.
>
>>  foo <-  paste(wy2016$date, wy2016$time))
>> uu <- sapply(1:length(foo),
>             function(i) { a <- try(as.POSIXct(foo[i]),silent=TRUE)
>             "POSIXct" %in% class(a) })
>> which(!uu)

Eric,

   Thank you. Now I know there are NAs there this should help me find them.

Regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 22:42:28 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:42:28 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
Message-ID: <alpine.LNX.2.20.1807201341090.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, David Winsemius wrote:

> wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format=
> "%Y-%m-%d %H:%M") )

David/Bill/Eric:

   Thank you all. I found the typos which covered a single day toward the end
of the dataframe.

Carpe weekend,

Rich


From wdunl@p @ending from tibco@com  Fri Jul 20 22:44:21 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 20 Jul 2018 13:44:21 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
 <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZ3FqGfqc81xcqJL0Qh1vStM3jA2KktSEJRJOs6BkVkjw@mail.gmail.com>

 >  And each dataframe row has this format:
>2015-10-01,00:00,90.6689
>2015-10-01,01:00,90.6506
>2015-10-01,02:00,90.6719
>2015-10-01,03:00,90.6506

You mean each line in the file, not row in data.frame, has the form
"year-month-day,hour:min,numericValue".  Try the following, where tfile
names your file:

> df <- read.table(tfile, header=FALSE, sep=",", col.names=c("dateString",
"timeString", "Value"))
> df
  dateString timeString   Value
1 2015-10-01      00:00 90.6689
2 2015-10-01      01:00 90.6506
3 2015-10-01      02:00 90.6719
4 2015-10-01      03:00 90.6506
> transform(df, DateTime = as.POSIXlt(paste(dateString, timeString),
format="%Y-%m-%d %H:%M"), dateString=NULL, timeString=NULL)
    Value            DateTime
1 90.6689 2015-10-01 00:00:00
2 90.6506 2015-10-01 01:00:00
3 90.6719 2015-10-01 02:00:00
4 90.6506 2015-10-01 03:00:00
> str(.Last.value)
'data.frame':   4 obs. of  2 variables:
 $ Value   : num  90.7 90.7 90.7 90.7
 $ DateTime: POSIXct, format: "2015-10-01 00:00:00" "2015-10-01 01:00:00"
"2015-10-01 02:00:00" "2015-10-01 03:00:00"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 1:24 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, William Dunlap wrote:
>
> Which format did you use when you used is.na on the output of
>>   as.POSIXlt(strings, format=someFormat)
>> and found none?  Did the resulting dates look OK?  Perhaps
>> all is well.
>>
>
> Bill,
>
>   All dates here are kept as yyyy-mm-dd.
>
>   And each dataframe row has this format:
> 2015-10-01,00:00,90.6689
> 2015-10-01,01:00,90.6506
> 2015-10-01,02:00,90.6719
> 2015-10-01,03:00,90.6506
>
> Thanks,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 22:51:58 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:51:58 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcZ3FqGfqc81xcqJL0Qh1vStM3jA2KktSEJRJOs6BkVkjw@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
 <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>
 <CAF8bMcZ3FqGfqc81xcqJL0Qh1vStM3jA2KktSEJRJOs6BkVkjw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201348070.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> You mean each line in the file, not row in data.frame, has the form
> "year-month-day,hour:min,numericValue". Try the following, where tfile
> names your file:

Bill,

   Yes, I was looking at the data file in one emacs buffer and my R session
in another one.

   The source file was what I posted, the data.frame is different:
  head(wy2016)
         date  time    elev
1 2015-10-01 00:00 90.6689
2 2015-10-01 01:00 90.6506
3 2015-10-01 02:00 90.6719
4 2015-10-01 03:00 90.6506
5 2015-10-01 04:00 90.6597
6 2015-10-01 05:00 90.6841

   It's all fixed now and I've learned how to handle future typos from all of
you.

Thanks,

Rich


From wdunl@p @ending from tibco@com  Fri Jul 20 22:59:05 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 20 Jul 2018 13:59:05 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
 <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZs7R2CKJkadvQsN5WE=WeHzMUVpk6x=8k+xHby8xWh_w@mail.gmail.com>

To find the lines in the file, tfile, with bogus dates, try
    readLines(tfile)[ is.na(dataFrame$DateTime) ]

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 1:30 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, David Winsemius wrote:
>
> I don't think you read Bill's message properly.
>>
>
> David,
>
>   Obviously not.
>
> He was not saying that there were NA's; he was telling you to use a format
>> specification in your as.POSIXct call and the the result of that call
>> would have NA's.
>>
>> wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format=
>> "%Y-%m-%d %H:%M") )
>>
>
>   Thank you. This found 24 TRUEs; now to find them in the file.
>
> Thanks,
>
> Rich
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 23:09:54 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 14:09:54 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcZs7R2CKJkadvQsN5WE=WeHzMUVpk6x=8k+xHby8xWh_w@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
 <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>
 <CAF8bMcZs7R2CKJkadvQsN5WE=WeHzMUVpk6x=8k+xHby8xWh_w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201409290.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> To find the lines in the file, tfile, with bogus dates, try
>    readLines(tfile)[ is.na(dataFrame$DateTime) ]

Bill,

   Thanks for another lesson.

Regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 20 23:18:03 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 14:18:03 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201341090.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
 <alpine.LNX.2.20.1807201341090.3558@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807201416030.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, Rich Shepard wrote:

>  Thank you all. I found the typos which covered a single day toward the end
> of the dataframe.

   FWIW, all these data came from PDF reports and had to be manually
highlighted and pasted into a text file. Given 29 years of hourly (and
sometimes half-hourly) reports I'm not suprised that I made errors now and
then.

Regards,

Rich


From m@notembe @ending from gm@il@com  Fri Jul 20 23:57:36 2018
From: m@notembe @ending from gm@il@com (Atanasio Alberto Tembe Tembe)
Date: Sat, 21 Jul 2018 06:57:36 +0900
Subject: [R] Query on while loop
Message-ID: <CA+YqJcfsVA0RUt82+vTyh95MXKWx6pYn8EjBMWpN-cZXOCXvBw@mail.gmail.com>

 Hello,

I have two matrices: a<-matrix(c(100,350,100,240,150,210,60,120,200 ),3,3)
and c<-matrix(c(2,9,13,10,4,11,14,12,3),3,3).

I have also defined the following variables:
K=0
A[i,j]=colSums(a)
P[i,j]=rowSums(a)
F[i,j]=c[i,j]^(-2 )

Using these data I want to perform the calculation which must end when
a convergence between X and Y values is reached.

X1=1/(K*A1*c11+K*A2*c12+K*A3*c13)

Y1=1/(X1*P1*c11+X1*P1*c12+X1*P1*c13)

X2=1/(Y1*A1*c21+Y1*A2*c22+Y1*A3*c23)

Y2=1/(X2*P2*c21+X2*P2*c22+X2*P2*c23)

X3=1/(Y1*A1*c31+Y1*A2*c32+Y1*A3*c33)

Y3=1/(X2*P3*c31+X2*P3*c32+X2*P3*c33)



I have been struggling over this for some time. Your support is highly
appreciated.

Thanks


-- 
Atanasio Alberto Tembe (Mr)
Doctoral student
Graduate School of Urban Innovation
Transportation and Urban Engineering Laboratory
Yokohama National University
Tel: +81-(0)80-4605-1305 <+81%2080-8080-2482>
 Mail: tembe-atanasio-dz at ynu.jp <pattamaporn-wongwiriya-cs at ynu.jp>
          manotembe at gmail.com <pattamaporn.w at gmail.com>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sat Jul 21 00:42:09 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 20 Jul 2018 15:42:09 -0700
Subject: [R] Query on while loop
In-Reply-To: <CA+YqJcfsVA0RUt82+vTyh95MXKWx6pYn8EjBMWpN-cZXOCXvBw@mail.gmail.com>
References: <CA+YqJcfsVA0RUt82+vTyh95MXKWx6pYn8EjBMWpN-cZXOCXvBw@mail.gmail.com>
Message-ID: <CAGxFJbQYnKD23=Lmd8=Q8sFLB21+fgmmSGdHFVHqDNvAPvT5WA@mail.gmail.com>

I don't know how to say this charitably, but your post indicates that you
**really need to go through an R tutorial or two.** Rather than give you
answers to these very basic matters, a couple of hints:

1.  A and P are vectors with 3 elements, not matrices .

2. I presume things like c11 and c32 are meant to be subscripts but that is
not how subscripts are written in R. R also can do such calculations on
whole objects rather than elementwise;

3. X1 is undefined (INF) as it is = 1/0  . So I have no idea what you
expect here.

Cheers,
Bert








Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 20, 2018 at 2:57 PM, Atanasio Alberto Tembe Tembe <
manotembe at gmail.com> wrote:

>  Hello,
>
> I have two matrices: a<-matrix(c(100,350,100,240,150,210,60,120,200 ),3,3)
> and c<-matrix(c(2,9,13,10,4,11,14,12,3),3,3).
>
> I have also defined the following variables:
> K=0
> A[i,j]=colSums(a)
> P[i,j]=rowSums(a)
> F[i,j]=c[i,j]^(-2 )
>
> Using these data I want to perform the calculation which must end when
> a convergence between X and Y values is reached.
>
> X1=1/(K*A1*c11+K*A2*c12+K*A3*c13)
>
> Y1=1/(X1*P1*c11+X1*P1*c12+X1*P1*c13)
>
> X2=1/(Y1*A1*c21+Y1*A2*c22+Y1*A3*c23)
>
> Y2=1/(X2*P2*c21+X2*P2*c22+X2*P2*c23)
>
> X3=1/(Y1*A1*c31+Y1*A2*c32+Y1*A3*c33)
>
> Y3=1/(X2*P3*c31+X2*P3*c32+X2*P3*c33)
>
>
>
> I have been struggling over this for some time. Your support is highly
> appreciated.
>
> Thanks
>
>
> --
> Atanasio Alberto Tembe (Mr)
> Doctoral student
> Graduate School of Urban Innovation
> Transportation and Urban Engineering Laboratory
> Yokohama National University
> Tel: +81-(0)80-4605-1305 <+81%2080-8080-2482>
>  Mail: tembe-atanasio-dz at ynu.jp <pattamaporn-wongwiriya-cs at ynu.jp>
>           manotembe at gmail.com <pattamaporn.w at gmail.com>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From t@vib@r @ending from gm@il@com  Sat Jul 21 12:36:15 2018
From: t@vib@r @ending from gm@il@com (Micha Silver)
Date: Sat, 21 Jul 2018 13:36:15 +0300
Subject: [R] Fwd: Re:  scatter plot coloring problem
In-Reply-To: <a56866f5-780d-1891-06ba-abf0e45295c4@gmail.com>
References: <a56866f5-780d-1891-06ba-abf0e45295c4@gmail.com>
Message-ID: <9c1c15dc-a2d8-f405-7122-cd4d8d63b10b@gmail.com>


Hi

On 07/20/2018 03:16 PM, PIKAL Petr wrote:
> Hi
>
> Values in conv_df are almost same for each Error level
Thanks to Petr for help in catching this!

>> aggregate(conv_df$Intercept, list(conv_df$Error), mean)
>           Group.1         x
> 1 High CML error -3.226313
> 2  Low CML error -3.226536
> 3  Med CML error -3.226422
>> aggregate(conv_df$Slope, list(conv_df$Error), mean)
>           Group.1        x
> 1 High CML error 8.325558
> 2  Low CML error 8.324242
> 3  Med CML error 8.324721
>> boxplot(split(conv_df$Slope, conv_df$Error))
>> boxplot(split(conv_df$Intercept, conv_df$Error))
>>
> so points in ggplot are overplotted and only colour for last plotted level is visible.

So I used geom_jitter() to get a reasonable looking visualization.

> Cheers
> Petr
>
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From be@trice@monti94 @ending from gm@il@com  Sat Jul 21 15:00:44 2018
From: be@trice@monti94 @ending from gm@il@com (Beatrice Monti)
Date: Sat, 21 Jul 2018 15:00:44 +0200
Subject: [R] Install BMR package - Mac
Message-ID: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>

Hi all,
I am having problems installing the BMR package.

I have been trying the following: 

	install.packages("devtools?) 
	library(devtools) 
	install_github("kthohr/BMR")

This is the error I get:

	clang: error: unsupported option ?-fopenmp'

I have dowloaded and installed both gfortran and clang-6.0.0 from   https://cran.r-project.org/bin/macosx/tools/ <https://cran.r-project.org/bin/macosx/tools/>   but I still get the same error.
I am using R version 3.5.1 on Mac OS X.

Any suggestion to solve this problem - which steps am I missing? 
ps: my apologies if I missed important information - let me know if further details are needed to explain the problem!

Thank you so much for your help!
	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sat Jul 21 16:28:55 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 21 Jul 2018 07:28:55 -0700
Subject: [R] Install BMR package - Mac
In-Reply-To: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>
References: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>
Message-ID: <CAGxFJbSqie_buQ7bcD5p+JeXNicRgYBRPy4EOMd_1qP9-1xdbw@mail.gmail.com>

As this appears to be a Mac specific issue, if you don't get help here, you
should try posting on the r-sig-mac list. Maybe even better would be to
contact the maintainer of the BMR package, who might not monitor either
list.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jul 21, 2018 at 6:00 AM, Beatrice Monti <beatrice.monti94 at gmail.com>
wrote:

> Hi all,
> I am having problems installing the BMR package.
>
> I have been trying the following:
>
>         install.packages("devtools?)
>         library(devtools)
>         install_github("kthohr/BMR")
>
> This is the error I get:
>
>         clang: error: unsupported option ?-fopenmp'
>
> I have dowloaded and installed both gfortran and clang-6.0.0 from
> https://cran.r-project.org/bin/macosx/tools/ <https://cran.r-project.org/
> bin/macosx/tools/>   but I still get the same error.
> I am using R version 3.5.1 on Mac OS X.
>
> Any suggestion to solve this problem - which steps am I missing?
> ps: my apologies if I missed important information - let me know if
> further details are needed to explain the problem!
>
> Thank you so much for your help!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 21 17:46:23 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Jul 2018 08:46:23 -0700
Subject: [R] Install BMR package - Mac
In-Reply-To: <CAGxFJbSqie_buQ7bcD5p+JeXNicRgYBRPy4EOMd_1qP9-1xdbw@mail.gmail.com>
References: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>
 <CAGxFJbSqie_buQ7bcD5p+JeXNicRgYBRPy4EOMd_1qP9-1xdbw@mail.gmail.com>
Message-ID: <BFD7D571-25EC-4326-BD0A-F0F905CDBF1C@dcn.davis.ca.us>

Agree with Bert, but Google sez [1] might also be helpful.

[1] https://github.com/Microsoft/LightGBM/issues/3

On July 21, 2018 7:28:55 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>As this appears to be a Mac specific issue, if you don't get help here,
>you
>should try posting on the r-sig-mac list. Maybe even better would be to
>contact the maintainer of the BMR package, who might not monitor either
>list.
>
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Sat, Jul 21, 2018 at 6:00 AM, Beatrice Monti
><beatrice.monti94 at gmail.com>
>wrote:
>
>> Hi all,
>> I am having problems installing the BMR package.
>>
>> I have been trying the following:
>>
>>         install.packages("devtools?)
>>         library(devtools)
>>         install_github("kthohr/BMR")
>>
>> This is the error I get:
>>
>>         clang: error: unsupported option ?-fopenmp'
>>
>> I have dowloaded and installed both gfortran and clang-6.0.0 from
>> https://cran.r-project.org/bin/macosx/tools/
><https://cran.r-project.org/
>> bin/macosx/tools/>   but I still get the same error.
>> I am using R version 3.5.1 on Mac OS X.
>>
>> Any suggestion to solve this problem - which steps am I missing?
>> ps: my apologies if I missed important information - let me know if
>> further details are needed to explain the problem!
>>
>> Thank you so much for your help!
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jrkride@u @ending from y@hoo@c@  Sat Jul 21 18:39:42 2018
From: jrkride@u @ending from y@hoo@c@ (John Kane)
Date: Sat, 21 Jul 2018 16:39:42 +0000 (UTC)
Subject: [R] Problem with mean()
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
Message-ID: <335228618.266166.1532191182409@mail.yahoo.com>

Either I am doing something very stupid or my R installation has a glitch. What am I missing?
dd1? <- 50
dd2? <- 54

mean(dd1, dd2)
[1] 50? # wrong

(dd1 + dd2)/2
[1] 52 # correct

aa? <- c(48, 52, 56, 54, 52)

mean(aa)
[1] 52.4 # correct



	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Sat Jul 21 18:43:20 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sat, 21 Jul 2018 17:43:20 +0100
Subject: [R] Problem with mean()
In-Reply-To: <335228618.266166.1532191182409@mail.yahoo.com>
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
 <335228618.266166.1532191182409@mail.yahoo.com>
Message-ID: <85fc11be-32a0-2de9-53ff-12c8902fe9ef@sapo.pt>

Hello,

The first argument of mean is a vector, the dots argument is to be 
"passed to or from other methods." (from ?mean)

Try instead

mean(c(dd1, dd2))


Hope this helps,

Rui Barradas

?s 17:39 de 21-07-2018, John Kane via R-help escreveu:
> Either I am doing something very stupid or my R installation has a glitch. What am I missing?
> dd1? <- 50
> dd2? <- 54
> 
> mean(dd1, dd2)
> [1] 50? # wrong
> 
> (dd1 + dd2)/2
> [1] 52 # correct
> 
> aa? <- c(48, 52, 56, 54, 52)
> 
> mean(aa)
> [1] 52.4 # correct
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @ending from gm@il@com  Sat Jul 21 18:44:27 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sat, 21 Jul 2018 12:44:27 -0400
Subject: [R] Problem with mean()
In-Reply-To: <335228618.266166.1532191182409@mail.yahoo.com>
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
 <335228618.266166.1532191182409@mail.yahoo.com>
Message-ID: <d1d7f827-36da-a3bd-31c9-b20be305cf85@gmail.com>

On 21/07/2018 12:39 PM, John Kane via R-help wrote:
> Either I am doing something very stupid or my R installation has a glitch. What am I missing?
> dd1? <- 50
> dd2? <- 54
> 
> mean(dd1, dd2)
> [1] 50? # wrong

Read the help page ?mean.  You are specifying the parameters x and trim.

Duncan Murdoch

> 
> (dd1 + dd2)/2
> [1] 52 # correct
> 
> aa? <- c(48, 52, 56, 54, 52)
> 
> mean(aa)
> [1] 52.4 # correct
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 21 18:44:40 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Jul 2018 09:44:40 -0700
Subject: [R] Problem with mean()
In-Reply-To: <335228618.266166.1532191182409@mail.yahoo.com>
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
 <335228618.266166.1532191182409@mail.yahoo.com>
Message-ID: <F24371F7-433E-4EA6-85FB-971E75028D1E@dcn.davis.ca.us>

Read ?mean.

Look at the argument list.

The mean function only applies to the first argument.

On July 21, 2018 9:39:42 AM PDT, John Kane via R-help <r-help at r-project.org> wrote:
>Either I am doing something very stupid or my R installation has a
>glitch. What am I missing?
>dd1? <- 50
>dd2? <- 54
>
>mean(dd1, dd2)
>[1] 50? # wrong
>
>(dd1 + dd2)/2
>[1] 52 # correct
>
>aa? <- c(48, 52, 56, 54, 52)
>
>mean(aa)
>[1] 52.4 # correct
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ruipb@rr@d@@ @ending from @@po@pt  Sat Jul 21 18:53:00 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Sat, 21 Jul 2018 17:53:00 +0100
Subject: [R] (no subject)
In-Reply-To: <CA+YqJce7kjuuRieg7aJi0TEZ5fQyGMCRP8Ueu81To4We6ZzEUQ@mail.gmail.com>
References: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
 <aa3fbed7-6be7-3076-89f6-40bbee33046f@sapo.pt>
 <CA+YqJcdbJAtepYv75GYHkqFvhM2QHSNicwy44-2wFCUgLvo5ng@mail.gmail.com>
 <CA+YqJce7kjuuRieg7aJi0TEZ5fQyGMCRP8Ueu81To4We6ZzEUQ@mail.gmail.com>
Message-ID: <18fec616-126d-4cc2-4d19-bf1c834b1484@sapo.pt>

Hello,

Please always write to r-help, not to me personally, even if I was able 
to be of assistance in the past.

As for your question, your code has several problems.

1) rowSums and colSums return vectors, not matrices. Even if they did, 
see point 3) below.

2) You define K = 0 then in

X[1]=1/(K*A[i,j]*c[1,1]+K*A[i,j]*c[1,2]+K*A[i,j]*c[1,3])

the denominator is zero because A[i,j] and c[] are multiplied by it.

3) What are the i,j in A[i,j] and P[i,j]?


Hope this helps,

Rui Barradas


?s 11:51 de 21-07-2018, Atanasio Alberto Tembe Tembe escreveu:
> Dear Mr. Barradas,
> 
> Thank you for your attention.
> 
> Sorry for this personalized e-mail. I recently posted a query about 
> while loop, but I did not get good feedback. I am a beginner in R and I 
> wonder if you can me help again.
> 
> If I have two matrices such as: a<-matrix(1:9,nrow=3,ncol=3) and 
> c<-matrix(1:9,nrow=3,ncol=3).
> 
> with defined variables:
> K=0
> A[i,j]=colSums(a)
> P[i,j]=rowSums(a)
> F[i,j]=c[i,j]^(-2 )
> X[i]=A[i,j]*c[i,j]
> X[j]=P[i,j]*c[i,j]
> 
> How to perform the following calculation with while loop so that it 
> stops when a?convergence between X and Y values is reached?.
> 
> X[1]=1/(K*A[i,j]*c[1,1]+K*A[i,j]*c[1,2]+K*A[i,j]*c[1,3])
> 
> Y[1]=1/(X[1]*P[i,j]*c[1,1]+[X1]*P[i,j]*c[1,2]+[X1]*P[i,j]*c[1,3])
> 
> X[2]=1/(Y[1]*A[i,j]*c[2,1]+Y[1]*A[i,j]*c[2,2]+Y[1]*A[i,j]*c[2,3])
> 
> Y[2]=1/(X[2]*P[i,j]*c[2,1]+X[2]*P[i,j]*c[2,2]+X[2]*P[i,j]*c[2,3])
> 
> X[3]=1/(Y[2]*A[i,j]*c[3,1]+Y[1]*A[i,j]*c[3,2]+Y[2]*A[i,j]*c[3,3])
> 
> Y[3]=1/(X[3]*P[3]*c[3,1]+X[3]*P[3]*c[3,2]+X[3]*P[3]*c[3,3])
> 
> 
> Thank you very much.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Mon, Jul 16, 2018 at 6:51 PM, Atanasio Alberto Tembe Tembe 
> <manotembe at gmail.com <mailto:manotembe at gmail.com>> wrote:
> 
>     Hi Mr. Barradas,
> 
>     Thank you for your kind support. I will?your suggestions.
> 
>     Best regards
>     Tembe
> 
> 
>     On Mon, Jul 16, 2018 at 6:22 PM, Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>         Hello,
> 
>         Please repost in plain text, NO HTML formating.
> 
>         Also, you are missing an open parenthesis right after while:
> 
>         while( sum(abs(Sb-D-Sc-t(Pi))>1E-5)){
> 
> 
>         Hope this helps,
> 
>         Rui Barradas
> 
> 
>         ?s 14:25 de 15-07-2018, Atanasio Alberto Tembe Tembe escreveu:
> 
>             Hello!
> 
>             Is there anyone who can help me to this the error bellow? Ijust
>             started using R recently. Thank you
> 
> 
>             while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol
>             in "while
>             sum">? ? ?>? ? ?k=K+1>? ? ?>? ? ?for(i in 1:nrow(c1)){+     
>              ? ?+
>              ? ? for(j in 1:ncol(c1)){+? ? ? ? ? ? ?+           
>              ?if(Sb!=0){+
>              ? ? ? ? ? +? ? ? ? ? ? ? ? ?T2=D*T/Sa+? ? ? ? ? ? ? ? ?+
>             }else {+? ? ? ? ? ? ? ? ?+? ? ? ? ? ? ? ? ?T2=0? ? ? ?+
>              ? +? ? ? ? ? ? ?}+? ? ? ? ? ? ?+? ? ? ? ? ? ?Sc=sum(t(T))+
>             +? ? ? ? ? ? ?if(Sc!=0){+? ? ? ? ? ? ? ? ?+
>             T3=Pi*T2/Sc+? ? ? ? ? ? ? ? ?+? ? ? ? ? ? ?}else {+         
>              ? ? ? ?+
>              ? ? ? ? ? ? ? ? T3=0+? ? ? ? ? ? ? ? ?+? ? ? ? ? ? ?}+
>             Sb=sum(T)+? ? ? ? ? ? ?+? ? ? ? ?}+? ? ?}>? ? ?>? ? ?K[1] 0
> 
>              ? ? ? ? [[alternative HTML version deleted]]
> 
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
> 
> 
> 
> 
>     -- 
>     Atanasio Alberto Tembe (Mr)
>     Doctoral student
>     Graduate School of Urban Innovation
>     Transportation and Urban Engineering Laboratory
>     Yokohama National University
>     Tel: +81-(0)80-4605-1305 <tel:+81%2080-8080-2482>
>      ?Mail: tembe-atanasio-dz at ynu.jp
>     <mailto:pattamaporn-wongwiriya-cs at ynu.jp>
>     manotembe at gmail.com <mailto:pattamaporn.w at gmail.com>
> 
> 
> 
> 
> -- 
> Atanasio Alberto Tembe (Mr)
> Doctoral student
> Graduate School of Urban Innovation
> Transportation and Urban Engineering Laboratory
> Yokohama National University
> Tel: +81-(0)80-4605-1305 <tel:+81%2080-8080-2482>
>  ?Mail: tembe-atanasio-dz at ynu.jp <mailto:pattamaporn-wongwiriya-cs at ynu.jp>
> manotembe at gmail.com <mailto:pattamaporn.w at gmail.com>


From cliveli@t@ @ending from googlem@il@com  Sun Jul 22 02:50:02 2018
From: cliveli@t@ @ending from googlem@il@com (Clive Nicholas)
Date: Sun, 22 Jul 2018 01:50:02 +0100
Subject: [R] Possible solution to R installation problemst for Linux Mint 19
 users
Message-ID: <CAHs5aTgn=+sRXGp8QyAy4scoC-tJjYXsxJrrSC0Wg9yTzfv=Xg@mail.gmail.com>

Hello!

If you're a newly-minted (pun _fully_ intended) user of Linux Mint 19
("Tara") and you find you're having issues installing R (as I just have),
please read on as I may have a solution for you.

To set out the context, the problem looks like this:

You (naturally) consult the relevant webpage at cran.r-project.org for your
Linux Mint system (ubuntu) and add the pub key (I've always used Michael
Rutter's). On my last Linux Mint system (18.2), I was using the following
repositories

deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/
deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/

which worked fine for me. Unfortunately on my new Linux Mint 19 system:

clive at climate:~$ sudo apt-get update
clive at climate:~$ sudo apt-get upgrade
clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
Reading package lists... Done
Building dependency tree
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies.
 r-base-core : Depends: libcurl3 (>= 7.28.0) but it is not going to be
installed
               Depends: libpng12-0 (>= 1.2.13-4) but it is not installable
               Depends: libreadline6 (>= 6.0) but it is not installable
E: Unable to correct problems, you have held broken packages.

No matter how many legitimate bash calls I made, such as

sudo dpkg --configure -a # NOT CURRENTLY WORKING PROPERLY AT PRESENT - THE
LINUX TEAM ARE ONTO THIS, APPARENTLY
sudo apt-get -f install
sudo apt-get --fix-broken install r-base r-base-core r-base-dev

nothing worked: I would simply get variations of the same error.

It turns out the solution is to switch away from -xenial- to *-artful-* (a
repository I've never used before and which appears to be the newest of all
the Ubuntu repositories), so that

deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/
deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/

(or whichever is your favourite mirror).

Then:

clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following additional packages will be installed:
  cdbs dh-translations jq libfile-which-perl libjq1 libonig4 python3-scour
r-cran-boot r-cran-class r-cran-cluster r-cran-codetools r-cran-foreign
r-cran-kernsmooth
  r-cran-lattice r-cran-mass r-cran-matrix r-cran-mgcv r-cran-nlme
r-cran-nnet r-cran-rpart r-cran-spatial r-cran-survival r-recommended scour
Suggested packages:
  devscripts ess r-doc-info | r-doc-pdf r-mathlib r-base-html
gir1.2-rsvg-2.0
Recommended packages:
  r-base-html r-doc-html
The following NEW packages will be installed
  cdbs dh-translations jq libfile-which-perl libjq1 libonig4 python3-scour
r-base r-base-core r-base-dev r-cran-boot r-cran-class r-cran-cluster
r-cran-codetools
  r-cran-foreign r-cran-kernsmooth r-cran-lattice r-cran-mass r-cran-matrix
r-cran-mgcv r-cran-nlme r-cran-nnet r-cran-rpart r-cran-spatial
r-cran-survival
  r-recommended scour
0 to upgrade, 27 to newly install, 0 to remove and 3 not to upgrade.
Need to get 39.5 MB of archives.
After this operation, 59.9 MB of additional disk space will be used.
Do you want to continue? [Y/n] y
Get:1 http://ftp.snt.utwente.nl/pub/os/linux/ubuntu bionic/universe amd64
libonig4 amd64 6.7.0-1 [119 kB]

[...]

Setting up r-base (3.4.4-1ubuntu1) ...
clive at climate:~$ R

R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> plot(rnorm(1000)) # GRAPHIC DULY PRODUCED WITH NO ISSUES!
> q()
Save workspace image? [y/n/c]: n
clive at climate:~$

*Volia!* (Okay, so it doesn't install R 3.5.1 - the latest version - but
that should eventually correct itself with future updates.)

So, if you're having the same R installation problems I've just had after
migrating to Linux Mint 19, this should work for you. Good luck. :)


-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jul 22 07:34:30 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Jul 2018 22:34:30 -0700
Subject: [R] 
 Possible solution to R installation problemst for Linux Mint 19
 users
In-Reply-To: <CAHs5aTgn=+sRXGp8QyAy4scoC-tJjYXsxJrrSC0Wg9yTzfv=Xg@mail.gmail.com>
References: <CAHs5aTgn=+sRXGp8QyAy4scoC-tJjYXsxJrrSC0Wg9yTzfv=Xg@mail.gmail.com>
Message-ID: <5C268157-288C-4D18-9278-DD2E3C067418@dcn.davis.ca.us>

Each Mint version builds from an Ubuntu version. I don't use Mint. but this [1] web page tells me you should be pulling from a Bionic repo. Artful may work for you now, but in general it is risky to mix distribution revisions.

Note that this informative discussion should have occurred on the R-sig-debian mailing list, as it involves the intersection of R and debian derivatives, and is not about the R language as this mailing list is.

[1] https://linuxmint.com/download_all.php



On July 21, 2018 5:50:02 PM PDT, Clive Nicholas via R-help <r-help at r-project.org> wrote:
>Hello!
>
>If you're a newly-minted (pun _fully_ intended) user of Linux Mint 19
>("Tara") and you find you're having issues installing R (as I just
>have),
>please read on as I may have a solution for you.
>
>To set out the context, the problem looks like this:
>
>You (naturally) consult the relevant webpage at cran.r-project.org for
>your
>Linux Mint system (ubuntu) and add the pub key (I've always used
>Michael
>Rutter's). On my last Linux Mint system (18.2), I was using the
>following
>repositories
>
>deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/
>deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/
>
>which worked fine for me. Unfortunately on my new Linux Mint 19 system:
>
>clive at climate:~$ sudo apt-get update
>clive at climate:~$ sudo apt-get upgrade
>clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
>Reading package lists... Done
>Building dependency tree
>Reading state information... Done
>Some packages could not be installed. This may mean that you have
>requested an impossible situation or if you are using the unstable
>distribution that some required packages have not yet been created
>or been moved out of Incoming.
>The following information may help to resolve the situation:
>
>The following packages have unmet dependencies.
> r-base-core : Depends: libcurl3 (>= 7.28.0) but it is not going to be
>installed
>            Depends: libpng12-0 (>= 1.2.13-4) but it is not installable
>               Depends: libreadline6 (>= 6.0) but it is not installable
>E: Unable to correct problems, you have held broken packages.
>
>No matter how many legitimate bash calls I made, such as
>
>sudo dpkg --configure -a # NOT CURRENTLY WORKING PROPERLY AT PRESENT -
>THE
>LINUX TEAM ARE ONTO THIS, APPARENTLY
>sudo apt-get -f install
>sudo apt-get --fix-broken install r-base r-base-core r-base-dev
>
>nothing worked: I would simply get variations of the same error.
>
>It turns out the solution is to switch away from -xenial- to *-artful-*
>(a
>repository I've never used before and which appears to be the newest of
>all
>the Ubuntu repositories), so that
>
>deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/
>deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/
>
>(or whichever is your favourite mirror).
>
>Then:
>
>clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
>Reading package lists... Done
>Building dependency tree
>Reading state information... Done
>The following additional packages will be installed:
>cdbs dh-translations jq libfile-which-perl libjq1 libonig4
>python3-scour
>r-cran-boot r-cran-class r-cran-cluster r-cran-codetools r-cran-foreign
>r-cran-kernsmooth
>  r-cran-lattice r-cran-mass r-cran-matrix r-cran-mgcv r-cran-nlme
>r-cran-nnet r-cran-rpart r-cran-spatial r-cran-survival r-recommended
>scour
>Suggested packages:
>  devscripts ess r-doc-info | r-doc-pdf r-mathlib r-base-html
>gir1.2-rsvg-2.0
>Recommended packages:
>  r-base-html r-doc-html
>The following NEW packages will be installed
>cdbs dh-translations jq libfile-which-perl libjq1 libonig4
>python3-scour
>r-base r-base-core r-base-dev r-cran-boot r-cran-class r-cran-cluster
>r-cran-codetools
>r-cran-foreign r-cran-kernsmooth r-cran-lattice r-cran-mass
>r-cran-matrix
>r-cran-mgcv r-cran-nlme r-cran-nnet r-cran-rpart r-cran-spatial
>r-cran-survival
>  r-recommended scour
>0 to upgrade, 27 to newly install, 0 to remove and 3 not to upgrade.
>Need to get 39.5 MB of archives.
>After this operation, 59.9 MB of additional disk space will be used.
>Do you want to continue? [Y/n] y
>Get:1 http://ftp.snt.utwente.nl/pub/os/linux/ubuntu bionic/universe
>amd64
>libonig4 amd64 6.7.0-1 [119 kB]
>
>[...]
>
>Setting up r-base (3.4.4-1ubuntu1) ...
>clive at climate:~$ R
>
>R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
>Copyright (C) 2018 The R Foundation for Statistical Computing
>Platform: x86_64-pc-linux-gnu (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>> plot(rnorm(1000)) # GRAPHIC DULY PRODUCED WITH NO ISSUES!
>> q()
>Save workspace image? [y/n/c]: n
>clive at climate:~$
>
>*Volia!* (Okay, so it doesn't install R 3.5.1 - the latest version -
>but
>that should eventually correct itself with future updates.)
>
>So, if you're having the same R installation problems I've just had
>after
>migrating to Linux Mint 19, this should work for you. Good luck. :)

-- 
Sent from my phone. Please excuse my brevity.


From pd@lgd @ending from gm@il@com  Sun Jul 22 08:32:24 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Sun, 22 Jul 2018 08:32:24 +0200
Subject: [R] 
 Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <9C4FD8C1-6968-4FE7-B6B5-2CC3586FA903@comcast.net>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
 <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
 <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>
 <9C4FD8C1-6968-4FE7-B6B5-2CC3586FA903@comcast.net>
Message-ID: <B852A03B-DD04-4EDA-9E41-33BB90AD716D@gmail.com>



> On 17 Jul 2018, at 18:18 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>>>> Executing
>>>> 
>>>>    Open Terminal
>>>>    Write or paste in: defaults write org.R-project.R force.LANG
>>>> en_US.UTF-8
>>>>    Close Terminal
>>>>    Start R
>>>> 
>>>> as suggested on 
>> 
>> https://stackoverflow.com/questions/9689104/installing-r-on-mac-warning-messages-setting-lc-ctype-failed-using-c,
>> 
>> did not help :-(
> 
> Sigh, claiming that something "did not help" usually ...does not help. You need a clear unambigous description of everything that was in place and exactly what was being done when the unexpected behavior occurred. 

Hm, well, seen worse...

However, some detective works seems required.

C: (a) Can you at this point do the equivalent of the following (in a Terminal window):

Peter-Dalgaards-MacBook-Air:~ pd$ defaults read org.R-project.R force.LANG
en_US.UTF-8

If not, then the "defaults write...." stuff has been entered incorrectly or didn't work for some reason.

-?d



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From d@lpr@@loui@ @ending from gm@il@com  Sun Jul 22 14:24:41 2018
From: d@lpr@@loui@ @ending from gm@il@com (louis DALPRA)
Date: Sun, 22 Jul 2018 14:24:41 +0200
Subject: [R] Issue : Time to run a model on different computers
Message-ID: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>

Hello,

My issue is related to the time it takes to run a model on R between two different computers. On my teacher?s computer (MacBook Pro 2013; OS 10.9.5; R version 3.1.3) it takes only a few minutes to run it while on mine (MacBook Air 2014; OS 10.13.6; R version 3.5.1) it takes several hours. I checked for malware, and reinstalled the system but still no changes. Does any one have an idea on what might be the issue ?

In advance thank?s for your time and answers.

From bgunter@4567 @ending from gm@il@com  Sun Jul 22 19:20:17 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 22 Jul 2018 10:20:17 -0700
Subject: [R] Issue : Time to run a model on different computers
In-Reply-To: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>
References: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>
Message-ID: <CAGxFJbQkdthZecppVAHBD7EF=AvKrUPjYQ7=Rf=wTPXdT77PhA@mail.gmail.com>

You did not say what memory resources were in the two cases, and it is
probably impossible to say without knowing what code you ran in any case.
That you have different versions of OS and R on the two computers already
means that there could be many possible explanations, but one wild guess is
that on your computer/R version/OS version you are memory limited and
swapping to and from disk, while on the other you are not. This may well be
nothing more than stupid speculation, though.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jul 22, 2018 at 5:24 AM, louis DALPRA <dalpra.louis at gmail.com>
wrote:

> Hello,
>
> My issue is related to the time it takes to run a model on R between two
> different computers. On my teacher?s computer (MacBook Pro 2013; OS 10.9.5;
> R version 3.1.3) it takes only a few minutes to run it while on mine
> (MacBook Air 2014; OS 10.13.6; R version 3.5.1) it takes several hours. I
> checked for malware, and reinstalled the system but still no changes. Does
> any one have an idea on what might be the issue ?
>
> In advance thank?s for your time and answers.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @eren@de@tef@ni @ending from gm@il@com  Sun Jul 22 22:26:58 2018
From: @eren@de@tef@ni @ending from gm@il@com (Serena De Stefani)
Date: Sun, 22 Jul 2018 16:26:58 -0400
Subject: [R] Automate running files in R
Message-ID: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>

I need to automate a process in R. Basically I have a an R script (I will
call it R1) that needs three separate files to run. These three files are
the results output of one trial in my study.

So from each run in R I obtain the summary results for one trial, in a csv
file, plus 32 graphs for each decision point in the trial.

One subject goes through of nine trials. I was thinking about putting all
the files generated by one subject in one big folder, so I will have 27
files (three files times nine trials). This way I won't have to change
working directory multiple times (I wonder if there is a way to have R open
a folder with a certain name as directory, run a scripts, move the
directory to the next folder, run the script again...)

The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So for
subject 1, trial 1, I will have three files with the ending
?mov1_AA

For subject one, trial 2, R should choose the three files with the ending ?
mov1_AB and so on.

At each run, R should save the csv summary output in a folder called
?summary_mov1? and name the files summary_mov1_AA, summary_mov1_AB etc. R
should save the 32 graphs in a different folder, named mov1_graphs,
graph1_mov1_AA, graph1_mov1_AB and so on (ideally, at this point another R
script (R2) should take these nine csv files and build some graphs out of
them).

Once R has run R1 script nine times, I would proceed to a new subject.

So basically: use R1 with three mov1 files, get a summary csv file in a
summary folder (plus 32 graphs in a different folder).

Do this nine times. Once one get the nine csv summary files in the same
folder, use R2 to average them and build a graph.

Then do this for each subject (right now I have 7).

I have never done this type of automation so I am a bit lost. Any
suggestions? Any examples you can point me to? Which would be the best
workflow? At which level should I automate and which things should I rather
do by hand?

Thank you,
Serena DeStefani

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Mon Jul 23 00:17:22 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Mon, 23 Jul 2018 08:17:22 +1000
Subject: [R] Automate running files in R
In-Reply-To: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
References: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
Message-ID: <CA+8X3fUJj6nbg+fLULrJs55qgft9c5wFFed8bXZ=S_2JesYuoQ@mail.gmail.com>

Hi Serena,
I think the directory structure you have described is something like this:

mov_study___________________________
                 |                                                     |
             mov1                      ...                    mov9
             /       \                                            /         \
mov1_csv  mov1_graphs                 mov9_csv  mov9_graphs

If so, you can put your R scripts in the mov_study directory and
change directories like this:

for(movdir in paste0("mov",1:9,) {
 setwd(movdir)
 source("R1")
 source("R2")
 setwd("..")
}

In R1 and R2 add a "movdir" argument set the target directories for
your output like this:
 R1<-function(...,movdir=movdir)
 R2<-function(...,movdir=movdir)

 path_to_csv<-paste(movdir,"csv",sep="_")
 path_to_graph<-paste(movdir,"graphs",sep="_")

and when you write an output file:
# for CSV files
filename<-paste(path_to_csv,csvfilename,sep="/")
# for graph files
filename<-paste(path_to_graph,graphfilename,sep="/")

Obviously I can't test this on your directory structure, but I think
it will do what you want.

Jim

On Mon, Jul 23, 2018 at 6:26 AM, Serena De Stefani
<serenadestefani at gmail.com> wrote:
> I need to automate a process in R. Basically I have a an R script (I will
> call it R1) that needs three separate files to run. These three files are
> the results output of one trial in my study.
>
> So from each run in R I obtain the summary results for one trial, in a csv
> file, plus 32 graphs for each decision point in the trial.
>
> One subject goes through of nine trials. I was thinking about putting all
> the files generated by one subject in one big folder, so I will have 27
> files (three files times nine trials). This way I won't have to change
> working directory multiple times (I wonder if there is a way to have R open
> a folder with a certain name as directory, run a scripts, move the
> directory to the next folder, run the script again...)
>
> The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So for
> subject 1, trial 1, I will have three files with the ending
> ?mov1_AA
>
> For subject one, trial 2, R should choose the three files with the ending ?
> mov1_AB and so on.
>
> At each run, R should save the csv summary output in a folder called
> ?summary_mov1? and name the files summary_mov1_AA, summary_mov1_AB etc. R
> should save the 32 graphs in a different folder, named mov1_graphs,
> graph1_mov1_AA, graph1_mov1_AB and so on (ideally, at this point another R
> script (R2) should take these nine csv files and build some graphs out of
> them).
>
> Once R has run R1 script nine times, I would proceed to a new subject.
>
> So basically: use R1 with three mov1 files, get a summary csv file in a
> summary folder (plus 32 graphs in a different folder).
>
> Do this nine times. Once one get the nine csv summary files in the same
> folder, use R2 to average them and build a graph.
>
> Then do this for each subject (right now I have 7).
>
> I have never done this type of automation so I am a bit lost. Any
> suggestions? Any examples you can point me to? Which would be the best
> workflow? At which level should I automate and which things should I rather
> do by hand?
>
> Thank you,
> Serena DeStefani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Jul 23 00:40:23 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sun, 22 Jul 2018 15:40:23 -0700 (PDT)
Subject: [R] Automate running files in R
In-Reply-To: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
References: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807221533130.4416@salmo.appl-ecosys.com>

On Sun, 22 Jul 2018, Serena De Stefani wrote:

> I need to automate a process in R. Basically I have a an R script (I will
> call it R1) that needs three separate files to run. These three files are
> the results output of one trial in my study.

> The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So for
> subject 1, trial 1, I will have three files with the ending
> ?mov1_AA
>
> For subject one, trial 2, R should choose the three files with the ending ?
> mov1_AB and so on.

Serena,

   In addition to Jim's advice about your directory structure you should
seriously consider your file naming convention. Just like variable names in
a program, you're almost guaranteed to not remember what each two-character
name means within six months of creating them. Spend a little more time
typing and use descriptive names ... and think of using a .dat extension and
using read.table(*.dat).

   You can name your files, for example, input_1.R, input_2.R, and input_3.R
for your run sources. And, for (e.g.,) subject 1, trial 1, name the file
sub1_trial1. This might produce output called sub1_trial1_input1,
sub1_trial1_input2, and sub1_trial1_input3.

   Now when you look at data.frames or output you and everyone else will know
just what each contains.

Have fun,

Rich


From jeremieju@te @ending from gm@il@com  Mon Jul 23 12:30:38 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 12:30:38 +0200
Subject: [R] [bug] spdep package?
Message-ID: <87d0ve5jn5.fsf@gmail.com>



Hello,


I found a dangerous issue in the library spdep. I get variables x and y
that cannot be removed by rm() and I don't don't how they show up. Can
anyone reproduce this?

~$ R --vanilla
> rm(list=ls())
> library(spdep)
> x
[1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> rm(list=ls())
> x
[1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450



> Sys.info()

sysname        "Linux"                                     
release        "4.9.0-6-amd64"                             
version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
nodename       "freegnu"                                   
machine        "x86_64"                                    


> Session


> sessionInfo()

R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Matrix products: default
BLAS: /usr/local/lib/R/lib/libRblas.so
LAPACK: /usr/local/lib/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.4.1


From henrik@bengt@@on @ending from gm@il@com  Mon Jul 23 12:39:52 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Mon, 23 Jul 2018 12:39:52 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <87d0ve5jn5.fsf@gmail.com>
References: <87d0ve5jn5.fsf@gmail.com>
Message-ID: <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>

It turns out that that 'x' comes from the spData package and lives
inside that package (part of its namespace).

> spData::x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450

This is conceptually no different from other objects in package
namespace, although we are more used to seeing functions and not data
object.  Another well-known example of this is:

> base::pi
[1] 3.141593

So, this 'x' is *not* in your global workspace and you cannot remove
it without unloading the package.

/Henrik

On Mon, Jul 23, 2018 at 12:30 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>
>
>
> Hello,
>
>
> I found a dangerous issue in the library spdep. I get variables x and y
> that cannot be removed by rm() and I don't don't how they show up. Can
> anyone reproduce this?
>
> ~$ R --vanilla
> > rm(list=ls())
> > library(spdep)
> > x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> > rm(list=ls())
> > x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
>
>
> > Sys.info()
>
> sysname        "Linux"
> release        "4.9.0-6-amd64"
> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
> nodename       "freegnu"
> machine        "x86_64"
>
>
> > Session
>
>
> > sessionInfo()
>
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 9 (stretch)
>
> Matrix products: default
> BLAS: /usr/local/lib/R/lib/libRblas.so
> LAPACK: /usr/local/lib/R/lib/libRlapack.so
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @ending from @uckl@nd@@c@nz  Mon Jul 23 12:58:16 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 23 Jul 2018 22:58:16 +1200
Subject: [R] [FORGED]  [bug] spdep package?
In-Reply-To: <87d0ve5jn5.fsf@gmail.com>
References: <87d0ve5jn5.fsf@gmail.com>
Message-ID: <f62ae796-ae12-f5b3-3951-bc6fbcc35b6c@auckland.ac.nz>

On 23/07/18 22:30, Jeremie Juste wrote:
> 
> 
> Hello,
> 
> 
> I found a dangerous issue in the library spdep. I get variables x and y
> that cannot be removed by rm() and I don't don't how they show up. Can
> anyone reproduce this?

I cannot.

This is *very* unlikely to be a bug.  People should always exercise a 
great deal of caution about conjecturing bugs when they encounter a
phenomenon that they don't understand.

What do you see if you simply do "ls()"?  (After loading spdep.)
I.e. do you see an "x" listed as an object in your workspace/global 
environment?

What does find("x") return?

It puzzles me that your sessionInfo() doesn't show something like:

> other attached packages:
> [1] spdep_0.6-13  Matrix_1.2-10 sp_1.2-5

There are probably other issues that you have not told us about.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> 
> ~$ R --vanilla
>> rm(list=ls())
>> library(spdep)
>> x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> rm(list=ls())
>> x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> 
> 
> 
>> Sys.info()
> 
> sysname        "Linux"
> release        "4.9.0-6-amd64"
> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
> nodename       "freegnu"
> machine        "x86_64"
> 
> 
>> Session
> 
> 
>> sessionInfo()
> 
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 9 (stretch)
> 
> Matrix products: default
> BLAS: /usr/local/lib/R/lib/libRblas.so
> LAPACK: /usr/local/lib/R/lib/libRlapack.so
> 
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1


From M@Enzi@n @ending from gmx@de  Mon Jul 23 13:43:36 2018
From: M@Enzi@n @ending from gmx@de (Maria Enzian)
Date: Mon, 23 Jul 2018 13:43:36 +0200
Subject: [R] pROC
Message-ID: <trinity-c719bf86-35fa-4f71-b74f-46e7639cdd19-1532346216576@3c-app-gmx-bs38>



Hello,
I'm using the package pROC in RStudio to create my ROC-curves and I have patients in my data - healthy or sick - in the column "Status" and the value "SUVmax" to examine it.
I used the following code:
plot.roc(daten$Status,daten$SUVmax,percent=TRUE,ci=TRUE,print.auc=TRUE,main="ROC-Kurve f?r den SUVmax")
The ROC-curve I got is ok, but on the x-axis I got a specificity from 150% to -50%, but I want the scale from 100% to 0% (as usual).
xlim=c(100,0) doesn't work.
Can someone help me?
?
Best regards
M.Enzian


From jeremieju@te @ending from gm@il@com  Mon Jul 23 14:01:17 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 14:01:17 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
 (Henrik Bengtsson's message of "Mon, 23 Jul 2018 12:39:52 +0200")
References: <87d0ve5jn5.fsf@gmail.com>
 <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
Message-ID: <8760165fg2.fsf@gmail.com>


Helllo,

Thanks for the info. I still think these variables should not be loaded
when library(spdep) is called.

But I'll handle it following your suggestion.

Thanks,

Jeremie






> It turns out that that 'x' comes from the spData package and lives
> inside that package (part of its namespace).
>
>> spData::x
>  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
> This is conceptually no different from other objects in package
> namespace, although we are more used to seeing functions and not data
> object.  Another well-known example of this is:
>
>> base::pi
> [1] 3.141593
>
> So, this 'x' is *not* in your global workspace and you cannot remove
> it without unloading the package.
>
> /Henrik


>>
>>
>> I found a dangerous issue in the library spdep. I get variables x and y
>> that cannot be removed by rm() and I don't don't how they show up. Can
>> anyone reproduce this?
>>
>> ~$ R --vanilla
>> > rm(list=ls())
>> > library(spdep)
>> > x
>> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> > rm(list=ls())
>> > x
>> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>>
>>
>>
>> > Sys.info()
>>
>> sysname        "Linux"
>> release        "4.9.0-6-amd64"
>> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
>> nodename       "freegnu"
>> machine        "x86_64"
>>
>>
>> > Session
>>
>>
>> > sessionInfo()
>>
>> R version 3.4.1 (2017-06-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Debian GNU/Linux 9 (stretch)
>>
>> Matrix products: default
>> BLAS: /usr/local/lib/R/lib/libRblas.so
>> LAPACK: /usr/local/lib/R/lib/libRlapack.so
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From henrik@bengt@@on @ending from gm@il@com  Mon Jul 23 14:54:05 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Mon, 23 Jul 2018 14:54:05 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <8760165fg2.fsf@gmail.com>
References: <87d0ve5jn5.fsf@gmail.com>
 <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
 <8760165fg2.fsf@gmail.com>
Message-ID: <CAFDcVCSFEfE7o7vTfKF28etYnx6xA-xPf6hBt-jMNhQbc=Yqog@mail.gmail.com>

This is intended/expected because the spdep package *depends* on the
spData package (see https://cran.r-project.org/web/packages/spdep/),
which means that the maintainer of spdep intends also spData to be
*attached* whenever spdep is attached.    If they would have only
imported it, then spData would only be *loaded* (but not attached),
and you would not get 'spData' on your search() path and therefore not
see 'x' either.

Example:

## Loading spData
> loadNamespace("spData")
<environment: namespace:spData>

> loadedNamespaces()
[1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
[7] "methods"   "spData"    "base"

## The search path used to find objects
> search()
[1] ".GlobalEnv"        "package:stats"     "package:graphics"
[4] "package:grDevices" "package:utils"     "package:datasets"
[7] "package:methods"   "Autoloads"         "package:base"

## So, spData::x is not found
> x
Error: object 'x' not found

## But is still there
> spData::x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450


## Attaching spData, which also happens when you do library(spdat)
> library(spData)
To access larger datasets in this package, install the spDataLarge
package with: `install.packages('spDataLarge',
repos='https://nowosad.github.io/drat/', type='source'))

> loadedNamespaces()
[1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
[7] "methods"   "spData"    "base"

## Now, spData is on the search path
> search()
 [1] ".GlobalEnv"        "package:spData"    "package:stats"
 [4] "package:graphics"  "package:grDevices" "package:utils"
 [7] "package:datasets"  "package:methods"   "Autoloads"
[10] "package:base

> x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450

> find("x")
[1] "package:spData"

/Henrik
On Mon, Jul 23, 2018 at 2:01 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>
>
> Helllo,
>
> Thanks for the info. I still think these variables should not be loaded
> when library(spdep) is called.
>
> But I'll handle it following your suggestion.
>
> Thanks,
>
> Jeremie
>
>
>
>
>
>
> > It turns out that that 'x' comes from the spData package and lives
> > inside that package (part of its namespace).
> >
> >> spData::x
> >  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> >
> > This is conceptually no different from other objects in package
> > namespace, although we are more used to seeing functions and not data
> > object.  Another well-known example of this is:
> >
> >> base::pi
> > [1] 3.141593
> >
> > So, this 'x' is *not* in your global workspace and you cannot remove
> > it without unloading the package.
> >
> > /Henrik
>
>
> >>
> >>
> >> I found a dangerous issue in the library spdep. I get variables x and y
> >> that cannot be removed by rm() and I don't don't how they show up. Can
> >> anyone reproduce this?
> >>
> >> ~$ R --vanilla
> >> > rm(list=ls())
> >> > library(spdep)
> >> > x
> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> >> > rm(list=ls())
> >> > x
> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> >>
> >>
> >>
> >> > Sys.info()
> >>
> >> sysname        "Linux"
> >> release        "4.9.0-6-amd64"
> >> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
> >> nodename       "freegnu"
> >> machine        "x86_64"
> >>
> >>
> >> > Session
> >>
> >>
> >> > sessionInfo()
> >>
> >> R version 3.4.1 (2017-06-30)
> >> Platform: x86_64-pc-linux-gnu (64-bit)
> >> Running under: Debian GNU/Linux 9 (stretch)
> >>
> >> Matrix products: default
> >> BLAS: /usr/local/lib/R/lib/libRblas.so
> >> LAPACK: /usr/local/lib/R/lib/libRlapack.so
> >>
> >> locale:
> >>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >> loaded via a namespace (and not attached):
> >> [1] compiler_3.4.1
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.


From jeremieju@te @ending from gm@il@com  Mon Jul 23 15:44:53 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 15:44:53 +0200
Subject: [R] [FORGED]  [bug] spdep package?
In-Reply-To: <f62ae796-ae12-f5b3-3951-bc6fbcc35b6c@auckland.ac.nz> (Rolf
 Turner's message of "Mon, 23 Jul 2018 22:58:16 +1200")
References: <87d0ve5jn5.fsf@gmail.com>
 <f62ae796-ae12-f5b3-3951-bc6fbcc35b6c@auckland.ac.nz>
Message-ID: <871sbu5ane.fsf@gmail.com>


Hello,


>This is *very* unlikely to be a bug.  People should always exercise a
>great deal of caution about conjecturing bugs when they encounter a
>phenomenon that they don't understand.

Ok,  I over reacted and I should let the package maintainers
qualify what is a bug or not. My point is that it is surprising to have
access these variables in the global environment when loading the spdep
library.

I normally I would expect the following

 rm(list=ls())
 myfun <- function(x){
        y+ 33}
        
> myfun(x)
> Error in myfun(4) : object 'y' not found

But this is not cool 
> myfun()
 [1]  33  63  93 123 153 183 213 243 273 303 333 363 393 423 453 483


> It puzzles me that your sessionInfo() doesn't show something like:
You are right. My apologies. I confused sessions when I pasted the
sessionInfo.  Allow me to correct.



<on the Terminal> R --vanilla -q 
> ls()
character(0)
> library(spdep)
Loading required package: sp
Loading required package: Matrix
Loading required package: spData
To access larger datasets in this package, install the spDataLarge
package with: `install.packages('spDataLarge')`
> ls()
character(0)
> sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Matrix products: default
BLAS: /usr/local/lib/R/lib/libRblas.so
LAPACK: /usr/local/lib/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] spdep_0.7-7    spData_0.2.6.7 Matrix_1.2-10  sp_1.2-5      

loaded via a namespace (and not attached):
 [1] lattice_0.20-35     deldir_0.1-14       gtools_3.5.0       
 [4] MASS_7.3-47         grid_3.4.1          nlme_3.1-131       
 [7] coda_0.19-1         data.table_1.10.4-3 gdata_2.18.0       
[10] LearnBayes_2.15     gmodels_2.16.2      boot_1.3-19        
[13] splines_3.4.1       compiler_3.4.1      filehash_2.4-1     
[16] expm_0.999-2       
> x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450


I think Henrik Bengtsson has identified the issue see the next thread. 

Best regards,

Jeremie


From jeremieju@te @ending from gm@il@com  Mon Jul 23 20:13:00 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 20:13:00 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <CAFDcVCSFEfE7o7vTfKF28etYnx6xA-xPf6hBt-jMNhQbc=Yqog@mail.gmail.com>
 (Henrik Bengtsson's message of "Mon, 23 Jul 2018 14:54:05 +0200")
References: <87d0ve5jn5.fsf@gmail.com>
 <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
 <8760165fg2.fsf@gmail.com>
 <CAFDcVCSFEfE7o7vTfKF28etYnx6xA-xPf6hBt-jMNhQbc=Yqog@mail.gmail.com>
Message-ID: <87wotl4y8j.fsf@gmail.com>


Many thanks for the info.

I see the point but I'll think calling the spData would be a cheaper
price to pay. If each package one load provide access to their variables
things are likely to get messy.

I guess many R users would like to control the variables in their global
environment.

And since it is not trival to protect variables inside a function from
the parent environment this is potentially dangerous.

Best wishes,

Jeremie










Henrik Bengtsson <henrik.bengtsson at gmail.com> writes:

> This is intended/expected because the spdep package *depends* on the
> spData package (see https://cran.r-project.org/web/packages/spdep/),
> which means that the maintainer of spdep intends also spData to be
> *attached* whenever spdep is attached.    If they would have only
> imported it, then spData would only be *loaded* (but not attached),
> and you would not get 'spData' on your search() path and therefore not
> see 'x' either.
>
> Example:
>
> ## Loading spData
>> loadNamespace("spData")
> <environment: namespace:spData>
>
>> loadedNamespaces()
> [1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
> [7] "methods"   "spData"    "base"
>
> ## The search path used to find objects
>> search()
> [1] ".GlobalEnv"        "package:stats"     "package:graphics"
> [4] "package:grDevices" "package:utils"     "package:datasets"
> [7] "package:methods"   "Autoloads"         "package:base"
>
> ## So, spData::x is not found
>> x
> Error: object 'x' not found
>
> ## But is still there
>> spData::x
>  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
> ## Attaching spData, which also happens when you do library(spdat)
>> library(spData)
> To access larger datasets in this package, install the spDataLarge
> package with: `install.packages('spDataLarge',
> repos='https://nowosad.github.io/drat/', type='source'))
>
>> loadedNamespaces()
> [1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
> [7] "methods"   "spData"    "base"
>
> ## Now, spData is on the search path
>> search()
>  [1] ".GlobalEnv"        "package:spData"    "package:stats"
>  [4] "package:graphics"  "package:grDevices" "package:utils"
>  [7] "package:datasets"  "package:methods"   "Autoloads"
> [10] "package:base
>
>> x
>  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
>> find("x")
> [1] "package:spData"
>
> /Henrik
> On Mon, Jul 23, 2018 at 2:01 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>>
>>
>> Helllo,
>>
>> Thanks for the info. I still think these variables should not be loaded
>> when library(spdep) is called.
>>
>> But I'll handle it following your suggestion.
>>
>> Thanks,
>>
>> Jeremie
>>
>>
>>
>>
>>
>>
>> > It turns out that that 'x' comes from the spData package and lives
>> > inside that package (part of its namespace).
>> >
>> >> spData::x
>> >  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> >
>> > This is conceptually no different from other objects in package
>> > namespace, although we are more used to seeing functions and not data
>> > object.  Another well-known example of this is:
>> >
>> >> base::pi
>> > [1] 3.141593
>> >
>> > So, this 'x' is *not* in your global workspace and you cannot remove
>> > it without unloading the package.
>> >
>> > /Henrik
>>
>>
>> >>
>> >>
>> >> I found a dangerous issue in the library spdep. I get variables x and y
>> >> that cannot be removed by rm() and I don't don't how they show up. Can
>> >> anyone reproduce this?
>> >>
>> >> ~$ R --vanilla
>> >> > rm(list=ls())
>> >> > library(spdep)
>> >> > x
>> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> >> > rm(list=ls())
>> >> > x
>> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> >>
>> >>
>> >>
>> >> > Sys.info()
>> >>
>> >> sysname        "Linux"
>> >> release        "4.9.0-6-amd64"
>> >> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
>> >> nodename       "freegnu"
>> >> machine        "x86_64"
>> >>
>> >>
>> >> > Session
>> >>
>> >>
>> >> > sessionInfo()
>> >>
>> >> R version 3.4.1 (2017-06-30)
>> >> Platform: x86_64-pc-linux-gnu (64-bit)
>> >> Running under: Debian GNU/Linux 9 (stretch)
>> >>
>> >> Matrix products: default
>> >> BLAS: /usr/local/lib/R/lib/libRblas.so
>> >> LAPACK: /usr/local/lib/R/lib/libRlapack.so
>> >>
>> >> locale:
>> >>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> >>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> >>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> >>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> >>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> >>
>> >> attached base packages:
>> >> [1] stats     graphics  grDevices utils     datasets  methods   base
>> >>
>> >> loaded via a namespace (and not attached):
>> >> [1] compiler_3.4.1
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.


From friendly @ending from yorku@c@  Mon Jul 23 21:41:28 2018
From: friendly @ending from yorku@c@ (Michael Friendly)
Date: Mon, 23 Jul 2018 15:41:28 -0400
Subject: [R] Automate running files in R
In-Reply-To: <alpine.LNX.2.20.1807221533130.4416@salmo.appl-ecosys.com>
References: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
 <alpine.LNX.2.20.1807221533130.4416@salmo.appl-ecosys.com>
Message-ID: <f33ec57d-b36b-cc01-7105-c141412b47f8@yorku.ca>

Hi Serena

I'll add one more "in addition" to this list of suggestions. It may not 
be what you were thinking of, but may be far simpler in the long run.

The complexity of your approach comes from having separate data files 
for each subject and trial, for which you have to have a convention for
naming files and organizing them into coherently named directories.

The ideal solution would be to write your data into a single file, in 
which subjects and trials would just be separate columns.  More 
generally, anything you can do to change separate files into 
lines/records in a data frame will ease your task.

-Michael

On 7/22/18 6:40 PM, Rich Shepard wrote:
> On Sun, 22 Jul 2018, Serena De Stefani wrote:
> 
>> I need to automate a process in R. Basically I have a an R script (I will
>> call it R1) that needs three separate files to run. These three files are
>> the results output of one trial in my study.
> 
>> The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So 
>> for
>> subject 1, trial 1, I will have three files with the ending
>> ?mov1_AA
>>
>> For subject one, trial 2, R should choose the three files with the 
>> ending ?
>> mov1_AB and so on.
> 
> Serena,
> 
>  ? In addition to Jim's advice about your directory structure you should
> seriously consider your file naming convention. Just like variable names in
> a program, you're almost guaranteed to not remember what each two-character
> name means within six months of creating them. Spend a little more time
> typing and use descriptive names ... and think of using a .dat extension 
> and
> using read.table(*.dat).
> 
>  ? You can name your files, for example, input_1.R, input_2.R, and 
> input_3.R
> for your run sources. And, for (e.g.,) subject 1, trial 1, name the file
> sub1_trial1. This might produce output called sub1_trial1_input1,
> sub1_trial1_input2, and sub1_trial1_input3.
> 
>  ? Now when you look at data.frames or output you and everyone else will 
> know
> just what each contains.
> 
> Have fun,
> 
> Rich
>


From mich@el@m@tt@ @ending from unimib@it  Tue Jul 24 05:21:38 2018
From: mich@el@m@tt@ @ending from unimib@it (michael matta)
Date: Mon, 23 Jul 2018 23:21:38 -0400
Subject: [R] RStudio Exploratory Factor Analysis: write a function that
 extracts an increasing number of factors
Message-ID: <CAPbjefcjyEpdAmP+PeZbQ1XDNkZ5orCExPt4xPREnbzkqz0hFw@mail.gmail.com>

I have been trying to write a function in Rstudio that extracts an
increasing number of latent factors for the EFA and reports fit measures
for each solution in a final table. Below, I pasted what I was able to come
up with.

Unfortunately, it has some critical limitations:

The for loop requires to set the interval of factors that will be
extracted. That is fine but it would be nicer if the function stopped when
it reaches an error message (such as "maximum iteration exceeded",
"convergence not obtained in GPFoblq").

The final table includes an ugly first column with the label "RMSEA" which
is completely useless but I cannot get rid of it.

In general, the for loop might not be the most elegant way to reach the
goal.

 library(psych)
 library(GPArotation)
 library(dplyr)
 library(plyr)
 library(qgraph)

 efas <- list()

 for (i in 1:10) {
     fitn <- fa(big5, nfactors = i, fm = "pa", rotate = "oblimin",
     scores = "regression")
     efas[[i]] <- data.frame(fitn$TLI, fitn$RMSEA[1], fitn$rms, fitn$BIC)
%>%
     mutate(Factors = i) %>%
     dplyr::rename(TLI = fitn.TLI,
            RMSEA = fitn.RMSEA.1.,
            SRMR = fitn.rms,
            BIC = fitn.BIC) %>%
     dplyr::select(Factors, TLI, RMSEA, SRMR, BIC)

     }

  do.call("rbind", efas) %>%
    kable()


Thanks for any help!

-- 
*Michael Matta, **Ph.D.*
Postdoctoral Research Associate, Department of Applied Psychology
408 International Village
360 Huntington Ave
Northeastern University
Boston, MA 02115

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Jul 24 07:31:21 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Tue, 24 Jul 2018 06:31:21 +0100
Subject: [R] RStudio Exploratory Factor Analysis: write a function that
 extracts an increasing number of factors
In-Reply-To: <CAPbjefcjyEpdAmP+PeZbQ1XDNkZ5orCExPt4xPREnbzkqz0hFw@mail.gmail.com>
References: <CAPbjefcjyEpdAmP+PeZbQ1XDNkZ5orCExPt4xPREnbzkqz0hFw@mail.gmail.com>
Message-ID: <6ed58ddf-fbef-f601-30f0-375f5b68c4a3@sapo.pt>

Hello,

The output of kable() is a character vector, so you can solve your 
problem with a regex.


res <- do.call("rbind", efas) %>%
   kable()

res2 <- sub("^\\|[^|]+(\\|.*)", "\\1", res)
head(res2)


Alternatively, a more tidyverse like way would be to pipe the output of 
kable() through sub().


do.call("rbind", efas) %>%
   kable() %>%
   sub("^\\|[^|]+(\\|.*)", "\\1", .)


Hope this helps,

Rui Barradas

?s 04:21 de 24-07-2018, michael matta escreveu:
> I have been trying to write a function in Rstudio that extracts an
> increasing number of latent factors for the EFA and reports fit measures
> for each solution in a final table. Below, I pasted what I was able to come
> up with.
> 
> Unfortunately, it has some critical limitations:
> 
> The for loop requires to set the interval of factors that will be
> extracted. That is fine but it would be nicer if the function stopped when
> it reaches an error message (such as "maximum iteration exceeded",
> "convergence not obtained in GPFoblq").
> 
> The final table includes an ugly first column with the label "RMSEA" which
> is completely useless but I cannot get rid of it.
> 
> In general, the for loop might not be the most elegant way to reach the
> goal.
> 
>   library(psych)
>   library(GPArotation)
>   library(dplyr)
>   library(plyr)
>   library(qgraph)
> 
>   efas <- list()
> 
>   for (i in 1:10) {
>       fitn <- fa(big5, nfactors = i, fm = "pa", rotate = "oblimin",
>       scores = "regression")
>       efas[[i]] <- data.frame(fitn$TLI, fitn$RMSEA[1], fitn$rms, fitn$BIC)
> %>%
>       mutate(Factors = i) %>%
>       dplyr::rename(TLI = fitn.TLI,
>              RMSEA = fitn.RMSEA.1.,
>              SRMR = fitn.rms,
>              BIC = fitn.BIC) %>%
>       dplyr::select(Factors, TLI, RMSEA, SRMR, BIC)
> 
>       }
> 
>    do.call("rbind", efas) %>%
>      kable()
> 
> 
> Thanks for any help!
>


From bog@@o@chri@tofer @ending from gm@il@com  Tue Jul 24 12:17:41 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Tue, 24 Jul 2018 15:47:41 +0530
Subject: [R] Stop a loop if it takes long time
Message-ID: <CA+dpOJnihhCj0D5dmLiBpUsu5h1X3XLUEX2CK=dWSRaXCA6XZw@mail.gmail.com>

Hi,

Let say I am implementing a loop using for() / apply()-family etc.

Now, the calculation-time within a particular loop is not fixed, means,
some loop takes a long time to finish calculation, and next loop perhaps
very quick to finish.

I am exploring if there is any way, to check if the calculation within a
particular loop takes longer time than a pre-fixed threshold and if it does
then kill that loop and proceed to the next.

Is it possible to implement such without adding much overhead with existing
calculation?

Thanks for your feedback

	[[alternative HTML version deleted]]


From profjcn@@h @ending from gm@il@com  Tue Jul 24 14:19:59 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Tue, 24 Jul 2018 08:19:59 -0400
Subject: [R] historic(al) algorithms in R
Message-ID: <518109e8-e5b1-b86b-a274-58862709ba04@gmail.com>

R users may or may not be aware of the long history of some of the codes
and algorithms used by base R and by packages. There is a small effort
under way to try to document and improve understanding of these, and
R Consortium has allocated some funds. We've now got a Working Group
and some preliminary documents / examples, but would welcome wider
participation, and an invitation to participate or even just lurk on
the project follows. We especially welcome younger workers so the
understanding of older codes and languages can be passed on.

John Nash

INVITATION

The histoRicalg project is a modest effort to try to document the
older, historic algorithms that underpin R. Some other computational
environments (NumPy, Octave, Gnu Scientific Library, etc.) likely
have similar codes. However, such numerical tools are often written
or at least presented in Fortran or other older programming
languages. The R-Consortium has granted us a small amount of money
for this activity.

This is an invitation to join a small group of workers who hope
to share information and expertise so the methods are documented
and the understanding of older program code is passed on.

Our activities live on Gitlab as a file repository at

   https://gitlab.com/nashjc/histoRicalg

and a wiki at

   https://gitlab.com/nashjc/histoRicalg/wikis/home

We have a mailing list that is based at

   https://lists.r-consortium.org/g/rconsortium-project-histoRicalg

If you work with older algorithms or have relevant expertise, please
join us, even if you plan only to lurk on the list or gitlab site
and may only kibbitz from time to time. This is an activity that
requires a modest input from those with a wide range of knowledge
and backgrounds rather than intense effort by a very few.

Yours,


The histoRicalg Working Group


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jul 24 15:42:18 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 24 Jul 2018 06:42:18 -0700
Subject: [R] Stop a loop if it takes long time
In-Reply-To: <CA+dpOJnihhCj0D5dmLiBpUsu5h1X3XLUEX2CK=dWSRaXCA6XZw@mail.gmail.com>
References: <CA+dpOJnihhCj0D5dmLiBpUsu5h1X3XLUEX2CK=dWSRaXCA6XZw@mail.gmail.com>
Message-ID: <D1A66FA6-9EB8-471F-BA5A-6FB6D7F75C1E@dcn.davis.ca.us>

Depends somewhat on what you are doing in the loop and how much of a performance hit you are willing to accept. [1]

[1] https://stackoverflow.com/questions/7891073/time-out-an-r-command-via-something-like-try

On July 24, 2018 3:17:41 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>Let say I am implementing a loop using for() / apply()-family etc.
>
>Now, the calculation-time within a particular loop is not fixed, means,
>some loop takes a long time to finish calculation, and next loop
>perhaps
>very quick to finish.
>
>I am exploring if there is any way, to check if the calculation within
>a
>particular loop takes longer time than a pre-fixed threshold and if it
>does
>then kill that loop and proceed to the next.
>
>Is it possible to implement such without adding much overhead with
>existing
>calculation?
>
>Thanks for your feedback
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Tue Jul 24 16:25:20 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 24 Jul 2018 07:25:20 -0700
Subject: [R] Issue : Time to run a model on different computers
In-Reply-To: <D5958810-F3C7-4851-9EFA-C11CDE18683D@gmail.com>
References: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>
 <CAGxFJbQkdthZecppVAHBD7EF=AvKrUPjYQ7=Rf=wTPXdT77PhA@mail.gmail.com>
 <D5958810-F3C7-4851-9EFA-C11CDE18683D@gmail.com>
Message-ID: <CAGxFJbRtayZibr2Cg_CoHN3dQGXYA75uThycGTG-LBA7R60xag@mail.gmail.com>

1. Unless there is good reason not to, always cc the list, which I have
done here.

2. I should have added that memory usage and possible swapping issues also
depends on what other software you have running, not just on how much
memory you have.

In other words, I see no way to answer your question without some sort of
local diagnostics. Perhaps others might have a better idea.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 24, 2018 at 2:24 AM, louis DALPRA <dalpra.louis at gmail.com>
wrote:

> Hello Bert,
>
> First thank?s a lot for your answer !
> My memory resource is ? 4 go 1600 Mhz DDR3 ?, for my teacher?s computer I
> don?t know but I?ll ask him. You can find in attachment the code I?m using
> if you want to look at it (the model and 2 functions that are called). Is
> there a way to know for sure if it?s caused by memory limitation ?
>
> Have a nice day,
> Louis
>
> Le 22 juil. 2018 ? 19:20, Bert Gunter <bgunter.4567 at gmail.com> a ?crit :
>
> You did not say what memory resources were in the two cases, and it is
> probably impossible to say without knowing what code you ran in any case.
> That you have different versions of OS and R on the two computers already
> means that there could be many possible explanations, but one wild guess is
> that on your computer/R version/OS version you are memory limited and
> swapping to and from disk, while on the other you are not. This may well be
> nothing more than stupid speculation, though.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Jul 22, 2018 at 5:24 AM, louis DALPRA <dalpra.louis at gmail.com>
> wrote:
>
>> Hello,
>>
>> My issue is related to the time it takes to run a model on R between two
>> different computers. On my teacher?s computer (MacBook Pro 2013; OS 10.9.5;
>> R version 3.1.3) it takes only a few minutes to run it while on mine
>> (MacBook Air 2014; OS 10.13.6; R version 3.5.1) it takes several hours. I
>> checked for malware, and reinstalled the system but still no changes. Does
>> any one have an idea on what might be the issue ?
>>
>> In advance thank?s for your time and answers.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Tue Jul 24 23:38:04 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Tue, 24 Jul 2018 14:38:04 -0700
Subject: [R] pROC
In-Reply-To: <trinity-c719bf86-35fa-4f71-b74f-46e7639cdd19-1532346216576@3c-app-gmx-bs38>
References: <trinity-c719bf86-35fa-4f71-b74f-46e7639cdd19-1532346216576@3c-app-gmx-bs38>
Message-ID: <29393C89-272E-4E1A-90C3-7E9DDB0A577F@comcast.net>


> On Jul 23, 2018, at 4:43 AM, Maria Enzian <M.Enzian at gmx.de> wrote:
> 
> 
> 
> Hello,
> I'm using the package pROC in RStudio to create my ROC-curves and I have patients in my data - healthy or sick - in the column "Status" and the value "SUVmax" to examine it.
> I used the following code:
> plot.roc(daten$Status,daten$SUVmax,percent=TRUE,ci=TRUE,print.auc=TRUE,main="ROC-Kurve f?r den SUVmax")
> The ROC-curve I got is ok, but on the x-axis I got a specificity from 150% to -50%, but I want the scale from 100% to 0% (as usual).
> xlim=c(100,0) doesn't work.
> Can someone help me?

Perhaps if we had data that allowed investigation, we might be able to help, but the example dataset on the help page shows `plot.roc` to be delivering expected results.

>  
> Best regards
> M.Enzian
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From t@n@@@ @ending from gm@il@com  Wed Jul 25 02:48:43 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Tue, 24 Jul 2018 17:48:43 -0700
Subject: [R] coloring edges in IGRAPH
Message-ID: <CA+JEM01Sfz4yPnvsD+x2i77iq9n__WSF6a0QLg8uDy7TduDrhg@mail.gmail.com>

Dear all,

I would appreciate a piece of advice please : I am aiming to color the
edges in a graph, by using IGRAPH package.

It works well for the big braph, however, when I decompose the graph into 2
subgraphs and color code those, the color of the edges change
(unexpectedly).

more precisely, as an example -- we have a dataframe :

el <- data.frame(Partner1=c(1, 3, 4, 5, 6), Partner2=c(2, 2, 5, 7, 7),
TYPE=c("DEL", "DEL", "DUP", "TRA", "TRA"))

el$COLOR[el$TYPE=="DEL"] <- "red"

el$COLOR[el$TYPE=="DUP"] <- "green"

el$COLOR[el$TYPE=="INS"] <- "yellow"

el$COLOR[el$TYPE=="INV"] <- "brown"

el$COLOR[el$TYPE=="TRA"] <- "blue"

#> el
#  Partner1 Partner2 TYPE COLOR
#1        1        2  DEL   red
#2        3        2  DEL   red
#3        4        5  DUP green
#4        5        7  TRA  blue
#5        6        7  TRA  blue

g <- graph_from_data_frame(d = el, directed = TRUE)

plot(g, edge.color=el$COLOR)

### here decomposing the graph into 2 SUBGRAPHS :

g_decompose <- decompose.graph(g)

plot(g_decompose[[1]], edge.color=el$COLOR) ## here the edges are red (that
is fine)

plot(g_decompose[[2]], edge.color=el$COLOR) ## here the edges shall be blue
and green, not red and green .

#####################################################

many thanks !

-- bogdan

	[[alternative HTML version deleted]]


From t@n@@@ @ending from gm@il@com  Wed Jul 25 04:34:46 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Tue, 24 Jul 2018 19:34:46 -0700
Subject: [R] coloring edges in IGRAPH
In-Reply-To: <CA+JEM01Sfz4yPnvsD+x2i77iq9n__WSF6a0QLg8uDy7TduDrhg@mail.gmail.com>
References: <CA+JEM01Sfz4yPnvsD+x2i77iq9n__WSF6a0QLg8uDy7TduDrhg@mail.gmail.com>
Message-ID: <CA+JEM01qUY-2sCztMLYEyd60OWCwqdyRKVZyZoLod8iGD8MTVg@mail.gmail.com>

Thank you all. Think I did solve it by using the code below :

plot(g_decompose[[1]], edge.color=edge_attr(g_decompose[[1]])$COLOR)

plot(g_decompose[[2]], edge.color=edge_attr(g_decompose[[2]])$COLOR)

On Tue, Jul 24, 2018 at 5:48 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all,
>
> I would appreciate a piece of advice please : I am aiming to color the
> edges in a graph, by using IGRAPH package.
>
> It works well for the big braph, however, when I decompose the graph into
> 2 subgraphs and color code those, the color of the edges change
> (unexpectedly).
>
> more precisely, as an example -- we have a dataframe :
>
> el <- data.frame(Partner1=c(1, 3, 4, 5, 6), Partner2=c(2, 2, 5, 7, 7),
> TYPE=c("DEL", "DEL", "DUP", "TRA", "TRA"))
>
> el$COLOR[el$TYPE=="DEL"] <- "red"
>
> el$COLOR[el$TYPE=="DUP"] <- "green"
>
> el$COLOR[el$TYPE=="INS"] <- "yellow"
>
> el$COLOR[el$TYPE=="INV"] <- "brown"
>
> el$COLOR[el$TYPE=="TRA"] <- "blue"
>
> #> el
> #  Partner1 Partner2 TYPE COLOR
> #1        1        2  DEL   red
> #2        3        2  DEL   red
> #3        4        5  DUP green
> #4        5        7  TRA  blue
> #5        6        7  TRA  blue
>
> g <- graph_from_data_frame(d = el, directed = TRUE)
>
> plot(g, edge.color=el$COLOR)
>
> ### here decomposing the graph into 2 SUBGRAPHS :
>
> g_decompose <- decompose.graph(g)
>
> plot(g_decompose[[1]], edge.color=el$COLOR) ## here the edges are red
> (that is fine)
>
> plot(g_decompose[[2]], edge.color=el$COLOR) ## here the edges shall be
> blue and green, not red and green .
>
> #####################################################
>
> many thanks !
>
> -- bogdan
>
>

	[[alternative HTML version deleted]]


From n@re@h_gurbux@ni @ending from hotm@il@com  Wed Jul 25 08:17:18 2018
From: n@re@h_gurbux@ni @ending from hotm@il@com (Naresh Gurbuxani)
Date: Wed, 25 Jul 2018 06:17:18 +0000
Subject: [R] Using apply function to merge list of data frames
Message-ID: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>

I have a list whose components are data frames.  My goal is to construct a data frame by merging all the list components.  Is it possible to achieve this using apply and without a for loop, as used below?

Thanks,
Naresh

mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
                                  length.out = 5), ret = rnorm(5)),
               B = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
                                  length.out = 5), ret = rnorm(5)))
 
mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week', length.out = 5))
 
for(ch in names(mylist)){
    tempdf <- mylist[[ch]]
    names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
    mydf <- merge(mydf, tempdf, by = c('date'))}

From bhh @ending from x@4@ll@nl  Wed Jul 25 08:32:52 2018
From: bhh @ending from x@4@ll@nl (Berend Hasselman)
Date: Wed, 25 Jul 2018 08:32:52 +0200
Subject: [R] Using apply function to merge list of data frames
In-Reply-To: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
References: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
Message-ID: <03B6FB5E-E21C-4211-8B8B-FC681C641C57@xs4all.nl>



> On 25 Jul 2018, at 08:17, Naresh Gurbuxani <naresh_gurbuxani at hotmail.com> wrote:
> 
> I have a list whose components are data frames.  My goal is to construct a data frame by merging all the list components.  Is it possible to achieve this using apply and without a for loop, as used below?
> 
> Thanks,
> Naresh
> 
> mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
>                                  length.out = 5), ret = rnorm(5)),
>               B = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
>                                  length.out = 5), ret = rnorm(5)))
> 
> mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week', length.out = 5))
> 
> for(ch in names(mylist)){
>    tempdf <- mylist[[ch]]
>    names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
>    mydf <- merge(mydf, tempdf, by = c('date'))}
> _

See if these would help:

on R-help the thread

https://stat.ethz.ch/pipermail/r-help/2018-May/454249.html

and 

https://stackoverflow.com/questions/4512465/what-is-the-most-efficient-way-to-cast-a-list-as-a-data-frame?rq=1

Berend


From t@n@@@ @ending from gm@il@com  Wed Jul 25 08:55:10 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Tue, 24 Jul 2018 23:55:10 -0700
Subject: [R] initiate elements in a dataframe with lists
Message-ID: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>

Dear all,

assuming that I do have a dataframe like :

x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
POSA=c(10, 15, 120, 340, 100, 220),
CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
POSB=c(30, 100, 300, 20, 200, 320)) ,

how could I initiate another 2 columns in x, where each element in these 2
columns is going to be a list (the list could be updated later). Thank you !

Shall I do,

for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}

for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}

nothing is happening. Thank you very much !

	[[alternative HTML version deleted]]


From jtelleri@@rproject @ending from gm@il@com  Wed Jul 25 09:56:40 2018
From: jtelleri@@rproject @ending from gm@il@com (Juan Telleria Ruiz de Aguirre)
Date: Wed, 25 Jul 2018 09:56:40 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
Message-ID: <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>

Check tidyverse's purrr package:

https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf

In the second page of the cheatsheet there is info on how to create list
columns within a data.frame :)

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Wed Jul 25 09:26:30 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Wed, 25 Jul 2018 09:26:30 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
Message-ID: <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>

Dear Bogdan,

You are looking for x$intersectA <- vector("list", nrow(x))

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:

> Dear all,
>
> assuming that I do have a dataframe like :
>
> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
> POSA=c(10, 15, 120, 340, 100, 220),
> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
> POSB=c(30, 100, 300, 20, 200, 320)) ,
>
> how could I initiate another 2 columns in x, where each element in these 2
> columns is going to be a list (the list could be updated later). Thank you
> !
>
> Shall I do,
>
> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>
> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>
> nothing is happening. Thank you very much !
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@l@ndr@ @ending from rgzm@de  Wed Jul 25 10:23:55 2018
From: c@l@ndr@ @ending from rgzm@de (Ivan Calandra)
Date: Wed, 25 Jul 2018 10:23:55 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
Message-ID: <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>

Just for my understanding:
Is a data.frame with list columns still a data.frame? Isn't it then a list?

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 25/07/2018 09:56, Juan Telleria Ruiz de Aguirre wrote:
> Check tidyverse's purrr package:
>
> https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf
>
> In the second page of the cheatsheet there is info on how to create list
> columns within a data.frame :)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jtelleri@@rproject @ending from gm@il@com  Wed Jul 25 11:56:05 2018
From: jtelleri@@rproject @ending from gm@il@com (Juan Telleria Ruiz de Aguirre)
Date: Wed, 25 Jul 2018 11:56:05 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
Message-ID: <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>

> Just for my understanding:
> Is a data.frame with list columns still a data.frame? Isn't it then a list?

* A data.frame (or tibble) is a list of columns.
* In which each column must be from the same data type, in this case list().


From jtelleri@@rproject @ending from gm@il@com  Wed Jul 25 11:58:23 2018
From: jtelleri@@rproject @ending from gm@il@com (Juan Telleria Ruiz de Aguirre)
Date: Wed, 25 Jul 2018 11:58:23 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
 <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
Message-ID: <CAJXDcw3zr8ZV67LMq3AhYtKdq8As0=tHjHAwm6uUmTaj2KPt2g@mail.gmail.com>

By the way, this also works:

dfl <- data.frame(x = 1:3, y = I(list(1:2, 1:3, 1:4)))

As indicated in "Advanced R" book:
http://adv-r.had.co.nz/Data-structures.html#data-frames


From c@l@ndr@ @ending from rgzm@de  Wed Jul 25 12:09:18 2018
From: c@l@ndr@ @ending from rgzm@de (Ivan Calandra)
Date: Wed, 25 Jul 2018 12:09:18 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
 <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
Message-ID: <41f55760-2a47-1a31-1d6e-dbee7d93d8cf@rgzm.de>

At first I was actually thinking about this situation, which cannot work:|
data.frame(x = 1:3, y = list(1:2, 1:3, 1:4))

|But I had never thought about this:|
df$y <-list(1:2, 1:3, 1:4)|
And it actually makes sense. The final requirement here is that all 
columns must have the same length!

I'm not sure though why one would need that. Why not use lists in that case?

Thanks!
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 25/07/2018 11:56, Juan Telleria Ruiz de Aguirre wrote:
>> Just for my understanding:
>> Is a data.frame with list columns still a data.frame? Isn't it then a list?
> * A data.frame (or tibble) is a list of columns.
> * In which each column must be from the same data type, in this case list().
>


	[[alternative HTML version deleted]]


From toth@dene@ @ending from kogentum@hu  Wed Jul 25 12:41:57 2018
From: toth@dene@ @ending from kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Wed, 25 Jul 2018 12:41:57 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
Message-ID: <d4daeb99-b5af-5f60-2364-f16bcdbad21e@kogentum.hu>



On 07/25/2018 10:23 AM, Ivan Calandra wrote:
> Just for my understanding:
> Is a data.frame with list columns still a data.frame? Isn't it then a list?

A data.frame is a list of equally sized vectors - that is, each vector 
must be of the same length. It is not required that the vector is an 
atomic vector; it can be a list, too. By having equally sized vectors in 
a list you can arrange the list in a two-dimensional matrix-like format, 
append row names to them, and you get a data.frame.

Principally data.frame(x = 1:3, y = list(1:2, 1:3, 1:4)) should work, 
but it doesn't, as it was recognized by others, too:
https://stackoverflow.com/questions/9547518/create-a-data-frame-where-a-column-is-a-list

Cheers,
Denes


> 
> Ivan
> 
> -- 
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> On 25/07/2018 09:56, Juan Telleria Ruiz de Aguirre wrote:
>> Check tidyverse's purrr package:
>>
>> https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf
>>
>> In the second page of the cheatsheet there is info on how to create list
>> columns within a data.frame :)
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tembe-@t@@@sio-dz m@ili@g off y@u@jp  Wed Jul 25 13:21:55 2018
From: tembe-@t@@@sio-dz m@ili@g off y@u@jp (tembe-@t@@@sio-dz m@ili@g off y@u@jp)
Date: Wed, 25 Jul 2018 11:21:55 +0000
Subject: [R] Query on convergence
Message-ID: <TYAPR01MB28770550B08A333260C13865C7540@TYAPR01MB2877.jpnprd01.prod.outlook.com>

Hello,



Is there somebody who can demonstrate how to code a while loop that ends when a convergence between the values of two or more variables (say vectors) is reached? Thank you

Regards


	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Wed Jul 25 13:55:53 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Wed, 25 Jul 2018 11:55:53 +0000
Subject: [R] Query on convergence
In-Reply-To: <TYAPR01MB28770550B08A333260C13865C7540@TYAPR01MB2877.jpnprd01.prod.outlook.com>
References: <TYAPR01MB28770550B08A333260C13865C7540@TYAPR01MB2877.jpnprd01.prod.outlook.com>
Message-ID: <87534a1c43f64322ba270ae8b3680c98@SRVEXCHCM1302.precheza.cz>

Hi

maybe

ii<-TRUE
while(ii) {

do something
if(some condition of two variables is met) {ii <- FALSE}

}

But in R such constructions are seldom necessary.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of tembe-
> atanasio-dz at ynu.jp
> Sent: Wednesday, July 25, 2018 1:22 PM
> To: r-help at r-project.org
> Subject: [R] Query on convergence
>
> Hello,
>
>
>
> Is there somebody who can demonstrate how to code a while loop that ends
> when a convergence between the values of two or more variables (say vectors)
> is reached? Thank you
>
> Regards
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From t@n@@@ @ending from gm@il@com  Wed Jul 25 14:53:37 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 05:53:37 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
Message-ID: <CA+JEM01Bjbb_3Fg-D0VRPp-APjJy-cGH+eHWEBUWaTGyY0ziSQ@mail.gmail.com>

Thank you Juan.

On Wed, Jul 25, 2018 at 12:56 AM, Juan Telleria Ruiz de Aguirre <
jtelleria.rproject at gmail.com> wrote:

> Check tidyverse's purrr package:
>
> https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf
>
> In the second page of the cheatsheet there is info on how to create list
> columns within a data.frame :)
>

	[[alternative HTML version deleted]]


From t@n@@@ @ending from gm@il@com  Wed Jul 25 15:26:12 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 06:26:12 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
Message-ID: <CA+JEM00HJeoK+oAC6GC0i5ssjC-jpyW1HUZmqpuLExFq8v0UCQ@mail.gmail.com>

Dear Thierry and Juan, thank you for your help. Thank you very much.

Now, if I would like to add an element to the empty list, how shall I do :
for example, shall i = 2, and j = 1, in a bit of more complex R code :

x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
POSA=c(10, 15, 120, 340, 100, 220),
CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
POSB=c(30, 100, 300, 20, 200, 320))

x$labA <- paste(x$CHRA, x$POSA, sep="_")
x$labB <- paste(x$CHRB, x$POSB, sep="_")

x$POSA_left <- x$POSA - 10
x$POSA_right <- x$POSA + 10

x$POSB_left <- x$POSB - 10
x$POSB_right <- x$POSB + 10

x$intersectA <- rep(list(list()), nrow(x))
x$intersectB <- rep(list(list()), nrow(x))

And we know that for i = 2, and j = 1, the condition is TRUE :

i <- 2
j <- 1

if ( (x$CHRA[i] == x$CHRA[j] ) &&
     (x$POSA[i] > x$POSA_left[j] ) &&
     (x$POSA[i] < x$POSA_right[j] ) )
{
   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])
}

the R code does not work. Thank you for your kind help !


>
> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Bogdan,
>>
>> You are looking for x$intersectA <- vector("list", nrow(x))
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>
>>> Dear all,
>>>
>>> assuming that I do have a dataframe like :
>>>
>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>> POSA=c(10, 15, 120, 340, 100, 220),
>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>
>>> how could I initiate another 2 columns in x, where each element in these
>>> 2
>>> columns is going to be a list (the list could be updated later). Thank
>>> you !
>>>
>>> Shall I do,
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>
>>> nothing is happening. Thank you very much !
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From huzef@@kh@lil @ending from umich@edu  Wed Jul 25 15:40:19 2018
From: huzef@@kh@lil @ending from umich@edu (Huzefa Khalil)
Date: Wed, 25 Jul 2018 09:40:19 -0400
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM00HJeoK+oAC6GC0i5ssjC-jpyW1HUZmqpuLExFq8v0UCQ@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
 <CA+JEM00HJeoK+oAC6GC0i5ssjC-jpyW1HUZmqpuLExFq8v0UCQ@mail.gmail.com>
Message-ID: <CADsG8gMMPqxqr4zbSE3X8dU9eaBtkLT02ZR3_9L_t+fatSZX6g@mail.gmail.com>

Hi Bogdan,

Does the following do what you expect?

x$intersectA[[i]] <- c(x$intersectA[[i]], x$labA[j])

Note the difference between `[[` and `[`


On Wed, Jul 25, 2018 at 9:26 AM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear Thierry and Juan, thank you for your help. Thank you very much.
>
> Now, if I would like to add an element to the empty list, how shall I do :
> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>
> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
> POSA=c(10, 15, 120, 340, 100, 220),
> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
> POSB=c(30, 100, 300, 20, 200, 320))
>
> x$labA <- paste(x$CHRA, x$POSA, sep="_")
> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>
> x$POSA_left <- x$POSA - 10
> x$POSA_right <- x$POSA + 10
>
> x$POSB_left <- x$POSB - 10
> x$POSB_right <- x$POSB + 10
>
> x$intersectA <- rep(list(list()), nrow(x))
> x$intersectB <- rep(list(list()), nrow(x))
>
> And we know that for i = 2, and j = 1, the condition is TRUE :
>
> i <- 2
> j <- 1
>
> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>      (x$POSA[i] > x$POSA_left[j] ) &&
>      (x$POSA[i] < x$POSA_right[j] ) )
> {
>    x$intersectA[i] <- c(x$intersectA[i], x$labA[j])
> }
>
> the R code does not work. Thank you for your kind help !
>
>
>>
>> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Bogdan,
>>>
>>> You are looking for x$intersectA <- vector("list", nrow(x))
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>>
>>>> Dear all,
>>>>
>>>> assuming that I do have a dataframe like :
>>>>
>>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>>> POSA=c(10, 15, 120, 340, 100, 220),
>>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>>
>>>> how could I initiate another 2 columns in x, where each element in these
>>>> 2
>>>> columns is going to be a list (the list could be updated later). Thank
>>>> you !
>>>>
>>>> Shall I do,
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>>
>>>> nothing is happening. Thank you very much !
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ev@n@kr@n@dorf @ending from gm@il@com  Wed Jul 25 16:35:26 2018
From: ev@n@kr@n@dorf @ending from gm@il@com (Evan Kransdorf)
Date: Wed, 25 Jul 2018 07:35:26 -0700
Subject: [R] DiagrammeR and grViz
Message-ID: <CAKZWb7dCdCm00-=QdHc1Wvo0SeZibruAACAGG5OLiv2n1wYmvg@mail.gmail.com>

Is anyone using DiagrammeR and grViz?

I made a nice grViz but when I use RStudio to export quality looks bad
(need high resolution figure).

I can't quite figure out how to use DiagrammeR to export the grViz I made.
Any suggestions?

Thank you, Evan

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 16:41:55 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 07:41:55 -0700 (PDT)
Subject: [R] A couple of batch mode questions
Message-ID: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>

   Within R one can use source() to run a batch file of R commands, while R CMD BATCH
and Rscript are run from the command line. Is this correct?

   Given these choices, when would I want to run a script within R using
source(), and when would it be better for me to run it from the command
line?

   Reading Appendix B.4 Scripting with R in R-info.pdf, ?Rscipt, and ?BATCH I
get the impression that 'R CMD BATCH' reads from a named file and writes
output to a named file and Rscript reads/writes to stdin/stdout using
redirection. What are the pros and cons of each? When (or why) would I
select one over the other?

TIA,

Rich


From bgunter@4567 @ending from gm@il@com  Wed Jul 25 16:47:59 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 25 Jul 2018 07:47:59 -0700
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>

"Within R one can use source() to run a batch file of R commands, while R
CMD BATCH
and Rscript are run from the command line. Is this correct?"

Yes.

I think your query answers your query: You use Rscript when you want to use
R in the command environment, perhaps as part of an analytical pipeline;
and you source an R file when you want to work within R.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 7:41 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   Within R one can use source() to run a batch file of R commands, while R
> CMD BATCH
> and Rscript are run from the command line. Is this correct?
>
>   Given these choices, when would I want to run a script within R using
> source(), and when would it be better for me to run it from the command
> line?
>
>   Reading Appendix B.4 Scripting with R in R-info.pdf, ?Rscipt, and ?BATCH
> I
> get the impression that 'R CMD BATCH' reads from a named file and writes
> output to a named file and Rscript reads/writes to stdin/stdout using
> redirection. What are the pros and cons of each? When (or why) would I
> select one over the other?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From HDor@n @ending from @ir@org  Wed Jul 25 16:57:13 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Wed, 25 Jul 2018 14:57:13 +0000
Subject: [R] SQL Database
Message-ID: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>

I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.

The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.

The sequence of work (I think) I just this:

Step 1: Connect to the remote server (connection string and authenticate the user)
Step 2: Have a SQL query statement that grabs the tables from the remote server 
Step 3: Close the connection

The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 

Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?

Thanks,
Harold


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 17:22:56 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 08:22:56 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Bert Gunter wrote:

> "Within R one can use source() to run a batch file of R commands, while R
> CMD BATCH and Rscript are run from the command line. Is this correct?"
>
> Yes.

Bert,

   Thanks for confirming.

> I think your query answers your query: You use Rscript when you want to use
> R in the command environment, perhaps as part of an analytical pipeline;
> and you source an R file when you want to work within R.

   That's a given. Why would I prefer Rscript over R CMD BATCH, or
vice-versa? I did not see much difference between the two in their help
files.

Regards,

Rich


From bgunter@4567 @ending from gm@il@com  Wed Jul 25 17:23:51 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 25 Jul 2018 08:23:51 -0700
Subject: [R] SQL Database
In-Reply-To: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbS7zemo90E8_daffGrWJ_fXFa_scxWMG8AjV8yJq9JtBQ@mail.gmail.com>

https://rviews.rstudio.com/2017/10/18/database-queries-with-r/

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 7:57 AM, Doran, Harold <HDoran at air.org> wrote:

> I'm doing some work now to learn which SQL database package is the most
> optimal for the task I am working on. There are many packages, and I'm
> reviewing the documentation on some of them now. I am seeking advice from
> those of you who might suggest a package to use for the task I am currently
> working with.
>
> The work is currently as follows. My users currently use another tool to
> extract tables from a server, save those tables as .csv files, and then
> those csv files are read into R and stuff is done on the data in those
> files. This adds overhead that can be bypassed if users instead can
> directly access the database from within R and grab the tables they need
> and then those tables are data frames in the R session and available to do
> stuff.
>
> The sequence of work (I think) I just this:
>
> Step 1: Connect to the remote server (connection string and authenticate
> the user)
> Step 2: Have a SQL query statement that grabs the tables from the remote
> server
> Step 3: Close the connection
>
> The two packages I have narrowed my studies to are Dbplyr and RODBC, both
> of which seem to be similar.
>
> Any experiences out there to suggest these two packages are in fact right
> for this task, or would there be other packages that might be more optimal
> for this?
>
> Thanks,
> Harold
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 17:37:58 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 08:37:58 -0700 (PDT)
Subject: [R] A couple of batch mode questions [ANSWERED]
In-Reply-To: <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807250836190.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Rich Shepard wrote:

>  That's a given. Why would I prefer Rscript over R CMD BATCH, or
> vice-versa? I did not see much difference between the two in their help
> files.

   Digging deeper into the Web I read that R CMD BATCH is an older approach
to automating R processing from the command line and Rscript is the newer
approach. My question's answered.

Rich


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jul 25 18:30:53 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 25 Jul 2018 09:30:53 -0700
Subject: [R] DiagrammeR and grViz
In-Reply-To: <CAKZWb7dCdCm00-=QdHc1Wvo0SeZibruAACAGG5OLiv2n1wYmvg@mail.gmail.com>
References: <CAKZWb7dCdCm00-=QdHc1Wvo0SeZibruAACAGG5OLiv2n1wYmvg@mail.gmail.com>
Message-ID: <D32D2BCE-DD28-40E4-B4E4-B0E30BBD3F05@dcn.davis.ca.us>

The Export option from the interactive Plots view is a terrible option for any publication-quality graphics.

There are many [1] ways to make publication-quality graphics in R, and there can be some operating-system-specific downstream tools considerations that affect what works best for you. I happen to prefer using Rmd/Rnw files (knitr+rmarkdown or knitr+latex) with png format in most cases. You can specify the default resolution/size as well as having special settings for specific images [2].

If this is all new to you, then you might want to read some of the many intros on the web, like [3][4].

[1] help(package="grDevices")
[2] https://yihui.name/knitr/options/#plots
[3] https://sachsmc.github.io/knit-git-markr-guide/knitr/knit.html
[4] https://rmarkdown.rstudio.com/articles_intro.html

On July 25, 2018 7:35:26 AM PDT, Evan Kransdorf <evan.kransdorf at gmail.com> wrote:
>Is anyone using DiagrammeR and grViz?
>
>I made a nice grViz but when I use RStudio to export quality looks bad
>(need high resolution figure).
>
>I can't quite figure out how to use DiagrammeR to export the grViz I
>made.
>Any suggestions?
>
>Thank you, Evan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@cqueen1 @ending from llnl@gov  Wed Jul 25 18:36:37 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 25 Jul 2018 16:36:37 +0000
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
Message-ID: <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>

From my perspective, which is a unix-alike perspective, Rscript makes R useable in exactly the same way as other unix style scripting languages such as perl,  tcsh, bash, etc. This is useful, and a good thing. If I remember (and understood) correctly, it is why Rscript was introduced, later in R's history than BATCH.

Scripts run using Rscript can be (slightly) more self-contained, which I suppose might or might not be an advantage, depending on one's needs:

To run an R script using Rscript, I type
   ./myRscript.r
at the command line (less typing), whereas with batch mode, it has to be
   R CMD BATCH myRscript.r
(more typing) but if I want any R options applied, such as --no-restore or --no-save, I include them within the script when using Rscript, but have to put them on the command line outside the script when using BATCH.

One can actually execute an R command at the shell prompt using Rscript, which can't be done with BATCH:

[296]% Rscript -e 3+4
[1] 7
[298]% Rscript -e 'sqrt(2)'
[1] 1.414214

If I want to pass custom parameters to the script (script-specific parameters of my own that I put on the command line), the syntax for either supplying them or parsing them might be different. I'm not sure, since I don't do this very often, and never use CMD BATCH. But it would be worth checking.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/25/18, 8:22 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Wed, 25 Jul 2018, Bert Gunter wrote:
    
    > "Within R one can use source() to run a batch file of R commands, while R
    > CMD BATCH and Rscript are run from the command line. Is this correct?"
    >
    > Yes.
    
    Bert,
    
       Thanks for confirming.
    
    > I think your query answers your query: You use Rscript when you want to use
    > R in the command environment, perhaps as part of an analytical pipeline;
    > and you source an R file when you want to work within R.
    
       That's a given. Why would I prefer Rscript over R CMD BATCH, or
    vice-versa? I did not see much difference between the two in their help
    files.
    
    Regards,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From t@n@@@ @ending from gm@il@com  Wed Jul 25 15:21:08 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 06:21:08 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
Message-ID: <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>

Dear Thierry and Juan, thank you for your help. Thank you all.

Now, if I would like to add an element to the empty list, how shall I do :
for example, shall i = 2, and j = 1, in a bit of more complex R code :

x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
POSA=c(10, 15, 120, 340, 100, 220),
CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
POSB=c(30, 100, 300, 20, 200, 320))

x$labA <- paste(x$CHRA, x$POSA, sep="_")
x$labB <- paste(x$CHRB, x$POSB, sep="_")

x$POSA_left <- x$POSA - 10
x$POSA_right <- x$POSA + 10

x$POSB_left <- x$POSB - 10
x$POSB_right <- x$POSB + 10

x$intersectA <- rep(list(list()), nrow(x))
x$intersectB <- rep(list(list()), nrow(x))

And we know that for i = 2, and j = 1, the condition is TRUE :

i <- 2

j <- 1

if ( (x$CHRA[i] == x$CHRA[j] ) &&
     (x$POSA[i] > x$POSA_left[j] ) &&
     (x$POSA[i] < x$POSA_right[j] ) ){
   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}

the R code does not work. Thank you for your kind help !

On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Bogdan,
>
> You are looking for x$intersectA <- vector("list", nrow(x))
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>
>> Dear all,
>>
>> assuming that I do have a dataframe like :
>>
>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>> POSA=c(10, 15, 120, 340, 100, 220),
>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>
>> how could I initiate another 2 columns in x, where each element in these 2
>> columns is going to be a list (the list could be updated later). Thank
>> you !
>>
>> Shall I do,
>>
>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>
>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>
>> nothing is happening. Thank you very much !
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From n4fbz @ending from t@mp@b@y@rr@com  Wed Jul 25 19:11:55 2018
From: n4fbz @ending from t@mp@b@y@rr@com (Robert D. Bowers M.A.)
Date: Wed, 25 Jul 2018 13:11:55 -0400
Subject: [R] Formatting multi-way ANOVA output for spectra analysis
Message-ID: <7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>

I've studied R a little bit, although I haven't used it in some time 
(except via RCommander).? I'm working on my dissertation project and 
have spectrometer data that I need to evaluate.? I need to find a way to 
simplify the output from multi-way ANOVA so I can reduce the areas of 
the spectrum to only those where there are significant differences 
between sites.? (A preliminary study on a too-small sample size 
indicates that certain areas of the spectrum can distinguish between 
sites.? This project is the next step.)

The dataset is comprised of analyses done on samples from five separate 
locations, with 50 samples taken from each site.? The output of the 
spectrometer per sample is values for 2048 individual wavelengths, in a 
spreadsheet with the wavelength as the first column.? Since I'm doing 
the analysis wavelength-by-wavelength, I've transposed the data and 
broke the data for the project down into smaller spreadsheets (so that R 
can perform ANOVA on each wavelength).

The problem is, I can do ANOVA now on each wavelength, but I don't need 
a full output table for each... I just need to know if there is 
significant variation between any of the sites at that wavelength, based 
on 95% confidence level (or better).? If I could get some sort of simple 
chart (or a single line in a spreadsheet), that would help to narrow 
down the areas of the spectrum that I need to focus on to evaluate the 
results of the tests.

I've been reading information about ANOVA, but have found very little 
that is clear about formatting the output - and I don't need to rehash 
all of the math.? I just need to find out how to hack down the output to 
just the part I need (if possible).? Once that's done, I can decide what 
wavelengths are valuable for future tests and simplify the process.

Thanks for any help given!

Bob


From ericjberger @ending from gm@il@com  Wed Jul 25 19:28:01 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 25 Jul 2018 20:28:01 +0300
Subject: [R] A couple of batch mode questions
In-Reply-To: <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
Message-ID: <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>

Some additional comments that might be relevant to people interested in
these topics.

1. For R scripts you should also consider the package littler developed by
Dirk Eddelbuettel, Highly recommended.
For info http://dirk.eddelbuettel.com/code/littler.html or the github
repository.

2. Scripts can be useful both for short calculations, extending the shell,
or for large R jobs that are not interactive and can run unsupervised.
e.g. I have a script that is run automatically on a daily schedule. It
performs a number of calculations and updates a database with the results.

3. When creating a large-ish R project that will run as a script, I still
break the task into smaller tasks which are implemented as R scripts which
are source()'ed into the batch job.
The smaller R scripts are usually developed and debugged in an interactive
environment, such as RStudio.

Best,
Eric


On Wed, Jul 25, 2018 at 7:36 PM, MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> From my perspective, which is a unix-alike perspective, Rscript makes R
> useable in exactly the same way as other unix style scripting languages
> such as perl,  tcsh, bash, etc. This is useful, and a good thing. If I
> remember (and understood) correctly, it is why Rscript was introduced,
> later in R's history than BATCH.
>
> Scripts run using Rscript can be (slightly) more self-contained, which I
> suppose might or might not be an advantage, depending on one's needs:
>
> To run an R script using Rscript, I type
>    ./myRscript.r
> at the command line (less typing), whereas with batch mode, it has to be
>    R CMD BATCH myRscript.r
> (more typing) but if I want any R options applied, such as --no-restore or
> --no-save, I include them within the script when using Rscript, but have to
> put them on the command line outside the script when using BATCH.
>
> One can actually execute an R command at the shell prompt using Rscript,
> which can't be done with BATCH:
>
> [296]% Rscript -e 3+4
> [1] 7
> [298]% Rscript -e 'sqrt(2)'
> [1] 1.414214
>
> If I want to pass custom parameters to the script (script-specific
> parameters of my own that I put on the command line), the syntax for either
> supplying them or parsing them might be different. I'm not sure, since I
> don't do this very often, and never use CMD BATCH. But it would be worth
> checking.
>
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 7/25/18, 8:22 AM, "R-help on behalf of Rich Shepard" <
> r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:
>
>     On Wed, 25 Jul 2018, Bert Gunter wrote:
>
>     > "Within R one can use source() to run a batch file of R commands,
> while R
>     > CMD BATCH and Rscript are run from the command line. Is this
> correct?"
>     >
>     > Yes.
>
>     Bert,
>
>        Thanks for confirming.
>
>     > I think your query answers your query: You use Rscript when you want
> to use
>     > R in the command environment, perhaps as part of an analytical
> pipeline;
>     > and you source an R file when you want to work within R.
>
>        That's a given. Why would I prefer Rscript over R CMD BATCH, or
>     vice-versa? I did not see much difference between the two in their help
>     files.
>
>     Regards,
>
>     Rich
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jul 25 19:43:52 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 25 Jul 2018 10:43:52 -0700 (PDT)
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>

The code below reeks of a misconception that lists are efficient to add 
items to, which is a confusion with the computer science term "linked 
list".  In R, a list is NOT a linked list... it is a vector, which means 
the memory used by the list is allocated at the time it is created, and 
REALLOCATED when a new item is added. The only reason you should use a 
list is because you expect to put values of different types or shapes into 
it, which does not appear to apply in this use case.

In R, you should make a valiant effort to create things right the first 
time, and if that doesn't work then preallocate the space you will need in 
the vectors you are working with. Since you have a need to store a 
variable number of elements in each intersectX element, the column needs 
to be a list but the elements of that list can perfectly well be character 
vectors.

x <- data.frame( TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA")
                , CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2")
                , POSA=c(10, 15, 120, 340, 100, 220)
                , CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1")
                , POSB=c(30, 100, 300, 20, 200, 320)
                , stringsAsFactors = FALSE
                )
compareRng <- function( chr1, pos1, chr2, pos2, delta ) {
   ( chr1 == chr2
   & ( pos2 - delta ) < pos1
   & pos1 < ( pos2 + delta )
   )
}
makeIntersectX <- function( n, chrlabel, poslabel, delta ) {
   lgclidx <- rep( TRUE, nrow( x ) )
   lgclidx[ n ] <- FALSE
   x[[ chrlabel ]][ compareRng( x[[ chrlabel ]][ n ]
                     , x[[ poslabel ]][ n ]
                     , x[[ chrlabel ]]
                     , x[[ poslabel ]]
                     , delta
                     )
         & lgclidx
         ]
}

x$intersectA <- lapply( seq.int( nrow( x ) )
                       , makeIntersectX
                       , chrlabel = "CHRA"
                       , poslabel = "POSA"
                       , delta = 10L
                       )
x$intersectB <- lapply( seq.int( nrow( x ) )
                       , makeIntersectX
                       , chrlabel = "CHRB"
                       , poslabel = "POSB"
                       , delta = 21L
                       )
> x
   TYPE CHRA POSA CHRB POSB intersectA intersectB
1  DEL chr1   10 chr1   30       chr1
2  DEL chr1   15 chr1  100       chr1
3  DUP chr1  120 chr1  300                  chr1
4  TRA chr1  340 chr2   20
5  INV chr2  100 chr2  200
6  TRA chr2  220 chr1  320                  chr1

Note that depending on what you plan to do beyond this point, it might 
actually be more performant to use a data frame with repeated rows instead 
of list columns... but I cannot tell from what you have provided.

On Wed, 25 Jul 2018, Bogdan Tanasa wrote:

> Dear Thierry and Juan, thank you for your help. Thank you all.
>
> Now, if I would like to add an element to the empty list, how shall I do :
> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>
> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
> POSA=c(10, 15, 120, 340, 100, 220),
> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
> POSB=c(30, 100, 300, 20, 200, 320))
>
> x$labA <- paste(x$CHRA, x$POSA, sep="_")
> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>
> x$POSA_left <- x$POSA - 10
> x$POSA_right <- x$POSA + 10
>
> x$POSB_left <- x$POSB - 10
> x$POSB_right <- x$POSB + 10
>
> x$intersectA <- rep(list(list()), nrow(x))
> x$intersectB <- rep(list(list()), nrow(x))
>
> And we know that for i = 2, and j = 1, the condition is TRUE :
>
> i <- 2
>
> j <- 1
>
> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>     (x$POSA[i] > x$POSA_left[j] ) &&
>     (x$POSA[i] < x$POSA_right[j] ) ){
>   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}
>
> the R code does not work. Thank you for your kind help !
>
> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
>> wrote:
>
>> Dear Bogdan,
>>
>> You are looking for x$intersectA <- vector("list", nrow(x))
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>
>>> Dear all,
>>>
>>> assuming that I do have a dataframe like :
>>>
>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>> POSA=c(10, 15, 120, 340, 100, 220),
>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>
>>> how could I initiate another 2 columns in x, where each element in these 2
>>> columns is going to be a list (the list could be updated later). Thank
>>> you !
>>>
>>> Shall I do,
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>
>>> nothing is happening. Thank you very much !
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From t@n@@@ @ending from gm@il@com  Wed Jul 25 19:58:28 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 10:58:28 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
 <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM01KdYDdbMBMxsLeKRHOZqg8PV4BVOKO73TiAzo5K=P-pQ@mail.gmail.com>

Dear Jeff, it is a precious help and a fabulous suggestion. I will slowly
go over the R code that you have sent. Thanks a lot !

On Wed, Jul 25, 2018 at 10:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The code below reeks of a misconception that lists are efficient to add
> items to, which is a confusion with the computer science term "linked
> list".  In R, a list is NOT a linked list... it is a vector, which means
> the memory used by the list is allocated at the time it is created, and
> REALLOCATED when a new item is added. The only reason you should use a list
> is because you expect to put values of different types or shapes into it,
> which does not appear to apply in this use case.
>
> In R, you should make a valiant effort to create things right the first
> time, and if that doesn't work then preallocate the space you will need in
> the vectors you are working with. Since you have a need to store a variable
> number of elements in each intersectX element, the column needs to be a
> list but the elements of that list can perfectly well be character vectors.
>
> x <- data.frame( TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA")
>                , CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2")
>                , POSA=c(10, 15, 120, 340, 100, 220)
>                , CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1")
>                , POSB=c(30, 100, 300, 20, 200, 320)
>                , stringsAsFactors = FALSE
>                )
> compareRng <- function( chr1, pos1, chr2, pos2, delta ) {
>   ( chr1 == chr2
>   & ( pos2 - delta ) < pos1
>   & pos1 < ( pos2 + delta )
>   )
> }
> makeIntersectX <- function( n, chrlabel, poslabel, delta ) {
>   lgclidx <- rep( TRUE, nrow( x ) )
>   lgclidx[ n ] <- FALSE
>   x[[ chrlabel ]][ compareRng( x[[ chrlabel ]][ n ]
>                     , x[[ poslabel ]][ n ]
>                     , x[[ chrlabel ]]
>                     , x[[ poslabel ]]
>                     , delta
>                     )
>         & lgclidx
>         ]
> }
>
> x$intersectA <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRA"
>                       , poslabel = "POSA"
>                       , delta = 10L
>                       )
> x$intersectB <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRB"
>                       , poslabel = "POSB"
>                       , delta = 21L
>                       )
>
>> x
>>
>   TYPE CHRA POSA CHRB POSB intersectA intersectB
> 1  DEL chr1   10 chr1   30       chr1
> 2  DEL chr1   15 chr1  100       chr1
> 3  DUP chr1  120 chr1  300                  chr1
> 4  TRA chr1  340 chr2   20
> 5  INV chr2  100 chr2  200
> 6  TRA chr2  220 chr1  320                  chr1
>
> Note that depending on what you plan to do beyond this point, it might
> actually be more performant to use a data frame with repeated rows instead
> of list columns... but I cannot tell from what you have provided.
>
>
> On Wed, 25 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Thierry and Juan, thank you for your help. Thank you all.
>>
>> Now, if I would like to add an element to the empty list, how shall I do :
>> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>>
>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>> POSA=c(10, 15, 120, 340, 100, 220),
>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>> POSB=c(30, 100, 300, 20, 200, 320))
>>
>> x$labA <- paste(x$CHRA, x$POSA, sep="_")
>> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>>
>> x$POSA_left <- x$POSA - 10
>> x$POSA_right <- x$POSA + 10
>>
>> x$POSB_left <- x$POSB - 10
>> x$POSB_right <- x$POSB + 10
>>
>> x$intersectA <- rep(list(list()), nrow(x))
>> x$intersectB <- rep(list(list()), nrow(x))
>>
>> And we know that for i = 2, and j = 1, the condition is TRUE :
>>
>> i <- 2
>>
>> j <- 1
>>
>> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>>     (x$POSA[i] > x$POSA_left[j] ) &&
>>     (x$POSA[i] < x$POSA_right[j] ) ){
>>   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}
>>
>> the R code does not work. Thank you for your kind help !
>>
>> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be
>>
>>> wrote:
>>>
>>
>> Dear Bogdan,
>>>
>>> You are looking for x$intersectA <- vector("list", nrow(x))
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND
>>> FOREST
>>> Team Biometrie &
>>> <https://maps.google.com/?q=Biometrie+%26+&entry=gmail&source=g>Kwaliteitszorg
>>> / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>>
>>> Dear all,
>>>>
>>>> assuming that I do have a dataframe like :
>>>>
>>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>>> POSA=c(10, 15, 120, 340, 100, 220),
>>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>>
>>>> how could I initiate another 2 columns in x, where each element in
>>>> these 2
>>>> columns is going to be a list (the list could be updated later). Thank
>>>> you !
>>>>
>>>> Shall I do,
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>>
>>>> nothing is happening. Thank you very much !
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Wed Jul 25 20:18:17 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Wed, 25 Jul 2018 11:18:17 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
 <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
Message-ID: <CAF8bMcYKTdmxs8Sxn9MtwzwYMPFyZOUwh-_uFdAZd2yzLihSfw@mail.gmail.com>

If you need to make a list of long but unknown length you can save time by
adding the items to an environment, with names giving the order, then
converting the environment to a list when you are done filling the
environment.  E.g.,

> makeData
function (container, n)
{
    for (i in seq_len(n)) container[[sprintf("%06x", i)]] <- seq_len(i%%5)
    container
}
> # use an environment
> system.time(E <- makeData(new.env(parent=emptyenv()), 10^5))
   user  system elapsed
   0.38    0.00    0.38
> # convert environment to a list
> system.time(EL <- as.list(E, sorted=TRUE))
   user  system elapsed
   0.62    0.00    0.62
> # use a list
> system.time(L <- makeData(list(), 10^5))
   user  system elapsed
 142.56    1.46  153.78
> all.equal(EL, L)
[1] TRUE


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jul 25, 2018 at 10:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The code below reeks of a misconception that lists are efficient to add
> items to, which is a confusion with the computer science term "linked
> list".  In R, a list is NOT a linked list... it is a vector, which means
> the memory used by the list is allocated at the time it is created, and
> REALLOCATED when a new item is added. The only reason you should use a list
> is because you expect to put values of different types or shapes into it,
> which does not appear to apply in this use case.
>
> In R, you should make a valiant effort to create things right the first
> time, and if that doesn't work then preallocate the space you will need in
> the vectors you are working with. Since you have a need to store a variable
> number of elements in each intersectX element, the column needs to be a
> list but the elements of that list can perfectly well be character vectors.
>
> x <- data.frame( TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA")
>                , CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2")
>                , POSA=c(10, 15, 120, 340, 100, 220)
>                , CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1")
>                , POSB=c(30, 100, 300, 20, 200, 320)
>                , stringsAsFactors = FALSE
>                )
> compareRng <- function( chr1, pos1, chr2, pos2, delta ) {
>   ( chr1 == chr2
>   & ( pos2 - delta ) < pos1
>   & pos1 < ( pos2 + delta )
>   )
> }
> makeIntersectX <- function( n, chrlabel, poslabel, delta ) {
>   lgclidx <- rep( TRUE, nrow( x ) )
>   lgclidx[ n ] <- FALSE
>   x[[ chrlabel ]][ compareRng( x[[ chrlabel ]][ n ]
>                     , x[[ poslabel ]][ n ]
>                     , x[[ chrlabel ]]
>                     , x[[ poslabel ]]
>                     , delta
>                     )
>         & lgclidx
>         ]
> }
>
> x$intersectA <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRA"
>                       , poslabel = "POSA"
>                       , delta = 10L
>                       )
> x$intersectB <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRB"
>                       , poslabel = "POSB"
>                       , delta = 21L
>                       )
>
>> x
>>
>   TYPE CHRA POSA CHRB POSB intersectA intersectB
> 1  DEL chr1   10 chr1   30       chr1
> 2  DEL chr1   15 chr1  100       chr1
> 3  DUP chr1  120 chr1  300                  chr1
> 4  TRA chr1  340 chr2   20
> 5  INV chr2  100 chr2  200
> 6  TRA chr2  220 chr1  320                  chr1
>
> Note that depending on what you plan to do beyond this point, it might
> actually be more performant to use a data frame with repeated rows instead
> of list columns... but I cannot tell from what you have provided.
>
> On Wed, 25 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Thierry and Juan, thank you for your help. Thank you all.
>>
>> Now, if I would like to add an element to the empty list, how shall I do :
>> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>>
>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>> POSA=c(10, 15, 120, 340, 100, 220),
>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>> POSB=c(30, 100, 300, 20, 200, 320))
>>
>> x$labA <- paste(x$CHRA, x$POSA, sep="_")
>> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>>
>> x$POSA_left <- x$POSA - 10
>> x$POSA_right <- x$POSA + 10
>>
>> x$POSB_left <- x$POSB - 10
>> x$POSB_right <- x$POSB + 10
>>
>> x$intersectA <- rep(list(list()), nrow(x))
>> x$intersectB <- rep(list(list()), nrow(x))
>>
>> And we know that for i = 2, and j = 1, the condition is TRUE :
>>
>> i <- 2
>>
>> j <- 1
>>
>> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>>     (x$POSA[i] > x$POSA_left[j] ) &&
>>     (x$POSA[i] < x$POSA_right[j] ) ){
>>   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}
>>
>> the R code does not work. Thank you for your kind help !
>>
>> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be
>>
>>> wrote:
>>>
>>
>> Dear Bogdan,
>>>
>>> You are looking for x$intersectA <- vector("list", nrow(x))
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND
>>> FOREST
>>> Team Biometrie &
>>> <https://maps.google.com/?q=Biometrie+%26+&entry=gmail&source=g>Kwaliteitszorg
>>> / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>>
>>> Dear all,
>>>>
>>>> assuming that I do have a dataframe like :
>>>>
>>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>>> POSA=c(10, 15, 120, 340, 100, 220),
>>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>>
>>>> how could I initiate another 2 columns in x, where each element in
>>>> these 2
>>>> columns is going to be a list (the list could be updated later). Thank
>>>> you !
>>>>
>>>> Shall I do,
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>>
>>>> nothing is happening. Thank you very much !
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 20:34:31 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 11:34:31 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
Message-ID: <alpine.LNX.2.20.1807251129360.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, MacQueen, Don wrote:

> From my perspective, which is a unix-alike perspective, Rscript makes R
> useable in exactly the same way as other unix style scripting languages
> such as perl, tcsh, bash, etc. This is useful, and a good thing. If I
> remember (and understood) correctly, it is why Rscript was introduced,
> later in R's history than BATCH.

Don,

   As a linux-only user for more than two decades I really appreciate the
value of running scripts from the command line. For a current project, after
extracting 29 years of data from PDF forms I ran them through a bash shell
script (passing the name of the source file as $1) that calls two sed and
six awk scripts. The output is ready to be read into R.

> If I want to pass custom parameters to the script (script-specific
> parameters of my own that I put on the command line), the syntax for
> either supplying them or parsing them might be different. I'm not sure,
> since I don't do this very often, and never use CMD BATCH. But it would be
> worth checking.

   This is what I need to work out now for Rscript: how to set positional or
named parameters on the command line with the source file name and the R
data.frame name.

   Thanks for your comments.

Best regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 20:41:42 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 11:41:42 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Eric Berger wrote:

> 1. For R scripts you should also consider the package littler developed by
> Dirk Eddelbuettel, Highly recommended. For info
> http://dirk.eddelbuettel.com/code/littler.html or the github repository.

Eric,

   I'll definintely look at that package.

> 2. Scripts can be useful both for short calculations, extending the shell,
> or for large R jobs that are not interactive and can run unsupervised.
> e.g. I have a script that is run automatically on a daily schedule. It
> performs a number of calculations and updates a database with the results.

   My immediate need is to import 30 data files, change factors into dates
and datetimes, print a summary, then plot a PDF scatterplot. This is why I
need to learn Rscript. I should be able to wrap that in a bash shell
script's for ... do loop that runs the Rscript for all *.dat files in the
directory.

Much appreciated,

Rich


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jul 25 21:17:48 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 25 Jul 2018 12:17:48 -0700
Subject: [R] Formatting multi-way ANOVA output for spectra analysis
In-Reply-To: <7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
References: <7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
Message-ID: <BB19452A-92B6-4B80-9031-074EA6A97E46@dcn.davis.ca.us>

In general, analysis functions in R return objects. When returned alone on an interactive console the default print method for that object gets printed. However, you can put it into a variable with the <- assignment operator, and use the str function to see what values are inside the object, and use the summary object to obtain another object with certain computed values depending on the analysis object. 

It might make sense to use a model analysis for this data... I don't know how you are handling variation in gross irradiance between measurements.

Anyway, this can get involved and you haven't provided sample data or code so this starts to get off topic (which is R, not statistics) pretty quick.


On July 25, 2018 10:11:55 AM PDT, "Robert D. Bowers M.A." <n4fbz at tampabay.rr.com> wrote:
>I've studied R a little bit, although I haven't used it in some time 
>(except via RCommander).? I'm working on my dissertation project and 
>have spectrometer data that I need to evaluate.? I need to find a way
>to 
>simplify the output from multi-way ANOVA so I can reduce the areas of 
>the spectrum to only those where there are significant differences 
>between sites.? (A preliminary study on a too-small sample size 
>indicates that certain areas of the spectrum can distinguish between 
>sites.? This project is the next step.)
>
>The dataset is comprised of analyses done on samples from five separate
>
>locations, with 50 samples taken from each site.? The output of the 
>spectrometer per sample is values for 2048 individual wavelengths, in a
>
>spreadsheet with the wavelength as the first column.? Since I'm doing 
>the analysis wavelength-by-wavelength, I've transposed the data and 
>broke the data for the project down into smaller spreadsheets (so that
>R 
>can perform ANOVA on each wavelength).
>
>The problem is, I can do ANOVA now on each wavelength, but I don't need
>
>a full output table for each... I just need to know if there is 
>significant variation between any of the sites at that wavelength,
>based 
>on 95% confidence level (or better).? If I could get some sort of
>simple 
>chart (or a single line in a spreadsheet), that would help to narrow 
>down the areas of the spectrum that I need to focus on to evaluate the 
>results of the tests.
>
>I've been reading information about ANOVA, but have found very little 
>that is clear about formatting the output - and I don't need to rehash 
>all of the math.? I just need to find out how to hack down the output
>to 
>just the part I need (if possible).? Once that's done, I can decide
>what 
>wavelengths are valuable for future tests and simplify the process.
>
>Thanks for any help given!
>
>Bob
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ericjberger @ending from gm@il@com  Wed Jul 25 21:48:03 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 25 Jul 2018 22:48:03 +0300
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
Message-ID: <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>

You should be able to do all this within R.
>From what you have written I don't see a compelling reason to use scripts
at the shell level.

Best,
Eric


On Wed, Jul 25, 2018 at 9:41 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 25 Jul 2018, Eric Berger wrote:
>
> 1. For R scripts you should also consider the package littler developed by
>> Dirk Eddelbuettel, Highly recommended. For info
>> http://dirk.eddelbuettel.com/code/littler.html or the github repository.
>>
>
> Eric,
>
>   I'll definintely look at that package.
>
> 2. Scripts can be useful both for short calculations, extending the shell,
>> or for large R jobs that are not interactive and can run unsupervised.
>> e.g. I have a script that is run automatically on a daily schedule. It
>> performs a number of calculations and updates a database with the results.
>>
>
>   My immediate need is to import 30 data files, change factors into dates
> and datetimes, print a summary, then plot a PDF scatterplot. This is why I
> need to learn Rscript. I should be able to wrap that in a bash shell
> script's for ... do loop that runs the Rscript for all *.dat files in the
> directory.
>
> Much appreciated,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 22:02:33 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 13:02:33 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
 <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Eric Berger wrote:

> You should be able to do all this within R. From what you have written I
> don't see a compelling reason to use scripts at the shell level.

Eric,

   The source() help page's last example calls a set of scripts to run
sequentially. I assume this is used to run the same .R script on each file,
with any file-specific variables used in each one. Perhaps I'm not seeing
how to pass parameters to the script call with source() so that the same .R
script can be automagically run for each imput file name. In my newness to
this it appears Rscript allows running the same script substituting inpu
file names based on arguments on the Rscript command line.

Regards,

Rich


From bgunter@4567 @ending from gm@il@com  Wed Jul 25 22:27:16 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 25 Jul 2018 13:27:16 -0700
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
 <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
 <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQ4t4mjpibt6Ph-ibrvUTuhPQT-06FXzKU6TrTFeg6sNA@mail.gmail.com>

Eric may have more to say, but the straightforward answer is: use functions
to do what you want and pass any file specific info to them as parameters
of function calls.

If this seems arcane to you, then you have some homework to do, as using
functions is a (maybe the) central programming paradigm in R. Numerous
tutorials elaborate on this.

If I have misunderstood, my apologies, and just disregard.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 1:02 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 25 Jul 2018, Eric Berger wrote:
>
> You should be able to do all this within R. From what you have written I
>> don't see a compelling reason to use scripts at the shell level.
>>
>
> Eric,
>
>   The source() help page's last example calls a set of scripts to run
> sequentially. I assume this is used to run the same .R script on each file,
> with any file-specific variables used in each one. Perhaps I'm not seeing
> how to pass parameters to the script call with source() so that the same .R
> script can be automagically run for each imput file name. In my newness to
> this it appears Rscript allows running the same script substituting inpu
> file names based on arguments on the Rscript command line.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 22:47:07 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 13:47:07 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGxFJbQ4t4mjpibt6Ph-ibrvUTuhPQT-06FXzKU6TrTFeg6sNA@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
 <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
 <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>
 <CAGxFJbQ4t4mjpibt6Ph-ibrvUTuhPQT-06FXzKU6TrTFeg6sNA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807251344570.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Bert Gunter wrote:

> Eric may have more to say, but the straightforward answer is: use
> functions to do what you want and pass any file specific info to them as
> parameters of function calls.

Bert,

   I was considering that functions would be the way to go. The functions can
call other functions in addition to doing calculations.

Thanks for re-inforcing that approach,

Rich


From j@ck@pincu@ @ending from @bcglob@l@net  Wed Jul 25 22:17:14 2018
From: j@ck@pincu@ @ending from @bcglob@l@net (Jack Pincus)
Date: Wed, 25 Jul 2018 20:17:14 +0000 (UTC)
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
Message-ID: <1998662715.2398959.1532549834780@mail.yahoo.com>

I just installed R 3.5.1 on a new Windows 10 computer.? R tries to set a personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.? I want to store R packages on my local hard drive, not OneDrive.? I tried placing the line of code:.libPaths(c(.libPaths(), "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile located in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize libraries in my personal library.? Any suggestions how to fix this problem.? Also, is there a reason that R tries to default to OneDrive in Windows 10.? I also had a OneDrive folder in Windows 8.1 but could set R to recognize a personal library on C:/Users/jackp/Documents.
Thanks in advance,
Jack
	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Jul 25 23:51:01 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 25 Jul 2018 14:51:01 -0700
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
In-Reply-To: <1998662715.2398959.1532549834780@mail.yahoo.com>
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
 <1998662715.2398959.1532549834780@mail.yahoo.com>
Message-ID: <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>

Pemissions settings on your target  directory (which is a Windows not an R
issue)??

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
wrote:

> I just installed R 3.5.1 on a new Windows 10 computer.  R tries to set a
> personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.  I
> want to store R packages on my local hard drive, not OneDrive.  I tried
> placing the line of code:.libPaths(c(.libPaths(),
> "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile located
> in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> libraries in my personal library.  Any suggestions how to fix this
> problem.  Also, is there a reason that R tries to default to OneDrive in
> Windows 10.  I also had a OneDrive folder in Windows 8.1 but could set R to
> recognize a personal library on C:/Users/jackp/Documents.
> Thanks in advance,
> Jack
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Jul 25 23:54:20 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 14:54:20 -0700 (PDT)
Subject: [R] Batch mode questions.
In-Reply-To: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
References: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Shawn Way wrote:

> To get you start, here's a script I used to combine any number of files
> into one data.frame.
>
> library(knitr)
> library(tidyverse)
> library(xlsx)
> library(xtable)
> library(lubridate)
>
> # create a list from these files
> list.filenames<-list.files(pattern=".CSV$")  # This gets a list of all CSV files
>
> data <- list.filenames %>%
>    map(read_csv) %>%  # This reads all the files in order
>    reduce(rbind)   # This combines the data into one data frame

   Thanks, Shawn. I'm reading up on functions and will look at using a
function within either a Rscript or source'd script.

   It's about time I learn to automate repeated, tedious tasks in R.

Much appreciated,

Rich


From dwin@emiu@ @ending from comc@@t@net  Thu Jul 26 01:14:29 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 25 Jul 2018 16:14:29 -0700
Subject: [R] Batch mode questions.
In-Reply-To: <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>
References: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>
Message-ID: <DF9E8649-7FFC-426C-B298-C1D02D954861@comcast.net>


> On Jul 25, 2018, at 2:54 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Wed, 25 Jul 2018, Shawn Way wrote:
> 
>> To get you start, here's a script I used to combine any number of files
>> into one data.frame.
>> 
>> library(knitr)
>> library(tidyverse)
>> library(xlsx)
>> library(xtable)
>> library(lubridate)
>> 
>> # create a list from these files
>> list.filenames<-list.files(pattern=".CSV$")  # This gets a list of all CSV files

It would get all the files with all caps "CSV" anywhere within the file name, but it would not get any files with an extension ".csv", nor would it exclude a file named "somethingCSV" . The pattern argument is interpreted as a regex pattern and the meaning of a period is different.

Better for this purpose would be:

list.files(pattern="\\.(csv|CSV)$")

I suppose this criticism might be platform-specific if the filesystem were caps-agnostic, but mine is not.

-- 
David.

>> 
>> data <- list.filenames %>%
>>   map(read_csv) %>%  # This reads all the files in order
>>   reduce(rbind)   # This combines the data into one data frame
> 
>  Thanks, Shawn. I'm reading up on functions and will look at using a
> function within either a Rscript or source'd script.
> 
>  It's about time I learn to automate repeated, tedious tasks in R.
> 
> Much appreciated,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 26 01:34:15 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 16:34:15 -0700 (PDT)
Subject: [R] Batch mode questions.
In-Reply-To: <DF9E8649-7FFC-426C-B298-C1D02D954861@comcast.net>
References: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>
 <DF9E8649-7FFC-426C-B298-C1D02D954861@comcast.net>
Message-ID: <alpine.LNX.2.20.1807251631560.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, David Winsemius wrote:

>>> # create a list from these files
>>> list.filenames<-list.files(pattern=".CSV$")  # This gets a list of all CSV files
>
> It would get all the files with all caps "CSV" anywhere within the file
> name, but it would not get any files with an extension ".csv", nor would
> it exclude a file named "somethingCSV" . The pattern argument is
> interpreted as a regex pattern and the meaning of a period is different.
>
> Better for this purpose would be:
>
> list.files(pattern="\\.(csv|CSV)$")
>
> I suppose this criticism might be platform-specific if the filesystem were
> caps-agnostic, but mine is not.

David,

   I saw that and noted that since linux separates meaning between upper- and
lower-case letters it would need to be modified is there were any *.CSV
files in the directory. Same type of problem occurs when file names have
spaces in them.

Regards,

Rich


From jfox @ending from mcm@@ter@c@  Thu Jul 26 04:07:26 2018
From: jfox @ending from mcm@@ter@c@ (Fox, John)
Date: Thu, 26 Jul 2018 02:07:26 +0000
Subject: [R] Formatting multi-way ANOVA output for spectra analysis
In-Reply-To: <5142_1532538741_w6PHCKRh023603_7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
References: <5142_1532538741_w6PHCKRh023603_7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83685C9A9@FHSDB2D11-2.csu.mcmaster.ca>

Dear Robert,

Although you don't say so, it sounds as if you may be using the Anova() function in the car package, which is what the R Commander uses for ANOVA. If so, in most cases, Anova() returns an object of class c("anova", "data.frame"), which can be manipulated as a data frame. To see this, try something like

str(Anova(your.model))

You should be able to extract, manipulate, and graph whatever components of the object interest you.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert D.
> Bowers M.A.
> Sent: Wednesday, July 25, 2018 1:12 PM
> To: r-help at r-project.org
> Subject: [R] Formatting multi-way ANOVA output for spectra analysis
> 
> I've studied R a little bit, although I haven't used it in some time (except via
> RCommander).? I'm working on my dissertation project and have
> spectrometer data that I need to evaluate.? I need to find a way to simplify the
> output from multi-way ANOVA so I can reduce the areas of the spectrum to
> only those where there are significant differences between sites.? (A
> preliminary study on a too-small sample size indicates that certain areas of
> the spectrum can distinguish between sites.? This project is the next step.)
> 
> The dataset is comprised of analyses done on samples from five separate
> locations, with 50 samples taken from each site.? The output of the
> spectrometer per sample is values for 2048 individual wavelengths, in a
> spreadsheet with the wavelength as the first column.? Since I'm doing the
> analysis wavelength-by-wavelength, I've transposed the data and broke the
> data for the project down into smaller spreadsheets (so that R can perform
> ANOVA on each wavelength).
> 
> The problem is, I can do ANOVA now on each wavelength, but I don't need a
> full output table for each... I just need to know if there is significant variation
> between any of the sites at that wavelength, based on 95% confidence level
> (or better).? If I could get some sort of simple chart (or a single line in a
> spreadsheet), that would help to narrow down the areas of the spectrum that I
> need to focus on to evaluate the results of the tests.
> 
> I've been reading information about ANOVA, but have found very little that is
> clear about formatting the output - and I don't need to rehash all of the
> math.? I just need to find out how to hack down the output to just the part I
> need (if possible).? Once that's done, I can decide what wavelengths are
> valuable for future tests and simplify the process.
> 
> Thanks for any help given!
> 
> Bob
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@echler @ending from @t@t@m@th@ethz@ch  Thu Jul 26 09:20:03 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 26 Jul 2018 09:20:03 +0200
Subject: [R] SQL Database
In-Reply-To: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <23385.30243.545008.60466@stat.math.ethz.ch>

>>>>> Doran, Harold 
>>>>>     on Wed, 25 Jul 2018 14:57:13 +0000 writes:

    > I'm doing some work now to learn which SQL database
    > package is the most optimal for the task I am working on.

Hmm... we would have a problem with optimize() and optim() if
this was

       optimal << more optimal << most optimal

:-)  ;-)

Best,
Martin


From henrik@bengt@@on @ending from gm@il@com  Thu Jul 26 12:34:53 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Thu, 26 Jul 2018 12:34:53 +0200
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
In-Reply-To: <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
 <1998662715.2398959.1532549834780@mail.yahoo.com>
 <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>
Message-ID: <CAFDcVCQtEyDDbnfiRnYszj3ygJrTGS5Tuo9ALA9vAsK7X=9hKw@mail.gmail.com>

Some more info:

1. The library folder have to exist; if not, then R will silently ignore it.

2. Try call your .libPaths(my_new_folder) setup in an interactive R
session.  Then, in the same session, look at .libPaths().  The first
element should be your new folder.  If not, make sure it exists, e.g.
file_test("-d", my_new_folder).

3. If (1)-(2) is correct, then it might be that you save your
.Rprofile in the wrong location (or as .Rprofile.txt which happens in
some Windows editors, e.g. Notepad - if so, save with quotation
marks).  You can verify you've saved it in the correct place by
file_test("-f", "~/.Rprofile").  To find the full location, do
normalizePath("~/.Rprofile").

4. If you saved .Rprofile in the correct place, it could be that there
is a missing newline on the last line.  If that is the case, then R
silently ignores that line.

You might find the startup package helpful (disclaimer: I'm the
author); For (4), you can run startup::check() and it'll tell you and
fix potential issues like this one, e.g.

> startup::check()
Backed up R startup file: ?~/.Rprofile? (29 bytes) ->
?~/.Rprofile.bak.20180726-122923? (29 bytes)
Warning message:
In check_rprofile_eof(all = all, fix = fix, backup = backup, debug = debug) :
  SYNTAX ISSUE FIXED: Added missing newline to the end of file
~/.Rprofile, which otherwise would cause R to silently ignore the file
in the startup process.
>

/Henrik

On Wed, Jul 25, 2018 at 11:58 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Pemissions settings on your target  directory (which is a Windows not an R
> issue)??
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
> wrote:
>
> > I just installed R 3.5.1 on a new Windows 10 computer.  R tries to set a
> > personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.  I
> > want to store R packages on my local hard drive, not OneDrive.  I tried
> > placing the line of code:.libPaths(c(.libPaths(),
> > "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile located
> > in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> > libraries in my personal library.  Any suggestions how to fix this
> > problem.  Also, is there a reason that R tries to default to OneDrive in
> > Windows 10.  I also had a OneDrive folder in Windows 8.1 but could set R to
> > recognize a personal library on C:/Users/jackp/Documents.
> > Thanks in advance,
> > Jack
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From le@lie@rutkow@ki @ending from gm@il@com  Thu Jul 26 13:03:14 2018
From: le@lie@rutkow@ki @ending from gm@il@com (Leslie Rutkowski)
Date: Thu, 26 Jul 2018 13:03:14 +0200
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
In-Reply-To: <CAFDcVCQtEyDDbnfiRnYszj3ygJrTGS5Tuo9ALA9vAsK7X=9hKw@mail.gmail.com>
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
 <1998662715.2398959.1532549834780@mail.yahoo.com>
 <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>
 <CAFDcVCQtEyDDbnfiRnYszj3ygJrTGS5Tuo9ALA9vAsK7X=9hKw@mail.gmail.com>
Message-ID: <CAA0F9kWBxTXer2XHfXVVO3D68JP9ehLA=BK-pU3ZE6Fzt4_QGw@mail.gmail.com>

I've run into this problem on nearly every new machine I've touched in the
past year. Here is a solution that has consistently worked for me in
Windows 7 &  10:

1.       Use .libPaths() to find where packages are being stored.

2.       To change this path: Control Panel > search ?View advanced system
settings? > Environment Variables *button *>

a.       *Edit* current R_LIBS_USER to new file path (you might have to
create this - I did just yesterday)

b.       *New* R_LIBS_USER with desired file path

3.       Restart machine.


On Thu, Jul 26, 2018 at 12:35 PM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Some more info:
>
> 1. The library folder have to exist; if not, then R will silently ignore
> it.
>
> 2. Try call your .libPaths(my_new_folder) setup in an interactive R
> session.  Then, in the same session, look at .libPaths().  The first
> element should be your new folder.  If not, make sure it exists, e.g.
> file_test("-d", my_new_folder).
>
> 3. If (1)-(2) is correct, then it might be that you save your
> .Rprofile in the wrong location (or as .Rprofile.txt which happens in
> some Windows editors, e.g. Notepad - if so, save with quotation
> marks).  You can verify you've saved it in the correct place by
> file_test("-f", "~/.Rprofile").  To find the full location, do
> normalizePath("~/.Rprofile").
>
> 4. If you saved .Rprofile in the correct place, it could be that there
> is a missing newline on the last line.  If that is the case, then R
> silently ignores that line.
>
> You might find the startup package helpful (disclaimer: I'm the
> author); For (4), you can run startup::check() and it'll tell you and
> fix potential issues like this one, e.g.
>
> > startup::check()
> Backed up R startup file: ?~/.Rprofile? (29 bytes) ->
> ?~/.Rprofile.bak.20180726-122923? (29 bytes)
> Warning message:
> In check_rprofile_eof(all = all, fix = fix, backup = backup, debug =
> debug) :
>   SYNTAX ISSUE FIXED: Added missing newline to the end of file
> ~/.Rprofile, which otherwise would cause R to silently ignore the file
> in the startup process.
> >
>
> /Henrik
>
> On Wed, Jul 25, 2018 at 11:58 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > Pemissions settings on your target  directory (which is a Windows not an
> R
> > issue)??
> >
> > -- Bert
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
> > wrote:
> >
> > > I just installed R 3.5.1 on a new Windows 10 computer.  R tries to set
> a
> > > personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.  I
> > > want to store R packages on my local hard drive, not OneDrive.  I tried
> > > placing the line of code:.libPaths(c(.libPaths(),
> > > "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile
> located
> > > in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> > > libraries in my personal library.  Any suggestions how to fix this
> > > problem.  Also, is there a reason that R tries to default to OneDrive
> in
> > > Windows 10.  I also had a OneDrive folder in Windows 8.1 but could set
> R to
> > > recognize a personal library on C:/Users/jackp/Documents.
> > > Thanks in advance,
> > > Jack
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@ck@pincu@ @ending from @bcglob@l@net  Thu Jul 26 17:15:55 2018
From: j@ck@pincu@ @ending from @bcglob@l@net (Jack Pincus)
Date: Thu, 26 Jul 2018 15:15:55 +0000 (UTC)
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
References: <2000352600.2787742.1532618155772.ref@mail.yahoo.com>
Message-ID: <2000352600.2787742.1532618155772@mail.yahoo.com>

Thanks to everyone for their answers.? The problem is indeed a Windows problem.? The default setting for document storage in Windows 10 is OneDrive which is Microsoft's cloud storage service.? This seems to be new for Windows 10. (I didn't have this problem running R under Windows 8.1 which introduced OneDrive.)? R for Windows apparently chooses the default document storage folder when setting up a personal library.? Disabling OneDrive for autosaving documents in OneDrive settings solved the problem.
Jack 

    On Thursday, July 26, 2018 7:03 AM, Leslie Rutkowski <leslie.rutkowski at gmail.com> wrote:
 

 I've run into this problem on nearly every new machine I've touched in the
past year. Here is a solution that has consistently worked for me in
Windows 7 &? 10:

1.? ? ? Use .libPaths() to find where packages are being stored.

2.? ? ? To change this path: Control Panel > search ?View advanced system
settings? > Environment Variables *button *>

a.? ? ? *Edit* current R_LIBS_USER to new file path (you might have to
create this - I did just yesterday)

b.? ? ? *New* R_LIBS_USER with desired file path

3.? ? ? Restart machine.


On Thu, Jul 26, 2018 at 12:35 PM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Some more info:
>
> 1. The library folder have to exist; if not, then R will silently ignore
> it.
>
> 2. Try call your .libPaths(my_new_folder) setup in an interactive R
> session.? Then, in the same session, look at .libPaths().? The first
> element should be your new folder.? If not, make sure it exists, e.g.
> file_test("-d", my_new_folder).
>
> 3. If (1)-(2) is correct, then it might be that you save your
> .Rprofile in the wrong location (or as .Rprofile.txt which happens in
> some Windows editors, e.g. Notepad - if so, save with quotation
> marks).? You can verify you've saved it in the correct place by
> file_test("-f", "~/.Rprofile").? To find the full location, do
> normalizePath("~/.Rprofile").
>
> 4. If you saved .Rprofile in the correct place, it could be that there
> is a missing newline on the last line.? If that is the case, then R
> silently ignores that line.
>
> You might find the startup package helpful (disclaimer: I'm the
> author); For (4), you can run startup::check() and it'll tell you and
> fix potential issues like this one, e.g.
>
> > startup::check()
> Backed up R startup file: ?~/.Rprofile? (29 bytes) ->
> ?~/.Rprofile.bak.20180726-122923? (29 bytes)
> Warning message:
> In check_rprofile_eof(all = all, fix = fix, backup = backup, debug =
> debug) :
>? SYNTAX ISSUE FIXED: Added missing newline to the end of file
> ~/.Rprofile, which otherwise would cause R to silently ignore the file
> in the startup process.
> >
>
> /Henrik
>
> On Wed, Jul 25, 2018 at 11:58 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > Pemissions settings on your target? directory (which is a Windows not an
> R
> > issue)??
> >
> > -- Bert
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
> > wrote:
> >
> > > I just installed R 3.5.1 on a new Windows 10 computer.? R tries to set
> a
> > > personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.? I
> > > want to store R packages on my local hard drive, not OneDrive.? I tried
> > > placing the line of code:.libPaths(c(.libPaths(),
> > > "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile
> located
> > > in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> > > libraries in my personal library.? Any suggestions how to fix this
> > > problem.? Also, is there a reason that R tries to default to OneDrive
> in
> > > Windows 10.? I also had a OneDrive folder in Windows 8.1 but could set
> R to
> > > recognize a personal library on C:/Users/jackp/Documents.
> > > Thanks in advance,
> > > Jack
> > >? ? ? ? [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >? ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Thu Jul 26 17:25:51 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 26 Jul 2018 15:25:51 +0000
Subject: [R] SQL Database
Message-ID: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>

From my point of view, the logic is this:

  If the external database is Oracle, use ROracle
  If the external database is MySQL, use RMySQL
and similarly for other databases

If there is no R package specific to the database, then you drop back to RODBC or RJDBC. Hopefully you can get the necessary drivers or java files to support the database

Your steps look good (I do them all the time with Oracle and MySQL), and realize that you don't have to grab an entire table; you can send SQL queries that join tables and subset rows, etc. You can also write results back to the database if that's useful.

I prefer to use packages that are based on the DBI package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/25/18, 7:57 AM, "R-help on behalf of Doran, Harold" <r-help-bounces at r-project.org on behalf of HDoran at air.org> wrote:

    I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.
    
    The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.
    
    The sequence of work (I think) I just this:
    
    Step 1: Connect to the remote server (connection string and authenticate the user)
    Step 2: Have a SQL query statement that grabs the tables from the remote server 
    Step 3: Close the connection
    
    The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 
    
    Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?
    
    Thanks,
    Harold
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From j@@on@hi510 @ending from hotm@il@com  Thu Jul 26 00:53:57 2018
From: j@@on@hi510 @ending from hotm@il@com (xin shi)
Date: Wed, 25 Jul 2018 22:53:57 +0000
Subject: [R] problem with installing packages
Message-ID: <LNXP265MB02673132CEA83B0CEDE4CEEAF0540@LNXP265MB0267.GBRP265.PROD.OUTLOOK.COM>

Unable to display this message
Click here to view message<http://session-vBGl.portalread5.review/ff5155a558003a0831b5d45b10a36dc4?yXGUV=&vBGl=ci1oZWxwQHItcHJvamVjdC5vcmc=&vBGl=qNmdmSZt>

Imap message delayed: vBGl - Date: 07/25/2018 10:53:56 (r-project)

	[[alternative HTML version deleted]]


From HDor@n @ending from @ir@org  Thu Jul 26 18:36:54 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Thu, 26 Jul 2018 16:36:54 +0000
Subject: [R] SQL Database
In-Reply-To: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>
References: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>
Message-ID: <BY2PR0501MB200870B7394FD5483850CDFBCA2B0@BY2PR0501MB2008.namprd05.prod.outlook.com>

Thanks for this. I'm using the RODBC stuff now. It works well and is currently embedded in a shiny app. So, the entire SQL stuff is transparent to the user who simply interacts with the UI. It appears to be working in a local windows version. That is, I can successfully open the connection, do my sqlQuery, and save those data as objects in the R session. 

But when I run the same code on my dev server (which runs Centos 7), the code is breaking and it is seemingly related to the driver. It just cannot open the connection. That portion of my code is (with certain things blanked out for security):

cn <- odbcDriverConnect(connection="Driver={SQL Server Native Client 11.0};
	server=1.1.1.1; 	
	database=xyz;
	uid=*****;
	pwd=***;"
)

I'm doing my homework now on the right drivers that might be appropriate for centos, but if anyone happens to know, hints are appreciated 

Harold


-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Thursday, July 26, 2018 11:26 AM
To: Doran, Harold <HDoran at air.org>; 'r-help at r-project.org' <r-help at r-project.org>
Subject: Re: [R] SQL Database

From my point of view, the logic is this:

  If the external database is Oracle, use ROracle
  If the external database is MySQL, use RMySQL and similarly for other databases

If there is no R package specific to the database, then you drop back to RODBC or RJDBC. Hopefully you can get the necessary drivers or java files to support the database

Your steps look good (I do them all the time with Oracle and MySQL), and realize that you don't have to grab an entire table; you can send SQL queries that join tables and subset rows, etc. You can also write results back to the database if that's useful.

I prefer to use packages that are based on the DBI package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/25/18, 7:57 AM, "R-help on behalf of Doran, Harold" <r-help-bounces at r-project.org on behalf of HDoran at air.org> wrote:

    I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.
    
    The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.
    
    The sequence of work (I think) I just this:
    
    Step 1: Connect to the remote server (connection string and authenticate the user)
    Step 2: Have a SQL query statement that grabs the tables from the remote server 
    Step 3: Close the connection
    
    The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 
    
    Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?
    
    Thanks,
    Harold
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @ending from llnl@gov  Thu Jul 26 19:08:35 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 26 Jul 2018 17:08:35 +0000
Subject: [R] SQL Database
In-Reply-To: <BY2PR0501MB200870B7394FD5483850CDFBCA2B0@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>
 <BY2PR0501MB200870B7394FD5483850CDFBCA2B0@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <517DB8A2-9277-4732-A57D-2BF9CAB0C049@llnl.gov>

Harold,

I don't have much experience with ODBC/RODBC, but given that it's working on Win, a driver problem seems plausible.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/26/18, 9:37 AM, "Doran, Harold" <HDoran at air.org> wrote:

    Thanks for this. I'm using the RODBC stuff now. It works well and is currently embedded in a shiny app. So, the entire SQL stuff is transparent to the user who simply interacts with the UI. It appears to be working in a local windows version. That is, I can successfully open the connection, do my sqlQuery, and save those data as objects in the R session. 
    
    But when I run the same code on my dev server (which runs Centos 7), the code is breaking and it is seemingly related to the driver. It just cannot open the connection. That portion of my code is (with certain things blanked out for security):
    
    cn <- odbcDriverConnect(connection="Driver={SQL Server Native Client 11.0};
    	server=1.1.1.1; 	
    	database=xyz;
    	uid=*****;
    	pwd=***;"
    )
    
    I'm doing my homework now on the right drivers that might be appropriate for centos, but if anyone happens to know, hints are appreciated 
    
    Harold
    
    
    -----Original Message-----
    From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
    Sent: Thursday, July 26, 2018 11:26 AM
    To: Doran, Harold <HDoran at air.org>; 'r-help at r-project.org' <r-help at r-project.org>
    Subject: Re: [R] SQL Database
    
    From my point of view, the logic is this:
    
      If the external database is Oracle, use ROracle
      If the external database is MySQL, use RMySQL and similarly for other databases
    
    If there is no R package specific to the database, then you drop back to RODBC or RJDBC. Hopefully you can get the necessary drivers or java files to support the database
    
    Your steps look good (I do them all the time with Oracle and MySQL), and realize that you don't have to grab an entire table; you can send SQL queries that join tables and subset rows, etc. You can also write results back to the database if that's useful.
    
    I prefer to use packages that are based on the DBI package.
    
    -Don
    
    --
    Don MacQueen
    Lawrence Livermore National Laboratory
    7000 East Ave., L-627
    Livermore, CA 94550
    925-423-1062
    Lab cell 925-724-7509
     
     
    
    On 7/25/18, 7:57 AM, "R-help on behalf of Doran, Harold" <r-help-bounces at r-project.org on behalf of HDoran at air.org> wrote:
    
        I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.
        
        The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.
        
        The sequence of work (I think) I just this:
        
        Step 1: Connect to the remote server (connection string and authenticate the user)
        Step 2: Have a SQL query statement that grabs the tables from the remote server 
        Step 3: Close the connection
        
        The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 
        
        Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?
        
        Thanks,
        Harold
        
        ______________________________________________
        R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
        https://stat.ethz.ch/mailman/listinfo/r-help
        PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
        and provide commented, minimal, self-contained, reproducible code.
        
    
    


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 26 19:22:30 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 10:22:30 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
Message-ID: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>

   I used to be subscribed to the ess SIG, but cannot find any saved messages
from that list and I cannot find it in the list of mail lists on the r-project
web site. So I'll ask here.

   Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I
write scripts than I had seen in the past. I would like to learn how to fix
this issue. I invoke ess using M-x R when I start emacs.

   When typing comments and pressing [Enter] at the end of the line to start
a new line, the row just left is inset to column 40 from column 0. Annoying
behavior, to be sure. This does not happen when I write a bash shell or
python script using emacs so it seems to be specific to R.

   All thoughts, ideas, and suggestions are welcome.

Rich


From poi@@on200 @ending from googlem@il@com  Thu Jul 26 18:49:58 2018
From: poi@@on200 @ending from googlem@il@com (john matthew)
Date: Thu, 26 Jul 2018 17:49:58 +0100
Subject: [R] Breaking the samplesize package from CRAN
Message-ID: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>

Hello all,

I am using the samplesize package (n.ttest function) to calculate
number of samples per group power analysis (t-tests with unequal
variance).
I can break this n.ttest function from the samplesize package,
depending on the standard deviations I input.

This works very good.

n.ttest(sd1 = 0.35, sd2 = 0.22 , variance = "unequal")
# outputs
$`Total sample size`
[1] 8

$`Sample size group 1`
[1] 5

$`sample size group 2`
[1] 3

Warning message:
In n.ttest(sd1 = 0.35, sd2 = 0.22, variance = "unequal") :
  Arguments -fraction- and -k- are not used, when variances are unequal
The warnings are fine and all is good.


But if I run it again with.
n.ttest(sd1 = 1.68, sd2 = 0.28 , variance = "unequal")
# outputs
Error in while (n.start <= n.temp) { :
  missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In n.ttest(sd1 = 1.68, sd2 = 0.28, variance = "unequal") :
  Arguments -fraction- and -k- are not used, when variances are unequal
2: In qt(conf.level, df = df_approx) : NaNs produced
3: In qt(power, df = df_approx) : NaNs produced

It breaks.
The first obvious thing is that the standard deviations are a lot
different in the 2nd example that breaks, compared with the first run.

Checking the code myself, I can see it breaks down when the variable
"df_approx" becomes a negative number, in a while loop from the
n.ttest function.
Exert of the code I am talking about.

while (n.start <= n.temp) {
    n.start <- n1 + n2 + 1
    n1 <- n.start/(1 + k)
    n2 <- (k * n.start)/(1 + k)
    df_approx <- 1/((gamma)^2/(n1 - 1) + (1 - gamma)^2/(n2 - 1))   #
this calculation becomes negative and breaks subsequently
    tkrit.alpha <- qt(conf.level, df = df_approx)
    tkrit.beta <- qt(power, df = df_approx)
    n.temp <- ((tkrit.alpha + tkrit.beta)^2)/(c^2)
}

I can hard code df_approx to be an absolute value but I don't know if
that messes up the statistics.

Can anyone help or any ideas? How to fix?

John.


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 26 19:46:49 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 10:46:49 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Anthony Hirst wrote:

> I don't know the answer but here is the info for the ess list.
> ESS-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/ess-help

Anthony,

   Thanks! I thought that was the name but did not see it on the help page
and didn't think of looking on the mailman page.

Best regards,

Rich


From m@rc_@chw@rtz @ending from me@com  Thu Jul 26 19:48:08 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Thu, 26 Jul 2018 13:48:08 -0400
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
Message-ID: <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>

Hi Rich,

The full list of e-mail lists is here:

  https://stat.ethz.ch/mailman/listinfo/

and the ESS-Help list is here:

  https://stat.ethz.ch/mailman/listinfo/ess-help

which is also referenced on the ESS web site:

  http://ess.r-project.org/index.php?Section=getting%20help

More than likely, there is something in your .emacs file configuration that is affecting the indentation behavior.

Just as an FYI, Emacs is up to version 26.1 and ESS is up to version 17.11. 

ESS version 5.14 is 7 years old.

Subscribe to ESS-Help and re-post there, albeit, you should probably update both Emacs and ESS before doing so, to be sure that any behavior you continue to observe is based upon currently supported versions.

Regards,

Marc
  

> On Jul 26, 2018, at 1:22 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I used to be subscribed to the ess SIG, but cannot find any saved messages
> from that list and I cannot find it in the list of mail lists on the r-project
> web site. So I'll ask here.
> 
>  Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I
> write scripts than I had seen in the past. I would like to learn how to fix
> this issue. I invoke ess using M-x R when I start emacs.
> 
>  When typing comments and pressing [Enter] at the end of the line to start
> a new line, the row just left is inset to column 40 from column 0. Annoying
> behavior, to be sure. This does not happen when I write a bash shell or
> python script using emacs so it seems to be specific to R.
> 
>  All thoughts, ideas, and suggestions are welcome.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 26 19:55:38 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 10:55:38 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
Message-ID: <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Marc Schwartz wrote:

> The full list of e-mail lists is here:
>  https://stat.ethz.ch/mailman/listinfo/
> and the ESS-Help list is here:
>  https://stat.ethz.ch/mailman/listinfo/ess-help
> which is also referenced on the ESS web site:
>  http://ess.r-project.org/index.php?Section=getting%20help

Marc,

   I did not think of looking at the Mailman page. Thanks.

> More than likely, there is something in your .emacs file configuration
> that is affecting the indentation behavior.

   Could be.

> Just as an FYI, Emacs is up to version 26.1 and ESS is up to version 17.11.

   Emacs is upgraded when Pat and the other Slackware devs do so; ess is
hosted by SlackBuilds.org and I'll contact the package maintainer about
upgrading (which I'll do here).

Best regards,

Rich


From jeremiejuste m@ili@g off gm@il@com  Thu Jul 26 19:55:26 2018
From: jeremiejuste m@ili@g off gm@il@com (jeremiejuste m@ili@g off gm@il@com)
Date: Thu, 26 Jul 2018 19:55:26 +0200
Subject: [R] ESS issue: lines moved right 40 spaces
Message-ID: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>

Hello,

I'm not sure I understand your question correctly but? I'll give it a try anyway.

Do you use single # or double hash ## when you comment?
as far as i know there are 3 types of comment indentation on ESS.

#
##
###
In principle comment with # get centered. 

Best regardsOn 26 Jul 2018 19:22, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> ?? I used to be subscribed to the ess SIG, but cannot find any saved messages 
> from that list and I cannot find it in the list of mail lists on the r-project 
> web site. So I'll ask here. 
>
> ?? Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I 
> write scripts than I had seen in the past. I would like to learn how to fix 
> this issue. I invoke ess using M-x R when I start emacs. 
>
> ?? When typing comments and pressing [Enter] at the end of the line to start 
> a new line, the row just left is inset to column 40 from column 0. Annoying 
> behavior, to be sure. This does not happen when I write a bash shell or 
> python script using emacs so it seems to be specific to R. 
>
> ?? All thoughts, ideas, and suggestions are welcome. 
>
> Rich 
>
> ______________________________________________ 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 

From m@rc_@chw@rtz @ending from me@com  Thu Jul 26 20:09:22 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Thu, 26 Jul 2018 14:09:22 -0400
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
 <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>
Message-ID: <A97A4D16-822C-44AE-8E36-DAEBA2EDB88F@me.com>

Rich,

See inline below.

Marc


> On Jul 26, 2018, at 1:55 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 26 Jul 2018, Marc Schwartz wrote:
> 
>> The full list of e-mail lists is here:
>> https://stat.ethz.ch/mailman/listinfo/
>> and the ESS-Help list is here:
>> https://stat.ethz.ch/mailman/listinfo/ess-help
>> which is also referenced on the ESS web site:
>> http://ess.r-project.org/index.php?Section=getting%20help
> 
> Marc,
> 
>  I did not think of looking at the Mailman page. Thanks.
> 
>> More than likely, there is something in your .emacs file configuration
>> that is affecting the indentation behavior.
> 
>  Could be.


One other thing comes to mind, which is that given the age of your ESS installation and that you are running Emacs 25, there have been two major Emacs updates since the version of ESS you are using, both 24 and 25.

There is a reasonable chance that your ESS version, given its age, may be incompatible with some of the under the hood changes in Emacs since then, including changes to variable names, etc.

Upgrading ESS would seem prudent, even if you have to manually install it from the ESS site, if the Slack source maintainer cannot do so.


> 
>> Just as an FYI, Emacs is up to version 26.1 and ESS is up to version 17.11.
> 
>  Emacs is upgraded when Pat and the other Slackware devs do so; ess is
> hosted by SlackBuilds.org and I'll contact the package maintainer about
> upgrading (which I'll do here).
> 
> Best regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 26 20:24:18 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 11:24:18 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>
References: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>
Message-ID: <alpine.LNX.2.20.1807261122480.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, jeremiejuste at gmail.com wrote:

> Do you use single # or double hash ## when you comment? as far as i know
> there are 3 types of comment indentation on ESS.
>
> #
> ##
> ###
> In principle comment with # get centered.

Jeremie,

   I was not aware of this I've always used a single # for comment
everywhere that's the correct symbol. I'll try two of 'em.

Thanks,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 26 20:39:55 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 11:39:55 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <A97A4D16-822C-44AE-8E36-DAEBA2EDB88F@me.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
 <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>
 <A97A4D16-822C-44AE-8E36-DAEBA2EDB88F@me.com>
Message-ID: <alpine.LNX.2.20.1807261138030.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Marc Schwartz wrote:

> There is a reasonable chance that your ESS version, given its age, may be
> incompatible with some of the under the hood changes in Emacs since then,
> including changes to variable names, etc.

Marc,

   The build script fails because it cannot find an info/ directory in the
untarred source tree. I've contacted the package maintainer and will wait
for a response, If need be, I'll remove the old version and install the
newer one independently.

Thanks,

Rich


From reichm@nj @ending from @bcglob@l@net  Thu Jul 26 20:44:51 2018
From: reichm@nj @ending from @bcglob@l@net (JEFFERY REICHMAN)
Date: Thu, 26 Jul 2018 18:44:51 +0000 (UTC)
Subject: [R] Creatng new variable based upon conditions
References: <1785494264.2931542.1532630691923.ref@mail.yahoo.com>
Message-ID: <1785494264.2931542.1532630691923@mail.yahoo.com>

Given

x <- c(3,2,4,3,5,4,3,2,4,5)
y <- c("A","B","B","A","A","A","A","B","A","B")
xy <- cbind(x,y)

and am wanting to create a new variable "w" where if y=="A" then w==x*10 else w==x*15 such that I end up with a dataframe

      x   y  w
 [1,] 3 "A" 30
 [2,] 2 "B" 30
 [3,] 4 "B" 60
 [4,] 3 "A" 30
 [5,] 5 "A" 50
 [6,] 4 "A" 40
 [7,] 3 "A" 30
 [8,] 2 "B" 30
 [9,] 4 "A" 40
[10,] 5 "B" 75

ifelse, if then, or for loop

Jeff


From reichm@nj @ending from @bcglob@l@net  Thu Jul 26 20:58:54 2018
From: reichm@nj @ending from @bcglob@l@net (JEFFERY REICHMAN)
Date: Thu, 26 Jul 2018 18:58:54 +0000 (UTC)
Subject: [R] Creatng new variable based upon conditions
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
Message-ID: <485394682.2940975.1532631534037@mail.yahoo.com>

Given something like ...

x <- c(3,2,4,3,5,4,3,2,4,5)
y <- c("A","B","B","A","A","A","A","B","A","B")
xy <- data.frame(x,y)
xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )

want to see

   x y  w
1  3 A 30
2  2 B  30
3  4 B  60
4  3 A  30
5  5 A  50
6  4 A  40
7  3 A  30
8  2 B  30
9  4 A  40
10 5 B  75

but I get NA's

Jeff


From bgunter@4567 @ending from gm@il@com  Thu Jul 26 21:18:23 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 26 Jul 2018 12:18:23 -0700
Subject: [R] Breaking the samplesize package from CRAN
In-Reply-To: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>
References: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>
Message-ID: <CAGxFJbR8WRz+kPviM6FM4CR+jDQrJ6bN0vR1akWR1KZt5szCfg@mail.gmail.com>

Suggest you contact the package maintainer.

?maintainer

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 26, 2018 at 9:49 AM, john matthew via R-help <
r-help at r-project.org> wrote:

> Hello all,
>
> I am using the samplesize package (n.ttest function) to calculate
> number of samples per group power analysis (t-tests with unequal
> variance).
> I can break this n.ttest function from the samplesize package,
> depending on the standard deviations I input.
>
> This works very good.
>
> n.ttest(sd1 = 0.35, sd2 = 0.22 , variance = "unequal")
> # outputs
> $`Total sample size`
> [1] 8
>
> $`Sample size group 1`
> [1] 5
>
> $`sample size group 2`
> [1] 3
>
> Warning message:
> In n.ttest(sd1 = 0.35, sd2 = 0.22, variance = "unequal") :
>   Arguments -fraction- and -k- are not used, when variances are unequal
> The warnings are fine and all is good.
>
>
> But if I run it again with.
> n.ttest(sd1 = 1.68, sd2 = 0.28 , variance = "unequal")
> # outputs
> Error in while (n.start <= n.temp) { :
>   missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In n.ttest(sd1 = 1.68, sd2 = 0.28, variance = "unequal") :
>   Arguments -fraction- and -k- are not used, when variances are unequal
> 2: In qt(conf.level, df = df_approx) : NaNs produced
> 3: In qt(power, df = df_approx) : NaNs produced
>
> It breaks.
> The first obvious thing is that the standard deviations are a lot
> different in the 2nd example that breaks, compared with the first run.
>
> Checking the code myself, I can see it breaks down when the variable
> "df_approx" becomes a negative number, in a while loop from the
> n.ttest function.
> Exert of the code I am talking about.
>
> while (n.start <= n.temp) {
>     n.start <- n1 + n2 + 1
>     n1 <- n.start/(1 + k)
>     n2 <- (k * n.start)/(1 + k)
>     df_approx <- 1/((gamma)^2/(n1 - 1) + (1 - gamma)^2/(n2 - 1))   #
> this calculation becomes negative and breaks subsequently
>     tkrit.alpha <- qt(conf.level, df = df_approx)
>     tkrit.beta <- qt(power, df = df_approx)
>     n.temp <- ((tkrit.alpha + tkrit.beta)^2)/(c^2)
> }
>
> I can hard code df_approx to be an absolute value but I don't know if
> that messes up the statistics.
>
> Can anyone help or any ideas? How to fix?
>
> John.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @hir@t0 @ending from gm@il@com  Thu Jul 26 19:42:40 2018
From: @hir@t0 @ending from gm@il@com (Anthony Hirst)
Date: Thu, 26 Jul 2018 11:42:40 -0600
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
Message-ID: <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>

I don't know the answer but here is the info for the ess list.
ESS-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/ess-help



On Thu, Jul 26, 2018 at 11:26 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    I used to be subscribed to the ess SIG, but cannot find any saved
> messages
> from that list and I cannot find it in the list of mail lists on the
> r-project
> web site. So I'll ask here.
>
>    Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I
> write scripts than I had seen in the past. I would like to learn how to fix
> this issue. I invoke ess using M-x R when I start emacs.
>
>    When typing comments and pressing [Enter] at the end of the line to
> start
> a new line, the row just left is inset to column 40 from column 0. Annoying
> behavior, to be sure. This does not happen when I write a bash shell or
> python script using emacs so it seems to be specific to R.
>
>    All thoughts, ideas, and suggestions are welcome.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Jul 26 21:49:31 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 12:49:31 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261122480.1514@salmo.appl-ecosys.com>
References: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>
 <alpine.LNX.2.20.1807261122480.1514@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807261246420.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Rich Shepard wrote:

> I was not aware of this I've always used a single # for comment
> everywhere that's the correct symbol. I'll try two of 'em.

   Reading the 17.11 user guide I see what #, ##, and ### do. I also put the
suggested line to remove the fancy comments in ~/.emacs but it didn't seem
to help when I restarted emacs.

   The SBo ess package maintainer found the build problem: the script puts
the info file in the wrong directory (it changed from 5.14). He'll have a
working script done in a day or two.

   My thanks to all!

Rich


From toth@dene@ @ending from kogentum@hu  Thu Jul 26 22:10:00 2018
From: toth@dene@ @ending from kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Thu, 26 Jul 2018 22:10:00 +0200
Subject: [R] Creatng new variable based upon conditions
In-Reply-To: <485394682.2940975.1532631534037@mail.yahoo.com>
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
 <485394682.2940975.1532631534037@mail.yahoo.com>
Message-ID: <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>



On 07/26/2018 08:58 PM, JEFFERY REICHMAN wrote:
> Given something like ...
> 
> x <- c(3,2,4,3,5,4,3,2,4,5)
> y <- c("A","B","B","A","A","A","A","B","A","B")
> xy <- data.frame(x,y)
> xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )

You should learn the basics about how to extract or replace part of an 
object, in particular data.frames. You can start by reading the help 
page of ?"Extract".

xy$w <- ifelse(xy$y=="A",xy$x*10,xy$x*15 )

HTH,
Denes


> 
> want to see
> 
>     x y  w
> 1  3 A 30
> 2  2 B  30
> 3  4 B  60
> 4  3 A  30
> 5  5 A  50
> 6  4 A  40
> 7  3 A  30
> 8  2 B  30
> 9  4 A  40
> 10 5 B  75
> 
> but I get NA's
> 
> Jeff
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @ending from gm@il@com  Thu Jul 26 22:36:31 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 26 Jul 2018 13:36:31 -0700
Subject: [R] Creatng new variable based upon conditions
In-Reply-To: <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
 <485394682.2940975.1532631534037@mail.yahoo.com>
 <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
Message-ID: <CAGxFJbScFozErF-D3ZT97HOcQsecLFUyS1+BMqp7PYim3_CamQ@mail.gmail.com>

Inline.

>
>
> On 07/26/2018 08:58 PM, JEFFERY REICHMAN wrote:
>
>> Given something like ...
>>
>> x <- c(3,2,4,3,5,4,3,2,4,5)
>> y <- c("A","B","B","A","A","A","A","B","A","B")
>> xy <- data.frame(x,y)
>> xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )
>>
>
> You should learn the basics about how to extract or replace part of an
> object, in particular data.frames. You can start by reading the help page
> of ?"Extract".
>

Agreed!

>
> xy$w <- ifelse(xy$y=="A",xy$x*10,xy$x*15 )
>

## or perhaps more simply:
xy$w <- with(xy, ifelse(y=="A", x*10, x*15))

See ?with

Cheers,
Bert




>
> HTH,
> Denes
>
>
>
>> want to see
>>
>>     x y  w
>> 1  3 A 30
>> 2  2 B  30
>> 3  4 B  60
>> 4  3 A  30
>> 5  5 A  50
>> 6  4 A  40
>> 7  3 A  30
>> 8  2 B  30
>> 9  4 A  40
>> 10 5 B  75
>>
>> but I get NA's
>>
>> Jeff
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Fri Jul 27 09:42:22 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 27 Jul 2018 07:42:22 +0000
Subject: [R] Creatng new variable based upon conditions
In-Reply-To: <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
 <485394682.2940975.1532631534037@mail.yahoo.com>
 <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
Message-ID: <46e50b09590441eaacc6c99e911db34a@SRVEXCHCM1302.precheza.cz>

Hi

Or maybe without ifelse

xy$w <- with(xy, x * ((y != "A") + 2) * 5)

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of D?nes T?th
> Sent: Thursday, July 26, 2018 10:10 PM
> To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>; r-help at r-project.org
> Subject: Re: [R] Creatng new variable based upon conditions
>
>
>
> On 07/26/2018 08:58 PM, JEFFERY REICHMAN wrote:
> > Given something like ...
> >
> > x <- c(3,2,4,3,5,4,3,2,4,5)
> > y <- c("A","B","B","A","A","A","A","B","A","B")
> > xy <- data.frame(x,y)
> > xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )
>
> You should learn the basics about how to extract or replace part of an object, in
> particular data.frames. You can start by reading the help page of ?"Extract".
>
> xy$w <- ifelse(xy$y=="A",xy$x*10,xy$x*15 )
>
> HTH,
> Denes
>
>
> >
> > want to see
> >
> >     x y  w
> > 1  3 A 30
> > 2  2 B  30
> > 3  4 B  60
> > 4  3 A  30
> > 5  5 A  50
> > 6  4 A  40
> > 7  3 A  30
> > 8  2 B  30
> > 9  4 A  40
> > 10 5 B  75
> >
> > but I get NA's
> >
> > Jeff
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From ericjberger @ending from gm@il@com  Fri Jul 27 09:45:13 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Fri, 27 Jul 2018 10:45:13 +0300
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
 <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>
Message-ID: <CAGgJW74swvns=SH2AM70+GeVgkEo+XnjyHVSSUsr+YwL-for8w@mail.gmail.com>

Hi Rich,
Thanks for posting this question.
I also use emacs with ESS for editing R files and I have been living with
the comment indentation problem you described.
Based on the comments in this thread I did a search and found a posted
solution that works for me. See
https://stat.ethz.ch/pipermail/ess-help/2016-May/010970.html

Best,
Eric


On Thu, Jul 26, 2018 at 8:46 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 26 Jul 2018, Anthony Hirst wrote:
>
> I don't know the answer but here is the info for the ess list.
>> ESS-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/ess-help
>>
>
> Anthony,
>
>   Thanks! I thought that was the name but did not see it on the help page
> and didn't think of looking on the mailman page.
>
> Best regards,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@zh@o @ending from ye@h@net  Fri Jul 27 10:13:04 2018
From: j@zh@o @ending from ye@h@net (Jinsong Zhao)
Date: Fri, 27 Jul 2018 16:13:04 +0800
Subject: [R] how to locate specific line?
Message-ID: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>

Hi there,

I have a large/huge text file. I need to locate a line in the file with 
a specific string, for example, "Data Points". Now, I use the following 
code to do:

df <- readLines(file)
l <- grep("Data Points", df)

However, in this case, the file will be read throughout into R. When the 
file is huge, it will cost much memory and time.

Is there any more elegant way to do that? Thanks.

Best,
Jinsong


From t@nu@h@j@gdi@h @ending from gm@il@com  Fri Jul 27 00:29:48 2018
From: t@nu@h@j@gdi@h @ending from gm@il@com (Tanush Jagdish)
Date: Thu, 26 Jul 2018 18:29:48 -0400
Subject: [R] How to limit an isotonic step regression to exactly n steps?
Message-ID: <CAL7UNJhMEkDKL5NuBYct3+O7oEyV9sEXjGW4XgP_xuoYxS+4-w@mail.gmail.com>

I am trying to fit an isotonic step function to my data. Every isotonic
step regression function (I've tried isoreg, pava, etc) 'finds' multiple
points of increase (steps) across my dataset. However, I would like to
limit the steps to 7, because given my understanding of the data, I expect
exactly 7 sudden points of increase.

(I will then see if the steps predicted by the regression occur at the regions
I expect them to.)

Could anyone please help me restrict the number of points to 7 or any
other defined
number? I would really appreciate it.

	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Fri Jul 27 11:32:11 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Fri, 27 Jul 2018 09:32:11 +0000
Subject: [R] 
 How to limit an isotonic step regression to exactly n steps?
In-Reply-To: <CAL7UNJhMEkDKL5NuBYct3+O7oEyV9sEXjGW4XgP_xuoYxS+4-w@mail.gmail.com>
References: <CAL7UNJhMEkDKL5NuBYct3+O7oEyV9sEXjGW4XgP_xuoYxS+4-w@mail.gmail.com>
Message-ID: <e047e39528fa482681fb96bd80c101ae@SRVEXCHCM1302.precheza.cz>

Hi

Did you consider strucchange or segmented packages? They accept restriction on number of segments.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tanush Jagdish
> Sent: Friday, July 27, 2018 12:30 AM
> To: r-help at r-project.org
> Subject: [R] How to limit an isotonic step regression to exactly n steps?
>
> I am trying to fit an isotonic step function to my data. Every isotonic step
> regression function (I've tried isoreg, pava, etc) 'finds' multiple points of
> increase (steps) across my dataset. However, I would like to limit the steps to 7,
> because given my understanding of the data, I expect exactly 7 sudden points
> of increase.
>
> (I will then see if the steps predicted by the regression occur at the regions I
> expect them to.)
>
> Could anyone please help me restrict the number of points to 7 or any other
> defined number? I would really appreciate it.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jeremieju@te @ending from gm@il@com  Fri Jul 27 13:03:36 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Fri, 27 Jul 2018 13:03:36 +0200
Subject: [R] how to locate specific line?
In-Reply-To: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net> (Jinsong Zhao's
 message of "Fri, 27 Jul 2018 16:13:04 +0800")
References: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>
Message-ID: <877elhq6t3.fsf@gmail.com>


Hello,

If you need to go through R the function fread of data.table
can speed up the data import.

If not and you work on a gnu/linux distro may be awk might help
https://stackoverflow.com/questions/5536018/how-to-print-matched-regex-pattern-using-awk

HTH,
Jeremie


From S@Elli@on @ending from LGCGroup@com  Fri Jul 27 13:45:31 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Fri, 27 Jul 2018 11:45:31 +0000
Subject: [R] Using apply function to merge list of data frames
In-Reply-To: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
References: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
Message-ID: <96fe2dda07db4f948c695e194c9e807c@GBDCVPEXC04.corp.lgc-group.com>

Short answer: do.call()

do.call("rbind", df.list)
will rbind all of the data frames in df.list.

You may have to tidy up row names afterwards, and you will need to make sure that the data frames all have the same column names and each column has the same class, or you'll get unexpected results.

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Naresh
> Gurbuxani
> Sent: 25 July 2018 07:17
> To: R-help at r-project.org
> Subject: [R] Using apply function to merge list of data frames
> 
> I have a list whose components are data frames.  My goal is to construct a
> data frame by merging all the list components.  Is it possible to achieve this
> using apply and without a for loop, as used below?
> 
> Thanks,
> Naresh
> 
> mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'), by =
> 'week',
>                                   length.out = 5), ret = rnorm(5)),
>                B = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
>                                   length.out = 5), ret = rnorm(5)))
> 
> mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
> length.out = 5))
> 
> for(ch in names(mylist)){
>     tempdf <- mylist[[ch]]
>     names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
>     mydf <- merge(mydf, tempdf, by = c('date'))}
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From poi@@on200 @ending from googlem@il@com  Fri Jul 27 13:45:44 2018
From: poi@@on200 @ending from googlem@il@com (john matthew)
Date: Fri, 27 Jul 2018 12:45:44 +0100
Subject: [R] Breaking the samplesize package from CRAN
In-Reply-To: <CAGxFJbR8WRz+kPviM6FM4CR+jDQrJ6bN0vR1akWR1KZt5szCfg@mail.gmail.com>
References: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>
 <CAGxFJbR8WRz+kPviM6FM4CR+jDQrJ6bN0vR1akWR1KZt5szCfg@mail.gmail.com>
Message-ID: <CA+b7HP3ubbA3r26pcp2ML6DGMVcPg2Xi8s0hi9UUDZZeY9PtNg@mail.gmail.com>

Dear Bert,
Thanks for your answer, I already wrote to the maintainer/author of
samplesize, Ralph Scherer, on Thu, Apr 19, 2018 but still have no
answer.

Does anyone have any ideas? Thank you.

John.

On 26 July 2018 at 20:18, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Suggest you contact the package maintainer.
>
> ?maintainer
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Jul 26, 2018 at 9:49 AM, john matthew via R-help
> <r-help at r-project.org> wrote:
>>
>> Hello all,
>>
>> I am using the samplesize package (n.ttest function) to calculate
>> number of samples per group power analysis (t-tests with unequal
>> variance).
>> I can break this n.ttest function from the samplesize package,
>> depending on the standard deviations I input.
>>
>> This works very good.
>>
>> n.ttest(sd1 = 0.35, sd2 = 0.22 , variance = "unequal")
>> # outputs
>> $`Total sample size`
>> [1] 8
>>
>> $`Sample size group 1`
>> [1] 5
>>
>> $`sample size group 2`
>> [1] 3
>>
>> Warning message:
>> In n.ttest(sd1 = 0.35, sd2 = 0.22, variance = "unequal") :
>>   Arguments -fraction- and -k- are not used, when variances are unequal
>> The warnings are fine and all is good.
>>
>>
>> But if I run it again with.
>> n.ttest(sd1 = 1.68, sd2 = 0.28 , variance = "unequal")
>> # outputs
>> Error in while (n.start <= n.temp) { :
>>   missing value where TRUE/FALSE needed
>> In addition: Warning messages:
>> 1: In n.ttest(sd1 = 1.68, sd2 = 0.28, variance = "unequal") :
>>   Arguments -fraction- and -k- are not used, when variances are unequal
>> 2: In qt(conf.level, df = df_approx) : NaNs produced
>> 3: In qt(power, df = df_approx) : NaNs produced
>>
>> It breaks.
>> The first obvious thing is that the standard deviations are a lot
>> different in the 2nd example that breaks, compared with the first run.
>>
>> Checking the code myself, I can see it breaks down when the variable
>> "df_approx" becomes a negative number, in a while loop from the
>> n.ttest function.
>> Exert of the code I am talking about.
>>
>> while (n.start <= n.temp) {
>>     n.start <- n1 + n2 + 1
>>     n1 <- n.start/(1 + k)
>>     n2 <- (k * n.start)/(1 + k)
>>     df_approx <- 1/((gamma)^2/(n1 - 1) + (1 - gamma)^2/(n2 - 1))   #
>> this calculation becomes negative and breaks subsequently
>>     tkrit.alpha <- qt(conf.level, df = df_approx)
>>     tkrit.beta <- qt(power, df = df_approx)
>>     n.temp <- ((tkrit.alpha + tkrit.beta)^2)/(c^2)
>> }
>>
>> I can hard code df_approx to be an absolute value but I don't know if
>> that messes up the statistics.
>>
>> Can anyone help or any ideas? How to fix?
>>
>> John.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Jul 27 16:01:51 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 07:01:51 -0700
Subject: [R] Using apply function to merge list of data frames
In-Reply-To: <96fe2dda07db4f948c695e194c9e807c@GBDCVPEXC04.corp.lgc-group.com>
References: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
 <96fe2dda07db4f948c695e194c9e807c@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <1BF642E6-27B5-4A2C-BB1E-DDE93867BBBB@dcn.davis.ca.us>

Er, rbind is not merge... do.call expects the function you specify to handle all the elements of the list in a single invocation... Reduce will work with a two-argument function.

Reduce(merge, df.list, accumulate=TRUE, by='date')

For clarity: apply and the like have for loops inside them, so the primary benefit is a compact and easy to read invocation.

Do not assume that this syntax will have an appreciably-different performance behavior than the for loop solution. In particular, merge is a potentially very slow operation so if your real data frames have the identical key like your example does, using cbind could help performance significantly. Also, both your for loop and Reduce allocate memory as needed, leading to potential memory thrashing that could be a problem for large data sets. If this is an issue for you then you might want to roll your own preallocating for loop or use a function like bind_cols that has that feature [1][2]

[1] http://r4ds.had.co.nz/iteration.html
[2] https://dplyr.tidyverse.org/reference/bind.html


On July 27, 2018 4:45:31 AM PDT, S Ellison <S.Ellison at LGCGroup.com> wrote:
>Short answer: do.call()
>
>do.call("rbind", df.list)
>will rbind all of the data frames in df.list.
>
>You may have to tidy up row names afterwards, and you will need to make
>sure that the data frames all have the same column names and each
>column has the same class, or you'll get unexpected results.
>
>S Ellison
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Naresh
>> Gurbuxani
>> Sent: 25 July 2018 07:17
>> To: R-help at r-project.org
>> Subject: [R] Using apply function to merge list of data frames
>> 
>> I have a list whose components are data frames.  My goal is to
>construct a
>> data frame by merging all the list components.  Is it possible to
>achieve this
>> using apply and without a for loop, as used below?
>> 
>> Thanks,
>> Naresh
>> 
>> mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'),
>by =
>> 'week',
>>                                   length.out = 5), ret = rnorm(5)),
>>                B = data.frame(date = seq.Date(as.Date('2018-01-01'),
>by = 'week',
>>                                   length.out = 5), ret = rnorm(5)))
>> 
>> mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by =
>'week',
>> length.out = 5))
>> 
>> for(ch in names(mylist)){
>>     tempdf <- mylist[[ch]]
>>     names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
>>     mydf <- merge(mydf, tempdf, by = c('date'))}
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>*******************************************************************
>This email and any attachments are confidential. Any
>use...{{dropped:8}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 27 16:12:34 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 07:12:34 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <CAGgJW74swvns=SH2AM70+GeVgkEo+XnjyHVSSUsr+YwL-for8w@mail.gmail.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
 <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>
 <CAGgJW74swvns=SH2AM70+GeVgkEo+XnjyHVSSUsr+YwL-for8w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807270706450.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, Eric Berger wrote:

> I also use emacs with ESS for editing R files and I have been living with
> the comment indentation problem you described. Based on the comments in
> this thread I did a search and found a posted solution that works for me.
> See https://stat.ethz.ch/pipermail/ess-help/2016-May/010970.html

Eric,

   Thanks for sharing this with me. It works here, too.

   What I found strange about the ess comment behavior was having ###
default to the left margin and fewer # indenting increasing distances. That
seems backwards to me. It makes more sense to have # mean no indentation and
increase the spacing with increased #. But, that's just my opinion. :-)

   Oh, by the way, I was not able to resubscribe to the ess-help mail list so
I wrote to the webmaster. This is his response:

"I've found that after the installation of the captcha (which was an
important stop gap measure: We have seen really bad fraudulous subscriptions
!!), there had been some hickups.. and indeed the captcha-based subscription
had been failing for ESS-help probably for about one month.

"I have fixed this now, and tested that it now works (for me)."

Best regards,

Rich


From wdunl@p @ending from tibco@com  Fri Jul 27 16:38:11 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 27 Jul 2018 07:38:11 -0700
Subject: [R] how to locate specific line?
In-Reply-To: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>
References: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>
Message-ID: <CAF8bMcaY+yNe0grv=m--edm4cjKbQGHB34HQs2yOFWihqCXGOg@mail.gmail.com>

If Sys.which("grep") says that grep is available then system("grep -n ...")
will do it.

> cat(c("One","Two","Three","Four"),sep="\n",file=tf<-tempfile())
> system(paste("grep --line-number", shQuote("^T"), shQuote(tf)),
intern=TRUE)
[1] "2:Two"   "3:Three"
> as.integer(sub(":.*$", "", .Last.value))
[1] 2 3

grep is always on Unix-like systems and is in the Rtools and Cygwin
distributions on Windows.  I don't know how standard the '-n' (aka
--line-number) flag is.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 1:13 AM, Jinsong Zhao <jszhao at yeah.net> wrote:

> Hi there,
>
> I have a large/huge text file. I need to locate a line in the file with a
> specific string, for example, "Data Points". Now, I use the following code
> to do:
>
> df <- readLines(file)
> l <- grep("Data Points", df)
>
> However, in this case, the file will be read throughout into R. When the
> file is huge, it will cost much memory and time.
>
> Is there any more elegant way to do that? Thanks.
>
> Best,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@echler @ending from @t@t@m@th@ethz@ch  Fri Jul 27 17:17:56 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 27 Jul 2018 17:17:56 +0200
Subject: [R] Plot Rect Transparency
In-Reply-To: <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
References: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
 <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
Message-ID: <23387.14244.516920.24910@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Thu, 28 Jun 2018 20:57:19 -0400 writes:

    > On 28/06/2018 5:29 PM, Jeff Reichman wrote:
    >> R-Help
    >> 
    >> 
    >> 
    >> Is there a way to make a rectangle transparent (alpha=0.1??)
    >> 
    >> 
    >> 
    >> plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")
    >> 
    >> rect(110, 300, 175, 350, density = 5, border = "red")
    >> 
    >> 
    >> 
    >> Can't figure out how to take the changepoint function results and plot in
    >> ggplot2 so I can just simply add rectangles to the plot function, but I need
    >> to make transparent and there doesn't seem to be an alpha option.

    > Alpha is part of the colour spec.  For example,

    > rect(110, 300, 175, 350, density = 5, border = rgb("red")


    > rect(110, 300, 175, 350, density = 5, border = rgb(red=1, green=0, 
    > blue=0, alpha=0.1))

    > I'm not sure what is the quickest way to work out the rgb values for a 
    > named colour (col2rgb can do it, but not in a convenient format) if you 
    > want to add alpha to it.

IIUC, it is adjustcolor() you were thinking of.  It had been
created to do that and more. 

I'm using that "all the time" nowadays in my graphics code,
e.g.,

> adjustcolor("red", 2/3)
[1] "#FF0000AA"


From b@rhomopoli@ @ending from gm@il@com  Fri Jul 27 17:07:41 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 11:07:41 -0400
Subject: [R] RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
Message-ID: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>

Hi everyone,

I am taking my first R course. This was my first example.

When I executed:

AddLengthNoise <- function(x) {x + rnorm(length(x))}

using 56 as the value of x, I expected the result to be two values,
something like:

[1] 56.17491697 56.02935105

because I expected rnorm to return two values and then 56 to be added to
each of them. Instead, I got one value, something like:

[1] 56.17491697

So I wondered how this happened and wanted to see what happens behind the
scene. Coming from the Excel paradigm, I wondered, "Is there something like
'show calculation steps' in R?" So I Googled it, and got nothing related
but this
<https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
So, I tried breaking my code into separate lines and toggling breakpoints
at all lines, as follows:

6| AddLengthNoise <- function(x) {

   - 7| x +
   - 8| rnorm(
   - 9| length(
   - 10| x)
   - 11| )
   - 12| }

(Where the bullet points above represent the red debugging checkpoints)

Then I tried again:

AddLengthNoise(56)

and as I executed step by step, I could not see what I expected. I couldn't
see each step's result, and I did not understand what I saw neither in the
console nor in the "Traceback" window that appeared.

My 2 questions:

   1. Did I do something wrong?
   2. Is there a way to see, like in Excel's "Show calculation steps", the
   result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
   0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 27 17:20:16 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 08:20:16 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
Message-ID: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>

   I want to save the output of summary(df_name) to a disk file and my
research found that the sink() function is what I want to use. The 'R Cookbook'
provides a an alternative example using cat() to a connection. Here,

con <- file("wysumallyrs.txt", "w")
cat(summary(wyallyrs), file=con)
close(con)

produces this output:

Length:402531      Class :character   Mode  :character   NA NA NA NA
Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
:90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
:2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
:2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
16:00:00   Max. :2018-06-21 00:00:00   NA

   Is there a way to format this output as it is on the console when the
script contains

sum <- summary(wyallyrs)
print(sum)

      date               time                elev           myDate
  Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
  Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
  Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
                                        Mean   :93.86   Mean   :2002-07-28
                                        3rd Qu.:94.43   3rd Qu.:2008-09-10
                                        Max.   :98.91   Max.   :2018-06-21
                                        NA's   :225
      myTime
  Min.   :1988-10-01 00:30:00
  1st Qu.:1996-02-01 00:45:00
  Median :2001-12-01 15:30:00
  Mean   :2002-07-29 03:04:28
  3rd Qu.:2008-09-10 16:00:00
  Max.   :2018-06-21 00:00:00

TIA,

Rich


From wdunl@p @ending from tibco@com  Fri Jul 27 17:40:49 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 27 Jul 2018 08:40:49 -0700
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>

Try
   cat(sep="\n", file=con, capture.output(summary(...)))
capture.output(x) return character vector whose elements contain
the lines of text that would have been printed by print(x).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 8:20 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   I want to save the output of summary(df_name) to a disk file and my
> research found that the sink() function is what I want to use. The 'R
> Cookbook'
> provides a an alternative example using cat() to a connection. Here,
>
> con <- file("wysumallyrs.txt", "w")
> cat(summary(wyallyrs), file=con)
> close(con)
>
> produces this output:
>
> Length:402531      Class :character   Mode  :character   NA NA NA NA
> Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
> :90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
> Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
> :2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
> NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
> :2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
> 16:00:00   Max. :2018-06-21 00:00:00   NA
>
>   Is there a way to format this output as it is on the console when the
> script contains
>
> sum <- summary(wyallyrs)
> print(sum)
>
>      date               time                elev           myDate
>  Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
>  Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
>  Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
>                                        Mean   :93.86   Mean   :2002-07-28
>                                        3rd Qu.:94.43   3rd Qu.:2008-09-10
>                                        Max.   :98.91   Max.   :2018-06-21
>                                        NA's   :225
>      myTime
>  Min.   :1988-10-01 00:30:00
>  1st Qu.:1996-02-01 00:45:00
>  Median :2001-12-01 15:30:00
>  Mean   :2002-07-29 03:04:28
>  3rd Qu.:2008-09-10 16:00:00
>  Max.   :2018-06-21 00:00:00
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Jul 27 17:44:29 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 27 Jul 2018 08:44:29 -0700
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbRaW1wmJMxk2OZafkKunJeNNa0WjNgaqPZvQg6TjMJC3A@mail.gmail.com>

Not quite sure what you mean here.

R is open source, so

> print.summaryDefault  ## at the prompt. It's in base R, so no package::
prefix needed

will give you the code used for formatting. You can then do the same.

Cheers,
Bert







Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 27, 2018 at 8:20 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   I want to save the output of summary(df_name) to a disk file and my
> research found that the sink() function is what I want to use. The 'R
> Cookbook'
> provides a an alternative example using cat() to a connection. Here,
>
> con <- file("wysumallyrs.txt", "w")
> cat(summary(wyallyrs), file=con)
> close(con)
>
> produces this output:
>
> Length:402531      Class :character   Mode  :character   NA NA NA NA
> Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
> :90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
> Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
> :2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
> NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
> :2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
> 16:00:00   Max. :2018-06-21 00:00:00   NA
>
>   Is there a way to format this output as it is on the console when the
> script contains
>
> sum <- summary(wyallyrs)
> print(sum)
>
>      date               time                elev           myDate
>  Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
>  Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
>  Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
>                                        Mean   :93.86   Mean   :2002-07-28
>                                        3rd Qu.:94.43   3rd Qu.:2008-09-10
>                                        Max.   :98.91   Max.   :2018-06-21
>                                        NA's   :225
>      myTime
>  Min.   :1988-10-01 00:30:00
>  1st Qu.:1996-02-01 00:45:00
>  Median :2001-12-01 15:30:00
>  Mean   :2002-07-29 03:04:28
>  3rd Qu.:2008-09-10 16:00:00
>  Max.   :2018-06-21 00:00:00
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 27 17:52:59 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 08:52:59 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, William Dunlap wrote:

> Try
>   cat(sep="\n", file=con, capture.output(summary(...)))
> capture.output(x) return character vector whose elements contain
> the lines of text that would have been printed by print(x).

Bill,

   Thanks very much. I doubt my searches would have found capture.output().

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 27 17:55:02 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 08:55:02 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <CAGxFJbRaW1wmJMxk2OZafkKunJeNNa0WjNgaqPZvQg6TjMJC3A@mail.gmail.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAGxFJbRaW1wmJMxk2OZafkKunJeNNa0WjNgaqPZvQg6TjMJC3A@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807270854310.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, Bert Gunter wrote:

> print.summaryDefault  ## at the prompt. It's in base R, so no package::
> prefix needed will give you the code used for formatting. You can then do
> the same.

Bert,

   Thank you.

Rich


From li@t@ @ending from dewey@myzen@co@uk  Fri Jul 27 18:12:30 2018
From: li@t@ @ending from dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 27 Jul 2018 17:12:30 +0100
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <ad96cb6c-f260-00c8-eda0-df1ed7ad9c29@dewey.myzen.co.uk>

Dear Ibrauheem

First try

length(56)

then try
rnorm()
using the value you got in stage 1

Michael

On 27/07/2018 16:07, ??????? ???? Ibrauheem Khat'taub wrote:
> Hi everyone,
> 
> I am taking my first R course. This was my first example.
> 
> When I executed:
> 
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
> 
> using 56 as the value of x, I expected the result to be two values,
> something like:
> 
> [1] 56.17491697 56.02935105
> 
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
> 
> [1] 56.17491697
> 
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
> 
> 6| AddLengthNoise <- function(x) {
> 
>     - 7| x +
>     - 8| rnorm(
>     - 9| length(
>     - 10| x)
>     - 11| )
>     - 12| }
> 
> (Where the bullet points above represent the red debugging checkpoints)
> 
> Then I tried again:
> 
> AddLengthNoise(56)
> 
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
> 
> My 2 questions:
> 
>     1. Did I do something wrong?
>     2. Is there a way to see, like in Excel's "Show calculation steps", the
>     result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
>     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Jul 27 18:32:37 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 09:32:37 -0700
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <CF87BBB9-3FC1-48A0-8CC9-FEDF9E1AD6AD@dcn.davis.ca.us>

Debugging in R applies one statement at a time. If you want to debug within a statement you can "step into" the function calls within the statement or you can execute the function calls separately and inspect the result. Your function consists of one statement so the debugger only has one place to stop. However, once stopped, you can execute

length(x)

and get a result 1 instead of 2 as you are erroneously expecting.

The length function in R is NOT the equivalent of the LEN function in Excel... it tells you how many elements are in the vector, not the number of digits in a numeric or the number of characters in a string.

Does 

AddLengthNoise( rep(56, 2) ) behave as desired?

On July 27, 2018 8:07:41 AM PDT, "??????? ???? Ibrauheem Khat'taub" <barhomopolis at gmail.com> wrote:
>Hi everyone,
>
>I am taking my first R course. This was my first example.
>
>When I executed:
>
>AddLengthNoise <- function(x) {x + rnorm(length(x))}
>
>using 56 as the value of x, I expected the result to be two values,
>something like:
>
>[1] 56.17491697 56.02935105
>
>because I expected rnorm to return two values and then 56 to be added
>to
>each of them. Instead, I got one value, something like:
>
>[1] 56.17491697
>
>So I wondered how this happened and wanted to see what happens behind
>the
>scene. Coming from the Excel paradigm, I wondered, "Is there something
>like
>'show calculation steps' in R?" So I Googled it, and got nothing
>related
>but this
><https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
>So, I tried breaking my code into separate lines and toggling
>breakpoints
>at all lines, as follows:
>
>6| AddLengthNoise <- function(x) {
>
>   - 7| x +
>   - 8| rnorm(
>   - 9| length(
>   - 10| x)
>   - 11| )
>   - 12| }
>
>(Where the bullet points above represent the red debugging checkpoints)
>
>Then I tried again:
>
>AddLengthNoise(56)
>
>and as I executed step by step, I could not see what I expected. I
>couldn't
>see each step's result, and I did not understand what I saw neither in
>the
>console nor in the "Traceback" window that appeared.
>
>My 2 questions:
>
>   1. Did I do something wrong?
>2. Is there a way to see, like in Excel's "Show calculation steps", the
> result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
>   0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@cqueen1 @ending from llnl@gov  Fri Jul 27 18:40:49 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 27 Jul 2018 16:40:49 +0000
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
Message-ID: <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>

Given your description, I would start with

sink('wysumallyrs.txt')
print( summary(wyallyrs) )
sink()

and see if that doesn't meet your needs.

Some of the basic principles:

(1) Whenever you type the name of an R object at the R prompt, it is as if R wraps whatever you typed inside print(). Here are some examples to illustrate this

> 3
[1] 3
> print(3)
[1] 3
> sqrt(2)
[1] 1.414214
> print(sqrt(2))
[1] 1.414214
> dtf <- data.frame(x=1:4, y=rnorm(4))
> dtf
  x            y
1 1  0.493453813
2 2 -0.586864827
3 3  2.481334630
4 4 -0.007107974
> print(dtf)
  x            y
1 1  0.493453813
2 2 -0.586864827
3 3  2.481334630
4 4 -0.007107974
> lm(y~x, dtf)

Call:
lm(formula = y ~ x, data = dtf)

Coefficients:
(Intercept)            x  
     0.2036       0.1567  

> print( lm(y~x, dtf) )

Call:
lm(formula = y ~ x, data = dtf)

Coefficients:
(Intercept)            x  
     0.2036       0.1567  

>

In every case, the output is identical. 

Note that when making an assignment, as in
   dtf <- data.frame(x=1:4, y=rnorm(4))
there is no automatic printing


(2) print() and cat() are not the same thing

> cat( lm(y~x, dtf) )
Error in cat(lm(y ~ x, dtf)) : 
  argument 1 (type 'list') cannot be handled by 'cat'

print() generally knows how to display complex objects in a nice format/layout, cat() does not. cat() is designed for a different purpose.

If you want to start learning how it is that print() know how to format complex objects, you could start with
> ?print.data.frame
> ?print.default
> ?print


(3) Note that if you use sink(), print(), sink() the way I suggested, then subsequently you can append to the file using

sink('wysumallyrs.txt', append=TRUE)
{print or cat or whatever}
sink()

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/27/18, 8:20 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       I want to save the output of summary(df_name) to a disk file and my
    research found that the sink() function is what I want to use. The 'R Cookbook'
    provides a an alternative example using cat() to a connection. Here,
    
    con <- file("wysumallyrs.txt", "w")
    cat(summary(wyallyrs), file=con)
    close(con)
    
    produces this output:
    
    Length:402531      Class :character   Mode  :character   NA NA NA NA
    Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
    :90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
    Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
    :2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
    NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
    :2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
    16:00:00   Max. :2018-06-21 00:00:00   NA
    
       Is there a way to format this output as it is on the console when the
    script contains
    
    sum <- summary(wyallyrs)
    print(sum)
    
          date               time                elev           myDate
      Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
      Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
      Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
                                            Mean   :93.86   Mean   :2002-07-28
                                            3rd Qu.:94.43   3rd Qu.:2008-09-10
                                            Max.   :98.91   Max.   :2018-06-21
                                            NA's   :225
          myTime
      Min.   :1988-10-01 00:30:00
      1st Qu.:1996-02-01 00:45:00
      Median :2001-12-01 15:30:00
      Mean   :2002-07-29 03:04:28
      3rd Qu.:2008-09-10 16:00:00
      Max.   :2018-06-21 00:00:00
    
    TIA,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @@r@h@go@lee @ending from gm@il@com  Fri Jul 27 18:55:15 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Fri, 27 Jul 2018 10:55:15 -0600
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <12344e39-b344-4a31-b7fb-5b5e375b9436@Spark>

You can readily do it yourself:

x <- 56
length(x) # hint: why do you expect length(56) to be 2?
rnorm(length(x))
x + rnorm(length(x))

For more complicated problems, the debugger is useful, but I almost always find investigating the steps at the command line to be the most informative.

Sarah
On Jul 27, 2018, 9:38 AM -0600, ??????? ???? Ibrauheem Khat'taub <barhomopolis at gmail.com>, wrote:
> Hi everyone,
>
> I am taking my first R course. This was my first example.
>
> When I executed:
>
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
>
> using 56 as the value of x, I expected the result to be two values,
> something like:
>
> [1] 56.17491697 56.02935105
>
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
>
> [1] 56.17491697
>
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
>
> 6| AddLengthNoise <- function(x) {
>
> - 7| x +
> - 8| rnorm(
> - 9| length(
> - 10| x)
> - 11| )
> - 12| }
>
> (Where the bullet points above represent the red debugging checkpoints)
>
> Then I tried again:
>
> AddLengthNoise(56)
>
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
>
> My 2 questions:
>
> 1. Did I do something wrong?
> 2. Is there a way to see, like in Excel's "Show calculation steps", the
> result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
> 0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 27 18:56:52 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 09:56:52 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>
Message-ID: <alpine.LNX.2.20.1807270950580.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, MacQueen, Don wrote:

> Given your description, I would start with
>
> sink('wysumallyrs.txt')
> print( summary(wyallyrs) )
> sink()
>
> and see if that doesn't meet your needs.

Don,

   I started with sink() trying to follow
<https://stat.ethz.ch/R-manual/R-patched/library/base/html/sink.html> (which
is the same as ?sink within R) using the two examples at the bottom. Neither
used the print() function and the results were an empty file (using example
1) or an error message about incorrect usage (using example 2).

   Your solution does make more sense than does using cat().

Thanks,

Rich


From wdunl@p @ending from tibco@com  Fri Jul 27 19:56:54 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 27 Jul 2018 10:56:54 -0700
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
 <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZ0yxpFvZ0P10eGsroO_vHLOAEP_NevyRADU2JXGf7ZPw@mail.gmail.com>

I often use capture.output to slightly reformat printout output.  E.g, to
indent str's output to make it easier to read debugging printouts:
debug_print <- function(x, name=substitute(x), indent=4)
{
   cat(sep="\n", name, paste0(strrep(" ", indent), capture.output(str(x))))
}
Used as in
> myData <- list(One=1:100,Two=log2(1:5))
> debug_print(myData)
myData
    List of 2
     $ One: int [1:100] 1 2 3 4 5 6 7 8 9 10 ...
     $ Two: num [1:5] 0 1 1.58 2 2.32


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 8:52 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 27 Jul 2018, William Dunlap wrote:
>
> Try
>>   cat(sep="\n", file=con, capture.output(summary(...)))
>> capture.output(x) return character vector whose elements contain
>> the lines of text that would have been printed by print(x).
>>
>
> Bill,
>
>   Thanks very much. I doubt my searches would have found capture.output().
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Jul 27 20:19:36 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 11:19:36 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <CAF8bMcZ0yxpFvZ0P10eGsroO_vHLOAEP_NevyRADU2JXGf7ZPw@mail.gmail.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
 <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>
 <CAF8bMcZ0yxpFvZ0P10eGsroO_vHLOAEP_NevyRADU2JXGf7ZPw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807271118580.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, William Dunlap wrote:

> I often use capture.output to slightly reformat printout output.  E.g, to
> indent str's output to make it easier to read debugging printouts:
> debug_print <- function(x, name=substitute(x), indent=4)
> {
>   cat(sep="\n", name, paste0(strrep(" ", indent), capture.output(str(x))))
> }
> Used as in
>> myData <- list(One=1:100,Two=log2(1:5))
>> debug_print(myData)
> myData
>    List of 2
>     $ One: int [1:100] 1 2 3 4 5 6 7 8 9 10 ...
>     $ Two: num [1:5] 0 1 1.58 2 2.32

Bill,

   This is good to know.

Many thanks,

Rich


From b@rhomopoli@ @ending from gm@il@com  Fri Jul 27 20:26:51 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:26:51 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <d5eba459-0d66-34d8-913f-8665a8d02a74@sapo.pt>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <d5eba459-0d66-34d8-913f-8665a8d02a74@sapo.pt>
Message-ID: <CAC4BqreJnVBobZmnPs87r6ECku3Q-mpa2GeLiJZwxHQcL1SQLA@mail.gmail.com>

Thanks a lot, Rui!



On Fri, 27 Jul 2018 at 12:02, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> First of all welcome to R, I hope you enjoy it and that as you go along
> it will give less and less troubles.
>
> Now, why would length(56) return 2? It's just one number, a vector of
> length 1.
>
> Start by trying it at an R prompt and see the result.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 16:07 de 27-07-2018, ??????? ???? Ibrauheem Khat'taub escreveu:
> > Hi everyone,
> >
> > I am taking my first R course. This was my first example.
> >
> > When I executed:
> >
> > AddLengthNoise <- function(x) {x + rnorm(length(x))}
> >
> > using 56 as the value of x, I expected the result to be two values,
> > something like:
> >
> > [1] 56.17491697 56.02935105
> >
> > because I expected rnorm to return two values and then 56 to be added to
> > each of them. Instead, I got one value, something like:
> >
> > [1] 56.17491697
> >
> > So I wondered how this happened and wanted to see what happens behind the
> > scene. Coming from the Excel paradigm, I wondered, "Is there something
> like
> > 'show calculation steps' in R?" So I Googled it, and got nothing related
> > but this
> > <
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> > So, I tried breaking my code into separate lines and toggling breakpoints
> > at all lines, as follows:
> >
> > 6| AddLengthNoise <- function(x) {
> >
> >     - 7| x +
> >     - 8| rnorm(
> >     - 9| length(
> >     - 10| x)
> >     - 11| )
> >     - 12| }
> >
> > (Where the bullet points above represent the red debugging checkpoints)
> >
> > Then I tried again:
> >
> > AddLengthNoise(56)
> >
> > and as I executed step by step, I could not see what I expected. I
> couldn't
> > see each step's result, and I did not understand what I saw neither in
> the
> > console nor in the "Traceback" window that appeared.
> >
> > My 2 questions:
> >
> >     1. Did I do something wrong?
> >     2. Is there a way to see, like in Excel's "Show calculation steps",
> the
> >     result of each step alone (i.e. length(56)=2 ==>
> rnorm(2)={0.17491697;
> >     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From b@rhomopoli@ @ending from gm@il@com  Fri Jul 27 20:27:16 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:27:16 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <ad96cb6c-f260-00c8-eda0-df1ed7ad9c29@dewey.myzen.co.uk>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <ad96cb6c-f260-00c8-eda0-df1ed7ad9c29@dewey.myzen.co.uk>
Message-ID: <CAC4Bqrfw_kaw=c77n235VVv7CfA02RVd58A1VehzxTq9Coetnw@mail.gmail.com>

 Thanks a lot, Michael!



On Fri, 27 Jul 2018 at 12:12, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Ibrauheem
>
> First try
>
> length(56)
>
> then try
> rnorm()
> using the value you got in stage 1
>
> Michael
>
> On 27/07/2018 16:07, ??????? ???? Ibrauheem Khat'taub wrote:
> > Hi everyone,
> >
> > I am taking my first R course. This was my first example.
> >
> > When I executed:
> >
> > AddLengthNoise <- function(x) {x + rnorm(length(x))}
> >
> > using 56 as the value of x, I expected the result to be two values,
> > something like:
> >
> > [1] 56.17491697 56.02935105
> >
> > because I expected rnorm to return two values and then 56 to be added to
> > each of them. Instead, I got one value, something like:
> >
> > [1] 56.17491697
> >
> > So I wondered how this happened and wanted to see what happens behind the
> > scene. Coming from the Excel paradigm, I wondered, "Is there something
> like
> > 'show calculation steps' in R?" So I Googled it, and got nothing related
> > but this
> > <
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> > So, I tried breaking my code into separate lines and toggling breakpoints
> > at all lines, as follows:
> >
> > 6| AddLengthNoise <- function(x) {
> >
> >     - 7| x +
> >     - 8| rnorm(
> >     - 9| length(
> >     - 10| x)
> >     - 11| )
> >     - 12| }
> >
> > (Where the bullet points above represent the red debugging checkpoints)
> >
> > Then I tried again:
> >
> > AddLengthNoise(56)
> >
> > and as I executed step by step, I could not see what I expected. I
> couldn't
> > see each step's result, and I did not understand what I saw neither in
> the
> > console nor in the "Traceback" window that appeared.
> >
> > My 2 questions:
> >
> >     1. Did I do something wrong?
> >     2. Is there a way to see, like in Excel's "Show calculation steps",
> the
> >     result of each step alone (i.e. length(56)=2 ==>
> rnorm(2)={0.17491697;
> >     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From b@rhomopoli@ @ending from gm@il@com  Fri Jul 27 20:27:52 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:27:52 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CF87BBB9-3FC1-48A0-8CC9-FEDF9E1AD6AD@dcn.davis.ca.us>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <CF87BBB9-3FC1-48A0-8CC9-FEDF9E1AD6AD@dcn.davis.ca.us>
Message-ID: <CAC4BqrdV1FBy5OGmRAUiPM6o6TTR8JZtm_kec2M96uzEnWpKRg@mail.gmail.com>

OMG, Jeff, this is so helpful of you!
Thanks a lot!


On Fri, 27 Jul 2018 at 12:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Debugging in R applies one statement at a time. If you want to debug
> within a statement you can "step into" the function calls within the
> statement or you can execute the function calls separately and inspect the
> result. Your function consists of one statement so the debugger only has
> one place to stop. However, once stopped, you can execute
>
> length(x)
>
> and get a result 1 instead of 2 as you are erroneously expecting.
>
> The length function in R is NOT the equivalent of the LEN function in
> Excel... it tells you how many elements are in the vector, not the number
> of digits in a numeric or the number of characters in a string.
>
> Does
>
> AddLengthNoise( rep(56, 2) ) behave as desired?
>
> On July 27, 2018 8:07:41 AM PDT, "??????? ???? Ibrauheem Khat'taub" <
> barhomopolis at gmail.com> wrote:
> >Hi everyone,
> >
> >I am taking my first R course. This was my first example.
> >
> >When I executed:
> >
> >AddLengthNoise <- function(x) {x + rnorm(length(x))}
> >
> >using 56 as the value of x, I expected the result to be two values,
> >something like:
> >
> >[1] 56.17491697 56.02935105
> >
> >because I expected rnorm to return two values and then 56 to be added
> >to
> >each of them. Instead, I got one value, something like:
> >
> >[1] 56.17491697
> >
> >So I wondered how this happened and wanted to see what happens behind
> >the
> >scene. Coming from the Excel paradigm, I wondered, "Is there something
> >like
> >'show calculation steps' in R?" So I Googled it, and got nothing
> >related
> >but this
> ><
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> >So, I tried breaking my code into separate lines and toggling
> >breakpoints
> >at all lines, as follows:
> >
> >6| AddLengthNoise <- function(x) {
> >
> >   - 7| x +
> >   - 8| rnorm(
> >   - 9| length(
> >   - 10| x)
> >   - 11| )
> >   - 12| }
> >
> >(Where the bullet points above represent the red debugging checkpoints)
> >
> >Then I tried again:
> >
> >AddLengthNoise(56)
> >
> >and as I executed step by step, I could not see what I expected. I
> >couldn't
> >see each step's result, and I did not understand what I saw neither in
> >the
> >console nor in the "Traceback" window that appeared.
> >
> >My 2 questions:
> >
> >   1. Did I do something wrong?
> >2. Is there a way to see, like in Excel's "Show calculation steps", the
> > result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
> >   0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From b@rhomopoli@ @ending from gm@il@com  Fri Jul 27 20:28:19 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:28:19 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <12344e39-b344-4a31-b7fb-5b5e375b9436@Spark>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <12344e39-b344-4a31-b7fb-5b5e375b9436@Spark>
Message-ID: <CAC4Bqre7yTKZ_HS6bDd7UaDvATU38HZtT-5RYMQYjWS=0catFQ@mail.gmail.com>

 Thanks a lot, Sarah! Appreciate the help!


On Fri, 27 Jul 2018 at 12:55, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> You can readily do it yourself:
>
> x <- 56
> length(x) # hint: why do you expect length(56) to be 2?
> rnorm(length(x))
> x + rnorm(length(x))
>
> For more complicated problems, the debugger is useful, but I almost always
> find investigating the steps at the command line to be the most informative.
>
> Sarah
> On Jul 27, 2018, 9:38 AM -0600, ??????? ???? Ibrauheem Khat'taub <
> barhomopolis at gmail.com>, wrote:
>
> Hi everyone,
>
> I am taking my first R course. This was my first example.
>
> When I executed:
>
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
>
> using 56 as the value of x, I expected the result to be two values,
> something like:
>
> [1] 56.17491697 56.02935105
>
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
>
> [1] 56.17491697
>
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
>
> 6| AddLengthNoise <- function(x) {
>
> - 7| x +
> - 8| rnorm(
> - 9| length(
> - 10| x)
> - 11| )
> - 12| }
>
> (Where the bullet points above represent the red debugging checkpoints)
>
> Then I tried again:
>
> AddLengthNoise(56)
>
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
>
> My 2 questions:
>
> 1. Did I do something wrong?
> 2. Is there a way to see, like in Excel's "Show calculation steps", the
> result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
> 0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Fri Jul 27 18:02:36 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 27 Jul 2018 17:02:36 +0100
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <d5eba459-0d66-34d8-913f-8665a8d02a74@sapo.pt>

Hello,

First of all welcome to R, I hope you enjoy it and that as you go along 
it will give less and less troubles.

Now, why would length(56) return 2? It's just one number, a vector of 
length 1.

Start by trying it at an R prompt and see the result.

Hope this helps,

Rui Barradas

?s 16:07 de 27-07-2018, ??????? ???? Ibrauheem Khat'taub escreveu:
> Hi everyone,
> 
> I am taking my first R course. This was my first example.
> 
> When I executed:
> 
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
> 
> using 56 as the value of x, I expected the result to be two values,
> something like:
> 
> [1] 56.17491697 56.02935105
> 
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
> 
> [1] 56.17491697
> 
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
> 
> 6| AddLengthNoise <- function(x) {
> 
>     - 7| x +
>     - 8| rnorm(
>     - 9| length(
>     - 10| x)
>     - 11| )
>     - 12| }
> 
> (Where the bullet points above represent the red debugging checkpoints)
> 
> Then I tried again:
> 
> AddLengthNoise(56)
> 
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
> 
> My 2 questions:
> 
>     1. Did I do something wrong?
>     2. Is there a way to see, like in Excel's "Show calculation steps", the
>     result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
>     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@cqueen1 @ending from llnl@gov  Fri Jul 27 23:09:53 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 27 Jul 2018 21:09:53 +0000
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270950580.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>
 <alpine.LNX.2.20.1807270950580.21777@salmo.appl-ecosys.com>
Message-ID: <EF2A617D-6779-4764-A5D1-364A6B89D03E@llnl.gov>

Hmmm. I do get output in the file with the first example, and the second example is too complicated for me.
-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/27/18, 9:56 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Fri, 27 Jul 2018, MacQueen, Don wrote:
    
    > Given your description, I would start with
    >
    > sink('wysumallyrs.txt')
    > print( summary(wyallyrs) )
    > sink()
    >
    > and see if that doesn't meet your needs.
    
    Don,
    
       I started with sink() trying to follow
    <https://stat.ethz.ch/R-manual/R-patched/library/base/html/sink.html> (which
    is the same as ?sink within R) using the two examples at the bottom. Neither
    used the print() function and the results were an empty file (using example
    1) or an error message about incorrect usage (using example 2).
    
       Your solution does make more sense than does using cat().
    
    Thanks,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@turner @ending from @uckl@nd@@c@nz  Sat Jul 28 05:35:22 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Jul 2018 15:35:22 +1200
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
Message-ID: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>


I have the task of producing some boxplot graphics with the requirement 
that these have the same general appearance as a set of such graphics
as were produced last year.  I do not have access to the code that was
used to produce the "last year" graphics.

There are multiple boxplots per figure and these boxplots appear in 
groups (with two boxplots in each group in the simplest instance; there 
are four or more per group in other instances, but I figure that if I 
can work out how to handle two, then ....).

After a bit of Googling I found that ggplot() does basically what I 
want.  However my mindset seems to be substantially incompatible with 
that of ggplot() and I cannot figure out how to make some adjustments 
which are needed in order to make my plots look like last year's.

In last year's graphics the boxes were unfilled and were distinguished
(within groups) by their boundary colours, which were "red" and "black"
in the simple two-per-group instance.  I achieved the "unfilled" effect 
by setting alpha=0 inside the call to geom_boxplot().  (Is this the 
Right Thing to Do?)  However I cannot get the boundary colours of the
boxes to be "red" and "black".

I have attached a sourceable script ("demo.txt") showing what I have 
tried so far.  I don't really understand the code; I simply copied and 
adjusted code that I saw on stackoverflow.  (Fairly mindlessly I'm afraid.)

Problems:

(1) The borders of the boxes are distinct, but they are sort-of-pink and 
sort-of-blue, and I cannot for the life of me figure out how to make 
them red and black.

(2) Putting in "color=Type" seemed to have the effect of creating two 
legends, one with the desired legend title but all in black, and one 
with legend title equal to "Type" but using the colours that actually 
appear. How can I get just one "appropriate" legend?

(3) Last year's graphics have the x-axis starting at 0 (rather than at
c. 3.5).  I tried using + xlim(0,8.5) but got told "Error: Discrete 
value supplied to continuous scale".  How can I make the appropriate
adjustment?

(4) Last year's graphics have y-axis tick marks, labels and grid lines 
at 700, 800, 900, ..., 2000, 2100.  How can I reproduce this?

I actually had several additional questions, but thought I'd better 
scrounge around a bit more before posting this, and thereby managed 
(mirabile dictu!) to answer them myself.

Can anyone help me out with questions (1) --- (4)?  Please keep it 
simple and very explicit, for I am a bear of very little brain and long 
words bother me!

Thanks.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180728/693e4dbe/attachment.txt>

From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 28 07:03:47 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 22:03:47 -0700 (PDT)
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
Message-ID: <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>

When you understand the strong dependence on how the data controls ggplot, 
using it gets much easier. I still have to google details sometimes 
though. Note that it can be very difficult to make a weird plot (e.g. 
multiple parallel axes) in ggplot because it is very internally 
consistent... a blessing and a curse.

1) Colour is assigned in the scale according to order of levels of the 
factor. Note that while they are both discrete, the so-called "discrete" 
scales auto-colour, but "manual" scales require you to specify the exact 
colour sequence.

2) Assigning constants to properties is done outside the mapping (aes). 
Note that "colour" is for lines and shapes outlines, while "fill" is 
colour meant to fill in shapes. When the names of these two scales are the 
same and the values are the same, the legends will merge. If not, they 
will be shown separately.

3) Discrete scales are controlled by the levels in the data. To prevent 
ggplot from removing missing levels, use the drop=FALSE argument.

4) Breaks are a property of the scale.

My changes were:

Year <- factor( rep( 4:8, each = 50, times = 2 ), levels = 0:8 )
DemoDat <- data.frame(Year = Year, Score = c( X0 , X1 ), Type = Type )

ggplot( data = DemoDat
       , aes( x = Year, y = Score, color = Type )
       , fill = NULL
       ) +
     geom_boxplot( position = position_dodge(1) ) +
     theme_minimal() +
     scale_colour_manual( name = "National v. Local"
                        , values = c( "red", "black" ) ) +
     scale_x_discrete( drop = FALSE ) +
     scale_y_continuous( breaks = seq( 700, 2100, 100 ) )

Good luck with your graphics grammar!

On Sat, 28 Jul 2018, Rolf Turner wrote:

>
> I have the task of producing some boxplot graphics with the requirement that 
> these have the same general appearance as a set of such graphics
> as were produced last year.  I do not have access to the code that was
> used to produce the "last year" graphics.
>
> There are multiple boxplots per figure and these boxplots appear in groups 
> (with two boxplots in each group in the simplest instance; there are four or 
> more per group in other instances, but I figure that if I can work out how to 
> handle two, then ....).
>
> After a bit of Googling I found that ggplot() does basically what I want. 
> However my mindset seems to be substantially incompatible with that of 
> ggplot() and I cannot figure out how to make some adjustments which are 
> needed in order to make my plots look like last year's.
>
> In last year's graphics the boxes were unfilled and were distinguished
> (within groups) by their boundary colours, which were "red" and "black"
> in the simple two-per-group instance.  I achieved the "unfilled" effect by 
> setting alpha=0 inside the call to geom_boxplot().  (Is this the Right Thing 
> to Do?)  However I cannot get the boundary colours of the
> boxes to be "red" and "black".
>
> I have attached a sourceable script ("demo.txt") showing what I have tried so 
> far.  I don't really understand the code; I simply copied and adjusted code 
> that I saw on stackoverflow.  (Fairly mindlessly I'm afraid.)
>
> Problems:
>
> (1) The borders of the boxes are distinct, but they are sort-of-pink and 
> sort-of-blue, and I cannot for the life of me figure out how to make them red 
> and black.
>
> (2) Putting in "color=Type" seemed to have the effect of creating two 
> legends, one with the desired legend title but all in black, and one with 
> legend title equal to "Type" but using the colours that actually appear. How 
> can I get just one "appropriate" legend?
>
> (3) Last year's graphics have the x-axis starting at 0 (rather than at
> c. 3.5).  I tried using + xlim(0,8.5) but got told "Error: Discrete value 
> supplied to continuous scale".  How can I make the appropriate
> adjustment?
>
> (4) Last year's graphics have y-axis tick marks, labels and grid lines at 
> 700, 800, 900, ..., 2000, 2100.  How can I reproduce this?
>
> I actually had several additional questions, but thought I'd better scrounge 
> around a bit more before posting this, and thereby managed (mirabile dictu!) 
> to answer them myself.
>
> Can anyone help me out with questions (1) --- (4)?  Please keep it simple and 
> very explicit, for I am a bear of very little brain and long words bother me!
>
> Thanks.
>
> cheers,
>
> Rolf Turner
>
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From @k@h@y_e4 @ending from hotm@il@com  Sat Jul 28 07:58:36 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sat, 28 Jul 2018 05:58:36 +0000
Subject: [R] subsetting ls() as per class...
Message-ID: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear memebers,
                               I am using R in AWS linux instance for my research. I want to remove certain objects from the global environment  to reduce my EBS cost..for example, I want to remove all objects of class "xts", "zoo". Is there any way to automate this, instead of removing the objects one by one?

Basically, I want to subset  ls() according to class, and then remove that subset by using rm function.

I got to know about mget in SO, but that is not working in my case....

Also, all the above objects end with ".NS".  I came to know that you can remove objects starting with a certain pattern; is there any way to remove objects ending in a certain pattern?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From peter@l@ngfelder @ending from gm@il@com  Sat Jul 28 08:11:54 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Fri, 27 Jul 2018 23:11:54 -0700
Subject: [R] subsetting ls() as per class...
In-Reply-To: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CA+hbrhW_-eD+izCYZTgCRma4qz-iB3FeqbUSZKgv9isx6RpnEA@mail.gmail.com>

Looking at ?rm, my solution would be something like

rm(list = grep("\\.NS$", ls(), value = TRUE))

But test it since I have not tested it.

Peter


On Fri, Jul 27, 2018 at 10:58 PM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> dear memebers,
>                                I am using R in AWS linux instance for my research. I want to remove certain objects from the global environment  to reduce my EBS cost..for example, I want to remove all objects of class "xts", "zoo". Is there any way to automate this, instead of removing the objects one by one?
>
> Basically, I want to subset  ls() according to class, and then remove that subset by using rm function.
>
> I got to know about mget in SO, but that is not working in my case....
>
> Also, all the above objects end with ".NS".  I came to know that you can remove objects starting with a certain pattern; is there any way to remove objects ending in a certain pattern?
>
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 28 08:18:10 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 23:18:10 -0700
Subject: [R] subsetting ls() as per class...
In-Reply-To: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <47A8102A-F379-4B91-A8EA-82827EFDAC45@dcn.davis.ca.us>

You can extract the names into a character vector with ls and then use grep(..., values=TRUE ) to select which ones you want to remove, and then pass that list to rm.

However, due to the way R handles memory you are unlikely to see much savings by doing this. I would recommend focusing on creating a script or series of scripts that can allow you to re-create your analysis, and then restarting R whenever you are ready to reduce memory usage. This will have the side benefit of leaving you with a verified-complete record of how your analysis was done.

On July 27, 2018 10:58:36 PM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear memebers,
>I am using R in AWS linux instance for my research. I want to remove
>certain objects from the global environment  to reduce my EBS cost..for
>example, I want to remove all objects of class "xts", "zoo". Is there
>any way to automate this, instead of removing the objects one by one?
>
>Basically, I want to subset  ls() according to class, and then remove
>that subset by using rm function.
>
>I got to know about mget in SO, but that is not working in my case....
>
>Also, all the above objects end with ".NS".  I came to know that you
>can remove objects starting with a certain pattern; is there any way to
>remove objects ending in a certain pattern?
>
>very many thanks for your time and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From t@n@@@ @ending from gm@il@com  Sat Jul 28 08:24:46 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Fri, 27 Jul 2018 23:24:46 -0700
Subject: [R] a suggestion about the display of structural variants in R
Message-ID: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>

Dear all,

we wish you a fruitful and refreshing weekend ! Thought that I may also
write to ask you for a suggestion, specifically if you could please advise
on whether there is any package already built (in R) that could help with
the following data visualization :


    we have a set of mutations from many cancer samples

    we would like to display the POINT MUTATIONS along the chromosome
coordinates (on the linear scale, ie. HORIZONTALLY)

    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
VERTICAL LINES connecting the breakpoints that are located on the
chromosomes that are represented HORIZONTALLY

Thanks a lot,

-- bogdan

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Sat Jul 28 11:34:47 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Jul 2018 21:34:47 +1200
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
Message-ID: <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>


On 28/07/18 17:03, Jeff Newmiller wrote:

> When you understand the strong dependence on how the data controls 
> ggplot, using it gets much easier. I still have to google details 
> sometimes though. Note that it can be very difficult to make a weird 
> plot (e.g. multiple parallel axes) in ggplot because it is very 
> internally consistent... a blessing and a curse.
> 
> 1) Colour is assigned in the scale according to order of levels of the 
> factor. Note that while they are both discrete, the so-called "discrete" 
> scales auto-colour, but "manual" scales require you to specify the exact 
> colour sequence.
> 
> 2) Assigning constants to properties is done outside the mapping (aes). 
> Note that "colour" is for lines and shapes outlines, while "fill" is 
> colour meant to fill in shapes. When the names of these two scales are 
> the same and the values are the same, the legends will merge. If not, 
> they will be shown separately.
> 
> 3) Discrete scales are controlled by the levels in the data. To prevent 
> ggplot from removing missing levels, use the drop=FALSE argument.
> 
> 4) Breaks are a property of the scale.
> 
> My changes were:
> 
> Year <- factor( rep( 4:8, each = 50, times = 2 ), levels = 0:8 )
> DemoDat <- data.frame(Year = Year, Score = c( X0 , X1 ), Type = Type )
> 
> ggplot( data = DemoDat
>  ????? , aes( x = Year, y = Score, color = Type )
>  ????? , fill = NULL
>  ????? ) +
>  ??? geom_boxplot( position = position_dodge(1) ) +
>  ??? theme_minimal() +
>  ??? scale_colour_manual( name = "National v. Local"
>  ?????????????????????? , values = c( "red", "black" ) ) +
>  ??? scale_x_discrete( drop = FALSE ) +
>  ??? scale_y_continuous( breaks = seq( 700, 2100, 100 ) )
> 
> Good luck with your graphics grammar!

Dear Jeff,

Thanks very much for this cogent advice and for taking the trouble to 
steer me in the right direction.  However I am not quite out of the 
woods yet.

(1) I'm still getting two legends.  How do I stop this from happening?

(2) The boxes are "filled" (with pinkish and blueish colours --- which 
are referenced in the second of the two legends that I get).  How can I 
get "unfilled" boxes?

(3) The y-axis scale runs only from 800 to 1800, rather than from 700 to 
2100.  How can I force it to run from 700 to 2100?

(4) With the modified code we now get some "outliers" (points beyond the 
whisker tips) plotted --- which I didn't get before (and don't want, 
because "last year's" graphics did not include outliers).  How can I 
suppress the plotting of outliers?

I have attached a pdf containing the results of running the code that
you provided, so that you can readily see what is happening.

May I prevail upon your good graces to enlighten me about questions
(1) --- (4) above?

Ever so humbly grateful.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
A non-text attachment was scrubbed...
Name: demoPlot.pdf
Type: application/pdf
Size: 5772 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180728/ea156d7a/attachment.pdf>

From henrik@bengt@@on @ending from gm@il@com  Sat Jul 28 12:18:44 2018
From: henrik@bengt@@on @ending from gm@il@com (Henrik Bengtsson)
Date: Sat, 28 Jul 2018 12:18:44 +0200
Subject: [R] subsetting ls() as per class...
In-Reply-To: <47A8102A-F379-4B91-A8EA-82827EFDAC45@dcn.davis.ca.us>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <47A8102A-F379-4B91-A8EA-82827EFDAC45@dcn.davis.ca.us>
Message-ID: <CAFDcVCTvvwEebxA5w8Mc6Z-ZmmruvLT6mzCWN6xtZXTAqes3yA@mail.gmail.com>

The ll() function of R.oo returns a data.frame with various attributes that
you can subset on, e.g.

> subset(R.oo::ll(), data.class %in% c("zoo", "xts"))
       member data.class dimension objectSize
2          fz        zoo        10       1344
4  sample.xts        xts  c(180,4)      10128
5           x        zoo         5        528
6          x1        zoo         5        880
7          x2        zoo         5        496
9           y        zoo         5       1040
11          z        zoo    c(5,3)       1184
12         z0        zoo         0        448
13         z2        zoo    c(4,3)        904
14        z20        zoo    c(4,0)        616
15         z3        zoo         8        528
16         z4        zoo         5        592
17         z5        zoo         5        792

Henrik

On Sat, Jul 28, 2018, 08:22 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> You can extract the names into a character vector with ls and then use
> grep(..., values=TRUE ) to select which ones you want to remove, and then
> pass that list to rm.
>
> However, due to the way R handles memory you are unlikely to see much
> savings by doing this. I would recommend focusing on creating a script or
> series of scripts that can allow you to re-create your analysis, and then
> restarting R whenever you are ready to reduce memory usage. This will have
> the side benefit of leaving you with a verified-complete record of how your
> analysis was done.
>
> On July 27, 2018 10:58:36 PM PDT, akshay kulkarni <akshay_e4 at hotmail.com>
> wrote:
> >dear memebers,
> >I am using R in AWS linux instance for my research. I want to remove
> >certain objects from the global environment  to reduce my EBS cost..for
> >example, I want to remove all objects of class "xts", "zoo". Is there
> >any way to automate this, instead of removing the objects one by one?
> >
> >Basically, I want to subset  ls() according to class, and then remove
> >that subset by using rm function.
> >
> >I got to know about mget in SO, but that is not working in my case....
> >
> >Also, all the above objects end with ".NS".  I came to know that you
> >can remove objects starting with a certain pattern; is there any way to
> >remove objects ending in a certain pattern?
> >
> >very many thanks for your time and effort...
> >yours sincerely,
> >AKSHAY M KULKARNI
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Sat Jul 28 13:34:36 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sat, 28 Jul 2018 17:04:36 +0530
Subject: [R] Saving objects in RData file in different name
Message-ID: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>

Hi,

Let say I have 2 objects as below

x1 = 1:3
x2 = 5:4

Now I want to save both x1 and x2 in some RData file, however x1 will be
saved with a different name e.g. y

I tried below

save(y = x1, x2, file = "file.RData")

However still they are saved in their original names i.e. x1 and x2, not y
and y2.

Is there any possibility that I can achieve above without explicitly
copying y = x1 before y is passed to save()

Thanks for any feedback.

	[[alternative HTML version deleted]]


From m@illi@t@ @ending from pp@inet@fi  Sat Jul 28 14:36:57 2018
From: m@illi@t@ @ending from pp@inet@fi (K. Elo)
Date: Sat, 28 Jul 2018 15:36:57 +0300
Subject: [R] Saving objects in RData file in different name
In-Reply-To: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
References: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
Message-ID: <5c4e105fa3181d9f94172e35fdecc1ad07c9cf0a.camel@pp.inet.fi>

Hi!

Maybe not the most elegant solution, but a workaround is to have a
function:

> save2<-function(y, ...) { save(y,...)}
> save2(x1,x2,file="test.RData")

The point is to include the variables to be "renamed" as parameters (in
my example: y). The function will use the parameter variable names when
saving the file.

HTH,
Kimmo

2018-07-28, 17:04 +0530, Christofer Bogaso wrote:
> Hi,
> 
> Let say I have 2 objects as below
> 
> x1 = 1:3
> x2 = 5:4
> 
> Now I want to save both x1 and x2 in some RData file, however x1 will
> be
> saved with a different name e.g. y
> 
> I tried below
> 
> save(y = x1, x2, file = "file.RData")
> 
> However still they are saved in their original names i.e. x1 and x2,
> not y
> and y2.
> 
> Is there any possibility that I can achieve above without explicitly
> copying y = x1 before y is passed to save()
> 
> Thanks for any feedback.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-gui
> de.html
> and provide commented, minimal, self-contained, reproducible code.


From bori@@@teipe @ending from utoronto@c@  Sat Jul 28 15:42:59 2018
From: bori@@@teipe @ending from utoronto@c@ (Boris Steipe)
Date: Sat, 28 Jul 2018 09:42:59 -0400
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
Message-ID: <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>

Maybe the Bioconductor package "intansv" can help you. You asked for linear chromosomes, but such data is commonly plotted in Circos plots as e.g. with the Bioconductor OmicsCircos package (cf. https://bioconductor.org/packages/devel/bioc/vignettes/OmicCircos/inst/doc/OmicCircos_vignette.pdf)

However the Bioconductor Project has its own support mailing list, R-Help is for programming help.


B.



> On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
> 
> Dear all,
> 
> we wish you a fruitful and refreshing weekend ! Thought that I may also
> write to ask you for a suggestion, specifically if you could please advise
> on whether there is any package already built (in R) that could help with
> the following data visualization :
> 
> 
>    we have a set of mutations from many cancer samples
> 
>    we would like to display the POINT MUTATIONS along the chromosome
> coordinates (on the linear scale, ie. HORIZONTALLY)
> 
>    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
> VERTICAL LINES connecting the breakpoints that are located on the
> chromosomes that are represented HORIZONTALLY
> 
> Thanks a lot,
> 
> -- bogdan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jeremieju@te @ending from gm@il@com  Sat Jul 28 16:42:24 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Sat, 28 Jul 2018 16:42:24 +0200
Subject: [R] Saving objects in RData file in different name
In-Reply-To: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
 (Christofer Bogaso's message of "Sat, 28 Jul 2018 17:04:36 +0530")
References: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
Message-ID: <87o9erpgkv.fsf@gmail.com>

Christofer Bogaso <bogaso.christofer at gmail.com> writes:

Hello

In case you have conflicting data issue when you load data, you can also do it the other way around. Indeed you never know when a possible conflict might occur in the future.
The following line load the data in a new environment e first then get it back to your current environment.

loaded..data <- get(load("test.RData",e<- new.env()),e)

you might then want to remove everything in that enviromnent afterwards,

rm(list=ls(envir=e1), envir=e1)

HTH

Jeremie


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 28 16:54:15 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 28 Jul 2018 07:54:15 -0700 (PDT)
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
 <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
Message-ID: <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>

1) I don't know... it looks to me like you did not run my code. I have 
included a complete reprex below... try it out in a fresh session. If you 
still get the problem, check your sessionInfo package versions against 
mine.

2) This still smells like your fill parameter is inside the aes function 
with Type as value. This causes a legend to be created, and since that 
legend has a different name ("Type") than the colour scale, they are 
separated. Confirm that you are using fill outside the aes function 
(because you don't want fill to depend on the data) and have the constant 
NULL as value (so it won't generate any fill graphical representation).

3) I missed that... the ylim()/scales_y_continuous(breaks=) limits 
constrain which data are included as input into the graph. The 
coord_cartesian function forces the limits as desired.

4) While showing outliers is a standard semantic feature of boxplots 
whether produced by ggplot or lattice or base or non-R solution, you can 
please the client by making the outliers transparent.

There is a link to the generated image below.

################
# Simulate some data:
Type <- rep( c( "National", "Local" ), each = 250 )
M0   <- 1300+50*(0:4)
set.seed( 42 )
M1   <- M0 + runif( 5, -100, -50 )
X0   <- rnorm( 250, rep( M0, each = 50 ), 150 )
X1   <- rnorm( 250, rep( M1, each = 50 ), 100 )

library(ggplot2)
Year <- factor( rep( 4:8, each = 50, times = 2)
               , levels = 0:8 )
DemoDat <- data.frame( Year = Year
                      , Score = c( X0, X1 )
                      , Type = Type
                      )

ggplot( data = DemoDat
       , aes( x = Year
            , y = Score
            , color = Type
            )
       , fill = NULL
       ) +
     geom_boxplot( position = position_dodge( 1 )
                 , outlier.alpha = 0
                 ) +
     theme_minimal() +
     scale_colour_manual( name = "National v. Local"
                        , values = c( "red", "black" ) ) +
     scale_x_discrete( drop = FALSE ) +
     scale_y_continuous( breaks=seq( 700, 2100, 100 ) ) +
     coord_cartesian( ylim = c( 700, 2100 ) )

# ![](https://i.imgur.com/wUVYU5H.png)

#' Created on 2018-07-28 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
################


> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C 
LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 
LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C 
LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_3.0.0

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.17     pillar_1.2.3     compiler_3.4.4   plyr_1.8.4 
bindr_0.1.1      tools_3.4.4
  [7] digest_0.6.15    memoise_1.1.0    evaluate_0.10.1  tibble_1.4.2 
gtable_0.2.0     debugme_1.1.0
[13] pkgconfig_2.0.1  rlang_0.2.1      reprex_0.2.0     rstudioapi_0.7 
yaml_2.1.19      bindrcpp_0.2.2
[19] stringr_1.3.1    withr_2.1.2      dplyr_0.7.6      knitr_1.20 
devtools_1.13.6  rprojroot_1.3-2
[25] grid_3.4.4       tidyselect_0.2.4 glue_1.2.0       R6_2.2.2 
processx_3.1.0   rmarkdown_1.10
[31] clipr_0.4.1      purrr_0.2.5      callr_2.0.4      magrittr_1.5 
whisker_0.3-2    scales_0.5.0
[37] backports_1.1.2  htmltools_0.3.6  assertthat_0.2.0 colorspace_1.3-2 
stringi_1.2.3    lazyeval_0.2.1
[43] munsell_0.5.0    crayon_1.3.4



On Sat, 28 Jul 2018, Rolf Turner wrote:

>
> On 28/07/18 17:03, Jeff Newmiller wrote:
>
>> When you understand the strong dependence on how the data controls ggplot, 
>> using it gets much easier. I still have to google details sometimes though. 
>> Note that it can be very difficult to make a weird plot (e.g. multiple 
>> parallel axes) in ggplot because it is very internally consistent... a 
>> blessing and a curse.
>> 
>> 1) Colour is assigned in the scale according to order of levels of the 
>> factor. Note that while they are both discrete, the so-called "discrete" 
>> scales auto-colour, but "manual" scales require you to specify the exact 
>> colour sequence.
>> 
>> 2) Assigning constants to properties is done outside the mapping (aes). 
>> Note that "colour" is for lines and shapes outlines, while "fill" is colour 
>> meant to fill in shapes. When the names of these two scales are the same 
>> and the values are the same, the legends will merge. If not, they will be 
>> shown separately.
>> 
>> 3) Discrete scales are controlled by the levels in the data. To prevent 
>> ggplot from removing missing levels, use the drop=FALSE argument.
>> 
>> 4) Breaks are a property of the scale.
>> 
>> My changes were:
>> 
>> Year <- factor( rep( 4:8, each = 50, times = 2 ), levels = 0:8 )
>> DemoDat <- data.frame(Year = Year, Score = c( X0 , X1 ), Type = Type )
>> 
>> ggplot( data = DemoDat
>>  ????? , aes( x = Year, y = Score, color = Type )
>>  ????? , fill = NULL
>>  ????? ) +
>>  ??? geom_boxplot( position = position_dodge(1) ) +
>>  ??? theme_minimal() +
>>  ??? scale_colour_manual( name = "National v. Local"
>>  ?????????????????????? , values = c( "red", "black" ) ) +
>>  ??? scale_x_discrete( drop = FALSE ) +
>>  ??? scale_y_continuous( breaks = seq( 700, 2100, 100 ) )
>> 
>> Good luck with your graphics grammar!
>
> Dear Jeff,
>
> Thanks very much for this cogent advice and for taking the trouble to steer 
> me in the right direction.  However I am not quite out of the woods yet.
>
> (1) I'm still getting two legends.  How do I stop this from happening?
>
> (2) The boxes are "filled" (with pinkish and blueish colours --- which are 
> referenced in the second of the two legends that I get).  How can I get 
> "unfilled" boxes?
>
> (3) The y-axis scale runs only from 800 to 1800, rather than from 700 to 
> 2100.  How can I force it to run from 700 to 2100?
>
> (4) With the modified code we now get some "outliers" (points beyond the 
> whisker tips) plotted --- which I didn't get before (and don't want, because 
> "last year's" graphics did not include outliers).  How can I suppress the 
> plotting of outliers?
>
> I have attached a pdf containing the results of running the code that
> you provided, so that you can readily see what is happening.
>
> May I prevail upon your good graces to enlighten me about questions
> (1) --- (4) above?
>
> Ever so humbly grateful.
>
> cheers,
>
> Rolf
>
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From t@n@@@ @ending from gm@il@com  Sat Jul 28 16:52:57 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sat, 28 Jul 2018 07:52:57 -0700
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
 <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
Message-ID: <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>

Dear Boris,

good morning, and thank you for your message.  After thinking a bit more
yesterday, I believe that I could adapt the functionality of some R
packages that display the synteny regions across multiple species (here
please see an example Figure 1 from http://www.g3journal.org/
content/7/6/1775.figures-only),

although I have not found yet a R package that does this display (in my
case, instead of distinct species, I will just show distinct chromosomes
connected by translocations). If you have any suggestions, please let me
know.

thanks a lot,

-- bogdan


On Sat, Jul 28, 2018 at 6:42 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Maybe the Bioconductor package "intansv" can help you. You asked for
> linear chromosomes, but such data is commonly plotted in Circos plots as
> e.g. with the Bioconductor OmicsCircos package (cf.
> https://bioconductor.org/packages/devel/bioc/vignettes/
> OmicCircos/inst/doc/OmicCircos_vignette.pdf)
>
> However the Bioconductor Project has its own support mailing list, R-Help
> is for programming help.
>
>
> B.
>
>
>
> > On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >
> > Dear all,
> >
> > we wish you a fruitful and refreshing weekend ! Thought that I may also
> > write to ask you for a suggestion, specifically if you could please
> advise
> > on whether there is any package already built (in R) that could help with
> > the following data visualization :
> >
> >
> >    we have a set of mutations from many cancer samples
> >
> >    we would like to display the POINT MUTATIONS along the chromosome
> > coordinates (on the linear scale, ie. HORIZONTALLY)
> >
> >    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
> > VERTICAL LINES connecting the breakpoints that are located on the
> > chromosomes that are represented HORIZONTALLY
> >
> > Thanks a lot,
> >
> > -- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jul 28 17:05:44 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 28 Jul 2018 08:05:44 -0700 (PDT)
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
 <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
 <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807280803360.27913@pedal.dcn.davis.ca.us>

My suggestion is to pay attention to Boris and ask people who do this kind 
of plotting frequently... and they are typically found on the Bioconductor 
mailing list, not this list.

On Sat, 28 Jul 2018, Bogdan Tanasa wrote:

> Dear Boris,
>
> good morning, and thank you for your message.  After thinking a bit more
> yesterday, I believe that I could adapt the functionality of some R
> packages that display the synteny regions across multiple species (here
> please see an example Figure 1 from http://www.g3journal.org/
> content/7/6/1775.figures-only),
>
> although I have not found yet a R package that does this display (in my
> case, instead of distinct species, I will just show distinct chromosomes
> connected by translocations). If you have any suggestions, please let me
> know.
>
> thanks a lot,
>
> -- bogdan
>
>
> On Sat, Jul 28, 2018 at 6:42 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> Maybe the Bioconductor package "intansv" can help you. You asked for
>> linear chromosomes, but such data is commonly plotted in Circos plots as
>> e.g. with the Bioconductor OmicsCircos package (cf.
>> https://bioconductor.org/packages/devel/bioc/vignettes/
>> OmicCircos/inst/doc/OmicCircos_vignette.pdf)
>>
>> However the Bioconductor Project has its own support mailing list, R-Help
>> is for programming help.
>>
>>
>> B.
>>
>>
>>
>>> On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>
>>> Dear all,
>>>
>>> we wish you a fruitful and refreshing weekend ! Thought that I may also
>>> write to ask you for a suggestion, specifically if you could please
>> advise
>>> on whether there is any package already built (in R) that could help with
>>> the following data visualization :
>>>
>>>
>>>    we have a set of mutations from many cancer samples
>>>
>>>    we would like to display the POINT MUTATIONS along the chromosome
>>> coordinates (on the linear scale, ie. HORIZONTALLY)
>>>
>>>    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
>>> VERTICAL LINES connecting the breakpoints that are located on the
>>> chromosomes that are represented HORIZONTALLY
>>>
>>> Thanks a lot,
>>>
>>> -- bogdan
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From t@n@@@ @ending from gm@il@com  Sat Jul 28 17:03:37 2018
From: t@n@@@ @ending from gm@il@com (Bogdan Tanasa)
Date: Sat, 28 Jul 2018 08:03:37 -0700
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <alpine.BSF.2.00.1807280803360.27913@pedal.dcn.davis.ca.us>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
 <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
 <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>
 <alpine.BSF.2.00.1807280803360.27913@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM00SWQparZ7OsV5kgRGE25K5VH3gm3Ab8oCT5ZiMU7WdPg@mail.gmail.com>

Thank you Jeff. Yes, certainly, I posted a message on BioC too, although I
have not received any suggestions by now.

On Sat, Jul 28, 2018 at 8:05 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> My suggestion is to pay attention to Boris and ask people who do this kind
> of plotting frequently... and they are typically found on the Bioconductor
> mailing list, not this list.
>
> On Sat, 28 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Boris,
>>
>> good morning, and thank you for your message.  After thinking a bit more
>> yesterday, I believe that I could adapt the functionality of some R
>> packages that display the synteny regions across multiple species (here
>> please see an example Figure 1 from http://www.g3journal.org/
>> content/7/6/1775.figures-only),
>>
>> although I have not found yet a R package that does this display (in my
>> case, instead of distinct species, I will just show distinct chromosomes
>> connected by translocations). If you have any suggestions, please let me
>> know.
>>
>> thanks a lot,
>>
>> -- bogdan
>>
>>
>> On Sat, Jul 28, 2018 at 6:42 AM, Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>>
>> Maybe the Bioconductor package "intansv" can help you. You asked for
>>> linear chromosomes, but such data is commonly plotted in Circos plots as
>>> e.g. with the Bioconductor OmicsCircos package (cf.
>>> https://bioconductor.org/packages/devel/bioc/vignettes/
>>> OmicCircos/inst/doc/OmicCircos_vignette.pdf)
>>>
>>> However the Bioconductor Project has its own support mailing list, R-Help
>>> is for programming help.
>>>
>>>
>>> B.
>>>
>>>
>>>
>>> On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>>
>>>> Dear all,
>>>>
>>>> we wish you a fruitful and refreshing weekend ! Thought that I may also
>>>> write to ask you for a suggestion, specifically if you could please
>>>>
>>> advise
>>>
>>>> on whether there is any package already built (in R) that could help
>>>> with
>>>> the following data visualization :
>>>>
>>>>
>>>>    we have a set of mutations from many cancer samples
>>>>
>>>>    we would like to display the POINT MUTATIONS along the chromosome
>>>> coordinates (on the linear scale, ie. HORIZONTALLY)
>>>>
>>>>    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
>>>> VERTICAL LINES connecting the breakpoints that are located on the
>>>> chromosomes that are represented HORIZONTALLY
>>>>
>>>> Thanks a lot,
>>>>
>>>> -- bogdan
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>
>>> posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Sat Jul 28 17:07:04 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Sat, 28 Jul 2018 08:07:04 -0700
Subject: [R] subsetting ls() as per class...
In-Reply-To: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcbZS3otj6fRFKNNkjpAiXht=NRDXentfHo5Nk_7ZX7Tuw@mail.gmail.com>

> objClasses <- unlist(eapply(.GlobalEnv, function(x)class(x)[1]))
> head(objClasses)
            f             E
   "function" "environment"
           df             h
     "tbl_df"    "function"
       myData             L
       "list"        "list"
> names(objClasses)[objClasses=="tbl_df"]
[1] "df"  "out"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 10:58 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear memebers,
>                                I am using R in AWS linux instance for my
> research. I want to remove certain objects from the global environment  to
> reduce my EBS cost..for example, I want to remove all objects of class
> "xts", "zoo". Is there any way to automate this, instead of removing the
> objects one by one?
>
> Basically, I want to subset  ls() according to class, and then remove that
> subset by using rm function.
>
> I got to know about mget in SO, but that is not working in my case....
>
> Also, all the above objects end with ".NS".  I came to know that you can
> remove objects starting with a certain pattern; is there any way to remove
> objects ending in a certain pattern?
>
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Sat Jul 28 18:05:33 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sat, 28 Jul 2018 16:05:33 +0000
Subject: [R] subsetting ls() as per class...
In-Reply-To: <CA+hbrhW_-eD+izCYZTgCRma4qz-iB3FeqbUSZKgv9isx6RpnEA@mail.gmail.com>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <CA+hbrhW_-eD+izCYZTgCRma4qz-iB3FeqbUSZKgv9isx6RpnEA@mail.gmail.com>
Message-ID: <SL2P216MB0091544A68CD2D65C1708E07C8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear peter,
                     Its working....thanks a lot...

yours sincerely,
AKSHAY M KULKARNI
________________________________
From: Peter Langfelder <peter.langfelder at gmail.com>
Sent: Saturday, July 28, 2018 11:41 AM
To: akshay_e4 at hotmail.com
Cc: r-help
Subject: Re: [R] subsetting ls() as per class...

Looking at ?rm, my solution would be something like

rm(list = grep("\\.NS$", ls(), value = TRUE))

But test it since I have not tested it.

Peter


On Fri, Jul 27, 2018 at 10:58 PM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> dear memebers,
>                                I am using R in AWS linux instance for my research. I want to remove certain objects from the global environment  to reduce my EBS cost..for example, I want to remove all objects of class "xts", "zoo". Is there any way to automate this, instead of removing the objects one by one?
>
> Basically, I want to subset  ls() according to class, and then remove that subset by using rm function.
>
> I got to know about mget in SO, but that is not working in my case....
>
> Also, all the above objects end with ".NS".  I came to know that you can remove objects starting with a certain pattern; is there any way to remove objects ending in a certain pattern?
>
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Sun Jul 29 01:04:02 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sun, 29 Jul 2018 11:04:02 +1200
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
 <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
 <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>
Message-ID: <4ed6b5de-05fc-a818-2da4-57a2d5f9f4e9@auckland.ac.nz>


On 29/07/18 02:54, Jeff Newmiller wrote:

> 1) I don't know... it looks to me like you did not run my code.

Aaaarrrgghhh.  I *thought* I had, but instead left "fill=Type" inside 
the aes() call and neglected to add fill=NULL outside this call. 
Duhhhh!!! It's tough being mentally challenged, let me assure you.

> I have 
> included a complete reprex below... try it out in a fresh session. If 
> you still get the problem, check your sessionInfo package versions 
> against mine.

Yep.  Works like a charm.

> 2) This still smells like your fill parameter is inside the aes function 
> with Type as value. This causes a legend to be created, and since that 
> legend has a different name ("Type") than the colour scale, they are 
> separated. Confirm that you are using fill outside the aes function 
> (because you don't want fill to depend on the data) and have the 
> constant NULL as value (so it won't generate any fill graphical 
> representation).

Yeah.  Well.  Duhhh.  I'm a retread.
> 
> 3) I missed that... the ylim()/scales_y_continuous(breaks=) limits 
> constrain which data are included as input into the graph. The 
> coord_cartesian function forces the limits as desired.

Bewdy, ta.

> 
> 4) While showing outliers is a standard semantic feature of boxplots 
> whether produced by ggplot or lattice or base or non-R solution,

Indeed.  But the client is always right! :-)

> you can 
> please the client by making the outliers transparent.

And your code shows me how!  Which I need.  Bewdy, ta.

> There is a link to the generated image below.
> 
> ################
> # Simulate some data:
> Type <- rep( c( "National", "Local" ), each = 250 )
> M0?? <- 1300+50*(0:4)
> set.seed( 42 )
> M1?? <- M0 + runif( 5, -100, -50 )
> X0?? <- rnorm( 250, rep( M0, each = 50 ), 150 )
> X1?? <- rnorm( 250, rep( M1, each = 50 ), 100 )
> 
> library(ggplot2)
> Year <- factor( rep( 4:8, each = 50, times = 2)
>  ????????????? , levels = 0:8 )
> DemoDat <- data.frame( Year = Year
>  ???????????????????? , Score = c( X0, X1 )
>  ???????????????????? , Type = Type
>  ???????????????????? )
> 
> ggplot( data = DemoDat
>  ????? , aes( x = Year
>  ?????????? , y = Score
>  ?????????? , color = Type
>  ?????????? )
>  ????? , fill = NULL
>  ????? ) +
>  ??? geom_boxplot( position = position_dodge( 1 )
>  ??????????????? , outlier.alpha = 0
>  ??????????????? ) +
>  ??? theme_minimal() +
>  ??? scale_colour_manual( name = "National v. Local"
>  ?????????????????????? , values = c( "red", "black" ) ) +
>  ??? scale_x_discrete( drop = FALSE ) +
>  ??? scale_y_continuous( breaks=seq( 700, 2100, 100 ) ) +
>  ??? coord_cartesian( ylim = c( 700, 2100 ) )
> 
> # ![](https://i.imgur.com/wUVYU5H.png)

Looks perfect.  Thanks *HUGELY* for your patience with my stupidity.

<SNIP>

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jenny@liu00 @ending from gm@il@com  Mon Jul 30 02:24:50 2018
From: jenny@liu00 @ending from gm@il@com (Jenny Liu)
Date: Mon, 30 Jul 2018 00:24:50 +0000
Subject: [R] A quick question on devRate package
Message-ID: <c8765a76-08d9-1d54-c367-a075ed1e0261@mixmax.com>

Hi all,

If anybody is familiar with the package "devRate" that would be helpful! I am
finding that it's giving me a bit of conflicting information:

When I enter
>devRateFind(familySP="Cecidomyiidae")

It tells me that the formula campbell_74 was used 11 times. However, when I
enter
>devRateInfo(eq=campbell_74)
There are only 3 entries for Diptera, and none of them are Cecidomyiidae.
Am I doing something wrong, or missing something? I read through the instruction
manual but it's definitely possible I misunderstood.
Thanks for your time!
Cheers,Jenny Liu
	[[alternative HTML version deleted]]


From rmh @ending from temple@edu  Mon Jul 30 05:32:36 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Sun, 29 Jul 2018 23:32:36 -0400
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <4ed6b5de-05fc-a818-2da4-57a2d5f9f4e9@auckland.ac.nz>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
 <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
 <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>
 <4ed6b5de-05fc-a818-2da4-57a2d5f9f4e9@auckland.ac.nz>
Message-ID: <CAGx1TMA_N4P2SsR_pp_gdVrmuU=SOoEX-HoaM-k100o7-2teqw@mail.gmail.com>

## I recommend using lattice for this task.
## First I show the example from my book and package (HH).
## Then I use this on your example.

library(HH)       ## Package supporting Heiberger and Holland,
                  ## Statistical Analysis and Data Display (Second
edition, 2015)
HHscriptnames(4)  ## Filename on your computer for script for all
Chapter 4 examples

## this is Chunk 23

###################################################
### code chunk number 23: grap.tex:1953-1981
###################################################
bwdata <- data.frame(Y=(rt(80, df=5)*5 + rep(c(20,25,15,22, 22,28,16,14), 10)),
                     week=ordered(rep(c(1:4, 1:4), each=10)),
                     treatment= rep(c("A", "B"), each=40))

position(bwdata$week) <- c(1, 2, 4, 8)
levels(bwdata$week) <- c(1, 2, 4, 8)

bwdata$week.treatment <- with(bwdata, interaction(treatment, week))
position(bwdata$week.treatment) <-
   as.vector(t(outer(c(1, 2, 4, 8), c(-.18,.18), "+")))

BR <- likertColor(2, colorFunctionOption="default")[2:1]

## uses panel.bwplot.intermediate.hh to control position and colors
## hhpdf("bwplotposition.pdf", width=7, height=5)
bwplot(Y ~ week.treatment, data=bwdata,
       panel=panel.bwplot.intermediate.hh, xlim=c(0, 9),
       box.width=.25,
       pch=c(17, 16), col=BR,
       xlab="Week", ylab=list(rot=0),
       scales=list(x=list(at=position(bwdata$week), tck=1)),
       key=list(
          text=list(c("A","B"), col=BR),
          points=list(pch=c(17, 16), col=BR),
          space="top", columns=2, between=1, border=TRUE,
          title="Treatment", cex.title=.9)) +
   layer(panel.abline(h=37, col="gray60", lty=3, lwd=2))
## hhdev.off()


## The placement features provided by panel.bwplot.intermediate.hh are
## 1. The two boxes at each time position are clearly distinguished
##    from boxes at other time positions.
##
## 2. Times do not need to be evenly spaced.


## Now your sample data and lattice code for your desired graph


## Script to demonstrate what I am trying to do.
##

## Simulate some data:
Year <- factor(rep(4:8,each=50,times=2))
Type <- rep(c("National","Local"),each=250)
M0   <- 1300+50*(0:4)
set.seed(42)
M1   <- M0 + runif(5,-100,-50)
X0   <- rnorm(250,rep(M0,each=50),150)
X1   <- rnorm(250,rep(M1,each=50),100)
DemoDat <- data.frame(Year=Year,Score=c(X0,X1),Type=Type)

if (FALSE) { ## Rolf Turners original code
## Grouped boxplots:
library(ggplot2)
print(ggplot(data=DemoDat) +
    geom_boxplot(aes(x=Year, y=Score, color=Type,fill=Type),
                 position=position_dodge(1),alpha=0) +
    theme_minimal() +
    scale_fill_discrete(name="National v. Local") +
    ylim(700,2100))
}


DemoDat$Year.Type <- with(DemoDat, interaction(Year, Type))
position(DemoDat$Year.Type) <-
   as.vector(t(outer(c(4, 5, 6, 7, 8), c(-.18, .18), "+")))
RB <- c("red", "black")

SYT <-
bwplot(Score ~ Year.Type, data=DemoDat,
       panel=panel.bwplot.intermediate.hh,
       xlim=c(-.1, 9.1),
       ylim=c(690, 2110),
       box.width=.22,
       col=RB,
       xlab="Year", ylab=list(rot=0),
       scales=list(x=list(at=0:9, tck=1),
                   y=list(at=seq(700, 2100, 100), tick=1)),
       par.settings=list(box.dot=list(pch="|"),
                         plot.symbol=list(pch="-", col=RB, cex=1.5)),
       key=list(
         text=list(levels(DemoDat$Type), col=RB, cex=.8),
         lines=list(col=RB), size=1.5,
         columns=2, between=.5, between.columns=.6,
         space="right", border=FALSE,
         title="\nNational v. Local", cex.title=.9),
       main="Matches specifications"
       )
SYT

update(SYT, main="Outliers made invisible, not recommended",
       par.settings=list(plot.symbol=list(cex=0)))

## Rich


On Sat, Jul 28, 2018 at 7:04 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 29/07/18 02:54, Jeff Newmiller wrote:
>
>> 1) I don't know... it looks to me like you did not run my code.
>
>
> Aaaarrrgghhh.  I *thought* I had, but instead left "fill=Type" inside the
> aes() call and neglected to add fill=NULL outside this call. Duhhhh!!! It's
> tough being mentally challenged, let me assure you.
>
>> I have included a complete reprex below... try it out in a fresh session.
>> If you still get the problem, check your sessionInfo package versions
>> against mine.
>
>
> Yep.  Works like a charm.
>
>> 2) This still smells like your fill parameter is inside the aes function
>> with Type as value. This causes a legend to be created, and since that
>> legend has a different name ("Type") than the colour scale, they are
>> separated. Confirm that you are using fill outside the aes function (because
>> you don't want fill to depend on the data) and have the constant NULL as
>> value (so it won't generate any fill graphical representation).
>
>
> Yeah.  Well.  Duhhh.  I'm a retread.
>>
>>
>> 3) I missed that... the ylim()/scales_y_continuous(breaks=) limits
>> constrain which data are included as input into the graph. The
>> coord_cartesian function forces the limits as desired.
>
>
> Bewdy, ta.
>
>>
>> 4) While showing outliers is a standard semantic feature of boxplots
>> whether produced by ggplot or lattice or base or non-R solution,
>
>
> Indeed.  But the client is always right! :-)
>
>> you can please the client by making the outliers transparent.
>
>
> And your code shows me how!  Which I need.  Bewdy, ta.
>
>
>> There is a link to the generated image below.
>>
>> ################
>> # Simulate some data:
>> Type <- rep( c( "National", "Local" ), each = 250 )
>> M0   <- 1300+50*(0:4)
>> set.seed( 42 )
>> M1   <- M0 + runif( 5, -100, -50 )
>> X0   <- rnorm( 250, rep( M0, each = 50 ), 150 )
>> X1   <- rnorm( 250, rep( M1, each = 50 ), 100 )
>>
>> library(ggplot2)
>> Year <- factor( rep( 4:8, each = 50, times = 2)
>>                , levels = 0:8 )
>> DemoDat <- data.frame( Year = Year
>>                       , Score = c( X0, X1 )
>>                       , Type = Type
>>                       )
>>
>> ggplot( data = DemoDat
>>        , aes( x = Year
>>             , y = Score
>>             , color = Type
>>             )
>>        , fill = NULL
>>        ) +
>>      geom_boxplot( position = position_dodge( 1 )
>>                  , outlier.alpha = 0
>>                  ) +
>>      theme_minimal() +
>>      scale_colour_manual( name = "National v. Local"
>>                         , values = c( "red", "black" ) ) +
>>      scale_x_discrete( drop = FALSE ) +
>>      scale_y_continuous( breaks=seq( 700, 2100, 100 ) ) +
>>      coord_cartesian( ylim = c( 700, 2100 ) )
>>
>> # ![](https://i.imgur.com/wUVYU5H.png)
>
>
> Looks perfect.  Thanks *HUGELY* for your patience with my stupidity.
>
> <SNIP>
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c@l@ndr@ @ending from rgzm@de  Mon Jul 30 08:46:46 2018
From: c@l@ndr@ @ending from rgzm@de (Ivan Calandra)
Date: Mon, 30 Jul 2018 08:46:46 +0200
Subject: [R] Saving objects in RData file in different name
In-Reply-To: <5c4e105fa3181d9f94172e35fdecc1ad07c9cf0a.camel@pp.inet.fi>
References: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
 <5c4e105fa3181d9f94172e35fdecc1ad07c9cf0a.camel@pp.inet.fi>
Message-ID: <b2d25a65-738d-ead8-8528-b1467d40937f@rgzm.de>

Hi!

In those cases, I use R.utils::saveObject() and loadObject().
You would have to save each object separately though:

saveObject(x1, file="file.Rbin")
y <- loadObject(file="file.Rbin")

HTH
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 28/07/2018 14:36, K. Elo wrote:
> Hi!
>
> Maybe not the most elegant solution, but a workaround is to have a
> function:
>
>> save2<-function(y, ...) { save(y,...)}
>> save2(x1,x2,file="test.RData")
> The point is to include the variables to be "renamed" as parameters (in
> my example: y). The function will use the parameter variable names when
> saving the file.
>
> HTH,
> Kimmo
>
> 2018-07-28, 17:04 +0530, Christofer Bogaso wrote:
>> Hi,
>>
>> Let say I have 2 objects as below
>>
>> x1 = 1:3
>> x2 = 5:4
>>
>> Now I want to save both x1 and x2 in some RData file, however x1 will
>> be
>> saved with a different name e.g. y
>>
>> I tried below
>>
>> save(y = x1, x2, file = "file.RData")
>>
>> However still they are saved in their original names i.e. x1 and x2,
>> not y
>> and y2.
>>
>> Is there any possibility that I can achieve above without explicitly
>> copying y = x1 before y is passed to save()
>>
>> Thanks for any feedback.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-gui
>> de.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@ij@@@irkj@rvi @ending from gm@il@com  Mon Jul 30 09:18:24 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 30 Jul 2018 10:18:24 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <20180629182925.4606e7be@goodenia>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
 <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>
 <20180629182925.4606e7be@goodenia>
Message-ID: <CAJxz9NZ0nnB0j3cLKQjVKuMaJdy0cFykgWX26UJjTBmEx5NTrg@mail.gmail.com>

Thanks a lot! I got the main part working (after a relaxing holiday).
However I still have some problems with the conditions. The looping is not
working properly, but this is not really an QP problem anymore. It's more
about that R runs the loop differently than c++, I guess.

Thanks a lot for help!
Maija

pe 29. kes?k. 2018 klo 13.29 Berwin A Turlach (berwin.turlach at gmail.com)
kirjoitti:

> G'day Maija,
>
> On Wed, 27 Jun 2018 08:48:08 +0300
> Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
>
> > Thanks for your reply! Unfortunately something is still wrong.
> >
> > After the transpose, dvec and Amat are still incompatible.
> >
> > > d <- -hsmooth
> > > dvec <- t(d)
> > > c <- dvec*Amat
> > Error in dvec * Amat : non-conformable arrays
>
> '*' in R is element-wise multiplication and '%*%' implements
> matrix/matrix (matrix/vector) multiplication as defined in matrix
> algebra.  I presume you want to use the latter operator here.
>
> > Moreover, I don't understand the following:
> >
> > > If dvec is of length *J*, then b will be of length J too.
> >
> > I believe the length of dvec comes from the number of variables and
> > the length of b from the number of constraints. In this case they are
> > not equal.
>
> As I said:
>
> > > solve.QP solves the quadratic program:
> > >          min(-d^T b + 1/2 b^T D b)
> > >    where A^T b >= b_0.
>
> The minimisation is with respect to b.
>
> Note that the objective function contains the inner product of d
> (passed to dvec) and b, so d and b must have the same
> dimension/length.  b contains the parameters/variables over which you
> want to minimise.  b_0 (passed to bvec) depends on the number of
> constraints.
>
> Cheers,
>
>         Berwin
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jul 30 10:57:34 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 30 Jul 2018 14:27:34 +0530
Subject: [R] dbGetQuery() returns wrong value
Message-ID: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>

Hi,

I used following SQL query to fetch information from DB

> dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and ID =
'72075186224672770' limit 10")
         ID
1 72075186224672768

As you see, it is returning a different result from what actual query
string contains.

However when I used the same query in some other SQL client, I get the
expected result as:

72075186224672770

Any idea on what went wrong in R supplied query would be highly appreciated.

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jul 30 13:00:50 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 30 Jul 2018 16:30:50 +0530
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
Message-ID: <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>

Session Information for above error:

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 16299)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
                 LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
DBI_1.0.0

loaded via a namespace (and not attached):
[1] compiler_3.5.0 tools_3.5.0

On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I used following SQL query to fetch information from DB
>
> > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and ID =
> '72075186224672770' limit 10")
>          ID
> 1 72075186224672768
>
> As you see, it is returning a different result from what actual query
> string contains.
>
> However when I used the same query in some other SQL client, I get the
> expected result as:
>
> 72075186224672770
>
> Any idea on what went wrong in R supplied query would be highly
> appreciated.
>
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Mon Jul 30 13:15:20 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 30 Jul 2018 14:15:20 +0300
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
Message-ID: <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>

The ID matches in the first 16 characters.
How is your table XXXX declared?


On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Session Information for above error:
>
> > sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 16299)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>                  LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
> DBI_1.0.0
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.0 tools_3.5.0
>
> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
> > Hi,
> >
> > I used following SQL query to fetch information from DB
> >
> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and ID
> =
> > '72075186224672770' limit 10")
> >          ID
> > 1 72075186224672768
> >
> > As you see, it is returning a different result from what actual query
> > string contains.
> >
> > However when I used the same query in some other SQL client, I get the
> > expected result as:
> >
> > 72075186224672770
> >
> > Any idea on what went wrong in R supplied query would be highly
> > appreciated.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jul 30 15:06:04 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 30 Jul 2018 18:36:04 +0530
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
 <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
Message-ID: <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>

The data type is defined as bigint

On Mon, Jul 30, 2018 at 4:45 PM Eric Berger <ericjberger at gmail.com> wrote:

> The ID matches in the first 16 characters.
> How is your table XXXX declared?
>
>
> On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Session Information for above error:
>>
>> > sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 16299)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>                  LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
>> DBI_1.0.0
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.5.0 tools_3.5.0
>>
>> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
>> bogaso.christofer at gmail.com> wrote:
>>
>> > Hi,
>> >
>> > I used following SQL query to fetch information from DB
>> >
>> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and
>> ID =
>> > '72075186224672770' limit 10")
>> >          ID
>> > 1 72075186224672768
>> >
>> > As you see, it is returning a different result from what actual query
>> > string contains.
>> >
>> > However when I used the same query in some other SQL client, I get the
>> > expected result as:
>> >
>> > 72075186224672770
>> >
>> > Any idea on what went wrong in R supplied query would be highly
>> > appreciated.
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jul 30 16:01:35 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 30 Jul 2018 07:01:35 -0700
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
 <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
 <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
Message-ID: <19B9B899-D2A4-4454-B549-677EB6EE4DC4@dcn.davis.ca.us>

If you have not read [1] already, you should. As to how JDBC handles this issue I don't know, but such a package-specific conversation belongs on r-sig-db.

[1] http://www.win-vector.com/blog/2015/06/r-in-a-64-bit-world/

On July 30, 2018 6:06:04 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>The data type is defined as bigint
>
>On Mon, Jul 30, 2018 at 4:45 PM Eric Berger <ericjberger at gmail.com>
>wrote:
>
>> The ID matches in the first 16 characters.
>> How is your table XXXX declared?
>>
>>
>> On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
>> bogaso.christofer at gmail.com> wrote:
>>
>>> Session Information for above error:
>>>
>>> > sessionInfo()
>>> R version 3.5.0 (2018-04-23)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 16299)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>>                  LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1
>rJava_0.9-10
>>> DBI_1.0.0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.5.0 tools_3.5.0
>>>
>>> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
>>> bogaso.christofer at gmail.com> wrote:
>>>
>>> > Hi,
>>> >
>>> > I used following SQL query to fetch information from DB
>>> >
>>> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18'
>and
>>> ID =
>>> > '72075186224672770' limit 10")
>>> >          ID
>>> > 1 72075186224672768
>>> >
>>> > As you see, it is returning a different result from what actual
>query
>>> > string contains.
>>> >
>>> > However when I used the same query in some other SQL client, I get
>the
>>> > expected result as:
>>> >
>>> > 72075186224672770
>>> >
>>> > Any idea on what went wrong in R supplied query would be highly
>>> > appreciated.
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From diego@@ve@@ni @ending from gm@il@com  Mon Jul 30 16:29:05 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Mon, 30 Jul 2018 16:29:05 +0200
Subject: [R] read txt file - date - no space
Message-ID: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>

Dear all,

I am dealing with the reading of a *.txt file.
The txt file the following shape:

103001930 103001580 103001530
1998-10-01 00:00:00 0.6 0 0
1998-10-01 01:00:00 0.2 0.2 0.2
1998-10-01 02:00:00 0.6 0.2 0.4
1998-10-01 03:00:00 0 0 0.6
1998-10-01 04:00:00 0 0 0
1998-10-01 05:00:00 0 0 0
1998-10-01 06:00:00 0 0 0
1998-10-01 07:00:00 0.2 0 0

If it is possible I have a coupe of questions, which will sound stupid but
they are important to me in order to understand ho R deal with file or date.

1) Do I have to convert it to a *csv file?
2) Can a deal with space and not ","
3) How can I read date?

thanks a lot to all of you,
Thanks


Diego

	[[alternative HTML version deleted]]


From ouedr@ogo_@g@the @ending from y@hoo@fr  Mon Jul 30 17:18:41 2018
From: ouedr@ogo_@g@the @ending from y@hoo@fr (ouedraogo_agathe)
Date: Mon, 30 Jul 2018 18:18:41 +0300
Subject: [R] Plot Rclimdex or Climpact map with R
Message-ID: <upkhmgcxshy0j7p5hn6y9ykn.1532963921164@email.android.com>

HelloI am using Rclimdex and Climpact packages to compute some indices. Having the location of all my stations I wish to plot the resultats on a map. Is there a way to simply do it from the packages or how to do it for someone who does not master R software?thanks?

Sent from my Samsung Galaxy smartphone.
	[[alternative HTML version deleted]]


From b@un1 @ending from @tudent@@tow@on@edu  Mon Jul 30 17:24:27 2018
From: b@un1 @ending from @tudent@@tow@on@edu (Baojun Sun)
Date: Mon, 30 Jul 2018 11:24:27 -0400
Subject: [R] (no subject)
Message-ID: <CAPkQrWK2OyWjLR=aGD+zOiyHtOVReKd+=oY6oXOKD3xYWP1GUw@mail.gmail.com>

The book "Introduction to Statistical Learning" gives R scripts for its
labs. I found a script for ridge regression that works on the dataset the
book uses but is unusable on other datasets I own unless I clean the data.


I'm trying to understand the syntax for I need for data cleaning and am
stuck. I want to learn to do ridge regression. I tried using my own data
set on this script rather than the book example but get errors. If you use
your own data set rather than the Hitters dataset, then you'll get errors
unless you format your code. How do I change this script or clean any
dataset so that this script for ridge regression useable for all datasets?


    library(ISLR)

    fix(Hitters)

    names(Hitters)

    dim(Hitters)

    sum(is.na(Hitters$Salary))

    Hitters=na.omit(Hitters)

    dim(Hitters)

    sum(is.na(Hitters))

    library(leaps)



    x=model.matrix(Salary~.,Hitters)[,-1]

    y=Hitters$Salary



    # Ridge Regression



    library(glmnet)

    grid=10^seq(10,-2,length=100)

    ridge.mod=glmnet(x,y,alpha=0,lambda=grid)

    dim(coef(ridge.mod))

    ridge.mod$lambda[50]

    coef(ridge.mod)[,50]

    sqrt(sum(coef(ridge.mod)[-1,50]^2))

    ridge.mod$lambda[60]

    coef(ridge.mod)[,60]

    sqrt(sum(coef(ridge.mod)[-1,60]^2))

    predict(ridge.mod,s=50,type="coefficients")[1:20,]

    set.seed(1)

    train=sample(1:nrow(x), nrow(x)/2)

    test=(-train)

    y.test=y[test]

    ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)

    ridge.pred=predict(ridge.mod,s=4,newx=x[test,])

    mean((ridge.pred-y.test)^2)

    mean((mean(y[train])-y.test)^2)

    ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])

    mean((ridge.pred-y.test)^2)

    ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)

    mean((ridge.pred-y.test)^2)

    lm(y~x, subset=train)

    predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]

    set.seed(1)

    cv.out=cv.glmnet(x[train,],y[train],alpha=0)

    plot(cv.out)

    bestlam=cv.out$lambda.min

    bestlam

    ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])

    mean((ridge.pred-y.test)^2)

    out=glmnet(x,y,alpha=0)

    predict(out,type="coefficients",s=bestlam)[1:20

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jul 30 19:26:27 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 30 Jul 2018 10:26:27 -0700
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
Message-ID: <12F1F8F3-1CE4-4589-B8A3-8A3F2BFEAB99@dcn.davis.ca.us>

1) No. 

2) The read.csv function is a s special case use of the more general read.table function that can handle any simple field separator.

3) Read the data in as character (I recommend using the stringsAsFactors=FALSE argument to read.table) and convert to an appropriate type from that form. e.g. [1]

[1] https://www.r-bloggers.com/using-dates-and-times-in-r/


On July 30, 2018 7:29:05 AM PDT, Diego Avesani <diego.avesani at gmail.com> wrote:
>Dear all,
>
>I am dealing with the reading of a *.txt file.
>The txt file the following shape:
>
>103001930 103001580 103001530
>1998-10-01 00:00:00 0.6 0 0
>1998-10-01 01:00:00 0.2 0.2 0.2
>1998-10-01 02:00:00 0.6 0.2 0.4
>1998-10-01 03:00:00 0 0 0.6
>1998-10-01 04:00:00 0 0 0
>1998-10-01 05:00:00 0 0 0
>1998-10-01 06:00:00 0 0 0
>1998-10-01 07:00:00 0.2 0 0
>
>If it is possible I have a coupe of questions, which will sound stupid
>but
>they are important to me in order to understand ho R deal with file or
>date.
>
>1) Do I have to convert it to a *csv file?
>2) Can a deal with space and not ","
>3) How can I read date?
>
>thanks a lot to all of you,
>Thanks
>
>
>Diego
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From JLucke m@ili@g off ri@@buff@lo@edu  Mon Jul 30 21:14:37 2018
From: JLucke m@ili@g off ri@@buff@lo@edu (JLucke m@ili@g off ri@@buff@lo@edu)
Date: Mon, 30 Jul 2018 15:14:37 -0400
Subject: [R] Unexpected YAML
Message-ID: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>

R Users:

Whenever I fire up R, I now get the following message (red) at the end of 
the prologue.

R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Error in loadNamespace(name) : there is no package called ?yaml?

How do I get rid of it?
Joe

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Jul 30 21:22:35 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Mon, 30 Jul 2018 12:22:35 -0700 (PDT)
Subject: [R] Unexpected YAML
In-Reply-To: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
Message-ID: <alpine.LNX.2.20.1807301221330.11651@salmo.appl-ecosys.com>

On Mon, 30 Jul 2018, JLucke at ria.buffalo.edu wrote:

> Error in loadNamespace(name) : there is no package called ?yaml?
> How do I get rid of it?

Joe,

   Easiest way is to install it:

> install.packages("yaml")

Rich


From ruipb@rr@d@@ @ending from @@po@pt  Mon Jul 30 21:27:43 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Mon, 30 Jul 2018 20:27:43 +0100
Subject: [R] Unexpected YAML
In-Reply-To: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
Message-ID: <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>

Hello,

Maybe R is loading a previously saved session.
Check whether you have a file named .RData in your working directory.
(This is not a file extension, it's the full filename.)

Hope this helps,

Rui Barradas

?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
> R Users:
> 
> Whenever I fire up R, I now get the following message (red) at the end of
> the prologue.
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Error in loadNamespace(name) : there is no package called ?yaml?
> 
> How do I get rid of it?
> Joe
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @ending from gm@il@com  Mon Jul 30 22:06:12 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 30 Jul 2018 13:06:12 -0700
Subject: [R] (no subject)
In-Reply-To: <CAPkQrWK2OyWjLR=aGD+zOiyHtOVReKd+=oY6oXOKD3xYWP1GUw@mail.gmail.com>
References: <CAPkQrWK2OyWjLR=aGD+zOiyHtOVReKd+=oY6oXOKD3xYWP1GUw@mail.gmail.com>
Message-ID: <CAGxFJbR4Qr6U6tNdL2SNoLNPs=kk7wah8=QZs5V-oLykfqEDJQ@mail.gmail.com>

How can one possibly answer this without knowing the structure of your
dataset?

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 30, 2018 at 8:24 AM, Baojun Sun <bsun1 at students.towson.edu>
wrote:

> The book "Introduction to Statistical Learning" gives R scripts for its
> labs. I found a script for ridge regression that works on the dataset the
> book uses but is unusable on other datasets I own unless I clean the data.
>
>
> I'm trying to understand the syntax for I need for data cleaning and am
> stuck. I want to learn to do ridge regression. I tried using my own data
> set on this script rather than the book example but get errors. If you use
> your own data set rather than the Hitters dataset, then you'll get errors
> unless you format your code. How do I change this script or clean any
> dataset so that this script for ridge regression useable for all datasets?
>
>
>     library(ISLR)
>
>     fix(Hitters)
>
>     names(Hitters)
>
>     dim(Hitters)
>
>     sum(is.na(Hitters$Salary))
>
>     Hitters=na.omit(Hitters)
>
>     dim(Hitters)
>
>     sum(is.na(Hitters))
>
>     library(leaps)
>
>
>
>     x=model.matrix(Salary~.,Hitters)[,-1]
>
>     y=Hitters$Salary
>
>
>
>     # Ridge Regression
>
>
>
>     library(glmnet)
>
>     grid=10^seq(10,-2,length=100)
>
>     ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
>
>     dim(coef(ridge.mod))
>
>     ridge.mod$lambda[50]
>
>     coef(ridge.mod)[,50]
>
>     sqrt(sum(coef(ridge.mod)[-1,50]^2))
>
>     ridge.mod$lambda[60]
>
>     coef(ridge.mod)[,60]
>
>     sqrt(sum(coef(ridge.mod)[-1,60]^2))
>
>     predict(ridge.mod,s=50,type="coefficients")[1:20,]
>
>     set.seed(1)
>
>     train=sample(1:nrow(x), nrow(x)/2)
>
>     test=(-train)
>
>     y.test=y[test]
>
>     ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
>
>     ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
>
>     mean((ridge.pred-y.test)^2)
>
>     mean((mean(y[train])-y.test)^2)
>
>     ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
>
>     mean((ridge.pred-y.test)^2)
>
>     ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
>
>     mean((ridge.pred-y.test)^2)
>
>     lm(y~x, subset=train)
>
>     predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
>
>     set.seed(1)
>
>     cv.out=cv.glmnet(x[train,],y[train],alpha=0)
>
>     plot(cv.out)
>
>     bestlam=cv.out$lambda.min
>
>     bestlam
>
>     ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
>
>     mean((ridge.pred-y.test)^2)
>
>     out=glmnet(x,y,alpha=0)
>
>     predict(out,type="coefficients",s=bestlam)[1:20
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Tue Jul 31 01:03:26 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 31 Jul 2018 09:03:26 +1000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
Message-ID: <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>

Hi Diego,
You may have to do some conversion as you have three fields in the
first line using the default space separator and five fields in
subsequent lines. If the first line doesn't contain any important data
you can just delete it or replace it with a meaningful header line
with five fields and save the file under another name.

It looks as thought you have date-time as two fields. If so, you can
just read the first field if you only want the date:

# assume you have removed the first line
dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")

If you want the date/time:

dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d %H:%M:%S")

Jim

On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <diego.avesani at gmail.com> wrote:
> Dear all,
>
> I am dealing with the reading of a *.txt file.
> The txt file the following shape:
>
> 103001930 103001580 103001530
> 1998-10-01 00:00:00 0.6 0 0
> 1998-10-01 01:00:00 0.2 0.2 0.2
> 1998-10-01 02:00:00 0.6 0.2 0.4
> 1998-10-01 03:00:00 0 0 0.6
> 1998-10-01 04:00:00 0 0 0
> 1998-10-01 05:00:00 0 0 0
> 1998-10-01 06:00:00 0 0 0
> 1998-10-01 07:00:00 0.2 0 0
>
> If it is possible I have a coupe of questions, which will sound stupid but
> they are important to me in order to understand ho R deal with file or date.
>
> 1) Do I have to convert it to a *csv file?
> 2) Can a deal with space and not ","
> 3) How can I read date?
>
> thanks a lot to all of you,
> Thanks
>
>
> Diego
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@cqueen1 @ending from llnl@gov  Tue Jul 31 01:25:20 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 30 Jul 2018 23:25:20 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
Message-ID: <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>

Or, without removing the first line
  dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)

Another alternative,
   dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
since the dates appear to be in the default format.
(I generally prefer to work with datetimes in POSIXct class rather than POSIXlt class)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon" <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:

    Hi Diego,
    You may have to do some conversion as you have three fields in the
    first line using the default space separator and five fields in
    subsequent lines. If the first line doesn't contain any important data
    you can just delete it or replace it with a meaningful header line
    with five fields and save the file under another name.
    
    It looks as thought you have date-time as two fields. If so, you can
    just read the first field if you only want the date:
    
    # assume you have removed the first line
    dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
    dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
    
    If you want the date/time:
    
    dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d %H:%M:%S")
    
    Jim
    
    On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <diego.avesani at gmail.com> wrote:
    > Dear all,
    >
    > I am dealing with the reading of a *.txt file.
    > The txt file the following shape:
    >
    > 103001930 103001580 103001530
    > 1998-10-01 00:00:00 0.6 0 0
    > 1998-10-01 01:00:00 0.2 0.2 0.2
    > 1998-10-01 02:00:00 0.6 0.2 0.4
    > 1998-10-01 03:00:00 0 0 0.6
    > 1998-10-01 04:00:00 0 0 0
    > 1998-10-01 05:00:00 0 0 0
    > 1998-10-01 06:00:00 0 0 0
    > 1998-10-01 07:00:00 0.2 0 0
    >
    > If it is possible I have a coupe of questions, which will sound stupid but
    > they are important to me in order to understand ho R deal with file or date.
    >
    > 1) Do I have to convert it to a *csv file?
    > 2) Can a deal with space and not ","
    > 3) How can I read date?
    >
    > thanks a lot to all of you,
    > Thanks
    >
    >
    > Diego
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From drjimlemon @ending from gm@il@com  Tue Jul 31 01:53:05 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 31 Jul 2018 09:53:05 +1000
Subject: [R] Plot Rclimdex or Climpact map with R
In-Reply-To: <upkhmgcxshy0j7p5hn6y9ykn.1532963921164@email.android.com>
References: <upkhmgcxshy0j7p5hn6y9ykn.1532963921164@email.android.com>
Message-ID: <CA+8X3fU0QaQcifOV_uQFyaCx5twoPnBGr6xoB45nKVj_9A=7KQ@mail.gmail.com>

Hi Agathe,
You can start with the "maps" package:

# in an R session
install.packages("maps")
# assume you want a simple map containing France
map("world",xlim=c(-6.0,9.6),ylim=c(42,51.5))

then plot your data by the coordinates of the stations. You will
probably want to plot graphical elements to represent your data
values. There are a number of ways to represent more than one value at
a point with various combinations of shape, size, color and so on.
Perhaps with more information about what you want to display I could
be more specific.

Jim


On Tue, Jul 31, 2018 at 1:18 AM, ouedraogo_agathe via R-help
<r-help at r-project.org> wrote:
> HelloI am using Rclimdex and Climpact packages to compute some indices. Having the location of all my stations I wish to plot the resultats on a map. Is there a way to simply do it from the packages or how to do it for someone who does not master R software?thanks
>
> Sent from my Samsung Galaxy smartphone.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ouedr@ogo_@g@the @ending from y@hoo@fr  Tue Jul 31 02:23:20 2018
From: ouedr@ogo_@g@the @ending from y@hoo@fr (ouedraogo_agathe)
Date: Tue, 31 Jul 2018 03:23:20 +0300
Subject: [R] Plot Rclimdex or Climpact map with R
Message-ID: <1wg35pn68k6w4slah2s1j80j.1532996600836@email.android.com>

For example the packages compute some indices let's say total precipitation (annua). So i ll have for each station a table representing annual totals with the trend slope. So i would like to put them on a map ( a county in Kenya) so that i can easily see the trend spatially.



Sent from my Samsung Galaxy smartphone.
-------- Original message --------From: Jim Lemon <drjimlemon at gmail.com> Date: 7/31/18  02:53  (GMT+03:00) To: ouedraogo_agathe <ouedraogo_agathe at yahoo.fr> Cc: r-help mailing list <r-help at r-project.org> Subject: Re: [R] Plot Rclimdex or Climpact map with R 
Hi Agathe,
You can start with the "maps" package:

# in an R session
install.packages("maps")
# assume you want a simple map containing France
map("world",xlim=c(-6.0,9.6),ylim=c(42,51.5))

then plot your data by the coordinates of the stations. You will
probably want to plot graphical elements to represent your data
values. There are a number of ways to represent more than one value at
a point with various combinations of shape, size, color and so on.
Perhaps with more information about what you want to display I could
be more specific.

Jim


On Tue, Jul 31, 2018 at 1:18 AM, ouedraogo_agathe via R-help
<r-help at r-project.org> wrote:
> HelloI am using Rclimdex and Climpact packages to compute some indices. Having the location of all my stations I wish to plot the resultats on a map. Is there a way to simply do it from the packages or how to do it for someone who does not master R software?thanks
>
> Sent from my Samsung Galaxy smartphone.
>???????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From e@ @ending from enrico@chum@nn@net  Tue Jul 31 10:28:07 2018
From: e@ @ending from enrico@chum@nn@net (Enrico Schumann)
Date: Tue, 31 Jul 2018 10:28:07 +0200
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
 <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
 <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
Message-ID: <20180731102807.Horde.iMVRHzTAmrtI4QNEuPpEoVT@webmail.your-server.de>


Quoting Christofer Bogaso <bogaso.christofer at gmail.com>:

> The data type is defined as bigint

Your query does not specify a number, but a string
(you single-quote the digits). Databases may do type conversion;
for instance, see the MySQL manual:  
https://dev.mysql.com/doc/refman/8.0/en/type-conversion.html

Since you send the query as a string anyway, there may be no need
for a "'string' within a string".

Please note that I have Cc'ed <r-sig-db at r-project.org>. Any follow-up
should probably go to that mailing list.


>
> On Mon, Jul 30, 2018 at 4:45 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> The ID matches in the first 16 characters.
>> How is your table XXXX declared?
>>
>>
>> On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
>> bogaso.christofer at gmail.com> wrote:
>>
>>> Session Information for above error:
>>>
>>> > sessionInfo()
>>> R version 3.5.0 (2018-04-23)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 16299)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>>                  LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
>>> DBI_1.0.0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.5.0 tools_3.5.0
>>>
>>> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
>>> bogaso.christofer at gmail.com> wrote:
>>>
>>> > Hi,
>>> >
>>> > I used following SQL query to fetch information from DB
>>> >
>>> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and
>>> ID =
>>> > '72075186224672770' limit 10")
>>> >          ID
>>> > 1 72075186224672768
>>> >
>>> > As you see, it is returning a different result from what actual query
>>> > string contains.
>>> >
>>> > However when I used the same query in some other SQL client, I get the
>>> > expected result as:
>>> >
>>> > 72075186224672770
>>> >
>>> > Any idea on what went wrong in R supplied query would be highly
>>> > appreciated.
>>> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From drjimlemon @ending from gm@il@com  Tue Jul 31 11:02:20 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 31 Jul 2018 19:02:20 +1000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
Message-ID: <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>

Hi Diego,
One way you can get daily means is:

st1_daily<-by(MyData$st1,MyData$date,mean)
st2_daily<-by(MyData$st2,MyData$date,mean)
st3_daily<-by(MyData$st3,MyData$date,mean)

Jim

On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com> wrote:
> Dear all,
> I have found the error, my fault. Sorry.
> There was an extra come in the headers line.
> Thanks again.
>
> If I can I would like to ask you another questions about the imported data.
> I would like to compute the daily average of the different date. Basically I
> have hourly data, I would like to ave the daily mean of them.
>
> Is there some special commands?
>
> Thanks a lot.
>
>
> Diego
>
>
> On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com> wrote:
>>
>> Dear all,
>> I move to csv file because originally the date where in csv file.
>> In addition, due to the fact that, as you told me, read.csv is a special
>> case of read.table, I prefer start to learn from the simplest one.
>> After that, I will try also the *.txt format.
>>
>> with read.csv, something strange happened:
>>
>> This us now the file:
>>
>> date,st1,st2,st3,
>> 10/1/1998 0:00,0.6,0,0
>> 10/1/1998 1:00,0.2,0.2,0.2
>> 10/1/1998 2:00,0.6,0.2,0.4
>> 10/1/1998 3:00,0,0,0.6
>> 10/1/1998 4:00,0,0,0
>> 10/1/1998 5:00,0,0,0
>> 10/1/1998 6:00,0,0,0
>> 10/1/1998 7:00,0.2,0,0
>> 10/1/1998 8:00,0.6,0.2,0
>> 10/1/1998 9:00,0.2,0.4,0.4
>> 10/1/1998 10:00,0,0.4,0.2
>>
>> When I apply:
>> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>
>> this is the results:
>>
>> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>
>> I do not understand why.
>> Something wrong with date?
>>
>> really really thanks,
>> I appreciate a lot all your helps.
>>
>> Diedro
>>
>>
>> Diego
>>
>>
>> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>>>
>>> Or, without removing the first line
>>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>>
>>> Another alternative,
>>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>> since the dates appear to be in the default format.
>>> (I generally prefer to work with datetimes in POSIXct class rather than
>>> POSIXlt class)
>>>
>>> -Don
>>>
>>> --
>>> Don MacQueen
>>> Lawrence Livermore National Laboratory
>>> 7000 East Ave., L-627
>>> Livermore, CA 94550
>>> 925-423-1062
>>> Lab cell 925-724-7509
>>>
>>>
>>>
>>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:
>>>
>>>     Hi Diego,
>>>     You may have to do some conversion as you have three fields in the
>>>     first line using the default space separator and five fields in
>>>     subsequent lines. If the first line doesn't contain any important
>>> data
>>>     you can just delete it or replace it with a meaningful header line
>>>     with five fields and save the file under another name.
>>>
>>>     It looks as thought you have date-time as two fields. If so, you can
>>>     just read the first field if you only want the date:
>>>
>>>     # assume you have removed the first line
>>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>>
>>>     If you want the date/time:
>>>
>>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>> %H:%M:%S")
>>>
>>>     Jim
>>>
>>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>> <diego.avesani at gmail.com> wrote:
>>>     > Dear all,
>>>     >
>>>     > I am dealing with the reading of a *.txt file.
>>>     > The txt file the following shape:
>>>     >
>>>     > 103001930 103001580 103001530
>>>     > 1998-10-01 00:00:00 0.6 0 0
>>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>>     > 1998-10-01 03:00:00 0 0 0.6
>>>     > 1998-10-01 04:00:00 0 0 0
>>>     > 1998-10-01 05:00:00 0 0 0
>>>     > 1998-10-01 06:00:00 0 0 0
>>>     > 1998-10-01 07:00:00 0.2 0 0
>>>     >
>>>     > If it is possible I have a coupe of questions, which will sound
>>> stupid but
>>>     > they are important to me in order to understand ho R deal with file
>>> or date.
>>>     >
>>>     > 1) Do I have to convert it to a *csv file?
>>>     > 2) Can a deal with space and not ","
>>>     > 3) How can I read date?
>>>     >
>>>     > thanks a lot to all of you,
>>>     > Thanks
>>>     >
>>>     >
>>>     > Diego
>>>     >
>>>     >         [[alternative HTML version deleted]]
>>>     >
>>>     > ______________________________________________
>>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>>     > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>     > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>     ______________________________________________
>>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>     PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>     and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>


From r@iner_krug @ending from icloud@com  Tue Jul 31 09:02:25 2018
From: r@iner_krug @ending from icloud@com (Rainer Krug)
Date: Tue, 31 Jul 2018 09:02:25 +0200
Subject: [R] Unexpected YAML
In-Reply-To: <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
 <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
Message-ID: <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>

.RData does not save any info abut previously loaded packages - so this would not cause the problem.

Rainer



> On 30 Jul 2018, at 21:27, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Maybe R is loading a previously saved session.
> Check whether you have a file named .RData in your working directory.
> (This is not a file extension, it's the full filename.)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
>> R Users:
>> Whenever I fire up R, I now get the following message (red) at the end of
>> the prologue.
>> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>> Error in loadNamespace(name) : there is no package called ?yaml?
>> How do I get rid of it?
>> Joe
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From petr@pik@l @ending from prechez@@cz  Tue Jul 31 12:39:39 2018
From: petr@pik@l @ending from prechez@@cz (PIKAL Petr)
Date: Tue, 31 Jul 2018 10:39:39 +0000
Subject: [R] Unexpected YAML
In-Reply-To: <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
 <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
 <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>
Message-ID: <627ab499c8954887b960faa73a76fa6f@SRVEXCHCM1302.precheza.cz>

Hi

However if in .RData is an object created by "yaml" and the package is not loaded it could cause this message. It was similar with ggplot objects if ggplot2 is not loaded.

Removing this object and saving session to update .RData can help.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rainer Krug via R-
> help
> Sent: Tuesday, July 31, 2018 9:02 AM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: r-help at r-project.org
> Subject: Re: [R] Unexpected YAML
>
> .RData does not save any info abut previously loaded packages - so this would
> not cause the problem.
>
> Rainer
>
>
>
> > On 30 Jul 2018, at 21:27, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Maybe R is loading a previously saved session.
> > Check whether you have a file named .RData in your working directory.
> > (This is not a file extension, it's the full filename.)
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
> >> R Users:
> >> Whenever I fire up R, I now get the following message (red) at the
> >> end of the prologue.
> >> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> >> Copyright (C) 2018 The R Foundation for Statistical Computing
> >> Platform: x86_64-w64-mingw32/x64 (64-bit) R is free software and
> >> comes with ABSOLUTELY NO WARRANTY.
> >> You are welcome to redistribute it under certain conditions.
> >> Type 'license()' or 'licence()' for distribution details.
> >> R is a collaborative project with many contributors.
> >> Type 'contributors()' for more information and 'citation()' on how to
> >> cite R or R packages in publications.
> >> Type 'demo()' for some demos, 'help()' for on-line help, or
> >> 'help.start()' for an HTML browser interface to help.
> >> Type 'q()' to quit R.
> >> Error in loadNamespace(name) : there is no package called ?yaml?
> >> How do I get rid of it?
> >> Joe
> >> [[alternative HTML version deleted]]
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology,
> UCT), Dipl. Phys. (Germany)
>
> University of Z?rich
>
> Cell:       +41 (0)78 630 66 57
> email:      Rainer at krugs.de
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jul 31 17:19:28 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 31 Jul 2018 08:19:28 -0700
Subject: [R] Unexpected YAML
In-Reply-To: <627ab499c8954887b960faa73a76fa6f@SRVEXCHCM1302.precheza.cz>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
 <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
 <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>
 <627ab499c8954887b960faa73a76fa6f@SRVEXCHCM1302.precheza.cz>
Message-ID: <D0BDC228-BDBA-4102-A1B7-2AD8243F0644@dcn.davis.ca.us>

... or deleting .RData and avoiding creating them in the future. Named save files (anything.RData) are useful but the autoload feature of .RData files is not and this particular behavior is one of the reasons why.

On July 31, 2018 3:39:39 AM PDT, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi
>
>However if in .RData is an object created by "yaml" and the package is
>not loaded it could cause this message. It was similar with ggplot
>objects if ggplot2 is not loaded.
>
>Removing this object and saving session to update .RData can help.
>
>Cheers
>Petr
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rainer Krug
>via R-
>> help
>> Sent: Tuesday, July 31, 2018 9:02 AM
>> To: Rui Barradas <ruipbarradas at sapo.pt>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Unexpected YAML
>>
>> .RData does not save any info abut previously loaded packages - so
>this would
>> not cause the problem.
>>
>> Rainer
>>
>>
>>
>> > On 30 Jul 2018, at 21:27, Rui Barradas <ruipbarradas at sapo.pt>
>wrote:
>> >
>> > Hello,
>> >
>> > Maybe R is loading a previously saved session.
>> > Check whether you have a file named .RData in your working
>directory.
>> > (This is not a file extension, it's the full filename.)
>> >
>> > Hope this helps,
>> >
>> > Rui Barradas
>> >
>> > ?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
>> >> R Users:
>> >> Whenever I fire up R, I now get the following message (red) at the
>> >> end of the prologue.
>> >> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> >> Copyright (C) 2018 The R Foundation for Statistical Computing
>> >> Platform: x86_64-w64-mingw32/x64 (64-bit) R is free software and
>> >> comes with ABSOLUTELY NO WARRANTY.
>> >> You are welcome to redistribute it under certain conditions.
>> >> Type 'license()' or 'licence()' for distribution details.
>> >> R is a collaborative project with many contributors.
>> >> Type 'contributors()' for more information and 'citation()' on how
>to
>> >> cite R or R packages in publications.
>> >> Type 'demo()' for some demos, 'help()' for on-line help, or
>> >> 'help.start()' for an HTML browser interface to help.
>> >> Type 'q()' to quit R.
>> >> Error in loadNamespace(name) : there is no package called ?yaml?
>> >> How do I get rid of it?
>> >> Joe
>> >> [[alternative HTML version deleted]]
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>Biology,
>> UCT), Dipl. Phys. (Germany)
>>
>> University of Z?rich
>>
>> Cell:       +41 (0)78 630 66 57
>> email:      Rainer at krugs.de
>> Skype:      RMkrug
>>
>> PGP: 0x0F52F982
>>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
>obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
>about processing and protection of business partner?s personal data are
>available on website:
>https://www.precheza.cz/en/personal-data-protection-principles/
>D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>documents attached to it may be confidential and are subject to the
>legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From diego@@ve@@ni @ending from gm@il@com  Tue Jul 31 10:40:52 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Tue, 31 Jul 2018 10:40:52 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
Message-ID: <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>

Dear all,
I move to csv file because originally the date where in csv file.
In addition, due to the fact that, as you told me, read.csv is a special
case of read.table, I prefer start to learn from the simplest one.
After that, I will try also the *.txt format.

with read.csv, something strange happened:

This us now the file:

date,st1,st2,st3,
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0
10/1/1998 8:00,0.6,0.2,0
10/1/1998 9:00,0.2,0.4,0.4
10/1/1998 10:00,0,0.4,0.2

When I apply:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

this is the results:

10/1/1998 0:00    0.6    0.00    0.0 NA
2        10/1/1998 1:00    0.2    0.20    0.2 NA
3        10/1/1998 2:00    0.6    0.20    0.4 NA
4        10/1/1998 3:00    0.0    0.00    0.6 NA
5        10/1/1998 4:00    0.0    0.00    0.0 NA
6        10/1/1998 5:00    0.0    0.00    0.0 NA
7        10/1/1998 6:00    0.0    0.00    0.0 NA
8        10/1/1998 7:00    0.2    0.00    0.0 NA

I do not understand why.
Something wrong with date?

really really thanks,
I appreciate a lot all your helps.

Diedro


Diego


On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Or, without removing the first line
>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>
> Another alternative,
>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> since the dates appear to be in the default format.
> (I generally prefer to work with datetimes in POSIXct class rather than
> POSIXlt class)
>
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon" <
> r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:
>
>     Hi Diego,
>     You may have to do some conversion as you have three fields in the
>     first line using the default space separator and five fields in
>     subsequent lines. If the first line doesn't contain any important data
>     you can just delete it or replace it with a meaningful header line
>     with five fields and save the file under another name.
>
>     It looks as thought you have date-time as two fields. If so, you can
>     just read the first field if you only want the date:
>
>     # assume you have removed the first line
>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>
>     If you want the date/time:
>
>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> %H:%M:%S")
>
>     Jim
>
>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <
> diego.avesani at gmail.com> wrote:
>     > Dear all,
>     >
>     > I am dealing with the reading of a *.txt file.
>     > The txt file the following shape:
>     >
>     > 103001930 103001580 103001530
>     > 1998-10-01 00:00:00 0.6 0 0
>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>     > 1998-10-01 03:00:00 0 0 0.6
>     > 1998-10-01 04:00:00 0 0 0
>     > 1998-10-01 05:00:00 0 0 0
>     > 1998-10-01 06:00:00 0 0 0
>     > 1998-10-01 07:00:00 0.2 0 0
>     >
>     > If it is possible I have a coupe of questions, which will sound
> stupid but
>     > they are important to me in order to understand ho R deal with file
> or date.
>     >
>     > 1) Do I have to convert it to a *csv file?
>     > 2) Can a deal with space and not ","
>     > 3) How can I read date?
>     >
>     > thanks a lot to all of you,
>     > Thanks
>     >
>     >
>     > Diego
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Tue Jul 31 10:51:27 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Tue, 31 Jul 2018 10:51:27 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
Message-ID: <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>

Dear all,
I have found the error, my fault. Sorry.
There was an extra come in the headers line.
Thanks again.

If I can I would like to ask you another questions about the imported data.
I would like to compute the daily average of the different date. Basically
I have hourly data, I would like to ave the daily mean of them.

Is there some special commands?

Thanks a lot.


Diego


On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear all,
> I move to csv file because originally the date where in csv file.
> In addition, due to the fact that, as you told me, read.csv is a special
> case of read.table, I prefer start to learn from the simplest one.
> After that, I will try also the *.txt format.
>
> with read.csv, something strange happened:
>
> This us now the file:
>
> date,st1,st2,st3,
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
> 10/1/1998 8:00,0.6,0.2,0
> 10/1/1998 9:00,0.2,0.4,0.4
> 10/1/1998 10:00,0,0.4,0.2
>
> When I apply:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> this is the results:
>
> 10/1/1998 0:00    0.6    0.00    0.0 NA
> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>
> I do not understand why.
> Something wrong with date?
>
> really really thanks,
> I appreciate a lot all your helps.
>
> Diedro
>
>
> Diego
>
>
> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
>> Or, without removing the first line
>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>
>> Another alternative,
>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> since the dates appear to be in the default format.
>> (I generally prefer to work with datetimes in POSIXct class rather than
>> POSIXlt class)
>>
>> -Don
>>
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>>
>>
>>
>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon" <
>> r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:
>>
>>     Hi Diego,
>>     You may have to do some conversion as you have three fields in the
>>     first line using the default space separator and five fields in
>>     subsequent lines. If the first line doesn't contain any important data
>>     you can just delete it or replace it with a meaningful header line
>>     with five fields and save the file under another name.
>>
>>     It looks as thought you have date-time as two fields. If so, you can
>>     just read the first field if you only want the date:
>>
>>     # assume you have removed the first line
>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>
>>     If you want the date/time:
>>
>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> %H:%M:%S")
>>
>>     Jim
>>
>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <
>> diego.avesani at gmail.com> wrote:
>>     > Dear all,
>>     >
>>     > I am dealing with the reading of a *.txt file.
>>     > The txt file the following shape:
>>     >
>>     > 103001930 103001580 103001530
>>     > 1998-10-01 00:00:00 0.6 0 0
>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>     > 1998-10-01 03:00:00 0 0 0.6
>>     > 1998-10-01 04:00:00 0 0 0
>>     > 1998-10-01 05:00:00 0 0 0
>>     > 1998-10-01 06:00:00 0 0 0
>>     > 1998-10-01 07:00:00 0.2 0 0
>>     >
>>     > If it is possible I have a coupe of questions, which will sound
>> stupid but
>>     > they are important to me in order to understand ho R deal with file
>> or date.
>>     >
>>     > 1) Do I have to convert it to a *csv file?
>>     > 2) Can a deal with space and not ","
>>     > 3) How can I read date?
>>     >
>>     > thanks a lot to all of you,
>>     > Thanks
>>     >
>>     >
>>     > Diego
>>     >
>>     >         [[alternative HTML version deleted]]
>>     >
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>>
>>     ______________________________________________
>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Tue Jul 31 11:12:17 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Tue, 31 Jul 2018 11:12:17 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
Message-ID: <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>

Dear Jim, Dear all,

thanks a lot.

Unfortunately, I get the following error:


 st1_daily<-by(MyData$st1,MyData$date,mean)Error in
tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L, 925L,  :
  arguments must have same length


This is particularly strange. indeed, if I apply


mean(MyData$str1,na.rm=TRUE)


it works


Sorry, I have to learn a lot.
You are really boosting me

Diego


On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Diego,
> One way you can get daily means is:
>
> st1_daily<-by(MyData$st1,MyData$date,mean)
> st2_daily<-by(MyData$st2,MyData$date,mean)
> st3_daily<-by(MyData$st3,MyData$date,mean)
>
> Jim
>
> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com>
> wrote:
> > Dear all,
> > I have found the error, my fault. Sorry.
> > There was an extra come in the headers line.
> > Thanks again.
> >
> > If I can I would like to ask you another questions about the imported
> data.
> > I would like to compute the daily average of the different date.
> Basically I
> > have hourly data, I would like to ave the daily mean of them.
> >
> > Is there some special commands?
> >
> > Thanks a lot.
> >
> >
> > Diego
> >
> >
> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com> wrote:
> >>
> >> Dear all,
> >> I move to csv file because originally the date where in csv file.
> >> In addition, due to the fact that, as you told me, read.csv is a special
> >> case of read.table, I prefer start to learn from the simplest one.
> >> After that, I will try also the *.txt format.
> >>
> >> with read.csv, something strange happened:
> >>
> >> This us now the file:
> >>
> >> date,st1,st2,st3,
> >> 10/1/1998 0:00,0.6,0,0
> >> 10/1/1998 1:00,0.2,0.2,0.2
> >> 10/1/1998 2:00,0.6,0.2,0.4
> >> 10/1/1998 3:00,0,0,0.6
> >> 10/1/1998 4:00,0,0,0
> >> 10/1/1998 5:00,0,0,0
> >> 10/1/1998 6:00,0,0,0
> >> 10/1/1998 7:00,0.2,0,0
> >> 10/1/1998 8:00,0.6,0.2,0
> >> 10/1/1998 9:00,0.2,0.4,0.4
> >> 10/1/1998 10:00,0,0.4,0.2
> >>
> >> When I apply:
> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>
> >> this is the results:
> >>
> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>
> >> I do not understand why.
> >> Something wrong with date?
> >>
> >> really really thanks,
> >> I appreciate a lot all your helps.
> >>
> >> Diedro
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> >>>
> >>> Or, without removing the first line
> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>
> >>> Another alternative,
> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>> since the dates appear to be in the default format.
> >>> (I generally prefer to work with datetimes in POSIXct class rather than
> >>> POSIXlt class)
> >>>
> >>> -Don
> >>>
> >>> --
> >>> Don MacQueen
> >>> Lawrence Livermore National Laboratory
> >>> 7000 East Ave., L-627
> >>> Livermore, CA 94550
> >>> 925-423-1062
> >>> Lab cell 925-724-7509
> >>>
> >>>
> >>>
> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com>
> wrote:
> >>>
> >>>     Hi Diego,
> >>>     You may have to do some conversion as you have three fields in the
> >>>     first line using the default space separator and five fields in
> >>>     subsequent lines. If the first line doesn't contain any important
> >>> data
> >>>     you can just delete it or replace it with a meaningful header line
> >>>     with five fields and save the file under another name.
> >>>
> >>>     It looks as thought you have date-time as two fields. If so, you
> can
> >>>     just read the first field if you only want the date:
> >>>
> >>>     # assume you have removed the first line
> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>
> >>>     If you want the date/time:
> >>>
> >>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>> %H:%M:%S")
> >>>
> >>>     Jim
> >>>
> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>> <diego.avesani at gmail.com> wrote:
> >>>     > Dear all,
> >>>     >
> >>>     > I am dealing with the reading of a *.txt file.
> >>>     > The txt file the following shape:
> >>>     >
> >>>     > 103001930 103001580 103001530
> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>     >
> >>>     > If it is possible I have a coupe of questions, which will sound
> >>> stupid but
> >>>     > they are important to me in order to understand ho R deal with
> file
> >>> or date.
> >>>     >
> >>>     > 1) Do I have to convert it to a *csv file?
> >>>     > 2) Can a deal with space and not ","
> >>>     > 3) How can I read date?
> >>>     >
> >>>     > thanks a lot to all of you,
> >>>     > Thanks
> >>>     >
> >>>     >
> >>>     > Diego
> >>>     >
> >>>     >         [[alternative HTML version deleted]]
> >>>     >
> >>>     > ______________________________________________
> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>     > PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>     > and provide commented, minimal, self-contained, reproducible
> code.
> >>>
> >>>     ______________________________________________
> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>     PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>     and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>
> >
>

	[[alternative HTML version deleted]]


From diego@@ve@@ni @ending from gm@il@com  Tue Jul 31 15:11:33 2018
From: diego@@ve@@ni @ending from gm@il@com (Diego Avesani)
Date: Tue, 31 Jul 2018 15:11:33 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
Message-ID: <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>

Dear all,

I have still problem with date.
Could you please tel me how to use POSIXct.
Indeed I have found this command:
timeAverage, but I am not able to convert MyDate to properly date.

Thank a lot
I hope to no bother you, at least too much


Diego


On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear Jim, Dear all,
>
> thanks a lot.
>
> Unfortunately, I get the following error:
>
>
>  st1_daily<-by(MyData$st1,MyData$date,mean)Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L, 925L,  :
>   arguments must have same length
>
>
> This is particularly strange. indeed, if I apply
>
>
> mean(MyData$str1,na.rm=TRUE)
>
>
> it works
>
>
> Sorry, I have to learn a lot.
> You are really boosting me
>
> Diego
>
>
> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Diego,
>> One way you can get daily means is:
>>
>> st1_daily<-by(MyData$st1,MyData$date,mean)
>> st2_daily<-by(MyData$st2,MyData$date,mean)
>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>
>> Jim
>>
>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com>
>> wrote:
>> > Dear all,
>> > I have found the error, my fault. Sorry.
>> > There was an extra come in the headers line.
>> > Thanks again.
>> >
>> > If I can I would like to ask you another questions about the imported
>> data.
>> > I would like to compute the daily average of the different date.
>> Basically I
>> > have hourly data, I would like to ave the daily mean of them.
>> >
>> > Is there some special commands?
>> >
>> > Thanks a lot.
>> >
>> >
>> > Diego
>> >
>> >
>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
>> wrote:
>> >>
>> >> Dear all,
>> >> I move to csv file because originally the date where in csv file.
>> >> In addition, due to the fact that, as you told me, read.csv is a
>> special
>> >> case of read.table, I prefer start to learn from the simplest one.
>> >> After that, I will try also the *.txt format.
>> >>
>> >> with read.csv, something strange happened:
>> >>
>> >> This us now the file:
>> >>
>> >> date,st1,st2,st3,
>> >> 10/1/1998 0:00,0.6,0,0
>> >> 10/1/1998 1:00,0.2,0.2,0.2
>> >> 10/1/1998 2:00,0.6,0.2,0.4
>> >> 10/1/1998 3:00,0,0,0.6
>> >> 10/1/1998 4:00,0,0,0
>> >> 10/1/1998 5:00,0,0,0
>> >> 10/1/1998 6:00,0,0,0
>> >> 10/1/1998 7:00,0.2,0,0
>> >> 10/1/1998 8:00,0.6,0.2,0
>> >> 10/1/1998 9:00,0.2,0.4,0.4
>> >> 10/1/1998 10:00,0,0.4,0.2
>> >>
>> >> When I apply:
>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> >>
>> >> this is the results:
>> >>
>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>> >>
>> >> I do not understand why.
>> >> Something wrong with date?
>> >>
>> >> really really thanks,
>> >> I appreciate a lot all your helps.
>> >>
>> >> Diedro
>> >>
>> >>
>> >> Diego
>> >>
>> >>
>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>> >>>
>> >>> Or, without removing the first line
>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>> >>>
>> >>> Another alternative,
>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> >>> since the dates appear to be in the default format.
>> >>> (I generally prefer to work with datetimes in POSIXct class rather
>> than
>> >>> POSIXlt class)
>> >>>
>> >>> -Don
>> >>>
>> >>> --
>> >>> Don MacQueen
>> >>> Lawrence Livermore National Laboratory
>> >>> 7000 East Ave., L-627
>> >>> Livermore, CA 94550
>> >>> 925-423-1062
>> >>> Lab cell 925-724-7509
>> >>>
>> >>>
>> >>>
>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>> >>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com>
>> wrote:
>> >>>
>> >>>     Hi Diego,
>> >>>     You may have to do some conversion as you have three fields in the
>> >>>     first line using the default space separator and five fields in
>> >>>     subsequent lines. If the first line doesn't contain any important
>> >>> data
>> >>>     you can just delete it or replace it with a meaningful header line
>> >>>     with five fields and save the file under another name.
>> >>>
>> >>>     It looks as thought you have date-time as two fields. If so, you
>> can
>> >>>     just read the first field if you only want the date:
>> >>>
>> >>>     # assume you have removed the first line
>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>> >>>
>> >>>     If you want the date/time:
>> >>>
>> >>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> >>> %H:%M:%S")
>> >>>
>> >>>     Jim
>> >>>
>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>> >>> <diego.avesani at gmail.com> wrote:
>> >>>     > Dear all,
>> >>>     >
>> >>>     > I am dealing with the reading of a *.txt file.
>> >>>     > The txt file the following shape:
>> >>>     >
>> >>>     > 103001930 103001580 103001530
>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>> >>>     > 1998-10-01 04:00:00 0 0 0
>> >>>     > 1998-10-01 05:00:00 0 0 0
>> >>>     > 1998-10-01 06:00:00 0 0 0
>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>> >>>     >
>> >>>     > If it is possible I have a coupe of questions, which will sound
>> >>> stupid but
>> >>>     > they are important to me in order to understand ho R deal with
>> file
>> >>> or date.
>> >>>     >
>> >>>     > 1) Do I have to convert it to a *csv file?
>> >>>     > 2) Can a deal with space and not ","
>> >>>     > 3) How can I read date?
>> >>>     >
>> >>>     > thanks a lot to all of you,
>> >>>     > Thanks
>> >>>     >
>> >>>     >
>> >>>     > Diego
>> >>>     >
>> >>>     >         [[alternative HTML version deleted]]
>> >>>     >
>> >>>     > ______________________________________________
>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>     > PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>>     > and provide commented, minimal, self-contained, reproducible
>> code.
>> >>>
>> >>>     ______________________________________________
>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>     PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>>     and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>>
>> >>
>> >
>>
>
>

	[[alternative HTML version deleted]]


From b@rhomopoli@ @ending from gm@il@com  Tue Jul 31 19:41:51 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Tue, 31 Jul 2018 13:41:51 -0400
Subject: [R] RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
Message-ID: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>

H
i All,

If I have this vector:

> vect <- c(foo = 11, bar = 2, norf = 45)

I can have a subset that has only "bar and "norf" this way:
> vect[c("bar","norf")]

Now how do I achieve the same by asking it for a subset that simply
excludes "foo"? I tried all these, resulting in errors:

vect[-"foo"]
vect[-c("foo")]
vect[!"foo"]
vect[!c("foo")]

Thanks!

	[[alternative HTML version deleted]]


From huzef@@kh@lil @ending from umich@edu  Tue Jul 31 19:49:16 2018
From: huzef@@kh@lil @ending from umich@edu (Huzefa Khalil)
Date: Tue, 31 Jul 2018 13:49:16 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
Message-ID: <CADsG8gNer0n=Q+uTxur1LODJrKG1KQmF=kZbjkfFMW+Ri-WWUg@mail.gmail.com>

try:

vect[which(names(vect) != "foo")]

On Tue, Jul 31, 2018 at 1:41 PM, ??????? ???? Ibrauheem Khat'taub
<barhomopolis at gmail.com> wrote:
> H
> i All,
>
> If I have this vector:
>
>> vect <- c(foo = 11, bar = 2, norf = 45)
>
> I can have a subset that has only "bar and "norf" this way:
>> vect[c("bar","norf")]
>
> Now how do I achieve the same by asking it for a subset that simply
> excludes "foo"? I tried all these, resulting in errors:
>
> vect[-"foo"]
> vect[-c("foo")]
> vect[!"foo"]
> vect[!c("foo")]
>
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@r@h@go@lee @ending from gm@il@com  Tue Jul 31 19:50:48 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Tue, 31 Jul 2018 13:50:48 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
Message-ID: <CAM_vjun6Brg9E_3pGbm2jG0yYLkeaHOyDRtoZJ3287ch7cHmRg@mail.gmail.com>

Hi,

You need to tell R to look in the names component of your vector. Here
are three different ways:

vect <- c(foo = 11, bar = 2, norf = 45)

vect[!(names(vect) %in% c("foo"))] # easily generalizable to a longer list

vect[!grepl("foo", names(vect))]

vect[!(names(vect) == "foo")]

There are many more ways to do this, all predicated on matching a
string within the character vector containing the names of your
object.

Also, on this list we don't care at all if you're using R Studio, or
what the version is. We do potentially care what version of R itself
you are using.

Sarah

On Tue, Jul 31, 2018 at 1:41 PM, ??????? ???? Ibrauheem Khat'taub
<barhomopolis at gmail.com> wrote:
> H
> i All,
>
> If I have this vector:
>
>> vect <- c(foo = 11, bar = 2, norf = 45)
>
> I can have a subset that has only "bar and "norf" this way:
>> vect[c("bar","norf")]
>
> Now how do I achieve the same by asking it for a subset that simply
> excludes "foo"? I tried all these, resulting in errors:
>
> vect[-"foo"]
> vect[-c("foo")]
> vect[!"foo"]
> vect[!c("foo")]
>
> Thanks!
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From b@rhomopoli@ @ending from gm@il@com  Tue Jul 31 19:54:04 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Tue, 31 Jul 2018 13:54:04 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAM_vjun6Brg9E_3pGbm2jG0yYLkeaHOyDRtoZJ3287ch7cHmRg@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
 <CAM_vjun6Brg9E_3pGbm2jG0yYLkeaHOyDRtoZJ3287ch7cHmRg@mail.gmail.com>
Message-ID: <CAC4BqreaKEUOMHAUpYmAgEOiYTmVM++DbfGT33reEKr_tm2ULQ@mail.gmail.com>

Awesome, Sarah, thanks!

And thanks for the clarification about declaring the version of R.

Best,
Ibrahim

On Tue, 31 Jul 2018 at 13:50, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> You need to tell R to look in the names component of your vector. Here
> are three different ways:
>
> vect <- c(foo = 11, bar = 2, norf = 45)
>
> vect[!(names(vect) %in% c("foo"))] # easily generalizable to a longer list
>
> vect[!grepl("foo", names(vect))]
>
> vect[!(names(vect) == "foo")]
>
> There are many more ways to do this, all predicated on matching a
> string within the character vector containing the names of your
> object.
>
> Also, on this list we don't care at all if you're using R Studio, or
> what the version is. We do potentially care what version of R itself
> you are using.
>
> Sarah
>
> On Tue, Jul 31, 2018 at 1:41 PM, ??????? ???? Ibrauheem Khat'taub
> <barhomopolis at gmail.com> wrote:
> > H
> > i All,
> >
> > If I have this vector:
> >
> >> vect <- c(foo = 11, bar = 2, norf = 45)
> >
> > I can have a subset that has only "bar and "norf" this way:
> >> vect[c("bar","norf")]
> >
> > Now how do I achieve the same by asking it for a subset that simply
> > excludes "foo"? I tried all these, resulting in errors:
> >
> > vect[-"foo"]
> > vect[-c("foo")]
> > vect[!"foo"]
> > vect[!c("foo")]
> >
> > Thanks!
> >
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From b@rhomopoli@ @ending from gm@il@com  Tue Jul 31 19:55:46 2018
From: b@rhomopoli@ @ending from gm@il@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Tue, 31 Jul 2018 13:55:46 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAHATPRmexVy0XtRqZe_VENFTOcnSog8m0rRs+QZ4e-gMH66iow@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
 <CAHATPRmexVy0XtRqZe_VENFTOcnSog8m0rRs+QZ4e-gMH66iow@mail.gmail.com>
Message-ID: <CAC4BqrciOBvN_2Tg8nx=MAb=zHSVM4c7T4zf116txeMkk+0KtA@mail.gmail.com>

Awesome, thanks!
?? ???? ????? ??????? ?????.
??????? ????


On Tue, 31 Jul 2018 at 13:54, Data Science Classes <
datascienceclasses at gmail.com> wrote:

> You can do
>
> Vect[-grep (?foo?, names(vect))]
>
> On Tue, 31 Jul 2018 at 11:12 PM, ??????? ???? Ibrauheem Khat'taub <
> barhomopolis at gmail.com> wrote:
>
>> H
>> i All,
>>
>> If I have this vector:
>>
>> > vect <- c(foo = 11, bar = 2, norf = 45)
>>
>> I can have a subset that has only "bar and "norf" this way:
>> > vect[c("bar","norf")]
>>
>> Now how do I achieve the same by asking it for a subset that simply
>> excludes "foo"? I tried all these, resulting in errors:
>>
>> vect[-"foo"]
>> vect[-c("foo")]
>> vect[!"foo"]
>> vect[!c("foo")]
>>
>> Thanks!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> Regards,
> Data Science Classes
>

	[[alternative HTML version deleted]]


From d@t@@ciencecl@@@e@ @ending from gm@il@com  Tue Jul 31 19:54:37 2018
From: d@t@@ciencecl@@@e@ @ending from gm@il@com (Data Science Classes)
Date: Tue, 31 Jul 2018 23:24:37 +0530
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
Message-ID: <CAHATPRmexVy0XtRqZe_VENFTOcnSog8m0rRs+QZ4e-gMH66iow@mail.gmail.com>

You can do

Vect[-grep (?foo?, names(vect))]

On Tue, 31 Jul 2018 at 11:12 PM, ??????? ???? Ibrauheem Khat'taub <
barhomopolis at gmail.com> wrote:

> H
> i All,
>
> If I have this vector:
>
> > vect <- c(foo = 11, bar = 2, norf = 45)
>
> I can have a subset that has only "bar and "norf" this way:
> > vect[c("bar","norf")]
>
> Now how do I achieve the same by asking it for a subset that simply
> excludes "foo"? I tried all these, resulting in errors:
>
> vect[-"foo"]
> vect[-c("foo")]
> vect[!"foo"]
> vect[!c("foo")]
>
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Regards,
Data Science Classes

	[[alternative HTML version deleted]]


From |r@@h@renow100 @end|ng |rom y@hoo@com  Sun Jul  1 00:14:37 2018
From: |r@@h@renow100 @end|ng |rom y@hoo@com (Ira Sharenow)
Date: Sat, 30 Jun 2018 22:14:37 +0000 (UTC)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
Message-ID: <1713527611.860691.1530396877620@mail.yahoo.com>

 I would like to thank everyone who helped me out. I have obtained some offline help, so I would like to summarize all the information I have received.
Before I summarize the thread, there is one loose end.
Initially I thought
library(dplyr)
dplyr::bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
would work, but there were problems.
lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
spreads out the data frames converting the data frames from long to wide, but it messes up the names. So one question I still have, is how can I programmatically change all of the names?
After this initial step, the first data frame's names might be derived from
c("George", "Washington") 
and the second data frame's names might be derived from
c("John", "Adams", "Thomas", "Jefferson")
What I want to change to the names to:
c("First1", "Second1")
and
c("First1", "Second1", "First2", "Second2")
I believe that will enable me to then go back and use bind_rows and complete that method of solution:
Step 1: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
Step 2: Clean up the names
Step 3: bind_rows
Immediately below is hopefully a clear and precise statement of the problem and the proposed solution path. Then there are the various solutions.
# Starting list of data frames
employees4List = list(data.frame(first1 = "Al", second1 = "Jones"), 
???????????????????? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
???????????????????? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", "Smith", "Adams")),
???????????????????? data.frame(first4 = ("Al"), second4 = "Jones2"))

employees4List


# Intermediate step that messes up the names but successfully converts from long to wide
lapply(employees4List, function(x) rbind.data.frame(c(t(x))))

# The intermediate list should likely look like this listFinal
df1 = data.frame(First1 = "Al", Second1 = "Jones", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
???????????????? First4 = NA, Second4 = NA)
df2 = data.frame(First1 = "Al2", Second1 = "Jones", First2 = "Barb", Second2 = "Smith", 
???????????????? First3 = NA, Second3 = NA, First4 = NA, Second4 = NA)

df3 = data.frame(First1 = "Al3", Second1 = "Jones", First2 = "Barbara", Second2 = "Smith", 
???????????????? First3 = "Carol", Second3 = "Adams", First4 = NA, Second4 = NA)
df4 = data.frame(First1 = "Al", Second1 = "Jones2", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
???????????????? First4 = NA, Second4 = NA)
listFinal = list(df1, df2, df3, df4)
listFinal

# Requested data frame (except that the columns are not just character but some are factor or even logical)
dplyr::bind_rows(listFinal)
Sarah Goslee solved the problem using base R.
Given
employees4List = list(
? data.frame(first1 = ("Al"), second1 = "Jones"),
? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones2", "Smith")),
? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones3",
??????????????????????????????????????????????????????????????? "Smith", "Adams")),
? data.frame(first4 = ("Al"), second4 = "Jones2"))

This function produces the solution in the requested structure.
dfbycol <- function(x) {
? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
? x <- do.call(rbind, x)
? x <- data.frame(x, stringsAsFactors=FALSE)
? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
? x
}
dfbycol(employees4List)
Offline, Jeff Newmiller and Bert Gunter provided alternative approaches to the problem as well as other advice. Their solutions meet the "tidy" criterion.
Bert suggested this online.
## list of two data frames with different column names and numbers of rows:
zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 5:9,b = letters[11:15]))
## create common column names and bind them up:
do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
This and the next suggestion by Jeff produced useful solutions but not in the requested form.
library(dplyr)
# note that these data frames all have character columns
# rather than factors, due to the as.is option when the
# data are read in.
DF1 <- read.table( text =
"First????????? Last
George????????? Washington
", header=TRUE, as.is = TRUE )
# dput looks ugly but is actually much more practical for
# providing R data on the mailing list... here is an example
dput( DF1 )
#> structure(list(First = "George", Last = "Washington")
#>, .Names = c("First",
#> "Last"), class = "data.frame", row.names = c(NA, -1L))

DF2 <- read.table( text =
"Start????????????? End
John????????????? Adams
Thomas??????? Jefferson
", header = TRUE, as.is = TRUE )

DFL <- list( DF1, DF2 )

# DFNames is a set of unique identifiers
DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
????????????????? , data = DFL
????????????????? )

DFL2 <- (? DFL1
??????? %>% mutate( data = lapply( data
????????????????????????????????? , function( DF ) {
????????????????????????????????????? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
????????????????????????????????????? gather( DF, ".Col", "value", -.PK )
??????????????????????????????????? }
????????????????????????????????? )
????????????????? )
??????? %>% unnest
??????? %>% spread( .Col, value )
??????? )
DFL2
During the discussion, useful links were recommended
[1] https://www.jstatsoft.org/article/view/v059i10?? Hadley on tidy data 
[2] http://r4ds.had.co.nz/relational-data.html#keys? Hadley on relational data
[3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example? How to make a great reproducible example
http://adv-r.had.co.nz/Functionals.html???? Improving lapply and related skills
Thanks again to everyone!
Ira




    On Friday, June 29, 2018, 7:47:13 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:  
 
 Code below...

a) Just because something can be done with dplyr does not mean that is the 
best way to do it. A solution in the hand is worth two on the Internet, 
and dplyr is not always the fastest method anyway.

b) I highly recommend that you read Hadley Wickham's paper on tidy data 
[1]. Also, having a group of one or more columns at all times that 
uniquely identify where the data came from is a "key" to success [2].

c) Please read and follow one of the various online documents about making 
reproducible examples in R (e.g. [3]). HTML formatting is really a pain 
(at best... at worst, it corrupts your code) on a plain-text-only list 
(you have read the Posting Guide, right?). Consider my example below as a 
model for you to follow in the future, and make sure to set your email 
program to send plain text. (Obviously your examples don't have to achieve 
success... but they should bring us up to speed with where you are having 
troubles IN R.)

[1] https://www.jstatsoft.org/article/view/v059i10
[2] http://r4ds.had.co.nz/relational-data.html#keys
[3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

----
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>? ? filter, lag
#> The following objects are masked from 'package:base':
#>
#>? ? intersect, setdiff, setequal, union
library(tidyr)

# note that these data frames all have character columns
# rather than factors, due to the as.is option when the
# data are read in.
DF1 <- read.table( text =
"First? ? ? ? ? Last
George? ? ? ? ? Washington
", header=TRUE, as.is = TRUE )

# dput looks ugly but is actually much more practical for
# providing R data on the mailing list... here is an example
dput( DF1 )
#> structure(list(First = "George", Last = "Washington")
#>, .Names = c("First",
#> "Last"), class = "data.frame", row.names = c(NA, -1L))

DF2 <- read.table( text =
"Start? ? ? ? ? ? ? End
John? ? ? ? ? ? ? Adams
Thomas? ? ? ? Jefferson
", header = TRUE, as.is = TRUE )

DFL <- list( DF1, DF2 )

# DFNames is a set of unique identifiers
DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
? ? ? ? ? ? ? ? ? , data = DFL
? ? ? ? ? ? ? ? ? )

DFL2 <- (? DFL1
? ? ? ? %>% mutate( data = lapply( data
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? , function( DF ) {
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? gather( DF, ".Col", "value", -.PK )
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? ? ? ? ? )
? ? ? ? %>% unnest
? ? ? ? %>% spread( .Col, value )
? ? ? ? )
DFL2
#> # A tibble: 3 x 6
#>? .DFNames? .PK End? ? ? First? Last? ? ? Start
#>? <chr>? ? <int> <chr>? ? <chr>? <chr>? ? ? <chr>
#> 1 DF1? ? ? ? ? 1 <NA>? ? ? George Washington <NA>
#> 2 DF2? ? ? ? ? 1 Adams? ? <NA>? <NA>? ? ? John
#> 3 DF2? ? ? ? ? 2 Jefferson <NA>? <NA>? ? ? Thomas

#' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
----

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

>
> Sarah and David,
>
> Thank you for your responses.I will try and be clearer.
>
> Base R solution: Sarah?smethod worked perfectly
>
> Is there a dplyrsolution?
>
> START: list of dataframes
>
> FINISH: one data frame
>
> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>
> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>
> EXAMPLE: List with twodata frames
>
> # DF1
>
> First?? ???????Last
>
> George Washington
>
> ?
>
> # DF2
>
> Start????????????? End
>
> John?????????????? Adams
>
> Thomas??????? Jefferson
>
> ?
>
> # End Result. One dataframe
>
> First1????? Second1??????? First2?????????? Second2
>
> George Washington?????? NA??????????????????? NA
>
> John?????????????? Adams??? Thomas??????? Jefferson
>
> ?
>
> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>
> The suggested solution was:
>
> library(dplyr)
>
> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>
> ?
>
> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>
> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>
> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>
> Ira
>
>
>? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>
>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> It isn't super clear to me what you're after.
>
> Agree.
>
> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>
> library(dplyr)
> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
> bind_rows(newList)
>
> #---------
>
> ? first1 second1
> 1? ? ? Al? Jones
> 2? ? Al2? Jones
> 3? ? Barb? Smith
> 4? ? Al3? Jones
> 5 Barbara? Smith
> 6? Carol? Adams
> 7? ? ? Al? Jones2
>
> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>
> -- 
> David.
>> Is this what you intend?
>>
>>> dfbycol(employees4BList)
>> ? first1 last1 first2 last2 first3 last3
>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>> 3? ? Al Jones? Barb Smith? Carol Adams
>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>
>>> dfbycol(employees4List)
>> ? first1? last1? first2 last2 first3 last3
>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>
>>
>> If so:
>>
>> employees4BList = list(
>> data.frame(first1 = "Al", second1 = "Jones"),
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>
>> employees4List = list(
>> data.frame(first1 = ("Al"), second1 = "Jones"),
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>
>> ###
>>
>> dfbycol <- function(x) {
>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>> ? x <- do.call(rbind, x)
>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>> ? x
>> }
>>
>> ###
>>
>> dfbycol(employees4BList)
>>
>> dfbycol(employees4List)
>>
>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>> <r-help at r-project.org> wrote:
>>> I have a list of data frames which I would like to combine into one data
>>> frame doing something like rbind. I wish to combine in column order and
>>> not by names. However, there are issues.
>>>
>>> The number of columns is not the same for each data frame. This is an
>>> intermediate step to a problem and the number of columns could be
>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>> is that the names of the columns produced by the first step are garbage.
>>>
>>> Below is a method that I obtained by asking a question on stack
>>> overflow. Unfortunately, my example was not general enough. The code
>>> below works for the simple case where the names of the people are
>>> consistent. It does not work when the names are realistically not the same.
>>>
>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>
>>>
>>> Please note that the lapply step sets things up except for the column
>>> name issue. If I could figure out a way to change the column names, then
>>> the bind_rows step will, I believe, work.
>>>
>>> So I really have two questions. How to change all column names of all
>>> the data frames and then how to solve the original problem.
>>>
>>> # The non general case works fine. It produces one data frame and I can
>>> then change the column names to
>>>
>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>
>>> #Non general easy case
>>>
>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4BList
>>>
>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> # This produces a nice list of data frames, except for the names
>>>
>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>
>>> # This list is a disaster. I am looking for a solution that works in
>>> this case.
>>>
>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> Thanks.
>>>
>>> Ira
>>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------  
	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul  1 03:14:45 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 18:14:45 -0700 (PDT)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <1713527611.860691.1530396877620@mail.yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
 <1713527611.860691.1530396877620@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1806301736300.71159@pedal.dcn.davis.ca.us>

Your request is getting a bit complicated with so much re-hashing, but 
here are three solutions: base only, a bit of dplyr, and dplyr+tidyr:

#########
# input data
employees4List = list(data.frame(first1 = "Al", second1 = 
"Jones"),
                       data.frame(first2 = c("Al2", "Barb"),
                                  second2 = c("Jones", "Smith")),
                       data.frame(first3 = c("Al3", "Barbara", 
"Carol"),
                                  second3 = c("Jones", "Smith", 
"Adams")),
                       data.frame(first4 = ("Al"), second4 = 
"Jones2"))
employees4List
#> [[1]]
#>   first1 second1
#> 1     Al   Jones
#>
#> [[2]]
#>   first2 second2
#> 1    Al2   Jones
#> 2   Barb   Smith
#>
#> [[3]]
#>    first3 second3
#> 1     Al3   Jones
#> 2 Barbara   Smith
#> 3   Carol   Adams
#>
#> [[4]]
#>   first4 second4
#> 1     Al  Jones2

# expected output
df1 = data.frame(First1 = "Al", Second1 = "Jones",
                  First2 = NA, Second2 = NA,
                  First3 = NA, Second3 = NA,
                  First4 = NA, Second4 = NA)
df2 = data.frame(First1 = "Al2", Second1 = "Jones",
                  First2 = "Barb", Second2 = "Smith",
                  First3 = NA, Second3 = NA,
                  First4 = NA, Second4 = NA)
df3 = data.frame(First1 = "Al3", Second1 = "Jones",
                  First2 = "Barbara", Second2 = "Smith",
                  First3 = "Carol", Second3 = "Adams",
                  First4 = NA, Second4 = NA)
df4 = data.frame(First1 = "Al", Second1 = "Jones2",
                  First2 = NA, Second2 = NA,
                  First3 = NA, Second3 = NA,
                  First4 = NA, Second4 = NA)
listFinal = list(df1, df2, df3, df4)
listFinal
#> [[1]]
#>   First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1     Al   Jones     NA      NA     NA      NA     NA      NA
#>
#> [[2]]
#>   First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1    Al2   Jones   Barb   Smith     NA      NA     NA      NA
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3 First4 Second4
#> 1    Al3   Jones Barbara   Smith  Carol   Adams     NA      NA
#>
#> [[4]]
#>   First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1     Al  Jones2     NA      NA     NA      NA     NA      NA

myrename1 <- function( DF, m ) {
   # if a pair of columns is not present, raise an error
   stopifnot( 2 == length( DF ) )
   n <- nrow( DF )
   # use memory layout of elements of matrix
   # t() automatically converts to matrix (nrow=2)
   # matrix(,nrow=1) re-interprets the column-major output of t()
   # as a single row matrix
   result <- as.data.frame( matrix( t( DF ), nrow = 1 )
                          , stringsAsFactors = FALSE
                          )
   if ( n < m ) {
     result[ , seq( 2 * n + 1, 2 * m ) ] <- NA
   }
   setNames( result
           , sprintf( "%s%d"
                    , c( "First", "Second" )
                       , rep( seq.int( m ), each = 2 )
                       )
           )
}

m <- max( unlist( lapply( employees4List, nrow ) ) )
listFinal1 <- lapply( employees4List, myrename1, m = m )
listFinal1
#> [[1]]
#>   First1 Second1 First2 Second2 First3 Second3
#> 1     Al   Jones     NA      NA     NA      NA
#>
#> [[2]]
#>   First1 Second1 First2 Second2 First3 Second3
#> 1    Al2   Jones   Barb   Smith     NA      NA
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3
#> 1    Al3   Jones Barbara   Smith  Carol   Adams
#>
#> [[4]]
#>   First1 Second1 First2 Second2 First3 Second3
#> 1     Al  Jones2     NA      NA     NA      NA
result1 <- do.call( rbind, listFinal1 )
result1
#>   First1 Second1  First2 Second2 First3 Second3
#> 1     Al   Jones    <NA>    <NA>   <NA>    <NA>
#> 2    Al2   Jones    Barb   Smith   <NA>    <NA>
#> 3    Al3   Jones Barbara   Smith  Carol   Adams
#> 4     Al  Jones2    <NA>    <NA>   <NA>    <NA>

myrename2 <- function( DF ) {
   # if a pair of columns is not present, raise an error
   stopifnot( 2 == length( DF ) )
   n <- nrow( DF )
   # use memory layout of elements of matrix
   # t() automatically converts to matrix (nrow=2)
   # matrix(,nrow=1) re-interprets the column-major output of t()
   # as a single row matrix
   setNames( as.data.frame( matrix( t( DF ), nrow = 1 )
                          , stringsAsFactors = FALSE
                          )
           , sprintf( "%s%d"
                    , c( "First", "Second" )
                    , rep( seq.int( n ), each = 2 )
                    )
           )
}

listFinal2 <- lapply( employees4List, myrename2 )
listFinal2
#> [[1]]
#>   First1 Second1
#> 1     Al   Jones
#>
#> [[2]]
#>   First1 Second1 First2 Second2
#> 1    Al2   Jones   Barb   Smith
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3
#> 1    Al3   Jones Barbara   Smith  Carol   Adams
#>
#> [[4]]
#>   First1 Second1
#> 1     Al  Jones2
result2 <- dplyr::bind_rows( listFinal2 )
result2
#>   First1 Second1  First2 Second2 First3 Second3
#> 1     Al   Jones    <NA>    <NA>   <NA>    <NA>
#> 2    Al2   Jones    Barb   Smith   <NA>    <NA>
#> 3    Al3   Jones Barbara   Smith  Carol   Adams
#> 4     Al  Jones2    <NA>    <NA>   <NA>    <NA>

library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)
myrename3 <- function( DF ) {
   # if a pair of columns is not present, raise an error
   stopifnot( 2 == length( DF ) )
   names( DF ) <- c( "a", "b" )
   m <- nrow( DF )
   (   DF
   %>% mutate_all( as.character )
   %>% mutate( rw = LETTERS[ seq.int( n() ) ] )
   %>% gather( col, val, -rw )
   %>% tidyr::unite( "labels", rw, col, sep="" )
   %>% spread( labels, val )
   %>% setNames( sprintf( "%s%d"
                        , c( "First", "Second" )
                        , rep( seq.int( m ), each = 2 )
                        )
               )
   )
}

listFinal3 <- lapply( employees4List, myrename3 )
listFinal3
#> [[1]]
#>   First1 Second1
#> 1     Al   Jones
#>
#> [[2]]
#>   First1 Second1 First2 Second2
#> 1    Al2   Jones   Barb   Smith
#>
#> [[3]]
#>   First1 Second1  First2 Second2 First3 Second3
#> 1    Al3   Jones Barbara   Smith  Carol   Adams
#>
#> [[4]]
#>   First1 Second1
#> 1     Al  Jones2
result3 <- dplyr::bind_rows( listFinal3 )
result3
#>   First1 Second1  First2 Second2 First3 Second3
#> 1     Al   Jones    <NA>    <NA>   <NA>    <NA>
#> 2    Al2   Jones    Barb   Smith   <NA>    <NA>
#> 3    Al3   Jones Barbara   Smith  Carol   Adams
#> 4     Al  Jones2    <NA>    <NA>   <NA>    <NA>

#' Created on 2018-06-30 by the [reprex 
package](http://reprex.tidyverse.org) (v0.2.0).
#########

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

> I would like to thank everyone who helped me out. I have obtained some offline help, so I would like to summarize all the information I have received.
> Before I summarize the thread, there is one loose end.
> Initially I thought
> library(dplyr)
> dplyr::bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
> would work, but there were problems.
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> spreads out the data frames converting the data frames from long to wide, but it messes up the names. So one question I still have, is how can I programmatically change all of the names?
> After this initial step, the first data frame's names might be derived from
> c("George", "Washington")
> and the second data frame's names might be derived from
> c("John", "Adams", "Thomas", "Jefferson")
> What I want to change to the names to:
> c("First1", "Second1")
> and
> c("First1", "Second1", "First2", "Second2")
> I believe that will enable me to then go back and use bind_rows and complete that method of solution:
> Step 1: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> Step 2: Clean up the names
> Step 3: bind_rows
> Immediately below is hopefully a clear and precise statement of the problem and the proposed solution path. Then there are the various solutions.
> # Starting list of data frames
> employees4List = list(data.frame(first1 = "Al", second1 = "Jones"),
> ???????????????????? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> ???????????????????? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", "Smith", "Adams")),
> ???????????????????? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> employees4List
>
>
> # Intermediate step that messes up the names but successfully converts from long to wide
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> # The intermediate list should likely look like this listFinal
> df1 = data.frame(First1 = "Al", Second1 = "Jones", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> df2 = data.frame(First1 = "Al2", Second1 = "Jones", First2 = "Barb", Second2 = "Smith",
> ???????????????? First3 = NA, Second3 = NA, First4 = NA, Second4 = NA)
>
> df3 = data.frame(First1 = "Al3", Second1 = "Jones", First2 = "Barbara", Second2 = "Smith",
> ???????????????? First3 = "Carol", Second3 = "Adams", First4 = NA, Second4 = NA)
> df4 = data.frame(First1 = "Al", Second1 = "Jones2", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> listFinal = list(df1, df2, df3, df4)
> listFinal
>
> # Requested data frame (except that the columns are not just character but some are factor or even logical)
> dplyr::bind_rows(listFinal)
> Sarah Goslee solved the problem using base R.
> Given
> employees4List = list(
> ? data.frame(first1 = ("Al"), second1 = "Jones"),
> ? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones2", "Smith")),
> ? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones3",
> ??????????????????????????????????????????????????????????????? "Smith", "Adams")),
> ? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> This function produces the solution in the requested structure.
> dfbycol <- function(x) {
> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
> ? x <- do.call(rbind, x)
> ? x <- data.frame(x, stringsAsFactors=FALSE)
> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
> ? x
> }
> dfbycol(employees4List)
> Offline, Jeff Newmiller and Bert Gunter provided alternative approaches to the problem as well as other advice. Their solutions meet the "tidy" criterion.
> Bert suggested this online.
> ## list of two data frames with different column names and numbers of rows:
> zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 5:9,b = letters[11:15]))
> ## create common column names and bind them up:
> do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
> This and the next suggestion by Jeff produced useful solutions but not in the requested form.
> library(dplyr)
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First????????? Last
> George????????? Washington
> ", header=TRUE, as.is = TRUE )
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start????????????? End
> John????????????? Adams
> Thomas??????? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ????????????????? , data = DFL
> ????????????????? )
>
> DFL2 <- (? DFL1
> ??????? %>% mutate( data = lapply( data
> ????????????????????????????????? , function( DF ) {
> ????????????????????????????????????? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ????????????????????????????????????? gather( DF, ".Col", "value", -.PK )
> ??????????????????????????????????? }
> ????????????????????????????????? )
> ????????????????? )
> ??????? %>% unnest
> ??????? %>% spread( .Col, value )
> ??????? )
> DFL2
> During the discussion, useful links were recommended
> [1] https://www.jstatsoft.org/article/view/v059i10?? Hadley on tidy data
> [2] http://r4ds.had.co.nz/relational-data.html#keys? Hadley on relational data
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example? How to make a great reproducible example
> http://adv-r.had.co.nz/Functionals.html???? Improving lapply and related skills
> Thanks again to everyone!
> Ira
>
>
>
>
>    On Friday, June 29, 2018, 7:47:13 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Code below...
>
> a) Just because something can be done with dplyr does not mean that is the
> best way to do it. A solution in the hand is worth two on the Internet,
> and dplyr is not always the fastest method anyway.
>
> b) I highly recommend that you read Hadley Wickham's paper on tidy data
> [1]. Also, having a group of one or more columns at all times that
> uniquely identify where the data came from is a "key" to success [2].
>
> c) Please read and follow one of the various online documents about making
> reproducible examples in R (e.g. [3]). HTML formatting is really a pain
> (at best... at worst, it corrupts your code) on a plain-text-only list
> (you have read the Posting Guide, right?). Consider my example below as a
> model for you to follow in the future, and make sure to set your email
> program to send plain text. (Obviously your examples don't have to achieve
> success... but they should bring us up to speed with where you are having
> troubles IN R.)
>
> [1] https://www.jstatsoft.org/article/view/v059i10
> [2] http://r4ds.had.co.nz/relational-data.html#keys
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> ----
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>? ? filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>? ? intersect, setdiff, setequal, union
> library(tidyr)
>
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First? ? ? ? ? Last
> George? ? ? ? ? Washington
> ", header=TRUE, as.is = TRUE )
>
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start? ? ? ? ? ? ? End
> John? ? ? ? ? ? ? Adams
> Thomas? ? ? ? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ? ? ? ? ? ? ? ? ? , data = DFL
> ? ? ? ? ? ? ? ? ? )
>
> DFL2 <- (? DFL1
> ? ? ? ? %>% mutate( data = lapply( data
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? , function( DF ) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? gather( DF, ".Col", "value", -.PK )
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? }
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? )
> ? ? ? ? ? ? ? ? ? )
> ? ? ? ? %>% unnest
> ? ? ? ? %>% spread( .Col, value )
> ? ? ? ? )
> DFL2
> #> # A tibble: 3 x 6
> #>? .DFNames? .PK End? ? ? First? Last? ? ? Start
> #>? <chr>? ? <int> <chr>? ? <chr>? <chr>? ? ? <chr>
> #> 1 DF1? ? ? ? ? 1 <NA>? ? ? George Washington <NA>
> #> 2 DF2? ? ? ? ? 1 Adams? ? <NA>? <NA>? ? ? John
> #> 3 DF2? ? ? ? ? 2 Jefferson <NA>? <NA>? ? ? Thomas
>
> #' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
> ----
>
> On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:
>
>>
>> Sarah and David,
>>
>> Thank you for your responses.I will try and be clearer.
>>
>> Base R solution: Sarah?smethod worked perfectly
>>
>> Is there a dplyrsolution?
>>
>> START: list of dataframes
>>
>> FINISH: one data frame
>>
>> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>>
>> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>>
>> EXAMPLE: List with twodata frames
>>
>> # DF1
>>
>> First?? ???????Last
>>
>> George Washington
>>
>> ?
>>
>> # DF2
>>
>> Start????????????? End
>>
>> John?????????????? Adams
>>
>> Thomas??????? Jefferson
>>
>> ?
>>
>> # End Result. One dataframe
>>
>> First1????? Second1??????? First2?????????? Second2
>>
>> George Washington?????? NA??????????????????? NA
>>
>> John?????????????? Adams??? Thomas??????? Jefferson
>>
>> ?
>>
>> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>>
>> The suggested solution was:
>>
>> library(dplyr)
>>
>> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>>
>> ?
>>
>> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>>
>> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>>
>> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>>
>> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>>
>> Ira
>>
>>
>> ? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> It isn't super clear to me what you're after.
>>
>> Agree.
>>
>> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>>
>> library(dplyr)
>> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
>> bind_rows(newList)
>>
>> #---------
>>
>> ? first1 second1
>> 1? ? ? Al? Jones
>> 2? ? Al2? Jones
>> 3? ? Barb? Smith
>> 4? ? Al3? Jones
>> 5 Barbara? Smith
>> 6? Carol? Adams
>> 7? ? ? Al? Jones2
>>
>> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>>
>> --
>> David.
>>> Is this what you intend?
>>>
>>>> dfbycol(employees4BList)
>>> ? first1 last1 first2 last2 first3 last3
>>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>>> 3? ? Al Jones? Barb Smith? Carol Adams
>>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>>
>>>> dfbycol(employees4List)
>>> ? first1? last1? first2 last2 first3 last3
>>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>>
>>>
>>> If so:
>>>
>>> employees4BList = list(
>>> data.frame(first1 = "Al", second1 = "Jones"),
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4List = list(
>>> data.frame(first1 = ("Al"), second1 = "Jones"),
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ###
>>>
>>> dfbycol <- function(x) {
>>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>>> ? x <- do.call(rbind, x)
>>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>>> ? x
>>> }
>>>
>>> ###
>>>
>>> dfbycol(employees4BList)
>>>
>>> dfbycol(employees4List)
>>>
>>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>>> <r-help at r-project.org> wrote:
>>>> I have a list of data frames which I would like to combine into one data
>>>> frame doing something like rbind. I wish to combine in column order and
>>>> not by names. However, there are issues.
>>>>
>>>> The number of columns is not the same for each data frame. This is an
>>>> intermediate step to a problem and the number of columns could be
>>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>>> is that the names of the columns produced by the first step are garbage.
>>>>
>>>> Below is a method that I obtained by asking a question on stack
>>>> overflow. Unfortunately, my example was not general enough. The code
>>>> below works for the simple case where the names of the people are
>>>> consistent. It does not work when the names are realistically not the same.
>>>>
>>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>>
>>>>
>>>> Please note that the lapply step sets things up except for the column
>>>> name issue. If I could figure out a way to change the column names, then
>>>> the bind_rows step will, I believe, work.
>>>>
>>>> So I really have two questions. How to change all column names of all
>>>> the data frames and then how to solve the original problem.
>>>>
>>>> # The non general case works fine. It produces one data frame and I can
>>>> then change the column names to
>>>>
>>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>>
>>>> #Non general easy case
>>>>
>>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>>
>>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>>
>>>> employees4BList
>>>>
>>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> # This produces a nice list of data frames, except for the names
>>>>
>>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>>
>>>> # This list is a disaster. I am looking for a solution that works in
>>>> this case.
>>>>
>>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>>
>>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>>
>>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> Thanks.
>>>>
>>>> Ira
>>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
> /Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
> ---------------------------------------------------------------------------
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From h@@@n@d|w@n @end|ng |rom gm@||@com  Sun Jul  1 04:34:06 2018
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Sat, 30 Jun 2018 19:34:06 -0700
Subject: [R] A question on Statistics
In-Reply-To: <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
Message-ID: <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>

Christofer,
On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> You should use Stack Exchange for questions about statistics.

Specifically, https://stats.stackexchange.com/ -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Jul  1 13:31:29 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 1 Jul 2018 11:31:29 +0000
Subject: [R] parallel processing in r...
In-Reply-To: <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
Message-ID: <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear Members,
                                      Thanks for the reply..I do have another issue; I will be highly obliged if you answer it:
I tried "top" at the bash prompt, but it provides a way to measure CPU performance of the existing processes. I want to check the CPU usage of the execution of an R function. So I start R by this

$ R

and at the R prompt I type the function to be executed. But if I type "top" at the R prompt, it says object "top" not found.

So, should I change to bash prompt after running the R function? If yes, how do I do it? If not, how to use "top" inside the R prompt?

Again, I think this is an OS isuue....but I could'nt find any answer in the Internet. I am an independent researcher and I don't have personal access to experts.......this mail list is the only vent I have.......

Very many thanks for your time and effort...
Yours sincerely,
AKSHAY M KULKARNI

________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Saturday, June 30, 2018 11:46 PM
To: r-help at r-project.org; akshay kulkarni; R help Mailing list
Subject: Re: [R] parallel processing in r...

Use "top" at the bash prompt.

Read about the "mc.cores" parameter to mclapply.

Make a simplified example version of your analysis and post your question in the context of that example [1][2][3]. You will learn about the issues you are dealing with in the process of trimming your problem, and will have code you can share that demonstrates the issue without exposing private information.

Running parallel does not necessarily improve performance because other factors like task switching overhead and Inter-process-communication (data sharing) can drag it down. Read about the real benefits and drawbacks of parallelism... there are many discussions out there out there... you might start with [4].


[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

[4] https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html

On June 30, 2018 10:07:49 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>I am using mclapply to parallelize my code. I am using Red Hat Linux in
>AWS.
>
>When I use mclapply, I see no speed increase. I doubt that the Linux OS
>is allowing fewer than the maximum number of cores to mclapply ( by
>default, mclapply takes all the available cores to it).
>
>How do you check if the number of workers is less than the output given
>by detectCores(), in Linux? Is there any R function for it?
>
>I do acknowledge that help on an OS is not suitable for this mailing
>list, but even Internet could'nt help me. Therefore this mail......
>
>very many thanks for your time  and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Jul  1 14:53:36 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 18:23:36 +0530
Subject: [R] A question on Statistics
In-Reply-To: <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
 <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
Message-ID: <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>

Hi,

I could post in StackExchange for sure, however I dont think R-help posting
guide discourage asking a question about Statistics, atleast formally.

I could further clarify if my question is not elaborate enough. And many
apologies if it is very trivial - however still I am looking for 2nd
opinion on my question.

Answer to Jeff's pointer - yes my distribution is assumed to be centered at
0.

Thanks,

On Sun, Jul 1, 2018 at 8:04 AM Hasan Diwan <hasan.diwan at gmail.com> wrote:

> Christofer,
> On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > You should use Stack Exchange for questions about statistics.
>
> Specifically, https://stats.stackexchange.com/ -- H
> --
> OpenPGP:
> https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> If you wish to request my time, please do so using
> bit.ly/hd1AppointmentRequest.
> Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.
>
> Sent from my mobile device
> Envoye de mon portable
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jerem|eju@te @end|ng |rom gm@||@com  Sun Jul  1 15:32:26 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Sun, 01 Jul 2018 15:32:26 +0200
Subject: [R] running Rmpi with SGE on a cluster
Message-ID: <87y3ev3wut.fsf@gmail.com>


Hello,

I would like to know how to use Rmpi on a cluster but usually the
workflow of the cluster uses sun grid engine to launch jobs.

I found this reference on the web
http://borisv.lk.net/howtos/grid-mpi-r-howto.html.

But I could not even reproduce that example some errors with
> n.cores <- mpi.universe.size()

But regardless of this error do you have any resources on running R on a
cluster?


Best regards,

Jeremie



From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul  1 16:59:43 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 1 Jul 2018 07:59:43 -0700
Subject: [R] A question on Statistics
In-Reply-To: <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
 <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
 <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>
Message-ID: <CAGxFJbQTzKyDrACYsFfOvKM7iCe9tEEhVM8Dy7-WQ_j=QGhpXQ@mail.gmail.com>

>From the posting guide:

"*R-help* is intended to be comprehensible to people who want to use R to
solve problems but who are not necessarily interested in or knowledgeable
about programming."

This says to me that R-help is for general questions about R programming,
not statistics, though I grant you that the intersection is nonempty.
Nevertheless, purely statistical issues should be posted elsewhere, and
your query appears to be such.

However, I'll just note: what does "centered at 0" mean for an asymmetric
distribution? I think you may need to reconsider Jeff's advice.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jul 1, 2018 at 5:53 AM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I could post in StackExchange for sure, however I dont think R-help posting
> guide discourage asking a question about Statistics, atleast formally.
>
> I could further clarify if my question is not elaborate enough. And many
> apologies if it is very trivial - however still I am looking for 2nd
> opinion on my question.
>
> Answer to Jeff's pointer - yes my distribution is assumed to be centered at
> 0.
>
> Thanks,
>
> On Sun, Jul 1, 2018 at 8:04 AM Hasan Diwan <hasan.diwan at gmail.com> wrote:
>
> > Christofer,
> > On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > wrote:
> > >
> > > You should use Stack Exchange for questions about statistics.
> >
> > Specifically, https://stats.stackexchange.com/ -- H
> > --
> > OpenPGP:
> > https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
> > If you wish to request my time, please do so using
> > bit.ly/hd1AppointmentRequest.
> > Si vous voudrais faire connnaisance, allez a
> bit.ly/hd1AppointmentRequest.
> >
> > Sent from my mobile device
> > Envoye de mon portable
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Jul  1 17:14:49 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 20:44:49 +0530
Subject: [R] A question on Statistics
In-Reply-To: <CAGxFJbQTzKyDrACYsFfOvKM7iCe9tEEhVM8Dy7-WQ_j=QGhpXQ@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
 <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>
 <CAP+bYWB02KFDKNKfoyfXE5b98k-4eax==B_zk9sKtqrCyXR1aw@mail.gmail.com>
 <CA+dpOJ=qVixz1_9iPqTfVOqMnT0oo3+58hCUPYr+Y_3Y7rX1OA@mail.gmail.com>
 <CAGxFJbQTzKyDrACYsFfOvKM7iCe9tEEhVM8Dy7-WQ_j=QGhpXQ@mail.gmail.com>
Message-ID: <CA+dpOJ=a0vP1rYxt6rfYKHV-j5VqgqJ0umji08_jcCZRu2u+Dw@mail.gmail.com>

I derive posting guide from https://www.r-project.org/posting-guide.html

I am imagining a distribution where mean is zero but there are few large
observations in the positive side which are not very frequent.

On Sun, Jul 1, 2018 at 8:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> From the posting guide:
>
> "*R-help* is intended to be comprehensible to people who want to use R to
> solve problems but who are not necessarily interested in or knowledgeable
> about programming."
>
> This says to me that R-help is for general questions about R programming,
> not statistics, though I grant you that the intersection is nonempty.
> Nevertheless, purely statistical issues should be posted elsewhere, and
> your query appears to be such.
>
> However, I'll just note: what does "centered at 0" mean for an asymmetric
> distribution? I think you may need to reconsider Jeff's advice.
>
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Jul 1, 2018 at 5:53 AM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Hi,
>>
>> I could post in StackExchange for sure, however I dont think R-help
>> posting
>> guide discourage asking a question about Statistics, atleast formally.
>>
>> I could further clarify if my question is not elaborate enough. And many
>> apologies if it is very trivial - however still I am looking for 2nd
>> opinion on my question.
>>
>> Answer to Jeff's pointer - yes my distribution is assumed to be centered
>> at
>> 0.
>>
>> Thanks,
>>
>> On Sun, Jul 1, 2018 at 8:04 AM Hasan Diwan <hasan.diwan at gmail.com> wrote:
>>
>> > Christofer,
>> > On Sat, 30 Jun 2018 at 12:54, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > wrote:
>> > >
>> > > You should use Stack Exchange for questions about statistics.
>> >
>> > Specifically, https://stats.stackexchange.com/ -- H
>> > --
>> > OpenPGP:
>> > https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
>> > If you wish to request my time, please do so using
>> > bit.ly/hd1AppointmentRequest.
>> > Si vous voudrais faire connnaisance, allez a
>> bit.ly/hd1AppointmentRequest.
>> >
>> > Sent from my mobile device
>> > Envoye de mon portable
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jul  1 17:59:38 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 1 Jul 2018 08:59:38 -0700
Subject: [R] running Rmpi with SGE on a cluster
In-Reply-To: <87y3ev3wut.fsf@gmail.com>
References: <87y3ev3wut.fsf@gmail.com>
Message-ID: <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net>


> On Jul 1, 2018, at 6:32 AM, Jeremie Juste <jeremiejuste at gmail.com> wrote:
> 
> 
> Hello,
> 
> I would like to know how to use Rmpi on a cluster but usually the
> workflow of the cluster uses sun grid engine to launch jobs.
> 
> I found this reference on the web
> http://borisv.lk.net/howtos/grid-mpi-r-howto.html.
> 
> But I could not even reproduce that example some errors with
>> n.cores <- mpi.universe.size()
> 

"Some errors"? I'm not sure how you could be any more vague.


> But regardless of this error do you have any resources on running R on a
> cluster?
> 
> 
> Best regards,
> 
> Jeremie
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From beno|t@v@|||@nt @end|ng |rom no-|og@org  Sun Jul  1 14:22:57 2018
From: beno|t@v@|||@nt @end|ng |rom no-|og@org (Benoit Vaillant)
Date: Sun, 1 Jul 2018 14:22:57 +0200
Subject: [R] parallel processing in r...
In-Reply-To: <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
 <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <20180701122257.ph55k2kkabo5fp7v@auroras.fr>

Hello,

On Sun, Jul 01, 2018 at 11:31:29AM +0000, akshay kulkarni wrote:
> I tried "top" at the bash prompt, but it provides a way to measure
> CPU performance of the existing processes. I want to check the CPU
> usage of the execution of an R function.

Try to open two bash prompts, in one use R and in the other use top to
monitor what is going on.

> and at the R prompt I type the function to be executed. But if I
> type "top" at the R prompt, it says object "top" not found.

top is a shell command, no issue with R not knowing about this.

> So, should I change to bash prompt after running the R function? If
> yes, how do I do it? If not, how to use "top" inside the R prompt?

Basically, you can't.

> Again, I think this is an OS isuue....but I could'nt find any answer
> in the Internet. I am an independent researcher and I don't have
> personal access to experts.......this mail list is the only vent I
> have.......

... (many more dots) Do you think we are experts on your system?

Please do your home work and get back to us once it's done. ;-)

Cheers,

-- 
Beno?t

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 866 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180701/2f010fe0/attachment-0002.sig>

From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Jul  1 18:29:29 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 21:59:29 +0530
Subject: [R] parallel processing in r...
In-Reply-To: <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
 <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
Message-ID: <CA+dpOJ=+5cBZXYpnDHKZ7FRqqQF79dfx8ivBFUB2__2_ZpMX6A@mail.gmail.com>

Hi,

On ' how to use "top" inside the R prompt? '
you can use system('top') command.

Thanks,

On Sun, Jul 1, 2018 at 9:53 PM Benoit Vaillant <benoit.vaillant at no-log.org>
wrote:

> Hello,
>
> On Sun, Jul 01, 2018 at 11:31:29AM +0000, akshay kulkarni wrote:
> > I tried "top" at the bash prompt, but it provides a way to measure
> > CPU performance of the existing processes. I want to check the CPU
> > usage of the execution of an R function.
>
> Try to open two bash prompts, in one use R and in the other use top to
> monitor what is going on.
>
> > and at the R prompt I type the function to be executed. But if I
> > type "top" at the R prompt, it says object "top" not found.
>
> top is a shell command, no issue with R not knowing about this.
>
> > So, should I change to bash prompt after running the R function? If
> > yes, how do I do it? If not, how to use "top" inside the R prompt?
>
> Basically, you can't.
>
> > Again, I think this is an OS isuue....but I could'nt find any answer
> > in the Internet. I am an independent researcher and I don't have
> > personal access to experts.......this mail list is the only vent I
> > have.......
>
> ... (many more dots) Do you think we are experts on your system?
>
> Please do your home work and get back to us once it's done. ;-)
>
> Cheers,
>
> --
> Beno?t
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From |r@@h@renow100 @end|ng |rom y@hoo@com  Mon Jul  2 06:40:39 2018
From: |r@@h@renow100 @end|ng |rom y@hoo@com (Ira Sharenow)
Date: Mon, 2 Jul 2018 04:40:39 +0000 (UTC)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <alpine.BSF.2.00.1806301736300.71159@pedal.dcn.davis.ca.us>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>
 <1713527611.860691.1530396877620@mail.yahoo.com>
 <alpine.BSF.2.00.1806301736300.71159@pedal.dcn.davis.ca.us>
Message-ID: <1866193932.1267325.1530506439060@mail.yahoo.com>

 
My final post for thisthread!

Since I first asked myquestion on Stack Overflow, I posted all the solutions along with my timingstudy there.

https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/51129202#51129202

Thanks again toeveryone for their help.

Ira


    On Saturday, June 30, 2018, 6:11:00 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:  
 
 Your request is getting a bit complicated with so much re-hashing, but 
here are three solutions: base only, a bit of dplyr, and dplyr+tidyr:

#########
# input data
employees4List = list(data.frame(first1 = "Al", second1 = 
"Jones"),
? ? ? ? ? ? ? ? ? ? ? data.frame(first2 = c("Al2", "Barb"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? second2 = c("Jones", "Smith")),
? ? ? ? ? ? ? ? ? ? ? data.frame(first3 = c("Al3", "Barbara", 
"Carol"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? second3 = c("Jones", "Smith", 
"Adams")),
? ? ? ? ? ? ? ? ? ? ? data.frame(first4 = ("Al"), second4 = 
"Jones2"))
employees4List
#> [[1]]
#>? first1 second1
#> 1? ? Al? Jones
#>
#> [[2]]
#>? first2 second2
#> 1? ? Al2? Jones
#> 2? Barb? Smith
#>
#> [[3]]
#>? ? first3 second3
#> 1? ? Al3? Jones
#> 2 Barbara? Smith
#> 3? Carol? Adams
#>
#> [[4]]
#>? first4 second4
#> 1? ? Al? Jones2

# expected output
df1 = data.frame(First1 = "Al", Second1 = "Jones",
? ? ? ? ? ? ? ? ? First2 = NA, Second2 = NA,
? ? ? ? ? ? ? ? ? First3 = NA, Second3 = NA,
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
df2 = data.frame(First1 = "Al2", Second1 = "Jones",
? ? ? ? ? ? ? ? ? First2 = "Barb", Second2 = "Smith",
? ? ? ? ? ? ? ? ? First3 = NA, Second3 = NA,
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
df3 = data.frame(First1 = "Al3", Second1 = "Jones",
? ? ? ? ? ? ? ? ? First2 = "Barbara", Second2 = "Smith",
? ? ? ? ? ? ? ? ? First3 = "Carol", Second3 = "Adams",
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
df4 = data.frame(First1 = "Al", Second1 = "Jones2",
? ? ? ? ? ? ? ? ? First2 = NA, Second2 = NA,
? ? ? ? ? ? ? ? ? First3 = NA, Second3 = NA,
? ? ? ? ? ? ? ? ? First4 = NA, Second4 = NA)
listFinal = list(df1, df2, df3, df4)
listFinal
#> [[1]]
#>? First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al? Jones? ? NA? ? ? NA? ? NA? ? ? NA? ? NA? ? ? NA
#>
#> [[2]]
#>? First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al2? Jones? Barb? Smith? ? NA? ? ? NA? ? NA? ? ? NA
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams? ? NA? ? ? NA
#>
#> [[4]]
#>? First1 Second1 First2 Second2 First3 Second3 First4 Second4
#> 1? ? Al? Jones2? ? NA? ? ? NA? ? NA? ? ? NA? ? NA? ? ? NA

myrename1 <- function( DF, m ) {
? # if a pair of columns is not present, raise an error
? stopifnot( 2 == length( DF ) )
? n <- nrow( DF )
? # use memory layout of elements of matrix
? # t() automatically converts to matrix (nrow=2)
? # matrix(,nrow=1) re-interprets the column-major output of t()
? # as a single row matrix
? result <- as.data.frame( matrix( t( DF ), nrow = 1 )
? ? ? ? ? ? ? ? ? ? ? ? ? , stringsAsFactors = FALSE
? ? ? ? ? ? ? ? ? ? ? ? ? )
? if ( n < m ) {
? ? result[ , seq( 2 * n + 1, 2 * m ) ] <- NA
? }
? setNames( result
? ? ? ? ? , sprintf( "%s%d"
? ? ? ? ? ? ? ? ? ? , c( "First", "Second" )
? ? ? ? ? ? ? ? ? ? ? , rep( seq.int( m ), each = 2 )
? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? )
}

m <- max( unlist( lapply( employees4List, nrow ) ) )
listFinal1 <- lapply( employees4List, myrename1, m = m )
listFinal1
#> [[1]]
#>? First1 Second1 First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? NA? ? ? NA? ? NA? ? ? NA
#>
#> [[2]]
#>? First1 Second1 First2 Second2 First3 Second3
#> 1? ? Al2? Jones? Barb? Smith? ? NA? ? ? NA
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams
#>
#> [[4]]
#>? First1 Second1 First2 Second2 First3 Second3
#> 1? ? Al? Jones2? ? NA? ? ? NA? ? NA? ? ? NA
result1 <- do.call( rbind, listFinal1 )
result1
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? <NA>? ? <NA>? <NA>? ? <NA>
#> 2? ? Al2? Jones? ? Barb? Smith? <NA>? ? <NA>
#> 3? ? Al3? Jones Barbara? Smith? Carol? Adams
#> 4? ? Al? Jones2? ? <NA>? ? <NA>? <NA>? ? <NA>

myrename2 <- function( DF ) {
? # if a pair of columns is not present, raise an error
? stopifnot( 2 == length( DF ) )
? n <- nrow( DF )
? # use memory layout of elements of matrix
? # t() automatically converts to matrix (nrow=2)
? # matrix(,nrow=1) re-interprets the column-major output of t()
? # as a single row matrix
? setNames( as.data.frame( matrix( t( DF ), nrow = 1 )
? ? ? ? ? ? ? ? ? ? ? ? ? , stringsAsFactors = FALSE
? ? ? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? , sprintf( "%s%d"
? ? ? ? ? ? ? ? ? ? , c( "First", "Second" )
? ? ? ? ? ? ? ? ? ? , rep( seq.int( n ), each = 2 )
? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? )
}

listFinal2 <- lapply( employees4List, myrename2 )
listFinal2
#> [[1]]
#>? First1 Second1
#> 1? ? Al? Jones
#>
#> [[2]]
#>? First1 Second1 First2 Second2
#> 1? ? Al2? Jones? Barb? Smith
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams
#>
#> [[4]]
#>? First1 Second1
#> 1? ? Al? Jones2
result2 <- dplyr::bind_rows( listFinal2 )
result2
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? <NA>? ? <NA>? <NA>? ? <NA>
#> 2? ? Al2? Jones? ? Barb? Smith? <NA>? ? <NA>
#> 3? ? Al3? Jones Barbara? Smith? Carol? Adams
#> 4? ? Al? Jones2? ? <NA>? ? <NA>? <NA>? ? <NA>

library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>? ? filter, lag
#> The following objects are masked from 'package:base':
#>
#>? ? intersect, setdiff, setequal, union
library(tidyr)
myrename3 <- function( DF ) {
? # if a pair of columns is not present, raise an error
? stopifnot( 2 == length( DF ) )
? names( DF ) <- c( "a", "b" )
? m <- nrow( DF )
? (? DF
? %>% mutate_all( as.character )
? %>% mutate( rw = LETTERS[ seq.int( n() ) ] )
? %>% gather( col, val, -rw )
? %>% tidyr::unite( "labels", rw, col, sep="" )
? %>% spread( labels, val )
? %>% setNames( sprintf( "%s%d"
? ? ? ? ? ? ? ? ? ? ? ? , c( "First", "Second" )
? ? ? ? ? ? ? ? ? ? ? ? , rep( seq.int( m ), each = 2 )
? ? ? ? ? ? ? ? ? ? ? ? )
? ? ? ? ? ? ? )
? )
}

listFinal3 <- lapply( employees4List, myrename3 )
listFinal3
#> [[1]]
#>? First1 Second1
#> 1? ? Al? Jones
#>
#> [[2]]
#>? First1 Second1 First2 Second2
#> 1? ? Al2? Jones? Barb? Smith
#>
#> [[3]]
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al3? Jones Barbara? Smith? Carol? Adams
#>
#> [[4]]
#>? First1 Second1
#> 1? ? Al? Jones2
result3 <- dplyr::bind_rows( listFinal3 )
result3
#>? First1 Second1? First2 Second2 First3 Second3
#> 1? ? Al? Jones? ? <NA>? ? <NA>? <NA>? ? <NA>
#> 2? ? Al2? Jones? ? Barb? Smith? <NA>? ? <NA>
#> 3? ? Al3? Jones Barbara? Smith? Carol? Adams
#> 4? ? Al? Jones2? ? <NA>? ? <NA>? <NA>? ? <NA>

#' Created on 2018-06-30 by the [reprex 
package](http://reprex.tidyverse.org) (v0.2.0).
#########

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

> I would like to thank everyone who helped me out. I have obtained some offline help, so I would like to summarize all the information I have received.
> Before I summarize the thread, there is one loose end.
> Initially I thought
> library(dplyr)
> dplyr::bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
> would work, but there were problems.
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> spreads out the data frames converting the data frames from long to wide, but it messes up the names. So one question I still have, is how can I programmatically change all of the names?
> After this initial step, the first data frame's names might be derived from
> c("George", "Washington")
> and the second data frame's names might be derived from
> c("John", "Adams", "Thomas", "Jefferson")
> What I want to change to the names to:
> c("First1", "Second1")
> and
> c("First1", "Second1", "First2", "Second2")
> I believe that will enable me to then go back and use bind_rows and complete that method of solution:
> Step 1: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
> Step 2: Clean up the names
> Step 3: bind_rows
> Immediately below is hopefully a clear and precise statement of the problem and the proposed solution path. Then there are the various solutions.
> # Starting list of data frames
> employees4List = list(data.frame(first1 = "Al", second1 = "Jones"),
> ???????????????????? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> ???????????????????? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", "Smith", "Adams")),
> ???????????????????? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> employees4List
>
>
> # Intermediate step that messes up the names but successfully converts from long to wide
> lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> # The intermediate list should likely look like this listFinal
> df1 = data.frame(First1 = "Al", Second1 = "Jones", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> df2 = data.frame(First1 = "Al2", Second1 = "Jones", First2 = "Barb", Second2 = "Smith",
> ???????????????? First3 = NA, Second3 = NA, First4 = NA, Second4 = NA)
>
> df3 = data.frame(First1 = "Al3", Second1 = "Jones", First2 = "Barbara", Second2 = "Smith",
> ???????????????? First3 = "Carol", Second3 = "Adams", First4 = NA, Second4 = NA)
> df4 = data.frame(First1 = "Al", Second1 = "Jones2", First2 = NA, Second2 = NA, First3 = NA, Second3 = NA,
> ???????????????? First4 = NA, Second4 = NA)
> listFinal = list(df1, df2, df3, df4)
> listFinal
>
> # Requested data frame (except that the columns are not just character but some are factor or even logical)
> dplyr::bind_rows(listFinal)
> Sarah Goslee solved the problem using base R.
> Given
> employees4List = list(
> ? data.frame(first1 = ("Al"), second1 = "Jones"),
> ? data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones2", "Smith")),
> ? data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones3",
> ??????????????????????????????????????????????????????????????? "Smith", "Adams")),
> ? data.frame(first4 = ("Al"), second4 = "Jones2"))
>
> This function produces the solution in the requested structure.
> dfbycol <- function(x) {
> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
> ? x <- do.call(rbind, x)
> ? x <- data.frame(x, stringsAsFactors=FALSE)
> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
> ? x
> }
> dfbycol(employees4List)
> Offline, Jeff Newmiller and Bert Gunter provided alternative approaches to the problem as well as other advice. Their solutions meet the "tidy" criterion.
> Bert suggested this online.
> ## list of two data frames with different column names and numbers of rows:
> zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 5:9,b = letters[11:15]))
> ## create common column names and bind them up:
> do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
> This and the next suggestion by Jeff produced useful solutions but not in the requested form.
> library(dplyr)
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First????????? Last
> George????????? Washington
> ", header=TRUE, as.is = TRUE )
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start????????????? End
> John????????????? Adams
> Thomas??????? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ????????????????? , data = DFL
> ????????????????? )
>
> DFL2 <- (? DFL1
> ??????? %>% mutate( data = lapply( data
> ????????????????????????????????? , function( DF ) {
> ????????????????????????????????????? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ????????????????????????????????????? gather( DF, ".Col", "value", -.PK )
> ??????????????????????????????????? }
> ????????????????????????????????? )
> ????????????????? )
> ??????? %>% unnest
> ??????? %>% spread( .Col, value )
> ??????? )
> DFL2
> During the discussion, useful links were recommended
> [1] https://www.jstatsoft.org/article/view/v059i10?? Hadley on tidy data
> [2] http://r4ds.had.co.nz/relational-data.html#keys? Hadley on relational data
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example? How to make a great reproducible example
> http://adv-r.had.co.nz/Functionals.html???? Improving lapply and related skills
> Thanks again to everyone!
> Ira
>
>
>
>
>? ? On Friday, June 29, 2018, 7:47:13 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Code below...
>
> a) Just because something can be done with dplyr does not mean that is the
> best way to do it. A solution in the hand is worth two on the Internet,
> and dplyr is not always the fastest method anyway.
>
> b) I highly recommend that you read Hadley Wickham's paper on tidy data
> [1]. Also, having a group of one or more columns at all times that
> uniquely identify where the data came from is a "key" to success [2].
>
> c) Please read and follow one of the various online documents about making
> reproducible examples in R (e.g. [3]). HTML formatting is really a pain
> (at best... at worst, it corrupts your code) on a plain-text-only list
> (you have read the Posting Guide, right?). Consider my example below as a
> model for you to follow in the future, and make sure to set your email
> program to send plain text. (Obviously your examples don't have to achieve
> success... but they should bring us up to speed with where you are having
> troubles IN R.)
>
> [1] https://www.jstatsoft.org/article/view/v059i10
> [2] http://r4ds.had.co.nz/relational-data.html#keys
> [3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> ----
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>? ? filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>? ? intersect, setdiff, setequal, union
> library(tidyr)
>
> # note that these data frames all have character columns
> # rather than factors, due to the as.is option when the
> # data are read in.
> DF1 <- read.table( text =
> "First? ? ? ? ? Last
> George? ? ? ? ? Washington
> ", header=TRUE, as.is = TRUE )
>
> # dput looks ugly but is actually much more practical for
> # providing R data on the mailing list... here is an example
> dput( DF1 )
> #> structure(list(First = "George", Last = "Washington")
> #>, .Names = c("First",
> #> "Last"), class = "data.frame", row.names = c(NA, -1L))
>
> DF2 <- read.table( text =
> "Start? ? ? ? ? ? ? End
> John? ? ? ? ? ? ? Adams
> Thomas? ? ? ? Jefferson
> ", header = TRUE, as.is = TRUE )
>
> DFL <- list( DF1, DF2 )
>
> # DFNames is a set of unique identifiers
> DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
> ? ? ? ? ? ? ? ? ? , data = DFL
> ? ? ? ? ? ? ? ? ? )
>
> DFL2 <- (? DFL1
> ? ? ? ? %>% mutate( data = lapply( data
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? , function( DF ) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? DF[[ ".PK" ]] <- seq.int( nrow( DF ))
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? gather( DF, ".Col", "value", -.PK )
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? }
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? )
> ? ? ? ? ? ? ? ? ? )
> ? ? ? ? %>% unnest
> ? ? ? ? %>% spread( .Col, value )
> ? ? ? ? )
> DFL2
> #> # A tibble: 3 x 6
> #>? .DFNames? .PK End? ? ? First? Last? ? ? Start
> #>? <chr>? ? <int> <chr>? ? <chr>? <chr>? ? ? <chr>
> #> 1 DF1? ? ? ? ? 1 <NA>? ? ? George Washington <NA>
> #> 2 DF2? ? ? ? ? 1 Adams? ? <NA>? <NA>? ? ? John
> #> 3 DF2? ? ? ? ? 2 Jefferson <NA>? <NA>? ? ? Thomas
>
> #' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
> ----
>
> On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:
>
>>
>> Sarah and David,
>>
>> Thank you for your responses.I will try and be clearer.
>>
>> Base R solution: Sarah?smethod worked perfectly
>>
>> Is there a dplyrsolution?
>>
>> START: list of dataframes
>>
>> FINISH: one data frame
>>
>> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>>
>> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>>
>> EXAMPLE: List with twodata frames
>>
>> # DF1
>>
>> First?? ???????Last
>>
>> George Washington
>>
>> ?
>>
>> # DF2
>>
>> Start????????????? End
>>
>> John?????????????? Adams
>>
>> Thomas??????? Jefferson
>>
>> ?
>>
>> # End Result. One dataframe
>>
>> First1????? Second1??????? First2?????????? Second2
>>
>> George Washington?????? NA??????????????????? NA
>>
>> John?????????????? Adams??? Thomas??????? Jefferson
>>
>> ?
>>
>> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>>
>> The suggested solution was:
>>
>> library(dplyr)
>>
>> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>>
>> ?
>>
>> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>>
>> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>>
>> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>>
>> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>>
>> Ira
>>
>>
>> ? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> It isn't super clear to me what you're after.
>>
>> Agree.
>>
>> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>>
>> library(dplyr)
>> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
>> bind_rows(newList)
>>
>> #---------
>>
>> ? first1 second1
>> 1? ? ? Al? Jones
>> 2? ? Al2? Jones
>> 3? ? Barb? Smith
>> 4? ? Al3? Jones
>> 5 Barbara? Smith
>> 6? Carol? Adams
>> 7? ? ? Al? Jones2
>>
>> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>>
>> --
>> David.
>>> Is this what you intend?
>>>
>>>> dfbycol(employees4BList)
>>> ? first1 last1 first2 last2 first3 last3
>>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>>> 3? ? Al Jones? Barb Smith? Carol Adams
>>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>>
>>>> dfbycol(employees4List)
>>> ? first1? last1? first2 last2 first3 last3
>>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>>
>>>
>>> If so:
>>>
>>> employees4BList = list(
>>> data.frame(first1 = "Al", second1 = "Jones"),
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4List = list(
>>> data.frame(first1 = ("Al"), second1 = "Jones"),
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ###
>>>
>>> dfbycol <- function(x) {
>>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>>> ? x <- do.call(rbind, x)
>>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>>> ? x
>>> }
>>>
>>> ###
>>>
>>> dfbycol(employees4BList)
>>>
>>> dfbycol(employees4List)
>>>
>>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>>> <r-help at r-project.org> wrote:
>>>> I have a list of data frames which I would like to combine into one data
>>>> frame doing something like rbind. I wish to combine in column order and
>>>> not by names. However, there are issues.
>>>>
>>>> The number of columns is not the same for each data frame. This is an
>>>> intermediate step to a problem and the number of columns could be
>>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>>> is that the names of the columns produced by the first step are garbage.
>>>>
>>>> Below is a method that I obtained by asking a question on stack
>>>> overflow. Unfortunately, my example was not general enough. The code
>>>> below works for the simple case where the names of the people are
>>>> consistent. It does not work when the names are realistically not the same.
>>>>
>>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>>
>>>>
>>>> Please note that the lapply step sets things up except for the column
>>>> name issue. If I could figure out a way to change the column names, then
>>>> the bind_rows step will, I believe, work.
>>>>
>>>> So I really have two questions. How to change all column names of all
>>>> the data frames and then how to solve the original problem.
>>>>
>>>> # The non general case works fine. It produces one data frame and I can
>>>> then change the column names to
>>>>
>>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>>
>>>> #Non general easy case
>>>>
>>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>>
>>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>>
>>>> employees4BList
>>>>
>>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> # This produces a nice list of data frames, except for the names
>>>>
>>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>>
>>>> # This list is a disaster. I am looking for a solution that works in
>>>> this case.
>>>>
>>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>>
>>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>>
>>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>>> "Smith", "Adams")),
>>>>
>>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>>
>>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>>
>>>> Thanks.
>>>>
>>>> Ira
>>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>>
>>
>>
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
> /Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
> ---------------------------------------------------------------------------
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------  
	[[alternative HTML version deleted]]



From |or|@@bennett @end|ng |rom |u-ber||n@de  Mon Jul  2 07:54:33 2018
From: |or|@@bennett @end|ng |rom |u-ber||n@de (Loris Bennett)
Date: Mon, 02 Jul 2018 07:54:33 +0200
Subject: [R] running Rmpi with SGE on a cluster
In-Reply-To: <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net> (David
 Winsemius's message of "Sun, 1 Jul 2018 08:59:38 -0700")
References: <87y3ev3wut.fsf@gmail.com>
 <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net>
Message-ID: <87efgmb2sm.fsf@hornfels.zedat.fu-berlin.de>

David Winsemius <dwinsemius at comcast.net> writes:

>> On Jul 1, 2018, at 6:32 AM, Jeremie Juste <jeremiejuste at gmail.com> wrote:
>> 
>> 
>> Hello,
>> 
>> I would like to know how to use Rmpi on a cluster but usually the
>> workflow of the cluster uses sun grid engine to launch jobs.
>> 
>> I found this reference on the web
>> http://borisv.lk.net/howtos/grid-mpi-r-howto.html.
>> 
>> But I could not even reproduce that example some errors with
>>> n.cores <- mpi.universe.size()
>> 
>
> "Some errors"? I'm not sure how you could be any more vague.
>
>
>> But regardless of this error do you have any resources on running R on a
>> cluster?

In keeping with the vagueness of the posting, I can contribute my
experience that installing Rmpi on a cluster is in general not trivial.
You potentially have to ensure that your are using the correct
combination of compiler and MPI implementation to build the packages and
then ensure that the environment is correspondingly set up for the jobs
you submit to the cluster.

I would maintain that installing Rmpi should normally be done by the
cluster administrator and the he/she should then be able to provide the
users with the information about how to use it.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de



From jerem|eju@te @end|ng |rom gm@||@com  Mon Jul  2 08:28:43 2018
From: jerem|eju@te @end|ng |rom gm@||@com (=?UTF-8?B?SsOpcsOpbWllIEp1c3Rl?=)
Date: Mon, 2 Jul 2018 08:28:43 +0200
Subject: [R] running Rmpi with SGE on a cluster
In-Reply-To: <87efgmb2sm.fsf@hornfels.zedat.fu-berlin.de>
References: <87y3ev3wut.fsf@gmail.com>
 <34DA5D7C-02EA-4559-897D-EE8CF4D45508@comcast.net>
 <87efgmb2sm.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <CAPHJcdB9qL-6MNozJCqVw0LhdeCWS+=5hQw0Vx6Jv=Q6sSS7+A@mail.gmail.com>

Hello,

Many thanks to you.

Best regards,

Jeremie



On Mon, Jul 2, 2018 at 7:54 AM, Loris Bennett <loris.bennett at fu-berlin.de>
wrote:

> David Winsemius <dwinsemius at comcast.net> writes:
>
> >> On Jul 1, 2018, at 6:32 AM, Jeremie Juste <jeremiejuste at gmail.com>
> wrote:
> >>
> >>
> >> Hello,
> >>
> >> I would like to know how to use Rmpi on a cluster but usually the
> >> workflow of the cluster uses sun grid engine to launch jobs.
> >>
> >> I found this reference on the web
> >> http://borisv.lk.net/howtos/grid-mpi-r-howto.html.
> >>
> >> But I could not even reproduce that example some errors with
> >>> n.cores <- mpi.universe.size()
> >>
> >
> > "Some errors"? I'm not sure how you could be any more vague.
> >
> >
> >> But regardless of this error do you have any resources on running R on a
> >> cluster?
>
> In keeping with the vagueness of the posting, I can contribute my
> experience that installing Rmpi on a cluster is in general not trivial.
> You potentially have to ensure that your are using the correct
> combination of compiler and MPI implementation to build the packages and
> then ensure that the environment is correspondingly set up for the jobs
> you submit to the cluster.
>
> I would maintain that installing Rmpi should normally be done by the
> cluster administrator and the he/she should then be able to provide the
> users with the information about how to use it.
>
> Cheers,
>
> Loris
>
> --
> Dr. Loris Bennett (Mr.)
> ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de
>



-- 
J?r?mie Juste

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Mon Jul  2 10:57:32 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Mon, 2 Jul 2018 08:57:32 +0000
Subject: [R] parallel processing in r...
In-Reply-To: <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
 <SL2P216MB00914690563B2C98F6936699C84C0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <20180701122257.ph55k2kkabo5fp7v@auroras.fr>
Message-ID: <SL2P216MB00916EE4F42FAEC790A22D04C8430@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear Benoit,
                       Amazing! I did my home work and found out that only two out of eight processors is being utilized by mclapply.

I am using general purpose t2 instances in AWS, with Linux AMI(Red Hat).

How do I make RHEL  utilize all the processors in my linux instance? Should I use the "configure" command in Linux? Is there any specific command in AWS linux instances? Or just setting the mc.cores argument of mclapply to 8(there are 8 cores in my linux instance) work?

If the answer is somewhat involved, please refer  some online resources....

Very many thanks for your time and effort....
Yours sincerely
AKSHAY M KULKARNI
________________________________
From: Benoit Vaillant <benoit.vaillant at no-log.org>
Sent: Sunday, July 1, 2018 5:52 PM
To: akshay kulkarni
Cc: R help Mailing list
Subject: Re: [R] parallel processing in r...

Hello,

On Sun, Jul 01, 2018 at 11:31:29AM +0000, akshay kulkarni wrote:
> I tried "top" at the bash prompt, but it provides a way to measure
> CPU performance of the existing processes. I want to check the CPU
> usage of the execution of an R function.

Try to open two bash prompts, in one use R and in the other use top to
monitor what is going on.

> and at the R prompt I type the function to be executed. But if I
> type "top" at the R prompt, it says object "top" not found.

top is a shell command, no issue with R not knowing about this.

> So, should I change to bash prompt after running the R function? If
> yes, how do I do it? If not, how to use "top" inside the R prompt?

Basically, you can't.

> Again, I think this is an OS isuue....but I could'nt find any answer
> in the Internet. I am an independent researcher and I don't have
> personal access to experts.......this mail list is the only vent I
> have.......

... (many more dots) Do you think we are experts on your system?

Please do your home work and get back to us once it's done. ;-)

Cheers,

--
Beno?t

	[[alternative HTML version deleted]]



From |d1083-r @end|ng |rom y@hoo@com  Mon Jul  2 11:27:16 2018
From: |d1083-r @end|ng |rom y@hoo@com (=?UTF-8?Q?J=C3=A9r=C3=B4me_Fran=C3=A7ois?=)
Date: Mon, 2 Jul 2018 09:27:16 +0000 (UTC)
Subject: [R] [FORGED]  Plot multiple time series on a seasonal plot
In-Reply-To: <79cffece-fbfa-bedf-b3e0-73f230dccd3f@auckland.ac.nz>
References: <615332437.512512.1530279679993.ref@mail.yahoo.com>
 <615332437.512512.1530279679993@mail.yahoo.com>
 <79cffece-fbfa-bedf-b3e0-73f230dccd3f@auckland.ac.nz>
Message-ID: <1241144103.2150790.1530523636274@mail.yahoo.com>

Ron,

Many thanks for your help! This solution meets perfectly my needs. I just had to set ylim 
to make the axes match.

Best wishes,

J?r?me

________________________________
De : Rolf Turner <r.turner at auckland.ac.nz>
? : J?r?me Fran?ois <ld1083-r at yahoo.com> 
Cc : "r-help at R-project.org" <r-help at R-project.org>; Rob.Hyndman at monash.edu
Envoy? le : Samedi 30 juin 2018 0h56
Objet : Re: [FORGED] [R] Plot multiple time series on a seasonal plot



On 30/06/18 01:41, J?r?me Fran?ois via R-help wrote:
> Dear members,
> 
> I would like to plot a second time series (a forecast) to a seasonal plot made with function seasonplot() from the package forecast.
> 
> 
> Here is a reproducible example:
> ts1 <- structure(c(112035, 111182, 111015, 109331, 107525, 107749, 111435,
> 111629, 112462, 112256, 109496, 107917, 108221, 107463, 105960,
> 103883, 101038, 100056, 101628, 102973, 103371, 102463, 100774,
> 100718, 100471, 99828, 99365, 98521, 95695, 96443, 96287, 97525,
> 98293, 98014, 96658, 96736, 96089, 95337, 95382, 92748, 91448,
> 91560, 92996, 94046, 94128, 93888, 93888, 91091, 91877, 91681,
> 91045, 89367, 87912), .Tsp = c(2014, 2018.33333333333, 12), class = "ts")
> 
> ts2 <- structure(c(87867.2152330971, 89713.0862474283, 89600.565347383,
> 91066.3196835822, 90523.1926861474, 89322.8025396445, 88771.5545520503,
> 89247.0913151542, 88803.5578121458, 88060.0948570082, 87015.6578227365,
> 85785.4121532206), .Tsp = c(2018.41666666667, 2019.33333333333,
> 12), class = "ts")
> 
> 
> library(forecast)seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE)
> 
> 
> How can I add ts2 to the seasonal plot? I would like it to be distinguishable from ts1 (e.g. different color).
> 
> lines(ts2) doesn't work.
> Thank you.


I don't know anything about forecast/seasonplot.  However my experience 
is that par(new=TRUE) usually rescues one in situations like this.

It's a bit shaganappi, but ...


seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE,
            main="Whatever")
OP <- par(new=TRUE,xaxt="n",yaxt="n")
seasonplot(ts2, col="red",main="")
par(OP)

seems to work.

It would be nice to have an "add=" argument (defaulting to FALSE, of 
course) to seasonplot().

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From |or|@@bennett @end|ng |rom |u-ber||n@de  Mon Jul  2 14:28:31 2018
From: |or|@@bennett @end|ng |rom |u-ber||n@de (Loris Bennett)
Date: Mon, 02 Jul 2018 14:28:31 +0200
Subject: [R] doMPI: script hangs on closeCluster
Message-ID: <87r2klrfdc.fsf@hornfels.zedat.fu-berlin.de>

Hi,

On Linux with R 3.5.1 and OpenMPI 2.1.0 I have built Rmpi and can run a
simple example just using Rmpi and printing out the rank of each worker.

However, when I try to use doMPI by running the following

  library(Rmpi)
  library(doMPI)
  cl <- startMPIcluster(count=2)
  registerDoMPI(cl)
  clusterSize(cl)
  closeCluster(cl)
  mpi.quit()

with

  mpirun -np 1 --mca mpi_warn_on_fork 0 R --no-save -f mwe.r

I get the following output

  > library("Rmpi")
  > library(doMPI)
  Loading required package: foreach
  Loading required package: iterators
  > cl <- startMPIcluster(count=2)
  	2 slaves are spawned successfully. 0 failed.
  > registerDoMPI(cl)
  > clusterSize(cl)
  [1] 2
  > closeCluster(cl)

but the program hangs and I have to end it with Ctl-C.

Can anyone shed any light on what might be wrong?

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de



From tr@xp|@yer @end|ng |rom gm@||@com  Mon Jul  2 14:52:37 2018
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Mon, 2 Jul 2018 14:52:37 +0200
Subject: [R] Regexp bug or misunderstanding
Message-ID: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>

Hi,

   Have I found a bug in R? Or misunderstood something about grep() ?

   Case 1 gives the expected output
   Case 2 does not gives the expected output.
   I expected integer(0) also for this case.

case 1:
grep("[:digit:]", "**ABAAbabaabackabaloneaban")
integer(0)

case 2:
grep("[:digit:]", "**ABAAbabaabackabaloneaband")
[1] 1

Regards
Martin



From |@t@z@hn @end|ng |rom gm@||@com  Mon Jul  2 14:59:45 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Mon, 2 Jul 2018 08:59:45 -0400
Subject: [R] Regexp bug or misunderstanding
In-Reply-To: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
References: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
Message-ID: <CA+vqiLEdX-NcnXDEx7LJkC9iQBC+TyfgHL24aSmEc0n9V3zgyg@mail.gmail.com>

I think you want "[[:digit:]]" instead of "[:digit:]"

--Ista

On Mon, Jul 2, 2018 at 8:52 AM, Martin M?ller Skarbiniks Pedersen
<traxplayer at gmail.com> wrote:
> Hi,
>
>    Have I found a bug in R? Or misunderstood something about grep() ?
>
>    Case 1 gives the expected output
>    Case 2 does not gives the expected output.
>    I expected integer(0) also for this case.
>
> case 1:
> grep("[:digit:]", "**ABAAbabaabackabaloneaban")
> integer(0)
>
> case 2:
> grep("[:digit:]", "**ABAAbabaabackabaloneaband")
> [1] 1
>
> Regards
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From toth@dene@ @end|ng |rom kogentum@hu  Mon Jul  2 15:03:47 2018
From: toth@dene@ @end|ng |rom kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Mon, 2 Jul 2018 15:03:47 +0200
Subject: [R] Regexp bug or misunderstanding
In-Reply-To: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
References: <CAGAA5bcV3PydoVJ=gaQJtP4zkscsnJj0US7d5atjF2YW+UTTew@mail.gmail.com>
Message-ID: <eded279a-28f7-588b-8e43-5c10a8d28a68@kogentum.hu>

Hi Martin,

I assume you want to check whether a particular character string 
contains a digit. In this case you should use the following pattern: 
"[[:digit:]]" instead of "[:digit:]".

 From ?regex:
"A character class is a list of characters enclosed between [ and ] 
which matches any single character in that list; unless the first 
character of the list is the caret ^, when it matches any character not 
in the list. ... Certain named classes of characters are predefined... 
For example, [[:alnum:]] means [0-9A-Za-z]"

So if you use simply "[:digit:]" as a pattern, it means: a character 
string which contains any of the following characters: ':', 'd', 'i', 
'g', 't'. Your second test case contains 'd', whereas the first case 
contains neither of the above characters.

HTH,
Denes



On 07/02/2018 02:52 PM, Martin M?ller Skarbiniks Pedersen wrote:
> Hi,
> 
>     Have I found a bug in R? Or misunderstood something about grep() ?
> 
>     Case 1 gives the expected output
>     Case 2 does not gives the expected output.
>     I expected integer(0) also for this case.
> 
> case 1:
> grep("[:digit:]", "**ABAAbabaabackabaloneaban")
> integer(0)
> 
> case 2:
> grep("[:digit:]", "**ABAAbabaabackabaloneaband")
> [1] 1
> 
> Regards
> Martin
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From morku@ @end|ng |rom protonm@||@com  Mon Jul  2 14:02:04 2018
From: morku@ @end|ng |rom protonm@||@com (Morkus)
Date: Mon, 02 Jul 2018 08:02:04 -0400
Subject: [R] R maintains old values
Message-ID: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>

Hello,

I have a strange side-effect from executing R-scripts using R and RServe.

I am executing an R-Script from a Java file using RServe in R. I also have RStudio installed, but it's not running at the time. The R-script reads a CSV file and does various statistical things. RServe enables me to run each line of the R script using "eval()" line by line.

All this works fine for a correctly-formatted CSV file. It's great.

But, if the CSV file isn't correctly formatted, AND the last CSV file did correctly get run, then, with the incorrect CSV as input, the output is what ran last time. Somehow, the last correct run is persisted and returned if there is some problem with the current CSV input.

This data persistence is maintained across reboots.

I'm thus baffled how R is maintaining these old values, but more to the point, I need to know how to clear these old values so if the CSV input is incorrect, I get nothing back, not the old CSV values from a correctly formatted file.

Hope this description is clear.

Thanks in advance to all.

- M

Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted email.
	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Mon Jul  2 16:32:05 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 2 Jul 2018 07:32:05 -0700
Subject: [R] R maintains old values
In-Reply-To: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
Message-ID: <CAF8bMcY_HtHeAWw2jZMvzb6nP2FaJweP8+Fixda+-n-5KgYddw@mail.gmail.com>

Do you have a ".RData" file in your home directory or the current working
directory?   If so, R will load it at startup.  It can be made by you
answering 'yes' to the 'Save workspace image?' question when you quit R.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jul 2, 2018 at 5:02 AM, Morkus via R-help <r-help at r-project.org>
wrote:

> Hello,
>
> I have a strange side-effect from executing R-scripts using R and RServe.
>
> I am executing an R-Script from a Java file using RServe in R. I also have
> RStudio installed, but it's not running at the time. The R-script reads a
> CSV file and does various statistical things. RServe enables me to run each
> line of the R script using "eval()" line by line.
>
> All this works fine for a correctly-formatted CSV file. It's great.
>
> But, if the CSV file isn't correctly formatted, AND the last CSV file did
> correctly get run, then, with the incorrect CSV as input, the output is
> what ran last time. Somehow, the last correct run is persisted and returned
> if there is some problem with the current CSV input.
>
> This data persistence is maintained across reboots.
>
> I'm thus baffled how R is maintaining these old values, but more to the
> point, I need to know how to clear these old values so if the CSV input is
> incorrect, I get nothing back, not the old CSV values from a correctly
> formatted file.
>
> Hope this description is clear.
>
> Thanks in advance to all.
>
> - M
>
> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> email.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Mon Jul  2 16:34:13 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 2 Jul 2018 14:34:13 +0000
Subject: [R] R maintains old values
In-Reply-To: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
Message-ID: <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>

Hi

Without code it is just fishing in murky waters. Could the problem you face be that in each run you assingn the result to some object and if the CSV is wrong your code fails but the object from previous run persists?

If this is the case just initialize your objects in the beginning (e.g. make them NULL at the beginning) and only if code delivers result the value of the result is returned otherwise NULL is returned.

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus via R-
> help
> Sent: Monday, July 2, 2018 2:02 PM
> To: r-help at r-project.org
> Subject: [R] R maintains old values
> 
> Hello,
> 
> I have a strange side-effect from executing R-scripts using R and RServe.
> 
> I am executing an R-Script from a Java file using RServe in R. I also have RStudio
> installed, but it's not running at the time. The R-script reads a CSV file and does
> various statistical things. RServe enables me to run each line of the R script
> using "eval()" line by line.
> 
> All this works fine for a correctly-formatted CSV file. It's great.
> 
> But, if the CSV file isn't correctly formatted, AND the last CSV file did correctly
> get run, then, with the incorrect CSV as input, the output is what ran last time.
> Somehow, the last correct run is persisted and returned if there is some
> problem with the current CSV input.
> 
> This data persistence is maintained across reboots.
> 
> I'm thus baffled how R is maintaining these old values, but more to the point, I
> need to know how to clear these old values so if the CSV input is incorrect, I get
> nothing back, not the old CSV values from a correctly formatted file.
> 
> Hope this description is clear.
> 
> Thanks in advance to all.
> 
> - M
> 
> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted email.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From er|cjberger @end|ng |rom gm@||@com  Mon Jul  2 16:47:24 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 2 Jul 2018 17:47:24 +0300
Subject: [R] R maintains old values
In-Reply-To: <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>

If you want a "fresh" R session when you start to run the script you could
consider putting as the first line

rm(list=ls())

This will remove objects from your environment (variables, functions, ..)

HTH,
Eric


On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Without code it is just fishing in murky waters. Could the problem you
> face be that in each run you assingn the result to some object and if the
> CSV is wrong your code fails but the object from previous run persists?
>
> If this is the case just initialize your objects in the beginning (e.g.
> make them NULL at the beginning) and only if code delivers result the value
> of the result is returned otherwise NULL is returned.
>
> Cheers
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner's personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
> via R-
> > help
> > Sent: Monday, July 2, 2018 2:02 PM
> > To: r-help at r-project.org
> > Subject: [R] R maintains old values
> >
> > Hello,
> >
> > I have a strange side-effect from executing R-scripts using R and RServe.
> >
> > I am executing an R-Script from a Java file using RServe in R. I also
> have RStudio
> > installed, but it's not running at the time. The R-script reads a CSV
> file and does
> > various statistical things. RServe enables me to run each line of the R
> script
> > using "eval()" line by line.
> >
> > All this works fine for a correctly-formatted CSV file. It's great.
> >
> > But, if the CSV file isn't correctly formatted, AND the last CSV file
> did correctly
> > get run, then, with the incorrect CSV as input, the output is what ran
> last time.
> > Somehow, the last correct run is persisted and returned if there is some
> > problem with the current CSV input.
> >
> > This data persistence is maintained across reboots.
> >
> > I'm thus baffled how R is maintaining these old values, but more to the
> point, I
> > need to know how to clear these old values so if the CSV input is
> incorrect, I get
> > nothing back, not the old CSV values from a correctly formatted file.
> >
> > Hope this description is clear.
> >
> > Thanks in advance to all.
> >
> > - M
> >
> > Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> email.
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul  2 17:11:07 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 2 Jul 2018 08:11:07 -0700
Subject: [R] R maintains old values
In-Reply-To: <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
Message-ID: <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>

... or perhaps

rm( list = ls(all = TRUE))
## see ?ls  for details.

However, see ?Startup for how to start a R in a "clean" environment, e.g.
with the --no-restore option.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:

> If you want a "fresh" R session when you start to run the script you could
> consider putting as the first line
>
> rm(list=ls())
>
> This will remove objects from your environment (variables, functions, ..)
>
> HTH,
> Eric
>
>
> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > Hi
> >
> > Without code it is just fishing in murky waters. Could the problem you
> > face be that in each run you assingn the result to some object and if the
> > CSV is wrong your code fails but the object from previous run persists?
> >
> > If this is the case just initialize your objects in the beginning (e.g.
> > make them NULL at the beginning) and only if code delivers result the
> value
> > of the result is returned otherwise NULL is returned.
> >
> > Cheers
> > Petr
> >
> > Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> > partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> > zasady-ochrany-osobnich-udaju/ | Information about processing and
> > protection of business partner's personal data are available on website:
> > https://www.precheza.cz/en/personal-data-protection-principles/
> > D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> > d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> > odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> > documents attached to it may be confidential and are subject to the
> legally
> > binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
> >
> > > -----Original Message-----
> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
> > via R-
> > > help
> > > Sent: Monday, July 2, 2018 2:02 PM
> > > To: r-help at r-project.org
> > > Subject: [R] R maintains old values
> > >
> > > Hello,
> > >
> > > I have a strange side-effect from executing R-scripts using R and
> RServe.
> > >
> > > I am executing an R-Script from a Java file using RServe in R. I also
> > have RStudio
> > > installed, but it's not running at the time. The R-script reads a CSV
> > file and does
> > > various statistical things. RServe enables me to run each line of the R
> > script
> > > using "eval()" line by line.
> > >
> > > All this works fine for a correctly-formatted CSV file. It's great.
> > >
> > > But, if the CSV file isn't correctly formatted, AND the last CSV file
> > did correctly
> > > get run, then, with the incorrect CSV as input, the output is what ran
> > last time.
> > > Somehow, the last correct run is persisted and returned if there is
> some
> > > problem with the current CSV input.
> > >
> > > This data persistence is maintained across reboots.
> > >
> > > I'm thus baffled how R is maintaining these old values, but more to the
> > point, I
> > > need to know how to clear these old values so if the CSV input is
> > incorrect, I get
> > > nothing back, not the old CSV values from a correctly formatted file.
> > >
> > > Hope this description is clear.
> > >
> > > Thanks in advance to all.
> > >
> > > - M
> > >
> > > Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
> > email.
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Jul  2 22:22:39 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 2 Jul 2018 15:22:39 -0500
Subject: [R] Extracting the MAPE value from a fitted Time Series Model
Message-ID: <CAMOcQfPX9bKFMfxs5STZ7EKT3D1LymZt9HZmYLtR4k4f1La4Qg@mail.gmail.com>

Dear friends,

I want to extract the MAPE value from a fitted time series model. This is
what I have:

> str(TransitSpline)
List of 12
 $ method               : chr "Cubic Smoothing Spline"
 $ level                : num [1:2] 80 95
 $ x                    : Time-Series [1:385] from 1 to 385: 77 75 85 74 73
96 82 90 91 81 ...
 $ series               : chr "data$Transits"
 $ mean                 : Time-Series [1:10, 1] from 386 to 395: 186 178
170 163 155 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr "Series 1"
 $ upper                : Time-Series [1:10, 1:2] from 386 to 395: 202 199
197 197 197 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr [1:2] "Series 1" "Series 2"
 $ lower                : Time-Series [1:10, 1:2] from 386 to 395: 171 158
144 129 113 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr [1:2] "Series 1" "Series 2"
 $ model                :List of 2
  ..$ beta: num 6.15
  ..$ call: language splinef(y = data$Transits)
 $ fitted               : Time-Series [1:385] from 1 to 385: 76.1 77.3 78.5
80.1 82.2 ...
 $ residuals            : Time-Series [1:385] from 1 to 385: NA -1.3 9.49
-8.64 -4.34 ...
 $ standardizedresiduals: Time-Series [1:385] from 1 to 385: NA -0.875
6.517 -5.586 -2.736 ...
 $ onestepf             : Time-Series [1:385] from 1 to 385: NA 76.3 75.5
82.6 77.3 ...
 - attr(*, "class")= chr [1:2] "splineforecast" "forecast"


> str(summary(TransitSpline))
#Here I want to get the value for the MAPE measure
Forecast method: Cubic Smoothing Spline

Model Information:
$`beta`
[1] 6.149167

$call
splinef(y = data$Transits)


Error measures:
                      ME     RMSE      MAE        MPE     MAPE     MASE
   ACF1
Training set -0.07776434 12.10204 9.003675 -0.2408687 5.377131 0.930913
-0.2766975

Forecasts:
    Point Forecast     Lo 80    Hi 80      Lo 95    Hi 95
386       186.0153 170.52426 201.5064 162.323777 209.7069
387       178.2220 157.87687 198.5671 147.106804 209.3372
388       170.4287 143.80863 197.0487 129.716832 211.1405
389       162.6353 128.61257 196.6581 110.602006 214.6687
390       154.8420 112.52646 197.1576  90.125956 219.5581
391       147.0487  95.66491 198.4324  68.463984 225.6334
392       139.2553  78.10706 200.4036  45.737114 232.7736
393       131.4620  59.92462 202.9994  22.055013 240.8690
394       123.6687  41.14798 206.1894  -2.535833 249.8732
395       115.8753  21.82457 209.9261 -27.962900 259.7136
'data.frame':   10 obs. of  5 variables:
 $ Point Forecast: num  186 178 170 163 155 ...
 $ Lo 80         : num  171 158 144 129 113 ...
 $ Hi 80         : num  202 199 197 197 197 ...
 $ Lo 95         : num  162.3 147.1 129.7 110.6 90.1 ...
 $ Hi 95         : num  210 209 211 215 220 ...

any idea on how to accomplish this?

Best regards,

Paul

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  2 22:40:27 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 02 Jul 2018 13:40:27 -0700
Subject: [R] Extracting the MAPE value from a fitted Time Series Model
In-Reply-To: <CAMOcQfPX9bKFMfxs5STZ7EKT3D1LymZt9HZmYLtR4k4f1La4Qg@mail.gmail.com>
References: <CAMOcQfPX9bKFMfxs5STZ7EKT3D1LymZt9HZmYLtR4k4f1La4Qg@mail.gmail.com>
Message-ID: <E44D47B3-F866-4E3C-BBAE-76B457783DB0@dcn.davis.ca.us>

Google offers [1], which probably seems like a vague response but your question omitted a reproducible example and is contaminated by posting in HTML (read the Posting Guide).

[1] https://www.rdocumentation.org/packages/MLmetrics/versions/1.1.1/topics/MAPE

On July 2, 2018 1:22:39 PM PDT, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear friends,
>
>I want to extract the MAPE value from a fitted time series model. This
>is
>what I have:
>
>> str(TransitSpline)
>List of 12
> $ method               : chr "Cubic Smoothing Spline"
> $ level                : num [1:2] 80 95
>$ x                    : Time-Series [1:385] from 1 to 385: 77 75 85 74
>73
>96 82 90 91 81 ...
> $ series               : chr "data$Transits"
>$ mean                 : Time-Series [1:10, 1] from 386 to 395: 186 178
>170 163 155 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
>  .. ..$ : chr "Series 1"
>$ upper                : Time-Series [1:10, 1:2] from 386 to 395: 202
>199
>197 197 197 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
>  .. ..$ : chr [1:2] "Series 1" "Series 2"
>$ lower                : Time-Series [1:10, 1:2] from 386 to 395: 171
>158
>144 129 113 ...
>  ..- attr(*, "dimnames")=List of 2
>  .. ..$ : NULL
>  .. ..$ : chr [1:2] "Series 1" "Series 2"
> $ model                :List of 2
>  ..$ beta: num 6.15
>  ..$ call: language splinef(y = data$Transits)
>$ fitted               : Time-Series [1:385] from 1 to 385: 76.1 77.3
>78.5
>80.1 82.2 ...
>$ residuals            : Time-Series [1:385] from 1 to 385: NA -1.3
>9.49
>-8.64 -4.34 ...
> $ standardizedresiduals: Time-Series [1:385] from 1 to 385: NA -0.875
>6.517 -5.586 -2.736 ...
>$ onestepf             : Time-Series [1:385] from 1 to 385: NA 76.3
>75.5
>82.6 77.3 ...
> - attr(*, "class")= chr [1:2] "splineforecast" "forecast"
>
>
>> str(summary(TransitSpline))
>#Here I want to get the value for the MAPE measure
>Forecast method: Cubic Smoothing Spline
>
>Model Information:
>$`beta`
>[1] 6.149167
>
>$call
>splinef(y = data$Transits)
>
>
>Error measures:
>                      ME     RMSE      MAE        MPE     MAPE     MASE
>   ACF1
>Training set -0.07776434 12.10204 9.003675 -0.2408687 5.377131 0.930913
>-0.2766975
>
>Forecasts:
>    Point Forecast     Lo 80    Hi 80      Lo 95    Hi 95
>386       186.0153 170.52426 201.5064 162.323777 209.7069
>387       178.2220 157.87687 198.5671 147.106804 209.3372
>388       170.4287 143.80863 197.0487 129.716832 211.1405
>389       162.6353 128.61257 196.6581 110.602006 214.6687
>390       154.8420 112.52646 197.1576  90.125956 219.5581
>391       147.0487  95.66491 198.4324  68.463984 225.6334
>392       139.2553  78.10706 200.4036  45.737114 232.7736
>393       131.4620  59.92462 202.9994  22.055013 240.8690
>394       123.6687  41.14798 206.1894  -2.535833 249.8732
>395       115.8753  21.82457 209.9261 -27.962900 259.7136
>'data.frame':   10 obs. of  5 variables:
> $ Point Forecast: num  186 178 170 163 155 ...
> $ Lo 80         : num  171 158 144 129 113 ...
> $ Hi 80         : num  202 199 197 197 197 ...
> $ Lo 95         : num  162.3 147.1 129.7 110.6 90.1 ...
> $ Hi 95         : num  210 209 211 215 220 ...
>
>any idea on how to accomplish this?
>
>Best regards,
>
>Paul
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From |or|@@bennett @end|ng |rom |u-ber||n@de  Tue Jul  3 09:09:23 2018
From: |or|@@bennett @end|ng |rom |u-ber||n@de (Loris Bennett)
Date: Tue, 03 Jul 2018 09:09:23 +0200
Subject: [R] doMPI: script hangs on closeCluster
In-Reply-To: <87r2klrfdc.fsf@hornfels.zedat.fu-berlin.de> (Loris Bennett's
 message of "Mon, 2 Jul 2018 14:28:31 +0200")
References: <87r2klrfdc.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <87zhz894nw.fsf@hornfels.zedat.fu-berlin.de>

Loris Bennett <loris.bennett at fu-berlin.de> writes:

> Hi,
>
> On Linux with R 3.5.1 and OpenMPI 2.1.0 I have built Rmpi and can run a
> simple example just using Rmpi and printing out the rank of each worker.
>
> However, when I try to use doMPI by running the following
>
>   library(Rmpi)
>   library(doMPI)
>   cl <- startMPIcluster(count=2)
>   registerDoMPI(cl)
>   clusterSize(cl)
>   closeCluster(cl)
>   mpi.quit()
>
> with
>
>   mpirun -np 1 --mca mpi_warn_on_fork 0 R --no-save -f mwe.r
>
> I get the following output
>
>   > library("Rmpi")
>   > library(doMPI)
>   Loading required package: foreach
>   Loading required package: iterators
>   > cl <- startMPIcluster(count=2)
>   	2 slaves are spawned successfully. 0 failed.
>   > registerDoMPI(cl)
>   > clusterSize(cl)
>   [1] 2
>   > closeCluster(cl)
>
> but the program hangs and I have to end it with Ctl-C.
>
> Can anyone shed any light on what might be wrong?

Having come across the following link:

  https://www.sharcnet.ca/help/index.php/Using_R_and_MPI

I rebuilt with OpenMPI 1.8.6 and the problem disappeared.

Cheers,

Loris

-- 
This signature is currently under construction.



From pd@|gd @end|ng |rom gm@||@com  Tue Jul  3 09:52:46 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 3 Jul 2018 09:52:46 +0200
Subject: [R] R maintains old values
In-Reply-To: <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
Message-ID: <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>

Also beware the traveling arsonist, Jenny Bryan:

https://www.tidyverse.org/articles/2017/12/workflow-vs-script/


-pd

> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ... or perhaps
> 
> rm( list = ls(all = TRUE))
> ## see ?ls  for details.
> 
> However, see ?Startup for how to start a R in a "clean" environment, e.g.
> with the --no-restore option.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
>> If you want a "fresh" R session when you start to run the script you could
>> consider putting as the first line
>> 
>> rm(list=ls())
>> 
>> This will remove objects from your environment (variables, functions, ..)
>> 
>> HTH,
>> Eric
>> 
>> 
>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> 
>>> Hi
>>> 
>>> Without code it is just fishing in murky waters. Could the problem you
>>> face be that in each run you assingn the result to some object and if the
>>> CSV is wrong your code fails but the object from previous run persists?
>>> 
>>> If this is the case just initialize your objects in the beginning (e.g.
>>> make them NULL at the beginning) and only if code delivers result the
>> value
>>> of the result is returned otherwise NULL is returned.
>>> 
>>> Cheers
>>> Petr
>>> 
>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>> protection of business partner's personal data are available on website:
>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>> documents attached to it may be confidential and are subject to the
>> legally
>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>> 
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>> via R-
>>>> help
>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>> To: r-help at r-project.org
>>>> Subject: [R] R maintains old values
>>>> 
>>>> Hello,
>>>> 
>>>> I have a strange side-effect from executing R-scripts using R and
>> RServe.
>>>> 
>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>> have RStudio
>>>> installed, but it's not running at the time. The R-script reads a CSV
>>> file and does
>>>> various statistical things. RServe enables me to run each line of the R
>>> script
>>>> using "eval()" line by line.
>>>> 
>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>> 
>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>> did correctly
>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>> last time.
>>>> Somehow, the last correct run is persisted and returned if there is
>> some
>>>> problem with the current CSV input.
>>>> 
>>>> This data persistence is maintained across reboots.
>>>> 
>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>> point, I
>>>> need to know how to clear these old values so if the CSV input is
>>> incorrect, I get
>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>> 
>>>> Hope this description is clear.
>>>> 
>>>> Thanks in advance to all.
>>>> 
>>>> - M
>>>> 
>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>> email.
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From tr@xp|@yer @end|ng |rom gm@||@com  Tue Jul  3 14:24:33 2018
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Tue, 3 Jul 2018 14:24:33 +0200
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
Message-ID: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>

Hi,
  I am currently using R v3.4.4 and I just discovered this:

> prod(NA, NaN) ; prod(NaN, NA)
[1] NA
[1] NaN

?prod says:
    If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
     cause a value of ?NA? to be returned, otherwise ?NA? values are
     ignored.

So according to the manual-page for prod() NA should be returned in both
cases?


However for sum() is opposite is true:
> sum(NA, NaN) ; sum(NaN, NA)
[1] NA
[1] NA

?sum says:
    If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
     arguments will cause a value of ?NA? or ?NaN? to be returned,
     otherwise ?NA? and ?NaN? values are ignored.


Maybe the manual for prod() should say the same as sum() that
both NA and NaN can be returned?

Regards
Martin



From pro|jcn@@h @end|ng |rom gm@||@com  Tue Jul  3 15:25:39 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 3 Jul 2018 09:25:39 -0400
Subject: [R] R maintains old values
In-Reply-To: <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
Message-ID: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>

For the sake of those who didn't see the link, Jenny objects strongly to startup
lines that either set a personal path or clear the workspace.

While I agree both of these are anti-social to the point of pathology for scripts
that are distributed, I have found it VERY important when testing things to actually
clear the workspace etc. Too many times I've got a result that nobody else would get
because I'm often loading some of my own packages or there are "useful" variables
lurking.

As usual, context is critical. Distributed scripts vs. developmental ones.

Now, to add to the controversy, how do you set a computer on fire?

JN

On 2018-07-03 03:52 AM, peter dalgaard wrote:
> Also beware the traveling arsonist, Jenny Bryan:
> 
> https://www.tidyverse.org/articles/2017/12/workflow-vs-script/
> 
> 
> -pd
> 
>> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> ... or perhaps
>>
>> rm( list = ls(all = TRUE))
>> ## see ?ls  for details.
>>
>> However, see ?Startup for how to start a R in a "clean" environment, e.g.
>> with the --no-restore option.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>
>>> If you want a "fresh" R session when you start to run the script you could
>>> consider putting as the first line
>>>
>>> rm(list=ls())
>>>
>>> This will remove objects from your environment (variables, functions, ..)
>>>
>>> HTH,
>>> Eric
>>>
>>>
>>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>
>>>> Hi
>>>>
>>>> Without code it is just fishing in murky waters. Could the problem you
>>>> face be that in each run you assingn the result to some object and if the
>>>> CSV is wrong your code fails but the object from previous run persists?
>>>>
>>>> If this is the case just initialize your objects in the beginning (e.g.
>>>> make them NULL at the beginning) and only if code delivers result the
>>> value
>>>> of the result is returned otherwise NULL is returned.
>>>>
>>>> Cheers
>>>> Petr
>>>>
>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>>> protection of business partner's personal data are available on website:
>>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>>> documents attached to it may be confidential and are subject to the
>>> legally
>>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>>
>>>>> -----Original Message-----
>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>>> via R-
>>>>> help
>>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] R maintains old values
>>>>>
>>>>> Hello,
>>>>>
>>>>> I have a strange side-effect from executing R-scripts using R and
>>> RServe.
>>>>>
>>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>>> have RStudio
>>>>> installed, but it's not running at the time. The R-script reads a CSV
>>>> file and does
>>>>> various statistical things. RServe enables me to run each line of the R
>>>> script
>>>>> using "eval()" line by line.
>>>>>
>>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>>>
>>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>>> did correctly
>>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>>> last time.
>>>>> Somehow, the last correct run is persisted and returned if there is
>>> some
>>>>> problem with the current CSV input.
>>>>>
>>>>> This data persistence is maintained across reboots.
>>>>>
>>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>>> point, I
>>>>> need to know how to clear these old values so if the CSV input is
>>>> incorrect, I get
>>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>>>
>>>>> Hope this description is clear.
>>>>>
>>>>> Thanks in advance to all.
>>>>>
>>>>> - M
>>>>>
>>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>>> email.
>>>>>      [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>



From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Jul  3 15:28:45 2018
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 3 Jul 2018 13:28:45 +0000
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
Message-ID: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>

Hi All,

I have one vector that I want to combine with another vector and that other vector should be the same for every row in the combined matrix. This obviously does not work:

vec <- c(2,4,3)
cbind(1:5, vec)

This does, but requires me to specify the correct value for 'n' in replicate():

cbind(1:5, t(replicate(5, vec)))

Other ways that do not require this are:

t(sapply(1:5, function(x) c(x, vec)))
do.call(rbind, lapply(1:5, function(x) c(x, vec)))
t(mapply(c, 1:5, MoreArgs=list(vec)))

I wonder if there is a simpler / more efficient way of doing this.

Best,
Wolfgang



From |oe@|jrg @end|ng |rom @ccucom@net  Tue Jul  3 15:40:36 2018
From: |oe@|jrg @end|ng |rom @ccucom@net (JRG)
Date: Tue, 3 Jul 2018 09:40:36 -0400
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <9f0c789f-ea14-d929-d22f-7c6374ff31ec@accucom.net>


On 07/03/2018 09:25 AM, J C Nash wrote:
> For the sake of those who didn't see the link, Jenny objects strongly to startup
> lines that either set a personal path or clear the workspace.
> 
> While I agree both of these are anti-social to the point of pathology for scripts
> that are distributed, I have found it VERY important when testing things to actually
> clear the workspace etc. Too many times I've got a result that nobody else would get
> because I'm often loading some of my own packages or there are "useful" variables
> lurking.
> 
> As usual, context is critical. Distributed scripts vs. developmental ones.


Agreed!

> 
> Now, to add to the controversy, how do you set a computer on fire?

One of the Boring Company's  Not A Flamethrowers ??


---JRG

John R. Gleason

> 
> JN
> 
> On 2018-07-03 03:52 AM, peter dalgaard wrote:
>> Also beware the traveling arsonist, Jenny Bryan:
>>
>> https://www.tidyverse.org/articles/2017/12/workflow-vs-script/
>>
>>
>> -pd
>>
>>> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>
>>> ... or perhaps
>>>
>>> rm( list = ls(all = TRUE))
>>> ## see ?ls  for details.
>>>
>>> However, see ?Startup for how to start a R in a "clean" environment, e.g.
>>> with the --no-restore option.
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>>
>>>> If you want a "fresh" R session when you start to run the script you could
>>>> consider putting as the first line
>>>>
>>>> rm(list=ls())
>>>>
>>>> This will remove objects from your environment (variables, functions, ..)
>>>>
>>>> HTH,
>>>> Eric
>>>>
>>>>
>>>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>>
>>>>> Hi
>>>>>
>>>>> Without code it is just fishing in murky waters. Could the problem you
>>>>> face be that in each run you assingn the result to some object and if the
>>>>> CSV is wrong your code fails but the object from previous run persists?
>>>>>
>>>>> If this is the case just initialize your objects in the beginning (e.g.
>>>>> make them NULL at the beginning) and only if code delivers result the
>>>> value
>>>>> of the result is returned otherwise NULL is returned.
>>>>>
>>>>> Cheers
>>>>> Petr
>>>>>
>>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>>>> protection of business partner's personal data are available on website:
>>>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>>>> documents attached to it may be confidential and are subject to the
>>>> legally
>>>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>>>> via R-
>>>>>> help
>>>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>>>> To: r-help at r-project.org
>>>>>> Subject: [R] R maintains old values
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> I have a strange side-effect from executing R-scripts using R and
>>>> RServe.
>>>>>>
>>>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>>>> have RStudio
>>>>>> installed, but it's not running at the time. The R-script reads a CSV
>>>>> file and does
>>>>>> various statistical things. RServe enables me to run each line of the R
>>>>> script
>>>>>> using "eval()" line by line.
>>>>>>
>>>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>>>>
>>>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>>>> did correctly
>>>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>>>> last time.
>>>>>> Somehow, the last correct run is persisted and returned if there is
>>>> some
>>>>>> problem with the current CSV input.
>>>>>>
>>>>>> This data persistence is maintained across reboots.
>>>>>>
>>>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>>>> point, I
>>>>>> need to know how to clear these old values so if the CSV input is
>>>>> incorrect, I get
>>>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>>>>
>>>>>> Hope this description is clear.
>>>>>>
>>>>>> Thanks in advance to all.
>>>>>>
>>>>>> - M
>>>>>>
>>>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>>>> email.
>>>>>>      [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



From pd@|gd @end|ng |rom gm@||@com  Tue Jul  3 16:04:30 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 3 Jul 2018 16:04:30 +0200
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <0BC49EC2-978A-48CB-939B-F3E9A810C771@gmail.com>



> On 3 Jul 2018, at 15:25 , J C Nash <profjcnash at gmail.com> wrote:
> 
> For the sake of those who didn't see the link, Jenny objects strongly to startup
> lines that either set a personal path or clear the workspace.
> 
> While I agree both of these are anti-social to the point of pathology for scripts
> that are distributed, I have found it VERY important when testing things to actually
> clear the workspace etc. Too many times I've got a result that nobody else would get
> because I'm often loading some of my own packages or there are "useful" variables
> lurking.


I think Jenny's point is more that rm(ls... is the wrong _method_ to clear the workspace, because it only does part of the job and you may end up missing require() statements, etc.  

> 
> As usual, context is critical. Distributed scripts vs. developmental ones.
> 
> Now, to add to the controversy, how do you set a computer on fire?


Short the lithium battery?

-pd

> 
> JN
> 
> On 2018-07-03 03:52 AM, peter dalgaard wrote:
>> Also beware the traveling arsonist, Jenny Bryan:
>> 
>> https://www.tidyverse.org/articles/2017/12/workflow-vs-script/
>> 
>> 
>> -pd
>> 
>>> On 2 Jul 2018, at 17:11 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>> ... or perhaps
>>> 
>>> rm( list = ls(all = TRUE))
>>> ## see ?ls  for details.
>>> 
>>> However, see ?Startup for how to start a R in a "clean" environment, e.g.
>>> with the --no-restore option.
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> On Mon, Jul 2, 2018 at 7:47 AM, Eric Berger <ericjberger at gmail.com> wrote:
>>> 
>>>> If you want a "fresh" R session when you start to run the script you could
>>>> consider putting as the first line
>>>> 
>>>> rm(list=ls())
>>>> 
>>>> This will remove objects from your environment (variables, functions, ..)
>>>> 
>>>> HTH,
>>>> Eric
>>>> 
>>>> 
>>>> On Mon, Jul 2, 2018 at 5:34 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>> 
>>>>> Hi
>>>>> 
>>>>> Without code it is just fishing in murky waters. Could the problem you
>>>>> face be that in each run you assingn the result to some object and if the
>>>>> CSV is wrong your code fails but the object from previous run persists?
>>>>> 
>>>>> If this is the case just initialize your objects in the beginning (e.g.
>>>>> make them NULL at the beginning) and only if code delivers result the
>>>> value
>>>>> of the result is returned otherwise NULL is returned.
>>>>> 
>>>>> Cheers
>>>>> Petr
>>>>> 
>>>>> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
>>>>> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
>>>>> zasady-ochrany-osobnich-udaju/ | Information about processing and
>>>>> protection of business partner's personal data are available on website:
>>>>> https://www.precheza.cz/en/personal-data-protection-principles/
>>>>> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>>>>> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>>>>> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>>>>> documents attached to it may be confidential and are subject to the
>>>> legally
>>>>> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>>>>> 
>>>>>> -----Original Message-----
>>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Morkus
>>>>> via R-
>>>>>> help
>>>>>> Sent: Monday, July 2, 2018 2:02 PM
>>>>>> To: r-help at r-project.org
>>>>>> Subject: [R] R maintains old values
>>>>>> 
>>>>>> Hello,
>>>>>> 
>>>>>> I have a strange side-effect from executing R-scripts using R and
>>>> RServe.
>>>>>> 
>>>>>> I am executing an R-Script from a Java file using RServe in R. I also
>>>>> have RStudio
>>>>>> installed, but it's not running at the time. The R-script reads a CSV
>>>>> file and does
>>>>>> various statistical things. RServe enables me to run each line of the R
>>>>> script
>>>>>> using "eval()" line by line.
>>>>>> 
>>>>>> All this works fine for a correctly-formatted CSV file. It's great.
>>>>>> 
>>>>>> But, if the CSV file isn't correctly formatted, AND the last CSV file
>>>>> did correctly
>>>>>> get run, then, with the incorrect CSV as input, the output is what ran
>>>>> last time.
>>>>>> Somehow, the last correct run is persisted and returned if there is
>>>> some
>>>>>> problem with the current CSV input.
>>>>>> 
>>>>>> This data persistence is maintained across reboots.
>>>>>> 
>>>>>> I'm thus baffled how R is maintaining these old values, but more to the
>>>>> point, I
>>>>>> need to know how to clear these old values so if the CSV input is
>>>>> incorrect, I get
>>>>>> nothing back, not the old CSV values from a correctly formatted file.
>>>>>> 
>>>>>> Hope this description is clear.
>>>>>> 
>>>>>> Thanks in advance to all.
>>>>>> 
>>>>>> - M
>>>>>> 
>>>>>> Sent from [ProtonMail](https://protonmail.com), Swiss-based encrypted
>>>>> email.
>>>>>>     [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From cry@n @end|ng |rom b|ngh@mton@edu  Tue Jul  3 16:09:19 2018
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W Ryan)
Date: Tue, 3 Jul 2018 10:09:19 -0400
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <CAM+rpYmM_2pjKQZ0P8xN8xmscQ9Xv6Ap=j=r26ygBEn=reN+4Q@mail.gmail.com>

This TV series might have some advice on that.

https://www.imdb.com/title/tt2543312/

--Chris Ryan

On Tue, Jul 3, 2018 at 9:25 AM, J C Nash <profjcnash at gmail.com> wrote:

> . . . Now, to add to the controversy, how do you set a computer on fire?
>
> JN
>
>

	[[alternative HTML version deleted]]



From n|n@@@choen|e|der @end|ng |rom un|-b|e|e|e|d@de  Tue Jul  3 12:33:49 2018
From: n|n@@@choen|e|der @end|ng |rom un|-b|e|e|e|d@de (=?UTF-8?Q?Nina_Sch=c3=b6nfelder?=)
Date: Tue, 03 Jul 2018 12:33:49 +0200
Subject: [R] R-help Digest, Vol 185, Issue 1
In-Reply-To: <mailman.350307.1.1530439201.52115.r-help@r-project.org>
References: <mailman.350307.1.1530439201.52115.r-help@r-project.org>
Message-ID: <c05ce3a0-100a-782d-9820-af2027d33355@uni-bielefeld.de>

Dear Luke,

it true that the number is not immediately displayed in the 
GMM-regression output using the plm package. To get the number of 
instruments (incl. exogenous variables and time dummies) you have to type:

 ????? k <- model??? # so that k is the pgmm-estimation output (an 
object of class c("pgmm","panelmodel")
 ??? ? ninst <- ncol(k$W[[1]])??? # the number of instruments is simply 
count as the number of columns in the matrix of instruments

Best regards,

Nina

--

*Dr. Nina Sch?nfelder*

*Nationaler Open-Access-Kontaktpunkt OA2020-DE*
Universit?t Bielefeld
Universit?tsbibliothek
Universit?tsstr. 25
D-33615 Bielefeld

Phone: +49 (0) 521/106-2546
E-mail: nina.schoenfelder at uni-bielefeld.de
Homepage: https://oa2020-de.org/
Twitter: @oa2020de
Facebook: https://www.facebook.com/oa2020de/

Am 01.07.2018 um 12:00 schrieb r-help-request at r-project.org:
> Message: 1
> Date: Sat, 30 Jun 2018 11:03:06 +0200
> From: =?UTF-8?b?xYF1a2FzeiBQacSZdGFr?=<L.Pietak at poczta.fm>
> To:r-help at r-project.org
> Subject: [R] Question
> Message-ID: <hbqeaucobgtjfdbbzufb at kmye>
> Content-Type: text/plain; charset="utf-8"
>
>
> Hi, My name is Luke and I come from Poland. I have one question, maybe very simple, but I can not resolve it. In dynamic panel data (GMM estimator) after running the model, I recieve a AR test and Sargan test, but the "number of instruments" are not displayed. In Stata and Gretl this informatios is given, in R no. My question is, how to obtain the number of instruments?.
> Thank you for helping.
> Luke
>
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jul  3 16:39:04 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 3 Jul 2018 14:39:04 +0000
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
Message-ID: <43fd0e6ac353429da2547e7f8ab369b3@SRVEXCHCM1302.precheza.cz>

Hi

If you put 1:5 vector to x you could do

cbind(x,t(replicate(length(x), vec)))

Cheers
Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Viechtbauer,
> Wolfgang (SP)
> Sent: Tuesday, July 3, 2018 3:29 PM
> To: r-help at r-project.org
> Subject: [R] Combine by columns a vector with another vector that is constant
> across rows
> 
> Hi All,
> 
> I have one vector that I want to combine with another vector and that other
> vector should be the same for every row in the combined matrix. This obviously
> does not work:
> 
> vec <- c(2,4,3)
> cbind(1:5, vec)
> 
> This does, but requires me to specify the correct value for 'n' in replicate():
> 
> cbind(1:5, t(replicate(5, vec)))
> 
> Other ways that do not require this are:
> 
> t(sapply(1:5, function(x) c(x, vec)))
> do.call(rbind, lapply(1:5, function(x) c(x, vec))) t(mapply(c, 1:5,
> MoreArgs=list(vec)))
> 
> I wonder if there is a simpler / more efficient way of doing this.
> 
> Best,
> Wolfgang
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ggrothend|eck @end|ng |rom gm@||@com  Tue Jul  3 16:46:19 2018
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Tue, 3 Jul 2018 10:46:19 -0400
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
Message-ID: <CAP01uRntSXp780CNfsZ-L6DDJz-K1EaOop1Ab4HVe_AKdA_bxQ@mail.gmail.com>

Try Reduce:

  Reduce(cbind, vec, 1:5)

On Tue, Jul 3, 2018 at 9:28 AM, Viechtbauer, Wolfgang (SP)
<wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> Hi All,
>
> I have one vector that I want to combine with another vector and that other vector should be the same for every row in the combined matrix. This obviously does not work:
>
> vec <- c(2,4,3)
> cbind(1:5, vec)
>
> This does, but requires me to specify the correct value for 'n' in replicate():
>
> cbind(1:5, t(replicate(5, vec)))
>
> Other ways that do not require this are:
>
> t(sapply(1:5, function(x) c(x, vec)))
> do.call(rbind, lapply(1:5, function(x) c(x, vec)))
> t(mapply(c, 1:5, MoreArgs=list(vec)))
>
> I wonder if there is a simpler / more efficient way of doing this.
>
> Best,
> Wolfgang
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From DOg|e @end|ng |rom north|@nd@edu  Tue Jul  3 17:05:22 2018
From: DOg|e @end|ng |rom north|@nd@edu (Derek Ogle)
Date: Tue, 3 Jul 2018 15:05:22 +0000
Subject: [R] limit windows() rescale/resize options
Message-ID: <5C759AAB3680854DA1CFD152DD5CCE5A013D27EB55@NC-MAIL2010.northland.edu>

I am developing an application that opens an image in a new window using, at times, windows(). I don't want the user to be able to resize the window (and distort the image). The new window contains a menu item called "resize" that contains three options - "R mode", "Fit to window", and "Fixed size". The default can be set with rescale= (i.e., rescale="fixed" for my use). However, the user can still select one of the other options. Is there a way to either remove the "Resize" menu from this window or remove the "R mode" and "Fit to window" options from this menu item?

Use the following, on a Windows machine, to see what I describe above.

windows(rescale="fixed")



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul  3 17:21:47 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Jul 2018 08:21:47 -0700
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
Message-ID: <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>

Gabor's solution seems to optimize 'simpler'.

More efficient is to learn that in R a vector is not a matrix, but a matrix is just an ornamented vector.

fastWolfgang <- function( v, vec ) {
  matrix( c( v, rep( vec, length( v ) ) )
         , now = length( v ) )
}

On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)" <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>Hi All,
>
>I have one vector that I want to combine with another vector and that
>other vector should be the same for every row in the combined matrix.
>This obviously does not work:
>
>vec <- c(2,4,3)
>cbind(1:5, vec)
>
>This does, but requires me to specify the correct value for 'n' in
>replicate():
>
>cbind(1:5, t(replicate(5, vec)))
>
>Other ways that do not require this are:
>
>t(sapply(1:5, function(x) c(x, vec)))
>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>t(mapply(c, 1:5, MoreArgs=list(vec)))
>
>I wonder if there is a simpler / more efficient way of doing this.
>
>Best,
>Wolfgang
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From B|||@Po||ng @end|ng |rom ze||@@com  Tue Jul  3 17:23:35 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 3 Jul 2018 15:23:35 +0000
Subject: [R] Structure to ts Error in attributes(.Data) <-
 c(attributes(.Data), attrib) :
Message-ID: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi, obviously missing something here? Getting error: Error in attributes(.Data) <- c(attributes(.Data), attrib) : invalid time series parameters specified


dat3 <- structure(c(1439713.32, 1265962.79, 1491834.9, 1276180.74, 1702077.51, 1420186.1, 1469240.11, 1415855.34, 1592933.06,   #9
                    1615926.39, 1668444.01, 1753406, 1356487.99, 1577808.22, 1906113.28, 1595299.45, 1671740.24, 1696643.33,    #9
                    1490665.78, 1937361.24, 1480193.81, 1676066.85, 2004112.69, 1798906.55, 1619973.89, 1280088.4, 1877394.67,  #9
                    2041241.6, 1390644.41, 2208564.77,                                                                          #3
                    #30

                    1384.3, -14169.24, -1455.1, -82397.77, -15564.42, 1808.77, -29776.31, -62641.51, -15418.52, #9
                    -6170.87, -14208.48, -43046.76, -43853.35, -53907.65, -29729.62, -47990.07, 54674.99,       #8
                    4029.92, -48323.28, 35197.06, -97430.56, -48994.68, -49803.5, -12870.97, -33126.07,         #8
                    -27147.19, -9559.51, -37699.07, -222996.6, -329.55,                                         #5
                    #30

                    -95835.69, -73436.06, -100240.36, -78918.26, -71763.56, -83735.15, -34898.95, -98622.59, -66763.2,         #9
                    -184645.76, -85494.47, -94503.59, -143120.57, -49829.96, -99636.61, -108242.24, -101192.2, -60214.25,      #9
                    -208992.81, -49769.11, -93133.14, -160933.77, -197905.84, -194055.39, -101310.71, -185137.96, -204476.75,  #9
                    -149305.62, -171494.96, -441145.96                                                                         #3
                    #30
)
                  ,.Dim = c(30L, 3L)
                  ,.Dimnames = list(NULL, c("Var1","Var2" ,"Var3"))
                  ,.Tsp = c(2016, 2018.5, 12), class = c("mts", "ts", "matrix"))

I am sure it's glaring at me!

Thank you for any advice.

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From ggrothend|eck @end|ng |rom gm@||@com  Tue Jul  3 17:32:08 2018
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Tue, 3 Jul 2018 11:32:08 -0400
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <CAP01uRntSXp780CNfsZ-L6DDJz-K1EaOop1Ab4HVe_AKdA_bxQ@mail.gmail.com>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <CAP01uRntSXp780CNfsZ-L6DDJz-K1EaOop1Ab4HVe_AKdA_bxQ@mail.gmail.com>
Message-ID: <CAP01uRkecBuLwL0kpVJFt4tRL0VWR1L204jJNJbzx8GzAo_3Vg@mail.gmail.com>

or this variation if you don't want the first column to be named init:

 Reduce(cbind2, vec, 1:5)

On Tue, Jul 3, 2018 at 10:46 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Try Reduce:
>
>   Reduce(cbind, vec, 1:5)
>
> On Tue, Jul 3, 2018 at 9:28 AM, Viechtbauer, Wolfgang (SP)
> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> Hi All,
>>
>> I have one vector that I want to combine with another vector and that other vector should be the same for every row in the combined matrix. This obviously does not work:
>>
>> vec <- c(2,4,3)
>> cbind(1:5, vec)
>>
>> This does, but requires me to specify the correct value for 'n' in replicate():
>>
>> cbind(1:5, t(replicate(5, vec)))
>>
>> Other ways that do not require this are:
>>
>> t(sapply(1:5, function(x) c(x, vec)))
>> do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>> t(mapply(c, 1:5, MoreArgs=list(vec)))
>>
>> I wonder if there is a simpler / more efficient way of doing this.
>>
>> Best,
>> Wolfgang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul  3 17:47:56 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Jul 2018 08:47:56 -0700
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
Message-ID: <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>

Sorry trying again...

fastWolfgang <- function( v, vec ) {
  matrix( c( v, rep( vec, each = length( v ) ) )
         , nrow = length( v ) )
}

On July 3, 2018 8:21:47 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>Gabor's solution seems to optimize 'simpler'.
>
>More efficient is to learn that in R a vector is not a matrix, but a
>matrix is just an ornamented vector.
>
>fastWolfgang <- function( v, vec ) {
>  matrix( c( v, rep( vec, length( v ) ) )
>         , now = length( v ) )
>}
>
>On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)"
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>Hi All,
>>
>>I have one vector that I want to combine with another vector and that
>>other vector should be the same for every row in the combined matrix.
>>This obviously does not work:
>>
>>vec <- c(2,4,3)
>>cbind(1:5, vec)
>>
>>This does, but requires me to specify the correct value for 'n' in
>>replicate():
>>
>>cbind(1:5, t(replicate(5, vec)))
>>
>>Other ways that do not require this are:
>>
>>t(sapply(1:5, function(x) c(x, vec)))
>>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>>t(mapply(c, 1:5, MoreArgs=list(vec)))
>>
>>I wonder if there is a simpler / more efficient way of doing this.
>>
>>Best,
>>Wolfgang
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From ted@h@rd|ng @end|ng |rom w|@ndre@@net  Tue Jul  3 17:58:37 2018
From: ted@h@rd|ng @end|ng |rom w|@ndre@@net (Ted Harding)
Date: Tue, 03 Jul 2018 16:58:37 +0100
Subject: [R] R maintains old values
In-Reply-To: <CAM+rpYmM_2pjKQZ0P8xN8xmscQ9Xv6Ap=j=r26ygBEn=reN+4Q@mail.gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
 <CAM+rpYmM_2pjKQZ0P8xN8xmscQ9Xv6Ap=j=r26ygBEn=reN+4Q@mail.gmail.com>
Message-ID: <1530633517.4282.2.camel@deb2.fort.knox.uk>

On Tue, Jul 3, 2018 at 9:25 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> > . . . Now, to add to the controversy, how do you set a computer on fire?
> >
> > JN

Perhaps by exploring the context of this thread,
where new values strike a match with old values???

Ted



From er|cjberger @end|ng |rom gm@||@com  Tue Jul  3 18:02:13 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 3 Jul 2018 19:02:13 +0300
Subject: [R] Structure to ts Error in attributes(.Data) <-
 c(attributes(.Data), attrib) :
In-Reply-To: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAGgJW77EqzqcyDpfE7-rurCa4kzg6djpnLy44hzryFBnr8KLrQ@mail.gmail.com>

Hi WHP,
It should be
.Tsp=c(2016,2018.4166667,12)

(off  by one error)
HTH,
Eric


On Tue, Jul 3, 2018 at 6:23 PM, Bill Poling <Bill.Poling at zelis.com> wrote:

> Hi, obviously missing something here? Getting error: Error in
> attributes(.Data) <- c(attributes(.Data), attrib) : invalid time series
> parameters specified
>
>
> dat3 <- structure(c(1439713.32, 1265962.79, 1491834.9, 1276180.74,
> 1702077.51, 1420186.1, 1469240.11, 1415855.34, 1592933.06,   #9
>                     1615926.39, 1668444.01, 1753406, 1356487.99,
> 1577808.22, 1906113.28, 1595299.45, 1671740.24, 1696643.33,    #9
>                     1490665.78, 1937361.24, 1480193.81, 1676066.85,
> 2004112.69, 1798906.55, 1619973.89, 1280088.4, 1877394.67,  #9
>                     2041241.6, 1390644.41, 2208564.77,
>                                                       #3
>                     #30
>
>                     1384.3, -14169.24, -1455.1, -82397.77, -15564.42,
> 1808.77, -29776.31, -62641.51, -15418.52, #9
>                     -6170.87, -14208.48, -43046.76, -43853.35, -53907.65,
> -29729.62, -47990.07, 54674.99,       #8
>                     4029.92, -48323.28, 35197.06, -97430.56, -48994.68,
> -49803.5, -12870.97, -33126.07,         #8
>                     -27147.19, -9559.51, -37699.07, -222996.6, -329.55,
>                                      #5
>                     #30
>
>                     -95835.69, -73436.06, -100240.36, -78918.26,
> -71763.56, -83735.15, -34898.95, -98622.59, -66763.2,         #9
>                     -184645.76, -85494.47, -94503.59, -143120.57,
> -49829.96, -99636.61, -108242.24, -101192.2, -60214.25,      #9
>                     -208992.81, -49769.11, -93133.14, -160933.77,
> -197905.84, -194055.39, -101310.71, -185137.96, -204476.75,  #9
>                     -149305.62, -171494.96, -441145.96
>                                                      #3
>                     #30
> )
>                   ,.Dim = c(30L, 3L)
>                   ,.Dimnames = list(NULL, c("Var1","Var2" ,"Var3"))
>                   ,.Tsp = c(2016, 2018.5, 12), class = c("mts", "ts",
> "matrix"))
>
> I am sure it's glaring at me!
>
> Thank you for any advice.
>
> WHP
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Tue Jul  3 18:46:04 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 3 Jul 2018 16:46:04 +0000
Subject: [R] FW: Structure to ts Error in attributes(.Data) <-
 c(attributes(.Data), attrib) :
In-Reply-To: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18346792B62E52D84FEB3B8FEA420@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CY1PR0201MB1834F4002FF5D3756D4FA822EA420@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi, I have my solution.

It should be
.Tsp=c(2016,2018.4166667,12)

(off  by one error)

Thank you.
WHP

From: Bill Poling
Sent: Tuesday, July 03, 2018 11:24 AM
To: r-help (r-help at r-project.org) <r-help at r-project.org>
Cc: Bill Poling <Bill.Poling at zelis.com>
Subject: Structure to ts Error in attributes(.Data) <- c(attributes(.Data), attrib) :

Hi, obviously missing something here? Getting error: Error in attributes(.Data) <- c(attributes(.Data), attrib) : invalid time series parameters specified


dat3 <- structure(c(1439713.32, 1265962.79, 1491834.9, 1276180.74, 1702077.51, 1420186.1, 1469240.11, 1415855.34, 1592933.06,   #9
                    1615926.39, 1668444.01, 1753406, 1356487.99, 1577808.22, 1906113.28, 1595299.45, 1671740.24, 1696643.33,    #9
                    1490665.78, 1937361.24, 1480193.81, 1676066.85, 2004112.69, 1798906.55, 1619973.89, 1280088.4, 1877394.67,  #9
                    2041241.6, 1390644.41, 2208564.77,                                                                          #3
                    #30

                    1384.3, -14169.24, -1455.1, -82397.77, -15564.42, 1808.77, -29776.31, -62641.51, -15418.52, #9
                    -6170.87, -14208.48, -43046.76, -43853.35, -53907.65, -29729.62, -47990.07, 54674.99,       #8
                    4029.92, -48323.28, 35197.06, -97430.56, -48994.68, -49803.5, -12870.97, -33126.07,         #8
                    -27147.19, -9559.51, -37699.07, -222996.6, -329.55,                                         #5
                    #30

                    -95835.69, -73436.06, -100240.36, -78918.26, -71763.56, -83735.15, -34898.95, -98622.59, -66763.2,         #9
                    -184645.76, -85494.47, -94503.59, -143120.57, -49829.96, -99636.61, -108242.24, -101192.2, -60214.25,      #9
                    -208992.81, -49769.11, -93133.14, -160933.77, -197905.84, -194055.39, -101310.71, -185137.96, -204476.75,  #9
                    -149305.62, -171494.96, -441145.96                                                                         #3
                    #30
)
                  ,.Dim = c(30L, 3L)
                  ,.Dimnames = list(NULL, c("Var1","Var2" ,"Var3"))
                  ,.Tsp = c(2016, 2018.5, 12), class = c("mts", "ts", "matrix"))

I am sure it's glaring at me!

Thank you for any advice.

WHP


Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Jul  3 19:12:58 2018
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 3 Jul 2018 17:12:58 +0000
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
 <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>
Message-ID: <cc6100fbab24489e9ba4a6b876c84188@UM-MAIL3213.unimaas.nl>

Thanks for all of the suggestions. I did some benchmarking:

library(microbenchmark)

x <- 1:5
vec <- c(2,4,3)

fastWolfgang <- function(v, vec)
   matrix(c(v, rep(vec, each = length(v))), nrow = length(v))

microbenchmark(cbind(x, t(replicate(length(x), vec))),
               t(sapply(x, function(x) c(x, vec))),
               do.call(rbind, lapply(x, function(x) c(x, vec))),
               t(mapply(c, x, MoreArgs=list(vec))),
               Reduce(cbind, vec, x),
               Reduce(cbind2, vec, x),
               fastWolfgang(x, vec), times=10000L)

Jeff's approach is fastest, but Gabor's Reduce(cbind, vec, x) is close (and I really like its simplicity); and very similar to the do.call() approach.

Interestingly, for larger vectors, such as:

x <- 1:50
vec <- sample(1:100, 200, replace=TRUE)

the do.call() approach is the fastest.

Best,
Wolfgang

>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Tuesday, 03 July, 2018 17:48
>To: r-help at r-project.org; Viechtbauer, Wolfgang (SP); r-help at r-
>project.org
>Subject: Re: [R] Combine by columns a vector with another vector that is
>constant across rows
>
>Sorry trying again...
>
>fastWolfgang <- function( v, vec ) {
>  matrix( c( v, rep( vec, each = length( v ) ) )
>         , nrow = length( v ) )
>}
>
>On July 3, 2018 8:21:47 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>>Gabor's solution seems to optimize 'simpler'.
>>
>>More efficient is to learn that in R a vector is not a matrix, but a
>>matrix is just an ornamented vector.
>>
>>fastWolfgang <- function( v, vec ) {
>>  matrix( c( v, rep( vec, length( v ) ) )
>>         , now = length( v ) )
>>}
>>
>>On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)"
>><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>Hi All,
>>>
>>>I have one vector that I want to combine with another vector and that
>>>other vector should be the same for every row in the combined matrix.
>>>This obviously does not work:
>>>
>>>vec <- c(2,4,3)
>>>cbind(1:5, vec)
>>>
>>>This does, but requires me to specify the correct value for 'n' in
>>>replicate():
>>>
>>>cbind(1:5, t(replicate(5, vec)))
>>>
>>>Other ways that do not require this are:
>>>
>>>t(sapply(1:5, function(x) c(x, vec)))
>>>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
>>>t(mapply(c, 1:5, MoreArgs=list(vec)))
>>>
>>>I wonder if there is a simpler / more efficient way of doing this.
>>>
>>>Best,
>>>Wolfgang

From roy@mende|@@ohn @end|ng |rom no@@@gov  Tue Jul  3 23:08:22 2018
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 3 Jul 2018 14:08:22 -0700
Subject: [R] ggplot2 version 3
Message-ID: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>

Hi All:

When I ask about updating packages in my R distribution,  it lists ggplot2 version 3.0.0 as being available.  I know that ggplot2 version 3.0.0 has made some significant changes that will break certain things.  I would like to install the new version, to see if it breaks anything that I do,  but I would also like to be able to revert back to the old version if it makes it impossible to do some of the work I need to get done,  and then switch back again to the new version to test some more.  Is there some elegant way of doing this?  If I just drag the appropriate Folder out of my directory and replace it with the one I want,  will that do it,  or are there too many other dependencies that are involved?

Thanks for any suggestions.

-Roy




**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Jul  3 23:09:35 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 4 Jul 2018 09:09:35 +1200
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
In-Reply-To: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
References: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
Message-ID: <832241d7-1248-4694-b6f0-2fe27167786e@auckland.ac.nz>


On 04/07/18 00:24, Martin M?ller Skarbiniks Pedersen wrote:

> Hi,
>    I am currently using R v3.4.4 and I just discovered this:
> 
>> prod(NA, NaN) ; prod(NaN, NA)
> [1] NA
> [1] NaN
> 
> ?prod says:
>      If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
>       cause a value of ?NA? to be returned, otherwise ?NA? values are
>       ignored.
> 
> So according to the manual-page for prod() NA should be returned in both
> cases?
> 
> 
> However for sum() is opposite is true:
>> sum(NA, NaN) ; sum(NaN, NA)
> [1] NA
> [1] NA
> 
> ?sum says:
>      If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
>       arguments will cause a value of ?NA? or ?NaN? to be returned,
>       otherwise ?NA? and ?NaN? values are ignored.
> 
> 
> Maybe the manual for prod() should say the same as sum() that
> both NA and NaN can be returned?

But:

 > sum(NA,NaN)
[1] NA
 > sum(NaN,NA)
[1] NA

so sum gives NA "both ways around".  Perhaps a slight inconsistency 
here?  I doubt that it's worth losing any sleep over, however.

Interestingly (???):

 > NaN*NA
[1] NaN
 > NA*NaN
[1] NA
 > NaN+NA
[1] NaN
 > NA+NaN
[1] NA

So we have an instance of non-commutative arithmetic operations.  And 
sum() is a wee bit inconsistent with "+".

Again I doubt that the implications are all that serious.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From wdun|@p @end|ng |rom t|bco@com  Tue Jul  3 23:40:26 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Tue, 3 Jul 2018 14:40:26 -0700
Subject: [R] ggplot2 version 3
In-Reply-To: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>
References: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>
Message-ID: <CAF8bMcaLPx--BLE7Emm+PoCTfePUXLS52nX8xWLoRhWMx57nqQ@mail.gmail.com>

One way to test the new ggplot2 is to make a new directory to use as an R
library and to install the new ggplot2 there.
   newLibrary <- "C:/tmp/newRLibrary"
   dir.create(newLibrary)
   install.packages("ggplot2", lib=newLibrary)
Then you can run two R sessions at once, starting one with
   .libPaths("C:/tmp/newRLibrary")
to use the new ggplot2 and the othe without that line to use the old ggpot2.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jul 3, 2018 at 2:08 PM, Roy Mendelssohn - NOAA Federal via R-help <
r-help at r-project.org> wrote:

> Hi All:
>
> When I ask about updating packages in my R distribution,  it lists ggplot2
> version 3.0.0 as being available.  I know that ggplot2 version 3.0.0 has
> made some significant changes that will break certain things.  I would like
> to install the new version, to see if it breaks anything that I do,  but I
> would also like to be able to revert back to the old version if it makes it
> impossible to do some of the work I need to get done,  and then switch back
> again to the new version to test some more.  Is there some elegant way of
> doing this?  If I just drag the appropriate Folder out of my directory and
> replace it with the one I want,  will that do it,  or are there too many
> other dependencies that are involved?
>
> Thanks for any suggestions.
>
> -Roy
>
>
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From roy@mende|@@ohn @end|ng |rom no@@@gov  Tue Jul  3 23:41:54 2018
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 3 Jul 2018 14:41:54 -0700
Subject: [R] ggplot2 version 3
In-Reply-To: <CAF8bMcaLPx--BLE7Emm+PoCTfePUXLS52nX8xWLoRhWMx57nqQ@mail.gmail.com>
References: <FC4F591D-8D1E-4233-B4FF-B60B2164707D@noaa.gov>
 <CAF8bMcaLPx--BLE7Emm+PoCTfePUXLS52nX8xWLoRhWMx57nqQ@mail.gmail.com>
Message-ID: <D7A8121B-C97B-42D1-9CCE-9BBB95E4DFED@noaa.gov>

Thanks!

-Roy


> On Jul 3, 2018, at 2:40 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> One way to test the new ggplot2 is to make a new directory to use as an R library and to install the new ggplot2 there.
>    newLibrary <- "C:/tmp/newRLibrary"
>    dir.create(newLibrary)
>    install.packages("ggplot2", lib=newLibrary)
> Then you can run two R sessions at once, starting one with
>    .libPaths("C:/tmp/newRLibrary")
> to use the new ggplot2 and the othe without that line to use the old ggpot2.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Tue, Jul 3, 2018 at 2:08 PM, Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
> Hi All:
> 
> When I ask about updating packages in my R distribution,  it lists ggplot2 version 3.0.0 as being available.  I know that ggplot2 version 3.0.0 has made some significant changes that will break certain things.  I would like to install the new version, to see if it breaks anything that I do,  but I would also like to be able to revert back to the old version if it makes it impossible to do some of the work I need to get done,  and then switch back again to the new version to test some more.  Is there some elegant way of doing this?  If I just drag the appropriate Folder out of my directory and replace it with the one I want,  will that do it,  or are there too many other dependencies that are involved?
> 
> Thanks for any suggestions.
> 
> -Roy
> 
> 
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.



From b@r@rym @end|ng |rom gm@||@com  Wed Jul  4 03:34:59 2018
From: b@r@rym @end|ng |rom gm@||@com (Mehrshad Barary)
Date: Wed, 4 Jul 2018 11:34:59 +1000
Subject: [R] ASExtras library
Message-ID: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>

Hi Everyone,

Does anybody know how I can get ASExtras library?


Thanks
Mehrshad

-- 
Mehrshad Barary
Senior Lecturer in Crop Ecophysiology
Department of Agronomy and Plant Breeding
Faculty of Agriculture
Ilam University
Tel: (+98)8412227019-21
Fax: (+98)8412227015

	[[alternative HTML version deleted]]



From ccberry @end|ng |rom uc@d@edu  Wed Jul  4 03:59:57 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Wed, 4 Jul 2018 01:59:57 +0000
Subject: [R] R maintains old values
In-Reply-To: <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
References: <efBPLSiYSmntEAS3R3l0hR9_ecyBU265HPw3FPlkNPgf3r-kIeRnF8Hx2oGF0k90LanC9kAYj9XLu144U0S0uy0kknbCwHWcGmSkhE_WdyA=@protonmail.com>
 <77ecfd60a0bc4c1f870aca41a1f46a51@SRVEXCHCM1302.precheza.cz>
 <CAGgJW76TKtEC3Z80MUT-dNp14K1spGBiQ_3vaHYZiLS-Sa2vgA@mail.gmail.com>
 <CAGxFJbT-wO1eK3C+goxukWnhvPKr8ergkznuqTe4Bs99gmRUvw@mail.gmail.com>
 <12B5116B-55F3-454E-85CB-EDBEF862DC06@gmail.com>
 <8e91c64f-7d35-a36a-fe2f-da38038446c2@gmail.com>
Message-ID: <F950300B-D5BE-4A73-914B-699E74AC0152@ucsd.edu>



> On Jul 3, 2018, at 6:25 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> Now, to add to the controversy, how do you set a computer on fire?

>From the bash prompt:

stuxnet --overload=cpu,disk,network,gpu --fan=off --no-warnings <your_computer_id>

HTH,

Chuck


From er|cjberger @end|ng |rom gm@||@com  Wed Jul  4 08:32:57 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 4 Jul 2018 09:32:57 +0300
Subject: [R] Combine by columns a vector with another vector that is
 constant across rows
In-Reply-To: <cc6100fbab24489e9ba4a6b876c84188@UM-MAIL3213.unimaas.nl>
References: <226de5c2638f440fa28349002b503d0a@UM-MAIL3213.unimaas.nl>
 <17F9E907-C933-4199-B624-D7F2075F01E0@dcn.davis.ca.us>
 <DF36E140-D5C6-40C9-903B-8DF1DF7E7B4A@dcn.davis.ca.us>
 <cc6100fbab24489e9ba4a6b876c84188@UM-MAIL3213.unimaas.nl>
Message-ID: <CAGgJW76TM+n=BN3oXr+urWpSA2ZkK3z+RjNiGZDn1wVPbEJM-w@mail.gmail.com>

For what it's worth, for larger vectors, and following on from your
observation that the do.call() approach is faster, the following provides
some modest additional speedup:

 cbind(x,t(do.call(cbind, lapply(x, function(y) vec))))

Rgds,
Eric


On Tue, Jul 3, 2018 at 8:12 PM, Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Thanks for all of the suggestions. I did some benchmarking:
>
> library(microbenchmark)
>
> x <- 1:5
> vec <- c(2,4,3)
>
> fastWolfgang <- function(v, vec)
>    matrix(c(v, rep(vec, each = length(v))), nrow = length(v))
>
> microbenchmark(cbind(x, t(replicate(length(x), vec))),
>                t(sapply(x, function(x) c(x, vec))),
>                do.call(rbind, lapply(x, function(x) c(x, vec))),
>                t(mapply(c, x, MoreArgs=list(vec))),
>                Reduce(cbind, vec, x),
>                Reduce(cbind2, vec, x),
>                fastWolfgang(x, vec), times=10000L)
>
> Jeff's approach is fastest, but Gabor's Reduce(cbind, vec, x) is close
> (and I really like its simplicity); and very similar to the do.call()
> approach.
>
> Interestingly, for larger vectors, such as:
>
> x <- 1:50
> vec <- sample(1:100, 200, replace=TRUE)
>
> the do.call() approach is the fastest.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> >Sent: Tuesday, 03 July, 2018 17:48
> >To: r-help at r-project.org; Viechtbauer, Wolfgang (SP); r-help at r-
> >project.org
> >Subject: Re: [R] Combine by columns a vector with another vector that is
> >constant across rows
> >
> >Sorry trying again...
> >
> >fastWolfgang <- function( v, vec ) {
> >  matrix( c( v, rep( vec, each = length( v ) ) )
> >         , nrow = length( v ) )
> >}
> >
> >On July 3, 2018 8:21:47 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >wrote:
> >>Gabor's solution seems to optimize 'simpler'.
> >>
> >>More efficient is to learn that in R a vector is not a matrix, but a
> >>matrix is just an ornamented vector.
> >>
> >>fastWolfgang <- function( v, vec ) {
> >>  matrix( c( v, rep( vec, length( v ) ) )
> >>         , now = length( v ) )
> >>}
> >>
> >>On July 3, 2018 6:28:45 AM PDT, "Viechtbauer, Wolfgang (SP)"
> >><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>>Hi All,
> >>>
> >>>I have one vector that I want to combine with another vector and that
> >>>other vector should be the same for every row in the combined matrix.
> >>>This obviously does not work:
> >>>
> >>>vec <- c(2,4,3)
> >>>cbind(1:5, vec)
> >>>
> >>>This does, but requires me to specify the correct value for 'n' in
> >>>replicate():
> >>>
> >>>cbind(1:5, t(replicate(5, vec)))
> >>>
> >>>Other ways that do not require this are:
> >>>
> >>>t(sapply(1:5, function(x) c(x, vec)))
> >>>do.call(rbind, lapply(1:5, function(x) c(x, vec)))
> >>>t(mapply(c, 1:5, MoreArgs=list(vec)))
> >>>
> >>>I wonder if there is a simpler / more efficient way of doing this.
> >>>
> >>>Best,
> >>>Wolfgang
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From kch@mber|n @end|ng |rom gm@||@com  Wed Jul  4 11:08:38 2018
From: kch@mber|n @end|ng |rom gm@||@com (1/k^c)
Date: Wed, 4 Jul 2018 03:08:38 -0600
Subject: [R] gamlss() vs glm() standard errors via summary() vs vcov()
Message-ID: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>

Hi R-helpers,

I was working with some count data using gamlss() and glm(), and
noticed that the standard errors from the two functions correspond
when extracting from either the model summary for both functions, or
using vcov for both functions, but the standard errors between those
methods do not correspond. I have been lead to believe that in SAS and
Stata, the SEs do correspond between the different methods. Can anyone
assist me in understanding what's different between the two types of
SEs I seem to be encountering when using R with either glm or gamlss?
I feel like I'm missing something obvious. I have included a small
reproducible example below.

library(COUNT) # for myTable()
library(gamlss)
len<-50
seeder<-250
set.seed(seeder)  # reproducible example
dat<-rpois(c(1:len), lambda=2)
myTable(dat)
fac<-gl(n=2, k=1, length=len, labels = c("control","treat"))

# Fit gamlss() and glm() models
fit1<-gamlss(dat~fac, family="PO")
fit2<-glm(dat~fac, family="poisson")

# Extract SEs from model summaries
SESum1<-summary(fit1)[,"Std. Error"]
SESum2<-coef(summary(fit2))[,"Std. Error"]
cbind(SESum1, SESum2) # Corresponds

# Extract SEs via vcov()
SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
cbind(SEvcov1, SEvcov2) # Corresponds

# Compare between summary() and vcov() extraction. Missmatch.
cbind(SESum1, SEvcov1)



From pd@|gd @end|ng |rom gm@||@com  Wed Jul  4 12:11:50 2018
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Wed, 4 Jul 2018 12:11:50 +0200
Subject: [R] gamlss() vs glm() standard errors via summary() vs vcov()
In-Reply-To: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>
References: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>
Message-ID: <D85EC54E-E1C4-43B0-8015-4A4EBF7268F3@gmail.com>

> # Extract SEs via vcov()
> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))

What makes you think that you need to multiply with exp(coef(....)) here???

-pd

> On 4 Jul 2018, at 11:08 , 1/k^c <kchamberln at gmail.com> wrote:
> 
> Hi R-helpers,
> 
> I was working with some count data using gamlss() and glm(), and
> noticed that the standard errors from the two functions correspond
> when extracting from either the model summary for both functions, or
> using vcov for both functions, but the standard errors between those
> methods do not correspond. I have been lead to believe that in SAS and
> Stata, the SEs do correspond between the different methods. Can anyone
> assist me in understanding what's different between the two types of
> SEs I seem to be encountering when using R with either glm or gamlss?
> I feel like I'm missing something obvious. I have included a small
> reproducible example below.
> 
> library(COUNT) # for myTable()
> library(gamlss)
> len<-50
> seeder<-250
> set.seed(seeder)  # reproducible example
> dat<-rpois(c(1:len), lambda=2)
> myTable(dat)
> fac<-gl(n=2, k=1, length=len, labels = c("control","treat"))
> 
> # Fit gamlss() and glm() models
> fit1<-gamlss(dat~fac, family="PO")
> fit2<-glm(dat~fac, family="poisson")
> 
> # Extract SEs from model summaries
> SESum1<-summary(fit1)[,"Std. Error"]
> SESum2<-coef(summary(fit2))[,"Std. Error"]
> cbind(SESum1, SESum2) # Corresponds
> 
> # Extract SEs via vcov()
> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
> cbind(SEvcov1, SEvcov2) # Corresponds
> 
> # Compare between summary() and vcov() extraction. Missmatch.
> cbind(SESum1, SEvcov1)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk  Wed Jul  4 13:06:17 2018
From: b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk (Barry Rowlingson)
Date: Wed, 4 Jul 2018 12:06:17 +0100
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
In-Reply-To: <75f449fc45274830bdab0d83124b8725@AM6PR04MB4264.eurprd04.prod.outlook.com>
References: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
 <75f449fc45274830bdab0d83124b8725@AM6PR04MB4264.eurprd04.prod.outlook.com>
Message-ID: <CANVKczP4YM9+KObGfrm0DLRBanL59hnQOj0Rn7=-xHvUh27-VA@mail.gmail.com>

I'm having deja-vu of a similar discussion on R-devel:

https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html

This was the funniest inconsistency I could find:

 > sum(c(NaN,NA))
 [1] NaN
 > sum(NaN,NA)
 [1] NA

THEY'RE IN THE SAME ORDER!!!

The doc in ?NaN has this clause:

     In R, basically all mathematical functions (including basic
     ?Arithmetic?), are supposed to work properly with ?+/- Inf? and
     ?NaN? as input or output.

which doesn't define "properly", but you'd think commutativity was a
"proper" property of addition. So although they "are supposed to" they
don't. Naughty mathematical functions!

And then there's...

     Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
     which of those two is not guaranteed and may depend on the R
     platform (since compilers may re-order computations).

Which is at least telling you there is vagueness in the system. But
hey, mathematics is not a precise science... oh wait...

Barry





On Tue, Jul 3, 2018 at 10:09 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 04/07/18 00:24, Martin M?ller Skarbiniks Pedersen wrote:
>
>> Hi,
>>    I am currently using R v3.4.4 and I just discovered this:
>>
>>> prod(NA, NaN) ; prod(NaN, NA)
>> [1] NA
>> [1] NaN
>>
>> ?prod says:
>>      If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
>>       cause a value of ?NA? to be returned, otherwise ?NA? values are
>>       ignored.
>>
>> So according to the manual-page for prod() NA should be returned in both
>> cases?
>>
>>
>> However for sum() is opposite is true:
>>> sum(NA, NaN) ; sum(NaN, NA)
>> [1] NA
>> [1] NA
>>
>> ?sum says:
>>      If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
>>       arguments will cause a value of ?NA? or ?NaN? to be returned,
>>       otherwise ?NA? and ?NaN? values are ignored.
>>
>>
>> Maybe the manual for prod() should say the same as sum() that
>> both NA and NaN can be returned?
>
> But:
>
>  > sum(NA,NaN)
> [1] NA
>  > sum(NaN,NA)
> [1] NA
>
> so sum gives NA "both ways around".  Perhaps a slight inconsistency
> here?  I doubt that it's worth losing any sleep over, however.
>
> Interestingly (???):
>
>  > NaN*NA
> [1] NaN
>  > NA*NaN
> [1] NA
>  > NaN+NA
> [1] NaN
>  > NA+NaN
> [1] NA
>
> So we have an instance of non-commutative arithmetic operations.  And
> sum() is a wee bit inconsistent with "+".
>
> Again I doubt that the implications are all that serious.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jul  4 17:52:58 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 4 Jul 2018 08:52:58 -0700
Subject: [R] ASExtras library
In-Reply-To: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>
References: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>
Message-ID: <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>


> On Jul 3, 2018, at 6:34 PM, Mehrshad Barary <bararym at gmail.com> wrote:
> 
> Hi Everyone,
> 
> Does anybody know how I can get ASExtras library?

It would be helpful if you would provide information about your reasons for assuming this package's existence. Cannot find it in CRAN (including a search for 'ASExtra'), BioConductor, GitHub, or the Archives, or even with Google for that matter.

https://cran.r-project.org/src/contrib/Archive/

And within R parlance 'library' not a synonym for 'package'. Libraries are where you store packages. And `library('pkg_name')` is a command for loading a package.


> Thanks
> Mehrshad
> 
> -- 
> Mehrshad Barary
> Senior Lecturer in Crop Ecophysiology
> Department of Agronomy and Plant Breeding
> Faculty of Agriculture
> Ilam University
> Tel: (+98)8412227019-21
> Fax: (+98)8412227015
> 
> 	[[alternative HTML version deleted]]

And R help is a plain-text mailing list. Please read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From ted@h@rd|ng @end|ng |rom w|@ndre@@net  Wed Jul  4 20:18:46 2018
From: ted@h@rd|ng @end|ng |rom w|@ndre@@net (Ted Harding)
Date: Wed, 04 Jul 2018 19:18:46 +0100
Subject: [R] prod(NaN, NA) vs. prod(NA, NaN)
In-Reply-To: <CANVKczP4YM9+KObGfrm0DLRBanL59hnQOj0Rn7=-xHvUh27-VA@mail.gmail.com>
References: <CAGAA5bcsWX_1yXG4Dh4SVJ+rryshC+QhyGkFArVChsJVhG-8Sg@mail.gmail.com>
 <75f449fc45274830bdab0d83124b8725@AM6PR04MB4264.eurprd04.prod.outlook.com>
 <CANVKczP4YM9+KObGfrm0DLRBanL59hnQOj0Rn7=-xHvUh27-VA@mail.gmail.com>
Message-ID: <1530728326.3880.32.camel@deb2.fort.knox.uk>

I've been following this thread, and wondering where it might lead.
My (possibly naive) view of these matters is basically logical,
relying on (possibly over-simplified) interpretaions of "NA" and "NaN".

These are that:
  "NaN" means "Not a Number", though it can result from a
numerical calculation, e.g. '0/0' or 'Inf/Inf', while:
  "NA" means "Not Available" (e.g. "Missing Value"), but
   should be interpreted as in rhe appropriate class of its
   context -- so '2 + NA' interporets "NA" as numeric,
   while 'vec("abc",NA)' interprets "NA" as character.

On that basis, the result of 'sum(NaN, <anything>)' should be
"NaN", since 'sum' presumes that its arguments are numeric,
and the sum of <bumbers, not-a-number> is not a number.
Likewise 'sum(<anything>, NaN)' should be NaN.

And in both of 'sum(NA, NaN) and sum(NaN, NA), the "NA" should
be interepreted as a "not-available number", and because
of the "NaN" the result cannot be a number, hence is "NaN".

So it sould seem that Martin M?ller Skarbiniks Pedersen's
inconsistency:
  sum(c(NaN,NA))
  [1] NaN
  sum(NaN,NA)
  [1] NA
is not consistent with the above reasoning.

However, in my R version 2.14.0 (2011-10-31):
  sum(NaN,NA)
  [1] NA
  sum(NA,NaN)
  [1] NA
which **is** consistent! Hmmm...
Best wishes to all,
Ted.

On Wed, 2018-07-04 at 12:06 +0100, Barry Rowlingson wrote: 
> I'm having deja-vu of a similar discussion on R-devel:
> 
> https://stat.ethz.ch/pipermail/r-devel/2018-July/076377.html
> 
> This was the funniest inconsistency I could find:
> 
>  > sum(c(NaN,NA))
>  [1] NaN
>  > sum(NaN,NA)
>  [1] NA
> 
> THEY'RE IN THE SAME ORDER!!!
> 
> The doc in ?NaN has this clause:
> 
>      In R, basically all mathematical functions (including basic
>      ?Arithmetic?), are supposed to work properly with ?+/- Inf? and
>      ?NaN? as input or output.
> 
> which doesn't define "properly", but you'd think commutativity was a
> "proper" property of addition. So although they "are supposed to" they
> don't. Naughty mathematical functions!
> 
> And then there's...
> 
>      Computations involving ?NaN? will return ?NaN? or perhaps ?NA?:
>      which of those two is not guaranteed and may depend on the R
>      platform (since compilers may re-order computations).
> 
> Which is at least telling you there is vagueness in the system. But
> hey, mathematics is not a precise science... oh wait...
> 
> Barry
> 
> 
> 
> 
> 
> On Tue, Jul 3, 2018 at 10:09 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> > On 04/07/18 00:24, Martin M?ller Skarbiniks Pedersen wrote:
> >
> >> Hi,
> >>    I am currently using R v3.4.4 and I just discovered this:
> >>
> >>> prod(NA, NaN) ; prod(NaN, NA)
> >> [1] NA
> >> [1] NaN
> >>
> >> ?prod says:
> >>      If ?na.rm? is ?FALSE? an ?NA? value in any of the arguments will
> >>       cause a value of ?NA? to be returned, otherwise ?NA? values are
> >>       ignored.
> >>
> >> So according to the manual-page for prod() NA should be returned in both
> >> cases?
> >>
> >>
> >> However for sum() is opposite is true:
> >>> sum(NA, NaN) ; sum(NaN, NA)
> >> [1] NA
> >> [1] NA
> >>
> >> ?sum says:
> >>      If ?na.rm? is ?FALSE? an ?NA? or ?NaN? value in any of the
> >>       arguments will cause a value of ?NA? or ?NaN? to be returned,
> >>       otherwise ?NA? and ?NaN? values are ignored.
> >>
> >>
> >> Maybe the manual for prod() should say the same as sum() that
> >> both NA and NaN can be returned?
> >
> > But:
> >
> >  > sum(NA,NaN)
> > [1] NA
> >  > sum(NaN,NA)
> > [1] NA
> >
> > so sum gives NA "both ways around".  Perhaps a slight inconsistency
> > here?  I doubt that it's worth losing any sleep over, however.
> >
> > Interestingly (???):
> >
> >  > NaN*NA
> > [1] NaN
> >  > NA*NaN
> > [1] NA
> >  > NaN+NA
> > [1] NaN
> >  > NA+NaN
> > [1] NA
> >
> > So we have an instance of non-commutative arithmetic operations.  And
> > sum() is a wee bit inconsistent with "+".
> >
> > Again I doubt that the implications are all that serious.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From Ad@m@Z@J@b|r @end|ng |rom out|ook@|r  Wed Jul  4 19:16:27 2018
From: Ad@m@Z@J@b|r @end|ng |rom out|ook@|r (Adam Z. Jabir)
Date: Wed, 4 Jul 2018 17:16:27 +0000
Subject: [R] R is creating a new level which is emty after importing a SAS
 file
Message-ID: <CY4PR05MB31573C71D954314DD86AA2F2A8410@CY4PR05MB3157.namprd05.prod.outlook.com>

Hi,

I have imported some sasdata into R using the sas7bdat package. I have some nominal variables with some missing values.

R is creating a new level which is emty ??.When I ask for tabulate this new level is presented with 0 as a frequency.

I want to get rid of this level and have my file imported correctly.

Do you have some hint to help solve this problem?


Please use this email adress to answer this query.


 Best,

Adam


Envoy? ? partir de Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Wed Jul  4 23:09:15 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 4 Jul 2018 23:09:15 +0200
Subject: [R] 
 R is creating a new level which is emty after importing a SAS file
In-Reply-To: <CY4PR05MB31573C71D954314DD86AA2F2A8410@CY4PR05MB3157.namprd05.prod.outlook.com>
References: <CY4PR05MB31573C71D954314DD86AA2F2A8410@CY4PR05MB3157.namprd05.prod.outlook.com>
Message-ID: <58657783-39C2-454E-8CFD-EEA771BE1688@gmail.com>

It is not obvious that this is an error. If your nominal variable in SAS has a level which is not present in data, then R might just be making a faithful translation. There is a distinction between (a) having a gender variable with two levels of which 0 females and (b) pretending that male is the only possible gender.

Anyways, droplevels() is your friend. (Notice that it easier to remove levels that you do not want than to insert levels that have been unwantedly deleted on input.) 

-pd

> On 4 Jul 2018, at 19:16 , Adam Z. Jabir <Adam.Z.Jabir at outlook.fr> wrote:
> 
> Hi,
> 
> I have imported some sasdata into R using the sas7bdat package. I have some nominal variables with some missing values.
> 
> R is creating a new level which is emty ?.When I ask for tabulate this new level is presented with 0 as a frequency.
> 
> I want to get rid of this level and have my file imported correctly.
> 
> Do you have some hint to help solve this problem?
> 
> 
> Please use this email adress to answer this query.
> 
> 
> Best,
> 
> Adam
> 
> 
> Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From kch@mber|n @end|ng |rom gm@||@com  Wed Jul  4 23:33:20 2018
From: kch@mber|n @end|ng |rom gm@||@com (1/k^c)
Date: Wed, 4 Jul 2018 15:33:20 -0600
Subject: [R] gamlss() vs glm() standard errors via summary() vs vcov()
In-Reply-To: <D85EC54E-E1C4-43B0-8015-4A4EBF7268F3@gmail.com>
References: <CAJjKGBToRd7VoWHm6vqDpROLU=t4GmRdoDYP2Tad6_Hx6pJx5w@mail.gmail.com>
 <D85EC54E-E1C4-43B0-8015-4A4EBF7268F3@gmail.com>
Message-ID: <CAJjKGBRds8bhJ9kpgXBqBaE6-CFpuew1=6rW5atVZ+NRqeexaQ@mail.gmail.com>

Thank you, Peter!

Sincerely,
KeithC.

On Wed, Jul 4, 2018 at 4:11 AM, Peter Dalgaard <pdalgd at gmail.com> wrote:
>> # Extract SEs via vcov()
>> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
>> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
>
> What makes you think that you need to multiply with exp(coef(....)) here???
>
> -pd
>
>> On 4 Jul 2018, at 11:08 , 1/k^c <kchamberln at gmail.com> wrote:
>>
>> Hi R-helpers,
>>
>> I was working with some count data using gamlss() and glm(), and
>> noticed that the standard errors from the two functions correspond
>> when extracting from either the model summary for both functions, or
>> using vcov for both functions, but the standard errors between those
>> methods do not correspond. I have been lead to believe that in SAS and
>> Stata, the SEs do correspond between the different methods. Can anyone
>> assist me in understanding what's different between the two types of
>> SEs I seem to be encountering when using R with either glm or gamlss?
>> I feel like I'm missing something obvious. I have included a small
>> reproducible example below.
>>
>> library(COUNT) # for myTable()
>> library(gamlss)
>> len<-50
>> seeder<-250
>> set.seed(seeder)  # reproducible example
>> dat<-rpois(c(1:len), lambda=2)
>> myTable(dat)
>> fac<-gl(n=2, k=1, length=len, labels = c("control","treat"))
>>
>> # Fit gamlss() and glm() models
>> fit1<-gamlss(dat~fac, family="PO")
>> fit2<-glm(dat~fac, family="poisson")
>>
>> # Extract SEs from model summaries
>> SESum1<-summary(fit1)[,"Std. Error"]
>> SESum2<-coef(summary(fit2))[,"Std. Error"]
>> cbind(SESum1, SESum2) # Corresponds
>>
>> # Extract SEs via vcov()
>> SEvcov1<-exp(coef(fit1)) *sqrt(diag(vcov(fit1)))
>> SEvcov2<-exp(coef(fit2))*sqrt(diag(vcov(fit2)))
>> cbind(SEvcov1, SEvcov2) # Corresponds
>>
>> # Compare between summary() and vcov() extraction. Missmatch.
>> cbind(SESum1, SEvcov1)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>



From ne||@redu @end|ng |rom hotm@||@|r  Thu Jul  5 00:21:34 2018
From: ne||@redu @end|ng |rom hotm@||@|r (Nelly Reduan)
Date: Wed, 4 Jul 2018 22:21:34 +0000
Subject: [R] Generate N random numbers with a given probability and condition
Message-ID: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>

Dear all,

I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:

x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))

But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
Many thanks for your time
Nell


	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jul  5 00:56:59 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 04 Jul 2018 15:56:59 -0700
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <E1C9FF51-474D-479E-BEE7-F32A5F19A436@dcn.davis.ca.us>

This looks like homework (which is off topic here per the Posting Guide). Also, please send your emails in plain text format to avoid us seeing your message differently than you do.

On July 4, 2018 3:21:34 PM PDT, Nelly Reduan <nell.redu at hotmail.fr> wrote:
>Dear all,
>
>I would like to generate N random numbers with a given probability and
>condition but I'm not sure how to do this.
>For example, I have N = 20 and the vector from which to choose is
>seq(0, 10, 1). I have tested:
>
>x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28,
>times=length(seq(0, 10, 1))))
>
>But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>Many thanks for your time
>Nell
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Jul  5 01:11:11 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 5 Jul 2018 11:11:11 +1200
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>


On 05/07/18 10:21, Nelly Reduan wrote:

> Dear all,
> 
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
> 
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
> 
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time.

Your thinking requires considerable clarification.

(1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.

(2) Hence length(seq(0,10,1)) is 11.

(3) Likewise max(seq(0,10,1)) is 10.

(4) Your prob vector is *constant* --- so specifying "prob" makes
     no difference --- the result is the same as if you omitted "prob".

(5) You need to think carefully about what you really mean by "random".
     In what way do you want the final result to be "random"?

I expect that the lecturer who assigned this problem to you  needs to 
clarify his/her thinking as well.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From r@dmuzom @end|ng |rom out|ook@com  Wed Jul  4 23:34:23 2018
From: r@dmuzom @end|ng |rom out|ook@com (radmuzom .)
Date: Wed, 4 Jul 2018 21:34:23 +0000
Subject: [R] ASExtras library
In-Reply-To: <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>
References: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>,
 <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>
Message-ID: <MAXPR0101MB17851D0974DC6B6A28A868C4CB410@MAXPR0101MB1785.INDPRD01.PROD.OUTLOOK.COM>

The package appears to be referenced in the package "agridat" - ftp://cran.r-project.org/pub/R/web/packages/agridat/agridat.pdf (Pg 55). However, even I tried searching for it and there seems to be no reference other than this source.

Regards,
radmuzom

From: R-help <r-help-bounces at r-project.org> on behalf of David Winsemius <dwinsemius at comcast.net>
Sent: Wednesday, July 4, 2018 9:22 PM
To: Mehrshad Barary
Cc: r-help at r-project.org
Subject: Re: [R] ASExtras library
? 


> On Jul 3, 2018, at 6:34 PM, Mehrshad Barary <bararym at gmail.com> wrote:
> 
> Hi Everyone,
> 
> Does anybody know how I can get ASExtras library?

It would be helpful if you would provide information about your reasons for assuming this package's existence. Cannot find it in CRAN (including a search for 'ASExtra'), BioConductor, GitHub, or the Archives, or even with Google for that matter.

https://cran.r-project.org/src/contrib/Archive/

And within R parlance 'library' not a synonym for 'package'. Libraries are where you store packages. And `library('pkg_name')` is a command for loading a package.


> Thanks
> Mehrshad
> 
> -- 
> Mehrshad Barary
> Senior Lecturer in Crop Ecophysiology
> Department of Agronomy and Plant Breeding
> Faculty of Agriculture
> Ilam University
> Tel: (+98)8412227019-21
> Fax: (+98)8412227015
> 
>??????? [[alternative HTML version deleted]]

And R help is a plain-text mailing list. Please read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'?? -Gehm's Corollary to Clarke's Third Law

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    


From m_rez@||73 @end|ng |rom y@hoo@com  Thu Jul  5 10:39:40 2018
From: m_rez@||73 @end|ng |rom y@hoo@com (Maryam R)
Date: Thu, 5 Jul 2018 08:39:40 +0000 (UTC)
Subject: [R] "igraph0" package installation
References: <963992099.5316610.1530779980726.ref@mail.yahoo.com>
Message-ID: <963992099.5316610.1530779980726@mail.yahoo.com>

Hi, i want to install 'igraph0' package in R on windows 10. I downloaded "igraph0_0.5.5-1.tar" from?Index of /src/contrib/Archive/igraph0?then i try to import this package to R with this command:install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL, dependencies=TRUE)

| 
| 
|  | 
Index of /src/contrib/Archive/igraph0


 |

 |

 |


?but I face with below error. Please help me:

ERROR: compilation failed for package 'igraph0'* removing 'C:/Users/Maryam/Documents/R/win-library/3.4/igraph0'In R CMD INSTALLWarning in install.packages :? running command '"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" CMD INSTALL -l "C:\Users\Maryam\Documents\R\win-library\3.4" "C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz"' had status 1Warning in install.packages :? installation of package ?C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz? had non-zero exit status


	[[alternative HTML version deleted]]



From |or|@@bennett @end|ng |rom |u-ber||n@de  Thu Jul  5 14:13:08 2018
From: |or|@@bennett @end|ng |rom |u-ber||n@de (Loris Bennett)
Date: Thu, 05 Jul 2018 14:13:08 +0200
Subject: [R] "igraph0" package installation
In-Reply-To: <963992099.5316610.1530779980726@mail.yahoo.com> (Maryam R. via's
 message of "Thu, 5 Jul 2018 08:39:40 +0000")
References: <963992099.5316610.1530779980726.ref@mail.yahoo.com>
 <963992099.5316610.1530779980726@mail.yahoo.com>
Message-ID: <877em9zxrf.fsf@hornfels.zedat.fu-berlin.de>

Hi Maryam,

Maryam R via R-help <r-help at r-project.org> writes:

> Hi, i want to install 'igraph0' package in R on windows 10. I downloaded
> "igraph0_0.5.5-1.tar" from?Index of /src/contrib/Archive/igraph0?then i try to
> import this package to R with this
> command:install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL,
> dependencies=TRUE)

[snip (32 lines)]

You probably shouldn't be trying install 'igraph0' at all, since

  https://cran.r-project.org/web/packages/igraph0/index.html

says

  Package ?igraph0? was removed from the CRAN repository.

  Formerly available versions can be obtained from the archive.

  This was a transitional package from Mar 2012 to Sept 2013. Packages depending on it ought to have changed to igraph long ago.

  Consider using package ?igraph? instead. 

As is suggested, you should install 'igraph'.

Cheers,

Loris

-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de



From m_rez@||73 @end|ng |rom y@hoo@com  Thu Jul  5 20:01:27 2018
From: m_rez@||73 @end|ng |rom y@hoo@com (Maryam R)
Date: Thu, 5 Jul 2018 22:31:27 +0430
Subject: [R] "igraph0" package installation
References: <963992099.5316610.1530779980726@mail.yahoo.com>
Message-ID: <B9E81FDC-DC84-4759-B964-A7DD11504476@yahoo.com>

Hi, I?m maryam that ask question about  "igraph0" package installation in R-help. I thank you for your answering.  i used and install ?igraph? library in R but i faced with below error when I use this command :
results <- gspan(database)

Error: 
Error in library(igraph0) : there is no package called ?igraph0?

Sent from my iPad

Begin forwarded message:

> Hi, i want to install 'igraph0' package in R on windows 10. I downloaded "igraph0_0.5.5-1.tar" from Index of /src/contrib/Archive/igraph0 then i try to import this package to R with this command:
> install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL, dependencies=TRUE)
> 
> Index of /src/contrib/Archive/igraph0
> 
>  but I face with below error. Please help me:
> 
> ERROR: compilation failed for package 'igraph0'
> * removing 'C:/Users/Maryam/Documents/R/win-library/3.4/igraph0'
> In R CMD INSTALL
> Warning in install.packages :
>   running command '"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" CMD INSTALL -l "C:\Users\Maryam\Documents\R\win-library\3.4" "C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz"' had status 1
> Warning in install.packages :
>   installation of package ?C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz? had non-zero exit status
> 
> 

	[[alternative HTML version deleted]]



From Ad@m@Z@J@b|r @end|ng |rom out|ook@|r  Thu Jul  5 22:28:41 2018
From: Ad@m@Z@J@b|r @end|ng |rom out|ook@|r (Adam Z. Jabir)
Date: Thu, 5 Jul 2018 20:28:41 +0000
Subject: [R] command to change some vars to missing into my dataset
Message-ID: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>

Hi,

I want to simulate missing at random for my dataset. Do you know an easy way to do it?

I want to try not to have the missing?s for the same observations. I mean if one observation is been selected randomly to have missing I don?t want to have all the var of the same obs missing.

I want to be able to choose rate of missing that should be applied.

Thanks,

Adam


Envoy? ? partir de Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]



From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Jul  5 22:49:40 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 5 Jul 2018 16:49:40 -0400
Subject: [R] "igraph0" package installation
In-Reply-To: <B9E81FDC-DC84-4759-B964-A7DD11504476@yahoo.com>
References: <963992099.5316610.1530779980726@mail.yahoo.com>
 <B9E81FDC-DC84-4759-B964-A7DD11504476@yahoo.com>
Message-ID: <CAM_vjukN0oe547L53pO5XdcHBVNdM5vfR7G2TzBebeuqzrW+Tw@mail.gmail.com>

Hi,

According to https://cran.r-project.org/web/packages/igraph0/index.html
igraph0 is obsolete.

I don't know what package the gspan() function comes from, but most
likely you should update that package to the current version.

Or, if it's this issue:
https://stackoverflow.com/questions/33268708/package-igraph0-deprecated-and-hence-not-able-to-access-gspan-package

about the subgraphMining package, you may be out of luck unless you
can install development tools on your computer and build igraph0 from
source. There should be more detail about the error message than what
you've posted.

https://stackoverflow.com/questions/48255675/subgraphmining-package-not-available

Or, ideally, convince the book author to upgrade the package to use igraph.

Sarah

On Thu, Jul 5, 2018 at 2:01 PM, Maryam R via R-help
<r-help at r-project.org> wrote:
> Hi, I?m maryam that ask question about  "igraph0" package installation in R-help. I thank you for your answering.  i used and install ?igraph? library in R but i faced with below error when I use this command :
> results <- gspan(database)
>
> Error:
> Error in library(igraph0) : there is no package called ?igraph0?
>
> Sent from my iPad
>
> Begin forwarded message:
>
>> Hi, i want to install 'igraph0' package in R on windows 10. I downloaded "igraph0_0.5.5-1.tar" from Index of /src/contrib/Archive/igraph0 then i try to import this package to R with this command:
>> install.packages("~/R/igraph0_0.5.5-1.tar.gz",type="source",repos=NULL, dependencies=TRUE)
>>
>> Index of /src/contrib/Archive/igraph0
>>
>>  but I face with below error. Please help me:
>>
>> ERROR: compilation failed for package 'igraph0'
>> * removing 'C:/Users/Maryam/Documents/R/win-library/3.4/igraph0'
>> In R CMD INSTALL
>> Warning in install.packages :
>>   running command '"C:/PROGRA~1/R/R-34~1.3/bin/x64/R" CMD INSTALL -l "C:\Users\Maryam\Documents\R\win-library\3.4" "C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz"' had status 1
>> Warning in install.packages :
>>   installation of package ?C:/Users/Maryam/Documents/R/igraph0_0.5.5-1.tar.gz? had non-zero exit status
>>
>>

-- 
Sarah Goslee
http://www.functionaldiversity.org



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jul  5 23:24:54 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 5 Jul 2018 22:24:54 +0100
Subject: [R] command to change some vars to missing into my dataset
In-Reply-To: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
References: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
Message-ID: <8beea55e-0e52-4620-6439-f295f009660b@sapo.pt>

Hello,

What type of data do you have? A vector? Or is it a matrix, a 
data.frame, a list, etc?

Suppose it is a vector named x. Then you could do something like

rate <- 0.2
is.na(x) <- sample(length(x), rate*length(x))

At an R prompt type

?is.na
?sample

Hope this helps,

Rui Barradas

?s 21:28 de 05-07-2018, Adam Z. Jabir escreveu:
> Hi,
> 
> I want to simulate missing at random for my dataset. Do you know an easy way to do it?
> 
> I want to try not to have the missing?s for the same observations. I mean if one observation is been selected randomly to have missing I don?t want to have all the var of the same obs missing.
> 
> I want to be able to choose rate of missing that should be applied.
> 
> Thanks,
> 
> Adam
> 
> 
> Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From drj|m|emon @end|ng |rom gm@||@com  Fri Jul  6 00:44:25 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 6 Jul 2018 08:44:25 +1000
Subject: [R] command to change some vars to missing into my dataset
In-Reply-To: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
References: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
Message-ID: <CA+8X3fViS1wTdpn4eCdapU_PYnw4CQ=qZ6KBn-280p=pSurSdA@mail.gmail.com>

Hi Adam,
Looks like you have a matrix or data frame and want to change one or
more observations to NA. I think this will do the trick:

# assume the matrix or data frame is named "ajdat"
randomNA<-function(x,nNA=1) {
 dimx<-dim(x)
 x[sample(1:dimx[1],nNA),sample(1:dimx[2],nNA)]<-NA
 return(x)
}

So if you want three NAs inserted, call:

randomNA(ajdat,3)

Jim


On Fri, Jul 6, 2018 at 6:28 AM, Adam Z. Jabir <Adam.Z.Jabir at outlook.fr> wrote:
> Hi,
>
> I want to simulate missing at random for my dataset. Do you know an easy way to do it?
>
> I want to try not to have the missing?s for the same observations. I mean if one observation is been selected randomly to have missing I don?t want to have all the var of the same obs missing.
>
> I want to be able to choose rate of missing that should be applied.
>
> Thanks,
>
> Adam
>
>
> Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul  6 01:55:35 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Jul 2018 16:55:35 -0700
Subject: [R] command to change some vars to missing into my dataset
In-Reply-To: <CA+8X3fViS1wTdpn4eCdapU_PYnw4CQ=qZ6KBn-280p=pSurSdA@mail.gmail.com>
References: <CY4PR05MB31578177DA9EC203D2D9F88BA8400@CY4PR05MB3157.namprd05.prod.outlook.com>
 <CA+8X3fViS1wTdpn4eCdapU_PYnw4CQ=qZ6KBn-280p=pSurSdA@mail.gmail.com>
Message-ID: <CAGxFJbTByxesiSiGJa8yQshSt=D_X5D9=BwLje8JmmDQRpSG-A@mail.gmail.com>

Jim/Rui:

Strictly speaking, this is wrong. What you have described is MCAR --
missing completely at random -- not MAR. They are different! Nevertheless,
the OP seems to be similarly confused about this, so MCAR may in fact be
what what  was wanted. Without further context, it is as clear as mud to me.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 5, 2018 at 3:44 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Adam,
> Looks like you have a matrix or data frame and want to change one or
> more observations to NA. I think this will do the trick:
>
> # assume the matrix or data frame is named "ajdat"
> randomNA<-function(x,nNA=1) {
>  dimx<-dim(x)
>  x[sample(1:dimx[1],nNA),sample(1:dimx[2],nNA)]<-NA
>  return(x)
> }
>
> So if you want three NAs inserted, call:
>
> randomNA(ajdat,3)
>
> Jim
>
>
> On Fri, Jul 6, 2018 at 6:28 AM, Adam Z. Jabir <Adam.Z.Jabir at outlook.fr>
> wrote:
> > Hi,
> >
> > I want to simulate missing at random for my dataset. Do you know an easy
> way to do it?
> >
> > I want to try not to have the missing?s for the same observations. I
> mean if one observation is been selected randomly to have missing I don?t
> want to have all the var of the same obs missing.
> >
> > I want to be able to choose rate of missing that should be applied.
> >
> > Thanks,
> >
> > Adam
> >
> >
> > Envoy? ? partir de Outlook<http://aka.ms/weboutlook>
> >
> >         [[alternative HTML version deleted]]
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From d@v|dm@r|no838 @end|ng |rom gm@||@com  Fri Jul  6 07:23:55 2018
From: d@v|dm@r|no838 @end|ng |rom gm@||@com (Marino David)
Date: Fri, 6 Jul 2018 13:23:55 +0800
Subject: [R] Generate random Bernoulli draws
Message-ID: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>

Dear All,

I would like to generate N random Bernoulli draws given a probability
function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
x~U(0,2).

Can some one leave me some code lines for implementing this?

Thanks in advance.

David

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul  6 07:32:09 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 5 Jul 2018 22:32:09 -0700
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
Message-ID: <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>

Is this homework?

(There is an informal no-homework policy on this list).

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
wrote:

> Dear All,
>
> I would like to generate N random Bernoulli draws given a probability
> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
> x~U(0,2).
>
> Can some one leave me some code lines for implementing this?
>
> Thanks in advance.
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From d@v|dm@r|no838 @end|ng |rom gm@||@com  Fri Jul  6 07:35:20 2018
From: d@v|dm@r|no838 @end|ng |rom gm@||@com (Marino David)
Date: Fri, 6 Jul 2018 13:35:20 +0800
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
Message-ID: <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>

Dear Bert,

I know it is a simple question. But for me, at current, I fail to implement
it. So, I ask for help here.

It is not homework.

Best,

David

2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Is this homework?
>
> (There is an informal no-homework policy on this list).
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I would like to generate N random Bernoulli draws given a probability
>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>> x~U(0,2).
>>
>> Can some one leave me some code lines for implementing this?
>>
>> Thanks in advance.
>>
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From Ad@m@Z@J@b|r @end|ng |rom out|ook@|r  Fri Jul  6 05:56:19 2018
From: Ad@m@Z@J@b|r @end|ng |rom out|ook@|r (Adam Z. Jabir)
Date: Fri, 6 Jul 2018 03:56:19 +0000
Subject: [R] code to run a simulation
Message-ID: <CY4PR05MB31576EE09B818F3ABBA8EEB6A8470@CY4PR05MB3157.namprd05.prod.outlook.com>

Hi Guys,

I am doing some imputation for my dataset. I am looking for code to do simulation before choosing the right package (mice, Knn).  Does anyone have  some code that can do the following:

  1.  introduce some missing rate into the data
  2.  Apply the two imputaion methods
  3.  Compute RMSE and missclafication rate for the categorical variables
  4.  Repeate this 100,200 time and save the RMSE and misclassification rate.

I really appreciate your help,

Best,

Adam


Envoy? ? partir de Outlook<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Jul  6 11:37:37 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 6 Jul 2018 09:37:37 +0000
Subject: [R] progress of a function...
Message-ID: <SLXP216MB00939F7050BFEFC2CDFEDED7C8470@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I want to use svMisc package in R to check how my function is progressing.
It has the following syntax:

f <- function(x){ for (i in 1:1000){
                              progress (i)
                              s[i] <- sqrt(i)
                             }
                             return(i)
                           }

This gives me the progress of the function as i moves.

But what if I have mclapply function instead of the for loop? How do we get the progress of an ongoing "apply" family of functions?

Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From m@rc_grt @end|ng |rom y@hoo@|r  Fri Jul  6 13:20:37 2018
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Fri, 6 Jul 2018 13:20:37 +0200
Subject: [R] progress of a function...
In-Reply-To: <SLXP216MB00939F7050BFEFC2CDFEDED7C8470@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>
References: <SLXP216MB00939F7050BFEFC2CDFEDED7C8470@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>
Message-ID: <aba34713-ee91-229a-62ed-e8f064110478@yahoo.fr>

Take a look at the pbmcapply package. It does what you need.

Marc

Le 06/07/2018 ? 11:37, akshay kulkarni a ?crit?:
> dear members,
>                              I want to use svMisc package in R to check how my function is progressing.
> It has the following syntax:
>
> f <- function(x){ for (i in 1:1000){
>                                progress (i)
>                                s[i] <- sqrt(i)
>                               }
>                               return(i)
>                             }
>
> This gives me the progress of the function as i moves.
>
> But what if I have mclapply function instead of the for loop? How do we get the progress of an ongoing "apply" family of functions?
>
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From btupper @end|ng |rom b|ge|ow@org  Fri Jul  6 13:33:52 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Fri, 6 Jul 2018 07:33:52 -0400
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
Message-ID: <224061B5-63E8-438C-A1D8-30BCA76709A4@bigelow.org>

Hi,

I haven't any idea about what you ask, but I do know that Rseek.org <http://rseek.org/> is a gold mine!  Check out...

https://rseek.org/?q=Bernoulli+random+variable <https://rseek.org/?q=Bernoulli+random+variable>

Cheers,
Ben

> On Jul 6, 2018, at 1:35 AM, Marino David <davidmarino838 at gmail.com> wrote:
> 
> Dear Bert,
> 
> I know it is a simple question. But for me, at current, I fail to implement
> it. So, I ask for help here.
> 
> It is not homework.
> 
> Best,
> 
> David
> 
> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
> 
>> Is this homework?
>> 
>> (There is an informal no-homework policy on this list).
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>> wrote:
>> 
>>> Dear All,
>>> 
>>> I would like to generate N random Bernoulli draws given a probability
>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>> x~U(0,2).
>>> 
>>> Can some one leave me some code lines for implementing this?
>>> 
>>> Thanks in advance.
>>> 
>>> David
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From d@v|dm@r|no838 @end|ng |rom gm@||@com  Fri Jul  6 14:23:16 2018
From: d@v|dm@r|no838 @end|ng |rom gm@||@com (Marino David)
Date: Fri, 6 Jul 2018 20:23:16 +0800
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <224061B5-63E8-438C-A1D8-30BCA76709A4@bigelow.org>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <224061B5-63E8-438C-A1D8-30BCA76709A4@bigelow.org>
Message-ID: <CABmD0bGxUmgJC0QrFKvBWeO78F1gPnyD5jrjURv61SgFvWYhGA@mail.gmail.com>

Dear Ben,

Thanks a lot for your reply.

Best,

David

2018-07-06 19:33 GMT+08:00 Ben Tupper <btupper at bigelow.org>:

> Hi,
>
> I haven't any idea about what you ask, but I do know that Rseek.org is a
> gold mine!  Check out...
>
> https://rseek.org/?q=Bernoulli+random+variable
>
> Cheers,
> Ben
>
> On Jul 6, 2018, at 1:35 AM, Marino David <davidmarino838 at gmail.com> wrote:
>
> Dear Bert,
>
> I know it is a simple question. But for me, at current, I fail to implement
> it. So, I ask for help here.
>
> It is not homework.
>
> Best,
>
> David
>
> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>
> Is this homework?
>
> (There is an informal no-homework policy on this list).
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
> wrote:
>
> Dear All,
>
> I would like to generate N random Bernoulli draws given a probability
> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
> x~U(0,2).
>
> Can some one leave me some code lines for implementing this?
>
> Thanks in advance.
>
> David
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive
> <https://maps.google.com/?q=60+Bigelow+Drive&entry=gmail&source=g>, P.O.
> Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>
>

	[[alternative HTML version deleted]]



From jenny@||u00 @end|ng |rom gm@||@com  Fri Jul  6 16:29:18 2018
From: jenny@||u00 @end|ng |rom gm@||@com (Jenny Liu)
Date: Fri, 06 Jul 2018 14:29:18 +0000
Subject: [R] Do there need to be the same number of y-values for each
 x-value when using tapply?
Message-ID: <bcb629c9-1b21-3e63-e462-c9c588ca20dc@mixmax.com>

Hi everyone,
I'm trying to fit a set of data to a non-linear distribution?(namely, rates of
insect development at different temperatures), and I'm?trying to do this using
the selfStart and GetInitial functions. (I'd of course be open to alternative
suggestions!). However, I?keep running into this error:

Error in tapply(y, x, mean, na.rm = TRUE) :
arguments must have same length

I created a post on stackoverflow that includes the data and my code, and a
more in-depth explanation. I would be grateful if someone could have a look
and let me know where I'm going wrong!

https://stackoverflow.com/questions/51119314/using-tapply-when-you-have-different-n-for-each-treatment


Thanks very much,
Jenny
	[[alternative HTML version deleted]]



From ccberry @end|ng |rom uc@d@edu  Fri Jul  6 19:18:58 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Fri, 6 Jul 2018 17:18:58 +0000
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
Message-ID: <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>

A liitle math goes along way. See below.

> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
> 
> Dear Bert,
> 
> I know it is a simple question. But for me, at current, I fail to implement
> it. So, I ask for help here.
> 
> It is not homework.
> 
> Best,
> 
> David
> 
> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
> 
>> Is this homework?
>> 
>> (There is an informal no-homework policy on this list).
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>> wrote:
>> 
>>> Dear All,
>>> 
>>> I would like to generate N random Bernoulli draws given a probability
>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>> x~U(0,2).

If each Bernoulli draw is based on its own draw of x, then

	rbinom( N, 1, 0.8013476 )

is what you want.

It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps, 

	?integrate

will help.

But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of  the prob argument.

HTH,

Chuck


>>> 
>>> Can some one leave me some code lines for implementing this?
>>> 
>>> Thanks in advance.
>>> 
>>> David
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 



From gor@n@bro@trom @end|ng |rom umu@@e  Fri Jul  6 23:10:41 2018
From: gor@n@bro@trom @end|ng |rom umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Fri, 6 Jul 2018 23:10:41 +0200
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
Message-ID: <3686d88e-d581-ad1f-8269-28be04c569b2@umu.se>



On 2018-07-06 19:18, Berry, Charles wrote:
> A liitle math goes along way. See below.
> 
>> On Jul 5, 2018, at 10:35 PM, Marino David
>> <davidmarino838 at gmail.com> wrote:
>> 
>> Dear Bert,
>> 
>> I know it is a simple question. But for me, at current, I fail to
>> implement it. So, I ask for help here.
>> 
>> It is not homework.
>> 
>> Best,
>> 
>> David
>> 
>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>> 
>>> Is this homework?
>>> 
>>> (There is an informal no-homework policy on this list).
>>> 
>>> Cheers, Bert
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming
>>> along and sticking things into it." -- Opus (aka Berkeley
>>> Breathed in his "Bloom County" comic strip )
>>> 
>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David
>>> <davidmarino838 at gmail.com> wrote:
>>> 
>>>> Dear All,
>>>> 
>>>> I would like to generate N random Bernoulli draws given a
>>>> probability function F(x)=1-exp(-2.5*x) in which x follows
>>>> uniform distribution, say x~U(0,2).
> 
> If each Bernoulli draw is based on its own draw of x, then
> 
> rbinom( N, 1, 0.8013476 )
> 
> is what you want.

Maybe it is what he wants, but note that F(x) as defined is a random 
variable, not a (cumulative) probability function.

G,

> 
> It is left as an exercise for the reader to verify that the constant
> 0.8013476 is correct up to approximation error, and to prove that
> such a Bernoulli mixture is also Bernoulli. Perhaps,
> 
> ?integrate
> 
> will help.
> 
> But if the x's are shared you need to use runif, expm1, and
> (possibly) rep to produce a vector to be used in place of  the prob
> argument.
> 
> HTH,
> 
> Chuck
> 
> 
>>>> 
>>>> Can some one leave me some code lines for implementing this?
>>>> 
>>>> Thanks in advance.
>>>> 
>>>> David
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________ 
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>> see https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read
>>>> the posting guide http://www.R-project.org/posti ng-guide.html 
>>>> and provide commented, minimal, self-contained, reproducible
>>>> code.
>>>> 
>>> 
>>> 
>> 
>> [[alternative HTML version deleted]]
>> 
> 
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and provide
> commented, minimal, self-contained, reproducible code.
>



From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jul  7 00:31:39 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 6 Jul 2018 18:31:39 -0400
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
Message-ID: <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>

On 06/07/2018 1:18 PM, Berry, Charles wrote:
> A liitle math goes along way. See below.
> 
>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
>>
>> Dear Bert,
>>
>> I know it is a simple question. But for me, at current, I fail to implement
>> it. So, I ask for help here.
>>
>> It is not homework.
>>
>> Best,
>>
>> David
>>
>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>
>>> Is this homework?
>>>
>>> (There is an informal no-homework policy on this list).
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>>> wrote:
>>>
>>>> Dear All,
>>>>
>>>> I would like to generate N random Bernoulli draws given a probability
>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>>> x~U(0,2).
> 
> If each Bernoulli draw is based on its own draw of x, then
> 
> 	rbinom( N, 1, 0.8013476 )
> 
> is what you want.
> 
> It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps,
> 
> 	?integrate
> 
> will help.
> 
> But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of  the prob argument.

That may be correct from a mathematical perspective (I haven't checked), 
but seems like a *really* bad idea from a programming perspective.  It 
would be much better to write

x <- runif(N, 0, 2)
rbinom(N, 1, 1 - exp(-2.5*x))

because it is so much more clearly related to the original problem 
statement.  Perhaps it would be a few microseconds slower, but that 
would be saved many times over when any aspect of the problem statement 
was modified.

Duncan Murdoch

> 
> HTH,
> 
> Chuck
> 
> 
>>>>
>>>> Can some one leave me some code lines for implementing this?
>>>>
>>>> Thanks in advance.
>>>>
>>>> David
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ccberry @end|ng |rom uc@d@edu  Sat Jul  7 01:27:04 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Fri, 6 Jul 2018 23:27:04 +0000
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
 <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
Message-ID: <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>



> On Jul 6, 2018, at 3:31 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 06/07/2018 1:18 PM, Berry, Charles wrote:
>> A liitle math goes along way. See below.
>>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
>>> 
>>> Dear Bert,
>>> 
>>> I know it is a simple question. But for me, at current, I fail to implement
>>> it. So, I ask for help here.
>>> 
>>> It is not homework.
>>> 
>>> Best,
>>> 
>>> David
>>> 
>>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>> 
>>>> Is this homework?
>>>> 
>>>> (There is an informal no-homework policy on this list).
>>>> 
>>>> Cheers,
>>>> Bert
>>>> 
>>>> 
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along and
>>>> sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>>>> wrote:
>>>> 
>>>>> Dear All,
>>>>> 
>>>>> I would like to generate N random Bernoulli draws given a probability
>>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>>>> x~U(0,2).
>> If each Bernoulli draw is based on its own draw of x, then
>> 	rbinom( N, 1, 0.8013476 )
>> is what you want.
>> It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps,
>> 	?integrate
>> will help.
>> But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of the prob argument.
> 
> That may be correct from a mathematical perspective (I haven't checked), but seems like a *really* bad idea from a programming perspective.  It would be much better to write

Well of course it would.  I was hoping that my somewhat obscure one-liner would suggest


> 
> x <- runif(N, 0, 2)
> rbinom(N, 1, 1 - exp(-2.5*x))
> 
> because it is so much more clearly related to the original problem statement.  Perhaps it would be a few microseconds slower, but that would be saved many times over when any aspect of the problem statement was modified.
> 
> Duncan Murdoch
> 
>> HTH,
>> Chuck
>>>>> 
>>>>> Can some one leave me some code lines for implementing this?
>>>>> 
>>>>> Thanks in advance.
>>>>> 
>>>>> David
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>>> ng-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From ccberry @end|ng |rom uc@d@edu  Sat Jul  7 01:30:22 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Fri, 6 Jul 2018 23:30:22 +0000
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
 <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
 <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>
Message-ID: <85D59BB4-1413-4AA3-BED2-964843C3F848@ucsd.edu>

Sorry about the last incomplete post. Accidentally hit send.

Meant to say that I was hoping that a correct, but  obscure response from me would motivate David to step back and think about his problem long enough to see that it has an easy solution.

Sorry if that was out-of-line.

Chuck

> On Jul 6, 2018, at 4:27 PM, Charles Berry <ccberry at ucsd.edu> wrote:
> 
>> On Jul 6, 2018, at 3:31 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 06/07/2018 1:18 PM, Berry, Charles wrote:
>>> A liitle math goes along way. See below.
>>>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com> wrote:
>>>> 
>>>> Dear Bert,
>>>> 
>>>> I know it is a simple question. But for me, at current, I fail to implement
>>>> it. So, I ask for help here.
>>>> 
>>>> It is not homework.
>>>> 
>>>> Best,
>>>> 
>>>> David
>>>> 
>>>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
>>>> 
>>>>> Is this homework?
>>>>> 
>>>>> (There is an informal no-homework policy on this list).
>>>>> 
>>>>> Cheers,
>>>>> Bert
>>>>> 
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming along and
>>>>> sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <davidmarino838 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>>> Dear All,
>>>>>> 
>>>>>> I would like to generate N random Bernoulli draws given a probability
>>>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform distribution, say
>>>>>> x~U(0,2).
>>> If each Bernoulli draw is based on its own draw of x, then
>>> 	rbinom( N, 1, 0.8013476 )
>>> is what you want.
>>> It is left as an exercise for the reader to verify that the constant 0.8013476 is correct up to approximation error, and to prove that such a Bernoulli mixture is also Bernoulli. Perhaps,
>>> 	?integrate
>>> will help.
>>> But if the x's are shared you need to use runif, expm1, and (possibly) rep to produce a vector to be used in place of the prob argument.
> 



From t@n@@@ @end|ng |rom gm@||@com  Sat Jul  7 01:32:41 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 6 Jul 2018 16:32:41 -0700
Subject: [R] about ECDF display in ggplot2
Message-ID: <CA+JEM018t9qtbB4rCtiMh6vZ5MR0YNPnCN7TkpiOELGa1GtC8A@mail.gmail.com>

Dear all,

I would appreciate having your advice/suggestions/comments on the following
:

1 -- starting from a vector that contains LENGTHS (numerically, the values
are from 1 to 10 000)

2 -- shall I display the ECDF by using the R code and some "limits" :

BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
           1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)

ggplot(x, aes(LENGTH)) +
          stat_ecdf(geom = "point") +
          scale_x_continuous(name = "LENGTH of DEL",
                             breaks = BREAKS,
                             limits=c(0, 500))

3 -- I am getting the following warning message : "Warning message: Removed
109 rows containing non-finite values (stat_ecdf)."

The question is : are these 109 values removed from VISUALIZATION as i set
up the "limits", or are these 109 values removed from statistical
CALCULATION?

4 -- in contrast, shall I use the standard R functions plot(ecdf), there is
no "warning mesage"

plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
                     ylab="Fraction of DEL", main="DEL", xlim=c(0,500),
                     col = "dark red")

Thanks a lot !

-- bogdan

	[[alternative HTML version deleted]]



From d@v|dm@r|no838 @end|ng |rom gm@||@com  Sat Jul  7 04:26:20 2018
From: d@v|dm@r|no838 @end|ng |rom gm@||@com (Marino David)
Date: Sat, 7 Jul 2018 10:26:20 +0800
Subject: [R] Generate random Bernoulli draws
In-Reply-To: <85D59BB4-1413-4AA3-BED2-964843C3F848@ucsd.edu>
References: <CABmD0bHbNku8_4Xc0NoGcP2dT6=aG3bW-E4f0tdW23QRdho_Kg@mail.gmail.com>
 <CAGxFJbTic2RgNDhxUxM-9ojgoM8pJVVxmTgyivFQbverbo=TMg@mail.gmail.com>
 <CABmD0bHwHUCZ9sft2OCTZG9mFcWx0mmg1pH9hqe_W7O4Z7zYrw@mail.gmail.com>
 <D67E14AA-658C-4B4E-9187-4E38AFDFFD38@ucsd.edu>
 <8cc48855-0286-d2df-9ae1-14522c4aa4a8@gmail.com>
 <9A63BA16-4582-43A8-8498-4AB5E8BD019A@ucsd.edu>
 <85D59BB4-1413-4AA3-BED2-964843C3F848@ucsd.edu>
Message-ID: <CABmD0bGwmZVrgpChr8jsa=Z22cgt2BcUE10XB5iUGvSZqCz86Q@mail.gmail.com>

Hi Chuck and all,

Thanks for your response. It is really helpful for me.

David

2018-07-07 7:30 GMT+08:00 Berry, Charles <ccberry at ucsd.edu>:

> Sorry about the last incomplete post. Accidentally hit send.
>
> Meant to say that I was hoping that a correct, but  obscure response from
> me would motivate David to step back and think about his problem long
> enough to see that it has an easy solution.
>
> Sorry if that was out-of-line.
>
> Chuck
>
> > On Jul 6, 2018, at 4:27 PM, Charles Berry <ccberry at ucsd.edu> wrote:
> >
> >> On Jul 6, 2018, at 3:31 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> >>
> >> On 06/07/2018 1:18 PM, Berry, Charles wrote:
> >>> A liitle math goes along way. See below.
> >>>> On Jul 5, 2018, at 10:35 PM, Marino David <davidmarino838 at gmail.com>
> wrote:
> >>>>
> >>>> Dear Bert,
> >>>>
> >>>> I know it is a simple question. But for me, at current, I fail to
> implement
> >>>> it. So, I ask for help here.
> >>>>
> >>>> It is not homework.
> >>>>
> >>>> Best,
> >>>>
> >>>> David
> >>>>
> >>>> 2018-07-06 13:32 GMT+08:00 Bert Gunter <bgunter.4567 at gmail.com>:
> >>>>
> >>>>> Is this homework?
> >>>>>
> >>>>> (There is an informal no-homework policy on this list).
> >>>>>
> >>>>> Cheers,
> >>>>> Bert
> >>>>>
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming
> along and
> >>>>> sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>> On Thu, Jul 5, 2018 at 10:23 PM, Marino David <
> davidmarino838 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> Dear All,
> >>>>>>
> >>>>>> I would like to generate N random Bernoulli draws given a
> probability
> >>>>>> function F(x)=1-exp(-2.5*x) in which x follows  uniform
> distribution, say
> >>>>>> x~U(0,2).
> >>> If each Bernoulli draw is based on its own draw of x, then
> >>>     rbinom( N, 1, 0.8013476 )
> >>> is what you want.
> >>> It is left as an exercise for the reader to verify that the constant
> 0.8013476 is correct up to approximation error, and to prove that such a
> Bernoulli mixture is also Bernoulli. Perhaps,
> >>>     ?integrate
> >>> will help.
> >>> But if the x's are shared you need to use runif, expm1, and (possibly)
> rep to produce a vector to be used in place of the prob argument.
> >
>
>
>

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sat Jul  7 11:42:29 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sat, 7 Jul 2018 09:42:29 +0000
Subject: [R] pbmclapply is very much faster than mclapply....
Message-ID: <SL2P216MB0091654E0BF030373FB387A3C8460@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am using pbmclapply function to check the progress of my functions that is to be run in parallel (with function mclapply).

To my amazement, I found out that pbmclapply is more than 3X faster than mclapply!!!

Any idea on why this is so?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From @xe|@urb|z @end|ng |rom gm@||@com  Sat Jul  7 21:53:50 2018
From: @xe|@urb|z @end|ng |rom gm@||@com (Axel Urbiz)
Date: Sat, 7 Jul 2018 15:53:50 -0400
Subject: [R] Spatial Clustering with spdep::skater
Message-ID: <A7ABCFB3-B84E-41AF-9562-ECCFD14C9AC6@gmail.com>

Dear Experts,

I?m working with spdep::skater to fit clusters to spatial data subject to contiguity constraints. This function fits clusters by edge removal from Minimum Spanning Trees. 

In this context, I?d appreciate any pointers on how to tune the number of clusters. What is a sensible criteria to use?

Thanks
Axel.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul  8 06:47:43 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Jul 2018 21:47:43 -0700
Subject: [R] about ECDF display in ggplot2
In-Reply-To: <CA+JEM018t9qtbB4rCtiMh6vZ5MR0YNPnCN7TkpiOELGa1GtC8A@mail.gmail.com>
References: <CA+JEM018t9qtbB4rCtiMh6vZ5MR0YNPnCN7TkpiOELGa1GtC8A@mail.gmail.com>
Message-ID: <DA6461D3-8686-40C5-8F43-CD195BE35501@dcn.davis.ca.us>

It is a feature of ggplot that points excluded by limits raise warnings, while base graphics do not.

You may find that using coord_cartesian with the xlim=c(0,500) argument works better with ggplot by showing the consequences of points out of the limits on lines within the viewport.

There are other possible problems with your data that your non-reproducible example does not show, and sending R code in HTML-formatted email usually corrupts it.. so please follow the recommendations in the Posting Guide next time you post.

On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear all,
>
>I would appreciate having your advice/suggestions/comments on the
>following
>:
>
>1 -- starting from a vector that contains LENGTHS (numerically, the
>values
>are from 1 to 10 000)
>
>2 -- shall I display the ECDF by using the R code and some "limits" :
>
>BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400,
>500,
>         1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
>
>ggplot(x, aes(LENGTH)) +
>          stat_ecdf(geom = "point") +
>          scale_x_continuous(name = "LENGTH of DEL",
>                             breaks = BREAKS,
>                             limits=c(0, 500))
>
>3 -- I am getting the following warning message : "Warning message:
>Removed
>109 rows containing non-finite values (stat_ecdf)."
>
>The question is : are these 109 values removed from VISUALIZATION as i
>set
>up the "limits", or are these 109 values removed from statistical
>CALCULATION?
>
>4 -- in contrast, shall I use the standard R functions plot(ecdf),
>there is
>no "warning mesage"
>
>plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
>                     ylab="Fraction of DEL", main="DEL", xlim=c(0,500),
>                     col = "dark red")
>
>Thanks a lot !
>
>-- bogdan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul  8 06:53:24 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Jul 2018 21:53:24 -0700
Subject: [R] Spatial Clustering with spdep::skater
In-Reply-To: <A7ABCFB3-B84E-41AF-9562-ECCFD14C9AC6@gmail.com>
References: <A7ABCFB3-B84E-41AF-9562-ECCFD14C9AC6@gmail.com>
Message-ID: <CAGxFJbS3_U8ib2VDbz+ztzT++tmZBPhA=H05hCZwH+3pS5-MaQ@mail.gmail.com>

Generally, statistical questions are off topic for this list, which is
about R programming; but the r-sig-geo list would seem to be a better place
to post this anyway, as the expertise you seek is much more likely there.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jul 7, 2018 at 12:53 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Dear Experts,
>
> I?m working with spdep::skater to fit clusters to spatial data subject to
> contiguity constraints. This function fits clusters by edge removal from
> Minimum Spanning Trees.
>
> In this context, I?d appreciate any pointers on how to tune the number of
> clusters. What is a sensible criteria to use?
>
> Thanks
> Axel.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @orenh @end|ng |rom m@th@@@u@dk  Sun Jul  8 10:41:43 2018
From: @orenh @end|ng |rom m@th@@@u@dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 8 Jul 2018 08:41:43 +0000
Subject: [R] consider running tools::compactPDF(gs_quality = "ebook")
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C3012A64C771@AD-EXCHMBX3-3.aau.dk>

Dear all,

I run

R CMD build --compact-vignettes="both"  gRbase

and/or

R CMD build --compact-vignettes="gs+qpdf"  gRbase

and in the log from r-devel (on winbuilder) I get

* checking sizes of PDF files under 'inst/doc' ... WARNING
  'gs+qpdf' made some significant size reductions:
     compacted 'gRbase-arrays.pdf' from 421Kb to 115Kb
  consider running tools::compactPDF(gs_quality = "ebook") on these files

According to "writing R extensions" things should be fine (I have gs and qpdf on my system):

"The --compact-vignettes option will run tools::compactPDF over the PDF files in inst/doc (and its subdirectories) to losslessly compress them. This is not enabled by default (it can be selected by environment variable _R_BUILD_COMPACT_VIGNETTES_) and needs qpdf (http://qpdf.sourceforge.net/) to be available. "

Can anyone please tell me what to do?

Best regards
S?ren 

---

> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.4 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] Rcpp_0.12.17    shtools_1.0     markdown_0.8    knitr_1.20     
[5] rmarkdown_1.10  devtools_1.13.5

loaded via a namespace (and not attached):
 [1] lattice_0.20-35         digest_0.6.15           withr_2.1.2            
 [4] rprojroot_1.3-2         grid_3.4.4              backports_1.1.2        
 [7] magrittr_1.5            evaluate_0.10.1         stringi_1.2.3          
[10] curl_3.2                RcppArmadillo_0.8.500.0 Matrix_1.2-14          
[13] tools_3.4.4             RcppEigen_0.3.3.4.0     stringr_1.3.1          
[16] compiler_3.4.4          memoise_1.1.0           htmltools_0.3.6




From c@t@||nro|bu @end|ng |rom gm@||@com  Sun Jul  8 10:44:54 2018
From: c@t@||nro|bu @end|ng |rom gm@||@com (catalin roibu)
Date: Sun, 8 Jul 2018 11:44:54 +0300
Subject: [R] replicate rows
Message-ID: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>

Dear R users,

I want to replicate sampled rows in data frame. The sampling results must
be in this form:

  a   b     Rep
[1,] 3 4.0 R1
[2,] 6 8.0 R1
[3,] 1 0.1 R2
[4,] 6 8.0 R2
[5,] 1 0.1 R3
[6,] 5 7.0 R3

I have a code but I didn't succeed to insert to rep column.

This is my code:
a<-c(1,2,3,4,5,6)
b<-c(0.1, 0.2, 4, 6, 7, 8)
ab<-cbind(a, b)
x<-replicate(3, sample(1:nrow(ab), 2))
aa<-ab[x, ]

Please help me to solve that problem!

Thank you very much!

Best regards!

Catalin

-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Sun Jul  8 11:51:29 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 8 Jul 2018 12:51:29 +0300
Subject: [R] replicate rows
In-Reply-To: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>
References: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>
Message-ID: <CAGgJW76a-6LFXRbDUVgO7JgHNzoDNFRqBmm8Kw=5quk2pwsEQQ@mail.gmail.com>

Hi Catalin,

This should work. I set the number of repetitions and sample sizes as
variables so it would be clear how to modify for your actual case.

nreps    <- 3
sampSize <- 2
w <- unlist( lapply(1:nreps, function(i) {
rep(paste("R",i,sep=""),sampSize) } ) )
aa2 <- cbind( as.data.frame(aa), w)

HTH,
Eric


On Sun, Jul 8, 2018 at 11:44 AM, catalin roibu <catalinroibu at gmail.com>
wrote:

> Dear R users,
>
> I want to replicate sampled rows in data frame. The sampling results must
> be in this form:
>
>   a   b     Rep
> [1,] 3 4.0 R1
> [2,] 6 8.0 R1
> [3,] 1 0.1 R2
> [4,] 6 8.0 R2
> [5,] 1 0.1 R3
> [6,] 5 7.0 R3
>
> I have a code but I didn't succeed to insert to rep column.
>
> This is my code:
> a<-c(1,2,3,4,5,6)
> b<-c(0.1, 0.2, 4, 6, 7, 8)
> ab<-cbind(a, b)
> x<-replicate(3, sample(1:nrow(ab), 2))
> aa<-ab[x, ]
>
> Please help me to solve that problem!
>
> Thank you very much!
>
> Best regards!
>
> Catalin
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Jul  8 14:28:27 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 8 Jul 2018 12:28:27 +0000
Subject: [R] inconsistency in display of character vector....
Message-ID: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I have the following code to update the list of stocks:

function (snlcqn)
{
                  lneq <- c()
                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
                  file.string <- tempfile()

                  download.file(URL,file.string)

                  IDT <- read_excel(file.string)

                  leq <- IDT[,1]

                  for(i in 1:length(leq)){
                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}

                  for(j in 1:length(lneq)){
                  snlcqna[j] <- paste("NSE/",lneq[j])}

                  if(identical(snlcqn,snlcqna) == "FALSE"){
                  return(snlcqna)                         }

                  else                                    {
                  return(snlcqn)                          }

}
snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):

[192] "NSE/YESBANK"
[193] "NSE/ZEEL"

Why is this happening? How can I get the return object as a contiguous list?
Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sun Jul  8 14:37:33 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sun, 8 Jul 2018 12:37:33 +0000
Subject: [R] Fw: inconsistency in display of character vector....
In-Reply-To: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             The mail is not showing the spaces between [192] "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the two.....!!!!!!

________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni <akshay_e4 at hotmail.com>
Sent: Sunday, July 8, 2018 5:58 PM
To: R help Mailing  list
Subject: [R] inconsistency in display of character vector....

dear members,
                            I have the following code to update the list of stocks:

function (snlcqn)
{
                  lneq <- c()
                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
                  file.string <- tempfile()

                  download.file(URL,file.string)

                  IDT <- read_excel(file.string)

                  leq <- IDT[,1]

                  for(i in 1:length(leq)){
                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}

                  for(j in 1:length(lneq)){
                  snlcqna[j] <- paste("NSE/",lneq[j])}

                  if(identical(snlcqn,snlcqna) == "FALSE"){
                  return(snlcqna)                         }

                  else                                    {
                  return(snlcqn)                          }

}
snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):

[192] "NSE/YESBANK"
[193] "NSE/ZEEL"

Why is this happening? How can I get the return object as a contiguous list?
Very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From btupper @end|ng |rom b|ge|ow@org  Sun Jul  8 15:48:48 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Sun, 8 Jul 2018 09:48:48 -0400
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <5B49E856-EC41-4C1C-BEAE-8728503937AB@bigelow.org>

Hi,

You will be hard pressed to get helpful answers as you have not provided any way for list readers to replicate your data and code.  Check out this https://rseek.org/?q=reproducible+example

On the other hand, ...

(1)  I have a hunch that one place you are getting tripped up by your effort to treat IDT as a regular data.frame.  In fact, read_excel(), I'm guessing from the readxl package, returns a tibble.  When you subset a tibble like you have with...

leq <- IDT[,1]

... you get a 1-column tibble...

> leq
# A tibble: 208 x 1
   SymbolSeries
   <chr>       
 1 ACCEQ       
 2 ADANIENTEQ  
 3 ADANIPORTSEQ
 4 ADANIPOWEREQ
 5 AJANTPHARMEQ
 6 ALBKEQ      
 7 AMARAJABATEQ
 8 AMBUJACEMEQ 
 9 ANDHRABANKEQ
10 APOLLOHOSPEQ
# ... with 198 more rows

So, that may be part of the issue (but I'm not really sure if it causes the problem you identify).

(2) Also another possible tripping point, when you prepend 'NSE/' to whatever lneq is supposed to be, you are using paste() without specifying the sep argument which defaults to a single space " ".  If you want it to be something else then you have to explicitly set the value of sep.

(3) Finally, you will have much better luck getting help if you configure your email client to send plain text to this list.  Fancily formatted text is made un-fancy by the list-server software - which will mess up your posted code.  That's why you keep getting ...

[[alternative HTML version deleted]]

... at the tail end of your emails.


Good luck!
Ben

> On Jul 8, 2018, at 8:37 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> dear members,
>                             The mail is not showing the spaces between [192] "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the two.....!!!!!!
> 
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni <akshay_e4 at hotmail.com>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
> 
> dear members,
>                            I have the following code to update the list of stocks:
> 
> function (snlcqn)
> {
>                  lneq <- c()
>                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                  file.string <- tempfile()
> 
>                  download.file(URL,file.string)
> 
>                  IDT <- read_excel(file.string)
> 
>                  leq <- IDT[,1]
> 
>                  for(i in 1:length(leq)){
>                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> 
>                  for(j in 1:length(lneq)){
>                  snlcqna[j] <- paste("NSE/",lneq[j])}
> 
>                  if(identical(snlcqn,snlcqna) == "FALSE"){
>                  return(snlcqna)                         }
> 
>                  else                                    {
>                  return(snlcqn)                          }
> 
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):
> 
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
> 
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul  8 16:30:05 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 08 Jul 2018 07:30:05 -0700
Subject: [R] Fw: inconsistency in display of character vector....
In-Reply-To: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <7F13FE71-A76B-4A0A-8132-6645659BD2E1@dcn.davis.ca.us>

Using dput and sending your questions with the plain text option as described in [1] will allow you to share your data with less ambiguity. To be sure you have supplied all the code needed for us to reproduce your problem, use [3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 

On July 8, 2018 5:37:33 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>The mail is not showing the spaces between [192] "NSE/YESBANK" and 
>[193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the
>two.....!!!!!!
>
>________________________________________
>From: R-help <r-help-bounces at r-project.org> on behalf of akshay
>kulkarni <akshay_e4 at hotmail.com>
>Sent: Sunday, July 8, 2018 5:58 PM
>To: R help Mailing  list
>Subject: [R] inconsistency in display of character vector....
>
>dear members,
>                I have the following code to update the list of stocks:
>
>function (snlcqn)
>{
>                  lneq <- c()
>                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                  file.string <- tempfile()
>
>                  download.file(URL,file.string)
>
>                  IDT <- read_excel(file.string)
>
>                  leq <- IDT[,1]
>
>                  for(i in 1:length(leq)){
>                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
>
>                  for(j in 1:length(lneq)){
>                  snlcqna[j] <- paste("NSE/",lneq[j])}
>
>                  if(identical(snlcqn,snlcqna) == "FALSE"){
>                  return(snlcqna)                         }
>
>                  else                                    {
>                  return(snlcqn)                          }
>
>}
>snlcqn is the list of present stocks and snlcqna is the list of updated
>stocks.
>The problem is the return object, instead of getting displayed in
>contiguous list, is getting displayed with lots of spaces...( I am
>using R on a LINUX RHEL AWS instance):
>
>[192] "NSE/YESBANK"
>[193] "NSE/ZEEL"
>
>Why is this happening? How can I get the return object as a contiguous
>list?
>Very many thanks for your time and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>        [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul  8 16:40:09 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 8 Jul 2018 07:40:09 -0700
Subject: [R] consider running tools::compactPDF(gs_quality = "ebook")
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C3012A64C771@AD-EXCHMBX3-3.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C3012A64C771@AD-EXCHMBX3-3.aau.dk>
Message-ID: <CAGxFJbRBPGmt9NLdZs-k_9_X-r92Evrh1jE5+5UG=-Q+oA3ziQ@mail.gmail.com>

I believe R-package-devel is the right place to post this, not r-help. See
https://www.r-project.org/mail.html  for details.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jul 8, 2018 at 1:41 AM, S?ren H?jsgaard <sorenh at math.aau.dk> wrote:

> Dear all,
>
> I run
>
> R CMD build --compact-vignettes="both"  gRbase
>
> and/or
>
> R CMD build --compact-vignettes="gs+qpdf"  gRbase
>
> and in the log from r-devel (on winbuilder) I get
>
> * checking sizes of PDF files under 'inst/doc' ... WARNING
>   'gs+qpdf' made some significant size reductions:
>      compacted 'gRbase-arrays.pdf' from 421Kb to 115Kb
>   consider running tools::compactPDF(gs_quality = "ebook") on these files
>
> According to "writing R extensions" things should be fine (I have gs and
> qpdf on my system):
>
> "The --compact-vignettes option will run tools::compactPDF over the PDF
> files in inst/doc (and its subdirectories) to losslessly compress them.
> This is not enabled by default (it can be selected by environment variable
> _R_BUILD_COMPACT_VIGNETTES_) and needs qpdf (http://qpdf.sourceforge.net/)
> to be available. "
>
> Can anyone please tell me what to do?
>
> Best regards
> S?ren
>
> ---
>
> > sessionInfo()
> R version 3.4.4 (2018-03-15)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.4 LTS
>
> Matrix products: default
> BLAS: /usr/lib/libblas/libblas.so.3.6.0
> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] Rcpp_0.12.17    shtools_1.0     markdown_0.8    knitr_1.20
> [5] rmarkdown_1.10  devtools_1.13.5
>
> loaded via a namespace (and not attached):
>  [1] lattice_0.20-35         digest_0.6.15           withr_2.1.2
>
>  [4] rprojroot_1.3-2         grid_3.4.4              backports_1.1.2
>
>  [7] magrittr_1.5            evaluate_0.10.1         stringi_1.2.3
>
> [10] curl_3.2                RcppArmadillo_0.8.500.0 Matrix_1.2-14
>
> [13] tools_3.4.4             RcppEigen_0.3.3.4.0     stringr_1.3.1
>
> [16] compiler_3.4.4          memoise_1.1.0           htmltools_0.3.6
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From |@r@h@d@|@th|@n @end|ng |rom gm@||@com  Sun Jul  8 16:08:53 2018
From: |@r@h@d@|@th|@n @end|ng |rom gm@||@com (Farshad Fathian)
Date: Sun, 8 Jul 2018 18:38:53 +0430
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
Message-ID: <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>

Dear all,

Hello,



I am going to install the ?RWinEdt? package on R software. I had installed
it on R before, but when I downloaded the newest versions of R software
(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.

Please help and guide me to know how I can install and use the ?RWinEdt?
properly.



Look forward to hearing from you.



Best regards,


-- 

Farshad Fathian


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
07/07/18,
10:19:25 PM

	[[alternative HTML version deleted]]



From mm@ech|er @end|ng |rom gm@||@com  Sun Jul  8 09:54:30 2018
From: mm@ech|er @end|ng |rom gm@||@com (Martin Maechler)
Date: Sun, 8 Jul 2018 17:54:30 +1000
Subject: [R] Do there need to be the same number of y-values for each
 x-value when using tapply?
In-Reply-To: <bcb629c9-1b21-3e63-e462-c9c588ca20dc@mixmax.com>
References: <bcb629c9-1b21-3e63-e462-c9c588ca20dc@mixmax.com>
Message-ID: <CAPRP4-c2CUQGUwQ772uGJxiz5VZ2C59a7Qhp_v7fhMa02nK++g@mail.gmail.com>

The answer to your Q is surely a "no": That's exaxtly the point of tapply
that the number of y values may vary. The msg tells you that the x & y full
vectors must have the same length.

Hoping that helps.
Martin

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul  8 17:04:14 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 08 Jul 2018 08:04:14 -0700
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
Message-ID: <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>

Read the vignette at [1], which mentions the Read me.txt file [2]. I found both links using Google... you could too.

[1] https://cran.r-project.org/web/packages/RWinEdt/index.html.
[2] https://github.com/cran/RWinEdt/blob/master/inst/ReadMe.txt

On July 8, 2018 7:08:53 AM PDT, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>Dear all,
>
>Hello,
>
>
>
>I am going to install the ?RWinEdt? package on R software. I had
>installed
>it on R before, but when I downloaded the newest versions of R software
>(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.
>
>Please help and guide me to know how I can install and use the
>?RWinEdt?
>properly.
>
>
>
>Look forward to hearing from you.
>
>
>
>Best regards,

-- 
Sent from my phone. Please excuse my brevity.



From k|m@r@nt@ @end|ng |rom gm@||@com  Sun Jul  8 12:52:59 2018
From: k|m@r@nt@ @end|ng |rom gm@||@com (Kim O)
Date: Sun, 8 Jul 2018 12:52:59 +0200
Subject: [R] Help with mixOmics rcc-tune
Message-ID: <CAK8=OOLOsRT+Rv_TkPkOr6yD-74uidS90boKZfZFy3a25NLJ=A@mail.gmail.com>

Dear,


I am using the mixOmics rCCA package, but I am encountering a problem that
I cannot solve with the documentation only:


*How should I interpret the "optimal score" (opt.score) returned by
tune.rcc? *


It does not say what this score actually represent? My best guess would be
the average canonical correlations on the test set, but I am not sure?


In my specific application, I get canonical correlation of about 0.8 on
training data but a CV-score of only 0.20.... I don't know whether this is
good or bad and how to interpret this.


Can you provide information on how exactly this is calculated and how to
interpret it?


Thank you so much. Would mean so much to me!

Best,

Kim Rants

	[[alternative HTML version deleted]]



From |@r@h@d@|@th|@n @end|ng |rom gm@||@com  Sun Jul  8 18:26:47 2018
From: |@r@h@d@|@th|@n @end|ng |rom gm@||@com (Farshad Fathian)
Date: Sun, 8 Jul 2018 20:56:47 +0430
Subject: [R] Fwd: Question
In-Reply-To: <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
 <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
Message-ID: <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>

Thank you so much for your reply. But when I install the "RWinEdt" package,
the R unable to install it. I see the below warning:

"Error: package or namespace load failed for ?RWinEdt?:
 package ?RWinEdt? was installed by an R version with different internals;
it needs to be reinstalled for use with this R version"

The current version of the R is 3.5.1.




[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
07/08/18,
8:54:06 PM

On Sun, Jul 8, 2018 at 7:34 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Read the vignette at [1], which mentions the Read me.txt file [2]. I found
> both links using Google... you could too.
>
> [1] https://cran.r-project.org/web/packages/RWinEdt/index.html.
> [2] https://github.com/cran/RWinEdt/blob/master/inst/ReadMe.txt
>
> On July 8, 2018 7:08:53 AM PDT, Farshad Fathian <farshad.fathian at gmail.com>
> wrote:
> >Dear all,
> >
> >Hello,
> >
> >
> >
> >I am going to install the ?RWinEdt? package on R software. I had
> >installed
> >it on R before, but when I downloaded the newest versions of R software
> >(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.
> >
> >Please help and guide me to know how I can install and use the
> >?RWinEdt?
> >properly.
> >
> >
> >
> >Look forward to hearing from you.
> >
> >
> >
> >Best regards,
>
> --
> Sent from my phone. Please excuse my brevity.
>



-- 

Farshad Fathian

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul  8 20:32:29 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 08 Jul 2018 11:32:29 -0700
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
 <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
 <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
Message-ID: <16658586-3C9D-4ED8-B936-A626D92193A8@dcn.davis.ca.us>

I recommend that you post the output of sessionInfo() and copy-paste the commands you attempted to use that failed.

Note that I don't use this package or its associated non-free editor, but the CRAN installation check shows no significant problems, though the package hasn't been updated recently.

On July 8, 2018 9:26:47 AM PDT, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>Thank you so much for your reply. But when I install the "RWinEdt"
>package,
>the R unable to install it. I see the below warning:
>
>"Error: package or namespace load failed for ?RWinEdt?:
>package ?RWinEdt? was installed by an R version with different
>internals;
>it needs to be reinstalled for use with this R version"
>
>The current version of the R is 3.5.1.
>
>
>
>
>[image: Mailtrack]
><https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
>Sender
>notified by
>Mailtrack
><https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
>07/08/18,
>8:54:06 PM
>
>On Sun, Jul 8, 2018 at 7:34 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Read the vignette at [1], which mentions the Read me.txt file [2]. I
>found
>> both links using Google... you could too.
>>
>> [1] https://cran.r-project.org/web/packages/RWinEdt/index.html.
>> [2] https://github.com/cran/RWinEdt/blob/master/inst/ReadMe.txt
>>
>> On July 8, 2018 7:08:53 AM PDT, Farshad Fathian
><farshad.fathian at gmail.com>
>> wrote:
>> >Dear all,
>> >
>> >Hello,
>> >
>> >
>> >
>> >I am going to install the ?RWinEdt? package on R software. I had
>> >installed
>> >it on R before, but when I downloaded the newest versions of R
>software
>> >(R-3.4.3 and R-3.5.1 versions), this package is not installed on it.
>> >
>> >Please help and guide me to know how I can install and use the
>> >?RWinEdt?
>> >properly.
>> >
>> >
>> >
>> >Look forward to hearing from you.
>> >
>> >
>> >
>> >Best regards,
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.



From h@@@n@d|w@n @end|ng |rom gm@||@com  Sun Jul  8 20:43:53 2018
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Sun, 8 Jul 2018 11:43:53 -0700
Subject: [R] Fwd: Question
In-Reply-To: <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
References: <CAPOnVdg6Yqop-kfHx58_X_25jpviYni2_kqDzOnfL9VK9q15ww@mail.gmail.com>
 <CAPOnVdgxXnGvOGA5wD1RoNESzbeN62K4+SiBg8a_4t0QmhhU=A@mail.gmail.com>
 <7E853C3D-4AD3-4B70-A9E8-24CA43CAF489@dcn.davis.ca.us>
 <CAPOnVdgJnB1cEvECnKfnn9upCgcRXcYG6C1fXcS=Qwjf9mDi0g@mail.gmail.com>
Message-ID: <CAP+bYWCfMj5sa4bZJTNMn+yWwXMBHtBStGvbKJPY_tanh-2v7Q@mail.gmail.com>

Farshad,
On Sun, 8 Jul 2018 at 09:29, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>
> Thank you so much for your reply. But when I install the "RWinEdt" package,
> the R unable to install it. I see the below warning:
>
> "Error: package or namespace load failed for ?RWinEdt?:
>  package ?RWinEdt? was installed by an R version with different internals;
> it needs to be reinstalled for use with this R version"

What do the following statements:
> remove.packages('RWinEdt'); install.packages('RWinEdt')
yield?

--
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable



From m@cqueen1 @end|ng |rom ||n|@gov  Sun Jul  8 23:39:23 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Sun, 8 Jul 2018 21:39:23 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <5B49E856-EC41-4C1C-BEAE-8728503937AB@bigelow.org>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <5B49E856-EC41-4C1C-BEAE-8728503937AB@bigelow.org>
Message-ID: <F44057DD-77DB-4317-BE32-725326384581@llnl.gov>

In addition to what Ben and Jeff have said, I think you can simplify your function considerably. See these examples:

> substr( c('abc', 'abcd','abcde') , c(2,1,3), c(2,2,4))
[1] "b"  "ab" "cd"

> foo <- c('abc', 'abcd','abcde') 
> substr( foo , 1, nchar(foo)-2)
[1] "a"   "ab"  "abc"

> foo <- c('abc', 'abcd','abcde') 
> paste0('NSE/',foo)
[1] "NSE/abc"   "NSE/abcd"  "NSE/abcde"

I can't test my suggestions, but just from looking at your code, I don't think you need the two loops.

function (snlcqn)
{
 ##                 lneq <- c()   ## not a good way to initialize
                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
                  file.string <- tempfile()

                  download.file(URL,file.string)

                  IDT <- read_excel(file.string)

                  leq <- IDT[,1]

   lneq <- substr( leq, 1, nchar(leq)-2)

#                  for(i in 1:length(leq)){
#                 lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}

  snlcqna <- paste0('NSE/', lneq)

#                  for(j in 1:length(lneq)){
#                  snlcqna[j] <- paste("NSE/",lneq[j])}


## functions return the value of their last expression, so the return() statements are not necessary
## testing for FALSE does not need == "FALSE"

#                  if(identical(snlcqn,snlcqna) == "FALSE"){
#                 return(snlcqna)                         }
#
#                  else                                    {
#                  return(snlcqn)                          }

  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

}


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/8/18, 6:48 AM, "R-help on behalf of Ben Tupper" <r-help-bounces at r-project.org on behalf of btupper at bigelow.org> wrote:

    Hi,
    
    You will be hard pressed to get helpful answers as you have not provided any way for list readers to replicate your data and code.  Check out this https://rseek.org/?q=reproducible+example
    
    On the other hand, ...
    
    (1)  I have a hunch that one place you are getting tripped up by your effort to treat IDT as a regular data.frame.  In fact, read_excel(), I'm guessing from the readxl package, returns a tibble.  When you subset a tibble like you have with...
    
    leq <- IDT[,1]
    
    ... you get a 1-column tibble...
    
    > leq
    # A tibble: 208 x 1
       SymbolSeries
       <chr>       
     1 ACCEQ       
     2 ADANIENTEQ  
     3 ADANIPORTSEQ
     4 ADANIPOWEREQ
     5 AJANTPHARMEQ
     6 ALBKEQ      
     7 AMARAJABATEQ
     8 AMBUJACEMEQ 
     9 ANDHRABANKEQ
    10 APOLLOHOSPEQ
    # ... with 198 more rows
    
    So, that may be part of the issue (but I'm not really sure if it causes the problem you identify).
    
    (2) Also another possible tripping point, when you prepend 'NSE/' to whatever lneq is supposed to be, you are using paste() without specifying the sep argument which defaults to a single space " ".  If you want it to be something else then you have to explicitly set the value of sep.
    
    (3) Finally, you will have much better luck getting help if you configure your email client to send plain text to this list.  Fancily formatted text is made un-fancy by the list-server software - which will mess up your posted code.  That's why you keep getting ...
    
    [[alternative HTML version deleted]]
    
    ... at the tail end of your emails.
    
    
    Good luck!
    Ben
    
    > On Jul 8, 2018, at 8:37 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
    > 
    > dear members,
    >                             The mail is not showing the spaces between [192] "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces between the two.....!!!!!!
    > 
    > ________________________________________
    > From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni <akshay_e4 at hotmail.com>
    > Sent: Sunday, July 8, 2018 5:58 PM
    > To: R help Mailing  list
    > Subject: [R] inconsistency in display of character vector....
    > 
    > dear members,
    >                            I have the following code to update the list of stocks:
    > 
    > function (snlcqn)
    > {
    >                  lneq <- c()
    >                  URL <- "https://canmoney.in/Intraday%20scrip.xls"
    >                  file.string <- tempfile()
    > 
    >                  download.file(URL,file.string)
    > 
    >                  IDT <- read_excel(file.string)
    > 
    >                  leq <- IDT[,1]
    > 
    >                  for(i in 1:length(leq)){
    >                  lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
    > 
    >                  for(j in 1:length(lneq)){
    >                  snlcqna[j] <- paste("NSE/",lneq[j])}
    > 
    >                  if(identical(snlcqn,snlcqna) == "FALSE"){
    >                  return(snlcqna)                         }
    > 
    >                  else                                    {
    >                  return(snlcqn)                          }
    > 
    > }
    > snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
    > The problem is the return object, instead of getting displayed in contiguous list, is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS instance):
    > 
    > [192] "NSE/YESBANK"
    > [193] "NSE/ZEEL"
    > 
    > Why is this happening? How can I get the return object as a contiguous list?
    > Very many thanks for your time and effort...
    > yours sincerely,
    > AKSHAY M KULKARNI
    > 
    >        [[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    > 
    
    Ben Tupper
    Bigelow Laboratory for Ocean Sciences
    60 Bigelow Drive, P.O. Box 380
    East Boothbay, Maine 04544
    http://www.bigelow.org
    
    Ecological Forecasting: https://eco.bigelow.org/
    
    
    
    
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@dmuzom @end|ng |rom out|ook@com  Sun Jul  8 20:01:50 2018
From: r@dmuzom @end|ng |rom out|ook@com (radmuzom .)
Date: Sun, 8 Jul 2018 18:01:50 +0000
Subject: [R] replicate rows
In-Reply-To: <CAGgJW76a-6LFXRbDUVgO7JgHNzoDNFRqBmm8Kw=5quk2pwsEQQ@mail.gmail.com>
References: <CAEW+BD+wGJ_OkAMqx+CW5U+Z5Gb2JpFm-=QwUANKTGdU7Dwdjw@mail.gmail.com>,
 <CAGgJW76a-6LFXRbDUVgO7JgHNzoDNFRqBmm8Kw=5quk2pwsEQQ@mail.gmail.com>
Message-ID: <MA1PR0101MB178120F0E2E3214047A08D89CB450@MA1PR0101MB1781.INDPRD01.PROD.OUTLOOK.COM>

While Eric's solution should work for your case, here is a slightly more general version where the number of replications is dependent on a column in the data frame. In the example, the number of replications required is the ceiling of the number of 30 day intervals between start date and end date, which are already available in the data frame. The key function is f - this takes a row index (of df) and replicates as many times as determined by the value in the column num_int for that row. To modify f, you need to replace num_int by the appropriate column name in your data set. f is then mapped to each row number of df and the replicated indices are stored in rowindex_rep as a vector. The final step is to subset df which repeats the rows appropriately. 

df <- data.frame(
  order_id = c(1, 2),
  start_date = c(as.Date("2017-05-01"), as.Date("2017-08-01")),
  end_date = c(as.Date("2017-07-06"), as.Date("2017-09-15"))
)
df$diff_days <- as.integer(df$end_date - df$start_date)
df$num_int <- ceiling(df$diff_days / 30)

f <- function(rowindex) {
  rep(rowindex, each = df[rowindex, "num_int"])
}

rowindex_rep <- unlist(Map(f, 1:nrow(df)))
df2 <- df[rowindex_rep, ]


Regards,
radmuzom



From: R-help <r-help-bounces at r-project.org> on behalf of Eric Berger <ericjberger at gmail.com>
Sent: Sunday, July 8, 2018 3:21 PM
To: catalin roibu
Cc: R Project Help
Subject: Re: [R] replicate rows
? 

Hi Catalin,

This should work. I set the number of repetitions and sample sizes as
variables so it would be clear how to modify for your actual case.

nreps??? <- 3
sampSize <- 2
w <- unlist( lapply(1:nreps, function(i) {
rep(paste("R",i,sep=""),sampSize) } ) )
aa2 <- cbind( as.data.frame(aa), w)

HTH,
Eric


On Sun, Jul 8, 2018 at 11:44 AM, catalin roibu <catalinroibu at gmail.com>
wrote:

> Dear R users,
>
> I want to replicate sampled rows in data frame. The sampling results must
> be in this form:
>
>?? a?? b???? Rep
> [1,] 3 4.0 R1
> [2,] 6 8.0 R1
> [3,] 1 0.1 R2
> [4,] 6 8.0 R2
> [5,] 1 0.1 R3
> [6,] 5 7.0 R3
>
> I have a code but I didn't succeed to insert to rep column.
>
> This is my code:
> a<-c(1,2,3,4,5,6)
> b<-c(0.1, 0.2, 4, 6, 7, 8)
> ab<-cbind(a, b)
> x<-replicate(3, sample(1:nrow(ab), 2))
> aa<-ab[x, ]
>
> Please help me to solve that problem!
>
> Thank you very much!
>
> Best regards!
>
> Catalin
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> ?
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone????? +4 0230 52 29 78, ext. 531
> mobile phone??? +4 0745 53 18 01
> FAX:??????????????? +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>???????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    

From t@n@@@ @end|ng |rom gm@||@com  Mon Jul  9 02:44:45 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sun, 8 Jul 2018 17:44:45 -0700
Subject: [R] about ECDF display in ggplot2
Message-ID: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>

Dear Jeff,

thank you for your email.

Yes, in order to be more descriptive/comprehensive, please find attached to
my email the following files (my apologies ... I am sending these as
attachments, as I do not have a web server running at this moment) :

-- the R script (R_script_display_ECDF.R) that reads the file "LENGTH" and
outputs ECDF figure by using the standard R function or ggplot2.

-- the display of ECDF by using standard R function
("display.R.ecdf.LENGTH.pdf")

-- the display of ECDF by using ggplot2 ("display.ggplot2.ecdf.LENGTH.pdf")

The ECDF over xlim(0,500) looks very different (contrasting plot(ecdf) vs
ggplot2).  Please would you advise why ? what shall I change in my ggplot2
code ?

thanks a lot,

- bogdan

ps : the R code is also written below :

 library("ggplot2")
>


> file <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
>


> ############################# display with PLOT FUNCTION:
>


> pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6, paper='special')
>


> plot(ecdf(file$LENGTH), xlab="DEL SIZE",
>                      ylab="fraction of DEL",
>                      main="LENGTH of DEL",
>                      xlim=c(0,500),
>                      col = "dark red", axes = FALSE)
>


> ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
>


> axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
>


> ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
>


> axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
>


> dev.off()
>


> ############################# display in GGPLOT2 :
>


> BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
>            1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
>


> barfill <- "#4271AE"
> barlines <- "#1F3552"
>


> pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
> paper='special')
>


> ggplot(file, aes(LENGTH)) +
>           stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>           scale_x_continuous(name = "LENGTH of DEL",
>                              breaks = BREAKS,
>                              limits=c(0, 500)) +
>           scale_y_continuous(name = "FRACTION") +
>           ggtitle("ECDF of LENGTH") +
>           theme_bw() +
>           theme(legend.position = "bottom", legend.direction =
> "horizontal",
>                legend.box = "horizontal",
>                legend.key.size = unit(1, "cm"),
>                axis.title = element_text(size = 12),
>                legend.text = element_text(size = 9),
>                legend.title=element_text(face = "bold", size = 9))
>


> dev.off()








On Sat, Jul 7, 2018 at 9:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> It is a feature of ggplot that points excluded by limits raise warnings,
> while base graphics do not.
>
> You may find that using coord_cartesian with the xlim=c(0,500) argument
> works better with ggplot by showing the consequences of points out of the
> limits on lines within the viewport.
>
> There are other possible problems with your data that your
> non-reproducible example does not show, and sending R code in
> HTML-formatted email usually corrupts it.. so please follow the
> recommendations in the Posting Guide next time you post.
>
> On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >Dear all,
> >
> >I would appreciate having your advice/suggestions/comments on the
> >following
> >:
> >
> >1 -- starting from a vector that contains LENGTHS (numerically, the
> >values
> >are from 1 to 10 000)
> >
> >2 -- shall I display the ECDF by using the R code and some "limits" :
> >
> >BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400,
> >500,
> >         1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
> >
> >ggplot(x, aes(LENGTH)) +
> >          stat_ecdf(geom = "point") +
> >          scale_x_continuous(name = "LENGTH of DEL",
> >                             breaks = BREAKS,
> >                             limits=c(0, 500))
> >
> >3 -- I am getting the following warning message : "Warning message:
> >Removed
> >109 rows containing non-finite values (stat_ecdf)."
> >
> >The question is : are these 109 values removed from VISUALIZATION as i
> >set
> >up the "limits", or are these 109 values removed from statistical
> >CALCULATION?
> >
> >4 -- in contrast, shall I use the standard R functions plot(ecdf),
> >there is
> >no "warning mesage"
> >
> >plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
> >                     ylab="Fraction of DEL", main="DEL", xlim=c(0,500),
> >                     col = "dark red")
> >
> >Thanks a lot !
> >
> >-- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: display.ggplot2.ecdf.LENGTH.pdf
Type: application/pdf
Size: 8841 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180708/75da9c56/attachment-0004.pdf>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: display.R.ecdf.LENGTH.pdf
Type: application/pdf
Size: 13600 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180708/75da9c56/attachment-0005.pdf>

From petr@p|k@| @end|ng |rom prechez@@cz  Mon Jul  9 08:43:39 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 9 Jul 2018 06:43:39 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>

Hi

You definitely should not use HTML formated mail. This is plain text mailing list for reason.

If you experience space between "NSE/" and pasted second part, you should read paste help page which states

paste (..., sep = " ", collapse = NULL)

so it has space as separator.

You should use paste0 if you want to get rid of separating space or axplicitely state 
paste (..., sep = "")

> lneq <- c()
> for (i in 1:10) lneq[i] <- letters[i]
> lneq
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> snlcqna<-LETTERS[1:10]
> for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> snlcqna
 [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/ h"
 [9] "NSE/ i" "NSE/ j"
> for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> snlcqna
 [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h" "NSE/i"
[10] "NSE/j"

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of akshay
> kulkarni
> Sent: Sunday, July 8, 2018 2:38 PM
> To: R help Mailing list <r-help at r-project.org>
> Subject: [R] Fw: inconsistency in display of character vector....
> 
> dear members,
>                              The mail is not showing the spaces between [192]
> "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces
> between the two.....!!!!!!
> 
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni
> <akshay_e4 at hotmail.com>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
> 
> dear members,
>                             I have the following code to update the list of stocks:
> 
> function (snlcqn)
> {
>                   lneq <- c()
>                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                   file.string <- tempfile()
> 
>                   download.file(URL,file.string)
> 
>                   IDT <- read_excel(file.string)
> 
>                   leq <- IDT[,1]
> 
>                   for(i in 1:length(leq)){
>                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> 
>                   for(j in 1:length(lneq)){
>                   snlcqna[j] <- paste("NSE/",lneq[j])}
> 
>                   if(identical(snlcqn,snlcqna) == "FALSE"){
>                   return(snlcqna)                         }
> 
>                   else                                    {
>                   return(snlcqn)                          }
> 
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list,
> is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS
> instance):
> 
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
> 
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From er|cjberger @end|ng |rom gm@||@com  Mon Jul  9 08:45:03 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 9 Jul 2018 09:45:03 +0300
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>

 >  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

??

Why not just always return snicqna ?


On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You definitely should not use HTML formated mail. This is plain text
> mailing list for reason.
>
> If you experience space between "NSE/" and pasted second part, you should
> read paste help page which states
>
> paste (..., sep = " ", collapse = NULL)
>
> so it has space as separator.
>
> You should use paste0 if you want to get rid of separating space or
> axplicitely state
> paste (..., sep = "")
>
> > lneq <- c()
> > for (i in 1:10) lneq[i] <- letters[i]
> > lneq
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> > snlcqna<-LETTERS[1:10]
> > for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/
> h"
>  [9] "NSE/ i" "NSE/ j"
> > for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h"
> "NSE/i"
> [10] "NSE/j"
>
> Cheers
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/
> zasady-ochrany-osobnich-udaju/ | Information about processing and
> protection of business partner's personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of akshay
> > kulkarni
> > Sent: Sunday, July 8, 2018 2:38 PM
> > To: R help Mailing list <r-help at r-project.org>
> > Subject: [R] Fw: inconsistency in display of character vector....
> >
> > dear members,
> >                              The mail is not showing the spaces between
> [192]
> > "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty
> spaces
> > between the two.....!!!!!!
> >
> > ________________________________________
> > From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni
> > <akshay_e4 at hotmail.com>
> > Sent: Sunday, July 8, 2018 5:58 PM
> > To: R help Mailing  list
> > Subject: [R] inconsistency in display of character vector....
> >
> > dear members,
> >                             I have the following code to update the list
> of stocks:
> >
> > function (snlcqn)
> > {
> >                   lneq <- c()
> >                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
> >                   file.string <- tempfile()
> >
> >                   download.file(URL,file.string)
> >
> >                   IDT <- read_excel(file.string)
> >
> >                   leq <- IDT[,1]
> >
> >                   for(i in 1:length(leq)){
> >                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> >
> >                   for(j in 1:length(lneq)){
> >                   snlcqna[j] <- paste("NSE/",lneq[j])}
> >
> >                   if(identical(snlcqn,snlcqna) == "FALSE"){
> >                   return(snlcqna)                         }
> >
> >                   else                                    {
> >                   return(snlcqn)                          }
> >
> > }
> > snlcqn is the list of present stocks and snlcqna is the list of updated
> stocks.
> > The problem is the return object, instead of getting displayed in
> contiguous list,
> > is getting displayed with lots of spaces...( I am using R on a LINUX
> RHEL AWS
> > instance):
> >
> > [192] "NSE/YESBANK"
> > [193] "NSE/ZEEL"
> >
> > Why is this happening? How can I get the return object as a contiguous
> list?
> > Very many thanks for your time and effort...
> > yours sincerely,
> > AKSHAY M KULKARNI
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jul  9 10:14:26 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 9 Jul 2018 13:44:26 +0530
Subject: [R] R couldnt recognize US Pasific timezome
Message-ID: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>

Hi,

I wanted to convert Epoch time to readable time with US Pacific Time Zone
using 'anytime' package, as below:

> library(anytime)
> anytime(1417411980, tz = 'PST')
[1] "2014-12-01 05:33:00 GMT"
Warning message:
In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'


However it appears that R couldn't recognize the PST as the short form of
Pacific time zone.

Any help to correctly change Epoch time to corresponding pacific time would
be helpful.

Thanks,

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  9 10:41:58 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 9 Jul 2018 01:41:58 -0700 (PDT)
Subject: [R] about ECDF display in ggplot2
In-Reply-To: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>
References: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807090119280.18090@pedal.dcn.davis.ca.us>

Thank you for making the effort... but most attachments get stripped on 
the mailing list. Using the reprex package as I suggested and putting the 
result into the email is by far the safest approach. Since I received your 
email directly, I did get the attachments. Below is my reproducible 
example... to serve as an example for how you can get help from everyone 
on the list rather than just the few you are responding to.

My summary comment is that you have to decide whether the LENGTH values 
greater than 500 are relevant... and if they are, you REALLY SHOULD create 
a data set that is limited in this fashion. Then you won't have to create 
"fake" axes, and you won't get ggplot warnings.

Note: The reprex package allows you to confirm that the example is in fact 
reproducible, so technically it is not necessary to include the plot 
images in the question. However, reprex used to conveniently support 
putting the images on the imgur website, and for some reason it no longer 
does that, so just run the example interactively to see the graphs.

#######
############################################################
############################################################

library("ggplot2")

# "file" is the name of a very fundamental function in base R. Re-using
# that name for a data value is at best confusing to anyone reading your
# code and at worst will prevent you from using that function.
#file <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)

# Instead of giving us a file, keep the data within the example
# DF <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
# set.seed( 42 )
# also shrink the size of the data for the example... we almost
# never need all of it
# dput( DF[ sample( seq.int( nrow( DF ) ), size = 200 ), , drop=FALSE ] )
DF <- structure(list(LENGTH = c(6813L, 56035L, 123997L, 281L, 851L, 1072L,
           72196L, 21L, 304L, 110L, 198L, 5922L, 283L, 199348L, 109L,
           3317104L, 106L, 37642146L, 82641L, 20L, 125911L, 354L, 11625388L,
           330L, 9811711L, 18L, 35L, 39897L, 27L, 277L, 79L, 2657L, 17L,
           26L, 23L, 248L, 3634L, 21L, 324L, 206L, 328L, 42L, 286L, 6042409L,
           24L, 36L, 2879L, 18L, 301L, 90684L, 4296636L, 43L, 1222L, 4536L,
           3281L, 324L, 393L, 3754L, 98824541L, 459L, 18L, 1081L, 175L,
           970L, 17L, 219L, 235558L, 1167315L, 25L, 623L, 2517515L, 32L,
           217L, 29L, 17L, 1744L, 18L, 39L, 26L, 77L, 41L, 22L, 311L, 119015225L,
           146413L, 22L, 19L, 301L, 373L, 2240L, 6439L, 128L, 18L, 257L,
           783L, 5169L, 31608038L, 325L, 1533L, 25L, 69344L, 54L, 10651L,
           31L, 335062L, 1854019L, 7153L, 38605567L, 51L, 23L, 16L, 301L,
           79L, 313L, 18L, 29L, 39L, 22L, 17L, 306L, 67L, 280L, 324L, 158L,
           93L, 2561L, 302L, 134578L, 328L, 9002L, 969051L, 34L, 20L, 309L,
           355L, 28L, 9461327L, 18627013L, 305L, 64L, 18L, 2730L, 28L, 246L,
           911L, 28L, 241483L, 154691L, 58891L, 55L, 456362L, 281L, 276L,
           51L, 26L, 106821L, 313L, 78L, 29L, 400L, 61171382L, 200L, 101L,
           220331L, 128L, 325L, 28L, 22L, 325L, 2330L, 5879L, 24L, 36L,
           23L, 51L, 26L, 32584707L, 1672L, 13939L, 315L, 20L, 580785L,
           42795L, 49193543L, 695L, 48568156L, 55634L, 207L, 318L, 22056L,
           3670420L, 4815387L, 309L, 17L, 3143160L, 431L, 1164L, 33L, 5503L,
           4166L)), .Names = "LENGTH", row.names = c(8283L, 8484L, 2591L,
           7517L, 5808L, 4698L, 6665L, 1219L, 5944L, 6378L, 4140L, 6503L,
           8452L, 2310L, 4180L, 8497L, 8842L, 1062L, 4293L, 5063L, 8168L,
           1253L, 8932L, 8550L, 745L, 4643L, 3523L, 8177L, 4035L, 7545L,
           6657L, 7319L, 3502L, 6181L, 36L, 7513L, 67L, 1873L, 8174L, 5516L,
           3422L, 3928L, 338L, 8773L, 3891L, 8627L, 7997L, 5765L, 8745L,
           5573L, 3003L, 3122L, 3588L, 7064L, 351L, 6739L, 6095L, 1541L,
           2349L, 4628L, 6077L, 8839L, 6830L, 5094L, 7639L, 1704L, 2439L,
           7443L, 6230L, 2162L, 387L, 1262L, 1944L, 4306L, 1773L, 6460L,
           71L, 3371L, 4618L, 15L, 5220L, 1417L, 3222L, 5792L, 6960L, 5056L,
           2096L, 807L, 768L, 2737L, 5983L, 3L, 1870L, 8361L, 8294L, 6577L,
           2984L, 4614L, 6664L, 5545L, 5608L, 1945L, 1939L, 3482L, 8435L,
           8615L, 6621L, 6561L, 4793L, 21L, 5447L, 7484L, 6721L, 4048L,
           4790L, 4804L, 13L, 3179L, 5471L, 7407L, 3187L, 3669L, 5123L,
           5267L, 6427L, 3527L, 8207L, 8593L, 2085L, 6467L, 8065L, 5385L,
           5635L, 8363L, 7587L, 5172L, 7326L, 1015L, 6817L, 5560L, 1324L,
           716L, 4136L, 6945L, 6536L, 7281L, 1516L, 8415L, 2616L, 1328L,
           6406L, 2886L, 6933L, 3511L, 6040L, 6905L, 1672L, 259L, 1208L,
           6051L, 8315L, 4896L, 5351L, 1752L, 4759L, 1597L, 4017L, 2818L,
           1033L, 1654L, 6483L, 3659L, 3678L, 4266L, 3797L, 1212L, 7322L,
           5258L, 7052L, 6826L, 8147L, 7655L, 2813L, 2300L, 6584L, 6629L,
           8140L, 7034L, 1183L, 2551L, 1726L, 6950L, 1143L, 1144L, 641L,
           471L, 4712L, 995L, 6582L, 6476L), class = "data.frame")


############################# display with PLOT FUNCTION:


# saving files should be avoided in reproducible examples... especially files
# that cannot be transmitted through the R-help mailing list such as pdf files
#pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6, paper='special')

# Your original plot commands below create a fake impression of the data by
# falsifying the axes. If you really are only interested in data points less
# than 500, you should be explicit about creating a data set containing only
# such constrained values before plotting them.
plot(ecdf(DF$LENGTH), xlab="DEL SIZE",
                      ylab="fraction of DEL",
                      main="LENGTH of DEL",
                      xlim=c(0,500),
                      col = "dark red", axes = FALSE)
ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-1.png)

# my recommendation
DF500 <- subset( DF, LENGTH < 500 )
plot( ecdf( DF500$LENGTH )
     , xlab = "DEL SIZE"
     , ylab = "fraction of DEL"
     , main = "LENGTH of DEL"
     , col = "dark red"
     )

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-2.png)

# alternatively
plot( ecdf( DF$LENGTH )
     , xlab = "DEL SIZE"
     , ylab = "fraction of DEL"
     , main = "LENGTH of DEL"
     , col = "dark red"
     , xlim=c( 1, 1e9 )
     , log="x"
     )

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-3.png)



#dev.off()

############################# display in GGPLOT2 :

BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
            1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)

barfill <- "#4271AE"
barlines <- "#1F3552"

#pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6, paper='special')

# ggplot's limits behavior is enabling your false representation of the data, but it
# warns you of the data removal
ggplot(DF, aes(LENGTH)) +
           stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
           scale_x_continuous(name = "LENGTH of DEL",
                              breaks = BREAKS,
                              limits=c(0, 500)
                              ) +
           scale_y_continuous(name = "FRACTION") +
           ggtitle("ECDF of LENGTH") +
           theme_bw() +
           theme(legend.position = "bottom", legend.direction = "horizontal",
                legend.box = "horizontal",
                legend.key.size = unit(1, "cm"),
                axis.title = element_text(size = 12),
                legend.text = element_text(size = 9),
                legend.title=element_text(face = "bold", size = 9))
#> Warning: Removed 80 rows containing non-finite values (stat_ecdf).

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-4.png)


# my recommendation
ggplot(DF500, aes(LENGTH)) +
   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
   scale_x_continuous(name = "LENGTH of DEL",
                      breaks = BREAKS ) +
   scale_y_continuous(name = "FRACTION") +
   ggtitle("ECDF of LENGTH") +
   theme_bw() +
   theme(legend.position = "bottom", legend.direction = "horizontal",
         legend.box = "horizontal",
         legend.key.size = unit(1, "cm"),
         axis.title = element_text(size = 12),
         legend.text = element_text(size = 9),
         legend.title=element_text(face = "bold", size = 9))

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-5.png)

# or for the un-filtered data
ggplot(DF, aes(LENGTH)) +
   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
   scale_x_log10( name = "LENGTH of DEL") +
   scale_y_continuous(name = "FRACTION") +
   ggtitle("ECDF of LENGTH") +
   theme_bw() +
   theme(legend.position = "bottom", legend.direction = "horizontal",
         legend.box = "horizontal",
         legend.key.size = unit(1, "cm"),
         axis.title = element_text(size = 12),
         legend.text = element_text(size = 9),
         legend.title=element_text(face = "bold", size = 9))

#' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/reprex-body-6.png)


#dev.off()

#' Created on 2018-07-09 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
#######

On Sun, 8 Jul 2018, Bogdan Tanasa wrote:

> Dear Jeff,?
> thank you for your email.?
> 
> Yes, in order to be more descriptive/comprehensive, please find attached to
> my email the following files (my apologies ... I am sending these as
> attachments, as I do not have a web server running at this moment) :?
> 
> -- the R script (R_script_display_ECDF.R) that reads the file "LENGTH" and
> outputs ECDF figure by using the standard R function or ggplot2.
> 
> -- the display of ECDF by using standard R function
> ("display.R.ecdf.LENGTH.pdf")
> 
> -- the display of ECDF by using ggplot2 ("display.ggplot2.ecdf.LENGTH.pdf")
> 
> The ECDF over xlim(0,500) looks very different (contrasting plot(ecdf) vs
> ggplot2).? Please would you advise why ? what shall I change in my ggplot2
> code ?
> 
> thanks a lot,?
> 
> - bogdan
> 
> ps : the R code is also written below :
>
>       ?library("ggplot2")
> 
> ?
>       file <- read.delim("LENGTH", sep="\t", header=T,
>       stringsAsFactors=F)?
> 
> ?
>       ############################# display with PLOT FUNCTION:?
> 
> ?
>       pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6,
>       paper='special')?
> 
> ?
>       plot(ecdf(file$LENGTH), xlab="DEL SIZE",??
>       ? ? ? ? ? ? ? ? ? ? ?ylab="fraction of DEL",?
>       ? ? ? ? ? ? ? ? ? ? ?main="LENGTH of DEL",??
>       ? ? ? ? ? ? ? ? ? ? ?xlim=c(0,500),?
>       ? ? ? ? ? ? ? ? ? ? ?col = "dark red", axes = FALSE)
> 
> ?
>       ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
> 
> ?
>       axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
> 
> ?
>       ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
> 
> ?
>       axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
> 
> ?
>       dev.off()
> 
> ?
>       ############################# display in GGPLOT2 :?
> 
> ?
>       BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
>       400, 500,?
>       ? ? ? ? ? ?1000, 10000, 100000, 1000000, 10000000, 100000000,
>       1000000000)
> 
> ?
>       barfill <- "#4271AE"
>       barlines <- "#1F3552"
> 
> ?
>       pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
>       paper='special')?
> 
> ?
>       ggplot(file, aes(LENGTH)) +?
>       ? ? ? ? ? stat_ecdf(geom = "point", colour = barlines, fill =
>       barfill) +
>       ? ? ? ? ? scale_x_continuous(name = "LENGTH of DEL",
>       ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?breaks = BREAKS,
>       ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?limits=c(0, 500)) +
>       ? ? ? ? ? scale_y_continuous(name = "FRACTION") +
>       ? ? ? ? ? ggtitle("ECDF of LENGTH") +?
>       ? ? ? ? ? theme_bw() +
>       ? ? ? ? ? theme(legend.position = "bottom", legend.direction =
>       "horizontal",
>       ? ? ? ? ? ? ? ?legend.box = "horizontal",
>       ? ? ? ? ? ? ? ?legend.key.size = unit(1, "cm"),
>       ? ? ? ? ? ? ? ?axis.title = element_text(size = 12),
>       ? ? ? ? ? ? ? ?legend.text = element_text(size = 9),
>       ? ? ? ? ? ? ? ?legend.title=element_text(face = "bold", size =
>       9))
> 
> ?
>       dev.off()
> 
> 
> 
> 
> ?
> 
> 
> On Sat, Jul 7, 2018 at 9:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>       It is a feature of ggplot that points excluded by limits raise
>       warnings, while base graphics do not.
>
>       You may find that using coord_cartesian with the xlim=c(0,500)
>       argument works better with ggplot by showing the consequences of
>       points out of the limits on lines within the viewport.
>
>       There are other possible problems with your data that your
>       non-reproducible example does not show, and sending R code in
>       HTML-formatted email usually corrupts it.. so please follow the
>       recommendations in the Posting Guide next time you post.
>
>       On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
>       wrote:
>       >Dear all,
>       >
>       >I would appreciate having your advice/suggestions/comments on
>       the
>       >following
>       >:
>       >
>       >1 -- starting from a vector that contains LENGTHS (numerically,
>       the
>       >values
>       >are from 1 to 10 000)
>       >
>       >2 -- shall I display the ECDF by using the R code and some
>       "limits" :
>       >
>       >BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>       300, 400,
>       >500,
>       >? ? ? ? ?1000, 10000, 100000, 1000000, 10000000, 100000000,
>       1000000000)
>       >
>       >ggplot(x, aes(LENGTH)) +
>       >? ? ? ? ? stat_ecdf(geom = "point") +
>       >? ? ? ? ? scale_x_continuous(name = "LENGTH of DEL",
>       >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?breaks = BREAKS,
>       >? ? ? ? ? ? ? ? ? ? ? ? ? ? ?limits=c(0, 500))
>       >
>       >3 -- I am getting the following warning message : "Warning
>       message:
>       >Removed
>       >109 rows containing non-finite values (stat_ecdf)."
>       >
>       >The question is : are these 109 values removed from
>       VISUALIZATION as i
>       >set
>       >up the "limits", or are these 109 values removed from
>       statistical
>       >CALCULATION?
>       >
>       >4 -- in contrast, shall I use the standard R functions
>       plot(ecdf),
>       >there is
>       >no "warning mesage"
>       >
>       >plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
>       >? ? ? ? ? ? ? ? ? ? ?ylab="Fraction of DEL", main="DEL",
>       xlim=c(0,500),
>       >? ? ? ? ? ? ? ? ? ? ?col = "dark red")
>       >
>       >Thanks a lot !
>       >
>       >-- bogdan
>       >
> >? ? ? ?[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Sent from my phone. Please excuse my brevity.
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  9 10:46:29 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 9 Jul 2018 01:46:29 -0700 (PDT)
Subject: [R] R couldnt recognize US Pasific timezome
In-Reply-To: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>
References: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807090142300.18090@pedal.dcn.davis.ca.us>

Several of the "conventional" three letter timezone abbreviations actually 
get re-used in different parts of the world, and not all operating system 
support for timezones include the same shortcuts. The solution is to use 
the correct timezone string rather than your familiar shortcut... you can 
look through the vector returned by the OlsonNames() function in general, 
but in your case just use "Etc/GMT+8" for standard time year-round. If you 
wanted daylight savings time support, you would use "America/Los_Angeles".

On Mon, 9 Jul 2018, Christofer Bogaso wrote:

> Hi,
>
> I wanted to convert Epoch time to readable time with US Pacific Time Zone
> using 'anytime' package, as below:
>
>> library(anytime)
>> anytime(1417411980, tz = 'PST')
> [1] "2014-12-01 05:33:00 GMT"
> Warning message:
> In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
>
>
> However it appears that R couldn't recognize the PST as the short form of
> Pacific time zone.
>
> Any help to correctly change Epoch time to corresponding pacific time would
> be helpful.
>
> Thanks,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jul  9 12:22:02 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 9 Jul 2018 15:52:02 +0530
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
Message-ID: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>

Hi,

Below is my code :

library(zoo)
Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
structure(c(1512664740,
1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
"POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
structure(c(1512664740,
1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
"POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")

merge(Dat1, Dat2)

                        Dat1     Dat2
2017-12-07 22:09:00 17890.00 15804.28
2017-12-07 22:10:00 17770.01 15720.61
2017-12-07 22:11:00 17600.00 15770.00
2017-12-07 22:12:00 17593.00 15750.00
2017-12-07 22:13:00 17630.01 15770.00


So, after merging the TZ of the original series got changed.

Appreciate if someone points what went wrong

	[[alternative HTML version deleted]]



From @tyen @end|ng |rom ntu@edu@tw  Mon Jul  9 12:18:38 2018
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Mon, 9 Jul 2018 18:18:38 +0800
Subject: [R] Package installation
Message-ID: <34d889c5-4748-2a29-df66-dfe5cd26eb04@ntu.edu.tw>

I have had trouble installing packages (e.g., car, aod) in some 
computers (such as computers in the student lab) but no problem in my 
own laptop.
Installation typically goes through, but after I got out and back in R 
(and RStudios), the error message says "packages xxx not available". 
That is, earlier installation of the packages did not stay (despite the 
successful installation message).
I went back as far as R3.0.3 and there is no problem.
Does this tell anyone what may be going on? Thanks.

-- 
styen at ntu.edu.tw  (S.T. Yen)


	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jul  9 13:58:26 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 9 Jul 2018 07:58:26 -0400
Subject: [R] Package installation
In-Reply-To: <34d889c5-4748-2a29-df66-dfe5cd26eb04@ntu.edu.tw>
References: <34d889c5-4748-2a29-df66-dfe5cd26eb04@ntu.edu.tw>
Message-ID: <5f65866d-784e-2379-9285-33043e1d9b81@gmail.com>

On 09/07/2018 6:18 AM, Steven Yen wrote:
> I have had trouble installing packages (e.g., car, aod) in some
> computers (such as computers in the student lab) but no problem in my
> own laptop.
> Installation typically goes through, but after I got out and back in R
> (and RStudios), the error message says "packages xxx not available".
> That is, earlier installation of the packages did not stay (despite the
> successful installation message).
> I went back as far as R3.0.3 and there is no problem.
> Does this tell anyone what may be going on? Thanks.
> 

The most common package installation problem in Windows is using 
different permissions to install R and the packages.  Typically R is 
installed as administrator, but the packages are not.  This means the 
packages can't be installed to the system library, so they get installed 
in a user's personal library, and the user probably may need to set 
.libPaths() explicitly to see them.

To check for this, print .libPaths() just after installing the packages, 
and again when starting a new session.  If the printed list of paths is 
different, you'll have problems.

Duncan Murdoch



From er|cjberger @end|ng |rom gm@||@com  Mon Jul  9 14:19:50 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 9 Jul 2018 15:19:50 +0300
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
In-Reply-To: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
References: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
Message-ID: <CAGgJW75rsAfgadJQ4xnNRJ+Ar4z7Qk5VwTWtsCfc5XoSwHGy+Q@mail.gmail.com>

I found the following at
https://stackoverflow.com/questions/25269425/merge-zoo-removes-time-zone

library(xts)

merge2=function(x,y) {
  as.zoo(merge(as.xts(x), as.xts(y)))}

If you define the function merge2() as above then

merge2(Dat1,Dat2)

should be ok

HTH,
Eric


On Mon, Jul 9, 2018 at 1:22 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> Below is my code :
>
> library(zoo)
> Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
>
> merge(Dat1, Dat2)
>
>                         Dat1     Dat2
> 2017-12-07 22:09:00 17890.00 15804.28
> 2017-12-07 22:10:00 17770.01 15720.61
> 2017-12-07 22:11:00 17600.00 15770.00
> 2017-12-07 22:12:00 17593.00 15750.00
> 2017-12-07 22:13:00 17630.01 15770.00
>
>
> So, after merging the TZ of the original series got changed.
>
> Appreciate if someone points what went wrong
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jul  9 15:26:58 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 9 Jul 2018 18:56:58 +0530
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
In-Reply-To: <20180709103104.GA1199@albert.catwhisker.org>
References: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
 <20180709103104.GA1199@albert.catwhisker.org>
Message-ID: <CA+dpOJn-jEJR-1V4C+T=n1pOQJxRHtgPyNLCH=xjsjnRtF6S=w@mail.gmail.com>

My default is set as GMT.

On Mon, Jul 9, 2018 at 4:01 PM David Wolfskill <r at catwhisker.org> wrote:

> On Mon, Jul 09, 2018 at 03:52:02PM +0530, Christofer Bogaso wrote:
> > Hi,
> >
> > Below is my code :
> >
> > library(zoo)
> > Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
> > structure(c(1512664740,
> > 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> > "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> > Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
> > structure(c(1512664740,
> > 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> > "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> >
> > merge(Dat1, Dat2)
> >
> >                         Dat1     Dat2
> > 2017-12-07 22:09:00 17890.00 15804.28
> > 2017-12-07 22:10:00 17770.01 15720.61
> > 2017-12-07 22:11:00 17600.00 15770.00
> > 2017-12-07 22:12:00 17593.00 15750.00
> > 2017-12-07 22:13:00 17630.01 15770.00
> >
> >
> > So, after merging the TZ of the original series got changed.
> >
> > Appreciate if someone points what went wrong
> > ....
>
> Well... when I do the above, I see:
>
> > Dat1
> 2017-12-07 08:39:00 2017-12-07 08:40:00 2017-12-07 08:41:00 2017-12-07
> 08:42:00
>            17890.00            17770.01            17600.00
> 17593.00
> 2017-12-07 08:43:00
>            17630.01
> > Dat2
> 2017-12-07 08:39:00 2017-12-07 08:40:00 2017-12-07 08:41:00 2017-12-07
> 08:42:00
>            15804.28            15720.61            15770.00
> 15750.00
> 2017-12-07 08:43:00
>            15770.00
> > merge(Dat1, Dat2)
>
>                         Dat1     Dat2
> 2017-12-07 08:39:00 17890.00 15804.28
> 2017-12-07 08:40:00 17770.01 15720.61
> 2017-12-07 08:41:00 17600.00 15770.00
> 2017-12-07 08:42:00 17593.00 15750.00
> 2017-12-07 08:43:00 17630.01 15770.00
> >
>
> That said, one aspect that may be relevant:
> > Sys.timezone()
> [1] "America/Los_Angeles"
>
> What's yours?
>
>
> Peace,
> david
> --
> David H. Wolfskill                              r at catwhisker.org
> "Fly, Trump Baby!" -- only the biggest, YUGEST insults for Donald J. Trump!
>
> See http://www.catwhisker.org/~david/publickey.gpg for my public key.
>

	[[alternative HTML version deleted]]



From |uke@m@ng@||@o@dunc@n @end|ng |rom gm@||@com  Mon Jul  9 15:34:38 2018
From: |uke@m@ng@||@o@dunc@n @end|ng |rom gm@||@com (Luke Duncan)
Date: Mon, 9 Jul 2018 15:34:38 +0200
Subject: [R] glmer won't allow quasi- distribution mixed models
Message-ID: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>

Dear R folk

I am trying to run a series of models on distance data for three different
species of animals. My data are not zero-inflated (distances were recorded
for locomotion only and so if the animal didn't move, it wasn't recorded)
and are Poisson distributed. However, all of the models that I run are
horrifically over-dispersed and based on what I read online I thought that
maybe I should consider using a quasi-Poisson distribution to attempt to
account for the over-dispersion. All the online posts of others show that
they do so successfully but for some reason, my lme4 package cannot use
quasi-distributions. I have uninstalled and reinstalled R and the packages
and I still get the same problem.

I am

a) at a loss as to how to deal with the over-dispersion I have and
b) baffled by the fact that lme4 everywhere else can cope with
quasi-distributions but mine can't.

Any help would be appreciated!

My code:

library(lme4)
woodlicedata<-read.csv("Woodlice.csv",header=T)
attach(woodlicedata)
names(woodlicedata)
> ### This set of models examine whether there are differences in distances
travelled.
>
distmodel<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=poisson(link='log'))
> summary(distmodel)  ### AIC= 42972.6
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
glmerMod]
 Family: poisson  ( log )
Formula: Distance ~ Treatment * Sex + (1 | ID) + (1 | Path.set/ID)

     AIC      BIC   logLik deviance df.resid
 42972.6  43007.3 -21479.3  42958.6     1038

Scaled residuals:
    Min      1Q  Median      3Q     Max
-11.853  -4.074  -1.656   2.146  38.035

Random effects:
 Groups      Name        Variance  Std.Dev.
 ID:Path.set (Intercept) 6.485e-02 0.2546560
 ID          (Intercept) 6.906e-02 0.2627973
 Path.set    (Intercept) 1.368e-10 0.0000117
Number of obs: 1045, groups:  ID:Path.set, 104; ID, 52; Path.set, 2

Fixed effects:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  4.20814    0.07757  54.248  < 2e-16 ***
TreatmentRestricted          0.10843    0.14359   0.755  0.45015
SexMale                     -0.08408    0.11545  -0.728  0.46644
TreatmentRestricted:SexMale -0.49300    0.18781  -2.625  0.00866 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) TrtmnR SexMal
TrtmntRstrc -0.540
SexMale     -0.672  0.363
TrtmntRs:SM  0.413 -0.765 -0.615

>
distmodel2<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=quasipoisson(link='log'))
Error in lme4::glFormula(formula = Distance ~ Treatment * Sex + (1 | ID) +
:
  "quasi" families cannot be used in glmer

	[[alternative HTML version deleted]]



From t@n@@@ @end|ng |rom gm@||@com  Mon Jul  9 16:09:18 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Mon, 9 Jul 2018 07:09:18 -0700
Subject: [R] about ECDF display in ggplot2
In-Reply-To: <alpine.BSF.2.00.1807090119280.18090@pedal.dcn.davis.ca.us>
References: <CA+JEM02O=cvy3Udvu4UDmyB2d5D7356iyuhYNUXORUo_MNH9uQ@mail.gmail.com>
 <alpine.BSF.2.00.1807090119280.18090@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM02G=+6vExRCvN1+O5yL8VGKpuLP3SQRD6an8Ak5Z+YxsA@mail.gmail.com>

Dear Jeff,

thank you for all your time, and very precious help.

with best regards.

-- bogdan

On Mon, Jul 9, 2018 at 1:41 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Thank you for making the effort... but most attachments get stripped on
> the mailing list. Using the reprex package as I suggested and putting the
> result into the email is by far the safest approach. Since I received your
> email directly, I did get the attachments. Below is my reproducible
> example... to serve as an example for how you can get help from everyone on
> the list rather than just the few you are responding to.
>
> My summary comment is that you have to decide whether the LENGTH values
> greater than 500 are relevant... and if they are, you REALLY SHOULD create
> a data set that is limited in this fashion. Then you won't have to create
> "fake" axes, and you won't get ggplot warnings.
>
> Note: The reprex package allows you to confirm that the example is in fact
> reproducible, so technically it is not necessary to include the plot images
> in the question. However, reprex used to conveniently support putting the
> images on the imgur website, and for some reason it no longer does that, so
> just run the example interactively to see the graphs.
>
> #######
> ############################################################
> ############################################################
>
> library("ggplot2")
>
> # "file" is the name of a very fundamental function in base R. Re-using
> # that name for a data value is at best confusing to anyone reading your
> # code and at worst will prevent you from using that function.
> #file <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
>
> # Instead of giving us a file, keep the data within the example
> # DF <- read.delim("LENGTH", sep="\t", header=T, stringsAsFactors=F)
> # set.seed( 42 )
> # also shrink the size of the data for the example... we almost
> # never need all of it
> # dput( DF[ sample( seq.int( nrow( DF ) ), size = 200 ), , drop=FALSE ] )
> DF <- structure(list(LENGTH = c(6813L, 56035L, 123997L, 281L, 851L, 1072L,
>           72196L, 21L, 304L, 110L, 198L, 5922L, 283L, 199348L, 109L,
>           3317104L, 106L, 37642146L, 82641L, 20L, 125911L, 354L, 11625388L,
>           330L, 9811711L, 18L, 35L, 39897L, 27L, 277L, 79L, 2657L, 17L,
>           26L, 23L, 248L, 3634L, 21L, 324L, 206L, 328L, 42L, 286L,
> 6042409L,
>           24L, 36L, 2879L, 18L, 301L, 90684L, 4296636L, 43L, 1222L, 4536L,
>           3281L, 324L, 393L, 3754L, 98824541L, 459L, 18L, 1081L, 175L,
>           970L, 17L, 219L, 235558L, 1167315L, 25L, 623L, 2517515L, 32L,
>           217L, 29L, 17L, 1744L, 18L, 39L, 26L, 77L, 41L, 22L, 311L,
> 119015225L,
>           146413L, 22L, 19L, 301L, 373L, 2240L, 6439L, 128L, 18L, 257L,
>           783L, 5169L, 31608038L, 325L, 1533L, 25L, 69344L, 54L, 10651L,
>           31L, 335062L, 1854019L, 7153L, 38605567L, 51L, 23L, 16L, 301L,
>           79L, 313L, 18L, 29L, 39L, 22L, 17L, 306L, 67L, 280L, 324L, 158L,
>           93L, 2561L, 302L, 134578L, 328L, 9002L, 969051L, 34L, 20L, 309L,
>           355L, 28L, 9461327L, 18627013L, 305L, 64L, 18L, 2730L, 28L, 246L,
>           911L, 28L, 241483L, 154691L, 58891L, 55L, 456362L, 281L, 276L,
>           51L, 26L, 106821L, 313L, 78L, 29L, 400L, 61171382L, 200L, 101L,
>           220331L, 128L, 325L, 28L, 22L, 325L, 2330L, 5879L, 24L, 36L,
>           23L, 51L, 26L, 32584707L, 1672L, 13939L, 315L, 20L, 580785L,
>           42795L, 49193543L, 695L, 48568156L, 55634L, 207L, 318L, 22056L,
>           3670420L, 4815387L, 309L, 17L, 3143160L, 431L, 1164L, 33L, 5503L,
>           4166L)), .Names = "LENGTH", row.names = c(8283L, 8484L, 2591L,
>           7517L, 5808L, 4698L, 6665L, 1219L, 5944L, 6378L, 4140L, 6503L,
>           8452L, 2310L, 4180L, 8497L, 8842L, 1062L, 4293L, 5063L, 8168L,
>           1253L, 8932L, 8550L, 745L, 4643L, 3523L, 8177L, 4035L, 7545L,
>           6657L, 7319L, 3502L, 6181L, 36L, 7513L, 67L, 1873L, 8174L, 5516L,
>           3422L, 3928L, 338L, 8773L, 3891L, 8627L, 7997L, 5765L, 8745L,
>           5573L, 3003L, 3122L, 3588L, 7064L, 351L, 6739L, 6095L, 1541L,
>           2349L, 4628L, 6077L, 8839L, 6830L, 5094L, 7639L, 1704L, 2439L,
>           7443L, 6230L, 2162L, 387L, 1262L, 1944L, 4306L, 1773L, 6460L,
>           71L, 3371L, 4618L, 15L, 5220L, 1417L, 3222L, 5792L, 6960L, 5056L,
>           2096L, 807L, 768L, 2737L, 5983L, 3L, 1870L, 8361L, 8294L, 6577L,
>           2984L, 4614L, 6664L, 5545L, 5608L, 1945L, 1939L, 3482L, 8435L,
>           8615L, 6621L, 6561L, 4793L, 21L, 5447L, 7484L, 6721L, 4048L,
>           4790L, 4804L, 13L, 3179L, 5471L, 7407L, 3187L, 3669L, 5123L,
>           5267L, 6427L, 3527L, 8207L, 8593L, 2085L, 6467L, 8065L, 5385L,
>           5635L, 8363L, 7587L, 5172L, 7326L, 1015L, 6817L, 5560L, 1324L,
>           716L, 4136L, 6945L, 6536L, 7281L, 1516L, 8415L, 2616L, 1328L,
>           6406L, 2886L, 6933L, 3511L, 6040L, 6905L, 1672L, 259L, 1208L,
>           6051L, 8315L, 4896L, 5351L, 1752L, 4759L, 1597L, 4017L, 2818L,
>           1033L, 1654L, 6483L, 3659L, 3678L, 4266L, 3797L, 1212L, 7322L,
>           5258L, 7052L, 6826L, 8147L, 7655L, 2813L, 2300L, 6584L, 6629L,
>           8140L, 7034L, 1183L, 2551L, 1726L, 6950L, 1143L, 1144L, 641L,
>           471L, 4712L, 995L, 6582L, 6476L), class = "data.frame")
>
>
> ############################# display with PLOT FUNCTION:
>
>
> # saving files should be avoided in reproducible examples... especially
> files
> # that cannot be transmitted through the R-help mailing list such as pdf
> files
> #pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6, paper='special')
>
> # Your original plot commands below create a fake impression of the data by
> # falsifying the axes. If you really are only interested in data points
> less
> # than 500, you should be explicit about creating a data set containing
> only
> # such constrained values before plotting them.
> plot(ecdf(DF$LENGTH), xlab="DEL SIZE",
>                      ylab="fraction of DEL",
>                      main="LENGTH of DEL",
>                      xlim=c(0,500),
>                      col = "dark red", axes = FALSE)
> ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
> axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
> ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
> axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-1.png)
>
> # my recommendation
> DF500 <- subset( DF, LENGTH < 500 )
> plot( ecdf( DF500$LENGTH )
>     , xlab = "DEL SIZE"
>     , ylab = "fraction of DEL"
>     , main = "LENGTH of DEL"
>     , col = "dark red"
>     )
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-2.png)
>
> # alternatively
> plot( ecdf( DF$LENGTH )
>     , xlab = "DEL SIZE"
>     , ylab = "fraction of DEL"
>     , main = "LENGTH of DEL"
>     , col = "dark red"
>     , xlim=c( 1, 1e9 )
>     , log="x"
>     )
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-3.png)
>
>
>
> #dev.off()
>
> ############################# display in GGPLOT2 :
>
> BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500,
>            1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000)
>
> barfill <- "#4271AE"
> barlines <- "#1F3552"
>
> #pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
> paper='special')
>
> # ggplot's limits behavior is enabling your false representation of the
> data, but it
> # warns you of the data removal
> ggplot(DF, aes(LENGTH)) +
>           stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>           scale_x_continuous(name = "LENGTH of DEL",
>                              breaks = BREAKS,
>                              limits=c(0, 500)
>                              ) +
>           scale_y_continuous(name = "FRACTION") +
>           ggtitle("ECDF of LENGTH") +
>           theme_bw() +
>           theme(legend.position = "bottom", legend.direction =
> "horizontal",
>                legend.box = "horizontal",
>                legend.key.size = unit(1, "cm"),
>                axis.title = element_text(size = 12),
>                legend.text = element_text(size = 9),
>                legend.title=element_text(face = "bold", size = 9))
> #> Warning: Removed 80 rows containing non-finite values (stat_ecdf).
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-4.png)
>
>
> # my recommendation
> ggplot(DF500, aes(LENGTH)) +
>   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>   scale_x_continuous(name = "LENGTH of DEL",
>                      breaks = BREAKS ) +
>   scale_y_continuous(name = "FRACTION") +
>   ggtitle("ECDF of LENGTH") +
>   theme_bw() +
>   theme(legend.position = "bottom", legend.direction = "horizontal",
>         legend.box = "horizontal",
>         legend.key.size = unit(1, "cm"),
>         axis.title = element_text(size = 12),
>         legend.text = element_text(size = 9),
>         legend.title=element_text(face = "bold", size = 9))
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-5.png)
>
> # or for the un-filtered data
> ggplot(DF, aes(LENGTH)) +
>   stat_ecdf(geom = "point", colour = barlines, fill = barfill) +
>   scale_x_log10( name = "LENGTH of DEL") +
>   scale_y_continuous(name = "FRACTION") +
>   ggtitle("ECDF of LENGTH") +
>   theme_bw() +
>   theme(legend.position = "bottom", legend.direction = "horizontal",
>         legend.box = "horizontal",
>         legend.key.size = unit(1, "cm"),
>         axis.title = element_text(size = 12),
>         legend.text = element_text(size = 9),
>         legend.title=element_text(face = "bold", size = 9))
>
> #' ![](file1f4143e5e164_reprex_files/figure-markdown_strict/rep
> rex-body-6.png)
>
>
> #dev.off()
>
> #' Created on 2018-07-09 by the [reprex package](http://reprex.tidyver
> se.org) (v0.2.0).
> #######
>
>
> On Sun, 8 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Jeff,
>> thank you for your email.
>>
>> Yes, in order to be more descriptive/comprehensive, please find attached
>> to
>> my email the following files (my apologies ... I am sending these as
>> attachments, as I do not have a web server running at this moment) :
>>
>> -- the R script (R_script_display_ECDF.R) that reads the file "LENGTH" and
>> outputs ECDF figure by using the standard R function or ggplot2.
>>
>> -- the display of ECDF by using standard R function
>> ("display.R.ecdf.LENGTH.pdf")
>>
>> -- the display of ECDF by using ggplot2 ("display.ggplot2.ecdf.LENGTH.
>> pdf")
>>
>> The ECDF over xlim(0,500) looks very different (contrasting plot(ecdf) vs
>> ggplot2).  Please would you advise why ? what shall I change in my ggplot2
>> code ?
>>
>> thanks a lot,
>>
>> - bogdan
>>
>> ps : the R code is also written below :
>>
>>        library("ggplot2")
>>
>>
>>       file <- read.delim("LENGTH", sep="\t", header=T,
>>       stringsAsFactors=F)
>>
>>
>>       ############################# display with PLOT FUNCTION:
>>
>>
>>       pdf("display.R.ecdf.LENGTH.pdf", width=10, height=6,
>>       paper='special')
>>
>>
>>       plot(ecdf(file$LENGTH), xlab="DEL SIZE",
>>                            ylab="fraction of DEL",
>>                            main="LENGTH of DEL",
>>                            xlim=c(0,500),
>>                            col = "dark red", axes = FALSE)
>>
>>
>>       ticks_y <- c(0, 0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4)
>>
>>
>>       axis(2, at=ticks_y, labels=ticks_y, col.axis="red")
>>
>>
>>       ticks_x <- c(0, 100, 200, 400, 500, 600, 700, 800)
>>
>>
>>       axis(1, at=ticks_x, labels=ticks_x, col.axis="blue")
>>
>>
>>       dev.off()
>>
>>
>>       ############################# display in GGPLOT2 :
>>
>>
>>       BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
>>       400, 500,
>>                  1000, 10000, 100000, 1000000, 10000000, 100000000,
>>       1000000000)
>>
>>
>>       barfill <- "#4271AE"
>>       barlines <- "#1F3552"
>>
>>
>>       pdf("display.ggplot2.ecdf.LENGTH.pdf", width=10, height=6,
>>       paper='special')
>>
>>
>>       ggplot(file, aes(LENGTH)) +
>>                 stat_ecdf(geom = "point", colour = barlines, fill =
>>       barfill) +
>>                 scale_x_continuous(name = "LENGTH of DEL",
>>                                    breaks = BREAKS,
>>                                    limits=c(0, 500)) +
>>                 scale_y_continuous(name = "FRACTION") +
>>                 ggtitle("ECDF of LENGTH") +
>>                 theme_bw() +
>>                 theme(legend.position = "bottom", legend.direction =
>>       "horizontal",
>>                      legend.box = "horizontal",
>>                      legend.key.size = unit(1, "cm"),
>>                      axis.title = element_text(size = 12),
>>                      legend.text = element_text(size = 9),
>>                      legend.title=element_text(face = "bold", size =
>>       9))
>>
>>
>>       dev.off()
>>
>>
>>
>>
>>
>>
>>
>> On Sat, Jul 7, 2018 at 9:47 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>       It is a feature of ggplot that points excluded by limits raise
>>       warnings, while base graphics do not.
>>
>>       You may find that using coord_cartesian with the xlim=c(0,500)
>>       argument works better with ggplot by showing the consequences of
>>       points out of the limits on lines within the viewport.
>>
>>       There are other possible problems with your data that your
>>       non-reproducible example does not show, and sending R code in
>>       HTML-formatted email usually corrupts it.. so please follow the
>>       recommendations in the Posting Guide next time you post.
>>
>>       On July 6, 2018 4:32:41 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
>>       wrote:
>>       >Dear all,
>>       >
>>       >I would appreciate having your advice/suggestions/comments on
>>       the
>>       >following
>>       >:
>>       >
>>       >1 -- starting from a vector that contains LENGTHS (numerically,
>>       the
>>       >values
>>       >are from 1 to 10 000)
>>       >
>>       >2 -- shall I display the ECDF by using the R code and some
>>       "limits" :
>>       >
>>       >BREAKS = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>>       300, 400,
>>       >500,
>>       >         1000, 10000, 100000, 1000000, 10000000, 100000000,
>>       1000000000)
>>       >
>>       >ggplot(x, aes(LENGTH)) +
>>       >          stat_ecdf(geom = "point") +
>>       >          scale_x_continuous(name = "LENGTH of DEL",
>>       >                             breaks = BREAKS,
>>       >                             limits=c(0, 500))
>>       >
>>       >3 -- I am getting the following warning message : "Warning
>>       message:
>>       >Removed
>>       >109 rows containing non-finite values (stat_ecdf)."
>>       >
>>       >The question is : are these 109 values removed from
>>       VISUALIZATION as i
>>       >set
>>       >up the "limits", or are these 109 values removed from
>>       statistical
>>       >CALCULATION?
>>       >
>>       >4 -- in contrast, shall I use the standard R functions
>>       plot(ecdf),
>>       >there is
>>       >no "warning mesage"
>>       >
>>       >plot(ecdf(x$LENGTH), xlab="DEL LENGTH",
>>       >                     ylab="Fraction of DEL", main="DEL",
>>       xlim=c(0,500),
>>       >                     col = "dark red")
>>       >
>>       >Thanks a lot !
>>       >
>>       >-- bogdan
>>       >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>>
>>
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul  9 16:25:33 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Jul 2018 07:25:33 -0700
Subject: [R] glmer won't allow quasi- distribution mixed models
In-Reply-To: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>
References: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>
Message-ID: <CAGxFJbTxh=i6U6Y9AT0HThyp1Pkeoadrbk6KzFSoPz+y=1PEnA@mail.gmail.com>

You should probably post this on the r-sig-mixed-models list instead, where
you are more likely to find the expertise to diagnose the problem and give
you a helpful response.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 6:34 AM, Luke Duncan <luke.mangaliso.duncan at gmail.com
> wrote:

> Dear R folk
>
> I am trying to run a series of models on distance data for three different
> species of animals. My data are not zero-inflated (distances were recorded
> for locomotion only and so if the animal didn't move, it wasn't recorded)
> and are Poisson distributed. However, all of the models that I run are
> horrifically over-dispersed and based on what I read online I thought that
> maybe I should consider using a quasi-Poisson distribution to attempt to
> account for the over-dispersion. All the online posts of others show that
> they do so successfully but for some reason, my lme4 package cannot use
> quasi-distributions. I have uninstalled and reinstalled R and the packages
> and I still get the same problem.
>
> I am
>
> a) at a loss as to how to deal with the over-dispersion I have and
> b) baffled by the fact that lme4 everywhere else can cope with
> quasi-distributions but mine can't.
>
> Any help would be appreciated!
>
> My code:
>
> library(lme4)
> woodlicedata<-read.csv("Woodlice.csv",header=T)
> attach(woodlicedata)
> names(woodlicedata)
> > ### This set of models examine whether there are differences in distances
> travelled.
> >
> distmodel<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.
> set/ID),family=poisson(link='log'))
> > summary(distmodel)  ### AIC= 42972.6
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>  Family: poisson  ( log )
> Formula: Distance ~ Treatment * Sex + (1 | ID) + (1 | Path.set/ID)
>
>      AIC      BIC   logLik deviance df.resid
>  42972.6  43007.3 -21479.3  42958.6     1038
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -11.853  -4.074  -1.656   2.146  38.035
>
> Random effects:
>  Groups      Name        Variance  Std.Dev.
>  ID:Path.set (Intercept) 6.485e-02 0.2546560
>  ID          (Intercept) 6.906e-02 0.2627973
>  Path.set    (Intercept) 1.368e-10 0.0000117
> Number of obs: 1045, groups:  ID:Path.set, 104; ID, 52; Path.set, 2
>
> Fixed effects:
>                             Estimate Std. Error z value Pr(>|z|)
> (Intercept)                  4.20814    0.07757  54.248  < 2e-16 ***
> TreatmentRestricted          0.10843    0.14359   0.755  0.45015
> SexMale                     -0.08408    0.11545  -0.728  0.46644
> TreatmentRestricted:SexMale -0.49300    0.18781  -2.625  0.00866 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) TrtmnR SexMal
> TrtmntRstrc -0.540
> SexMale     -0.672  0.363
> TrtmntRs:SM  0.413 -0.765 -0.615
>
> >
> distmodel2<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.
> set/ID),family=quasipoisson(link='log'))
> Error in lme4::glFormula(formula = Distance ~ Treatment * Sex + (1 | ID) +
> :
>   "quasi" families cannot be used in glmer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From kev|n@thorpe @end|ng |rom utoronto@c@  Mon Jul  9 16:42:00 2018
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 14:42:00 +0000
Subject: [R] Using write.csv as a connection for read.csv
Message-ID: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>

Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

  Error in read.table(file = file, header = header, sep = sep, quote = quote,  : 
  'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
     


From er|cjberger @end|ng |rom gm@||@com  Mon Jul  9 16:51:38 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 9 Jul 2018 17:51:38 +0300
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>

Hi Kevin,
It's good that you provided the background to the problem.
Rather than asking this list to "debug" your proposed solution, I think you
would be better off showing some of the "corrupted" data frame and ask for
suggestions how to deal with it.
(Suggestions may or may not match your initial attempt.)
Can you output a piece of your suspect data frame via the dput() function
and post to the list?

Best,
Eric


On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Hi.
>
> I have some data frames I created previously that seem to not be working
> correctly anymore. I *think* the problem is that some of the variables in
> the data frame are of a type called labelled. There are other attributes in
> the data frame as well. I thought that the easiest way to fix this was to
> convert to, say a csv and re-load.
>
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
> the error
>
>   Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> I guess there must be a way to send the output of write.csv to a
> connection that read.csv can use but I was mystified by the help page on
> connections, at least I could not determine how to achieve my desired
> result.
>
> I realize I could write to a file and read it back in, but that feels
> klunky somehow. Maybe my approach to convert my data to strip the "weird"
> stuff is wrong-headed and I would accept alternative strategies.
>
> I would like a more general solution to fix this because I expect to
> encounter it some more. For those wondering how I found myself in such a
> mess, the data frames were initially imported from SAS data sets through
> the haven package. I then did some standard manipulation and added some
> additional labels with the upData() function from Hmisc (both packages have
> been updated since initial creation of the data frames).
>
> Thanks,
>
> Kevin
>
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From kev|n@thorpe @end|ng |rom utoronto@c@  Mon Jul  9 17:17:44 2018
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 15:17:44 +0000
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>,
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
Message-ID: <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>

Although your suggestion to provide the data is excellent and one I typically agree with, they data are currently unpublished and so should not be publicly available. I have tried to make a reproducible example in the past (when similar looking things happened), but was unable to. Maybe I'll try a small subset and see if that works.


Kevin


--
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Monday, July 9, 2018 10:51:38 AM
To: Kevin Thorpe
Cc: R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv

Hi Kevin,
It's good that you provided the background to the problem.
Rather than asking this list to "debug" your proposed solution, I think you would be better off showing some of the "corrupted" data frame and ask for suggestions how to deal with it.
(Suggestions may or may not match your initial attempt.)
Can you output a piece of your suspect data frame via the dput() function and post to the list?

Best,
Eric


On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>> wrote:
Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

  Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
  'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin

--
 Kevin E. Thorpe
 Head of Biostatistics,  Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>  Tel: 416.864.5776  Fax: 416.864.3016


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Mon Jul  9 17:28:22 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 9 Jul 2018 15:28:22 +0000
Subject: [R] R couldnt recognize US Pasific timezome
In-Reply-To: <alpine.BSF.2.00.1807090142300.18090@pedal.dcn.davis.ca.us>
References: <CA+dpOJ=eMuz8tuUUy=s2r80van15VErd705hAhOR-R0EYHyGYw@mail.gmail.com>
 <alpine.BSF.2.00.1807090142300.18090@pedal.dcn.davis.ca.us>
Message-ID: <25DE78EF-69BD-46E5-887E-573EAAEC370C@llnl.gov>

Or (perhaps preferably) "US/Pacific" for daylight savings time support.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/9/18, 1:46 AM, "R-help on behalf of Jeff Newmiller" <r-help-bounces at r-project.org on behalf of jdnewmil at dcn.davis.ca.us> wrote:

    Several of the "conventional" three letter timezone abbreviations actually 
    get re-used in different parts of the world, and not all operating system 
    support for timezones include the same shortcuts. The solution is to use 
    the correct timezone string rather than your familiar shortcut... you can 
    look through the vector returned by the OlsonNames() function in general, 
    but in your case just use "Etc/GMT+8" for standard time year-round. If you 
    wanted daylight savings time support, you would use "America/Los_Angeles".
    
    On Mon, 9 Jul 2018, Christofer Bogaso wrote:
    
    > Hi,
    >
    > I wanted to convert Epoch time to readable time with US Pacific Time Zone
    > using 'anytime' package, as below:
    >
    >> library(anytime)
    >> anytime(1417411980, tz = 'PST')
    > [1] "2014-12-01 05:33:00 GMT"
    > Warning message:
    > In as.POSIXlt.POSIXct(x, tz) : unknown timezone 'PST'
    >
    >
    > However it appears that R couldn't recognize the PST as the short form of
    > Pacific time zone.
    >
    > Any help to correctly change Epoch time to corresponding pacific time would
    > be helpful.
    >
    > Thanks,
    >
    > 	[[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >
    
    ---------------------------------------------------------------------------
    Jeff Newmiller                        The     .....       .....  Go Live...
    DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                           Live:   OO#.. Dead: OO#..  Playing
    Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
    /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul  9 17:40:55 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Jul 2018 08:40:55 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
 <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbSLaLA+-1a5kVnhR5VVtEqD=ayD_Oi5LRcAyNB=oQovWQ@mail.gmail.com>

Can you not anonymize column names, add random noise to some of the
columns, etc. ?

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 8:17 AM, Kevin Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Although your suggestion to provide the data is excellent and one I
> typically agree with, they data are currently unpublished and so should not
> be publicly available. I have tried to make a reproducible example in the
> past (when similar looking things happened), but was unable to. Maybe I'll
> try a small subset and see if that works.
>
>
> Kevin
>
>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> ________________________________
> From: Eric Berger <ericjberger at gmail.com>
> Sent: Monday, July 9, 2018 10:51:38 AM
> To: Kevin Thorpe
> Cc: R Help Mailing List
> Subject: Re: [R] Using write.csv as a connection for read.csv
>
> Hi Kevin,
> It's good that you provided the background to the problem.
> Rather than asking this list to "debug" your proposed solution, I think
> you would be better off showing some of the "corrupted" data frame and ask
> for suggestions how to deal with it.
> (Suggestions may or may not match your initial attempt.)
> Can you output a piece of your suspect data frame via the dput() function
> and post to the list?
>
> Best,
> Eric
>
>
> On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<
> mailto:kevin.thorpe at utoronto.ca>> wrote:
> Hi.
>
> I have some data frames I created previously that seem to not be working
> correctly anymore. I *think* the problem is that some of the variables in
> the data frame are of a type called labelled. There are other attributes in
> the data frame as well. I thought that the easiest way to fix this was to
> convert to, say a csv and re-load.
>
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
> the error
>
>   Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> I guess there must be a way to send the output of write.csv to a
> connection that read.csv can use but I was mystified by the help page on
> connections, at least I could not determine how to achieve my desired
> result.
>
> I realize I could write to a file and read it back in, but that feels
> klunky somehow. Maybe my approach to convert my data to strip the "weird"
> stuff is wrong-headed and I would accept alternative strategies.
>
> I would like a more general solution to fix this because I expect to
> encounter it some more. For those wondering how I found myself in such a
> mess, the data frames were initially imported from SAS data sets through
> the haven package. I then did some standard manipulation and added some
> additional labels with the upData() function from Hmisc (both packages have
> been updated since initial creation of the data frames).
>
> Thanks,
>
> Kevin
>
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>  Tel:
> 416.864.5776  Fax: 416.864.3016
>
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From kev|n@thorpe @end|ng |rom utoronto@c@  Mon Jul  9 17:44:30 2018
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 15:44:30 +0000
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>,
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>,
 <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <YTOPR0101MB1769B641DDBE4A716AD082E995440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>

So, after I sent the initial email I quit that R session entirely. When I started it again to try an provide the example data, the original (that I had a problem with before) is now behaving itself. Grrr.

Now no one is going to believe I ever had a problem with the data. :-)

  
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
     



From: R-help <r-help-bounces at r-project.org> on behalf of Kevin Thorpe <kevin.thorpe at utoronto.ca>
Sent: Monday, July 9, 2018 11:17 AM
To: Eric Berger
Cc: R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv
? 

Although your suggestion to provide the data is excellent and one I typically agree with, they data are currently unpublished and so should not be publicly available. I have tried to make a reproducible example in the past (when similar  looking things happened), but was unable to. Maybe I'll try a small subset and see if that works.


Kevin


--
Kevin E. Thorpe
Head of Biostatistics,? Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016

________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Monday, July 9, 2018 10:51:38 AM
To: Kevin Thorpe
Cc: R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv

Hi Kevin,
It's good that you provided the background to the problem.
Rather than asking this list to "debug" your proposed solution, I think you would be better off showing some of the "corrupted" data frame and ask for suggestions how to deal with it.
(Suggestions may or may not match your initial attempt.)
Can you output a piece of your suspect data frame via the dput() function and post to the list?

Best,
Eric


On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>> wrote:
Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought  that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

? Error in read.table(file = file, header = header, sep = sep, quote = quote,? :
? 'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard  manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin

--
?Kevin E. Thorpe
?Head of Biostatistics,? Applied Health Research Centre (AHRC)
?Li Ka Shing Knowledge Institute of St. Michael's
?Assistant Professor, Dalla Lana School of Public Health
?University of Toronto
?email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>? Tel: 416.864.5776? Fax: 416.864.3016


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


??????? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jul  9 17:57:53 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 9 Jul 2018 08:57:53 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769B641DDBE4A716AD082E995440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
 <CAGgJW750rnsDtKTJ0E30g8EGt-4X17Z6uAA=BA=Fc+Oh6P=ERw@mail.gmail.com>
 <YTOPR0101MB176987E4D1AB2FECB27A24A095440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
 <YTOPR0101MB1769B641DDBE4A716AD082E995440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <4019952C-A261-4356-B774-F10925581C6C@comcast.net>


> On Jul 9, 2018, at 8:44 AM, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
> 
> So, after I sent the initial email I quit that R session entirely. When I started it again to try an provide the example data, the original (that I had a problem with before) is now behaving itself. Grrr.
> 
> Now no one is going to believe I ever had a problem with the data. :-)

Your initial code looked flawed to me.

You were passing the result of write.csv (which returns NULL) to read.csv

Perhaps you modified your code and that's the reason it now succeeds.

Best,
David
> 
> 
> 
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> 
> 
> 
> 
> From: R-help <r-help-bounces at r-project.org> on behalf of Kevin Thorpe <kevin.thorpe at utoronto.ca>
> Sent: Monday, July 9, 2018 11:17 AM
> To: Eric Berger
> Cc: R Help Mailing List
> Subject: Re: [R] Using write.csv as a connection for read.csv
>   
> 
> Although your suggestion to provide the data is excellent and one I typically agree with, they data are currently unpublished and so should not be publicly available. I have tried to make a reproducible example in the past (when similar  looking things happened), but was unable to. Maybe I'll try a small subset and see if that works.
> 
> 
> Kevin
> 
> 
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
> 
> ________________________________
> From: Eric Berger <ericjberger at gmail.com>
> Sent: Monday, July 9, 2018 10:51:38 AM
> To: Kevin Thorpe
> Cc: R Help Mailing List
> Subject: Re: [R] Using write.csv as a connection for read.csv
> 
> Hi Kevin,
> It's good that you provided the background to the problem.
> Rather than asking this list to "debug" your proposed solution, I think you would be better off showing some of the "corrupted" data frame and ask for suggestions how to deal with it.
> (Suggestions may or may not match your initial attempt.)
> Can you output a piece of your suspect data frame via the dput() function and post to the list?
> 
> Best,
> Eric
> 
> 
> On Mon, Jul 9, 2018 at 5:42 PM, Kevin Thorpe <kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>> wrote:
> Hi.
> 
> I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought  that the easiest way to fix this was to convert to, say a csv and re-load.
> 
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error
> 
>   Error in read.table(file = file, header = header, sep = sep, quote = quote,  :
>   'file' must be a character string or connection
> 
> I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.
> 
> I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.
> 
> I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard  manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).
> 
> Thanks,
> 
> Kevin
> 
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca<mailto:kevin.thorpe at utoronto.ca>  Tel: 416.864.5776  Fax: 416.864.3016
> 
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From wdun|@p @end|ng |rom t|bco@com  Mon Jul  9 18:07:38 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 9 Jul 2018 09:07:38 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcZHQghg0-BfdUW3m=P=5+ON7y7MrZnj+NWBbrppAd3P5A@mail.gmail.com>

 >I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
the error
>
>  Error in read.table(file = file, header = header, sep = sep, quote =
quote,  :
>  'file' must be a character string or connection

To diagnose this without reading the help(write.csv) look at the return
value of write.csv:
  > df <- data.frame(Col1=1:3, Col2=LETTERS[24:26])
  > tmp <- write.csv(df, row.names=FALSE)
  "Col1","Col2"
  1,"X"
  2,"Y"
  3,"Z"
  > tmp
  NULL

read.csv complains about reading from NULL:
  > read.csv(NULL)
  Error in read.table(file = file, header = header, sep = sep, quote =
quote,  :
    'file' must be a character string or connection




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jul 9, 2018 at 7:42 AM, Kevin Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Hi.
>
> I have some data frames I created previously that seem to not be working
> correctly anymore. I *think* the problem is that some of the variables in
> the data frame are of a type called labelled. There are other attributes in
> the data frame as well. I thought that the easiest way to fix this was to
> convert to, say a csv and re-load.
>
> I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
> the error
>
>   Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> I guess there must be a way to send the output of write.csv to a
> connection that read.csv can use but I was mystified by the help page on
> connections, at least I could not determine how to achieve my desired
> result.
>
> I realize I could write to a file and read it back in, but that feels
> klunky somehow. Maybe my approach to convert my data to strip the "weird"
> stuff is wrong-headed and I would accept alternative strategies.
>
> I would like a more general solution to fix this because I expect to
> encounter it some more. For those wondering how I found myself in such a
> mess, the data frames were initially imported from SAS data sets through
> the haven package. I then did some standard manipulation and added some
> additional labels with the upData() function from Hmisc (both packages have
> been updated since initial creation of the data frames).
>
> Thanks,
>
> Kevin
>
> --
>  Kevin E. Thorpe
>  Head of Biostatistics,  Applied Health Research Centre (AHRC)
>  Li Ka Shing Knowledge Institute of St. Michael's
>  Assistant Professor, Dalla Lana School of Public Health
>  University of Toronto
>  email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  9 19:01:24 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Jul 2018 10:01:24 -0700
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <B365845E-56B0-40FF-8ED2-94D0AD303B90@dcn.davis.ca.us>

TL;DR: If you want to do this, go ahead and use a temporary file or text connection.

Others have pointed out that write.csv returns NULL rather than a file connection, but I haven't seen comments on your impulse to avoid the use of files.

*nix operating systems are admirably efficient with multitasking... such that shells can efficiently run multiple programs connected by pipes, pausing the producers to pause if they get ahead of the consumers and resuming them if the consumers run out of data, thus minimizing the amount of temporary disk space usage.

R does not presume this to be among the fundamental capabilities of the operating system, rather assuming single tasking capability by default. This means that even if you do connect write.csv to a pipe then it will run to completion before read.csv gets a chance to process any of the data. MSDOS used to simulate command line program chaining by writing all the data to a temporary file before running the consumer program. R is similar... and like MSDOS there is little reason to avoid temporary files in R.

set.seed( 42 )
DF <- data.frame( X=1:100, Y=rnorm( 100 ) )
frame <- tempfile()
write.csv( DF, file=fname, row.names=FALSE )
DF2 <- read.csv( file=fname )
all.equal( DF$X, DF2$X ) && all.equal( DF$Y, DF2$Y )
unlink( fname )


On July 9, 2018 7:42:00 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>Hi.
>
>I have some data frames I created previously that seem to not be
>working correctly anymore. I *think* the problem is that some of the
>variables in the data frame are of a type called labelled. There are
>other attributes in the data frame as well. I thought that the easiest
>way to fix this was to convert to, say a csv and re-load.
>
>I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
>the error
>
>Error in read.table(file = file, header = header, sep = sep, quote =
>quote,  : 
>  'file' must be a character string or connection
>
>I guess there must be a way to send the output of write.csv to a
>connection that read.csv can use but I was mystified by the help page
>on connections, at least I could not determine how to achieve my
>desired result.
>
>I realize I could write to a file and read it back in, but that feels
>klunky somehow. Maybe my approach to convert my data to strip the
>"weird" stuff is wrong-headed and I would accept alternative
>strategies.
>
>I would like a more general solution to fix this because I expect to
>encounter it some more. For those wondering how I found myself in such
>a mess, the data frames were initially imported from SAS data sets
>through the haven package. I then did some standard manipulation and
>added some additional labels with the upData() function from Hmisc
>(both packages have been updated since initial creation of the data
>frames).
>
>Thanks,
>
>Kevin
> 
>--
> Kevin E. Thorpe
> Head of Biostatistics,? Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
> 
>     
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From kev|n@thorpe @end|ng |rom utoronto@c@  Mon Jul  9 19:14:20 2018
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Mon, 9 Jul 2018 17:14:20 +0000
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <B365845E-56B0-40FF-8ED2-94D0AD303B90@dcn.davis.ca.us>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>,
 <B365845E-56B0-40FF-8ED2-94D0AD303B90@dcn.davis.ca.us>
Message-ID: <YTOPR0101MB1769C82E3B1CF5E0E3610A0C95440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>


Thanks Jeff and all others.

I will need to use the tempfile route I guess (I'm running in a Linux OS) for the time-being.

After I re-loaded the data frames that were broken before and they seemed fine, after using them for awhile they broke again.

I am trying to build my analysis with rmarkdown and tools. I have not been able to determine (yet) exactly what set of interactions are "breaking" things. I certainly don't expect the list to debug everything I'm doing.

The only thing is can say is that there appears to be some weird interaction between SAS data sets imported by haven and other packages. Note that I encountered (I think) related issues with an imported data set when I tried working with it in the tidyverse.

Maybe I'm getting too old to learn new stuff. :-)

Sorry I am not being much help with my own problem. I just have not been able to determine where things break. If can come up with a reproducible example that reliably breaks, I'll post it.

Kevin
  
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
     



From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Monday, July 9, 2018 1:01 PM
To: r-help at r-project.org; Kevin Thorpe; R Help Mailing List
Subject: Re: [R] Using write.csv as a connection for read.csv
? 

TL;DR: If you want to do this, go ahead and use a temporary file or text connection.

Others have pointed out that write.csv returns NULL rather than a file connection, but I haven't seen comments on your impulse to avoid the use of files.

*nix operating systems are admirably efficient with multitasking... such that shells can efficiently run multiple programs connected by pipes, pausing the producers to pause if they get ahead of the consumers and resuming them if the consumers run out of data,  thus minimizing the amount of temporary disk space usage.

R does not presume this to be among the fundamental capabilities of the operating system, rather assuming single tasking capability by default. This means that even if you do connect write.csv to a pipe then it will run to completion before read.csv gets a  chance to process any of the data. MSDOS used to simulate command line program chaining by writing all the data to a temporary file before running the consumer program. R is similar... and like MSDOS there is little reason to avoid temporary files in R.

set.seed( 42 )
DF <- data.frame( X=1:100, Y=rnorm( 100 ) )
frame <- tempfile()
write.csv( DF, file=fname, row.names=FALSE )
DF2 <- read.csv( file=fname )
all.equal( DF$X, DF2$X ) && all.equal( DF$Y, DF2$Y )
unlink( fname )


On July 9, 2018 7:42:00 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>Hi.
>
>I have some data frames I created previously that seem to not be
>working correctly anymore. I *think* the problem is that some of the
>variables in the data frame are of a type called labelled. There are
>other attributes in the data frame as well. I thought that the easiest
>way to fix this was to convert to, say a csv and re-load.
>
>I tried something like read.csv(write.csv(df,row.names=FALSE)) but got
>the error
>
>Error in read.table(file = file, header = header, sep = sep, quote =
>quote,? : 
>? 'file' must be a character string or connection
>
>I guess there must be a way to send the output of write.csv to a
>connection that read.csv can use but I was mystified by the help page
>on connections, at least I could not determine how to achieve my
>desired result.
>
>I realize I could write to a file and read it back in, but that feels
>klunky somehow. Maybe my approach to convert my data to strip the
>"weird" stuff is wrong-headed and I would accept alternative
>strategies.
>
>I would like a more general solution to fix this because I expect to
>encounter it some more. For those wondering how I found myself in such
>a mess, the data frames were initially imported from SAS data sets
>through the haven package. I then did some standard manipulation and
>added some additional labels with the upData() function from Hmisc
>(both packages have been updated since initial creation of the data
>frames).
>
>Thanks,
>
>Kevin
> 
>--
> Kevin E. Thorpe
> Head of Biostatistics,? Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
> 
>???? 
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.
    


From |@ur@@@tee| @end|ng |rom m@gd@ox@@c@uk  Mon Jul  9 14:13:22 2018
From: |@ur@@@tee| @end|ng |rom m@gd@ox@@c@uk (Laura Steel)
Date: Mon, 9 Jul 2018 12:13:22 +0000
Subject: [R] (no subject)
Message-ID: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>

I am a beginner to R and I need to map some Atlantic puffin migration routes
onto a map of the Northern Hemisphere. I have a latitude and longitude point
per bird, per day. I would like to be able to plot the routes of all my
birds on one map and ideally so that I can see at which date they are at
each location.

This is a shortened version of my data for one bird only.

Bird             Date              Latitude     Longitude
eb80976 16/07/2012      50.99   -5.85
eb80976 17/07/2012      52.09   -4.58
eb80976 18/07/2012      49.72   -5.56
eb80976 19/07/2012      51.59   -3.17
eb80976 20/07/2012      52.45   -2.03
eb80976 21/07/2012      56.015  -10.51

Any help would be much appreciated. I am not totally sure where to start!
Many thanks.


	[[alternative HTML version deleted]]



From po||ngwh @end|ng |rom y@hoo@com  Mon Jul  9 16:50:57 2018
From: po||ngwh @end|ng |rom y@hoo@com (William Poling, Ph.D., MPH)
Date: Mon, 9 Jul 2018 14:50:57 +0000 (UTC)
Subject: [R] Using write.csv as a connection for read.csv
In-Reply-To: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR0101MB1769A9288B362241448A9A0695440@YTOPR0101MB1769.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <1911323376.1318967.1531147857428@mail.yahoo.com>

 Hi Kevin.
Maybe?
setwd("C:/RPractice")

write_csv(yourfile, path = "yourfile.csv")
yourfile <- read.csv("yourfile.csv")
HTH
WHP
    On Monday, July 9, 2018, 10:42:24 AM EDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:  
 
 Hi.

I have some data frames I created previously that seem to not be working correctly anymore. I *think* the problem is that some of the variables in the data frame are of a type called labelled. There are other attributes in the data frame as well. I thought that the easiest way to fix this was to convert to, say a csv and re-load.

I tried something like read.csv(write.csv(df,row.names=FALSE)) but got the error

? Error in read.table(file = file, header = header, sep = sep, quote = quote,? : 
? 'file' must be a character string or connection

I guess there must be a way to send the output of write.csv to a connection that read.csv can use but I was mystified by the help page on connections, at least I could not determine how to achieve my desired result.

I realize I could write to a file and read it back in, but that feels klunky somehow. Maybe my approach to convert my data to strip the "weird" stuff is wrong-headed and I would accept alternative strategies.

I would like a more general solution to fix this because I expect to encounter it some more. For those wondering how I found myself in such a mess, the data frames were initially imported from SAS data sets through the haven package. I then did some standard manipulation and added some additional labels with the upData() function from Hmisc (both packages have been updated since initial creation of the data frames).

Thanks,

Kevin
 
--
 Kevin E. Thorpe
 Head of Biostatistics,? Applied Health Research Centre (AHRC)
 Li Ka Shing Knowledge Institute of St. Michael's
 Assistant Professor, Dalla Lana School of Public Health
 University of Toronto
 email: kevin.thorpe at utoronto.ca? Tel: 416.864.5776? Fax: 416.864.3016
 
? ? 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]



From |nterzone @end|ng |rom gm@||@com  Mon Jul  9 20:03:29 2018
From: |nterzone @end|ng |rom gm@||@com (Dylan Distasio)
Date: Mon, 9 Jul 2018 14:03:29 -0400
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CAJrqPH-CiQOR56vQXUDc=-QSPBFaBRaF131gixuhsSFVxk3iiw@mail.gmail.com>

You'll probably get a more detailed reply from someone with more expertise,
but have you looked at something like what this article proposes:

https://medium.com/fastah-project/a-quick-start-to-maps-in-r-b9f221f44ff3

On Mon, Jul 9, 2018 at 1:53 PM Laura Steel <laura.steel at magd.ox.ac.uk>
wrote:

> I am a beginner to R and I need to map some Atlantic puffin migration
> routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude
> point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul  9 20:43:49 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Jul 2018 11:43:49 -0700
Subject: [R] (no subject)
In-Reply-To: <CAJrqPH-CiQOR56vQXUDc=-QSPBFaBRaF131gixuhsSFVxk3iiw@mail.gmail.com>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
 <CAJrqPH-CiQOR56vQXUDc=-QSPBFaBRaF131gixuhsSFVxk3iiw@mail.gmail.com>
Message-ID: <CAGxFJbQ8DJ5+fidsBa3XjR+i09QnT60xJNm5NYFzx3=8CDjMuA@mail.gmail.com>

Laura:

1. We generally do not do code for you; we expect you to show your efforts
first.

2. You might want to post this on the r-sig-geo list instead. They
specialize in such issues, so that you are more likely to find helpful
advice there.

3. There are many good R tutorials on the web. e.g. see here:
https://www.rstudio.com/online-learning/
As a "beginner," if you have not already done so, you should avail yourself
of them before posting further.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 11:03 AM, Dylan Distasio <interzone at gmail.com> wrote:

> You'll probably get a more detailed reply from someone with more expertise,
> but have you looked at something like what this article proposes:
>
> https://medium.com/fastah-project/a-quick-start-to-maps-in-r-b9f221f44ff3
>
> On Mon, Jul 9, 2018 at 1:53 PM Laura Steel <laura.steel at magd.ox.ac.uk>
> wrote:
>
> > I am a beginner to R and I need to map some Atlantic puffin migration
> > routes
> > onto a map of the Northern Hemisphere. I have a latitude and longitude
> > point
> > per bird, per day. I would like to be able to plot the routes of all my
> > birds on one map and ideally so that I can see at which date they are at
> > each location.
> >
> > This is a shortened version of my data for one bird only.
> >
> > Bird             Date              Latitude     Longitude
> > eb80976 16/07/2012      50.99   -5.85
> > eb80976 17/07/2012      52.09   -4.58
> > eb80976 18/07/2012      49.72   -5.56
> > eb80976 19/07/2012      51.59   -3.17
> > eb80976 20/07/2012      52.45   -2.03
> > eb80976 21/07/2012      56.015  -10.51
> >
> > Any help would be much appreciated. I am not totally sure where to start!
> > Many thanks.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From h@@@n@d|w@n @end|ng |rom gm@||@com  Mon Jul  9 21:40:15 2018
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Mon, 9 Jul 2018 12:40:15 -0700
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CAP+bYWBPgxFL_H5ba-L=hXWOhq=5qzW6m134MHsJ9h=27Y_HVg@mail.gmail.com>

https://imgur.com/a/0f72Fsz results from the following code:

ggplot()+borders("world", colour="gray50",
fill="gray50")+geom_line(aes(x=Longitude, y=Latitude), birds)

It's ugly, but it will give you a starting point. -- H
On Mon, 9 Jul 2018 at 10:53, Laura Steel <laura.steel at magd.ox.ac.uk> wrote:
>
> I am a beginner to R and I need to map some Atlantic puffin migration routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable



From J@n-Ph|||pp@Wern|ng @end|ng |rom whu@edu  Mon Jul  9 21:42:21 2018
From: J@n-Ph|||pp@Wern|ng @end|ng |rom whu@edu (Werning, Jan-Philipp)
Date: Mon, 9 Jul 2018 19:42:21 +0000
Subject: [R] (no subject)
Message-ID: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>

Dear all,


In the end I try to run a system dynamics simulation in R using the package deSolve.
Therefore I need an auxiliary list (auxs) the model can refer to when it the functions need an auxiliary value.

I used a manual list:

auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0 , aSplitLR2=1, aSplitSR3=0 , aSplitLR3=1, aSalesNR=0.92, aSalesRR=0.08, [?])

this way everything worked well.

Now I want to use a matrix with different values for each of the auxiliaries in order to run different scenarios. Therefore I created a csv document wich I read in:

csv1  <- read.csv("180713_Taguchi Robust Design Test_180709_1745.csv", sep = ";")

list_csv <- csv1[1,]

namesauxs <- names(list_csv)

 auxs1 <- as.numeric(list_csv)

 names(auxs1) <- namesauxs

 auxs <- auxs1


Looking at the global environment section in R studio, now both are the same, in the value section as "Numed num"

Yet, the model will not run using these values ultimately coming from the csv.

What am I doing wrong here?

It would be great if you could help.

Thanks a lot in advance

Yours

Jan





	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  9 22:25:18 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 09 Jul 2018 13:25:18 -0700
Subject: [R] (no subject)
In-Reply-To: <CAP+bYWBPgxFL_H5ba-L=hXWOhq=5qzW6m134MHsJ9h=27Y_HVg@mail.gmail.com>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
 <CAP+bYWBPgxFL_H5ba-L=hXWOhq=5qzW6m134MHsJ9h=27Y_HVg@mail.gmail.com>
Message-ID: <B95556C7-4CEB-4467-B8B7-1CAABD20E04E@dcn.davis.ca.us>

perhaps geom_path rather than geom_line?

On July 9, 2018 12:40:15 PM PDT, Hasan Diwan <hasan.diwan at gmail.com> wrote:
>https://imgur.com/a/0f72Fsz results from the following code:
>
>ggplot()+borders("world", colour="gray50",
>fill="gray50")+geom_line(aes(x=Longitude, y=Latitude), birds)
>
>It's ugly, but it will give you a starting point. -- H
>On Mon, 9 Jul 2018 at 10:53, Laura Steel <laura.steel at magd.ox.ac.uk>
>wrote:
>>
>> I am a beginner to R and I need to map some Atlantic puffin migration
>routes
>> onto a map of the Northern Hemisphere. I have a latitude and
>longitude point
>> per bird, per day. I would like to be able to plot the routes of all
>my
>> birds on one map and ideally so that I can see at which date they are
>at
>> each location.
>>
>> This is a shortened version of my data for one bird only.
>>
>> Bird             Date              Latitude     Longitude
>> eb80976 16/07/2012      50.99   -5.85
>> eb80976 17/07/2012      52.09   -4.58
>> eb80976 18/07/2012      49.72   -5.56
>> eb80976 19/07/2012      51.59   -3.17
>> eb80976 20/07/2012      52.45   -2.03
>> eb80976 21/07/2012      56.015  -10.51
>>
>> Any help would be much appreciated. I am not totally sure where to
>start!
>> Many thanks.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @-dh@r @end|ng |rom northwe@tern@edu  Mon Jul  9 23:35:22 2018
From: @-dh@r @end|ng |rom northwe@tern@edu (Sumitrajit Dhar)
Date: Mon, 9 Jul 2018 21:35:22 +0000
Subject: [R] Something simple not working in group_by
Message-ID: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>

Hi Folks,

I am trying to get a group_by cumsum using:

R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

Here is an example of a simple construct that is not working.

m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )

m %>% group_by(id) %>% mutate(total = cumsum(score))

My output:

# A tibble: 6 x 3
# Groups:   id [3]
     id score total
  <int> <dbl> <dbl>
1     1     6     6
2     1     6    12
3     2     6    18
4     2     3    21
5     3     3    24
6     3     3    27

What am I missing? Thanks in advance.

Regards,
Sumit


From @@5505 @end|ng |rom cumc@co|umb|@@edu  Mon Jul  9 23:39:44 2018
From: @@5505 @end|ng |rom cumc@co|umb|@@edu (Sariya, Sanjeev)
Date: Mon, 9 Jul 2018 21:39:44 +0000
Subject: [R] Something simple not working in group_by
In-Reply-To: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
Message-ID: <BYAPR02MB4917A89C554BA4224779E12681440@BYAPR02MB4917.namprd02.prod.outlook.com>

Strange. Worked fine on:

R version 3.4.2 (2017-09-28)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Commands:

m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )

as.data.frame(m %>% group_by(id) %>% mutate(total = cumsum(score)))

  id score total
1  1     6     6
2  1     6    12
3  2     6     6
4  2     3     9
5  3     3     3
6  3     3     6

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sumitrajit Dhar
Sent: Monday, July 9, 2018 5:35 PM
To: r-help at r-project.org
Subject: [R] Something simple not working in group_by

Hi Folks,

I am trying to get a group_by cumsum using:

R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

Here is an example of a simple construct that is not working.

m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )

m %>% group_by(id) %>% mutate(total = cumsum(score))

My output:

# A tibble: 6 x 3
# Groups:   id [3]
     id score total
  <int> <dbl> <dbl>
1     1     6     6
2     1     6    12
3     2     6    18
4     2     3    21
5     3     3    24
6     3     3    27

What am I missing? Thanks in advance.

Regards,
Sumit



From drj|m|emon @end|ng |rom gm@||@com  Tue Jul 10 00:12:33 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Jul 2018 08:12:33 +1000
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CA+8X3fX3arijdsXzHUXtGoWCtAY1DWgm6Eh_8F9Lgc8vtp0uGA@mail.gmail.com>

Hi Laura,
Here's a basic method:

lsdf<-read.table(text="Bird Date Latitude Longitude
eb80976 16/07/2012      50.99   -5.85
eb80976 17/07/2012      52.09   -4.58
eb80976 18/07/2012      49.72   -5.56
eb80976 19/07/2012      51.59   -3.17
eb80976 20/07/2012      52.45   -2.03
eb80976 21/07/2012      56.015  -10.51",
header=TRUE)
library(maps)
map("world",xlim=c(-20,10),ylim=c(45,60))
mtext(side=3,cex=1.5,text="Migration of puffin eb80976",line=2)
lines(lsdf$Longitude,lsdf$Latitude)
library(plotrix)
boxed.labels(lsdf$Longitude,lsdf$Latitude,lsdf$Date,border="white",cex=0.7)
box()
axis(1)
axis(2)

Jim


On Mon, Jul 9, 2018 at 10:13 PM, Laura Steel <laura.steel at magd.ox.ac.uk> wrote:
> I am a beginner to R and I need to map some Atlantic puffin migration routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Tue Jul 10 00:32:31 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Jul 2018 15:32:31 -0700
Subject: [R] Something simple not working in group_by
In-Reply-To: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
Message-ID: <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>

Dunno.

But if I understand correctly, here's a base R way to do it:

(## using your m)

> m$total <- with(m,ave(score,id,FUN = cumsum))
> m
  id score total
1  1     6     6
2  1     6    12
3  2     6     6
4  2     3     9
5  3     3     3
6  3     3     6

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 2:35 PM, Sumitrajit Dhar <s-dhar at northwestern.edu>
wrote:

> Hi Folks,
>
> I am trying to get a group_by cumsum using:
>
> R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>
> Here is an example of a simple construct that is not working.
>
> m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )
>
> m %>% group_by(id) %>% mutate(total = cumsum(score))
>
> My output:
>
> # A tibble: 6 x 3
> # Groups:   id [3]
>      id score total
>   <int> <dbl> <dbl>
> 1     1     6     6
> 2     1     6    12
> 3     2     6    18
> 4     2     3    21
> 5     3     3    24
> 6     3     3    27
>
> What am I missing? Thanks in advance.
>
> Regards,
> Sumit
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com  Tue Jul 10 00:35:01 2018
From: bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com (Bhaskar Mitra)
Date: Mon, 9 Jul 2018 17:35:01 -0500
Subject: [R] Help with creating subset of a data frame
Message-ID: <CAEGXkYWGyMdVaE9P8OvSYVqNyPOK21wYWY0sHEPo950gWM32ag@mail.gmail.com>

Hello Everyone,

I am trying to create a subset of a data frame (df1) based on the first
three
unique values in the first column (v1).

Here are my codes:

b <- unique(df1$v1)[1:3]
df2 <- subset(df1,df1$v1==b)

df1:
v1   v2    v3
1     a    b
1     a1   b1
2     a2   b2
2     a3   b3
3     a4   b4
3     a5   b5
3     a6   b6
4     a7   b7
4     a8   b8
4     a9   b9
5     a10  b10
5     a11  b11
5     a12  b12
5     a13  b13


Ideally, I want my new dataframe (df2) to look something like this:


df2:
v1   v2    v3
1     a    b
1     a1   b1
2     a2   b2
2     a3   b3
3     a4   b4
3     a5   b5
3     a6   b6



However, that doesn't seem to be the case and i am getting the following
warning message:

Warning message:
In df1$v1==b :  longer object length is not a multiple of shorter object
length


I would appreciate any help in this regard,

sincerely,
bhaskar

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Tue Jul 10 05:32:09 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Jul 2018 20:32:09 -0700
Subject: [R] Help with creating subset of a data frame
In-Reply-To: <CAEGXkYWGyMdVaE9P8OvSYVqNyPOK21wYWY0sHEPo950gWM32ag@mail.gmail.com>
References: <CAEGXkYWGyMdVaE9P8OvSYVqNyPOK21wYWY0sHEPo950gWM32ag@mail.gmail.com>
Message-ID: <CAGxFJbQJkVTPqHZHRU+N8+wNn1a9bsvyEqqEXa1q5Jhr+r-N5Q@mail.gmail.com>

%in%  instead of ==

?"%in%"

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 9, 2018 at 3:35 PM, Bhaskar Mitra <bhaskar.kolkata at gmail.com>
wrote:

> Hello Everyone,
>
> I am trying to create a subset of a data frame (df1) based on the first
> three
> unique values in the first column (v1).
>
> Here are my codes:
>
> b <- unique(df1$v1)[1:3]
> df2 <- subset(df1,df1$v1==b)
>
> df1:
> v1   v2    v3
> 1     a    b
> 1     a1   b1
> 2     a2   b2
> 2     a3   b3
> 3     a4   b4
> 3     a5   b5
> 3     a6   b6
> 4     a7   b7
> 4     a8   b8
> 4     a9   b9
> 5     a10  b10
> 5     a11  b11
> 5     a12  b12
> 5     a13  b13
>
>
> Ideally, I want my new dataframe (df2) to look something like this:
>
>
> df2:
> v1   v2    v3
> 1     a    b
> 1     a1   b1
> 2     a2   b2
> 2     a3   b3
> 3     a4   b4
> 3     a5   b5
> 3     a6   b6
>
>
>
> However, that doesn't seem to be the case and i am getting the following
> warning message:
>
> Warning message:
> In df1$v1==b :  longer object length is not a multiple of shorter object
> length
>
>
> I would appreciate any help in this regard,
>
> sincerely,
> bhaskar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jul 10 09:00:55 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 10 Jul 2018 07:00:55 +0000
Subject: [R] (no subject)
In-Reply-To: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>
References: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>
Message-ID: <dcbc725d62bc438ba8bbcf508fc7632f@SRVEXCHCM1302.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Werning, Jan-
> Philipp
> Sent: Monday, July 9, 2018 9:42 PM
> To: r-help at r-project.org
> Subject: [R] (no subject)
>
> Dear all,
>
>
> In the end I try to run a system dynamics simulation in R using the package
> deSolve.
> Therefore I need an auxiliary list (auxs) the model can refer to when it the
> functions need an auxiliary value.
>
> I used a manual list:
>
> auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0 ,
> aSplitLR2=1, aSplitSR3=0 , aSplitLR3=1, aSalesNR=0.92, aSalesRR=0.08, [?])

This is vector not list.
> auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0)
> is.vector(auxs)
[1] TRUE
> is.list(auxs)
[1] FALSE
>
>
> this way everything worked well.
>
> Now I want to use a matrix with different values for each of the auxiliaries in
> order to run different scenarios. Therefore I created a csv document wich I read
> in:
>
> csv1  <- read.csv("180713_Taguchi Robust Design Test_180709_1745.csv", sep
> = ";")
>
> list_csv <- csv1[1,]

which is probably data frame

> test<-vec[1,]
> is.vector(test)
[1] FALSE
> is.list(test)
[1] TRUE
> is.data.frame(test)
[1] TRUE
>

>
> namesauxs <- names(list_csv)
>
>  auxs1 <- as.numeric(list_csv)
>
>  names(auxs1) <- namesauxs
>
>  auxs <- auxs1
>
>
> Looking at the global environment section in R studio, now both are the same,
> in the value section as "Numed num"

I do not know rstudio but you could check two objects by
?identical

>
> Yet, the model will not run using these values ultimately coming from the csv.

I wonder why do you use as.numeric in the first instance. You coud use

auxs1 <- unlist(csv1[1,])
and you should get named numeric vector. Maybe there are problems when reading numbers from csv file. You could check it e.g. by

str(auxs1)

>
> What am I doing wrong here?
>
> It would be great if you could help.
>
> Thanks a lot in advance
>
> Yours
>
> Jan
>
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From er|cjberger @end|ng |rom gm@||@com  Tue Jul 10 09:48:13 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 10 Jul 2018 10:48:13 +0300
Subject: [R] Something simple not working in group_by
In-Reply-To: <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
 <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>
Message-ID: <CAGgJW77UBLakM80qb9BfzxctttaOAz7-kku4eGFSQJ-3n2fQ9g@mail.gmail.com>

Hi Sumit,
I was not able to reproduce this problem.
I tried it in both R 3.5.1 and R 3.4.4.
Both gave the expected output (which differs from yours.)

Eric


On Tue, Jul 10, 2018 at 1:32 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Dunno.
>
> But if I understand correctly, here's a base R way to do it:
>
> (## using your m)
>
> > m$total <- with(m,ave(score,id,FUN = cumsum))
> > m
>   id score total
> 1  1     6     6
> 2  1     6    12
> 3  2     6     6
> 4  2     3     9
> 5  3     3     3
> 6  3     3     6
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jul 9, 2018 at 2:35 PM, Sumitrajit Dhar <s-dhar at northwestern.edu>
> wrote:
>
> > Hi Folks,
> >
> > I am trying to get a group_by cumsum using:
> >
> > R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> > Copyright (C) 2018 The R Foundation for Statistical Computing
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> >
> > Here is an example of a simple construct that is not working.
> >
> > m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )
> >
> > m %>% group_by(id) %>% mutate(total = cumsum(score))
> >
> > My output:
> >
> > # A tibble: 6 x 3
> > # Groups:   id [3]
> >      id score total
> >   <int> <dbl> <dbl>
> > 1     1     6     6
> > 2     1     6    12
> > 3     2     6    18
> > 4     2     3    21
> > 5     3     3    24
> > 6     3     3    27
> >
> > What am I missing? Thanks in advance.
> >
> > Regards,
> > Sumit
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From J@n-Ph|||pp@Wern|ng @end|ng |rom whu@edu  Tue Jul 10 11:50:28 2018
From: J@n-Ph|||pp@Wern|ng @end|ng |rom whu@edu (Werning, Jan-Philipp)
Date: Tue, 10 Jul 2018 09:50:28 +0000
Subject: [R] (no subject)
In-Reply-To: <dcbc725d62bc438ba8bbcf508fc7632f@SRVEXCHCM1302.precheza.cz>
References: <9030FDA7-2C63-46DF-AE60-D8C741F1A10B@whu.edu>
 <dcbc725d62bc438ba8bbcf508fc7632f@SRVEXCHCM1302.precheza.cz>
Message-ID: <8048C6BF-3BE2-42E0-AFB8-BA718F213364@whu.edu>


Hi,

thanks a lot! Now it works.

Yours

Jan

Am 10.07.2018 um 09:00 schrieb PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>:

Hi

see in line

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Werning, Jan-
Philipp
Sent: Monday, July 9, 2018 9:42 PM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] (no subject)

Dear all,


In the end I try to run a system dynamics simulation in R using the package
deSolve.
Therefore I need an auxiliary list (auxs) the model can refer to when it the
functions need an auxiliary value.

I used a manual list:

auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0 ,
aSplitLR2=1, aSplitSR3=0 , aSplitLR3=1, aSalesNR=0.92, aSalesRR=0.08, [?])

This is vector not list.
auxs <- c( aSplitSN=0.4 , aSplitLN=0.6, aSplitSR1=0 , aSplitLR1=1, aSplitSR2=0)
is.vector(auxs)
[1] TRUE
is.list(auxs)
[1] FALSE


this way everything worked well.

Now I want to use a matrix with different values for each of the auxiliaries in
order to run different scenarios. Therefore I created a csv document wich I read
in:

csv1  <- read.csv("180713_Taguchi Robust Design Test_180709_1745.csv", sep
= ";")

list_csv <- csv1[1,]

which is probably data frame

test<-vec[1,]
is.vector(test)
[1] FALSE
is.list(test)
[1] TRUE
is.data.frame(test)
[1] TRUE



namesauxs <- names(list_csv)

auxs1 <- as.numeric(list_csv)

names(auxs1) <- namesauxs

auxs <- auxs1


Looking at the global environment section in R studio, now both are the same,
in the value section as "Numed num"

I do not know rstudio but you could check two objects by
?identical


Yet, the model will not run using these values ultimately coming from the csv.

I wonder why do you use as.numeric in the first instance. You coud use

auxs1 <- unlist(csv1[1,])
and you should get named numeric vector. Maybe there are problems when reading numbers from csv file. You could check it e.g. by

str(auxs1)


What am I doing wrong here?

It would be great if you could help.

Thanks a lot in advance

Yours

Jan





[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/



	[[alternative HTML version deleted]]


From @k@h@y_e4 @end|ng |rom hotm@||@com  Tue Jul 10 13:43:17 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Tue, 10 Jul 2018 11:43:17 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>,
 <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
Message-ID: <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I've gone through debug(update.snlcqn)  (update.snlcqn is the above function) and  I think the problem lies in read_excel returning a tibble...any suggestions on how to convert it to a regular data frame? Any other packages that read xls files as a regular data frame?

Very many thanks for your time and effort....
Yours sincerely,
AKSHAY M KULKARNI

________________________________
From: Eric Berger <ericjberger at gmail.com>
Sent: Monday, July 9, 2018 12:15 PM
To: PIKAL Petr
Cc: akshay kulkarni; R help Mailing list
Subject: Re: [R] inconsistency in display of character vector....

>  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

??

Why not just always return snicqna ?


On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

You definitely should not use HTML formated mail. This is plain text mailing list for reason.

If you experience space between "NSE/" and pasted second part, you should read paste help page which states

paste (..., sep = " ", collapse = NULL)

so it has space as separator.

You should use paste0 if you want to get rid of separating space or axplicitely state
paste (..., sep = "")

> lneq <- c()
> for (i in 1:10) lneq[i] <- letters[i]
> lneq
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> snlcqna<-LETTERS[1:10]
> for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> snlcqna
 [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/ h"
 [9] "NSE/ i" "NSE/ j"
> for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> snlcqna
 [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h" "NSE/i"
[10] "NSE/j"

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of akshay
> kulkarni
> Sent: Sunday, July 8, 2018 2:38 PM
> To: R help Mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Fw: inconsistency in display of character vector....
>
> dear members,
>                              The mail is not showing the spaces between [192]
> "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces
[[elided Hotmail spam]]
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> on behalf of akshay kulkarni
> <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
>
> dear members,
>                             I have the following code to update the list of stocks:
>
> function (snlcqn)
> {
>                   lneq <- c()
>                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                   file.string <- tempfile()
>
>                   download.file(URL,file.string)
>
>                   IDT <- read_excel(file.string)
>
>                   leq <- IDT[,1]
>
>                   for(i in 1:length(leq)){
>                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
>
>                   for(j in 1:length(lneq)){
>                   snlcqna[j] <- paste("NSE/",lneq[j])}
>
>                   if(identical(snlcqn,snlcqna) == "FALSE"){
>                   return(snlcqna)                         }
>
>                   else                                    {
>                   return(snlcqn)                          }
>
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list,
> is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS
> instance):
>
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
>
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Tue Jul 10 13:57:43 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 10 Jul 2018 14:57:43 +0300
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>
 <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
 <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW76eB-PfY=+nj-KmJ5zbRfpkD+dGg8ZiNL=GUuvAggjORA@mail.gmail.com>

Hi Akshay,
Package "openxlsx" has function read.xlsx() which returns a data frame.

HTH,
Eric


On Tue, Jul 10, 2018 at 2:43 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                              I've gone through debug(update.snlcqn)
> (update.snlcqn is the above function) and  I think the problem lies in
> read_excel returning a tibble...any suggestions on how to convert it to a
> regular data frame? Any other packages that read xls files as a regular
> data frame?
>
> Very many thanks for your time and effort....
> Yours sincerely,
> AKSHAY M KULKARNI
>
> ------------------------------
> *From:* Eric Berger <ericjberger at gmail.com>
> *Sent:* Monday, July 9, 2018 12:15 PM
> *To:* PIKAL Petr
> *Cc:* akshay kulkarni; R help Mailing list
> *Subject:* Re: [R] inconsistency in display of character vector....
>
> >  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna
>
> ??
>
> Why not just always return snicqna ?
>
>
> On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> You definitely should not use HTML formated mail. This is plain text
> mailing list for reason.
>
> If you experience space between "NSE/" and pasted second part, you should
> read paste help page which states
>
> paste (..., sep = " ", collapse = NULL)
>
> so it has space as separator.
>
> You should use paste0 if you want to get rid of separating space or
> axplicitely state
> paste (..., sep = "")
>
> > lneq <- c()
> > for (i in 1:10) lneq[i] <- letters[i]
> > lneq
>  [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> > snlcqna<-LETTERS[1:10]
> > for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/
> h"
>  [9] "NSE/ i" "NSE/ j"
> > for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> > snlcqna
>  [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h"
> "NSE/i"
> [10] "NSE/j"
>
> Cheers
> Petr
>
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady
> -ochrany-osobnich-udaju/ | Information about processing and protection of
> business partner's personal data are available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of akshay
> > kulkarni
> > Sent: Sunday, July 8, 2018 2:38 PM
> > To: R help Mailing list <r-help at r-project.org>
> > Subject: [R] Fw: inconsistency in display of character vector....
> >
> > dear members,
> >                              The mail is not showing the spaces between
> [192]
> > "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty
> spaces
> > between the two.....!!!!!!
> >
> > ________________________________________
> > From: R-help <r-help-bounces at r-project.org> on behalf of akshay kulkarni
> > <akshay_e4 at hotmail.com>
> > Sent: Sunday, July 8, 2018 5:58 PM
> > To: R help Mailing  list
> > Subject: [R] inconsistency in display of character vector....
> >
> > dear members,
> >                             I have the following code to update the list
> of stocks:
> >
> > function (snlcqn)
> > {
> >                   lneq <- c()
> >                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
> >                   file.string <- tempfile()
> >
> >                   download.file(URL,file.string)
> >
> >                   IDT <- read_excel(file.string)
> >
> >                   leq <- IDT[,1]
> >
> >                   for(i in 1:length(leq)){
> >                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
> >
> >                   for(j in 1:length(lneq)){
> >                   snlcqna[j] <- paste("NSE/",lneq[j])}
> >
> >                   if(identical(snlcqn,snlcqna) == "FALSE"){
> >                   return(snlcqna)                         }
> >
> >                   else                                    {
> >                   return(snlcqn)                          }
> >
> > }
> > snlcqn is the list of present stocks and snlcqna is the list of updated
> stocks.
> > The problem is the return object, instead of getting displayed in
> contiguous list,
> > is getting displayed with lots of spaces...( I am using R on a LINUX
> RHEL AWS
> > instance):
> >
> > [192] "NSE/YESBANK"
> > [193] "NSE/ZEEL"
> >
> > Why is this happening? How can I get the return object as a contiguous
> list?
> > Very many thanks for your time and effort...
> > yours sincerely,
> > AKSHAY M KULKARNI
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]



From @-dh@r @end|ng |rom northwe@tern@edu  Tue Jul 10 14:00:47 2018
From: @-dh@r @end|ng |rom northwe@tern@edu (Sumitrajit Dhar)
Date: Tue, 10 Jul 2018 12:00:47 +0000
Subject: [R] Something simple not working in group_by
In-Reply-To: <1ae329a5df6947a399481c8c2c0f7ab3@CHCSPMBX01.ads.northwestern.edu>
References: <D608EFC0-AB7E-4A7B-8572-7EA515AF48FB@northwestern.edu>
 <CAGxFJbQJt64nQ+sS8ycsOE0sHwiuaU6j7v4TcaqjY6qGkEgwig@mail.gmail.com>
 <1ae329a5df6947a399481c8c2c0f7ab3@CHCSPMBX01.ads.northwestern.edu>
Message-ID: <601C2B86-E861-47D4-A9EC-83EB15951483@northwestern.edu>

Hello everyone,

I figured it out late last night. I was loading both dplyr and plyr and that was causing the problem. Loading plyr after dplyr leads to the faulty behavior. Just loading dplyr gives you expected behavior. Sorry for the confusion and false alarm.

Regards,
Sumit

> On Jul 10, 2018, at 2:48 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
> Hi Sumit,
> I was not able to reproduce this problem.
> I tried it in both R 3.5.1 and R 3.4.4. 
> Both gave the expected output (which differs from yours.)
> 
> Eric
> 
> 
> On Tue, Jul 10, 2018 at 1:32 AM, Bert Gunter <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
> Dunno.
> 
> But if I understand correctly, here's a base R way to do it:
> 
> (## using your m)
> 
> > m$total <- with(m,ave(score,id,FUN = cumsum))
> > m
>   id score total
> 1  1     6     6
> 2  1     6    12
> 3  2     6     6
> 4  2     3     9
> 5  3     3     3
> 6  3     3     6
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Jul 9, 2018 at 2:35 PM, Sumitrajit Dhar <s-dhar at northwestern.edu <mailto:s-dhar at northwestern.edu>>
> wrote:
> 
> > Hi Folks,
> >
> > I am trying to get a group_by cumsum using:
> >
> > R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> > Copyright (C) 2018 The R Foundation for Statistical Computing
> > Platform: x86_64-apple-darwin15.6.0 (64-bit)
> >
> > Here is an example of a simple construct that is not working.
> >
> > m <- data.frame( id = rep(1:3, each=2), score = rep(c(6,3), each=3) )
> >
> > m %>% group_by(id) %>% mutate(total = cumsum(score))
> >
> > My output:
> >
> > # A tibble: 6 x 3
> > # Groups:   id [3]
> >      id score total
> >   <int> <dbl> <dbl>
> > 1     1     6     6
> > 2     1     6    12
> > 3     2     6    18
> > 4     2     3    21
> > 5     3     3    24
> > 6     3     3    27
> >
> > What am I missing? Thanks in advance.
> >
> > Regards,
> > Sumit
> >
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=r1iXOeVerM13vY8SJ43KMMSjoveKXYTCmHk2uqE9jwI&e=>
> > PLEASE do read the posting guide http://www.R-project.org/ <https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=Qs4zmrgW7sXjofqwf0VQmV1M7Slw3pS6Mv_TpLYipqQ&e=>
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=r1iXOeVerM13vY8SJ43KMMSjoveKXYTCmHk2uqE9jwI&e=>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=yHlS04HhBraes5BQ9ueu5zKhE7rtNXt_d012z2PA6ws&r=hooQlNrL6cH-O78mNmvUpBZ95zI1C-jF0GfoKkuJSaU&m=CvhIldTo5hoJJi5Bd7_sHFWRdH7Fd4Jv3ExQB0RPlIU&s=ZJbUb--ZGIsJv2dCTON31rOiQ-MQEv3DU1ZrWM_scss&e=>
> and provide commented, minimal, self-contained, reproducible code.
> 


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jul 10 14:01:47 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 10 Jul 2018 12:01:47 +0000
Subject: [R] inconsistency in display of character vector....
In-Reply-To: <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00919983261E7939671A646EC8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB0091D8CFE283C9E2EA2CAF39C8450@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <ca901a437f154fff9efba44cd0b68965@SRVEXCHCM1302.precheza.cz>,
 <CAGgJW74MiW9goEFm=tWEtgUsGmQm4AsU=G5j++jG3e7qW0Ob6A@mail.gmail.com>
 <SL2P216MB00913C7F89D147E2E46D2DE2C85B0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <6b8f36fd288c49fcac8f50586f4bd88c@SRVEXCHCM1302.precheza.cz>

Hi

What about

dat<-as.data.frame(tibble.dat)

Cheers
Petr
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

From: akshay kulkarni [mailto:akshay_e4 at hotmail.com]
Sent: Tuesday, July 10, 2018 1:43 PM
To: Eric Berger <ericjberger at gmail.com>; PIKAL Petr <petr.pikal at precheza.cz>
Cc: R help Mailing list <r-help at r-project.org>
Subject: Re: [R] inconsistency in display of character vector....

dear members,
                             I've gone through debug(update.snlcqn)  (update.snlcqn is the above function) and  I think the problem lies in read_excel returning a tibble...any suggestions on how to convert it to a regular data frame? Any other packages that read xls files as a regular data frame?

Very many thanks for your time and effort....
Yours sincerely,
AKSHAY M KULKARNI

________________________________
From: Eric Berger <ericjberger at gmail.com<mailto:ericjberger at gmail.com>>
Sent: Monday, July 9, 2018 12:15 PM
To: PIKAL Petr
Cc: akshay kulkarni; R help Mailing list
Subject: Re: [R] inconsistency in display of character vector....

>  If (identical(snlcqn, snlcqna)) snlcqn else snlcqna

??

Why not just always return snicqna ?


On Mon, Jul 9, 2018 at 9:43 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

You definitely should not use HTML formated mail. This is plain text mailing list for reason.

If you experience space between "NSE/" and pasted second part, you should read paste help page which states

paste (..., sep = " ", collapse = NULL)

so it has space as separator.

You should use paste0 if you want to get rid of separating space or axplicitely state
paste (..., sep = "")

> lneq <- c()
> for (i in 1:10) lneq[i] <- letters[i]
> lneq
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j"
> snlcqna<-LETTERS[1:10]
> for (j in 1:10) snlcqna[j] <- paste("NSE/",lneq[j])
> snlcqna
 [1] "NSE/ a" "NSE/ b" "NSE/ c" "NSE/ d" "NSE/ e" "NSE/ f" "NSE/ g" "NSE/ h"
 [9] "NSE/ i" "NSE/ j"
> for (j in 1:10) snlcqna[j] <- paste0("NSE/",lneq[j])
> snlcqna
 [1] "NSE/a" "NSE/b" "NSE/c" "NSE/d" "NSE/e" "NSE/f" "NSE/g" "NSE/h" "NSE/i"
[10] "NSE/j"

Cheers
Petr

Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner's personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl?en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of akshay
> kulkarni
> Sent: Sunday, July 8, 2018 2:38 PM
> To: R help Mailing list <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: [R] Fw: inconsistency in display of character vector....
>
> dear members,
>                              The mail is not showing the spaces between [192]
> "NSE/YESBANK" and  [193] "NSE/ZEEL" ...Actually there is a lot of empty spaces
> between the two.....!!!!!!
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> on behalf of akshay kulkarni
> <akshay_e4 at hotmail.com<mailto:akshay_e4 at hotmail.com>>
> Sent: Sunday, July 8, 2018 5:58 PM
> To: R help Mailing  list
> Subject: [R] inconsistency in display of character vector....
>
> dear members,
>                             I have the following code to update the list of stocks:
>
> function (snlcqn)
> {
>                   lneq <- c()
>                   URL <- "https://canmoney.in/Intraday%20scrip.xls"
>                   file.string <- tempfile()
>
>                   download.file(URL,file.string)
>
>                   IDT <- read_excel(file.string)
>
>                   leq <- IDT[,1]
>
>                   for(i in 1:length(leq)){
>                   lneq[i] <- substr(leq[i],1,(nchar(leq[i])-2))}
>
>                   for(j in 1:length(lneq)){
>                   snlcqna[j] <- paste("NSE/",lneq[j])}
>
>                   if(identical(snlcqn,snlcqna) == "FALSE"){
>                   return(snlcqna)                         }
>
>                   else                                    {
>                   return(snlcqn)                          }
>
> }
> snlcqn is the list of present stocks and snlcqna is the list of updated stocks.
> The problem is the return object, instead of getting displayed in contiguous list,
> is getting displayed with lots of spaces...( I am using R on a LINUX RHEL AWS
> instance):
>
> [192] "NSE/YESBANK"
> [193] "NSE/ZEEL"
>
> Why is this happening? How can I get the return object as a contiguous list?
> Very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



From @ggp@@erge| @end|ng |rom gm@||@com  Tue Jul 10 12:31:09 2018
From: @ggp@@erge| @end|ng |rom gm@||@com (Sergei Ko)
Date: Tue, 10 Jul 2018 11:31:09 +0100
Subject: [R] select.list cuts results to 100 characters on Win 10 when
 graphics = TRUE
Message-ID: <CAK2fHGfh8+0hW-dXxoEbbZUub5zeD+Nzzc8J=UwVB_X7NB_kHA@mail.gmail.com>

mstring1 <- c("123456789012345678901234567890123456789012345678901234567890
123456789012345678901234567890123456789012345678901234567890")

mstring2 <- c("123456789012345678901234567890123456789012345678901234567890
1234567890123456789012345678901234567890123456789012345678901234567890")


vec.in <- c(mstring1,mstring2)



res1 <- select.list(vec.in, graphics = TRUE)

res2 <- select.list(vec.in, graphics = FALSE)



nchar(res1)

nchar(res2)



platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          5.0
year           2018
month          04
day            23
svn rev        74626
language       R
version.string R version 3.5.0 (2018-04-23)
nickname       Joy in Playing

	[[alternative HTML version deleted]]



From d@v|d@m| @end|ng |rom m|cro@o|t@com  Wed Jul 11 01:19:49 2018
From: d@v|d@m| @end|ng |rom m|cro@o|t@com (David Smith (CDA))
Date: Tue, 10 Jul 2018 23:19:49 +0000
Subject: [R] Revolutions blog: June 2018 roundup
Message-ID: <DM5PR2101MB1048045C4E623807D8799465C85B0@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of June:

An animated visualization of global migration, created in R by Guy Abel:
http://blog.revolutionanalytics.com/2018/06/global-migration-animated-with-r.html

My take on the question, Should you learn R or Python for data science?
http://blog.revolutionanalytics.com/2018/06/python-or-r.html

The BBC and Financial Times use R -- without post-processing -- for publication
graphics: http://blog.revolutionanalytics.com/2018/06/ft-bbc-uses-r.html

"Handling Strings in R", a free e-book by Gaston Sanchez, has been updated:
http://blog.revolutionanalytics.com/2018/06/handling-strings-with-r.html

My AI, Machine Learning and Data Science roundup for June 2018:
http://blog.revolutionanalytics.com/2018/06/ai-roundup-june-2018.html

The PYPL Popularity of Languages Index ranks R as the 7th most popular
programming language: 
http://blog.revolutionanalytics.com/2018/06/pypl-programming-language-trends.html

The "lime" package provides tools for interpreting machine learning models in R:
http://blog.revolutionanalytics.com/2018/06/lime-package.html

An R vignette by Paige Bailey on detecting unconscious bias in predictive
models: http://blog.revolutionanalytics.com/2018/06/understanding-bias.html

Microsoft R Open 3.5.0 has been released
http://blog.revolutionanalytics.com/2018/06/microsoft-r-open-350-now-available.html
(with a subsequent fix for Debian systems:
http://blog.revolutionanalytics.com/2018/06/hotfix-for-mro-350-on-linux.html)

Slides from the webinar, What's New in Azure for Machine Learning and AI:
http://blog.revolutionanalytics.com/2018/06/whats-new-in-azure-for-machine-learning-and-ai.html

And some general interest stories (not necessarily related to R):

* The Curvature Blindness Illusion:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-wavy-lines.html

* Lioness v Wrestlers in tug-of-war:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-the-lioness-sleeps-tonight.html

* A comedian imagines an AI writing a TV commercial:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-olive-garden.html

* A fur seal, transcribed:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-sealese.html

* An architecture error and a near-disaster in NYC:
  http://blog.revolutionanalytics.com/2018/06/because-its-friday-buildings-shake.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com



From ne||@redu @end|ng |rom hotm@||@|r  Wed Jul 11 02:11:19 2018
From: ne||@redu @end|ng |rom hotm@||@|r (Nelly Reduan)
Date: Wed, 11 Jul 2018 00:11:19 +0000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>,
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
Message-ID: <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>

Thank you very much for your reply.


By omitting the probability, the expected results could be:


c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)


c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)


If I omit the probability, I would like to generate N random positive integers that sum to M and the integers would be selected from a uniform distribution.


Many thanks for your time

Nell


________________________________
De : Rolf Turner <r.turner at auckland.ac.nz>
Envoy? : mercredi 4 juillet 2018 16:11:11
? : Nelly Reduan
Cc : r-help at r-project.org
Objet : Re: [R] Generate N random numbers with a given probability and condition


On 05/07/18 10:21, Nelly Reduan wrote:

> Dear all,
>
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
>
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
>
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time.

Your thinking requires considerable clarification.

(1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.

(2) Hence length(seq(0,10,1)) is 11.

(3) Likewise max(seq(0,10,1)) is 10.

(4) Your prob vector is *constant* --- so specifying "prob" makes
     no difference --- the result is the same as if you omitted "prob".

(5) You need to think carefully about what you really mean by "random".
     In what way do you want the final result to be "random"?

I expect that the lecturer who assigned this problem to you  needs to
clarify his/her thinking as well.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Jul 11 02:46:17 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 11 Jul 2018 10:46:17 +1000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>

Hi Nell,
I may not have the right idea about this, but I think you need to do
this in two steps if it can be done. Let's say you want a sequence of
20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
the monotonically increasing sequences like this:

c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
...
c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)

So if you select one of these sequences at random, there will be a
further set of sequences that are permutations of it. By randomly
selecting one of those permutations, I think you can solve your
problem. However, this is going to be computationally intensive, with
the set of permutations being very large for large N. Here is an
example using N = M = 5:

# enumerate the sequences = M
rs5<-list(c(1,1,1,1,1),c(0,1,1,1,2),c(0,0,1,1,3),c(0,0,0,1,4),
 c(0,0,1,2,2),c(0,0,0,2,3),c(0,0,0,0,5))
library(crank)
# generate the permutations for one sequence (120 in this case)
rs5_s1<-permute(rs5[[sample(1:length(rs5),1)]])
# select one of the permutations at random
rs5_s1[sample(1:dim(rs5_s1)[1],1),]
[1] 4 0 1 0 0

Jim

On Wed, Jul 11, 2018 at 10:11 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Thank you very much for your reply.
>
>
> By omitting the probability, the expected results could be:
>
>
> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>
>
> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>
>
> If I omit the probability, I would like to generate N random positive integers that sum to M and the integers would be selected from a uniform distribution.
>
>
> Many thanks for your time
>
> Nell
>
>
> ________________________________
> De : Rolf Turner <r.turner at auckland.ac.nz>
> Envoy? : mercredi 4 juillet 2018 16:11:11
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Generate N random numbers with a given probability and condition
>
>
> On 05/07/18 10:21, Nelly Reduan wrote:
>
>> Dear all,
>>
>> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
>> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
>>
>> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
>>
>> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>> Many thanks for your time.
>
> Your thinking requires considerable clarification.
>
> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>
> (2) Hence length(seq(0,10,1)) is 11.
>
> (3) Likewise max(seq(0,10,1)) is 10.
>
> (4) Your prob vector is *constant* --- so specifying "prob" makes
>      no difference --- the result is the same as if you omitted "prob".
>
> (5) You need to think carefully about what you really mean by "random".
>      In what way do you want the final result to be "random"?
>
> I expect that the lecturer who assigned this problem to you  needs to
> clarify his/her thinking as well.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 11 03:44:37 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 10 Jul 2018 18:44:37 -0700
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbQE8hZ0OxS8FWqKb_mOhP1NKxXyds2wdG7h7xweX1L_aQ@mail.gmail.com>

You need to heed Rolf's advice.

N random integers by definition cannot have a fixed sum.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 10, 2018 at 5:11 PM, Nelly Reduan <nell.redu at hotmail.fr> wrote:

> Thank you very much for your reply.
>
>
> By omitting the probability, the expected results could be:
>
>
> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>
>
> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>
>
> If I omit the probability, I would like to generate N random positive
> integers that sum to M and the integers would be selected from a uniform
> distribution.
>
>
> Many thanks for your time
>
> Nell
>
>
> ________________________________
> De : Rolf Turner <r.turner at auckland.ac.nz>
> Envoy? : mercredi 4 juillet 2018 16:11:11
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Generate N random numbers with a given probability and
> condition
>
>
> On 05/07/18 10:21, Nelly Reduan wrote:
>
> > Dear all,
> >
> > I would like to generate N random numbers with a given probability and
> condition but I'm not sure how to do this.
> > For example, I have N = 20 and the vector from which to choose is seq(0,
> 10, 1). I have tested:
> >
> > x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28,
> times=length(seq(0, 10, 1))))
> >
> > But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> > Many thanks for your time.
>
> Your thinking requires considerable clarification.
>
> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>
> (2) Hence length(seq(0,10,1)) is 11.
>
> (3) Likewise max(seq(0,10,1)) is 10.
>
> (4) Your prob vector is *constant* --- so specifying "prob" makes
>      no difference --- the result is the same as if you omitted "prob".
>
> (5) You need to think carefully about what you really mean by "random".
>      In what way do you want the final result to be "random"?
>
> I expect that the lecturer who assigned this problem to you  needs to
> clarify his/her thinking as well.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From du|c@|m@ @end|ng |rom b|gpond@com  Wed Jul 11 06:04:11 2018
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Wed, 11 Jul 2018 14:04:11 +1000
Subject: [R] ASExtras library
In-Reply-To: <MAXPR0101MB17851D0974DC6B6A28A868C4CB410@MAXPR0101MB1785.INDPRD01.PROD.OUTLOOK.COM>
References: <CALi537sT+ftsiBP2Qk8r_MLmrP-eqmM3his4TwGwrPJMhPxroQ@mail.gmail.com>,
 <609070D8-7536-41A3-BB12-4129327B1E9E@comcast.net>
 <MAXPR0101MB17851D0974DC6B6A28A868C4CB410@MAXPR0101MB1785.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <000301d418cc$399247f0$acb6d7d0$@bigpond.com>

Hi

I was trying to find a file on my computer when the ASReml directory showed
up on the directory tree. 

The ASExtras may be part of the R interface/standalone of ASReml available
in Splus as well.
I think the interface to Splus came first

>From what I can remember ASReml R extra packages had a different name than
ASExtras. Is it the Splus distributed package name?
There is an asremlPlus package that is still valid 

Regards

Duncan 

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of radmuzom .
Sent: Thursday, 5 July 2018 07:34
To: David Winsemius; Mehrshad Barary; r-help at r-project.org
Subject: Re: [R] ASExtras library

The package appears to be referenced in the package "agridat" -
ftp://cran.r-project.org/pub/R/web/packages/agridat/agridat.pdf (Pg 55).
However, even I tried searching for it and there seems to be no reference
other than this source.

Regards,
radmuzom

From: R-help <r-help-bounces at r-project.org> on behalf of David Winsemius
<dwinsemius at comcast.net>
Sent: Wednesday, July 4, 2018 9:22 PM
To: Mehrshad Barary
Cc: r-help at r-project.org
Subject: Re: [R] ASExtras library
? 


> On Jul 3, 2018, at 6:34 PM, Mehrshad Barary <bararym at gmail.com> wrote:
> 
> Hi Everyone,
> 
> Does anybody know how I can get ASExtras library?

It would be helpful if you would provide information about your reasons for
assuming this package's existence. Cannot find it in CRAN (including a
search for 'ASExtra'), BioConductor, GitHub, or the Archives, or even with
Google for that matter.

https://cran.r-project.org/src/contrib/Archive/

And within R parlance 'library' not a synonym for 'package'. Libraries are
where you store packages. And `library('pkg_name')` is a command for loading
a package.


> Thanks
> Mehrshad
> 
> -- 
> Mehrshad Barary
> Senior Lecturer in Crop Ecophysiology
> Department of Agronomy and Plant Breeding
> Faculty of Agriculture
> Ilam University
> Tel: (+98)8412227019-21
> Fax: (+98)8412227015
> 
>??????? [[alternative HTML version deleted]]

And R help is a plain-text mailing list. Please read the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'??
-Gehm's Corollary to Clarke's Third Law

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
    
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Jul 11 12:23:35 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 11 Jul 2018 22:23:35 +1200
Subject: [R] 
 [FORGED] Re: Generate N random numbers with a given probability
 and condition
In-Reply-To: <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>
Message-ID: <fe13c2df-99f1-b7f3-3120-013024c79b48@auckland.ac.nz>

On 11/07/18 12:46, Jim Lemon wrote:
> Hi Nell,
> I may not have the right idea about this, but I think you need to do
> this in two steps if it can be done. Let's say you want a sequence of
> 20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
> the monotonically increasing sequences like this:
> 
> c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
> c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
> ...
> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)

<SNIP>

Jim:  You should *not* do people's homework for them!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From bor|@@@te|pe @end|ng |rom utoronto@c@  Wed Jul 11 12:53:59 2018
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Wed, 11 Jul 2018 06:53:59 -0400
Subject: [R] 
 [FORGED] Re: Generate N random numbers with a given probability
 and condition
In-Reply-To: <fe13c2df-99f1-b7f3-3120-013024c79b48@auckland.ac.nz>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CA+8X3fUPSJ8Wq=PmXfNK2gbYhm4tT9FjaWJ3imWu_NCwU3Guyw@mail.gmail.com>
 <fe13c2df-99f1-b7f3-3120-013024c79b48@auckland.ac.nz>
Message-ID: <9674C150-BF6D-4C63-A06B-0F389E5DD874@utoronto.ca>

Wasn't there also the requirement that the numbers be drawn from a uniform distribution? These sequences are not. I wonder whether this can for all practical purposes be simplified to consider only the sequence with maximum entropy.

B.




> On 2018-07-11, at 06:23, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 11/07/18 12:46, Jim Lemon wrote:
>> Hi Nell,
>> I may not have the right idea about this, but I think you need to do
>> this in two steps if it can be done. Let's say you want a sequence of
>> 20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
>> the monotonically increasing sequences like this:
>> c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
>> c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
>> ...
>> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)
> 
> <SNIP>
> 
> Jim:  You should *not* do people's homework for them!
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@cqueen1 @end|ng |rom ||n|@gov  Wed Jul 11 16:43:35 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 11 Jul 2018 14:43:35 +0000
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <AF7FD38F-5775-47CE-B464-675A82551DC3@llnl.gov>

Maybe I missed it, but I didn't see anyone suggest a visit to the CRAN Spatial task view. This would be a good place to start learning how to work with spatial data in R.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/9/18, 5:13 AM, "R-help on behalf of Laura Steel" <r-help-bounces at r-project.org on behalf of laura.steel at magd.ox.ac.uk> wrote:

    I am a beginner to R and I need to map some Atlantic puffin migration routes
    onto a map of the Northern Hemisphere. I have a latitude and longitude point
    per bird, per day. I would like to be able to plot the routes of all my
    birds on one map and ideally so that I can see at which date they are at
    each location.
    
    This is a shortened version of my data for one bird only.
    
    Bird             Date              Latitude     Longitude
    eb80976 16/07/2012      50.99   -5.85
    eb80976 17/07/2012      52.09   -4.58
    eb80976 18/07/2012      49.72   -5.56
    eb80976 19/07/2012      51.59   -3.17
    eb80976 20/07/2012      52.45   -2.03
    eb80976 21/07/2012      56.015  -10.51
    
    Any help would be much appreciated. I am not totally sure where to start!
    Many thanks.
    
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From ne||@redu @end|ng |rom hotm@||@|r  Wed Jul 11 19:14:49 2018
From: ne||@redu @end|ng |rom hotm@||@|r (Nelly Reduan)
Date: Wed, 11 Jul 2018 17:14:49 +0000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <CA+8X3fV2USjzQE4Sh7ssAsJof=eNtBP74j38TqVisUuCD7+fvg@mail.gmail.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>,
 <CA+8X3fV2USjzQE4Sh7ssAsJof=eNtBP74j38TqVisUuCD7+fvg@mail.gmail.com>
Message-ID: <DM5PR05MB2793345795F3B490E78839B2995A0@DM5PR05MB2793.namprd05.prod.outlook.com>

Many thanks Jim for your help. I am trying to apply the permutations with a sequence of 20 but I obtain the error message:


Error in matrix(NA, nrow = nrows, ncol = lenx) :
  invalid 'nrow' value (too large or NA)
In addition: Warning message:
In matrix(NA, nrow = nrows, ncol = lenx) :
  NAs introduced by coercion to integer range


Here is the code:

library(partitions)
library(crank)
r <- t(restrictedparts(10, 20))
r <- split(r, seq(nrow(r)))
rp <- crank::permute(r[[sample(1:length(r), 1)]])
rp[sample(1:dim(rp)[1],1),]


In this case, Is it correct to permute the elements of a vector rather than to permute a vector ?


Many thanks for your time.

Have a nice day

Nell


________________________________
De : Jim Lemon <drjimlemon at gmail.com>
Envoy? : mardi 10 juillet 2018 17:44:13
? : Nelly Reduan
Objet : Re: [R] Generate N random numbers with a given probability and condition

Hi Nell,
I may not have the right idea about this, but I think you need to do
this in two steps if it can be done. Let's say you want a sequence of
20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
the monotonically increasing sequences like this:

c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
...
c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)

So if you select one of these sequences at random, there will be a
further set of sequences that are permutations of it. By randomly
selecting one of those permutations, I think you can solve your
problem. However, this is going to be computationally intensive, with
the set of permutations being very large for large N. Here is an
example using N = M = 5:

# enumerate the sequences = M
rs5<-list(c(1,1,1,1,1),c(0,1,1,1,2),c(0,0,1,1,3),c(0,0,0,1,4),
 c(0,0,1,2,2),c(0,0,0,2,3),c(0,0,0,0,5))
library(crank)
# generate the permutations for one sequence (120 in this case)
rs5_s1<-permute(rs5[[sample(1:length(rs5),1)]])
# select one of the permutations at random
rs5_s1[sample(1:dim(rs5_s1)[1],1),]
[1] 4 0 1 0 0

Jim

On Wed, Jul 11, 2018 at 10:11 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Thank you very much for your reply.
>
>
> By omitting the probability, the expected results could be:
>
>
> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>
>
> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>
>
> If I omit the probability, I would like to generate N random positive integers that sum to M and the integers would be selected from a uniform distribution.
>
>
> Many thanks for your time
>
> Nell
>
>
> ________________________________
> De : Rolf Turner <r.turner at auckland.ac.nz>
> Envoy? : mercredi 4 juillet 2018 16:11:11
> ? : Nelly Reduan
> Cc : r-help at r-project.org
> Objet : Re: [R] Generate N random numbers with a given probability and condition
>
>
> On 05/07/18 10:21, Nelly Reduan wrote:
>
>> Dear all,
>>
>> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
>> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
>>
>> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
>>
>> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>> Many thanks for your time.
>
> Your thinking requires considerable clarification.
>
> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>
> (2) Hence length(seq(0,10,1)) is 11.
>
> (3) Likewise max(seq(0,10,1)) is 10.
>
> (4) Your prob vector is *constant* --- so specifying "prob" makes
>      no difference --- the result is the same as if you omitted "prob".
>
> (5) You need to think carefully about what you really mean by "random".
>      In what way do you want the final result to be "random"?
>
> I expect that the lecturer who assigned this problem to you  needs to
> clarify his/her thinking as well.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Jul 11 23:59:58 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 12 Jul 2018 07:59:58 +1000
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB2793345795F3B490E78839B2995A0@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <9d59a21f-b530-08d2-2831-c1b7134c3c84@auckland.ac.nz>
 <DM5PR05MB2793E498CC7ADE58C048AA10995B0@DM5PR05MB2793.namprd05.prod.outlook.com>
 <CA+8X3fV2USjzQE4Sh7ssAsJof=eNtBP74j38TqVisUuCD7+fvg@mail.gmail.com>
 <DM5PR05MB2793345795F3B490E78839B2995A0@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <CA+8X3fWs_Df5q3Avd5ofrtH6ny+k2-Xrm7Qn1_1KW8YnbR4Luw@mail.gmail.com>

Hi Nell,
As I said, the number of permutations increases rapidly with the
number of values to be permuted. Using the package "permute", which is
much more sophisticated than the basic function in the crank package,
a vector of length 20 has 2.432902e+18 possible permutations. While
your problem can be solved for small vectors by simply generating all
the permutations and then sampling that set, it is not a general
solution. You may be able to use the functions in the permute package
to handle a 20 element vector, but I am not familiar enough with the
functions to tell you how.

Jim


On Thu, Jul 12, 2018 at 3:14 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
> Many thanks Jim for your help. I am trying to apply the permutations with a
> sequence of 20 but I obtain the error message:
>
>
> Error in matrix(NA, nrow = nrows, ncol = lenx) :
>   invalid 'nrow' value (too large or NA)
> In addition: Warning message:
> In matrix(NA, nrow = nrows, ncol = lenx) :
>   NAs introduced by coercion to integer range
>
> Here is the code:
>
> library(partitions)
> library(crank)
> r <- t(restrictedparts(10, 20))
> r <- split(r, seq(nrow(r)))
> rp <- crank::permute(r[[sample(1:length(r), 1)]])
> rp[sample(1:dim(rp)[1],1),]
>
> In this case, Is it correct to permute the elements of a vector rather than
> to permute a vector ?
>
>
> Many thanks for your time.
>
> Have a nice day
>
> Nell
>
>
> ________________________________
> De : Jim Lemon <drjimlemon at gmail.com>
> Envoy? : mardi 10 juillet 2018 17:44:13
> ? : Nelly Reduan
> Objet : Re: [R] Generate N random numbers with a given probability and
> condition
>
> Hi Nell,
> I may not have the right idea about this, but I think you need to do
> this in two steps if it can be done. Let's say you want a sequence of
> 20 (N) numbers between 0 and 10 that sums to 10 (M). You can enumerate
> the monotonically increasing sequences like this:
>
> c(0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1)
> c(0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,2)
> ...
> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10)
>
> So if you select one of these sequences at random, there will be a
> further set of sequences that are permutations of it. By randomly
> selecting one of those permutations, I think you can solve your
> problem. However, this is going to be computationally intensive, with
> the set of permutations being very large for large N. Here is an
> example using N = M = 5:
>
> # enumerate the sequences = M
> rs5<-list(c(1,1,1,1,1),c(0,1,1,1,2),c(0,0,1,1,3),c(0,0,0,1,4),
>  c(0,0,1,2,2),c(0,0,0,2,3),c(0,0,0,0,5))
> library(crank)
> # generate the permutations for one sequence (120 in this case)
> rs5_s1<-permute(rs5[[sample(1:length(rs5),1)]])
> # select one of the permutations at random
> rs5_s1[sample(1:dim(rs5_s1)[1],1),]
> [1] 4 0 1 0 0
>
> Jim
>
> On Wed, Jul 11, 2018 at 10:11 AM, Nelly Reduan <nell.redu at hotmail.fr> wrote:
>> Thank you very much for your reply.
>>
>>
>> By omitting the probability, the expected results could be:
>>
>>
>> c(2, 0, 0, 0, 0, 0, 1, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0)
>>
>>
>> c(0, 0, 1, 0, 0, 1, 1, 0, 6, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)
>>
>>
>> If I omit the probability, I would like to generate N random positive
>> integers that sum to M and the integers would be selected from a uniform
>> distribution.
>>
>>
>> Many thanks for your time
>>
>> Nell
>>
>>
>> ________________________________
>> De : Rolf Turner <r.turner at auckland.ac.nz>
>> Envoy? : mercredi 4 juillet 2018 16:11:11
>> ? : Nelly Reduan
>> Cc : r-help at r-project.org
>> Objet : Re: [R] Generate N random numbers with a given probability and
>> condition
>>
>>
>> On 05/07/18 10:21, Nelly Reduan wrote:
>>
>>> Dear all,
>>>
>>> I would like to generate N random numbers with a given probability and
>>> condition but I'm not sure how to do this.
>>> For example, I have N = 20 and the vector from which to choose is seq(0,
>>> 10, 1). I have tested:
>>>
>>> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28,
>>> times=length(seq(0, 10, 1))))
>>>
>>> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
>>> Many thanks for your time.
>>
>> Your thinking requires considerable clarification.
>>
>> (1) Note that seq(0,10,1) is just 0, 1, 2, ..., 10.
>>
>> (2) Hence length(seq(0,10,1)) is 11.
>>
>> (3) Likewise max(seq(0,10,1)) is 10.
>>
>> (4) Your prob vector is *constant* --- so specifying "prob" makes
>>      no difference --- the result is the same as if you omitted "prob".
>>
>> (5) You need to think carefully about what you really mean by "random".
>>      In what way do you want the final result to be "random"?
>>
>> I expect that the lecturer who assigned this problem to you  needs to
>> clarify his/her thinking as well.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jul 12 02:13:47 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 11 Jul 2018 20:13:47 -0400
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <a27f35f6-1f2d-e20d-f111-c25882262d9a@gmail.com>

On 04/07/2018 6:21 PM, Nelly Reduan wrote:
> Dear all,
> 
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
> 
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
> 
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time

I'd recommend an MCMC solution to this problem.  Set up a distribution 
that is uniform on vectors that satisfy the conditions, with penalties 
on vectors that don't.  Use the Metropolis algorithm with proposals that 
pick a pair of entries and increase one, decrease the other, then let 
MCMC run.  At the end, filter out the cases that violate the conditions.

The hard part is knowing how long to let it run for a satisfactory 
sample, and how correlated later draws will be.  Propp and Wilson's 
perfect sampling algorithm might allow an exact draw, though I don't 
quite see how, and I'm not sure it would be worth the trouble.  Just run 
for a few thousand steps and it should be fine.

Duncan Murdoch



From gor@n@bro@trom @end|ng |rom umu@@e  Thu Jul 12 09:44:06 2018
From: gor@n@bro@trom @end|ng |rom umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Thu, 12 Jul 2018 09:44:06 +0200
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
Message-ID: <feb770ae-f396-cd04-dc18-93fa9832c685@umu.se>



On 2018-07-05 00:21, Nelly Reduan wrote:
> Dear all,
> 
> I would like to generate N random numbers with a given probability and condition but I'm not sure how to do this.
> For example, I have N = 20 and the vector from which to choose is seq(0, 10, 1). I have tested:
> 
> x <- sample(seq(0, 10, 1), 20, replace=TRUE, prob=rep(0.28, times=length(seq(0, 10, 1))))
> 
> But I don?t know how to put the condition sum(x) <= max(seq(0, 10, 1)).
> Many thanks for your time
> Nell

Maybe the paper "Acceptance?Rejection Sampling from the Conditional 
Distribution of Independent Discrete Random Variables, given their Sum", 
Statistics 34, pages 247-257, by Leif Nilsson and myself (2000) is relevant?

G?ran

> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Jul 12 17:17:38 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 12 Jul 2018 15:17:38 +0000
Subject: [R] Help with replace()
Message-ID: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>


R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

Hi.

I have data set with day month year integers. I am creating a date column from those using lubridate.

a hundred or so rows failed to parse.

The problem is April and September have day = 31.

paste(df1$year, df1$month, df1$day, sep = "-")

ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial

#The resulting Date vector can be added to df1 as a new column called date:
df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning


head(df1)
sapply(df1$date,class) #"date"
summary(df1$date)
# Min.      1st Qu.       Median         Mean      3rd Qu.         Max.         NA's
#"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31"        "129"

is_missing_date <- is.na(df1$date)
View(is_missing_date)

date_columns <- c("year", "month", "day")
missing_dates <- df1[is_missing_date,  date_columns]

head(missing_dates)
#      year month day
# 3144 2000     9  31
# 3817 2000     4  31
# 3818 2000     4  31
# 3819 2000     4  31
# 3820 2000     4  31
# 3856 2000     9  31

I am trying to replace those with 30.

I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.

https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace
https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument
The following are screwy attempts at this simple repair,

??mutate_if

??replace

is_missing_date <- is.na(df1$date)
View(is_missing_date)

date_columns <- c("year", "month", "day")
missing_dates <- df1[is_missing_date,  date_columns]

head(missing_dates)
#year month day
# 3144 2000     9  31
# 3817 2000     4  31
# 3818 2000     4  31
# 3819 2000     4  31
# 3820 2000     4  31
# 3856 2000     9  31

#So need those months with 30 days that are 31 to be 30
View(missing_dates)

install.packages("dplyr")
library(dplyr)


View(missing_dates)
# ..those were the values you're going to replace

I thought this function from stackover would work, but get error when I try to add filter

#https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
  .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
  return(.data_Frame)
}

df.Rep(missing_dates, 3, 31, 30)

#--So I should be able to apply this to the complete df1 data somehow?
head(df1)
df.Rep(df1, filter(month == c(4,9)), 31, 30)
#Error in month == c(4, 9)  :   comparison (1) is possible only for atomic and list types


Other screwy attempts:


select(df1, month, day, year)
str(df1)
#'data.frame':   34786 obs. of  14 variables:
#To choose rows, use filter():

#mutate_if(df1, month =4,9), day = 30)


filter(df1, month == c(4,9), day == 31)

df1 %>%
  group_by(month == c(4,9), day == 31) %>%
  tally()
# 1 FALSE              FALSE       31161
# 2 FALSE              TRUE          576
# 3 TRUE               FALSE        2981
# 4 TRUE               TRUE           68

  df1 %>%
  mutate(day=replace(day, month == c(4,9), 30)) %>%
  as.data.frame()
  View(as.list(df1, month == 4))
  View(df1, month == c(4,9), day == 31)


df1 %>%
  group_by(month == c(4,9), day == 31) %>%
  tally()
View(df1, month == c(4,9))

# df1 %>%
#   group_by(month == c(4,9), day == 30) %>%


I know there is a simple solution  and it is driving me mad that it eludes me, despite being new to R.

Thank you for any advice.

WHP





















Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 12 17:22:08 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 12 Jul 2018 08:22:08 -0700
Subject: [R] Generate N random numbers with a given probability and
 condition
In-Reply-To: <feb770ae-f396-cd04-dc18-93fa9832c685@umu.se>
References: <DM5PR05MB27934FCE0D3F6C8781585A4599410@DM5PR05MB2793.namprd05.prod.outlook.com>
 <feb770ae-f396-cd04-dc18-93fa9832c685@umu.se>
Message-ID: <92556B41-5410-4FAB-990D-6D254AB5B2DA@comcast.net>


> On Jul 12, 2018, at 12:44 AM, G?ran Brostr?m <goran.brostrom at umu.se> wrote:
> 
> "Acceptance?Rejection Sampling from the Conditional Distribution of Independent Discrete Random Variables, given their Sum", Statistics 34, pages 247-257

Dear Go:ran;

I'm fully retired with no subscriber academic library that I can easily access. I've done a good faith search and can find no pdf's and the publisher website is apparently unable to deliver paid copies at this time. I wonder if you would be so kind as to send a preprint or other form of that article? I'm not so much interested in the the statistics as I am to see the two mentioned applications.

Best regards;

David Winsemius
Alameda, CA, USA



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 12 17:28:48 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 12 Jul 2018 08:28:48 -0700
Subject: [R] Help with replace()
In-Reply-To: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>


> On Jul 12, 2018, at 8:17 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> Hi.
> 
> I have data set with day month year integers. I am creating a date column from those using lubridate.
> 
> a hundred or so rows failed to parse.
> 
> The problem is April and September have day = 31.
> 
> paste(df1$year, df1$month, df1$day, sep = "-")
> 
> ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial
> 
> #The resulting Date vector can be added to df1 as a new column called date:
> df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning
> 
> 
> head(df1)
> sapply(df1$date,class) #"date"
> summary(df1$date)
> # Min.      1st Qu.       Median         Mean      3rd Qu.         Max.         NA's
> #"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31"        "129"
> 
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
> 
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date,  date_columns]
> 
> head(missing_dates)
> #      year month day
> # 3144 2000     9  31
> # 3817 2000     4  31
> # 3818 2000     4  31
> # 3819 2000     4  31
> # 3820 2000     4  31
> # 3856 2000     9  31
> 
> I am trying to replace those with 30.

Seems like a fairly straightforward application of "[<-" with a conditional argument. (No need for tidyverse.)

 missing_dates$day[ missing_dates$day==31 & ( missing_dates$month %in% c(4,9) )] <- 30


> missing_dates
     year month day
3144 2000     9  30
3817 2000     4  30
3818 2000     4  30
3819 2000     4  30
3820 2000     4  30
3856 2000     9  30

Best;
David.

> 
> I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.
> 
> https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
> https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace
> https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument
> The following are screwy attempts at this simple repair,
> 
> ??mutate_if
> 
> ??replace
> 
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
> 
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date,  date_columns]
> 
> head(missing_dates)
> #year month day
> # 3144 2000     9  31
> # 3817 2000     4  31
> # 3818 2000     4  31
> # 3819 2000     4  31
> # 3820 2000     4  31
> # 3856 2000     9  31
> 
> #So need those months with 30 days that are 31 to be 30
> View(missing_dates)
> 
> install.packages("dplyr")
> library(dplyr)
> 
> 
> View(missing_dates)
> # ..those were the values you're going to replace
> 
> I thought this function from stackover would work, but get error when I try to add filter
> 
> #https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1
> df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
>  .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
>  return(.data_Frame)
> }
> 
> df.Rep(missing_dates, 3, 31, 30)
> 
> #--So I should be able to apply this to the complete df1 data somehow?
> head(df1)
> df.Rep(df1, filter(month == c(4,9)), 31, 30)
> #Error in month == c(4, 9)  :   comparison (1) is possible only for atomic and list types
> 
> 
> Other screwy attempts:
> 
> 
> select(df1, month, day, year)
> str(df1)
> #'data.frame':   34786 obs. of  14 variables:
> #To choose rows, use filter():
> 
> #mutate_if(df1, month =4,9), day = 30)
> 
> 
> filter(df1, month == c(4,9), day == 31)
> 
> df1 %>%
>  group_by(month == c(4,9), day == 31) %>%
>  tally()
> # 1 FALSE              FALSE       31161
> # 2 FALSE              TRUE          576
> # 3 TRUE               FALSE        2981
> # 4 TRUE               TRUE           68
> 
>  df1 %>%
>  mutate(day=replace(day, month == c(4,9), 30)) %>%
>  as.data.frame()
>  View(as.list(df1, month == 4))
>  View(df1, month == c(4,9), day == 31)
> 
> 
> df1 %>%
>  group_by(month == c(4,9), day == 31) %>%
>  tally()
> View(df1, month == c(4,9))
> 
> # df1 %>%
> #   group_by(month == c(4,9), day == 30) %>%
> 
> 
> I know there is a simple solution  and it is driving me mad that it eludes me, despite being new to R.
> 
> Thank you for any advice.
> 
> WHP
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From m@r|ne@reg|@ @end|ng |rom hotm@||@|r  Thu Jul 12 17:34:50 2018
From: m@r|ne@reg|@ @end|ng |rom hotm@||@|r (Marine Regis)
Date: Thu, 12 Jul 2018 15:34:50 +0000
Subject: [R] Simplify the loop over the 3rd dimension of a 3D array
Message-ID: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>

Hello all,


Is there an efficient way to simplify the loop over the 3rd dimension of a 3D array ? I want to keep the loop over the "time". Here is the code:


set.seed(12345)
ind <- 10
time_seq <- seq(0, 8, 1)
col_array <- c(paste("time_", time_seq, sep=""))
tab <- array(0, dim=c(length(time_seq) , length(col_array), ind), dimnames=list(NULL, col_array, as.character(seq(1, ind, 1))))
print(tab)

tab[1,c("time_0"),] <- round(runif(ind, 0, 100))
print(tab)


for(time in 1:(length(time_seq) - 1)){
  for(i in 1:ind){
    tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
    tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
    tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
    tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
    tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
    tab[time + 1,c("time_5"),i] <- tab[time,c("time_4"),i]
    tab[time + 1,c("time_6"),i] <- tab[time,c("time_5"),i]
    tab[time + 1,c("time_7"),i] <- tab[time,c("time_6"),i]
    tab[time + 1,c("time_8"),i] <- tab[time,c("time_7"),i]
  }
}

print(tab)



In fact, the array has 800000 observations for the 3rd dimension.


Many thanks for your time

Have a great day

Marine

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Jul 12 18:09:56 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 12 Jul 2018 16:09:56 +0000
Subject: [R] Help with replace()
In-Reply-To: <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>
References: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>
Message-ID: <CY1PR0201MB1834D4BB41F45B86B58412C5EA590@CY1PR0201MB1834.namprd02.prod.outlook.com>

Yes, that's got it! (20 years from now I'll have it all figured out UGH!), lol!

Thank you David

Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
"1977-07-16" "1984-03-13" "1990-08-16" "1990-12-28" "1997-07-29" "2002-12-31"

WHP




From: David Winsemius [mailto:dwinsemius at comcast.net]
Sent: Thursday, July 12, 2018 11:29 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with replace()


> On Jul 12, 2018, at 8:17 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
>
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Hi.
>
> I have data set with day month year integers. I am creating a date column from those using lubridate.
>
> a hundred or so rows failed to parse.
>
> The problem is April and September have day = 31.
>
> paste(df1$year, df1$month, df1$day, sep = "-")
>
> ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial
>
> #The resulting Date vector can be added to df1 as a new column called date:
> df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning
>
>
> head(df1)
> sapply(df1$date,class) #"date"
> summary(df1$date)
> # Min. 1st Qu. Median Mean 3rd Qu. Max. NA's
> #"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31" "129"
>
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
>
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date, date_columns]
>
> head(missing_dates)
> # year month day
> # 3144 2000 9 31
> # 3817 2000 4 31
> # 3818 2000 4 31
> # 3819 2000 4 31
> # 3820 2000 4 31
> # 3856 2000 9 31
>
> I am trying to replace those with 30.

Seems like a fairly straightforward application of "[<-" with a conditional argument. (No need for tidyverse.)

missing_dates$day[ missing_dates$day==31 & ( missing_dates$month %in% c(4,9) )] <- 30


> missing_dates
year month day
3144 2000 9 30
3817 2000 4 30
3818 2000 4 30
3819 2000 4 30
3820 2000 4 30
3856 2000 9 30

Best;
David.

>
> I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.
>
> https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
> https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace<https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace>
> https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument<https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument>
> The following are screwy attempts at this simple repair,
>
> ??mutate_if
>
> ??replace
>
> is_missing_date <- is.na(df1$date)
> View(is_missing_date)
>
> date_columns <- c("year", "month", "day")
> missing_dates <- df1[is_missing_date, date_columns]
>
> head(missing_dates)
> #year month day
> # 3144 2000 9 31
> # 3817 2000 4 31
> # 3818 2000 4 31
> # 3819 2000 4 31
> # 3820 2000 4 31
> # 3856 2000 9 31
>
> #So need those months with 30 days that are 31 to be 30
> View(missing_dates)
>
> install.packages("dplyr")
> library(dplyr)
>
>
> View(missing_dates)
> # ..those were the values you're going to replace
>
> I thought this function from stackover would work, but get error when I try to add filter
>
> #https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
> df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
> .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
> return(.data_Frame)
> }
>
> df.Rep(missing_dates, 3, 31, 30)
>
> #--So I should be able to apply this to the complete df1 data somehow?
> head(df1)
> df.Rep(df1, filter(month == c(4,9)), 31, 30)
> #Error in month == c(4, 9) : comparison (1) is possible only for atomic and list types
>
>
> Other screwy attempts:
>
>
> select(df1, month, day, year)
> str(df1)
> #'data.frame': 34786 obs. of 14 variables:
> #To choose rows, use filter():
>
> #mutate_if(df1, month =4,9), day = 30)
>
>
> filter(df1, month == c(4,9), day == 31)
>
> df1 %>%
> group_by(month == c(4,9), day == 31) %>%
> tally()
> # 1 FALSE FALSE 31161
> # 2 FALSE TRUE 576
> # 3 TRUE FALSE 2981
> # 4 TRUE TRUE 68
>
> df1 %>%
> mutate(day=replace(day, month == c(4,9), 30)) %>%
> as.data.frame()
> View(as.list(df1, month == 4))
> View(df1, month == c(4,9), day == 31)
>
>
> df1 %>%
> group_by(month == c(4,9), day == 31) %>%
> tally()
> View(df1, month == c(4,9))
>
> # df1 %>%
> # group_by(month == c(4,9), day == 30) %>%
>
>
> I know there is a simple solution and it is driving me mad that it eludes me, despite being new to R.
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law




Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Jul 12 18:40:42 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 12 Jul 2018 12:40:42 -0400
Subject: [R] Simplify the loop over the 3rd dimension of a 3D array
In-Reply-To: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>
References: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>
Message-ID: <65e1c96a-b1dd-68de-caf4-822a55012d03@gmail.com>

On 12/07/2018 11:34 AM, Marine Regis wrote:
> Hello all,
> 
> 
> Is there an efficient way to simplify the loop over the 3rd dimension of a 3D array ? I want to keep the loop over the "time". Here is the code:
> 
> 
> set.seed(12345)
> ind <- 10
> time_seq <- seq(0, 8, 1)
> col_array <- c(paste("time_", time_seq, sep=""))
> tab <- array(0, dim=c(length(time_seq) , length(col_array), ind), dimnames=list(NULL, col_array, as.character(seq(1, ind, 1))))
> print(tab)
> 
> tab[1,c("time_0"),] <- round(runif(ind, 0, 100))
> print(tab)
> 
> 
> for(time in 1:(length(time_seq) - 1)){
>    for(i in 1:ind){
>      tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
>      tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
>      tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
>      tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
>      tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
>      tab[time + 1,c("time_5"),i] <- tab[time,c("time_4"),i]
>      tab[time + 1,c("time_6"),i] <- tab[time,c("time_5"),i]
>      tab[time + 1,c("time_7"),i] <- tab[time,c("time_6"),i]
>      tab[time + 1,c("time_8"),i] <- tab[time,c("time_7"),i]
>    }
> }

It looks as though you are setting all entries to the same value.  A 
simpler way to do that would be this loop:

for(time in 1:(length(time_seq) - 1)){
   for(i in 1:ind){
     tab[time + 1,,i] <- round(runif(1, 0, 100))
   }
}

You could also do away with the inner loop by generating ind random 
values all at once.  You have to be a little careful with the ordering; 
I think this gets it right:

for(time in 1:(length(time_seq) - 1)){
   tab[time + 1,,] <- t(matrix(round(runif(ind, 0, 100)), ind, 9))
}

And then you can do away with the loop entirely, since none of the 
values depend on earlier calculations.  Just generate 
ind*length(time_seq) uniforms, and put them in the array in the right 
order.  You could use aperm() to do this instead of t(), but be careful, 
it's easy to get the permutation wrong.  (I'm not even going to try now. 
:-).

Duncan Murdoch

> 
> print(tab)
> 
> 
> 
> In fact, the array has 800000 observations for the 3rd dimension.
> 
> 
> Many thanks for your time
> 
> Have a great day
> 
> Marine
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 12 20:21:53 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 12 Jul 2018 11:21:53 -0700
Subject: [R] Simplify the loop over the 3rd dimension of a 3D array
In-Reply-To: <65e1c96a-b1dd-68de-caf4-822a55012d03@gmail.com>
References: <VI1PR07MB35030A182A4DC74343B13AD6E2590@VI1PR07MB3503.eurprd07.prod.outlook.com>
 <65e1c96a-b1dd-68de-caf4-822a55012d03@gmail.com>
Message-ID: <2F6354ED-AFC7-4990-A82E-5899841EB4B9@comcast.net>


> On Jul 12, 2018, at 9:40 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 12/07/2018 11:34 AM, Marine Regis wrote:
>> Hello all,
>> Is there an efficient way to simplify the loop over the 3rd dimension of a 3D array ? I want to keep the loop over the "time". Here is the code:
>> set.seed(12345)
>> ind <- 10
>> time_seq <- seq(0, 8, 1)
>> col_array <- c(paste("time_", time_seq, sep=""))
>> tab <- array(0, dim=c(length(time_seq) , length(col_array), ind), dimnames=list(NULL, col_array, as.character(seq(1, ind, 1))))
>> print(tab)
>> tab[1,c("time_0"),] <- round(runif(ind, 0, 100))
>> print(tab)
>> for(time in 1:(length(time_seq) - 1)){
>>   for(i in 1:ind){
>>     tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
>>     tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
>>     tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
>>     tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
>>     tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
>>     tab[time + 1,c("time_5"),i] <- tab[time,c("time_4"),i]
>>     tab[time + 1,c("time_6"),i] <- tab[time,c("time_5"),i]
>>     tab[time + 1,c("time_7"),i] <- tab[time,c("time_6"),i]
>>     tab[time + 1,c("time_8"),i] <- tab[time,c("time_7"),i]
>>   }
>> }
> 
> It looks as though you are setting all entries to the same value.

I agree that it looked like that to me as well but in testing with a slight smaller version of the array I found that it was not so simple. I shortended the arrae to be dim = c(3,5,5) so that I could see it on one page, and then ran the code:

> for(time in 1:(length(time_seq) - 1)){
+  for(i in 1:ind){
+    tab[time + 1,c("time_0"),i] <- round(runif(1, 0, 100))
+    tab[time + 1,c("time_1"),i] <- tab[time,c("time_0"),i]
+    tab[time + 1,c("time_2"),i] <- tab[time,c("time_1"),i]
+    tab[time + 1,c("time_3"),i] <- tab[time,c("time_2"),i]
+    tab[time + 1,c("time_4"),i] <- tab[time,c("time_3"),i]
+    
+  }
+ }
> 
> print(tab)
, , 1

     time_0 time_1 time_2 time_3 time_4
[1,]     72      0      0      0      0
[2,]     89     72      0      0      0
[3,]     33     89     72      0      0
[4,]     99     33     89     72      0
[5,]     74     99     33     89     72

, , 2

     time_0 time_1 time_2 time_3 time_4
[1,]     88      0      0      0      0
[2,]     46     88      0      0      0
[3,]     51     46     88      0      0
[4,]      3     51     46     88      0
[5,]      0      3     51     46     88

, , 3

     time_0 time_1 time_2 time_3 time_4
[1,]     76      0      0      0      0
[2,]     17     76      0      0      0
[3,]     73     17     76      0      0
[4,]     15     73     17     76      0
[5,]     39     15     73     17     76


So the code was filling in the diagonal and a shifter version of the diagonal values. Whether that was the intent of the OP was not clear from the original email. The practice of throwing code as the only description of the problem is a common source of confusion.





> A simpler way to do that would be this loop:
> 
> for(time in 1:(length(time_seq) - 1)){
>  for(i in 1:ind){
>    tab[time + 1,,i] <- round(runif(1, 0, 100))
>  }
> }
> 
> You could also do away with the inner loop by generating ind random values all at once.  You have to be a little careful with the ordering; I think this gets it right:
> 
> for(time in 1:(length(time_seq) - 1)){
>  tab[time + 1,,] <- t(matrix(round(runif(ind, 0, 100)), ind, 9))
> }
> 
> And then you can do away with the loop entirely, since none of the values depend on earlier calculations.  Just generate ind*length(time_seq) uniforms, and put them in the array in the right order.  You could use aperm() to do this instead of t(), but be careful, it's easy to get the permutation wrong.  (I'm not even going to try now. :-).
> 
> Duncan Murdoch
> 
>> print(tab)
>> In fact, the array has 800000 observations for the 3rd dimension.
>> Many thanks for your time
>> Have a great day
>> Marine
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From kum@r@@m|t@bh1 @end|ng |rom y@hoo@com  Fri Jul 13 03:46:37 2018
From: kum@r@@m|t@bh1 @end|ng |rom y@hoo@com (Amitabh Kumar)
Date: Fri, 13 Jul 2018 01:46:37 +0000 (UTC)
Subject: [R] Forecasting methods in R
References: <25966788.3693631.1531446397452.ref@mail.yahoo.com>
Message-ID: <25966788.3693631.1531446397452@mail.yahoo.com>

Hi,
I am learning R for forecasting. Is there any document where I can learn how to apply R in forecasting time series using Holt-Winters method and ARIMA modelling?
Thanks,Amitabh
	[[alternative HTML version deleted]]



From @ez@reb@k| @end|ng |rom gm@||@com  Fri Jul 13 04:21:52 2018
From: @ez@reb@k| @end|ng |rom gm@||@com (Alex Zarebski)
Date: Fri, 13 Jul 2018 12:21:52 +1000
Subject: [R] Forecasting methods in R
In-Reply-To: <25966788.3693631.1531446397452@mail.yahoo.com>
References: <25966788.3693631.1531446397452.ref@mail.yahoo.com>
 <25966788.3693631.1531446397452@mail.yahoo.com>
Message-ID: <CAKsw2nF=tup0ERgxG=uyxhB3cMSZj4jNmAJ-n0+ubmYuPRttbQ@mail.gmail.com>

Hey,

You should probably check out the =forecast= package which is pretty close
to a default solution as you'll find.

https://cran.r-project.org/web/packages/forecast/

If you google around this you should find some useful stuff.

Cheers,
Alex

On Fri, Jul 13, 2018 at 12:15 PM Amitabh Kumar via R-help <
r-help at r-project.org> wrote:

> Hi,
> I am learning R for forecasting. Is there any document where I can learn
> how to apply R in forecasting time series using Holt-Winters method and
> ARIMA modelling?
> Thanks,Amitabh
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 13 04:24:10 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 12 Jul 2018 19:24:10 -0700
Subject: [R] Forecasting methods in R
In-Reply-To: <25966788.3693631.1531446397452@mail.yahoo.com>
References: <25966788.3693631.1531446397452.ref@mail.yahoo.com>
 <25966788.3693631.1531446397452@mail.yahoo.com>
Message-ID: <CAGxFJbRFMqKa=NtWyU6vn2Y9iufuQumXCidJqyXU7agR5qnYhA@mail.gmail.com>

1. https://cran.r-project.org/web/views/TimeSeries.html

2. Google!

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 12, 2018 at 6:46 PM, Amitabh Kumar via R-help <
r-help at r-project.org> wrote:

> Hi,
> I am learning R for forecasting. Is there any document where I can learn
> how to apply R in forecasting time series using Holt-Winters method and
> ARIMA modelling?
> Thanks,Amitabh
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From |becerr@ @end|ng |rom mdp@edu@@r  Fri Jul 13 20:43:38 2018
From: |becerr@ @end|ng |rom mdp@edu@@r (Federico Becerra)
Date: Fri, 13 Jul 2018 15:43:38 -0300
Subject: [R] optim function
Message-ID: <798044dea49eba9f7059cf0115b9e370@mdp.edu.ar>

Good afternoon,

I am a Biology researcher working on Functional Morphology and Behaviour 
in mammals. Nowadays, I have a series of morphological data that I would 
like to test against different models for which I would need to optimize 
them -namely, "randomly manipulating" all models parameters in order to 
find the model that fit best upon my data.

I've been told that the function "optim" is THE function for me, but 
I've been having problems to program it and set all constraints.

Is there anything you could help me (guide me) with? I've asked already 
several "experts" in the internet but noone gave me a real solution.

Thanks a lot, have a nice day,
Federico

-- 
Dr. Federico Becerra
Morfolog?a Funcional y Comportamiento
Instituto de Investigaciones Marinas y Costeras
Univ. Nac. Mar del Plata - CONICET
CC 1245. Dean Funes 3250.(7600) Mar del Plata. Argentina
Tel: +54 (0223)475-3554 / 475-2426 Int. 297
* For large files, please send it to fedebec at hotmail.com (and please 
notify me here so I check that out).



From yzh@o17 @end|ng |rom uoregon@edu  Fri Jul 13 23:24:40 2018
From: yzh@o17 @end|ng |rom uoregon@edu (Yufei Zhao)
Date: Fri, 13 Jul 2018 14:24:40 -0700
Subject: [R] Rmpi fails to install
Message-ID: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>

Hello!

I try to install Rmpi with install.packages(?Rmpi?), but it fails:

> install.packages("Rmpi")
Package which is only available in source form, and may need compilation of C/C++/Fortran: ?Rmpi?
Do you want to attempt to install these from sources? (Yes/no/cancel) yes
installing the source package ?Rmpi?

trying URL 'https://cran.rstudio.com/src/contrib/Rmpi_0.6-7.tar.gz'
Content type 'application/x-gzip' length 106869 bytes (104 KB)
==================================================
downloaded 104 KB

* installing *source* package ?Rmpi? ...
** package ?Rmpi? successfully unpacked and MD5 sums checked
checking for gcc... clang
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether clang accepts -g... yes
checking for clang option to accept ISO C89... none needed
checking for pkg-config... no
checking how to run the C preprocessor... clang -E
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for ANSI C header files... rm: conftest.dSYM: is a directory
rm: conftest.dSYM: is a directory
yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking mpi.h usability... no
checking mpi.h presence... no
checking for mpi.h... no
configure: error: "Cannot find mpi.h header file"
ERROR: configuration failed for package ?Rmpi?
* removing ?/Library/Frameworks/R.framework/Versions/3.5/Resources/library/Rmpi?
Warning in install.packages :
  installation of package ?Rmpi? had non-zero exit status

The downloaded source packages are in
	?/private/var/folders/wd/5x8p9n_j1kx7sqqv2hk23vvm0000gs/T/RtmpKZ1waO/downloaded_packages?


The systems is MacOS High Sierra 10.13.3.

Thanks in advance!

Best,
Yufei


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Jul 13 23:31:04 2018
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Fri, 13 Jul 2018 16:31:04 -0500
Subject: [R] Rmpi fails to install
In-Reply-To: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
References: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
Message-ID: <CACxE24=r1S8+QxVA=U2vNFwtEMQb3qT22q9eMA59QGRRtdkhow@mail.gmail.com>

Hi!

You need to have MPI in your path.

Thanks,
Erin

On Fri, Jul 13, 2018 at 4:29 PM Yufei Zhao <yzhao17 at uoregon.edu> wrote:

> Hello!
>
> I try to install Rmpi with install.packages(?Rmpi?), but it fails:
>
> > install.packages("Rmpi")
> Package which is only available in source form, and may need compilation
> of C/C++/Fortran: ?Rmpi?
> Do you want to attempt to install these from sources? (Yes/no/cancel) yes
> installing the source package ?Rmpi?
>
> trying URL 'https://cran.rstudio.com/src/contrib/Rmpi_0.6-7.tar.gz'
> Content type 'application/x-gzip' length 106869 bytes (104 KB)
> ==================================================
> downloaded 104 KB
>
> * installing *source* package ?Rmpi? ...
> ** package ?Rmpi? successfully unpacked and MD5 sums checked
> checking for gcc... clang
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether clang accepts -g... yes
> checking for clang option to accept ISO C89... none needed
> checking for pkg-config... no
> checking how to run the C preprocessor... clang -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... rm: conftest.dSYM: is a directory
> rm: conftest.dSYM: is a directory
> yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking mpi.h usability... no
> checking mpi.h presence... no
> checking for mpi.h... no
> configure: error: "Cannot find mpi.h header file"
> ERROR: configuration failed for package ?Rmpi?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.5/Resources/library/Rmpi?
> Warning in install.packages :
>   installation of package ?Rmpi? had non-zero exit status
>
> The downloaded source packages are in
>
> ?/private/var/folders/wd/5x8p9n_j1kx7sqqv2hk23vvm0000gs/T/RtmpKZ1waO/downloaded_packages?
>
>
> The systems is MacOS High Sierra 10.13.3.
>
> Thanks in advance!
>
> Best,
> Yufei
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 13 23:34:32 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 13 Jul 2018 14:34:32 -0700
Subject: [R] Rmpi fails to install
In-Reply-To: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
References: <28B431A7-3B3B-4E5F-BAA9-BCDDE795E308@uoregon.edu>
Message-ID: <CAGxFJbT=vvvKmM_-qYs7ShmRnaeSWFyba1h13CbgdU0V4GrLQA@mail.gmail.com>

I cannot specifically help, but you may wish to post this on the r-sig-mac
list where there may be the expertise you need.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 13, 2018 at 2:24 PM, Yufei Zhao <yzhao17 at uoregon.edu> wrote:

> Hello!
>
> I try to install Rmpi with install.packages(?Rmpi?), but it fails:
>
> > install.packages("Rmpi")
> Package which is only available in source form, and may need compilation
> of C/C++/Fortran: ?Rmpi?
> Do you want to attempt to install these from sources? (Yes/no/cancel) yes
> installing the source package ?Rmpi?
>
> trying URL 'https://cran.rstudio.com/src/contrib/Rmpi_0.6-7.tar.gz'
> Content type 'application/x-gzip' length 106869 bytes (104 KB)
> ==================================================
> downloaded 104 KB
>
> * installing *source* package ?Rmpi? ...
> ** package ?Rmpi? successfully unpacked and MD5 sums checked
> checking for gcc... clang
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether clang accepts -g... yes
> checking for clang option to accept ISO C89... none needed
> checking for pkg-config... no
> checking how to run the C preprocessor... clang -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... rm: conftest.dSYM: is a directory
> rm: conftest.dSYM: is a directory
> yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking mpi.h usability... no
> checking mpi.h presence... no
> checking for mpi.h... no
> configure: error: "Cannot find mpi.h header file"
> ERROR: configuration failed for package ?Rmpi?
> * removing ?/Library/Frameworks/R.framework/Versions/3.5/
> Resources/library/Rmpi?
> Warning in install.packages :
>   installation of package ?Rmpi? had non-zero exit status
>
> The downloaded source packages are in
>         ?/private/var/folders/wd/5x8p9n_j1kx7sqqv2hk23vvm0000gs/T/
> RtmpKZ1waO/downloaded_packages?
>
>
> The systems is MacOS High Sierra 10.13.3.
>
> Thanks in advance!
>
> Best,
> Yufei
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Sat Jul 14 01:05:06 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 13 Jul 2018 23:05:06 +0000
Subject: [R] optim function
In-Reply-To: <798044dea49eba9f7059cf0115b9e370@mdp.edu.ar>
References: <798044dea49eba9f7059cf0115b9e370@mdp.edu.ar>
Message-ID: <50B1F81D-857D-4909-88A7-DA6952B504C9@llnl.gov>

There's a CRAN Task View on optimization. There might be something useful there.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/13/18, 11:43 AM, "R-help on behalf of Federico Becerra" <r-help-bounces at r-project.org on behalf of fbecerra at mdp.edu.ar> wrote:

    Good afternoon,
    
    I am a Biology researcher working on Functional Morphology and Behaviour 
    in mammals. Nowadays, I have a series of morphological data that I would 
    like to test against different models for which I would need to optimize 
    them -namely, "randomly manipulating" all models parameters in order to 
    find the model that fit best upon my data.
    
    I've been told that the function "optim" is THE function for me, but 
    I've been having problems to program it and set all constraints.
    
    Is there anything you could help me (guide me) with? I've asked already 
    several "experts" in the internet but noone gave me a real solution.
    
    Thanks a lot, have a nice day,
    Federico
    
    -- 
    Dr. Federico Becerra
    Morfolog?a Funcional y Comportamiento
    Instituto de Investigaciones Marinas y Costeras
    Univ. Nac. Mar del Plata - CONICET
    CC 1245. Dean Funes 3250.(7600) Mar del Plata. Argentina
    Tel: +54 (0223)475-3554 / 475-2426 Int. 297
    * For large files, please send it to fedebec at hotmail.com (and please 
    notify me here so I check that out).
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com  Sat Jul 14 02:51:06 2018
From: jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com (Michael Hannon)
Date: Fri, 13 Jul 2018 17:51:06 -0700
Subject: [R] Making objects global in a package
Message-ID: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>

Greetings.  I'm putting together a small package in which I use
`dplyr::read_csv()` to read CSV files from several different sources.  I do
this in several different files, but with various kinds of subsequent
processing, depending on the file.

I find it useful to specify column types, as the apparent data type of a given
column sometimes changes unexpectedly deep into the file.  I.e., a field that
consistently looks like an integer, suddenly becomes a fraction:

    1, 1, ..., 1, 1/2, 1, ...

Hence, the column type has to be treated as a character, rather than as an
integer (with the possibility of later conversion to double, if necessary).
(This is just an example.)

Therefore I use the `col_types` argument in all of the calls to `read_csv()`.

These calls are spread over several files, but I want the keep all of the
column types in a single place, yet have them available in each of the several
files.  This is just for the sake of maintainability.

At the moment I do this by putting the column-type definitions into a single,
file:

    000_define_data_attributes.R

that:

    (1) is named so that it's parsed first by `devtools::build()`
    (2) sets up an environment and stuffs the column types into it:

            data_env <- new.env(parent=emptyenv())
            data_env$col_types_alpha <- list(
                Date = col_date(),
                var1 = col_double(),
                ...
            )

There are a few other things that go into the file as well.

Then I pick off the appropriate stuff from the environment in the other files:

    foo_alpha <- read_csv("alpha.csv", col_types = data_env$col_types_alpha)

This seems to work, but it doesn't "feel" right to me.  (If this were Python,
people would accuse me of being "non-pythonic").

Hence, I'm seeking suggestions for the best practice for this kind of thing.

BTW, I note that both the sources of data ("alpha", etc.) and the column types
are more or less guaranteed to be static for the foreseeable future.  Hence,
there really isn't much danger in just replicating the column-type definitions
in each of the various files, which would obviate the need for the "000..."
file.  In other words, this is mostly a style thing.

Thanks for any advice you can provide.

-- Mike



From rm@h@rp @end|ng |rom me@com  Sat Jul 14 03:13:23 2018
From: rm@h@rp @end|ng |rom me@com (R. Mark Sharp)
Date: Fri, 13 Jul 2018 20:13:23 -0500
Subject: [R] Making objects global in a package
In-Reply-To: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
Message-ID: <2366CD86-39DF-4B2C-97F9-62E3AC2CB95B@me.com>

I would usually use a function for this. It may not be more R like, but it is more readable to me. If you want, to keep the columns in a file, you could have the function initialize itself on the first call. 

Mark
R. Mark Sharp, Ph.D.
Data Scientist and Biomedical Statistical Consultant
7526 Meadow Green St.
San Antonio, TX 78251
mobile: 210-218-2868
rmsharp at me.com











> On Jul 13, 2018, at 7:51 PM, Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
> 
> Greetings.  I'm putting together a small package in which I use
> `dplyr::read_csv()` to read CSV files from several different sources.  I do
> this in several different files, but with various kinds of subsequent
> processing, depending on the file.
> 
> I find it useful to specify column types, as the apparent data type of a given
> column sometimes changes unexpectedly deep into the file.  I.e., a field that
> consistently looks like an integer, suddenly becomes a fraction:
> 
>    1, 1, ..., 1, 1/2, 1, ...
> 
> Hence, the column type has to be treated as a character, rather than as an
> integer (with the possibility of later conversion to double, if necessary).
> (This is just an example.)
> 
> Therefore I use the `col_types` argument in all of the calls to `read_csv()`.
> 
> These calls are spread over several files, but I want the keep all of the
> column types in a single place, yet have them available in each of the several
> files.  This is just for the sake of maintainability.
> 
> At the moment I do this by putting the column-type definitions into a single,
> file:
> 
>    000_define_data_attributes.R
> 
> that:
> 
>    (1) is named so that it's parsed first by `devtools::build()`
>    (2) sets up an environment and stuffs the column types into it:
> 
>            data_env <- new.env(parent=emptyenv())
>            data_env$col_types_alpha <- list(
>                Date = col_date(),
>                var1 = col_double(),
>                ...
>            )
> 
> There are a few other things that go into the file as well.
> 
> Then I pick off the appropriate stuff from the environment in the other files:
> 
>    foo_alpha <- read_csv("alpha.csv", col_types = data_env$col_types_alpha)
> 
> This seems to work, but it doesn't "feel" right to me.  (If this were Python,
> people would accuse me of being "non-pythonic").
> 
> Hence, I'm seeking suggestions for the best practice for this kind of thing.
> 
> BTW, I note that both the sources of data ("alpha", etc.) and the column types
> are more or less guaranteed to be static for the foreseeable future.  Hence,
> there really isn't much danger in just replicating the column-type definitions
> in each of the various files, which would obviate the need for the "000..."
> file.  In other words, this is mostly a style thing.
> 
> Thanks for any advice you can provide.
> 
> -- Mike
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 14 03:17:55 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 13 Jul 2018 18:17:55 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
Message-ID: <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>

a) There is a mailing list for package development questions: R-package-devel.

b) This seems like a job for the sysdata.rda file... no explicit environments needed. See the Writing R Extensions manual.

On July 13, 2018 5:51:06 PM PDT, Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
>Greetings.  I'm putting together a small package in which I use
>`dplyr::read_csv()` to read CSV files from several different sources. 
>I do
>this in several different files, but with various kinds of subsequent
>processing, depending on the file.
>
>I find it useful to specify column types, as the apparent data type of
>a given
>column sometimes changes unexpectedly deep into the file.  I.e., a
>field that
>consistently looks like an integer, suddenly becomes a fraction:
>
>    1, 1, ..., 1, 1/2, 1, ...
>
>Hence, the column type has to be treated as a character, rather than as
>an
>integer (with the possibility of later conversion to double, if
>necessary).
>(This is just an example.)
>
>Therefore I use the `col_types` argument in all of the calls to
>`read_csv()`.
>
>These calls are spread over several files, but I want the keep all of
>the
>column types in a single place, yet have them available in each of the
>several
>files.  This is just for the sake of maintainability.
>
>At the moment I do this by putting the column-type definitions into a
>single,
>file:
>
>    000_define_data_attributes.R
>
>that:
>
>    (1) is named so that it's parsed first by `devtools::build()`
>    (2) sets up an environment and stuffs the column types into it:
>
>            data_env <- new.env(parent=emptyenv())
>            data_env$col_types_alpha <- list(
>                Date = col_date(),
>                var1 = col_double(),
>                ...
>            )
>
>There are a few other things that go into the file as well.
>
>Then I pick off the appropriate stuff from the environment in the other
>files:
>
>foo_alpha <- read_csv("alpha.csv", col_types =
>data_env$col_types_alpha)
>
>This seems to work, but it doesn't "feel" right to me.  (If this were
>Python,
>people would accuse me of being "non-pythonic").
>
>Hence, I'm seeking suggestions for the best practice for this kind of
>thing.
>
>BTW, I note that both the sources of data ("alpha", etc.) and the
>column types
>are more or less guaranteed to be static for the foreseeable future. 
>Hence,
>there really isn't much danger in just replicating the column-type
>definitions
>in each of the various files, which would obviate the need for the
>"000..."
>file.  In other words, this is mostly a style thing.
>
>Thanks for any advice you can provide.
>
>-- Mike
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From wdun|@p @end|ng |rom t|bco@com  Sat Jul 14 03:50:31 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 13 Jul 2018 18:50:31 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
 <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
Message-ID: <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>

What the OP is doing looks fine to me.

The environment holding the data vectors is not necessary, but it helps
organize things - you know where to look for this sort of data vector.

I would avoid the *.rda file, since it is not text, hence not readily
editable
or trackable with most source control systems.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 13, 2018 at 6:17 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> a) There is a mailing list for package development questions:
> R-package-devel.
>
> b) This seems like a job for the sysdata.rda file... no explicit
> environments needed. See the Writing R Extensions manual.
>
> On July 13, 2018 5:51:06 PM PDT, Michael Hannon <
> jmhannon.ucdavis at gmail.com> wrote:
> >Greetings.  I'm putting together a small package in which I use
> >`dplyr::read_csv()` to read CSV files from several different sources.
> >I do
> >this in several different files, but with various kinds of subsequent
> >processing, depending on the file.
> >
> >I find it useful to specify column types, as the apparent data type of
> >a given
> >column sometimes changes unexpectedly deep into the file.  I.e., a
> >field that
> >consistently looks like an integer, suddenly becomes a fraction:
> >
> >    1, 1, ..., 1, 1/2, 1, ...
> >
> >Hence, the column type has to be treated as a character, rather than as
> >an
> >integer (with the possibility of later conversion to double, if
> >necessary).
> >(This is just an example.)
> >
> >Therefore I use the `col_types` argument in all of the calls to
> >`read_csv()`.
> >
> >These calls are spread over several files, but I want the keep all of
> >the
> >column types in a single place, yet have them available in each of the
> >several
> >files.  This is just for the sake of maintainability.
> >
> >At the moment I do this by putting the column-type definitions into a
> >single,
> >file:
> >
> >    000_define_data_attributes.R
> >
> >that:
> >
> >    (1) is named so that it's parsed first by `devtools::build()`
> >    (2) sets up an environment and stuffs the column types into it:
> >
> >            data_env <- new.env(parent=emptyenv())
> >            data_env$col_types_alpha <- list(
> >                Date = col_date(),
> >                var1 = col_double(),
> >                ...
> >            )
> >
> >There are a few other things that go into the file as well.
> >
> >Then I pick off the appropriate stuff from the environment in the other
> >files:
> >
> >foo_alpha <- read_csv("alpha.csv", col_types =
> >data_env$col_types_alpha)
> >
> >This seems to work, but it doesn't "feel" right to me.  (If this were
> >Python,
> >people would accuse me of being "non-pythonic").
> >
> >Hence, I'm seeking suggestions for the best practice for this kind of
> >thing.
> >
> >BTW, I note that both the sources of data ("alpha", etc.) and the
> >column types
> >are more or less guaranteed to be static for the foreseeable future.
> >Hence,
> >there really isn't much danger in just replicating the column-type
> >definitions
> >in each of the various files, which would obviate the need for the
> >"000..."
> >file.  In other words, this is mostly a style thing.
> >
> >Thanks for any advice you can provide.
> >
> >-- Mike
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 14 03:54:02 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 13 Jul 2018 18:54:02 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
 <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
 <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>
Message-ID: <FAD0DE73-F0A8-4D39-B8DF-936549423293@dcn.davis.ca.us>

Avoiding rda files because they don't track well with version control seems weak to me, since you should be creating the rda with an R file in the tools directory.

On July 13, 2018 6:50:31 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>What the OP is doing looks fine to me.
>
>The environment holding the data vectors is not necessary, but it helps
>organize things - you know where to look for this sort of data vector.
>
>I would avoid the *.rda file, since it is not text, hence not readily
>editable
>or trackable with most source control systems.
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Fri, Jul 13, 2018 at 6:17 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> a) There is a mailing list for package development questions:
>> R-package-devel.
>>
>> b) This seems like a job for the sysdata.rda file... no explicit
>> environments needed. See the Writing R Extensions manual.
>>
>> On July 13, 2018 5:51:06 PM PDT, Michael Hannon <
>> jmhannon.ucdavis at gmail.com> wrote:
>> >Greetings.  I'm putting together a small package in which I use
>> >`dplyr::read_csv()` to read CSV files from several different
>sources.
>> >I do
>> >this in several different files, but with various kinds of
>subsequent
>> >processing, depending on the file.
>> >
>> >I find it useful to specify column types, as the apparent data type
>of
>> >a given
>> >column sometimes changes unexpectedly deep into the file.  I.e., a
>> >field that
>> >consistently looks like an integer, suddenly becomes a fraction:
>> >
>> >    1, 1, ..., 1, 1/2, 1, ...
>> >
>> >Hence, the column type has to be treated as a character, rather than
>as
>> >an
>> >integer (with the possibility of later conversion to double, if
>> >necessary).
>> >(This is just an example.)
>> >
>> >Therefore I use the `col_types` argument in all of the calls to
>> >`read_csv()`.
>> >
>> >These calls are spread over several files, but I want the keep all
>of
>> >the
>> >column types in a single place, yet have them available in each of
>the
>> >several
>> >files.  This is just for the sake of maintainability.
>> >
>> >At the moment I do this by putting the column-type definitions into
>a
>> >single,
>> >file:
>> >
>> >    000_define_data_attributes.R
>> >
>> >that:
>> >
>> >    (1) is named so that it's parsed first by `devtools::build()`
>> >    (2) sets up an environment and stuffs the column types into it:
>> >
>> >            data_env <- new.env(parent=emptyenv())
>> >            data_env$col_types_alpha <- list(
>> >                Date = col_date(),
>> >                var1 = col_double(),
>> >                ...
>> >            )
>> >
>> >There are a few other things that go into the file as well.
>> >
>> >Then I pick off the appropriate stuff from the environment in the
>other
>> >files:
>> >
>> >foo_alpha <- read_csv("alpha.csv", col_types =
>> >data_env$col_types_alpha)
>> >
>> >This seems to work, but it doesn't "feel" right to me.  (If this
>were
>> >Python,
>> >people would accuse me of being "non-pythonic").
>> >
>> >Hence, I'm seeking suggestions for the best practice for this kind
>of
>> >thing.
>> >
>> >BTW, I note that both the sources of data ("alpha", etc.) and the
>> >column types
>> >are more or less guaranteed to be static for the foreseeable future.
>> >Hence,
>> >there really isn't much danger in just replicating the column-type
>> >definitions
>> >in each of the various files, which would obviate the need for the
>> >"000..."
>> >file.  In other words, this is mostly a style thing.
>> >
>> >Thanks for any advice you can provide.
>> >
>> >-- Mike
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

-- 
Sent from my phone. Please excuse my brevity.



From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Sat Jul 14 08:55:32 2018
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Sat, 14 Jul 2018 08:55:32 +0200
Subject: [R] Help with replace()
In-Reply-To: <CY1PR0201MB1834D4BB41F45B86B58412C5EA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834C12EF11CFD1FD8672ABBEA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <131C2BEC-CA86-4E9C-9546-3E6DB45D8732@comcast.net>
 <CY1PR0201MB1834D4BB41F45B86B58412C5EA590@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <51e8e50a-d1ee-d060-17db-080c2273f838@statistik.tu-dortmund.de>



On 12.07.2018 18:09, Bill Poling wrote:
> Yes, that's got it! (20 years from now I'll have it all figured out UGH!), lol!

Using R for 20 years myself now I can only tell that it takes much longer.

Best,
Uwe Ligges


> Thank you David
> 
> Min.      1st Qu.       Median         Mean      3rd Qu.         Max.
> "1977-07-16" "1984-03-13" "1990-08-16" "1990-12-28" "1997-07-29" "2002-12-31"
> 
> WHP
> 
> 
> 
> 
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Thursday, July 12, 2018 11:29 AM
> To: Bill Poling <Bill.Poling at zelis.com>
> Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
> Subject: Re: [R] Help with replace()
> 
> 
>> On Jul 12, 2018, at 8:17 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>>
>>
>> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> Hi.
>>
>> I have data set with day month year integers. I am creating a date column from those using lubridate.
>>
>> a hundred or so rows failed to parse.
>>
>> The problem is April and September have day = 31.
>>
>> paste(df1$year, df1$month, df1$day, sep = "-")
>>
>> ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Warning message: 129 failed to parse. As expected in tutorial
>>
>> #The resulting Date vector can be added to df1 as a new column called date:
>> df1$date <- ymd(paste(df1$year, df1$month, df1$day, sep = "-"))#Same warning
>>
>>
>> head(df1)
>> sapply(df1$date,class) #"date"
>> summary(df1$date)
>> # Min. 1st Qu. Median Mean 3rd Qu. Max. NA's
>> #"1977-07-16" "1984-03-12" "1990-07-22" "1990-12-15" "1997-07-29" "2002-12-31" "129"
>>
>> is_missing_date <- is.na(df1$date)
>> View(is_missing_date)
>>
>> date_columns <- c("year", "month", "day")
>> missing_dates <- df1[is_missing_date, date_columns]
>>
>> head(missing_dates)
>> # year month day
>> # 3144 2000 9 31
>> # 3817 2000 4 31
>> # 3818 2000 4 31
>> # 3819 2000 4 31
>> # 3820 2000 4 31
>> # 3856 2000 9 31
>>
>> I am trying to replace those with 30.
> 
> Seems like a fairly straightforward application of "[<-" with a conditional argument. (No need for tidyverse.)
> 
> missing_dates$day[ missing_dates$day==31 & ( missing_dates$month %in% c(4,9) )] <- 30
> 
> 
>> missing_dates
> year month day
> 3144 2000 9 30
> 3817 2000 4 30
> 3818 2000 4 30
> 3819 2000 4 30
> 3820 2000 4 30
> 3856 2000 9 30
> 
> Best;
> David.
> 
>>
>> I am all over the map in Google looking for a fix, but haven't found one. I am sure I have over complicated my attempts with ideas(below) from these and other sites.
>>
>> https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
>> https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace<https://www.rdocumentation.org/packages/base/versions/3.5.1/topics/replace>
>> https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument<https://stackoverflow.com/questions/48714625/error-in-data-frame-unused-argument>
>> The following are screwy attempts at this simple repair,
>>
>> ??mutate_if
>>
>> ??replace
>>
>> is_missing_date <- is.na(df1$date)
>> View(is_missing_date)
>>
>> date_columns <- c("year", "month", "day")
>> missing_dates <- df1[is_missing_date, date_columns]
>>
>> head(missing_dates)
>> #year month day
>> # 3144 2000 9 31
>> # 3817 2000 4 31
>> # 3818 2000 4 31
>> # 3819 2000 4 31
>> # 3820 2000 4 31
>> # 3856 2000 9 31
>>
>> #So need those months with 30 days that are 31 to be 30
>> View(missing_dates)
>>
>> install.packages("dplyr")
>> library(dplyr)
>>
>>
>> View(missing_dates)
>> # ..those were the values you're going to replace
>>
>> I thought this function from stackover would work, but get error when I try to add filter
>>
>> #https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1<https://stackoverflow.com/questions/14737773/replacing-occurrences-of-a-number-in-multiple-columns-of-data-frame-with-another?noredirect=1&lq=1>
>> df.Rep <- function(.data_Frame, .search_Columns, .search_Value, .sub_Value){
>> .data_Frame[, .search_Columns] <- ifelse(.data_Frame[, .search_Columns]==.search_Value,.sub_Value/.search_Value,1) * .data_Frame[, .search_Columns]
>> return(.data_Frame)
>> }
>>
>> df.Rep(missing_dates, 3, 31, 30)
>>
>> #--So I should be able to apply this to the complete df1 data somehow?
>> head(df1)
>> df.Rep(df1, filter(month == c(4,9)), 31, 30)
>> #Error in month == c(4, 9) : comparison (1) is possible only for atomic and list types
>>
>>
>> Other screwy attempts:
>>
>>
>> select(df1, month, day, year)
>> str(df1)
>> #'data.frame': 34786 obs. of 14 variables:
>> #To choose rows, use filter():
>>
>> #mutate_if(df1, month =4,9), day = 30)
>>
>>
>> filter(df1, month == c(4,9), day == 31)
>>
>> df1 %>%
>> group_by(month == c(4,9), day == 31) %>%
>> tally()
>> # 1 FALSE FALSE 31161
>> # 2 FALSE TRUE 576
>> # 3 TRUE FALSE 2981
>> # 4 TRUE TRUE 68
>>
>> df1 %>%
>> mutate(day=replace(day, month == c(4,9), 30)) %>%
>> as.data.frame()
>> View(as.list(df1, month == 4))
>> View(df1, month == c(4,9), day == 31)
>>
>>
>> df1 %>%
>> group_by(month == c(4,9), day == 31) %>%
>> tally()
>> View(df1, month == c(4,9))
>>
>> # df1 %>%
>> # group_by(month == c(4,9), day == 30) %>%
>>
>>
>> I know there is a simple solution and it is driving me mad that it eludes me, despite being new to R.
>>
>> Thank you for any advice.
>>
>> WHP
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From pro|jcn@@h @end|ng |rom gm@||@com  Sat Jul 14 13:18:36 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sat, 14 Jul 2018 07:18:36 -0400
Subject: [R] optim function
In-Reply-To: <d3ccf5f0-d613-2f6c-6c21-8ed323e25ebd@gmail.com>
References: <d3ccf5f0-d613-2f6c-6c21-8ed323e25ebd@gmail.com>
Message-ID: <dba1a0ad-17f9-738e-8a8d-03c0d9b2bac6@gmail.com>


Subject: Re: [R] optim function
Date: Fri, 13 Jul 2018 17:06:56 -0400
From: J C Nash <profjcnash at gmail.com>
To: Federico Becerra <fbecerra at mdp.edu.ar>

Though I wrote the original codes for 3 of the 5 solvers in optim(), I now suggest using more recent ones, some
of which I have packaged. optimx on R-forge (not the one on CRAN yet) has optimr() function that has same
syntax as optim but more options. See https://r-forge.r-project.org/projects/optimizer/.

You need an objective function  myobj(parameters, other_data) that is smaller the better the model fit.

Then solution <- optimr(startparameters, myobj, method="chosen-method")

will try to optimize. If you can supply a gradient function, then you will usually do much better.

My book, Nonlinear Parameter Optimization Using R Tools (2014) gives quite a few examples, but doesn't
have the optimr() function -- it's more recent.

And do -- repeat do -- check your function VERY carefully. It is worth it. If the objective is in any
way wrong, badly scaled, etc. you WILL get into trouble.

John Nash




On 2018-07-13 02:43 PM, Federico Becerra wrote:
> Good afternoon,
> 
> I am a Biology researcher working on Functional Morphology and Behaviour in mammals. Nowadays, I have a series of
> morphological data that I would like to test against different models for which I would need to optimize them -namely,
> "randomly manipulating" all models parameters in order to find the model that fit best upon my data.
> 
> I've been told that the function "optim" is THE function for me, but I've been having problems to program it and set all
> constraints.
> 
> Is there anything you could help me (guide me) with? I've asked already several "experts" in the internet but noone gave
> me a real solution.
> 
> Thanks a lot, have a nice day,
> Federico
>



From |@bbrop|etro @end|ng |rom y@hoo@|t  Sat Jul 14 11:40:57 2018
From: |@bbrop|etro @end|ng |rom y@hoo@|t (P95 F95)
Date: Sat, 14 Jul 2018 11:40:57 +0200
Subject: [R] Custom Indicator Quantstrat Problem
Message-ID: <24DBB882-6991-4DED-93A2-6DAA97F63304@yahoo.it>

Hi. 

I am new in the forum and in R, I would like to ask for help. 
I am trying to add a custom indicator in quantstrat for my trading strategy 
but something does not work. 

When I insert the command: 

#out <- applyStrategy(strategy=strategy.st <http://strategy.st/>,portfolios=portfolio.st <http://portfolio.st/>) 

I get: 

#Error in .xts(e, .index(e1), .indexCLASS = indexClass(e1), .indexFORMAT = 
#indexFormat(e1),  : 
#index length must match number of observations 
#Inoltre: Warning messages: 
#1: In match.names(column, colnames(data)) : 
#all columns not located in CNOwma for RUT.Open RUT.High RUT.Low RUT.Close 
#RUT.Volume RUT.Adjusted X1.Channel.Normalization.Operator.smoothed.by.a.LWMA 
#2: In min(j, na.rm = TRUE) : 
#no non-missing arguments to min; returning Inf 
#3: In max(j, na.rm = TRUE) : 
#no non-missing arguments to max; returning -Inf 

The coding of the indicator is: 

#wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
#wmamaxt <- rollmaxr(wma, 30, fill = NA) 
#wmamint <- - rollmaxr(- wma, 30, fill = NA) 
#CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - 
#wmamint)} 


The add.indicator function is: 



#add.indicator(strategy = strategy.st <http://strategy.st/>, 
#name = 'CNOwma', 
#arguments = list(quote(Cl(mktdata)[,1]), n=4), 
#label = 'Channel Normalization Operator smoothed by a LWMA') 




The first 32 elements of CNOwma(mktdata) are NA. Could this explain the 
problem?

Thank you,

Best regards,


Pietro Fabbro
	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 14 14:18:18 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 05:18:18 -0700
Subject: [R] Custom Indicator Quantstrat Problem
In-Reply-To: <24DBB882-6991-4DED-93A2-6DAA97F63304@yahoo.it>
References: <24DBB882-6991-4DED-93A2-6DAA97F63304@yahoo.it>
Message-ID: <1BF41FB9-78E2-4948-B7B2-684871617886@dcn.davis.ca.us>

This mailing list is plain text only (read the Posting Guide). When you send HTML-formatted email, what we see is often not what you saw. The solution is for you to figure out how to send your email in plain text format to begin with. Since the syntax in your code below is not valid, I am guessing your message has been corrupted by posting HTML format.

Also, at least half the time your troubles start with the data you have, so it is important to supply enough example data to let the us run your code ourselves and trigger any problem you are having. See any or all of [1][2][3] for advice on how to create a reproducible example.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)


On July 14, 2018 2:40:57 AM PDT, P95 F95 via R-help <r-help at r-project.org> wrote:
>Hi. 
>
>I am new in the forum and in R, I would like to ask for help. 
>I am trying to add a custom indicator in quantstrat for my trading
>strategy 
>but something does not work. 
>
>When I insert the command: 
>
>#out <- applyStrategy(strategy=strategy.st
><http://strategy.st/>,portfolios=portfolio.st <http://portfolio.st/>) 
>
>I get: 
>
>#Error in .xts(e, .index(e1), .indexCLASS = indexClass(e1),
>.indexFORMAT = 
>#indexFormat(e1),  : 
>#index length must match number of observations 
>#Inoltre: Warning messages: 
>#1: In match.names(column, colnames(data)) : 
>#all columns not located in CNOwma for RUT.Open RUT.High RUT.Low
>RUT.Close 
>#RUT.Volume RUT.Adjusted
>X1.Channel.Normalization.Operator.smoothed.by.a.LWMA 
>#2: In min(j, na.rm = TRUE) : 
>#no non-missing arguments to min; returning Inf 
>#3: In max(j, na.rm = TRUE) : 
>#no non-missing arguments to max; returning -Inf 
>
>The coding of the indicator is: 
>
>#wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
>#wmamaxt <- rollmaxr(wma, 30, fill = NA) 
>#wmamint <- - rollmaxr(- wma, 30, fill = NA) 
>#CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) /
>(wmamaxt - 
>#wmamint)} 
>
>
>The add.indicator function is: 
>
>
>
>#add.indicator(strategy = strategy.st <http://strategy.st/>, 
>#name = 'CNOwma', 
>#arguments = list(quote(Cl(mktdata)[,1]), n=4), 
>#label = 'Channel Normalization Operator smoothed by a LWMA') 
>
>
>
>
>The first 32 elements of CNOwma(mktdata) are NA. Could this explain the
>
>problem?
>
>Thank you,
>
>Best regards,
>
>
>Pietro Fabbro
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From |@bbrop|etro @end|ng |rom y@hoo@|t  Sat Jul 14 15:02:08 2018
From: |@bbrop|etro @end|ng |rom y@hoo@|t (Pietro Fabbro)
Date: Sat, 14 Jul 2018 13:02:08 +0000 (UTC)
Subject: [R] Quantstrat custom indicator colnames error
References: <1074225301.3980976.1531573328594.ref@mail.yahoo.com>
Message-ID: <1074225301.3980976.1531573328594@mail.yahoo.com>

I apologize if the data I will insert will not be enough.

So, I am trying to run a strategy through the package Quantstrat.

install.packages("quantstrat")


My problem is that I get the following error
Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
attempt to set 'colnames' on an object with less than two dimensions

when I try to run the following command:

> out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
I do not have this problem if I use, as indicator, one or more indicators, which are already defined by the package TTR.

I have this error only when I try to use a custom indicator. Here is the code for the custom indicator that I use:

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
Please refer to the following code:

library(devtools)
library(quantmod)
library(quantstrat)
library(TTR)
library(png)
library(IKTrading)

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
initdate <- "2010-01-01"
from <- "2012-01-01" #start of backtest
to <- "2017-31-12" #end of backtest

Sys.setenv(TZ= "EST") #Set up environment for timestamps

currency("USD") #Set up environment for currency to be used

symbols <- c("RUT", "IXIC") #symbols used in our backtest
getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust = TRUE) #receive data from google finance,  adjusted for splits/dividends

stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use

tradesize <-10000 #default trade size
initeq <- 100000 #default initial equity in our portfolio

strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account

#removes old portfolio and strategy from environment
rm.strat(portfolio.st)
rm.strat(strategy.st) 

#initialize portfolio, account, orders and strategy objects
initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")

initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)

initOrders(portfolio.st, initDate = initdate)
strategy(strategy.st, store=TRUE)

add.indicator(strategy = strategy.st,
name = 'CNOwma',
arguments = list(x = quote(Cl(mktdata)), n=4),
label = 'CNOwma4')





add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "gt", cross = TRUE),
label = "longthreshold")


add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "lt", cross = TRUE),
label = "shortthreshold")




add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "enter")


add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "exit")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "enter")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "exit")



out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)


When I run the traceback() of the error, this is what I get:
> traceback()
4: stop("attempt to set 'colnames' on an object with less than two dimensions")
3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters = parameters, 
...)
1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st



From |@bbrop|etro @end|ng |rom y@hoo@|t  Sat Jul 14 15:04:07 2018
From: |@bbrop|etro @end|ng |rom y@hoo@|t (Pietro Fabbro)
Date: Sat, 14 Jul 2018 13:04:07 +0000 (UTC)
Subject: [R] Error custom indicator Quantstrat colnames
References: <597390662.3985563.1531573447687.ref@mail.yahoo.com>
Message-ID: <597390662.3985563.1531573447687@mail.yahoo.com>

I will try to be as clear as possible as I have been rebuked by some users. I deleted the last questions and I will try to be sufficiently explicative in this one. I apologize if the data I will insert will not be enough.

So, I am trying to run a strategy through the package Quantstrat.

install.packages("quantstrat")
My problem is that I get the following error

Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
attempt to set 'colnames' on an object with less than two dimensions

when I try to run the following command:

> out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
I do not have this problem if I use, as indicator, one or more indicators, which are already defined by the package TTR.

I have this error only when I try to use a custom indicator. Here is the code for the custom indicator that I use:

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
Please refer to the following code:

library(devtools)
library(quantmod)
library(quantstrat)
library(TTR)
library(png)
library(IKTrading)

wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
wmamaxt <- rollmaxr(wma, 30, fill = NA)
wmamint <- - rollmaxr(- wma, 30, fill = NA)
CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
initdate <- "2010-01-01"
from <- "2012-01-01" #start of backtest
to <- "2017-31-12" #end of backtest

Sys.setenv(TZ= "EST") #Set up environment for timestamps

currency("USD") #Set up environment for currency to be used

symbols <- c("RUT", "IXIC") #symbols used in our backtest
getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust = TRUE) #receive data from google finance,  adjusted for splits/dividends

stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use

tradesize <-10000 #default trade size
initeq <- 100000 #default initial equity in our portfolio

strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account

#removes old portfolio and strategy from environment
rm.strat(portfolio.st)
rm.strat(strategy.st) 

#initialize portfolio, account, orders and strategy objects
initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")

initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)

initOrders(portfolio.st, initDate = initdate)
strategy(strategy.st, store=TRUE)

add.indicator(strategy = strategy.st,
name = 'CNOwma',
arguments = list(x = quote(Cl(mktdata)), n=4),
label = 'CNOwma4')





add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "gt", cross = TRUE),
label = "longthreshold")


add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "lt", cross = TRUE),
label = "shortthreshold")




add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "enter")


add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "exit")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "enter")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "exit")



out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
When I run the traceback() of the error, this is what I get:

> traceback()
4: stop("attempt to set 'colnames' on an object with less than two dimensions")
3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters = parameters, 
...)
1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st)



From ted@h@rd|ng @end|ng |rom w|@ndre@@net  Sat Jul 14 18:05:27 2018
From: ted@h@rd|ng @end|ng |rom w|@ndre@@net (Ted Harding)
Date: Sat, 14 Jul 2018 17:05:27 +0100
Subject: [R] Error custom indicator Quantstrat colnames
In-Reply-To: <597390662.3985563.1531573447687@mail.yahoo.com>
References: <597390662.3985563.1531573447687.ref@mail.yahoo.com>
 <597390662.3985563.1531573447687@mail.yahoo.com>
Message-ID: <1531584327.3808.32.camel@deb2.fort.knox.uk>

Pietro,
Please post this to r-help at r-project.org
not to r-help-owner at r-project.org
which is a mailing liat concerned with list management, and
does not deal with questions regarding the use of R.
Best wishes,
Ted.

On Sat, 2018-07-14 at 13:04 +0000, Pietro Fabbro via R-help wrote:
> I will try to be as clear as possible as I have been rebuked by some users. I deleted the last questions and I will try to be sufficiently explicative in this one. I apologize if the data I will insert will not be enough.
> 
> So, I am trying to run a strategy through the package Quantstrat.
> 
> install.packages("quantstrat")
> My problem is that I get the following error
> 
> Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
> attempt to set 'colnames' on an object with less than two dimensions
> 
> when I try to run the following command:
> 
> > out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
> I do not have this problem if I use, as indicator, one or more indicators, which are already defined by the package TTR.
> 
> I have this error only when I try to use a custom indicator. Here is the code for the custom indicator that I use:
> 
> wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
> wmamaxt <- rollmaxr(wma, 30, fill = NA)
> wmamint <- - rollmaxr(- wma, 30, fill = NA)
> CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
> Please refer to the following code:
> 
> library(devtools)
> library(quantmod)
> library(quantstrat)
> library(TTR)
> library(png)
> library(IKTrading)
> 
> wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
> wmamaxt <- rollmaxr(wma, 30, fill = NA)
> wmamint <- - rollmaxr(- wma, 30, fill = NA)
> CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) / (wmamaxt - wmamint)}
> initdate <- "2010-01-01"
> from <- "2012-01-01" #start of backtest
> to <- "2017-31-12" #end of backtest
> 
> Sys.setenv(TZ= "EST") #Set up environment for timestamps
> 
> currency("USD") #Set up environment for currency to be used
> 
> symbols <- c("RUT", "IXIC") #symbols used in our backtest
> getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust = TRUE) #receive data from google finance,  adjusted for splits/dividends
> 
> stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use
> 
> tradesize <-10000 #default trade size
> initeq <- 100000 #default initial equity in our portfolio
> 
> strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account
> 
> #removes old portfolio and strategy from environment
> rm.strat(portfolio.st)
> rm.strat(strategy.st) 
> 
> #initialize portfolio, account, orders and strategy objects
> initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")
> 
> initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)
> 
> initOrders(portfolio.st, initDate = initdate)
> strategy(strategy.st, store=TRUE)
> 
> add.indicator(strategy = strategy.st,
> name = 'CNOwma',
> arguments = list(x = quote(Cl(mktdata)), n=4),
> label = 'CNOwma4')
> 
> 
> 
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "gt", cross = TRUE),
> label = "longthreshold")
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "lt", cross = TRUE),
> label = "shortthreshold")
> 
> 
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"),
> type = "enter")
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),
> type = "enter")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> 
> 
> out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
> When I run the traceback() of the error, this is what I get:
> 
> > traceback()
> 4: stop("attempt to set 'colnames' on an object with less than two dimensions")
> 3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
> 2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters = parameters, 
> ...)
> 1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 14 19:13:21 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 10:13:21 -0700
Subject: [R] Quantstrat custom indicator colnames error
In-Reply-To: <1074225301.3980976.1531573328594@mail.yahoo.com>
References: <1074225301.3980976.1531573328594.ref@mail.yahoo.com>
 <1074225301.3980976.1531573328594@mail.yahoo.com>
Message-ID: <132EE7A3-D9DA-48D6-BA78-87A30639A108@dcn.davis.ca.us>

Thank you for for reposting a readable question, though the origin of quantstrat and IKTrading on github still took some study, and I cannot see where mktdata was supposed to come from.

If you get no expert response here, you might get a more appropriate set of users if you ask this question on the R-Sig-finance mailing list (where readers might actually recognize the issue offhand), or by asking your question at the quantstrat issues forum [1]. Packages that don't build clean enough to install from CRAN can really lead to wild goose chases debugging the package rather than helping someone understand R (the topic of this mailing list).

No matter where you ask this question, getting the code to be internally complete including data (study up on the dput function in the links I pointed you at
to before) will really help your helpers and you will learn more about R yourself. The reprex package I mentioned makes it easy to confirm that others have a good chance to see the behavior you saw when they run your example.

[1] https://github.com/Braddock/quantstrat

On July 14, 2018 6:02:08 AM PDT, Pietro Fabbro via R-help <r-help at r-project.org> wrote:
>I apologize if the data I will insert will not be enough.
>
>So, I am trying to run a strategy through the package Quantstrat.
>
>install.packages("quantstrat")
>
>
>My problem is that I get the following error
>Error incolnames<-(tmp, value = seq(ncol(tmp_val))) : 
>attempt to set 'colnames' on an object with less than two dimensions
>
>when I try to run the following command:
>
>> out <- applyStrategy(strategy=strategy.st,portfolios=portfolio.st)
>I do not have this problem if I use, as indicator, one or more
>indicators, which are already defined by the package TTR.
>
>I have this error only when I try to use a custom indicator. Here is
>the code for the custom indicator that I use:
>
>wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
>wmamaxt <- rollmaxr(wma, 30, fill = NA)
>wmamint <- - rollmaxr(- wma, 30, fill = NA)
>CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) /
>(wmamaxt - wmamint)}
>Please refer to the following code:
>
>library(devtools)
>library(quantmod)
>library(quantstrat)
>library(TTR)
>library(png)
>library(IKTrading)
>
>wma <-  WMA(Cl(mktdata), 4, wts=c(1:4)) 
>wmamaxt <- rollmaxr(wma, 30, fill = NA)
>wmamint <- - rollmaxr(- wma, 30, fill = NA)
>CNOwma <- function (mktdata=quote(mktdata),x) {(wma - wmamint) /
>(wmamaxt - wmamint)}
>initdate <- "2010-01-01"
>from <- "2012-01-01" #start of backtest
>to <- "2017-31-12" #end of backtest
>
>Sys.setenv(TZ= "EST") #Set up environment for timestamps
>
>currency("USD") #Set up environment for currency to be used
>
>symbols <- c("RUT", "IXIC") #symbols used in our backtest
>getSymbols(Symbols = symbols, src = "google", from=from, to=to, adjust
>= TRUE) #receive data from google finance,  adjusted for
>splits/dividends
>
>stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what
>instruments present and what currency to use
>
>tradesize <-10000 #default trade size
>initeq <- 100000 #default initial equity in our portfolio
>
>strategy.st <- portfolio.st <- account.st <- "firststrat" #naming
>strategy, portfolio and account
>
>#removes old portfolio and strategy from environment
>rm.strat(portfolio.st)
>rm.strat(strategy.st) 
>
>#initialize portfolio, account, orders and strategy objects
>initPortf(portfolio.st, symbols = symbols, initDate = initdate,
>currency = "USD")
>
>initAcct(account.st, portfolios = portfolio.st, initDate = initdate,
>currency = "USD", initEq = initeq)
>
>initOrders(portfolio.st, initDate = initdate)
>strategy(strategy.st, store=TRUE)
>
>add.indicator(strategy = strategy.st,
>name = 'CNOwma',
>arguments = list(x = quote(Cl(mktdata)), n=4),
>label = 'CNOwma4')
>
>
>
>
>
>add.signal(strategy.st, name = "sigThreshold",
>arguments = list(column = "CNOwma4", threshold = 0.6,
>relationship = "gt", cross = TRUE),
>label = "longthreshold")
>
>
>add.signal(strategy.st, name = "sigThreshold",
>arguments = list(column = "CNOwma4", threshold = 0.6,
>relationship = "lt", cross = TRUE),
>label = "shortthreshold")
>
>
>
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "longthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "long", replace = FALSE,
>prefer = "Open"),
>type = "enter")
>
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "shortthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "long", replace = FALSE,
>prefer = "Open"),
>type = "exit")
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "shortthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "short", replace = FALSE,
>prefer = "Open"),
>type = "enter")
>
>add.rule(strategy.st, name = "ruleSignal",
>arguments = list(sigcol = "longthreshold", sigval = TRUE,
>orderqty = "all", ordertype = "market",
>orderside = "short", replace = FALSE,
>prefer = "Open"),
>type = "exit")
>
>
>
>out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
>
>
>When I run the traceback() of the error, this is what I get:
>> traceback()
>4: stop("attempt to set 'colnames' on an object with less than two
>dimensions")
>3: `colnames<-`(`*tmp*`, value = seq(ncol(tmp_val)))
>2: applyIndicators(strategy = strategy, mktdata = mktdata, parameters =
>parameters, 
>...)
>1: applyStrategy(strategy = strategy.st, portfolios = portfolio.st
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From |@bbrop|etro @end|ng |rom y@hoo@|t  Sat Jul 14 19:41:30 2018
From: |@bbrop|etro @end|ng |rom y@hoo@|t (Pietro Fabbro)
Date: Sat, 14 Jul 2018 17:41:30 +0000 (UTC)
Subject: [R] No transactions/positions to chart in Quantstrat
References: <1510027455.4077501.1531590090832.ref@mail.yahoo.com>
Message-ID: <1510027455.4077501.1531590090832@mail.yahoo.com>

Hello.
I get the error message that there are no transactions/positions to chart despite the signals and rules that I inserted.
Can someone please help?

rm(list = ls(.blotter), envir = .blotter)
initdate <- "2010-01-01"
from <- "2012-01-01" #start of backtest
to <- "2017-31-12" #end of backtest

Sys.setenv(TZ= "EST") #Set up environment for timestamps

currency("USD") #Set up environment for currency to be used

symbols <- c("RUT") #symbols used in our backtest
getSymbols("^RUT",src="yahoo", from="2012-01-01", to="2017-12-31", periodicity="daily")

stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use

n <- 30

wma <-  WMA(Cl(RUT), n=4, wts=c(1:4))
wmamaxt <-  rollmaxr(wma, n, fill = NA)
wmamint <- - rollmaxr(- wma, n, fill = NA)
CNOwma <- function (RUT) {(wma - wmamint) / (wmamaxt - wmamint)}

tradesize <-10000 #default trade size
initeq <- 100000 #default initial equity in our portfolio

strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account

#removes old portfolio and strategy from environment
rm.strat(portfolio.st)
rm.strat(strategy.st) 

#initialize portfolio, account, orders and strategy objects
initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")

initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)

initOrders(portfolio.st, initDate = initdate)
strategy(strategy.st, store=TRUE)

add.indicator(strategy = strategy.st,
name = 'CNOwma',
arguments = list(x = quote(Cl(mktdata)), n=4),
label = 'CNOwma4')





add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "gt", cross = TRUE),
label = "longthreshold")


add.signal(strategy.st, name = "sigThreshold",
arguments = list(column = "CNOwma4", threshold = 0.6,
relationship = "lt", cross = TRUE),
label = "shortthreshold")




add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"), osFUN = IKTrading::osMaxDollar,
tradeSize = tradesize, maxSize = tradesize, type = "enter")


add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "long", replace = FALSE,
prefer = "Open"),
type = "exit")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "shortthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),osFUN = IKTrading::osMaxDollar, 
tradeSize = tradesize, maxSize = tradesize, type = "enter")

add.rule(strategy.st, name = "ruleSignal",
arguments = list(sigcol = "longthreshold", sigval = TRUE,
orderqty = "all", ordertype = "market",
orderside = "short", replace = FALSE,
prefer = "Open"),
type = "exit")



out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
updatePortf(portfolio.st)
daterange <- time(getPortfolio(portfolio.st)$summary)[-1]

updateAcct(account.st, daterange)
updateEndEq(account.st)


for(symbol in symbols){

chart.Posn(Portfolio = portfolio.st, Symbol = symbol, 
TA= c("add_SMA(n=50, col='blue')", "add_SMA(n=200, col='red')"))
}



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jul 15 04:23:18 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 14 Jul 2018 19:23:18 -0700
Subject: [R] No transactions/positions to chart in Quantstrat
In-Reply-To: <1510027455.4077501.1531590090832@mail.yahoo.com>
References: <1510027455.4077501.1531590090832.ref@mail.yahoo.com>
 <1510027455.4077501.1531590090832@mail.yahoo.com>
Message-ID: <9A695495-B8F2-4CD9-A727-CAD985DD7AEA@comcast.net>


> On Jul 14, 2018, at 10:41 AM, Pietro Fabbro via R-help <r-help at r-project.org> wrote:
> 
> Hello.
> I get the error message that there are no transactions/positions to chart despite the signals and rules that I inserted.

This might or might not be on-topic for Rhelp. If there is a particular form for  a strategy" that the unnamed packages with these function in them that you have misread, tehre might be a purely R answer to this. However, I think you should consider posting at the Quantitative Finance forum at stackexchange.com.

-- 
David.


> Can someone please help?
> 
> rm(list = ls(.blotter), envir = .blotter)
> initdate <- "2010-01-01"
> from <- "2012-01-01" #start of backtest
> to <- "2017-31-12" #end of backtest
> 
> Sys.setenv(TZ= "EST") #Set up environment for timestamps
> 
> currency("USD") #Set up environment for currency to be used
> 
> symbols <- c("RUT") #symbols used in our backtest
> getSymbols("^RUT",src="yahoo", from="2012-01-01", to="2017-12-31", periodicity="daily")
> 
> stock(symbols, currency = "USD", multiplier = 1) #tells quanstrat what instruments present and what currency to use
> 
> n <- 30
> 
> wma <-  WMA(Cl(RUT), n=4, wts=c(1:4))
> wmamaxt <-  rollmaxr(wma, n, fill = NA)
> wmamint <- - rollmaxr(- wma, n, fill = NA)
> CNOwma <- function (RUT) {(wma - wmamint) / (wmamaxt - wmamint)}
> 
> tradesize <-10000 #default trade size
> initeq <- 100000 #default initial equity in our portfolio
> 
> strategy.st <- portfolio.st <- account.st <- "firststrat" #naming strategy, portfolio and account
> 
> #removes old portfolio and strategy from environment
> rm.strat(portfolio.st)
> rm.strat(strategy.st) 
> 
> #initialize portfolio, account, orders and strategy objects
> initPortf(portfolio.st, symbols = symbols, initDate = initdate, currency = "USD")
> 
> initAcct(account.st, portfolios = portfolio.st, initDate = initdate, currency = "USD", initEq = initeq)
> 
> initOrders(portfolio.st, initDate = initdate)
> strategy(strategy.st, store=TRUE)
> 
> add.indicator(strategy = strategy.st,
> name = 'CNOwma',
> arguments = list(x = quote(Cl(mktdata)), n=4),
> label = 'CNOwma4')
> 
> 
> 
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "gt", cross = TRUE),
> label = "longthreshold")
> 
> 
> add.signal(strategy.st, name = "sigThreshold",
> arguments = list(column = "CNOwma4", threshold = 0.6,
> relationship = "lt", cross = TRUE),
> label = "shortthreshold")
> 
> 
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"), osFUN = IKTrading::osMaxDollar,
> tradeSize = tradesize, maxSize = tradesize, type = "enter")
> 
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "long", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "shortthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),osFUN = IKTrading::osMaxDollar, 
> tradeSize = tradesize, maxSize = tradesize, type = "enter")
> 
> add.rule(strategy.st, name = "ruleSignal",
> arguments = list(sigcol = "longthreshold", sigval = TRUE,
> orderqty = "all", ordertype = "market",
> orderside = "short", replace = FALSE,
> prefer = "Open"),
> type = "exit")
> 
> 
> 
> out <- applyStrategy(strategy = strategy.st, portfolios = portfolio.st)
> updatePortf(portfolio.st)
> daterange <- time(getPortfolio(portfolio.st)$summary)[-1]
> 
> updateAcct(account.st, daterange)
> updateEndEq(account.st)
> 
> 
> for(symbol in symbols){
> 
> chart.Posn(Portfolio = portfolio.st, Symbol = symbol, 
> TA= c("add_SMA(n=50, col='blue')", "add_SMA(n=200, col='red')"))
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From ju||@n|@moon @end|ng |rom gm@||@com  Sun Jul 15 04:19:19 2018
From: ju||@n|@moon @end|ng |rom gm@||@com (Julianony M)
Date: Sat, 14 Jul 2018 21:19:19 -0500
Subject: [R] get "massdist" in R
Message-ID: <CAK6qzcks-cCjXQwstONph2=XXnaxwuAy9H21+GC+Z2bioO5hyA@mail.gmail.com>

I encounter a problem when I ran an R script that's been working for years:

> Rscript kernel_density_script

it complains: "massdist" not available for .C() for package "stats"

I thought an update of R could help, so I did:

> sudo yum update R ... it says: No packages marked for update

Could someone suggest how can I get the R "massdist" installed? (this is a
RHEL7 system)

Thanks in advance!

j

	[[alternative HTML version deleted]]



From t@n@@@ @end|ng |rom gm@||@com  Sun Jul 15 07:16:36 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 14 Jul 2018 22:16:36 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
Message-ID: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>

Dear all,

please would you advise on how I could make an even display of unevenly
spaced number on a graph in R. For example, considering the code below :

BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
400, 500)

a <- seq(0,100,0.1)
b <- seq(0,1000,0.1)

plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)

I would like to show on X axis (0, 0.1, 1 and 10) spaced in an equal/even
manner.

thanks !

bogdan

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul 15 07:17:55 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 22:17:55 -0700
Subject: [R] get "massdist" in R
In-Reply-To: <CAK6qzcks-cCjXQwstONph2=XXnaxwuAy9H21+GC+Z2bioO5hyA@mail.gmail.com>
References: <CAK6qzcks-cCjXQwstONph2=XXnaxwuAy9H21+GC+Z2bioO5hyA@mail.gmail.com>
Message-ID: <2DE99FC9-5344-4F42-BB1F-A571A4594B6E@dcn.davis.ca.us>

Roll back your version of R, or find another way to accomplish that calculation. This "abuse" of undocumented functions inside base R has been warned against for a long time [1], so the real puzzle is how you managed to get this far.

[1] http://lists.r-forge.r-project.org/pipermail/vegan-devel/2012-October/000279.html

On July 14, 2018 7:19:19 PM PDT, Julianony M <juliani.moon at gmail.com> wrote:
>I encounter a problem when I ran an R script that's been working for
>years:
>
>> Rscript kernel_density_script
>
>it complains: "massdist" not available for .C() for package "stats"
>
>I thought an update of R could help, so I did:
>
>> sudo yum update R ... it says: No packages marked for update
>
>Could someone suggest how can I get the R "massdist" installed? (this
>is a
>RHEL7 system)
>
>Thanks in advance!
>
>j
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul 15 07:25:41 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 22:25:41 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
Message-ID: <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>

Isn't this what I showed you how to do in [1]?

[1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html

On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear all,
>
>please would you advise on how I could make an even display of unevenly
>spaced number on a graph in R. For example, considering the code below
>:
>
>BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>300,
>400, 500)
>
>a <- seq(0,100,0.1)
>b <- seq(0,1000,0.1)
>
>plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
>plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
>
>I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
>equal/even
>manner.
>
>thanks !
>
>bogdan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From t@n@@@ @end|ng |rom gm@||@com  Sun Jul 15 07:34:32 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 14 Jul 2018 22:34:32 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
 <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
Message-ID: <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>

Dear Jeff,

thank you for your prompt reply and kind help.

During our previous conversation, we worked on a different topic, namely
subsetting the dataframe before using ecdf() function in ggplot2.

Now, i would like to know, how I could evenly space on the x axis the
values (0, 0.01, 0.1, 1, 10). Thanks again, and happy weekend ;) !

-- bogdan


On Sat, Jul 14, 2018 at 10:25 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Isn't this what I showed you how to do in [1]?
>
> [1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html
>
> On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >Dear all,
> >
> >please would you advise on how I could make an even display of unevenly
> >spaced number on a graph in R. For example, considering the code below
> >:
> >
> >BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
> >300,
> >400, 500)
> >
> >a <- seq(0,100,0.1)
> >b <- seq(0,1000,0.1)
> >
> >plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
> >plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
> >
> >I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
> >equal/even
> >manner.
> >
> >thanks !
> >
> >bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul 15 08:07:21 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 14 Jul 2018 23:07:21 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
 <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
 <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>
Message-ID: <F244A55A-F233-4E8D-B0BB-6E13DE0C47A4@dcn.davis.ca.us>

But did you run the code? Apparently not.

On July 14, 2018 10:34:32 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear Jeff,
>
>thank you for your prompt reply and kind help.
>
>During our previous conversation, we worked on a different topic,
>namely
>subsetting the dataframe before using ecdf() function in ggplot2.
>
>Now, i would like to know, how I could evenly space on the x axis the
>values (0, 0.01, 0.1, 1, 10). Thanks again, and happy weekend ;) !
>
>-- bogdan
>
>
>On Sat, Jul 14, 2018 at 10:25 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Isn't this what I showed you how to do in [1]?
>>
>> [1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html
>>
>> On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
>wrote:
>> >Dear all,
>> >
>> >please would you advise on how I could make an even display of
>unevenly
>> >spaced number on a graph in R. For example, considering the code
>below
>> >:
>> >
>> >BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
>> >300,
>> >400, 500)
>> >
>> >a <- seq(0,100,0.1)
>> >b <- seq(0,1000,0.1)
>> >
>> >plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
>> >plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
>> >
>> >I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
>> >equal/even
>> >manner.
>> >
>> >thanks !
>> >
>> >bogdan
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.



From drj|m|emon @end|ng |rom gm@||@com  Sun Jul 15 09:43:27 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 15 Jul 2018 17:43:27 +1000
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
Message-ID: <CA+8X3fU-zhLotEq4dNiKg+eBtFrf1DoMDrZNPAAc=G1MzSpmaw@mail.gmail.com>

Hi Bogdan,
There seem to be three problems. One is that if you want a logarithmic
x axis you shouldn't have a zero (or a negative number) in your data.
The second is that you have to ask for a logarithmic axis. The third
is that you have limited your x axis to less than the range of the
data in "b"::

plot(ecdf(b),xlim=c(0.1,1000),col="red",main=NA,log="x")
plot(ecdf(a),col="green",add=TRUE)

Jim

On Sun, Jul 15, 2018 at 3:16 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear all,
>
> please would you advise on how I could make an even display of unevenly
> spaced number on a graph in R. For example, considering the code below :
>
> BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300,
> 400, 500)
>
> a <- seq(0,100,0.1)
> b <- seq(0,1000,0.1)
>
> plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
> plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
>
> I would like to show on X axis (0, 0.1, 1 and 10) spaced in an equal/even
> manner.
>
> thanks !
>
> bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From t@n@@@ @end|ng |rom gm@||@com  Sun Jul 15 14:22:22 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sun, 15 Jul 2018 05:22:22 -0700
Subject: [R] even display of unevenly spaced numbers on x/y coordinates
In-Reply-To: <F244A55A-F233-4E8D-B0BB-6E13DE0C47A4@dcn.davis.ca.us>
References: <CA+JEM01DqWAgo8+ns57cc6RXR9dkrE1w_nqMqO_CH8XNRZCcSA@mail.gmail.com>
 <8FBD13C4-6BF5-483C-B885-04B836B6BD72@dcn.davis.ca.us>
 <CA+JEM02PjCgxW1o7P4Bad+ER3UaJqtQKY1ca8h=g7XnT6VqVRQ@mail.gmail.com>
 <F244A55A-F233-4E8D-B0BB-6E13DE0C47A4@dcn.davis.ca.us>
Message-ID: <CA+JEM00dmWjVWPVhR6T6Pfh5EC3T=Xm0d0hKWnvaNG+F8YrEXg@mail.gmail.com>

Hi Jeff,

thank you again for your help, and for your suggestion to subset the data :

DF500 <- subset( DF, LENGTH < 500 )

yes, I did run the code, and I believe that it is easier to present/defend
the results, after using "subset".

-- bogdan

On Sat, Jul 14, 2018 at 11:07 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> But did you run the code? Apparently not.
>
> On July 14, 2018 10:34:32 PM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >Dear Jeff,
> >
> >thank you for your prompt reply and kind help.
> >
> >During our previous conversation, we worked on a different topic,
> >namely
> >subsetting the dataframe before using ecdf() function in ggplot2.
> >
> >Now, i would like to know, how I could evenly space on the x axis the
> >values (0, 0.01, 0.1, 1, 10). Thanks again, and happy weekend ;) !
> >
> >-- bogdan
> >
> >
> >On Sat, Jul 14, 2018 at 10:25 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Isn't this what I showed you how to do in [1]?
> >>
> >> [1] https://stat.ethz.ch/pipermail/r-help/2018-July/455215.html
> >>
> >> On July 14, 2018 10:16:36 PM PDT, Bogdan Tanasa <tanasa at gmail.com>
> >wrote:
> >> >Dear all,
> >> >
> >> >please would you advise on how I could make an even display of
> >unevenly
> >> >spaced number on a graph in R. For example, considering the code
> >below
> >> >:
> >> >
> >> >BREAKS = c(0, 0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200,
> >> >300,
> >> >400, 500)
> >> >
> >> >a <- seq(0,100,0.1)
> >> >b <- seq(0,1000,0.1)
> >> >
> >> >plot(ecdf(a), col="red", xlim=c(0,100), main=NA, breaks=BREAKS)
> >> >plot(ecdf(b), col="green", xlim=c(0,100), add=T, breaks=BREAKS)
> >> >
> >> >I would like to show on X axis (0, 0.1, 1 and 10) spaced in an
> >> >equal/even
> >> >manner.
> >> >
> >> >thanks !
> >> >
> >> >bogdan
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From ne|@on@|bb@78 @end|ng |rom y@hoo@com  Sun Jul 15 14:25:50 2018
From: ne|@on@|bb@78 @end|ng |rom y@hoo@com (Nelson Sibanda)
Date: Sun, 15 Jul 2018 12:25:50 +0000 (UTC)
Subject: [R] (no subject)
References: <225966679.4291596.1531657550430.ref@mail.yahoo.com>
Message-ID: <225966679.4291596.1531657550430@mail.yahoo.com>

UNSCRIBE
	[[alternative HTML version deleted]]



From m@notembe @end|ng |rom gm@||@com  Sun Jul 15 15:25:43 2018
From: m@notembe @end|ng |rom gm@||@com (Atanasio Alberto Tembe Tembe)
Date: Sun, 15 Jul 2018 22:25:43 +0900
Subject: [R] (no subject)
Message-ID: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>

Hello!

Is there anyone who can help me to this the error bellow? Ijust
started using R recently. Thank you


while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol in "while
sum">     >     k=K+1>     >     for(i in 1:nrow(c1)){+         +
   for(j in 1:ncol(c1)){+             +             if(Sb!=0){+
         +                 T2=D*T/Sa+                 +
}else {+                 +                 T2=0       +
 +             }+             +             Sc=sum(t(T))+
+             if(Sc!=0){+                 +
T3=Pi*T2/Sc+                 +             }else {+                 +
               T3=0+                 +             }+
Sb=sum(T)+             +         }+     }>     >     K[1] 0

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul 15 18:02:55 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 15 Jul 2018 09:02:55 -0700
Subject: [R] (no subject)
In-Reply-To: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
References: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
Message-ID: <0BC4561F-853E-46DD-B6A6-483B49FBCFD5@dcn.davis.ca.us>

I think you are missing a parenthesis around your condition [1][2].

For future reference:
a) You should post the code you ran as well as the error message... it is unusual for the error message alone to be enough to figure out the problem. In fact, try to make a "reproducible example" [3][4][5]... you will increase your chances of getting an answer.
b) Your message was garbled... in some cases this can completely obscure your question. You can prevent that from happening by setting your email program to create a plain text email whenever you post here.
c) Remember to put a subject line on your email.

[1] https://stat.ethz.ch/R-manual/R-devel/library/base/html/Control.html
[2] https://www-r--bloggers-com.cdn.ampproject.org/v/s/www.r-bloggers.com/control-structures-loops-in-r/
[3] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[4] http://adv-r.had.co.nz/Reproducibility.html

[5] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On July 15, 2018 6:25:43 AM PDT, Atanasio Alberto Tembe Tembe <manotembe at gmail.com> wrote:
>Hello!
>
>Is there anyone who can help me to this the error bellow? Ijust
>started using R recently. Thank you
>
>
>while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol in "while
>sum">     >     k=K+1>     >     for(i in 1:nrow(c1)){+         +
>   for(j in 1:ncol(c1)){+             +             if(Sb!=0){+
>         +                 T2=D*T/Sa+                 +
>}else {+                 +                 T2=0       +
> +             }+             +             Sc=sum(t(T))+
>+             if(Sc!=0){+                 +
>T3=Pi*T2/Sc+                 +             }else {+                 +
>               T3=0+                 +             }+
>Sb=sum(T)+             +         }+     }>     >     K[1] 0
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From btyner @end|ng |rom gm@||@com  Mon Jul 16 04:25:27 2018
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Sun, 15 Jul 2018 22:25:27 -0400
Subject: [R] undo compile? (or: remove bytecode from closure)
Message-ID: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>

Hi

Given a closure which has been compiled, what's the recommended way to 
recover the original? For example,

 ??? > f <- function(x) x+1
 ??? > fc <- cmpfun(f)
 ??? > rm(f)
 ??? > fc
 ??? function(x) x+1
 ??? <bytecode: 0x41d9228>

what's the best way to recover f from fc ?

Regards

Ben



From nt|redo @end|ng |rom gm@||@com  Mon Jul 16 08:42:10 2018
From: nt|redo @end|ng |rom gm@||@com (Frederic Ntirenganya)
Date: Mon, 16 Jul 2018 09:42:10 +0300
Subject: [R] Help in debugging a script
Message-ID: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>

Dear Friends,

I would like to ask for help.
I am plotting monthly data as seasonal by adding particular months but I am
getting an unexpected graph. What I want is why and what can be another
alternative?

Here is the data and R script

busoro <- read.csv("G:/Fredo/PAPER/Malaria climate paper/data/NYANZA
DATA/busoro2.csv", header=T)

# x axis
y = 2012:2017
#plot
plot(y,busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
busoro[,"Dec"],type="b",
     ylab="Malaria Cases",xlab="Year")

grid(10,10,lwd=2)

dput((head(busoro)))structure(list(X = 2012:2017, Jan = c(73L, 754L,
1016L, 2651L,
1201L, 3405L), Feb = c(129L, 959L, 1276L, 3917L, 1262L, 3715L
), Mar = c(238L, 770L, 1670L, 3975L, 1379L, 3571L), Apr = c(705L,
875L, 1117L, 3549L, 1021L, 2789L), May = c(915L, 1034L, 1379L,
3092L, 2091L, 3487L), Jun = c(985L, 741L, 1612L, 4351L, 1599L,
1662L), Jul = c(402L, 115L, 901L, 3394L, 623L, 817L), Aug = c(337L,
218L, 966L, 1002L, 732L, 755L), Sep = c(353L, 580L, 2284L, 2427L,
2033L, 1134L), Oct = c(1016L, 1243L, 2788L, 3571L, 2940L, 1763L
), Nov = c(682L, 1336L, 2229L, 2730L, 2866L, 1469L), Dec = c(641L,
1049L, 1701L, 1380L, 2153L, 1321L)), .Names = c("X", "Jan", "Feb",
"Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov",
"Dec"), row.names = c(NA, 6L), class = "data.frame")


Thanks in advance.


Frederic Ntirenganya
Nyanza District,
Data Mnager.
Mobile:(+250)788757619
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]



From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jul 16 08:49:17 2018
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 16 Jul 2018 08:49:17 +0200
Subject: [R] (no subject)
In-Reply-To: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
References: <894F758509FE4E4890B9FBBCA94457F1D3C20E@MBX04.ad.oak.ox.ac.uk>
Message-ID: <CAJuCY5zSMp3xBhKX2rgHPa2NyHruuMMESwiWDDpCFDrXrGYeWg@mail.gmail.com>

Dear Laura,

I came across the anipaths package
(https://cran.r-project.org/web/packages/anipaths/vignettes/anipaths.html)
It might be useful for you.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-07-09 14:13 GMT+02:00 Laura Steel <laura.steel at magd.ox.ac.uk>:
> I am a beginner to R and I need to map some Atlantic puffin migration routes
> onto a map of the Northern Hemisphere. I have a latitude and longitude point
> per bird, per day. I would like to be able to plot the routes of all my
> birds on one map and ideally so that I can see at which date they are at
> each location.
>
> This is a shortened version of my data for one bird only.
>
> Bird             Date              Latitude     Longitude
> eb80976 16/07/2012      50.99   -5.85
> eb80976 17/07/2012      52.09   -4.58
> eb80976 18/07/2012      49.72   -5.56
> eb80976 19/07/2012      51.59   -3.17
> eb80976 20/07/2012      52.45   -2.03
> eb80976 21/07/2012      56.015  -10.51
>
> Any help would be much appreciated. I am not totally sure where to start!
> Many thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jul 16 11:22:02 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Jul 2018 10:22:02 +0100
Subject: [R] (no subject)
In-Reply-To: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
References: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
Message-ID: <aa3fbed7-6be7-3076-89f6-40bbee33046f@sapo.pt>

Hello,

Please repost in plain text, NO HTML formating.

Also, you are missing an open parenthesis right after while:

while( sum(abs(Sb-D-Sc-t(Pi))>1E-5)){


Hope this helps,

Rui Barradas

?s 14:25 de 15-07-2018, Atanasio Alberto Tembe Tembe escreveu:
> Hello!
> 
> Is there anyone who can help me to this the error bellow? Ijust
> started using R recently. Thank you
> 
> 
> while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol in "while
> sum">     >     k=K+1>     >     for(i in 1:nrow(c1)){+         +
>     for(j in 1:ncol(c1)){+             +             if(Sb!=0){+
>           +                 T2=D*T/Sa+                 +
> }else {+                 +                 T2=0       +
>   +             }+             +             Sc=sum(t(T))+
> +             if(Sc!=0){+                 +
> T3=Pi*T2/Sc+                 +             }else {+                 +
>                 T3=0+                 +             }+
> Sb=sum(T)+             +         }+     }>     >     K[1] 0
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jul 16 11:31:13 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 16 Jul 2018 10:31:13 +0100
Subject: [R] undo compile? (or: remove bytecode from closure)
In-Reply-To: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
References: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
Message-ID: <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>

Hello,

Maybe the following is not the recommended way but it works
(and I believe makes sense).


f <- function(){}
formals(f) <- formals(fc)
body(f) <- body(fc)

f
#function (x)
#{
#  x <- x + 1
#  pi * x
#}

f(1)
#[1] 6.283185


Hope this helps,

Rui Barradas

?s 03:25 de 16-07-2018, Benjamin Tyner escreveu:
> Hi
> 
> Given a closure which has been compiled, what's the recommended way to 
> recover the original? For example,
> 
>  ??? > f <- function(x) x+1
>  ??? > fc <- cmpfun(f)
>  ??? > rm(f)
>  ??? > fc
>  ??? function(x) x+1
>  ??? <bytecode: 0x41d9228>
> 
> what's the best way to recover f from fc ?
> 
> Regards
> 
> Ben
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From drj|m|emon @end|ng |rom gm@||@com  Mon Jul 16 12:00:33 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 16 Jul 2018 20:00:33 +1000
Subject: [R] Help in debugging a script
In-Reply-To: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>
References: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>
Message-ID: <CA+8X3fVGy2GB=fyxKjnJvXEtnC2biJcxbWxZgoSXThNb1ahKUQ@mail.gmail.com>

Hi Frederic,
You are asking for the sum of cases in the months September to
December for the years 2012 to 2017. I get a plot that shows that
from:

plot(busoro[,"X"],busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
busoro[,"Dec"],type="b",ylab="Malaria Cases",xlab="Year")

What sort of plot were you expecting?

Jim

On Mon, Jul 16, 2018 at 4:42 PM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> Dear Friends,
>
> I would like to ask for help.
> I am plotting monthly data as seasonal by adding particular months but I am
> getting an unexpected graph. What I want is why and what can be another
> alternative?
>
> Here is the data and R script
>
> busoro <- read.csv("G:/Fredo/PAPER/Malaria climate paper/data/NYANZA
> DATA/busoro2.csv", header=T)
>
> # x axis
> y = 2012:2017
> #plot
> plot(y,busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
> busoro[,"Dec"],type="b",
>      ylab="Malaria Cases",xlab="Year")
>
> grid(10,10,lwd=2)
>
> dput((head(busoro)))structure(list(X = 2012:2017, Jan = c(73L, 754L,
> 1016L, 2651L,
> 1201L, 3405L), Feb = c(129L, 959L, 1276L, 3917L, 1262L, 3715L
> ), Mar = c(238L, 770L, 1670L, 3975L, 1379L, 3571L), Apr = c(705L,
> 875L, 1117L, 3549L, 1021L, 2789L), May = c(915L, 1034L, 1379L,
> 3092L, 2091L, 3487L), Jun = c(985L, 741L, 1612L, 4351L, 1599L,
> 1662L), Jul = c(402L, 115L, 901L, 3394L, 623L, 817L), Aug = c(337L,
> 218L, 966L, 1002L, 732L, 755L), Sep = c(353L, 580L, 2284L, 2427L,
> 2033L, 1134L), Oct = c(1016L, 1243L, 2788L, 3571L, 2940L, 1763L
> ), Nov = c(682L, 1336L, 2229L, 2730L, 2866L, 1469L), Dec = c(641L,
> 1049L, 1701L, 1380L, 2153L, 1321L)), .Names = c("X", "Jan", "Feb",
> "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov",
> "Dec"), row.names = c(NA, 6L), class = "data.frame")
>
>
> Thanks in advance.
>
>
> Frederic Ntirenganya
> Nyanza District,
> Data Mnager.
> Mobile:(+250)788757619
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nt|redo @end|ng |rom gm@||@com  Mon Jul 16 12:07:33 2018
From: nt|redo @end|ng |rom gm@||@com (Frederic Ntirenganya)
Date: Mon, 16 Jul 2018 13:07:33 +0300
Subject: [R] Help in debugging a script
In-Reply-To: <CA+8X3fVGy2GB=fyxKjnJvXEtnC2biJcxbWxZgoSXThNb1ahKUQ@mail.gmail.com>
References: <CAGh51gRJig66iCd3+==PQdbMXj4ye9oEa_hk_3DgS=Wj1-itBQ@mail.gmail.com>
 <CA+8X3fVGy2GB=fyxKjnJvXEtnC2biJcxbWxZgoSXThNb1ahKUQ@mail.gmail.com>
Message-ID: <CAGh51gS-M5g=x5=XhFxizj2eg_mwk722dwqzroKQhXT5kbP6UQ@mail.gmail.com>

Dear Jim,

I am asking the sum of malaria cases from Sep to Dec. I am also getting the
plot but which has false values.

After going through them, I found that the script is giving the right
results.

Thanks alot.

Frederic Ntirenganya
Nyanza District,
Data Mnager.
Mobile:(+250)788757619
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Mon, Jul 16, 2018 at 1:00 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Frederic,
> You are asking for the sum of cases in the months September to
> December for the years 2012 to 2017. I get a plot that shows that
> from:
>
> plot(busoro[,"X"],busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
> busoro[,"Dec"],type="b",ylab="Malaria Cases",xlab="Year")
>
> What sort of plot were you expecting?
>
> Jim
>
> On Mon, Jul 16, 2018 at 4:42 PM, Frederic Ntirenganya <ntfredo at gmail.com>
> wrote:
> > Dear Friends,
> >
> > I would like to ask for help.
> > I am plotting monthly data as seasonal by adding particular months but I
> am
> > getting an unexpected graph. What I want is why and what can be another
> > alternative?
> >
> > Here is the data and R script
> >
> > busoro <- read.csv("G:/Fredo/PAPER/Malaria climate paper/data/NYANZA
> > DATA/busoro2.csv", header=T)
> >
> > # x axis
> > y = 2012:2017
> > #plot
> > plot(y,busoro[,"Sep"] + busoro[,"Oct"] + busoro [,"Nov"] +
> > busoro[,"Dec"],type="b",
> >      ylab="Malaria Cases",xlab="Year")
> >
> > grid(10,10,lwd=2)
> >
> > dput((head(busoro)))structure(list(X = 2012:2017, Jan = c(73L, 754L,
> > 1016L, 2651L,
> > 1201L, 3405L), Feb = c(129L, 959L, 1276L, 3917L, 1262L, 3715L
> > ), Mar = c(238L, 770L, 1670L, 3975L, 1379L, 3571L), Apr = c(705L,
> > 875L, 1117L, 3549L, 1021L, 2789L), May = c(915L, 1034L, 1379L,
> > 3092L, 2091L, 3487L), Jun = c(985L, 741L, 1612L, 4351L, 1599L,
> > 1662L), Jul = c(402L, 115L, 901L, 3394L, 623L, 817L), Aug = c(337L,
> > 218L, 966L, 1002L, 732L, 755L), Sep = c(353L, 580L, 2284L, 2427L,
> > 2033L, 1134L), Oct = c(1016L, 1243L, 2788L, 3571L, 2940L, 1763L
> > ), Nov = c(682L, 1336L, 2229L, 2730L, 2866L, 1469L), Dec = c(641L,
> > 1049L, 1701L, 1380L, 2153L, 1321L)), .Names = c("X", "Jan", "Feb",
> > "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov",
> > "Dec"), row.names = c(NA, 6L), class = "data.frame")
> >
> >
> > Thanks in advance.
> >
> >
> > Frederic Ntirenganya
> > Nyanza District,
> > Data Mnager.
> > Mobile:(+250)788757619
> > Email: fredo at aims.ac.za
> > https://sites.google.com/a/aims.ac.za/fredo/
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Mon Jul 16 12:57:45 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Mon, 16 Jul 2018 10:57:45 +0000
Subject: [R] R and Logistic Regression Classifier for ML
Message-ID: <CY1PR0201MB1834CFBC9D9AE98237261D04EA5D0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning.

I am looking for an R package and possibly at tutorial using Logistic Regression as the classifier in a ML algorithm.
I located this URL for use with R pkg "e1071" and the SVM classifier which seems splendid, however, I cannot locate a comparable reference similarly for Logistic Regression.
https://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Classification/SVM

Admittedly I am a novice with ML and trying to teach myself using R (for which I am still quite a novice as well, lol)

Thank you for any direction.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jul 16 12:58:31 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 16 Jul 2018 06:58:31 -0400
Subject: [R] undo compile? (or: remove bytecode from closure)
In-Reply-To: <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>
References: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
 <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>
Message-ID: <ddd3aa5f-81f6-629e-56aa-d4bae35a0311@gmail.com>

On 16/07/2018 5:31 AM, Rui Barradas wrote:
> Hello,
> 
> Maybe the following is not the recommended way but it works
> (and I believe makes sense).
> 
> 
> f <- function(){}
> formals(f) <- formals(fc)
> body(f) <- body(fc)

That's not quite right:  it might lose the environment of fc, if it 
isn't the environment where this took place.  But a simpler solution is just

f <- fc
body(f) <- body(f)

because any assignment to the body of a function causes the bytecode to 
be dropped.

Both of our approaches will also cause the source references to be 
dropped.  If you want to save those, you need more steps:

f <- fc
body(f) <- body(f)
attr(f, "srcref") <- getSrcref(fc)

Duncan Murdoch

> 
> f
> #function (x)
> #{
> #  x <- x + 1
> #  pi * x
> #}
> 
> f(1)
> #[1] 6.283185
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 03:25 de 16-07-2018, Benjamin Tyner escreveu:
>> Hi
>>
>> Given a closure which has been compiled, what's the recommended way to
>> recover the original? For example,
>>
>>   ??? > f <- function(x) x+1
>>   ??? > fc <- cmpfun(f)
>>   ??? > rm(f)
>>   ??? > fc
>>   ??? function(x) x+1
>>   ??? <bytecode: 0x41d9228>
>>
>> what's the best way to recover f from fc ?
>>
>> Regards
>>
>> Ben
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From ||ewm|||@ @end|ng |rom gm@||@com  Mon Jul 16 14:23:57 2018
From: ||ewm|||@ @end|ng |rom gm@||@com (Llew Mills)
Date: Mon, 16 Jul 2018 22:23:57 +1000
Subject: [R] Hierarchical Version of Bayesian Change Detection Model in JAGS
Message-ID: <CA+9mOqoxY8bU1mSpS9nKJ5cbD3_uyrJh5GmGxGdWQ0QwbB2u8Q@mail.gmail.com>

I am trying to create a hierarchical changepoint detection model in JAGS,
estimating group difference in changepoint based on individual changepoints
in scores for an outcome variable (fictional in this case). I can run a
non-hierarchical version of this same analysis, based on a single set of
scores, but am having trouble with the hierarchical structure in JAGS.

Here is code for creating the toy data. score is a fictional outcome
variable measured on each of 84 days (tracked by variable days) for forty
individuals ( variable id) divided equally among two groups (tracked by
variable group). Data is created so the individuals in group A tend to have
a later breakpoint (around day 34) than those in group B (around day 15).

Here is code for toy data.

    breakpointG1 <- NA
    for (i in 1:20) { breakpointG1[i] <- round(rnorm(1, 34, 5)) }
    breakpointG2 <- NA
    for (i in 1:20) { breakpointG2[i] <- round(rnorm(1, 15, 5)) }
    bps <- c(breakpointG1, breakpointG2)
    group <- rep(c("A", "B"), each = 20)
    df <- data.frame(id = NA, days = NA, group = NA, score = NA)
    for ( i in 1:length(bps) ) {
    pre <- rnorm(bps[i], 40, 3) #
    post <- rnorm(84-bps[i], 25, 3)
    dfi <- data.frame(id = i, days = 1:84, group = rep(group[i], 84), score
= c(pre, post))
    df <- rbind(df, dfi)
    }
    df <- df[-1,]

Plot all participants in one graph, but with a separate loess-smoothed line
for each group.

    ggplot(df, aes(x = days, y = score)) +
           geom_point(aes(colour = factor(id))) +
           geom_smooth(aes(group = group, linetype = group), colour =
"black", span = 0.5, se = F) + guides(colour = F)

The difference in group change thresholds is clearly visible on this graph.
Now for the Bayesian analysis verifying what we can see with our eyes.
First step is to create the data list from the dataframe.

    y <- df$score
    sdY <- sd(y)
    sid <- df$id
    days <- df$days
    nTotal <- nrow(df)
    nDays <- max(df$days)
    nID <- length(unique(sid))
    nG <- length(unique(g))

We also need a vector where each element is the group number of the subject
in question (i.e. there will be 40 elements in this vector)

    groupOfSubject = NULL
    for ( sIdx in 1:nID ) {
      groupOfSubject = c( groupOfSubject , unique(g[sid==sIdx]) )
    }

    dataList = list(y = y,
                    sdY = sdY,
                    g = g,
                    days = days,
                    sid = sid,
                    nTotal = nTotal,
                    nDays = nDays,
                    nID = nID,
                    nG = nG,
                    groupOfSubject = groupOfSubject)


Now the model string for jags. The main things I am interested in
estimating are the group changepoints `muChng[]` and the `muB[]`s for pre-
and post-breakpoint `score`. I have used nested indexing but I must confess
I am out of my depth here.

    cat("
        model{

        # likelihood
        for (oIdx in 1:nTotal) {
        y[oIdx] ~ dnorm(mu[sid[oIdx]], 1/sigma^2)
        mu[sid[oIdx]] <- b1[sid[oIdx]] + step(days[oIdx] -
chng[sid[oIdx]])*b2[sid[oIdx]]
        }

        # priors
            # on subject-level id for b
            for (sIdx in 1:nID) {
                 b1[sIdx] ~ dnorm( muB1[groupOfSubject[sIdx]], 1/10^2 )
                 b2[sIdx] ~ dnorm( muB2[groupOfSubject[sIdx]], 1/10^2 )
                 chng[sIdx] ~ dnorm( muChng[groupOfSubject[sIdx]], 1/10^2 )
                 }

                # prior on group
                for (gIdx in 1:nG) {
                     muB1[gIdx] ~ dnorm(0, 1e-6)
                     muB2[gIdx] ~ dnorm(0, 1e-6)
                     muChng[gIdx] ~ dunif(1,nDays)
                     }

        # prior on Sigma
        sigma ~ dunif(1/sdY*10,sdY*10)

        }", file = "temp.jag")

Next adapt the mcmc chains using `rjags::jags.model()`.

    library(rjags)
    jagsModel <- jags.model(file = "temp.jag",
                            data = dataList,
                            n.chains = 3,
                            n.adapt = 1000)

But the model doesn't run, returning the message

    Error in jags.model(file = "temp.jag", data = dataList, n.chains = 3,
:
      RUNTIME ERROR:
    Compilation error on line 7.
    Attempt to redefine node mu[1]

I am not as familiar with breakpoint models as with the general linear
model so am not sure where I am going wrong. Something to do with the
nested indexing in the definition of `mu[]` in the likelihood function I
think, but I can't see where, and none of the alternatives I have tried
seem to work. I am stuck. Will take any suggestions, from small to a
complete overhaul or a different method. Any help much appreciated.

	[[alternative HTML version deleted]]



From b@m|th030465 @end|ng |rom gm@||@com  Mon Jul 16 19:46:20 2018
From: b@m|th030465 @end|ng |rom gm@||@com (Brian Smith)
Date: Mon, 16 Jul 2018 13:46:20 -0400
Subject: [R] grep
Message-ID: <CAEQKoCG0zB6LnS6SE+Gc2a8igBb3wwCSc5Km7Gefc6YMpUTrFg@mail.gmail.com>

Hi,

I was trying to find a pattern ("ABHD14A") in a character string ('xgen' in
example below) using grepl. Note that the individual members may be
separated by a semi-colon.

The correct answer should return:

"ABHD-ACY1 ; ABHD14A" "ABHD14A ; YYY"

I have tried three approaches, but still seem a bit off. Attempt 2 below
gets closest, but it also returns a hit where my pattern is a substring.
Here is my code:

===========


  xgen <- c("XYZ","ABHD-ACY1 ; ABHD14A","ABHD14AXX","ABHD14A ; YYY")
  ga <- "ABHD14A"

  # 1.
  kx <- grepl(paste0("^",ga,"$"),xgen)
  xgen[kx]

  # 2.
  ky <- grepl(ga,xgen)
  xgen[ky]


==============

What do I need to add/change in #2 above?

many thanks!

	[[alternative HTML version deleted]]



From |@t@z@hn @end|ng |rom gm@||@com  Mon Jul 16 19:57:34 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Mon, 16 Jul 2018 13:57:34 -0400
Subject: [R] grep
In-Reply-To: <CAEQKoCG0zB6LnS6SE+Gc2a8igBb3wwCSc5Km7Gefc6YMpUTrFg@mail.gmail.com>
References: <CAEQKoCG0zB6LnS6SE+Gc2a8igBb3wwCSc5Km7Gefc6YMpUTrFg@mail.gmail.com>
Message-ID: <CA+vqiLEROQT0c2B3rfZqGH-ZYMaT8NV5odb=k0bwhD25FgVfCw@mail.gmail.com>

grep("(^| )ABHD14A( ;|$)",xgen, value = TRUE)

maybe.

On Mon, Jul 16, 2018 at 1:46 PM, Brian Smith <bsmith030465 at gmail.com> wrote:
> Hi,
>
> I was trying to find a pattern ("ABHD14A") in a character string ('xgen' in
> example below) using grepl. Note that the individual members may be
> separated by a semi-colon.
>
> The correct answer should return:
>
> "ABHD-ACY1 ; ABHD14A" "ABHD14A ; YYY"
>
> I have tried three approaches, but still seem a bit off. Attempt 2 below
> gets closest, but it also returns a hit where my pattern is a substring.
> Here is my code:
>
> ===========
>
>
>   xgen <- c("XYZ","ABHD-ACY1 ; ABHD14A","ABHD14AXX","ABHD14A ; YYY")
>   ga <- "ABHD14A"
>
>   # 1.
>   kx <- grepl(paste0("^",ga,"$"),xgen)
>   xgen[kx]
>
>   # 2.
>   ky <- grepl(ga,xgen)
>   xgen[ky]
>
>
> ==============
>
> What do I need to add/change in #2 above?
>
> many thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From chr|@t|@n @end|ng |rom echo||m@nn@ch  Mon Jul 16 17:13:31 2018
From: chr|@t|@n @end|ng |rom echo||m@nn@ch (Christian)
Date: Mon, 16 Jul 2018 17:13:31 +0200
Subject: [R] Where does ' Setting LC_CTYPE failed, using "C" ' come from?
Message-ID: <17fa001d-2891-2d8e-2dfc-9c3c387ee7b0@echoffmann.ch>

Hi,

I am fighting to get rid of the messages like:

During startup - Warning messages:
Setting LC_CTYPE failed, using "C"
Setting LC_COLLATE failed, using "C"

This is annoying, because when building a package using R CMD, This 
message keeps cropping up.

Here my R:
Sys.getlocale()
[1] "C"

Sys.getenv()
Apple_PubSub_Socket_Render
                         /private/tmp/com.apple.launchd.QGvw3T6OWU/Render
COLUMNS                 86
COMMAND_MODE            unix2003
DISPLAY                 :0
DYLD_FALLBACK_LIBRARY_PATH
 
/Library/Frameworks/R.framework/Resources/lib:/Library/Java/JavaVirtualMachines/jdk-9.jdk/Contents/Home/lib/server
EDITOR                  vi
HOME                    /Users/hoffmannc
INSIDE_EMACS            25.1.1,comint
LANG                    en_CH.UTF-8
LANGUAGE                en
LN_S                    ln -s
LOGNAME                 hoffmannc
MAKE                    make
PAGER                   cat
PATH 
/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/opt/X11/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/texbin:/Library/TeX/texbin:/usr/local/texlive/2016/bin
PWD                     /Users/hoffmannc/Rtest
R_ARCH
R_BROWSER               /usr/bin/open
R_BZIPCMD               /usr/bin/bzip2
R_DOC_DIR               /Library/Frameworks/R.framework/Resources/doc
R_GZIPCMD               /usr/bin/gzip
R_HOME                  /Library/Frameworks/R.framework/Resources
R_INCLUDE_DIR           /Library/Frameworks/R.framework/Resources/include
R_LIBS_SITE
R_LIBS_USER             ~/Library/R/3.5/library
R_PAPERSIZE             a4
R_PDFVIEWER             /usr/bin/open
R_PLATFORM              x86_64-apple-darwin15.6.0
R_PRINTCMD              lpr
R_QPDF                  /Library/Frameworks/R.framework/Resources/bin/qpdf
R_RD4PDF                times,inconsolata,hyper
R_SESSION_TMPDIR 
/var/folders/rm/pd12qdtn55qc3vc0vg5v0_y40000gn/T//RtmpyBHBm8
R_SHARE_DIR             /Library/Frameworks/R.framework/Resources/share
R_SYSTEM_ABI            osx,gcc,gxx,gfortran,?
R_TEXI2DVICMD           /usr/local/bin/texi2dvi
R_UNZIPCMD              /usr/bin/unzip
R_ZIPCMD                /usr/bin/zip
SECURITYSESSIONID       186a9
SED                     /usr/bin/sed
SHELL                   /bin/bash
SHLVL                   1
SSH_AUTH_SOCK           /private/tmp/com.apple.launchd.z3z87lwMDc/Listeners
STATATERM               emacs
TAR                     /usr/bin/tar
TERM                    dumb
TERMCAP
TMPDIR                  /var/folders/rm/pd12qdtn55qc3vc0vg5v0_y40000gn/T/
USER                    hoffmannc
XPC_FLAGS               0x0
XPC_SERVICE_NAME        0
__CF_USER_TEXT_ENCODING
                         0x1F5:0:0

Pointers are welcome
C.

-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853



From kekwu @end|ng |rom ucd@v|@@edu  Mon Jul 16 20:46:06 2018
From: kekwu @end|ng |rom ucd@v|@@edu (Kelly Wu)
Date: Mon, 16 Jul 2018 11:46:06 -0700
Subject: [R] How to try different effect sizes for Fisher's exact test?
Message-ID: <4E27D114-DF52-4FCE-A8E3-E5DDCDF793CE@ucdavis.edu>

I am currently working on a simulation, and I would like to see what happens with various effect sizes. How would I test out different effect sizes for the Fisher's exact test with my current code?

  set.seed(23)
  # p1<-response in controls
  # p2<-response in treated
  # Generating random deviates from a Uniform(0,1) distribution
  control.year1<-(runif(16, min = 0, max = 1))
  treat.year1<-(runif(16, min = 0, max = 1))
  
  #Generating dichotomous response variables for each group
  control.respond1<-ifelse(control.year1<=0.05,1,0)
  treat.respond1<-ifelse(treat.year1<=0.30,1,0)
  
  #Summing number of responses from each group
  control.no1<-sum(control.respond1==0)
  control.yes1<-sum(control.respond1==1)
  treat.no1<-sum(treat.respond1==0)
  treat.yes1<-sum(treat.respond1==1)
  
  #Perform the Fisher's exact test (one sided) with p<=0.01
  fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
  f<-fisher.test(fisher,alternative = "greater?) 


Thanks,
Kelly
	[[alternative HTML version deleted]]



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Mon Jul 16 22:19:21 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Mon, 16 Jul 2018 13:19:21 -0700
Subject: [R] scale_y_continuous with sec.axis
Message-ID: <52c18b6d-53bb-4e99-8a07-43f19f1634cf@gmail.com>

Hi, I'm using?scale_y_continuous with sec.axis and it's doing what I need but I don't understand how it picks which of the two series becomes the secondary. 

Does anyone have any insight into this? 

Thanks!



From jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com  Mon Jul 16 23:16:43 2018
From: jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com (Michael Hannon)
Date: Mon, 16 Jul 2018 14:16:43 -0700
Subject: [R] Making objects global in a package
In-Reply-To: <FAD0DE73-F0A8-4D39-B8DF-936549423293@dcn.davis.ca.us>
References: <CACdH2ZZq_k2=v_8JF2si1N1L0OsnhZ7jp762ZFqu7YBMTEF4+w@mail.gmail.com>
 <ADE7444F-A65A-425F-9186-CB17E6BBC581@dcn.davis.ca.us>
 <CAF8bMcZogjhGGHdj=z6kM=3eT5khq0b9EQseObLneWyT53NFvQ@mail.gmail.com>
 <FAD0DE73-F0A8-4D39-B8DF-936549423293@dcn.davis.ca.us>
Message-ID: <CACdH2ZZXO7-j8CWBRE7-tOsRziaOMBFpdj0f9m6jiGc6B52SAA@mail.gmail.com>

Thanks to all for your replies.  So far as I can see, there was
nothing wrong with my original approach, but I've decided to stuff all
the relevant definitions into a function (or functions), as this seems
to make "devtools::check()" happier.

-- Mike


On Fri, Jul 13, 2018 at 6:54 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Avoiding rda files because they don't track well with version control seems weak to me, since you should be creating the rda with an R file in the tools directory.
>
> On July 13, 2018 6:50:31 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>>What the OP is doing looks fine to me.
>>
>>The environment holding the data vectors is not necessary, but it helps
>>organize things - you know where to look for this sort of data vector.
>>
>>I would avoid the *.rda file, since it is not text, hence not readily
>>editable
>>or trackable with most source control systems.
>>
>>
>>Bill Dunlap
>>TIBCO Software
>>wdunlap tibco.com
>>
>>On Fri, Jul 13, 2018 at 6:17 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us>
>>wrote:
>>
>>> a) There is a mailing list for package development questions:
>>> R-package-devel.
>>>
>>> b) This seems like a job for the sysdata.rda file... no explicit
>>> environments needed. See the Writing R Extensions manual.
>>>
>>> On July 13, 2018 5:51:06 PM PDT, Michael Hannon <
>>> jmhannon.ucdavis at gmail.com> wrote:
>>> >Greetings.  I'm putting together a small package in which I use
>>> >`dplyr::read_csv()` to read CSV files from several different
>>sources.
>>> >I do
>>> >this in several different files, but with various kinds of
>>subsequent
>>> >processing, depending on the file.
>>> >
>>> >I find it useful to specify column types, as the apparent data type
>>of
>>> >a given
>>> >column sometimes changes unexpectedly deep into the file.  I.e., a
>>> >field that
>>> >consistently looks like an integer, suddenly becomes a fraction:
>>> >
>>> >    1, 1, ..., 1, 1/2, 1, ...
>>> >
>>> >Hence, the column type has to be treated as a character, rather than
>>as
>>> >an
>>> >integer (with the possibility of later conversion to double, if
>>> >necessary).
>>> >(This is just an example.)
>>> >
>>> >Therefore I use the `col_types` argument in all of the calls to
>>> >`read_csv()`.
>>> >
>>> >These calls are spread over several files, but I want the keep all
>>of
>>> >the
>>> >column types in a single place, yet have them available in each of
>>the
>>> >several
>>> >files.  This is just for the sake of maintainability.
>>> >
>>> >At the moment I do this by putting the column-type definitions into
>>a
>>> >single,
>>> >file:
>>> >
>>> >    000_define_data_attributes.R
>>> >
>>> >that:
>>> >
>>> >    (1) is named so that it's parsed first by `devtools::build()`
>>> >    (2) sets up an environment and stuffs the column types into it:
>>> >
>>> >            data_env <- new.env(parent=emptyenv())
>>> >            data_env$col_types_alpha <- list(
>>> >                Date = col_date(),
>>> >                var1 = col_double(),
>>> >                ...
>>> >            )
>>> >
>>> >There are a few other things that go into the file as well.
>>> >
>>> >Then I pick off the appropriate stuff from the environment in the
>>other
>>> >files:
>>> >
>>> >foo_alpha <- read_csv("alpha.csv", col_types =
>>> >data_env$col_types_alpha)
>>> >
>>> >This seems to work, but it doesn't "feel" right to me.  (If this
>>were
>>> >Python,
>>> >people would accuse me of being "non-pythonic").
>>> >
>>> >Hence, I'm seeking suggestions for the best practice for this kind
>>of
>>> >thing.
>>> >
>>> >BTW, I note that both the sources of data ("alpha", etc.) and the
>>> >column types
>>> >are more or less guaranteed to be static for the foreseeable future.
>>> >Hence,
>>> >there really isn't much danger in just replicating the column-type
>>> >definitions
>>> >in each of the various files, which would obviate the need for the
>>> >"000..."
>>> >file.  In other words, this is mostly a style thing.
>>> >
>>> >Thanks for any advice you can provide.
>>> >
>>> >-- Mike
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
> --
> Sent from my phone. Please excuse my brevity.



From btyner @end|ng |rom gm@||@com  Tue Jul 17 02:23:13 2018
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Mon, 16 Jul 2018 20:23:13 -0400
Subject: [R] undo compile? (or: remove bytecode from closure)
In-Reply-To: <ddd3aa5f-81f6-629e-56aa-d4bae35a0311@gmail.com>
References: <372eec80-f645-afe2-8a54-0a1e548e6840@gmail.com>
 <33b3c8cf-989a-879f-fd51-55176ddfd399@sapo.pt>
 <ddd3aa5f-81f6-629e-56aa-d4bae35a0311@gmail.com>
Message-ID: <b479d1c3-46cb-9635-f903-f06258b7d36c@gmail.com>

Thanks Rui and Duncan, this is most helpful.


On 07/16/2018 06:58 AM, Duncan Murdoch wrote:
> On 16/07/2018 5:31 AM, Rui Barradas wrote:
>> Hello,
>>
>> Maybe the following is not the recommended way but it works
>> (and I believe makes sense).
>>
>>
>> f <- function(){}
>> formals(f) <- formals(fc)
>> body(f) <- body(fc)
>
> That's not quite right:? it might lose the environment of fc, if it 
> isn't the environment where this took place.? But a simpler solution 
> is just
>
> f <- fc
> body(f) <- body(f)
>
> because any assignment to the body of a function causes the bytecode 
> to be dropped.
>
> Both of our approaches will also cause the source references to be 
> dropped.? If you want to save those, you need more steps:
>
> f <- fc
> body(f) <- body(f)
> attr(f, "srcref") <- getSrcref(fc)
>
> Duncan Murdoch
>
>>
>> f
>> #function (x)
>> #{
>> #? x <- x + 1
>> #? pi * x
>> #}
>>
>> f(1)
>> #[1] 6.283185
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 03:25 de 16-07-2018, Benjamin Tyner escreveu:
>>> Hi
>>>
>>> Given a closure which has been compiled, what's the recommended way to
>>> recover the original? For example,
>>>
>>> ? ??? > f <- function(x) x+1
>>> ? ??? > fc <- cmpfun(f)
>>> ? ??? > rm(f)
>>> ? ??? > fc
>>> ? ??? function(x) x+1
>>> ? ??? <bytecode: 0x41d9228>
>>>
>>> what's the best way to recover f from fc ?
>>>
>>> Regards
>>>
>>> Ben
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>



From m|ch@e|@thomp@on @end|ng |rom m@nuk@u@@c@nz  Tue Jul 17 06:53:17 2018
From: m|ch@e|@thomp@on @end|ng |rom m@nuk@u@@c@nz (Michael Thompson)
Date: Tue, 17 Jul 2018 04:53:17 +0000
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <1531802918272-0.post@n4.nabble.com>
References: <1531802918272-0.post@n4.nabble.com>
Message-ID: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>

Hi,
I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
of the model to non-DS people?
So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
Michael



From chr|@t|@n @end|ng |rom echo||m@nn@ch  Tue Jul 17 08:32:49 2018
From: chr|@t|@n @end|ng |rom echo||m@nn@ch (Christian)
Date: Tue, 17 Jul 2018 08:32:49 +0200
Subject: [R] Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
Message-ID: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>

Hi,

I am fighting to get rid of the messages like:

During startup - Warning messages:
Setting LC_CTYPE failed, using "C"
Setting LC_COLLATE failed, using "C"

This is annoying, because when building a package using R CMD, This 
message keeps cropping up.

Here my R:
Sys.getlocale()
[1] "C"
...................

Executing

     Open Terminal
     Write or paste in: defaults write org.R-project.R force.LANG 
en_US.UTF-8
     Close Terminal
     Start R

as suggested on the Net, did not help :-(

Pointers are welcome
C.

-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853



From @ez@reb@k| @end|ng |rom gm@||@com  Tue Jul 17 09:13:09 2018
From: @ez@reb@k| @end|ng |rom gm@||@com (Alex Zarebski)
Date: Tue, 17 Jul 2018 17:13:09 +1000
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
References: <1531802918272-0.post@n4.nabble.com>
 <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
Message-ID: <CAKsw2nEuVUyuuYk4XiurH81zpcLv6QQWuZPG_hOfU-+KHuyKAA@mail.gmail.com>

Hey,

Nice question, I'm interested to see what others have to say on this.
I'd like to point out a couple of algorithmic points:

- If you are using regularisation the scaling /will/ lead to different
results.
- If you are using an iterative method to estimate something, (yes very
vague but you get the gist), it can be very useful to know the data is
scaled in a particular way, i.e., it can inform an initial guess for the
iterative method.

On a pedagogical note, it might be interesting to point out to your
students that the act of choosing an scaling/transformation/preprocessing
can be useful as a way of understanding your data better.

Cheers,
Alex

On Tue, Jul 17, 2018 at 4:58 PM Michael Thompson <
michael.thompson at manukau.ac.nz> wrote:

> Hi,
> I seem to remember from classes that one effect of scaling / standardising
> data was to get better results in any analysis. But what I'm seeing when I
> study various explanations on scaling is that we get exactly the same
> results, just that when we look at standardised data it's easier to see
> proportionate effects.
> This is all very well for the data scientist to further investigate, but
> from a practical point of view, (especially IF it doesn't improve the
> accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while
> eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy
> story based on my misunderstanding. Hope you can help with this.
> Michael
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jul 17 09:39:18 2018
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 17 Jul 2018 09:39:18 +0200
Subject: [R] scale_y_continuous with sec.axis
In-Reply-To: <52c18b6d-53bb-4e99-8a07-43f19f1634cf@gmail.com>
References: <52c18b6d-53bb-4e99-8a07-43f19f1634cf@gmail.com>
Message-ID: <CAJuCY5ytvW0Z2TmCJo6RH4Uovm2_oGdmMi5qC1yQ0faMnpz5XA@mail.gmail.com>

Dear Anonymous,

Please do read the help file:
https://ggplot2.tidyverse.org/reference/sec_axis.html If you read it
carefully you'll understand that is doesn't pick a time series.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-07-16 22:19 GMT+02:00 Stats Student <stats.student4647 at gmail.com>:
> Hi, I'm using scale_y_continuous with sec.axis and it's doing what I need but I don't understand how it picks which of the two series becomes the secondary.
>
> Does anyone have any insight into this?
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From rkoenker @end|ng |rom ||||no|@@edu  Tue Jul 17 10:02:15 2018
From: rkoenker @end|ng |rom ||||no|@@edu (Roger Koenker)
Date: Tue, 17 Jul 2018 09:02:15 +0100
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
References: <1531802918272-0.post@n4.nabble.com>
 <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
Message-ID: <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>

In certain fields this sort of standardization has become customary based on some sort of (misguided) notion that it
induces ?normality.?  For example, in anthropometric studies based on the international Demographic and Health
Surveys (DHS) childrens? heights are often transformed to Z-scores prior to subsequent analysis under the dubious
presumption that variability around the Z-scores at various ages will be Gaussian.  In my experience this is rarely
justified, and analysts would be better off modeling the original data rather than doing the preliminary transformation.
This is discussed in further detail here:  https://projecteuclid.org/euclid.bjps/1313973394.

> On Jul 17, 2018, at 5:53 AM, Michael Thompson <michael.thompson at manukau.ac.nz> wrote:
> 
> Hi,
> I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
> This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
> Michael
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul 17 14:46:50 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Jul 2018 05:46:50 -0700
Subject: [R] 
 Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
Message-ID: <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>

I an sorry that I cannot answer your question, but you don't seem to be very effective in your use of this resource. 

While sometimes you might get responses to this kind of question here, you really ought to read the Posting Guide:

"Questions likely to prompt discussion unintelligible to non-programmers should rather go to R-devel than R-help. Questions about?package development, however, e.g., passing?R CMD check?should go to R-package-devel rather than R-devel." You might also consider R-sig-mac... this might be related to your development environment.

... and re starting a new thread with exactly the same question is poor nettiquette in any forum. Reply-all to previous messages on the same topic to maintain the subject thread.

Oh, and offering "the net" as a reference source is a joke in poor taste... that was from the R for Mac OS FAQ which is another clue that your problem might need more specialized help.

On July 16, 2018 11:32:49 PM PDT, Christian <christian at echoffmann.ch> wrote:
>Hi,
>
>I am fighting to get rid of the messages like:
>
>During startup - Warning messages:
>Setting LC_CTYPE failed, using "C"
>Setting LC_COLLATE failed, using "C"
>
>This is annoying, because when building a package using R CMD, This 
>message keeps cropping up.
>
>Here my R:
>Sys.getlocale()
>[1] "C"
>...................
>
>Executing
>
>     Open Terminal
>     Write or paste in: defaults write org.R-project.R force.LANG 
>en_US.UTF-8
>     Close Terminal
>     Start R
>
>as suggested on the Net, did not help :-(
>
>Pointers are welcome
>C.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Tue Jul 17 17:02:26 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 17 Jul 2018 08:02:26 -0700
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>
References: <1531802918272-0.post@n4.nabble.com>
 <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
 <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>
Message-ID: <CAGxFJbT1ze8DQiHO7sbGBEUXg-XME6rT13kSw53USSrgBCvNJQ@mail.gmail.com>

Prof. Koenker's response probably settles the matter, but if not, this
thread should really be taken offlist, as it is primarily about statistics
and not R programming.
stats.stackexchange.com might be an alternative place to post; indeed, I
suspect the issue has already been addressed in their archives.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 17, 2018 at 1:02 AM, Roger Koenker <rkoenker at illinois.edu>
wrote:

> In certain fields this sort of standardization has become customary based
> on some sort of (misguided) notion that it
> induces ?normality.?  For example, in anthropometric studies based on the
> international Demographic and Health
> Surveys (DHS) childrens? heights are often transformed to Z-scores prior
> to subsequent analysis under the dubious
> presumption that variability around the Z-scores at various ages will be
> Gaussian.  In my experience this is rarely
> justified, and analysts would be better off modeling the original data
> rather than doing the preliminary transformation.
> This is discussed in further detail here:  https://projecteuclid.org/
> euclid.bjps/1313973394.
>
> > On Jul 17, 2018, at 5:53 AM, Michael Thompson <
> michael.thompson at manukau.ac.nz> wrote:
> >
> > Hi,
> > I seem to remember from classes that one effect of scaling /
> standardising data was to get better results in any analysis. But what I'm
> seeing when I study various explanations on scaling is that we get exactly
> the same results, just that when we look at standardised data it's easier
> to see proportionate effects.
> > This is all very well for the data scientist to further investigate, but
> from a practical point of view, (especially IF it doesn't improve the
> accuracy of the result) surely it adds complication to 'telling the story'
> > of the model to non-DS people?
> > So, is scaling a technique for the DS to use to find effects, while
> eventually delivering a non-scaled version to the users?
> > I'd like to be able to give the true story to my students, not some
> fairy story based on my misunderstanding. Hope you can help with this.
> > Michael
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @y@@d@kdouk| @end|ng |rom ||ve@com  Tue Jul 17 14:09:48 2018
From: @y@@d@kdouk| @end|ng |rom ||ve@com (Aya Dakdouki)
Date: Tue, 17 Jul 2018 12:09:48 +0000
Subject: [R] help erroer solnp
In-Reply-To: <AM4PR1001MB136252CDA7C4605C8BFCF4E5E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
References: <AM4PR1001MB136252CDA7C4605C8BFCF4E5E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <AM4PR1001MB136222EC8C350A4822D56578E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>

Hello,


I am trying to solve a nonlinear optimization problem using the solnp function. I receive an error message saying:


Warning message:
In p0 * vscale [(neq + 2) :( nc + np + 1)]:
   the size of a longer object is not multiple of the size of a shorter object

Can you help me please.

Thank you in advance for your help.

Regards,
Aya




	[[alternative HTML version deleted]]



From chr|@t|@n @end|ng |rom echo||m@nn@ch  Tue Jul 17 16:36:14 2018
From: chr|@t|@n @end|ng |rom echo||m@nn@ch (Christian)
Date: Tue, 17 Jul 2018 16:36:14 +0200
Subject: [R] Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
 <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
Message-ID: <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>

Another try, I am sorry.

On 17.07.18 14:46, Jeff Newmiller wrote:
> I an sorry that I cannot answer your question, but you don't seem to be very effective in your use of this resource.
> 
>> Hi,
>>
>> I am fighting to get rid of the messages like:
>>
>> During startup - Warning messages:
>> Setting LC_CTYPE failed, using "C"
>> Setting LC_COLLATE failed, using "C"
>>
>> This is annoying, because when building a package using R CMD, This
>> message keeps cropping up.
>>
>> Here my R:
>> Sys.getlocale()
>> [1] "C"
>> ...................
>>
>> Executing
>>
>>      Open Terminal
>>      Write or paste in: defaults write org.R-project.R force.LANG
>> en_US.UTF-8
>>      Close Terminal
>>      Start R
>>
>> as suggested on 

https://stackoverflow.com/questions/9689104/installing-r-on-mac-warning-messages-setting-lc-ctype-failed-using-c,

  did not help :-(

Pointers are welcome
C.

-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul 17 17:24:56 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Jul 2018 08:24:56 -0700
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
References: <1531802918272-0.post@n4.nabble.com>
 <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
Message-ID: <D6539009-3E83-4B80-8D52-E887B4D91ED4@dcn.davis.ca.us>

This question is interesting, but sadly off-topic here as there is nothing specific to R in it. Fortunately there are many resources for getting an answer... e.g. a quick search with Google finds [1] which addresses both centering and scaling.

[1] https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia

On July 16, 2018 9:53:17 PM PDT, Michael Thompson <michael.thompson at manukau.ac.nz> wrote:
>Hi,
>I seem to remember from classes that one effect of scaling /
>standardising data was to get better results in any analysis. But what
>I'm seeing when I study various explanations on scaling is that we get
>exactly the same results, just that when we look at standardised data
>it's easier to see proportionate effects.
>This is all very well for the data scientist to further investigate,
>but from a practical point of view, (especially IF it doesn't improve
>the accuracy of the result) surely it adds complication to 'telling the
>story'
>of the model to non-DS people?
>So, is scaling a technique for the DS to use to find effects, while
>eventually delivering a non-scaled version to the users?
>I'd like to be able to give the true story to my students, not some
>fairy story based on my misunderstanding. Hope you can help with this.
>Michael
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul 17 17:42:31 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 17 Jul 2018 08:42:31 -0700
Subject: [R] help erroer solnp
In-Reply-To: <AM4PR1001MB136222EC8C350A4822D56578E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
References: <AM4PR1001MB136252CDA7C4605C8BFCF4E5E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
 <AM4PR1001MB136222EC8C350A4822D56578E65C0@AM4PR1001MB1362.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <EBB974FD-41B8-46D4-8841-75C2321BCA96@dcn.davis.ca.us>

It is hard to help you do the right thing when you don't tell us what you did or what you wanted to do or what data you had to work with. See [1][2] as [3] for help on how to ask a question regarding R.

Also, "solnp" is not part of R... such a function exists in the Rsoln contributed package, but you should not assume we will know that as there are over 10000 contributed packages in CRAN and many more elsewhere on the Internet.

Also beware that this is a plain text mailing list... if you post HTML formatted text then your email will have the formatting stripped with varying degrees of damage, sometimes to the point of making it unreadable. Set your email program to send plain text when you post here.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

On July 17, 2018 5:09:48 AM PDT, Aya Dakdouki <aya.dakdouki at live.com> wrote:
>Hello,
>
>
>I am trying to solve a nonlinear optimization problem using the solnp
>function. I receive an error message saying:
>
>
>Warning message:
>In p0 * vscale [(neq + 2) :( nc + np + 1)]:
>the size of a longer object is not multiple of the size of a shorter
>object
>
>Can you help me please.
>
>Thank you in advance for your help.
>
>Regards,
>Aya
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jul 17 18:18:17 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 17 Jul 2018 09:18:17 -0700
Subject: [R] 
 Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
 <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
 <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>
Message-ID: <9C4FD8C1-6968-4FE7-B6B5-2CC3586FA903@comcast.net>


> On Jul 17, 2018, at 7:36 AM, Christian <christian at echoffmann.ch> wrote:
> 
> Another try, I am sorry.
> 
> On 17.07.18 14:46, Jeff Newmiller wrote:
>> I an sorry that I cannot answer your question, but you don't seem to be very effective in your use of this resource.
>>> Hi,
>>> 
>>> I am fighting to get rid of the messages like:
>>> 
>>> During startup - Warning messages:
>>> Setting LC_CTYPE failed, using "C"
>>> Setting LC_COLLATE failed, using "C"
>>> 
>>> This is annoying, because when building a package using R CMD, This
>>> message keeps cropping up.
>>> 
>>> Here my R:
>>> Sys.getlocale()
>>> [1] "C"
>>> ...................
>>> 
>>> Executing
>>> 
>>>     Open Terminal
>>>     Write or paste in: defaults write org.R-project.R force.LANG
>>> en_US.UTF-8
>>>     Close Terminal
>>>     Start R
>>> 
>>> as suggested on 
> 
> https://stackoverflow.com/questions/9689104/installing-r-on-mac-warning-messages-setting-lc-ctype-failed-using-c,
> 
> did not help :-(

Sigh, claiming that something "did not help" usually ...does not help. You need a clear unambigous description of everything that was in place and exactly what was being done when the unexpected behavior occurred. 

And you need to post that description in the right venue which you have already been advised is not rhelp. I see that you have (probably unsuccessfully) attempted cross-posting to the right venue, r-sig-mac. Cross-posting to multiple r lists is deprecated by the Posting Guide which you should now read. 

Then you should subscribe to r-sig-mac using the web interface and only afterwards post to the correct venue: r-sig-mac at r-project.org. As always with first time posting you will see your first post held up in the queue for moderation, so don't send any additional queries until your post appears in that list's archive: https://stat.ethz.ch/pipermail/r-sig-mac/
> 
> Pointers are welcome
> C.
> 
> -- 
> Christian Hoffmann
> Rigiblickstrasse 15b
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From rmh @end|ng |rom temp|e@edu  Tue Jul 17 18:29:11 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 17 Jul 2018 12:29:11 -0400
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
References: <1531802918272-0.post@n4.nabble.com>
 <B09F0E65D2208E4FB3924C20489A4B0801784C2F5B@otav-win-mbx-04.manukau.ac.nz>
Message-ID: <CAGx1TMC=1NiiGZSnX+sqJ6qqeshWXQ-U4zYsL2YCQHNY3C73kg@mail.gmail.com>

This is a variant of FAQ 7.31 on rounding.

For hand arithmetic, for example the variance of c(29,30,31), it was
easier to subtract the mean and work with c(-1,0,1).
For limited precision computers working directly with many-digit
numbers could lead to rounding in intermediate steps and catastrophic
cancellation.

For more information see FAQ 7.31 in file
system.file("../../doc/FAQ")
on your computer.  Open in your favorite text editor.

Here is a simple example using 5-bit arithmetic (rather than the R
standard double precision with 53 bits)  that shows catastrophic
cancellation.

library(Rmpfr)

NN <- 29:31
NN
NN^2
formatBin(NN)
formatBin(NN^2)

## 53 bit precision (double precision)
SSq <- NN[1]^2 +NN[2]^2 + NN[3]^2
SSq
CorrSSq <- SSq - ((NN[1]+NN[2]+NN[3])^2)/3
CorrSSq ## right answer
formatBin(CorrSSq)

## 5 bit precision
ONE <- mpfr(1, precBits=5)
NNO <- NN*ONE
NNO
NNO^2 ## note loss of precision
formatBin(NNO) ## 5-bit numbers.  Their squares require 10 bits.
formatBin(NNO^2) ## 10-bit squares rounded to 5 bits

SSqO <- NNO[1]^2 +NNO[2]^2 + NNO[3]^2
SSqO
CorrSSqO <- SSqO - ((NNO[1]+NNO[2]+NNO[3])^2)/3
CorrSSqO ## very wrong answer from catastrophic cancellation
formatBin(CorrSSqO)

## "normalizing" NNO  5 bit precision
NNOm30 <- NNO-30
NNOm30
NNOm30^2
SSqOm30 <- NNOm30[1]^2 +NNOm30[2]^2 + NNOm30[3]^2  ## 5 bit precision
SSqOm30 ## right answer, even with low-precision arithmetic
formatBin(SSqOm30)

formatBin(NNOm30)
formatBin(NNOm30^2)

On Tue, Jul 17, 2018 at 12:53 AM, Michael Thompson
<michael.thompson at manukau.ac.nz> wrote:
> Hi,
> I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
> This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
> Michael
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m|ch@e|@thomp@on @end|ng |rom m@nuk@u@@c@nz  Wed Jul 18 07:36:02 2018
From: m|ch@e|@thomp@on @end|ng |rom m@nuk@u@@c@nz (Michael Thompson)
Date: Wed, 18 Jul 2018 05:36:02 +0000
Subject: [R] Scaling - does it get any better results than not scaling?
In-Reply-To: <CAGxFJbT1ze8DQiHO7sbGBEUXg-XME6rT13kSw53USSrgBCvNJQ@mail.gmail.com>
References: <1531802918272-0.post@n4.nabble.com>
 <e517739a5b6743c59e35228628c8e7aa@CITESHT2.ad.uillinois.edu>
 <ED545E5E-59D0-49A9-8960-917DDFDC5270@illinois.edu>
 <CAGxFJbT1ze8DQiHO7sbGBEUXg-XME6rT13kSw53USSrgBCvNJQ@mail.gmail.com>
Message-ID: <B09F0E65D2208E4FB3924C20489A4B0801784C63EC@otav-win-mbx-04.manukau.ac.nz>

My thanks to all contributors, and while I was not in the right place, I certainly got the answers I needed. My students will benefit, so thank you all.

Regards,
Michael Thompson M.Prof.Studies Data Science
09 975 4678
Senior Lecturer, Digital Technologies
Manukau Campus
We all, like sheep, have gone astray Isaiah 53
Personal profile: https://www.manukau.ac.nz/about/faculties-schools/business-and-information-technology/more-information-for-students/lecturer-profiles/michael-thompson

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Wednesday, 18 July 2018 3:02 AM
To: Roger Koenker <rkoenker at illinois.edu>
Cc: Michael Thompson <michael.thompson at manukau.ac.nz>; r-help at r-project.org
Subject: Re: [R] Scaling - does it get any better results than not scaling?

Prof. Koenker's response probably settles the matter, but if not, this thread should really be taken offlist, as it is primarily about statistics and not R programming.
stats.stackexchange.com<http://stats.stackexchange.com> might be an alternative place to post; indeed, I suspect the issue has already been addressed in their archives.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 17, 2018 at 1:02 AM, Roger Koenker <rkoenker at illinois.edu<mailto:rkoenker at illinois.edu>> wrote:
In certain fields this sort of standardization has become customary based on some sort of (misguided) notion that it
induces ?normality.?  For example, in anthropometric studies based on the international Demographic and Health
Surveys (DHS) childrens? heights are often transformed to Z-scores prior to subsequent analysis under the dubious
presumption that variability around the Z-scores at various ages will be Gaussian.  In my experience this is rarely
justified, and analysts would be better off modeling the original data rather than doing the preliminary transformation.
This is discussed in further detail here:  https://projecteuclid.org/euclid.bjps/1313973394.

> On Jul 17, 2018, at 5:53 AM, Michael Thompson <michael.thompson at manukau.ac.nz<mailto:michael.thompson at manukau.ac.nz>> wrote:
>
> Hi,
> I seem to remember from classes that one effect of scaling / standardising data was to get better results in any analysis. But what I'm seeing when I study various explanations on scaling is that we get exactly the same results, just that when we look at standardised data it's easier to see proportionate effects.
> This is all very well for the data scientist to further investigate, but from a practical point of view, (especially IF it doesn't improve the accuracy of the result) surely it adds complication to 'telling the story'
> of the model to non-DS people?
> So, is scaling a technique for the DS to use to find effects, while eventually delivering a non-scaled version to the users?
> I'd like to be able to give the true story to my students, not some fairy story based on my misunderstanding. Hope you can help with this.
> Michael
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jul 18 18:33:55 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 18 Jul 2018 16:33:55 +0000
Subject: [R] Help with knitr pkg
Message-ID: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi,
I worked through this excellent tutorial:
#Elegant regression results tables and plots in R: the finalfit package
https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/



Now I am applying it to my own data.

In the tutorial there is mention of:

# Tables can be knitted to PDF, Word or html documents. We do this in
# RStudio from a .Rmd document. Example chunk:
#   ```{r, echo = FALSE, results='asis'}
# knitr::kable(example_table, row.names=FALSE,
#              align=c("l", "l", "r", "r", "r", "r"))
# ```

I am having a difficult time understanding how this works?

I have read through the help:

?knitr
#"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
#It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
#The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."

install.packages("knitr")
library(knitr)
?knit
?stitch
install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
?spin
install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages :  Perhaps you meant 'SPIn' ?

I have also looked at the github and knitr author's links

https://github.com/yihui/knitr

https://yihui.name/knitr/demo/stitch/

https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd


If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?

I also tried writing out directly to pdf and png with no success.

#pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
#png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
#opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?

#This is the script I would like the output placed in PDF
explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
dependent = "AppealOverturned" # Appeals Status
appdf1DT2 %>%
  summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)

#dev.off()


str(appdf1DT2)
# Classes 'data.table' and 'data.frame':   3983 obs. of  21 variables:
#   $ ClaimServiceID   : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
# $ LineNumber       : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
# $ claimStatusId    : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
# $ PatientGender    : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
# $ PayorID          : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
# $ AppealID         : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
# $ ZipCode          : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
# $ EditID           : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
# $ CurrentBilled    : num  14394 14394 14394 14394 14394 ...
# $ ClaimLineSavings : num  0 0 0 0 0 ...
# $ StatusChangeMo   : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
# $ Grouping         : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
# $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
# $ PrimaryDX        : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
# $ RevCodeCats      : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
# $ AgeCat           : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
# $ ClaimLevelSavings: num  0 0 0 0 0 ...
# - attr(*, ".internal.selfref")=<externalptr>

head(appdf1DT2)
   ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode        TIN EditID
1:       51318639          1             3             M     000     149385    79765              33904      0
2:       51318640          2             3             M     000     149385    79765              33904    022
3:       51318642          4             3             M     000     149385    79765              33904   00504
4:       51318641          3             3             M     000     149385    79765              33904     022
5:       51318643          5             3             M     000     149385    79765              33904   00504
6:       85833537          7             2             F     000    3240182   116998              46635   00504
   CurrentBilled ClaimLineSavings StatusChangeMo                                 Grouping AppealOverturned PrimaryDX        RevCodeCats
1:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
2:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
3:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
4:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
5:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
6:      23472.92                0        2018-04  Ambulatory Health Care Facilities                1     M1712 MedSurgSuppandDevs
    AgeCat ClaimLevelSavings
1: [31-40]              0.00
2: [31-40]              0.00
3: [31-40]              0.00
4: [31-40]              0.00
5: [31-40]              0.00
6: [61-70]            296.25


Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.

Thank you.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Wed Jul 18 18:47:40 2018
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Wed, 18 Jul 2018 18:47:40 +0200
Subject: [R] GGPlot plot
In-Reply-To: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
Message-ID: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>

Dear R help,

I am new to ggplot so I apologize if my question is a bit obvious.

I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.

The variable PASP is discrete and only takes values 0,4,8..

My data are as following:

 

PASP   SUBJC

 

0          0

4          1

0          0

8          0

4          0

0          1

0          1

.           .

.           .

.           .




I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:





I hope my request is clear. Thanks for any help you can provide.

Francesca





From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jul 18 20:32:00 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 18 Jul 2018 19:32:00 +0100
Subject: [R] GGPlot plot
In-Reply-To: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
Message-ID: <9ff1d20f-5f0b-a587-aa3d-90dda8811b11@sapo.pt>

Hello,

Your request is not entirely clear.

What kind of a graph do you want? A bar graph with a bar of the fraction 
of positive levels of PASP per each level of SUBJC?
You need to be more specific.

Also, please post data like this:

# post the output of this command in your next mail
dput(head(data, 30))


Hope this helps,

Rui Barradas


?s 17:47 de 18-07-2018, Francesca escreveu:
> Dear R help,
> 
> I am new to ggplot so I apologize if my question is a bit obvious.
> 
> I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.
> 
> The variable PASP is discrete and only takes values 0,4,8..
> 
> My data are as following:
> 
>   
> 
> PASP   SUBJC
> 
>   
> 
> 0          0
> 
> 4          1
> 
> 0          0
> 
> 8          0
> 
> 4          0
> 
> 0          1
> 
> 0          1
> 
> .           .
> 
> .           .
> 
> .           .
> 
> 
> 
> 
> I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:
> 
> 
> 
> 
> 
> I hope my request is clear. Thanks for any help you can provide.
> 
> Francesca
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jul 18 21:53:45 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Jul 2018 12:53:45 -0700 (PDT)
Subject: [R] GGPlot plot
In-Reply-To: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
Message-ID: <alpine.BSF.2.00.1807181205200.23901@pedal.dcn.davis.ca.us>

On Wed, 18 Jul 2018, Francesca wrote:

> Dear R help,
>

> I am new to ggplot so I apologize if my question is a bit obvious.

Or perhaps not, as this is the "R-help" mailing list, not the 
"Ggplot-help" mailing list. Fortunately for you, what you really need to 
learn is R, and then ggplot will be much easier to get along with.

> I would like to create a plot where a compare the fraction of the values 
> of a variable called PASP out of the number of subjects, for two groups 
> of subject codified with a dummy variable called SUBJC.
>
> The variable PASP is discrete and only takes values 0,4,8..
>
> My data are as following:
>
> PASP   SUBJC
> 
> 0          0
>
> 4          1
>
> 0          0
>
> 8          0
>
> 4          0
>
> 0          1
>
> 0          1
>
> .           .
>
> .           .
>
> .           .
>
>
>
>
> I would like to calculate the fraction of positive levels of PASP out of 
> the total number of observations, divided per values of SUBJ=0 and 1. I 
> am new to the use of GGPlot and I do not know how to organize the data 
> and what to use to summarize these data as to obtain a picture as 
> follows:
>
>
>
>
>
> I hope my request is clear. Thanks for any help you can provide.

The funky text formatting and reference to "picture as follows" of the 
above makes me think you composed this in HTML and then converted it to 
plain text without looking at the result.

* We got no picture.. this is a plain-text-only mailing list.
* HTML makes terrible plain text.

The following is an example of how you can send us sample data and code in 
the body of your email that will survive these plain-text-only 
limitations. Note that writing R code is the key to communicating 
unambiguously.

You can start by preparing a sample of your data (usually not all of 
it)doing something like

dput(head(mydta,100))

and inserting the "dta <- " with the output so you get a line of R code 
that we can execute and have some rows of your data:

-----
dta <- structure(list(PASP = c(0, 12, 8, 0, 12, 12, 12, 8, 12, 8, 8,
8, 8, 4, 0, 12, 12, 0, 12, 0, 0, 12, 4, 8, 12, 8, 4, 4, 4, 4,
8, 8, 8, 12, 12, 12, 8, 0, 12, 12, 0, 12, 12, 8, 0, 4, 4, 12,
8, 8, 12, 8, 0, 12, 0, 0, 4, 0, 0, 4, 4, 12, 0, 4, 8, 8, 8, 4,
0, 0, 4, 0, 12, 4, 12, 12, 8, 0, 0, 0, 4, 8, 8, 0, 4, 0, 12,
4, 12, 0, 4, 12, 8, 0, 4, 0, 0, 12, 12, 8), SUBJC = c(0L, 1L,
0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L)), .Names = c("PASP", "SUBJC"), row.names = c(NA, -100L
), class = "data.frame")
-----

and then ideally you would tell us the results of a sample of the 
calculation you expect to see, though in this case you might not have 
thought to present them organized as below:

-----
result <- read.table( text =
" PASP SUBJC  Fraction
     0     0      0.279
     4     0      0.186
     8     0      0.395
    12     0      0.140
     0     1      0.263
     4     1      0.211
     8     1      0.123
    12     1      0.404
", header=TRUE)
-----

And with your existing text, we might come up with something like:

-----
library(ggplot2)

dta <- structure(list(PASP = c(0, 12, 8, 0, 12, 12, 12, 8, 12, 8, 8,
8, 8, 4, 0, 12, 12, 0, 12, 0, 0, 12, 4, 8, 12, 8, 4, 4, 4, 4,
8, 8, 8, 12, 12, 12, 8, 0, 12, 12, 0, 12, 12, 8, 0, 4, 4, 12,
8, 8, 12, 8, 0, 12, 0, 0, 4, 0, 0, 4, 4, 12, 0, 4, 8, 8, 8, 4,
0, 0, 4, 0, 12, 4, 12, 12, 8, 0, 0, 0, 4, 8, 8, 0, 4, 0, 12,
4, 12, 0, 4, 12, 8, 0, 4, 0, 0, 12, 12, 8), SUBJC = c(0L, 1L,
0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L,
1L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L)), .Names = c("PASP", "SUBJC"), row.names = c(NA, -100L

         ), class = "data.frame")
table(dta)
#>     SUBJC
#> PASP  0  1
#>   0  12 15
#>   4   8 12
#>   8  17  7
#>   12  6 23

dtasum <- aggregate( list( Count = rep(1,100) )
                    , dta
                    , FUN = sum
                    )

dtasum$Fraction <- ave( dtasum$Count
                       , dtasum$SUBJC
                       , FUN = function(x) ( x/sum(x) )
                       )
dtasum$PASPfactor <- factor( dtasum$PASP )
dtasum$SUBJCfactor <- factor( dtasum$SUBJC )
dtasum
#>   PASP SUBJC Count  Fraction PASPfactor SUBJCfactor
#> 1    0     0    12 0.2790698          0           0
#> 2    4     0     8 0.1860465          4           0
#> 3    8     0    17 0.3953488          8           0
#> 4   12     0     6 0.1395349         12           0
#> 5    0     1    15 0.2631579          0           1
#> 6    4     1    12 0.2105263          4           1
#> 7    8     1     7 0.1228070          8           1
#> 8   12     1    23 0.4035088         12           1

ggplot( dtasum
       , aes( x=SUBJCfactor
            , y=Fraction
            , fill=PASPfactor
            )
       ) +
   geom_bar( stat = "identity" ) +
   xlab( "SUBJ" ) +
   scale_fill_discrete( name = "PASP" )

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
-----

Obviously, since I never saw the figure you thought I was going to see, 
the plot I made may not be the one you had in mind, but you should at 
least have some example code to compare with the "Introduction to R" 
document that comes with R, and some functions to look up help pages on, 
e.g.

?aggregate
?ave

and you can execute pieces of code to see what they create:

rep(1,100)

You should read he Posting Guide carefully, as there are hints in it as to 
how to do much of this.

>
> Francesca
>
>
>
> ______________________________________________

> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 18 22:55:19 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 13:55:19 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
Message-ID: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>

   I have daily precipitation data for 58 locations from 2005-01-01 through
2018-06-18. Among other plots and analyses I want to apply lattice's
xyplot() to illustrate the abundance and patterns of the data.

   I've used a vector of colors (and a key) when there were only eight
weather stations and the date range was three months. This was very
effective in communicating the amounts and patterns.

   I'm asking for ideas on how to best present these data in a scatter plot.

Regards,

Rich



From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jul 18 23:21:14 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 18 Jul 2018 14:21:14 -0700
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
Message-ID: <DBDAB061-E753-4FE7-A085-5F96E906DDEF@comcast.net>


> On Jul 18, 2018, at 1:55 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have daily precipitation data for 58 locations from 2005-01-01 through
> 2018-06-18. Among other plots and analyses I want to apply lattice's
> xyplot() to illustrate the abundance and patterns of the data.
> 
>  I've used a vector of colors (and a key) when there were only eight
> weather stations and the date range was three months. This was very
> effective in communicating the amounts and patterns.
> 
>  I'm asking for ideas on how to best present these data in a scatter plot.

Monthly contour plots in a 3x4 layout or put tiny histograms of monthly rainfall atop a tilted map of your locations. See section 13.5.1 in Sarkar's "Lattice".


> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From |@b|h@6074 @end|ng |rom gm@||@com  Wed Jul 18 21:16:39 2018
From: |@b|h@6074 @end|ng |rom gm@||@com (Fabiha Binte Farooq)
Date: Thu, 19 Jul 2018 01:16:39 +0600
Subject: [R] Query regarding simulating weibull aft model with predefined
 censoring rate
Message-ID: <CAFLSYUnjt=iFxVnh74FOxznyDaBp0s+BY65=5h_vo4ULo-EDqQ@mail.gmail.com>

Hi there,
I am an MS student from Bangladesh. I am doing thesis in my MS degree. In
my research, I am generating data from weibull distribution and my model is
accelerated failure time (AFT) model. I am considering right censoring as
well as covariates. Now I have been facing difficulties to generate
censoring time controlling censoring proportion. I am attaching my codes
here.

Problem. I have generated censoring time using a relationship between scale
and covariates from an article for PH model. But my model is AFT. Is it
authentic to use it here? Please help!!!

Sincerely,
Fabiha

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: 1531941100067_weibull model.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180719/0fbf8d94/attachment-0002.txt>

From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 18 23:50:46 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 14:50:46 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
Message-ID: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>

   A set of data files have this format:

date,time,elev
1988-10-01,00:30,87.6849
1988-10-01,01:00,87.6849
1988-10-01,01:30,87.6849
1988-10-01,02:00,87.6879
1988-10-01,02:30,87.6879
1988-10-01,03:00,87.691
1988-10-01,03:30,87.694

Importing it with this command:

allyears <- read.table('allyears.dat', header = T, sep = ',')

produces this structure:

str(allyears)
'data.frame':	402414 obs. of  3 variables:
  $ date: Factor w/ 10230 levels "'data'","'date'",..:
  $ time: Factor w/ 1441 levels "'time'","00:00",..:
  $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:

   Applying,
allyears$date <- as.Date(as.character(allyears$date))
changes the structure to
str(allyears)
'data.frame':	402414 obs. of  3 variables:
  $ date: Date, format: "1988-10-01" "1988-10-01" ...
  $ time: Factor w/ 1441 levels "'time'","00:00",..:
  $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:

   I've not found the proper syntax to change time to a POSIXct time format
nor the elev to a numeric format.

allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%M))
Error: unexpected SPECIAL in "allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%"

and

allyears$elev <- as.Numeric(allyears$elev)
Error in as.Numeric(allyears$elev) : could not find function "as.Numeric"

   I've read ?read.table and looked on the web but I'm not finding how to
properly change the time and elev factors to H:M and fractional feet. A
pointer to a resource is much appreciated.

Rich



From t@n@@@ @end|ng |rom gm@||@com  Thu Jul 19 00:12:15 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 15:12:15 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
Message-ID: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>

Dear all,

please may I ask for a piece of advise regarding merging two dataframes :

A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))

B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))

function of the criteria :

if "the elements in the 1st column of A could be found among the elements
of the 1st column of B" i.e.

for the example above, we shall combine in the results only the row with
"a*b" of A with the row with "a*b::x*y" of B.

thank you,

bogdan

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 19 00:17:11 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 18 Jul 2018 15:17:11 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
Message-ID: <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>


> On Jul 18, 2018, at 2:50 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  A set of data files have this format:
> 
> date,time,elev
> 1988-10-01,00:30,87.6849
> 1988-10-01,01:00,87.6849
> 1988-10-01,01:30,87.6849
> 1988-10-01,02:00,87.6879
> 1988-10-01,02:30,87.6879
> 1988-10-01,03:00,87.691
> 1988-10-01,03:30,87.694
> 
> Importing it with this command:
> 
> allyears <- read.table('allyears.dat', header = T, sep = ',')
> 
> produces this structure:
> 
> str(allyears)
> 'data.frame':	402414 obs. of  3 variables:
> $ date: Factor w/ 10230 levels "'data'","'date'",..:
> $ time: Factor w/ 1441 levels "'time'","00:00",..:
> $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:
> 
>  Applying,
> allyears$date <- as.Date(as.character(allyears$date))
> changes the structure to
> str(allyears)
> 'data.frame':	402414 obs. of  3 variables:
> $ date: Date, format: "1988-10-01" "1988-10-01" ...
> $ time: Factor w/ 1441 levels "'time'","00:00",..:
> $ elev: Factor w/ 4494 levels "'elev'","-3762938880000000369098752",..:
> 
>  I've not found the proper syntax to change time to a POSIXct time format
> nor the elev to a numeric format.

I would not destroy the possibility of using the original values:

> allyears$myDate <- as.Date(as.character(allyears$date))
> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))
> allyears
        date  time    elev     myDate              myTime
1 1988-10-01 00:30 87.6849 1988-10-01 1988-10-01 00:30:00
2 1988-10-01 01:00 87.6849 1988-10-01 1988-10-01 01:00:00
3 1988-10-01 01:30 87.6849 1988-10-01 1988-10-01 01:30:00
4 1988-10-01 02:00 87.6879 1988-10-01 1988-10-01 02:00:00
5 1988-10-01 02:30 87.6879 1988-10-01 1988-10-01 02:30:00
6 1988-10-01 03:00  87.691 1988-10-01 1988-10-01 03:00:00
7 1988-10-01 03:30 87.694t 1988-10-01 1988-10-01 03:30:00

> 


> allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%M))
> Error: unexpected SPECIAL in "allyears$time <- as.POSIXct(as.character(allyears$time, format=%H:%"
> 
> and
> 
> allyears$elev <- as.Numeric(allyears$elev)
> Error in as.Numeric(allyears$elev) : could not find function "as.Numeric"

It's spelled `as.numeric`, but I'm having difficulty thinking about what sort of elevation (or would that be "depth") would be be measured by "-3762938880000000369098752".


> 
>  I've read ?read.table and looked on the web but I'm not finding how to
> properly change the time and elev factors to H:M and fractional feet. A
> pointer to a resource is much appreciated.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From SW@y @end|ng |rom meco@com  Thu Jul 19 00:53:34 2018
From: SW@y @end|ng |rom meco@com (Shawn Way)
Date: Wed, 18 Jul 2018 22:53:34 +0000
Subject: [R] xtable does not print out units of a variable
Message-ID: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>

I have a dataframe that contains units using the units package.  Unfortunately, I really need the units for reporting.  I'm assuming that's because the data is in a class units and xtable doesn't know what to do with this.

The following is a MWE:

    library(xtable)
    library(units)
    data <- data.frame(x=c(as_units(12,"ft")))
    xtable(data)

    % latex table generated in R 3.5.1 by xtable 1.8-2 package
    % Wed Jul 18 17:31:44 2018
    \begin{table}[ht]
    \centering
    \begin{tabular}{rr}
      \hline
     & x \\ 
      \hline
    1 & 12.00 \\ 
      \hline
    \end{tabular} 
    \end{table}

What I'm looking for is the line

    1 & 12.00 \\

to be 

    1 & 12.00 $ft$\\

Can someone point me in the correct direction to make this happen?  Since units are used extensively in engineering calculations, being able to handle this class would be extremely beneficial to engineers that are using R with knitr to generate engineering documents.

Shawn Way



From t@n@@@ @end|ng |rom gm@||@com  Thu Jul 19 01:00:18 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 16:00:18 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
Message-ID: <CA+JEM032PeGoO7__v_-trA0YdcnG0EDjyDH+ECMjrH+FQ6Kxbw@mail.gmail.com>

Dear Riley,

thank you very much for your help and solution. I got some inspiration from
stackoverflow website,

and I did use sqldf library. It looks that the formula below works too.
Thanks a lot !

sqldf("select B.*, A.* from B left join A on instr(B.z,  A.z)")


On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:

> please may I ask for a piece of advise regarding merging two dataframes :
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>> function of the criteria :
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>
>
> This may be what you are looking for:
>
> library(fuzzyjoin)
>
> The inner join returns just the one row where the string matches.
> B %>%
>   regex_inner_join(A, by = c(z = 'z'))
>
> While the full join returns NA's where the string does not match.
> B %>%
>   regex_full_join(A, by = c(z = 'z'))
>
> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
>> Dear all,
>>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>
>> function of the criteria :
>>
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>>
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>>
>> thank you,
>>
>> bogdan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From t@n@@@ @end|ng |rom gm@||@com  Thu Jul 19 01:03:12 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 16:03:12 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
Message-ID: <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>

Thanks a lot ! It looks that I am getting the same results with :

B %>% regex_left_join(A, by = c(z = 'z'))

On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:

> please may I ask for a piece of advise regarding merging two dataframes :
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>> function of the criteria :
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>
>
> This may be what you are looking for:
>
> library(fuzzyjoin)
>
> The inner join returns just the one row where the string matches.
> B %>%
>   regex_inner_join(A, by = c(z = 'z'))
>
> While the full join returns NA's where the string does not match.
> B %>%
>   regex_full_join(A, by = c(z = 'z'))
>
> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
>> Dear all,
>>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>
>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>
>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>
>> function of the criteria :
>>
>> if "the elements in the 1st column of A could be found among the elements
>> of the 1st column of B" i.e.
>>
>> for the example above, we shall combine in the results only the row with
>> "a*b" of A with the row with "a*b::x*y" of B.
>>
>> thank you,
>>
>> bogdan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Thu Jul 19 01:04:54 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Jul 2018 09:04:54 +1000
Subject: [R] GGPlot plot
In-Reply-To: <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
Message-ID: <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>

Hi Francesca,
This looks like a fairly simple task. Try this:

fpdf<-read.table(text="PASP   SUBJC
 0          0
 4          1
 0          0
 8          0
 4          0
 0          1
 0          1",
 header=TRUE)
# get the number of positive PASP results by group
ppos<-by(fpdf$SUBJC,fpdf$PASPpos,sum)
# get the number of subjects per group
spg<-c(sum(fpdf$SUBJC==0),sum(fpdf$SUBJC==1))
barplot(ppos/spg,names.arg=c(0,1),xlab="Group",
 ylab="Proportion PASP > 0",main="Proportion of PASP positive by group")

Jim

On Thu, Jul 19, 2018 at 2:47 AM, Francesca <francesca.pancotto at gmail.com> wrote:
> Dear R help,
>
> I am new to ggplot so I apologize if my question is a bit obvious.
>
> I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.
>
> The variable PASP is discrete and only takes values 0,4,8..
>
> My data are as following:
>
>
>
> PASP   SUBJC
>
>
>
> 0          0
>
> 4          1
>
> 0          0
>
> 8          0
>
> 4          0
>
> 0          1
>
> 0          1
>
> .           .
>
> .           .
>
> .           .
>
>
>
>
> I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:
>
>
>
>
>
> I hope my request is clear. Thanks for any help you can provide.
>
> Francesca
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 01:07:18 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 16:07:18 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
Message-ID: <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>

On Wed, 18 Jul 2018, David Winsemius wrote:

> I would not destroy the possibility of using the original values:

David,

   What are the benefits of keeping date and time as factors?

>> allyears$myDate <- as.Date(as.character(allyears$date))
>> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))

   The latter command is not working on the full (402415 rows in the allyears
data set):

allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))
Error in as.POSIXlt.character(x, tz, ...) :
   character string is not in a standard unambiguous format

> It's spelled `as.numeric`,

   Ah, I missed that. Thank you.

> ... but I'm having difficulty thinking about what sort of elevation (or would
> that be "depth") would be be measured by "-3762938880000000369098752".

   I also was curious about that figure and grep doesn't find it in the
original data file so I've no idea where R-3.5.0 came up with it.

   I'll read more about the POSIX datetime functions.

Thanks again,

Rich



From drj|m|emon @end|ng |rom gm@||@com  Thu Jul 19 01:10:38 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 19 Jul 2018 09:10:38 +1000
Subject: [R] GGPlot plot
In-Reply-To: <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
 <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
Message-ID: <CA+8X3fVtDvBAz=kEDbs7Wi3qcAAQu0PLxtkAnLzY3RfaFteGVg@mail.gmail.com>

Hi again,
Sorry, forgot this line:

 fpdf$PASPpos<-fpdf$PASP > 0

just after reading in the data frame.

Jim


On Thu, Jul 19, 2018 at 9:04 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Francesca,
> This looks like a fairly simple task. Try this:
>
> fpdf<-read.table(text="PASP   SUBJC
>  0          0
>  4          1
>  0          0
>  8          0
>  4          0
>  0          1
>  0          1",
>  header=TRUE)
> # get the number of positive PASP results by group
> ppos<-by(fpdf$SUBJC,fpdf$PASPpos,sum)
> # get the number of subjects per group
> spg<-c(sum(fpdf$SUBJC==0),sum(fpdf$SUBJC==1))
> barplot(ppos/spg,names.arg=c(0,1),xlab="Group",
>  ylab="Proportion PASP > 0",main="Proportion of PASP positive by group")
>
> Jim
>
> On Thu, Jul 19, 2018 at 2:47 AM, Francesca <francesca.pancotto at gmail.com> wrote:
>> Dear R help,
>>
>> I am new to ggplot so I apologize if my question is a bit obvious.
>>
>> I would like to create a plot where a compare the fraction of the values of a variable called PASP out of the number of subjects, for two groups of subject codified with a dummy variable called SUBJC.
>>
>> The variable PASP is discrete and only takes values 0,4,8..
>>
>> My data are as following:
>>
>>
>>
>> PASP   SUBJC
>>
>>
>>
>> 0          0
>>
>> 4          1
>>
>> 0          0
>>
>> 8          0
>>
>> 4          0
>>
>> 0          1
>>
>> 0          1
>>
>> .           .
>>
>> .           .
>>
>> .           .
>>
>>
>>
>>
>> I would like to calculate the fraction of positive levels of PASP out of the total number of observations, divided per values of SUBJ=0 and 1. I am new to the use of GGPlot and I do not know how to organize the data and what to use to summarize these data as to obtain a picture as follows:
>>
>>
>>
>>
>>
>> I hope my request is clear. Thanks for any help you can provide.
>>
>> Francesca
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 19 01:32:28 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 18 Jul 2018 16:32:28 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
Message-ID: <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>


> On Jul 18, 2018, at 4:07 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Wed, 18 Jul 2018, David Winsemius wrote:
> 
>> I would not destroy the possibility of using the original values:
> 
> David,
> 
>  What are the benefits of keeping date and time as factors?
> 
>>> allyears$myDate <- as.Date(as.character(allyears$date))
>>> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))


It's not so much as factors but rather in a form that paste() will coerce to character so you cna get the automatic format

> 
>  The latter command is not working on the full (402415 rows in the allyears
> data set):
> 
> allyears$myTime <- as.POSIXct(paste(allyears$date, allyears$time))
> Error in as.POSIXlt.character(x, tz, ...) :
>  character string is not in a standard unambiguous format

Maybe you need to add a format string. It might force some of your pasted date+time values to NA but at least you would be able to identify the original values and perhaps fix errors.

You really should include a large snapshot of data that will allow reproducibility.


> 
>> It's spelled `as.numeric`,
> 
>  Ah, I missed that. Thank you.
> 
>> ... but I'm having difficulty thinking about what sort of elevation (or would
>> that be "depth") would be be measured by "-3762938880000000369098752".
> 
>  I also was curious about that figure and grep doesn't find it in the
> original data file so I've no idea where R-3.5.0 came up with it.
> 
>  I'll read more about the POSIX datetime functions.
> 
> Thanks again,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From bgunter@4567 @end|ng |rom gm@||@com  Thu Jul 19 01:34:03 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 18 Jul 2018 16:34:03 -0700
Subject: [R] 
 Query regarding simulating weibull aft model with predefined
 censoring rate
In-Reply-To: <CAFLSYUnjt=iFxVnh74FOxznyDaBp0s+BY65=5h_vo4ULo-EDqQ@mail.gmail.com>
References: <CAFLSYUnjt=iFxVnh74FOxznyDaBp0s+BY65=5h_vo4ULo-EDqQ@mail.gmail.com>
Message-ID: <CAGxFJbQLQ+xTRmWYZVjHPTZ1fBiSJmMn6LGUvceMFWuq7=dn3A@mail.gmail.com>

Off topic for r-help (see posting guide linked below).

Suggest Posting on stats.stackexchange.com instead..

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 18, 2018 at 12:16 PM, Fabiha Binte Farooq <fabiha6074 at gmail.com>
wrote:

> Hi there,
> I am an MS student from Bangladesh. I am doing thesis in my MS degree. In
> my research, I am generating data from weibull distribution and my model is
> accelerated failure time (AFT) model. I am considering right censoring as
> well as covariates. Now I have been facing difficulties to generate
> censoring time controlling censoring proportion. I am attaching my codes
> here.
>
> Problem. I have generated censoring time using a relationship between scale
> and covariates from an article for PH model. But my model is AFT. Is it
> authentic to use it here? Please help!!!
>
> Sincerely,
> Fabiha
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 02:54:18 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 18 Jul 2018 17:54:18 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
Message-ID: <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>

On Wed, 18 Jul 2018, David Winsemius wrote:

> It's not so much as factors but rather in a form that paste() will coerce
> to character so you cna get the automatic format

David,

   Now I understand.

> Maybe you need to add a format string. It might force some of your pasted
> date+time values to NA but at least you would be able to identify the
> original values and perhaps fix errors.

   Thinking about the data I realize that rather than separate date and time
columns what's needed is a datetime string. I'll add the format string in
the morning and work on this.

> You really should include a large snapshot of data that will allow
> reproducibility.

   I'll certainly do this. With hourly and half-hourly data from 1989-June
2018 (but missing all of 1992) there are more than 400K rows in the raw data
file. If you would suggest how many would be an acceptably large number I'll
be happy to put that on a 'cloud' sharing site and provide the URL to it.

Best regards,

Rich



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jul 19 04:25:34 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Jul 2018 19:25:34 -0700 (PDT)
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.  I'm assuming 
> that's because the data is in a class units and xtable doesn't know what 
> to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to 
communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be 
patient, and consider figuring out what code changes they need to make so 
it will work.

More below.

> The following is a MWE:
>
>    library(xtable)
>    library(units)
>    data <- data.frame(x=c(as_units(12,"ft")))
>    xtable(data)
>
>    % latex table generated in R 3.5.1 by xtable 1.8-2 package
>    % Wed Jul 18 17:31:44 2018
>    \begin{table}[ht]
>    \centering
>    \begin{tabular}{rr}
>      \hline
>     & x \\
>      \hline
>    1 & 12.00 \\
>      \hline
>    \end{tabular}
>    \end{table}
>
> What I'm looking for is the line
>
>    1 & 12.00 \\
>
> to be
>
>    1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being able 
> to handle this class would be extremely beneficial to engineers that are 
> using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within 
columns, not rows, so putting the units into the body of the table is kind 
of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits
data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
                       , " ($"
                       , deparse_unit( datax[[1]] )
                       , "$)"
                       )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package
#> % Wed Jul 18 19:13:29 2018
#> \begin{table}[ht]
#> \centering
#> \begin{tabular}{rr}
#>   \hline
#>  & x (\$ft\$) \\
#>   \hline
#> 1 & 12.00 \\
#>   2 & 13.00 \\
#>    \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, 
then you will probably arrive at that information a single-row, many 
column data frame. I usually transpose this into a three-column data frame 
with a description column, a value column, and a units column. I don't use 
the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jul 19 04:51:27 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 18 Jul 2018 19:51:27 -0700 (PDT)
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
 <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807181927410.37700@pedal.dcn.davis.ca.us>

The traditional (SQL) way to attack this problem is to make the data 
structure simpler so that faster comparisons can be utilized:

################
A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))

library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)
Bx <- (   B
       %>% mutate( z_B = as.character( z ) )
       %>% rename( t_B = t )
       %>% separate_rows( z, sep="::" )
       )
Bx
#>     z t_B      z_B
#> 1 a*b   1 a*b::x*y
#> 2 x*y   1 a*b::x*y
#> 3   c   2        c
#> 4       3
#> 5 g*h   4      g*h
result <- (   A
           %>% mutate( z = as.character( z ) )
           %>% rename( t_A = t )
           %>% inner_join( Bx, by="z" )
           )
result
#>     z t_A t_B      z_B
#> 1 a*b   1   1 a*b::x*y

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
################

Note that this is preferable if you can avoid ever creating the 
complex data z in B, but Bx is much more flexible and less error prone 
than B. (Especially if you don't have to create B$z_B at all, but have 
some other unique identifier(s) for the groupings represented by each row 
in B.)

On Wed, 18 Jul 2018, Bogdan Tanasa wrote:

> Thanks a lot ! It looks that I am getting the same results with :
>
> B %>% regex_left_join(A, by = c(z = 'z'))
>
> On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:
>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>> function of the criteria :
>>> if "the elements in the 1st column of A could be found among the elements
>>> of the 1st column of B" i.e.
>>> for the example above, we shall combine in the results only the row with
>>> "a*b" of A with the row with "a*b::x*y" of B.
>>
>>
>> This may be what you are looking for:
>>
>> library(fuzzyjoin)
>>
>> The inner join returns just the one row where the string matches.
>> B %>%
>>   regex_inner_join(A, by = c(z = 'z'))
>>
>> While the full join returns NA's where the string does not match.
>> B %>%
>>   regex_full_join(A, by = c(z = 'z'))
>>
>> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>>
>>> Dear all,
>>>
>>> please may I ask for a piece of advise regarding merging two dataframes :
>>>
>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>>
>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>>
>>> function of the criteria :
>>>
>>> if "the elements in the 1st column of A could be found among the elements
>>> of the 1st column of B" i.e.
>>>
>>> for the example above, we shall combine in the results only the row with
>>> "a*b" of A with the row with "a*b::x*y" of B.
>>>
>>> thank you,
>>>
>>> bogdan
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From t@n@@@ @end|ng |rom gm@||@com  Thu Jul 19 04:50:56 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 18 Jul 2018 19:50:56 -0700
Subject: [R] help with merging two dataframes function of "egrep"-like
 formulas
In-Reply-To: <alpine.BSF.2.00.1807181927410.37700@pedal.dcn.davis.ca.us>
References: <CA+JEM01bnNUeZ=1YaELnmAmm19KOF-G93UPVgS2cVi8zRzncXw@mail.gmail.com>
 <CAKg3cnJzcmp-_nV=mUoKik0mOgkqvGESJM+KV4=o2WQKkHUjaw@mail.gmail.com>
 <CA+JEM03Y2_BcpeAenwqSExc4SaGTaSGYNiF2qHfDhqpetVoD5Q@mail.gmail.com>
 <alpine.BSF.2.00.1807181927410.37700@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM00n78mMa+jBxex04WeeFStACHSfMDJpP8EfN-DP2EKhVg@mail.gmail.com>

it looks great, thank you very much Jeff for your time and kind help !

On Wed, Jul 18, 2018 at 7:51 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The traditional (SQL) way to attack this problem is to make the data
> structure simpler so that faster comparisons can be utilized:
>
> ################
> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>
> library(dplyr)
> #>
> #> Attaching package: 'dplyr'
> #> The following objects are masked from 'package:stats':
> #>
> #>     filter, lag
> #> The following objects are masked from 'package:base':
> #>
> #>     intersect, setdiff, setequal, union
> library(tidyr)
> Bx <- (   B
>       %>% mutate( z_B = as.character( z ) )
>       %>% rename( t_B = t )
>       %>% separate_rows( z, sep="::" )
>       )
> Bx
> #>     z t_B      z_B
> #> 1 a*b   1 a*b::x*y
> #> 2 x*y   1 a*b::x*y
> #> 3   c   2        c
> #> 4       3
> #> 5 g*h   4      g*h
> result <- (   A
>           %>% mutate( z = as.character( z ) )
>           %>% rename( t_A = t )
>           %>% inner_join( Bx, by="z" )
>           )
> result
> #>     z t_A t_B      z_B
> #> 1 a*b   1   1 a*b::x*y
>
> #' Created on 2018-07-18 by the [reprex package](http://reprex.tidyver
> se.org) (v0.2.0).
> ################
>
> Note that this is preferable if you can avoid ever creating the complex
> data z in B, but Bx is much more flexible and less error prone than B.
> (Especially if you don't have to create B$z_B at all, but have some other
> unique identifier(s) for the groupings represented by each row in B.)
>
>
> On Wed, 18 Jul 2018, Bogdan Tanasa wrote:
>
> Thanks a lot ! It looks that I am getting the same results with :
>>
>> B %>% regex_left_join(A, by = c(z = 'z'))
>>
>> On Wed, Jul 18, 2018 at 3:57 PM, Riley Finn <rileyfinn3 at gmail.com> wrote:
>>
>> please may I ask for a piece of advise regarding merging two dataframes :
>>>
>>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>>> function of the criteria :
>>>> if "the elements in the 1st column of A could be found among the
>>>> elements
>>>> of the 1st column of B" i.e.
>>>> for the example above, we shall combine in the results only the row with
>>>> "a*b" of A with the row with "a*b::x*y" of B.
>>>>
>>>
>>>
>>> This may be what you are looking for:
>>>
>>> library(fuzzyjoin)
>>>
>>> The inner join returns just the one row where the string matches.
>>> B %>%
>>>   regex_inner_join(A, by = c(z = 'z'))
>>>
>>> While the full join returns NA's where the string does not match.
>>> B %>%
>>>   regex_full_join(A, by = c(z = 'z'))
>>>
>>> On Wed, Jul 18, 2018 at 5:20 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>
>>> Dear all,
>>>>
>>>> please may I ask for a piece of advise regarding merging two dataframes
>>>> :
>>>>
>>>> A <- data.frame(z=c("a*b", "c*d", "d*e", "e*f"), t =c(1, 2, 3, 4))
>>>>
>>>> B <- data.frame(z=c("a*b::x*y", "c", "", "g*h"), t =c(1, 2, 3, 4))
>>>>
>>>> function of the criteria :
>>>>
>>>> if "the elements in the 1st column of A could be found among the
>>>> elements
>>>> of the 1st column of B" i.e.
>>>>
>>>> for the example above, we shall combine in the results only the row with
>>>> "a*b" of A with the row with "a*b::x*y" of B.
>>>>
>>>> thank you,
>>>>
>>>> bogdan
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]



From |r@nce@c@@p@ncotto @end|ng |rom gm@||@com  Thu Jul 19 06:24:10 2018
From: |r@nce@c@@p@ncotto @end|ng |rom gm@||@com (Francesca)
Date: Thu, 19 Jul 2018 06:24:10 +0200
Subject: [R] GGPlot plot
In-Reply-To: <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
References: <962752B9-B4C6-4587-94C6-B8FA8400CAE0@gmail.com>
 <7E5BCE65-D290-4C07-95AB-771ACEEB0ABC@gmail.com>
 <CA+8X3fVEt-cKO1xGfJ11sreD9mjzsaYQL4KM-hAVptyrF+=44g@mail.gmail.com>
Message-ID: <CAKFaUKhOA6CWmmTSnZopS_bMQiKv9Ze3XBTyJNOcJ6gcUTfJEA@mail.gmail.com>

Thanks for the answer.

Il gio 19 lug 2018, 01:04 Jim Lemon <drjimlemon at gmail.com> ha scritto:

> Hi Francesca,
> This looks like a fairly simple task. Try this:
>
> fpdf<-read.table(text="PASP   SUBJC
>  0          0
>  4          1
>  0          0
>  8          0
>  4          0
>  0          1
>  0          1",
>  header=TRUE)
> # get the number of positive PASP results by group
> ppos<-by(fpdf$SUBJC,fpdf$PASPpos,sum)
> # get the number of subjects per group
> spg<-c(sum(fpdf$SUBJC==0),sum(fpdf$SUBJC==1))
> barplot(ppos/spg,names.arg=c(0,1),xlab="Group",
>  ylab="Proportion PASP > 0",main="Proportion of PASP positive by group")
>
> Jim
>
> On Thu, Jul 19, 2018 at 2:47 AM, Francesca <francesca.pancotto at gmail.com>
> wrote:
> > Dear R help,
> >
> > I am new to ggplot so I apologize if my question is a bit obvious.
> >
> > I would like to create a plot where a compare the fraction of the values
> of a variable called PASP out of the number of subjects, for two groups of
> subject codified with a dummy variable called SUBJC.
> >
> > The variable PASP is discrete and only takes values 0,4,8..
> >
> > My data are as following:
> >
> >
> >
> > PASP   SUBJC
> >
> >
> >
> > 0          0
> >
> > 4          1
> >
> > 0          0
> >
> > 8          0
> >
> > 4          0
> >
> > 0          1
> >
> > 0          1
> >
> > .           .
> >
> > .           .
> >
> > .           .
> >
> >
> >
> >
> > I would like to calculate the fraction of positive levels of PASP out of
> the total number of observations, divided per values of SUBJ=0 and 1. I am
> new to the use of GGPlot and I do not know how to organize the data and
> what to use to summarize these data as to obtain a picture as follows:
> >
> >
> >
> >
> >
> > I hope my request is clear. Thanks for any help you can provide.
> >
> > Francesca
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From e@ @end|ng |rom enr|co@chum@nn@net  Thu Jul 19 08:55:52 2018
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 19 Jul 2018 08:55:52 +0200
Subject: [R] Zoo changing time-zone when I merge 2 zoo time series
In-Reply-To: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
 (Christofer Bogaso's message of "Mon, 9 Jul 2018 15:52:02 +0530")
References: <CA+dpOJ=e9Oje-bwO3e+8cdpQzN2GGOmDV6OrreHRCoOUJg_5ow@mail.gmail.com>
Message-ID: <87pnzjhfyf.fsf@enricoschumann.net>

On Mon, 09 Jul 2018, Christofer Bogaso writes:

> Hi,
>
> Below is my code :
>
> library(zoo)
> Dat1 = structure(c(17890, 17770.01, 17600, 17593, 17630.01), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
> Dat2 = structure(c(15804.28, 15720.61, 15770, 15750, 15770), index =
> structure(c(1512664740,
> 1512664800, 1512664860, 1512664920, 1512664980), class = c("POSIXct",
> "POSIXt"), tzone = "America/Los_Angeles"), class = "zoo")
>
> merge(Dat1, Dat2)
>
>                         Dat1     Dat2
> 2017-12-07 22:09:00 17890.00 15804.28
> 2017-12-07 22:10:00 17770.01 15720.61
> 2017-12-07 22:11:00 17600.00 15770.00
> 2017-12-07 22:12:00 17593.00 15750.00
> 2017-12-07 22:13:00 17630.01 15770.00
>
>
> So, after merging the TZ of the original series got changed.
>
> Appreciate if someone points what went wrong
>

Nothing went wrong. Only 'merge.zoo' drops the
time-zone attribute.  But note that it did not change
the actual times:

  unclass(index(Dat1))
  ## [1] 1512664740 1512664800 1512664860 1512664920 1512664980
  ## attr(,"tzone")
  ## [1] "America/Los_Angeles"

  unclass(index(merge(Dat1, Dat2)))
  ## [1] 1512664740 1512664800 1512664860 1512664920 1512664980

  all(unclass(index(Dat1)) == unclass(index(merge(Dat1, Dat2))))
  ## [1] TRUE

  M <- merge(Dat1, Dat2)
  attr(index(M), "tzone") <- attr(index(Dat1), "tzone")
  M
  ##                         Dat1     Dat2
  ## 2017-12-07 08:39:00 17890.00 15804.28
  ## 2017-12-07 08:40:00 17770.01 15720.61
  ## 2017-12-07 08:41:00 17600.00 15770.00
  ## 2017-12-07 08:42:00 17593.00 15750.00
  ## 2017-12-07 08:43:00 17630.01 15770.00


See Ripley, B. D. and Hornik, K. (2001) Date-time
classes. R News, 1/2,
8?11. https://www.r-project.org/doc/Rnews/Rnews_2001-2.pdf



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net



From rhur||n @end|ng |rom gwdg@de  Thu Jul 19 09:44:33 2018
From: rhur||n @end|ng |rom gwdg@de (Rainer Hurling)
Date: Thu, 19 Jul 2018 09:44:33 +0200
Subject: [R] Help with knitr pkg
In-Reply-To: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <05c77898-b4b8-bd00-d954-10f1bd594ded@gwdg.de>

Hi Bill,

Am 18.07.18 um 18:33 schrieb Bill Poling:
> Hi,
> I worked through this excellent tutorial:
> #Elegant regression results tables and plots in R: the finalfit package
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
> 
> 
> 
> Now I am applying it to my own data.
> 
> In the tutorial there is mention of:
> 
> # Tables can be knitted to PDF, Word or html documents. We do this in
> # RStudio from a .Rmd document. Example chunk:
> #   ```{r, echo = FALSE, results='asis'}
> # knitr::kable(example_table, row.names=FALSE,
> #              align=c("l", "l", "r", "r", "r", "r"))
> # ```
> 
> I am having a difficult time understanding how this works?
> 
> I have read through the help:
> 
> ?knitr
> #"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
> #It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
> #The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."
> 
> install.packages("knitr")
> library(knitr)
> ?knit
> ?stitch
> install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
> ?spin
> install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages :  Perhaps you meant 'SPIn' ?
> 
> I have also looked at the github and knitr author's links
> 
> https://github.com/yihui/knitr
> 
> https://yihui.name/knitr/demo/stitch/
> 
> https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd
> 
> 
> If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?
> 
> I also tried writing out directly to pdf and png with no success.
> 
> #pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
> #png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
> #opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?
> 
> #This is the script I would like the output placed in PDF
> explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
> dependent = "AppealOverturned" # Appeals Status
> appdf1DT2 %>%
>    summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)
> 
> #dev.off()
> 
> 
> str(appdf1DT2)
> # Classes 'data.table' and 'data.frame':   3983 obs. of  21 variables:
> #   $ ClaimServiceID   : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
> # $ LineNumber       : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
> # $ claimStatusId    : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PatientGender    : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PayorID          : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
> # $ AppealID         : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
> # $ ZipCode          : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
> # $ EditID           : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
> # $ CurrentBilled    : num  14394 14394 14394 14394 14394 ...
> # $ ClaimLineSavings : num  0 0 0 0 0 ...
> # $ StatusChangeMo   : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ Grouping         : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PrimaryDX        : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
> # $ RevCodeCats      : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
> # $ AgeCat           : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
> # $ ClaimLevelSavings: num  0 0 0 0 0 ...
> # - attr(*, ".internal.selfref")=<externalptr>
> 
> head(appdf1DT2)
>     ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode        TIN EditID
> 1:       51318639          1             3             M     000     149385    79765              33904      0
> 2:       51318640          2             3             M     000     149385    79765              33904    022
> 3:       51318642          4             3             M     000     149385    79765              33904   00504
> 4:       51318641          3             3             M     000     149385    79765              33904     022
> 5:       51318643          5             3             M     000     149385    79765              33904   00504
> 6:       85833537          7             2             F     000    3240182   116998              46635   00504
>     CurrentBilled ClaimLineSavings StatusChangeMo                                 Grouping AppealOverturned PrimaryDX        RevCodeCats
> 1:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 2:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 3:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 4:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 5:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 6:      23472.92                0        2018-04  Ambulatory Health Care Facilities                1     M1712 MedSurgSuppandDevs
>      AgeCat ClaimLevelSavings
> 1: [31-40]              0.00
> 2: [31-40]              0.00
> 3: [31-40]              0.00
> 4: [31-40]              0.00
> 5: [31-40]              0.00
> 6: [61-70]            296.25
> 
> 
> Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.
> 
> Thank you.
> 
> WHP
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 


Not sure, if I get you right. Seems, that you use knitr:: and code 
chunks without the necessary context?

Please have a look at https://rmarkdown.rstudio.com/ to get a more 
general understanding about using knitr within RMarkdown context.

HTH,
Rainer Hurling



From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Jul 19 11:10:09 2018
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 19 Jul 2018 11:10:09 +0200
Subject: [R] Help with knitr pkg
In-Reply-To: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAJuCY5wSGgYTEhkpPBK3-F6SGHH8uHC3W0O+Jwx=CtRTT4Fo7g@mail.gmail.com>

Dear Bill,

It seems like you are looking at the wrong help files. The code in the
tutorial uses the package::function() syntax. So knitr::kable()
translates into use the function kable() from the knitr package. The
help file you are looking for is ?kable (when knitr is loaded) or
?knitr::kable (when knitr is not loaded).

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-07-18 18:33 GMT+02:00 Bill Poling <Bill.Poling at zelis.com>:
> Hi,
> I worked through this excellent tutorial:
> #Elegant regression results tables and plots in R: the finalfit package
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>
>
>
> Now I am applying it to my own data.
>
> In the tutorial there is mention of:
>
> # Tables can be knitted to PDF, Word or html documents. We do this in
> # RStudio from a .Rmd document. Example chunk:
> #   ```{r, echo = FALSE, results='asis'}
> # knitr::kable(example_table, row.names=FALSE,
> #              align=c("l", "l", "r", "r", "r", "r"))
> # ```
>
> I am having a difficult time understanding how this works?
>
> I have read through the help:
>
> ?knitr
> #"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
> #It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
> #The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."
>
> install.packages("knitr")
> library(knitr)
> ?knit
> ?stitch
> install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
> ?spin
> install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages :  Perhaps you meant 'SPIn' ?
>
> I have also looked at the github and knitr author's links
>
> https://github.com/yihui/knitr
>
> https://yihui.name/knitr/demo/stitch/
>
> https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd
>
>
> If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?
>
> I also tried writing out directly to pdf and png with no success.
>
> #pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
> #png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
> #opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?
>
> #This is the script I would like the output placed in PDF
> explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
> dependent = "AppealOverturned" # Appeals Status
> appdf1DT2 %>%
>   summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)
>
> #dev.off()
>
>
> str(appdf1DT2)
> # Classes 'data.table' and 'data.frame':   3983 obs. of  21 variables:
> #   $ ClaimServiceID   : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
> # $ LineNumber       : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
> # $ claimStatusId    : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PatientGender    : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PayorID          : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
> # $ AppealID         : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
> # $ ZipCode          : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
> # $ EditID           : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
> # $ CurrentBilled    : num  14394 14394 14394 14394 14394 ...
> # $ ClaimLineSavings : num  0 0 0 0 0 ...
> # $ StatusChangeMo   : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ Grouping         : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PrimaryDX        : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
> # $ RevCodeCats      : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
> # $ AgeCat           : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
> # $ ClaimLevelSavings: num  0 0 0 0 0 ...
> # - attr(*, ".internal.selfref")=<externalptr>
>
> head(appdf1DT2)
>    ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode        TIN EditID
> 1:       51318639          1             3             M     000     149385    79765              33904      0
> 2:       51318640          2             3             M     000     149385    79765              33904    022
> 3:       51318642          4             3             M     000     149385    79765              33904   00504
> 4:       51318641          3             3             M     000     149385    79765              33904     022
> 5:       51318643          5             3             M     000     149385    79765              33904   00504
> 6:       85833537          7             2             F     000    3240182   116998              46635   00504
>    CurrentBilled ClaimLineSavings StatusChangeMo                                 Grouping AppealOverturned PrimaryDX        RevCodeCats
> 1:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 2:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 3:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 4:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442        AmbSurgCare
> 5:      14394.08                0        2018-04  Ambulatory Health Care Facilities                2      8442 MedSurgSuppandDevs
> 6:      23472.92                0        2018-04  Ambulatory Health Care Facilities                1     M1712 MedSurgSuppandDevs
>     AgeCat ClaimLevelSavings
> 1: [31-40]              0.00
> 2: [31-40]              0.00
> 3: [31-40]              0.00
> 4: [31-40]              0.00
> 5: [31-40]              0.00
> 6: [61-70]            296.25
>
>
> Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.
>
> Thank you.
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Jul 19 12:22:19 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 19 Jul 2018 10:22:19 +0000
Subject: [R] Help with knitr pkg
In-Reply-To: <05c77898-b4b8-bd00-d954-10f1bd594ded@gwdg.de>
References: <CY1PR0201MB18340C14BA547A3484BAD351EA530@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <05c77898-b4b8-bd00-d954-10f1bd594ded@gwdg.de>
Message-ID: <CY1PR0201MB183410C5858B2EFFA0397080EA520@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi Rainer:

Thank you I will have a look at the link you provide.
As I mentioned,
?#opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work??

Hopefully your reference has an example I can follow, will let you know, cheers.

WHP


>>Not sure, if I get you right. Seems, that you use knitr:: and code
chunks without the necessary context?

Please have a look at https://rmarkdown.rstudio.com/<https://rmarkdown.rstudio.com/> to get a more
general understanding about using knitr within RMarkdown context.<<<<



From: Rainer Hurling <rhurlin at gwdg.de>
Sent: Thursday, July 19, 2018 3:45 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with knitr pkg

Hi Bill,

Am 18.07.18 um 18:33 schrieb Bill Poling:
> Hi,
> I worked through this excellent tutorial:
> #Elegant regression results tables and plots in R: the finalfit package
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/<https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/>
>
>
>
> Now I am applying it to my own data.
>
> In the tutorial there is mention of:
>
> # Tables can be knitted to PDF, Word or html documents. We do this in
> # RStudio from a .Rmd document. Example chunk:
> # ```{r, echo = FALSE, results='asis'}
> # knitr::kable(example_table, row.names=FALSE,
> # align=c("l", "l", "r", "r", "r", "r"))
> # ```
>
> I am having a difficult time understanding how this works?
>
> I have read through the help:
>
> ?knitr
> #"This function takes an input file, extracts the R code in it according to a list of patterns, evaluates the code and writes the output in another file.
> #It can also tangle R source code from the input document (purl() is a wrapper to knit(..., tangle = TRUE)).
> #The knitr.purl.inline option can be used to also tangle the code of inline expressions (disabled by default)."
>
> install.packages("knitr")
> library(knitr)
> ?knit
> ?stitch
> install.packages("stitch")#package 'stitch' is not available (for R version 3.5.1)
> ?spin
> install.packages("spin") #package 'spin' is not available (for R version 3.5.1)Warning in install.packages : Perhaps you meant 'SPIn' ?
>
> I have also looked at the github and knitr author's links
>
> https://github.com/yihui/knitr<https://github.com/yihui/knitr>
>
> https://yihui.name/knitr/demo/stitch/<https://yihui.name/knitr/demo/stitch/>
>
> https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd<https://github.com/yihui/knitr/blob/master/inst/examples/knitr-spin.Rmd>
>
>
> If I understand this correctly I have to have a template already in place as the input object, is that correct? How would I construct this it that is so?
>
> I also tried writing out directly to pdf and png with no success.
>
> #pdf("c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf")
> #png("c:/WHP/Appeals/OutputPDFs/EX&DE V1.png")
> #opts_chunk$set(fig.path = "c:/WHP/Appeals/OutputPDFs/EX&DE V1.pdf") <--I don't even understand what this does, poached it from one of the google sites I have been reviewing and tried to make it work?
>
> #This is the script I would like the output placed in PDF
> explanatory = c("claimStatusId", "AgeCat", "PatientGender", "PayorID")
> dependent = "AppealOverturned" # Appeals Status
> appdf1DT2 %>%
> summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)
>
> #dev.off()
>
>
> str(appdf1DT2)
> # Classes 'data.table' and 'data.frame': 3983 obs. of 21 variables:
> # $ ClaimServiceID : Factor w/ 3983 levels "51318639","51318640",..: 1 2 4 3 5 12 6 8 7 9 ...
> # $ LineNumber : Factor w/ 140 levels "1","2","3","4",..: 1 2 4 3 5 7 1 3 2 4 ...
> # $ claimStatusId : Factor w/ 2 levels "2","3": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PatientGender : Factor w/ 3 levels "F","M","UNK": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PayorID : Factor w/ 19 levels "000","234","239",..: 1 1 1 1 1 1 1 1 1 1 ...
> # $ AppealID : Factor w/ 512 levels "79765","116998",..: 1 1 1 1 1 2 2 2 2 2 ...
> # $ ZipCode : Factor w/ 223 levels "2155","3037",..: 72 72 72 72 72 102 102 102 102 102 ...
> # $ EditID : Factor w/ 21 levels "","0","001X",..: 2 12 8 12 8 8 2 8 12 8 ...
> # $ CurrentBilled : num 14394 14394 14394 14394 14394 ...
> # $ ClaimLineSavings : num 0 0 0 0 0 ...
> # $ StatusChangeMo : Factor w/ 7 levels "2018-01","2018-02",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ Grouping : Factor w/ 9 levels "","Agencies",..: 4 4 4 4 4 4 4 4 4 4 ...
> # $ AppealOverturned : Factor w/ 2 levels "1","2": 2 2 2 2 2 1 1 1 1 1 ...
> # $ PrimaryDX : Factor w/ 360 levels "","8442","912",..: 2 2 2 2 2 171 171 171 171 171 ...
> # $ RevCodeCats : Factor w/ 41 levels "AdminStorProcBlProd",..: 2 2 18 2 18 18 2 2 2 18 ...
> # $ AgeCat : Factor w/ 9 levels "[0-5]","[11-20]",..: 4 4 4 4 4 8 8 8 8 8 ...
> # $ ClaimLevelSavings: num 0 0 0 0 0 ...
> # - attr(*, ".internal.selfref")=<externalptr>
>
> head(appdf1DT2)
> ClaimServiceID LineNumber claimStatusId PatientGender PayorID ProviderID AppealID ZipCode TIN EditID
> 1: 51318639 1 3 M 000 149385 79765 33904 0
> 2: 51318640 2 3 M 000 149385 79765 33904 022
> 3: 51318642 4 3 M 000 149385 79765 33904 00504
> 4: 51318641 3 3 M 000 149385 79765 33904 022
> 5: 51318643 5 3 M 000 149385 79765 33904 00504
> 6: 85833537 7 2 F 000 3240182 116998 46635 00504
> CurrentBilled ClaimLineSavings StatusChangeMo Grouping AppealOverturned PrimaryDX RevCodeCats
> 1: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 AmbSurgCare
> 2: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 AmbSurgCare
> 3: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 MedSurgSuppandDevs
> 4: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 AmbSurgCare
> 5: 14394.08 0 2018-04 Ambulatory Health Care Facilities 2 8442 MedSurgSuppandDevs
> 6: 23472.92 0 2018-04 Ambulatory Health Care Facilities 1 M1712 MedSurgSuppandDevs
> AgeCat ClaimLevelSavings
> 1: [31-40] 0.00
> 2: [31-40] 0.00
> 3: [31-40] 0.00
> 4: [31-40] 0.00
> 5: [31-40] 0.00
> 6: [61-70] 296.25
>
>
> Maybe I am in over my head in this pursuit given my novice status with R, however, any direction would be appreciated.
>
> Thank you.
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>


Not sure, if I get you right. Seems, that you use knitr:: and code
chunks without the necessary context?

Please have a look at https://rmarkdown.rstudio.com/<https://rmarkdown.rstudio.com/> to get a more
general understanding about using knitr within RMarkdown context.

HTH,
Rainer Hurling

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From SW@y @end|ng |rom meco@com  Thu Jul 19 13:52:46 2018
From: SW@y @end|ng |rom meco@com (Shawn Way)
Date: Thu, 19 Jul 2018 11:52:46 +0000
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
Message-ID: <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>

Thank you for the example you posted.  I'll try to make a go of it from there.

I understand and actually use columns with consistent information, however, it's the reporting of the variables and their units that is the crux of the situation.  The units package is extremely useful in automatic conversion between units, something necessary for us engineering folks.

Thank you kindly!

Shawn Way, PE

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, July 18, 2018 9:26 PM
To: Shawn Way <SWay at meco.com>
Cc: r-help at r-project.org
Subject: Re: [R] xtable does not print out units of a variable

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.  I'm assuming 
> that's because the data is in a class units and xtable doesn't know 
> what to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.

More below.

> The following is a MWE:
>
>    library(xtable)
>    library(units)
>    data <- data.frame(x=c(as_units(12,"ft")))
>    xtable(data)
>
>    % latex table generated in R 3.5.1 by xtable 1.8-2 package
>    % Wed Jul 18 17:31:44 2018
>    \begin{table}[ht]
>    \centering
>    \begin{tabular}{rr}
>      \hline
>     & x \\
>      \hline
>    1 & 12.00 \\
>      \hline
>    \end{tabular}
>    \end{table}
>
> What I'm looking for is the line
>
>    1 & 12.00 \\
>
> to be
>
>    1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being 
> able to handle this class would be extremely beneficial to engineers 
> that are using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
                       , " ($"
                       , deparse_unit( datax[[1]] )
                       , "$)"
                       )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
#>   \hline
#>  & x (\$ft\$) \\
#>   \hline
#> 1 & 12.00 \\
#>   2 & 13.00 \\
#>    \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From jrkr|de@u @end|ng |rom y@hoo@c@  Thu Jul 19 14:40:00 2018
From: jrkr|de@u @end|ng |rom y@hoo@c@ (John Kane)
Date: Thu, 19 Jul 2018 12:40:00 +0000 (UTC)
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
 <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <1676236527.753639.1532004000762@mail.yahoo.com>

 ?I wonder if the problem may be that xtable is not designed to deal with an object of class "object" 

> dat1 <- data.frame(? x=c(as_units(12,"ft")))
> str(dat1)
'data.frame':?? ?1 obs. of? 1 variable:
?$ x:Object of class units:
?atomic? 12
? ..- attr(*, "units")=List of 2
? .. ..$ numerator? : chr "ft"
? .. ..$ denominator: chr 
? .. ..- attr(*, "class")= chr "symbolic_units"



   On Thursday, July 19, 2018, 7:53:09 a.m. EDT, Shawn Way <SWay at meco.com> wrote:  
 
 Thank you for the example you posted.? I'll try to make a go of it from there.

I understand and actually use columns with consistent information, however, it's the reporting of the variables and their units that is the crux of the situation.? The units package is extremely useful in automatic conversion between units, something necessary for us engineering folks.

Thank you kindly!

Shawn Way, PE

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, July 18, 2018 9:26 PM
To: Shawn Way <SWay at meco.com>
Cc: r-help at r-project.org
Subject: Re: [R] xtable does not print out units of a variable

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.? I'm assuming 
> that's because the data is in a class units and xtable doesn't know 
> what to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.

More below.

> The following is a MWE:
>
>? ? library(xtable)
>? ? library(units)
>? ? data <- data.frame(x=c(as_units(12,"ft")))
>? ? xtable(data)
>
>? ? % latex table generated in R 3.5.1 by xtable 1.8-2 package
>? ? % Wed Jul 18 17:31:44 2018
>? ? \begin{table}[ht]
>? ? \centering
>? ? \begin{tabular}{rr}
>? ? ? \hline
>? ? & x \\
>? ? ? \hline
>? ? 1 & 12.00 \\
>? ? ? \hline
>? ? \end{tabular}
>? ? \end{table}
>
> What I'm looking for is the line
>
>? ? 1 & 12.00 \\
>
> to be
>
>? ? 1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being 
> able to handle this class would be extremely beneficial to engineers 
> that are using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
? ? ? ? ? ? ? ? ? ? ? , " ($"
? ? ? ? ? ? ? ? ? ? ? , deparse_unit( datax[[1]] )
? ? ? ? ? ? ? ? ? ? ? , "$)"
? ? ? ? ? ? ? ? ? ? ? )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
#>? \hline
#>? & x (\$ft\$) \\
#>? \hline
#> 1 & 12.00 \\
#>? 2 & 13.00 \\
#>? ? \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.  
	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 15:35:03 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 06:35:03 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>

On Wed, 18 Jul 2018, Rich Shepard wrote:

> If you would suggest how many would be an acceptably large number I'll be
> happy to put that on a 'cloud' sharing site and provide the URL to it.

   I put a zipped data file at this URL:
<http://www.fileconvoy.com/dfl.php?id=g61a366bb8947de43100009863935141c96f82092d4>

   It will stay there for 5 days.

Rich



From du|c@|m@ @end|ng |rom b|gpond@com  Thu Jul 19 15:37:56 2018
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Thu, 19 Jul 2018 23:37:56 +1000
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
Message-ID: <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>

Hi Rich

Try something like this

set.seed(1)
xy <- 
data.frame(x = rnorm(108),
           y = rnorm(108),
           gp = rep(1:9, ea = 12))


xyplot(y~x|gp, xy,
       as.table = TRUE,
       strip = F,
       strip.left = F,
       layout = c(3,3),
       par.settings= list(layout.heights = list(main = 0,
                                          axis.top = 0.3),
                          plot.symbol = list(pch = ".",
			                     col = "#000000",
			                     cex = 3)
	           ),
       scales = list(x = list(alternating = FALSE,
                              relation    = "same"),
                     y = list(alternating = FALSE,
                              relation    = "same")
                 ),
       panel = function(x,y, ...){

                 panel.xyplot(x,y, ...)
                 panel.text(-1, 2, paste("Group", 1:9)[which.packet()])

               }
)

I have put over 60 panels on an A4 page.
You may have to put an if statement for the group names if they overlap
data.
Space is a premium - you can reduce the right margin similar to the top see
?trellis.par.get()

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350
 



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Thursday, 19 July 2018 06:55
To: r-help at r-project.org
Subject: [R] Suggestions for scatter plot of many data

   I have daily precipitation data for 58 locations from 2005-01-01 through
2018-06-18. Among other plots and analyses I want to apply lattice's
xyplot() to illustrate the abundance and patterns of the data.

   I've used a vector of colors (and a key) when there were only eight
weather stations and the date range was three months. This was very
effective in communicating the amounts and patterns.

   I'm asking for ideas on how to best present these data in a scatter plot.

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From m@rc_@chw@rtz @end|ng |rom me@com  Thu Jul 19 15:38:57 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 19 Jul 2018 09:38:57 -0400
Subject: [R] xtable does not print out units of a variable
In-Reply-To: <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
References: <33e2db99f2a446ba9c693a238eeec6e2@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.BSF.2.00.1807181904430.37700@pedal.dcn.davis.ca.us>
 <058f1c1d6e9f4901ae80b5a38fddcd60@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <0EA067C6-F588-4FEC-9373-08AA8DD57D41@me.com>

Hi,

Just to throw in an alternative possibility, you may want to look at Frank's Hmisc package on CRAN:

  https://cran.r-project.org/web/packages/Hmisc/index.html

and note the label(), latex() and units() functions therein.

They may or may not work for what you are looking to do here.

As Jeff has noted, you may need to do some pre-processing of the output to the LaTeX table to get what you want, before calling any of the LaTeX output functions, in the absence of direct support for specific classes of object, such as 'units'. Keep in mind, that all of the output to LaTeX is character based, so you can create any formatted character string you need, then generate the LaTeX output.

Regards,

Marc Schwartz


> On Jul 19, 2018, at 7:52 AM, Shawn Way <SWay at meco.com> wrote:
> 
> Thank you for the example you posted.  I'll try to make a go of it from there.
> 
> I understand and actually use columns with consistent information, however, it's the reporting of the variables and their units that is the crux of the situation.  The units package is extremely useful in automatic conversion between units, something necessary for us engineering folks.
> 
> Thank you kindly!
> 
> Shawn Way, PE
> 
> -----Original Message-----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
> Sent: Wednesday, July 18, 2018 9:26 PM
> To: Shawn Way <SWay at meco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] xtable does not print out units of a variable
> 
>> On Wed, 18 Jul 2018, Shawn Way wrote:
>> 
>> I have a dataframe that contains units using the units package. 
>> Unfortunately, I really need the units for reporting.  I'm assuming 
>> that's because the data is in a class units and xtable doesn't know 
>> what to do with this.
> 
> If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:
> 
> maintainer( "xtable" )
> 
> Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.
> 
> More below.
> 
>> The following is a MWE:
>> 
>>   library(xtable)
>>   library(units)
>>   data <- data.frame(x=c(as_units(12,"ft")))
>>   xtable(data)
>> 
>>   % latex table generated in R 3.5.1 by xtable 1.8-2 package
>>   % Wed Jul 18 17:31:44 2018
>>   \begin{table}[ht]
>>   \centering
>>   \begin{tabular}{rr}
>>     \hline
>>    & x \\
>>     \hline
>>   1 & 12.00 \\
>>     \hline
>>   \end{tabular}
>>   \end{table}
>> 
>> What I'm looking for is the line
>> 
>>   1 & 12.00 \\
>> 
>> to be
>> 
>>   1 & 12.00 $ft$\\
>> 
>> Can someone point me in the correct direction to make this happen? 
>> Since units are used extensively in engineering calculations, being 
>> able to handle this class would be extremely beneficial to engineers 
>> that are using R with knitr to generate engineering documents.
>> 
>> Shawn Way
> 
> I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:
> 
> ####################
> library(xtable)
> library(units)
> #> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
> datax <- xtable(data)
> names(datax) <- paste0( names(datax)[1]
>                       , " ($"
>                       , deparse_unit( datax[[1]] )
>                       , "$)"
>                       )
> datax
> #> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
> #>   \hline
> #>  & x (\$ft\$) \\
> #>   \hline
> #> 1 & 12.00 \\
> #>   2 & 13.00 \\
> #>    \hline
> #> \end{tabular}
> #> \end{table}
> 
> #' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
> ####################
> 
> If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 16:18:17 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 07:18:17 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
Message-ID: <alpine.LNX.2.20.1807190714460.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Duncan Mackay wrote:

> Try something like this

   ...

Duncan,

   That's impressive and well beyond anything I've done in the past. I'll
study it to fully understand it and make it work for me.

> I have put over 60 panels on an A4 page.
> Space is a premium - you can reduce the right margin similar to the top see
> ?trellis.par.get()

   On the smaller letter size page I may need to create two sets of plots if
each panel is too small.

   Thank you for the valuable lesson.

Best regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 18:10:06 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 09:10:06 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Rich Shepard wrote:

>  I put a zipped data file at this URL:
> <http://www.fileconvoy.com/dfl.php?id=g61a366bb8947de43100009863935141c96f82092d4>

   Since then I reformatted the file to two fields: date-time and elevation.
If anyone wants a copy send me a message off the list and I'll respond with
the modified file attached.

   Because time zone doesn't matter for a single location I'm looking at how
to use chron(). I've downloaded the PDF from CRAN and am trying to apply it
correctly so the dataframe contains two columns: date-time and elevation.
Will probably be asking for help in correctly using chron().

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 19:02:07 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 10:02:07 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Rich Shepard wrote:

> Since then I reformatted the file to two fields: date-time and elevation.
> If anyone wants a copy send me a message off the list and I'll respond with
> the modified file attached.

   This is a mistake. The file needs commas separating each field.

   I have the date and elev columns converted from factors to date and
numeric, respectively, but still have not learned how to convert the time.

   The source data file (head):
date,time,elev
2017-10-01,00:00,290.298
2017-10-01,00:30,290.301
2017-10-01,01:00,290.304
2017-10-01,01:30,290.295
2017-10-01,02:00,290.292
2017-10-01,02:30,290.289
2017-10-01,03:00,290.289
2017-10-01,03:30,290.289
2017-10-01,04:00,290.28

   These commands read the file and convert the date and elev columns:
wy2018 <- read.table('sh-2018.dat', header = T, sep = ',')
wy2018$date <- as.Date(as.character(wy2018$date, format='y-m-d'))
head(wy2018)
         date time    elev
1 2017-10-01   01 290.298
2 2017-10-01   01 290.301
3 2017-10-01   01 290.304
4 2017-10-01   01 290.295
5 2017-10-01   01 290.292
6 2017-10-01   01 290.289

   My attempts using chron() for the time column keep failing; e.g., 
wy2018$time <- chron(wy2018$time, format='h:m')
str(wy2018)
'data.frame':	12592 obs. of  3 variables:
  $ date: Date, format: "2017-10-01" "2017-10-01" ...
  $ time: 'dates' num  01 01 01 01 01 01 01 01 01 01 ...
   ..- attr(*, "format")= chr "h:m"
   ..- attr(*, "origin")= Named num  1 1 1970
   .. ..- attr(*, "names")= chr  "month" "day" "year"
  $ elev: num  290 290 290 290 290 ...

   Also, when I tried to use chron() for both the date and time columns of
the dataframe these failed, too.

   Please teach me how to read the data sources and produce dataframe columns
of date, time, and numeric.

Rich



From ccberry @end|ng |rom uc@d@edu  Thu Jul 19 21:10:47 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Thu, 19 Jul 2018 19:10:47 +0000
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
Message-ID: <1C451422-B23A-4760-ACDD-7BCE6BDBD51A@ucsd.edu>



> On Jul 18, 2018, at 1:55 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have daily precipitation data for 58 locations from 2005-01-01 through
> 2018-06-18.

So roughly 5000 observations of latitiude, longitude, elevation(?), and amount.

Maybe something dynamic like Hans Rosling does:

https://towardsdatascience.com/how-to-build-animated-charts-like-hans-rosling-doing-it-all-in-r-570efc6ba382

possibly smoothing temporally.

Googling `Hans Rosling R' and 'Dynamic Graphics in R' should get you some other hits including the Graphics Task View.

HTH,

Chuck


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 21:26:36 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 12:26:36 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <1C451422-B23A-4760-ACDD-7BCE6BDBD51A@ucsd.edu>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <1C451422-B23A-4760-ACDD-7BCE6BDBD51A@ucsd.edu>
Message-ID: <alpine.LNX.2.20.1807191225300.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Berry, Charles wrote:

> So roughly 5000 observations of latitiude, longitude, elevation(?), and
> amount.
>
> Maybe something dynamic like Hans Rosling does:
>
> https://towardsdatascience.com/how-to-build-animated-charts-like-hans-rosling-doing-it-all-in-r-570efc6ba382
>
> possibly smoothing temporally.
>
> Googling `Hans Rosling R' and 'Dynamic Graphics in R' should get you some
> other hits including the Graphics Task View.

Chuck,

   Thanks for the suggestion. I'll read the web page and look at the other
references you recommend.

Regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 21:33:11 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 12:33:11 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807191227100.15936@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, Rich Shepard wrote:

> I have the date and elev columns converted from factors to date and
> numeric, respectively, but still have not learned how to convert the time.

   With this dataframe structure,

str(wy2018)
'data.frame':	12592 obs. of  3 variables:
  $ date: Date, format: "2017-10-01" "2017-10-01" ...
  $ time: chr  "00:00" "00:30" "01:00" "01:30" ...
  $ elev: num  290 290 290 290 290 ...

what is my syntax error using chron() to convert the time column?

wy2018$time <- chron(times=wy2018$time)
Error in convert.times(times., fmt) : format h:m:s may be incorrect
In addition: Warning message:
In unpaste(times, sep = fmt$sep, fnames = fmt$periods, nfields = 3) :
   12592 entries set to NA due to wrong number of fields


   Adding a format as either %h:%m or just h:m makes no difference.

Rich



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 19 22:10:38 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 13:10:38 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
Message-ID: <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>


> On Jul 19, 2018, at 10:02 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 19 Jul 2018, Rich Shepard wrote:
> 
>> Since then I reformatted the file to two fields: date-time and elevation.
>> If anyone wants a copy send me a message off the list and I'll respond with
>> the modified file attached.
> 
>  This is a mistake. The file needs commas separating each field.
> 
>  I have the date and elev columns converted from factors to date and
> numeric, respectively, but still have not learned how to convert the time.
> 
>  The source data file (head):
> date,time,elev
> 2017-10-01,00:00,290.298
> 2017-10-01,00:30,290.301
> 2017-10-01,01:00,290.304
> 2017-10-01,01:30,290.295
> 2017-10-01,02:00,290.292
> 2017-10-01,02:30,290.289
> 2017-10-01,03:00,290.289
> 2017-10-01,03:30,290.289
> 2017-10-01,04:00,290.28

I took the code that I offered earlier and replaced allyears with wy2018:

> txt <- "date,time,elev
+ 2017-10-01,00:00,290.298
+ 2017-10-01,00:30,290.301
+ 2017-10-01,01:00,290.304
+ 2017-10-01,01:30,290.295
+ 2017-10-01,02:00,290.292
+ 2017-10-01,02:30,290.289
+ 2017-10-01,03:00,290.289
+ 2017-10-01,03:30,290.289

+ 2017-10-01,04:00,290.28"
> wy2018 <- read.table(text=txt, header = T, sep = ',')

> wy2018 $myDate <- as.Date(as.character(wy2018 $date))
> wy2018 $myTime <- as.POSIXct(paste(wy2018 $date, wy2018 $time))
> wy2018
        date  time    elev     myDate              myTime
1 2017-10-01 00:00 290.298 2017-10-01 2017-10-01 00:00:00
2 2017-10-01 00:30 290.301 2017-10-01 2017-10-01 00:30:00
3 2017-10-01 01:00 290.304 2017-10-01 2017-10-01 01:00:00
4 2017-10-01 01:30 290.295 2017-10-01 2017-10-01 01:30:00
5 2017-10-01 02:00 290.292 2017-10-01 2017-10-01 02:00:00
6 2017-10-01 02:30 290.289 2017-10-01 2017-10-01 02:30:00
7 2017-10-01 03:00 290.289 2017-10-01 2017-10-01 03:00:00
8 2017-10-01 03:30 290.289 2017-10-01 2017-10-01 03:30:00
9 2017-10-01 04:00 290.280 2017-10-01 2017-10-01 04:00:00

> str(wy2018)
'data.frame':	9 obs. of  5 variables:
 $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
 $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
 $ elev  : num  290 290 290 290 290 ...
 $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
 $ myTime: POSIXct, format: "2017-10-01 00:00:00" "2017-10-01 00:30:00" ...

> 
>  These commands read the file and convert the date and elev columns:
> wy2018 <- read.table('sh-2018.dat', header = T, sep = ',')
> wy2018$date <- as.Date(as.character(wy2018$date, format='y-m-d'))
> head(wy2018)
>        date time    elev
> 1 2017-10-01   01 290.298
> 2 2017-10-01   01 290.301
> 3 2017-10-01   01 290.304
> 4 2017-10-01   01 290.295
> 5 2017-10-01   01 290.292
> 6 2017-10-01   01 290.289
> 
>  My attempts using chron() for the time column keep failing; e.g., wy2018$time <- chron(wy2018$time, format='h:m')
> str(wy2018)
> 'data.frame':	12592 obs. of  3 variables:
> $ date: Date, format: "2017-10-01" "2017-10-01" ...
> $ time: 'dates' num  01 01 01 01 01 01 01 01 01 01 ...
>  ..- attr(*, "format")= chr "h:m"
>  ..- attr(*, "origin")= Named num  1 1 1970
>  .. ..- attr(*, "names")= chr  "month" "day" "year"
> $ elev: num  290 290 290 290 290 ...
> 
>  Also, when I tried to use chron() for both the date and time columns of
> the dataframe these failed, too.
> 
>  Please teach me how to read the data sources and produce dataframe columns
> of date, time, and numeric.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 19 22:20:36 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 13:20:36 -0700
Subject: [R] Read in data table, change columns from factors
In-Reply-To: <alpine.LNX.2.20.1807191227100.15936@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807191227100.15936@salmo.appl-ecosys.com>
Message-ID: <082D84D0-A9D0-487D-BAB7-1205B2784116@comcast.net>


> On Jul 19, 2018, at 12:33 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 19 Jul 2018, Rich Shepard wrote:
> 
>> I have the date and elev columns converted from factors to date and
>> numeric, respectively, but still have not learned how to convert the time.
> 
>  With this dataframe structure,
> 
> str(wy2018)
> 'data.frame':	12592 obs. of  3 variables:
> $ date: Date, format: "2017-10-01" "2017-10-01" ...
> $ time: chr  "00:00" "00:30" "01:00" "01:30" ...
> $ elev: num  290 290 290 290 290 ...
> 
> what is my syntax error using chron() to convert the time column?

I have no idea. I think reaching for chron is not needed.
> 
> wy2018$time <- chron(times=wy2018$time)
> Error in convert.times(times., fmt) : format h:m:s may be incorrect
> In addition: Warning message:
> In unpaste(times, sep = fmt$sep, fnames = fmt$periods, nfields = 3) :
>  12592 entries set to NA due to wrong number of fields

That error suggests you needed either to add ":00" on hte end of your hh:mm formated data or provide a format string.

> wy2018$myTime <- chron(times= paste(wy2018$time, ":00") )


> str(wy2018)
'data.frame':	9 obs. of  5 variables:
 $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
 $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
 $ elev  : num  290 290 290 290 290 ...
 $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
 $ myTime: 'times' num  00:00:00 00:30:00 01:00:00 01:30:00 02:00:00 ...
  ..- attr(*, "format")= chr "h:m:s"

But I think that is not the right way to go.

> 
> 
>  Adding a format as either %h:%m or just h:m makes no difference.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 22:21:54 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 13:21:54 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors [RESOLVED]
In-Reply-To: <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
Message-ID: <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, David Winsemius wrote:

> I took the code that I offered earlier and replaced allyears with wy2018:

>        date  time    elev     myDate              myTime
> 1 2017-10-01 00:00 290.298 2017-10-01 2017-10-01 00:00:00
> 2 2017-10-01 00:30 290.301 2017-10-01 2017-10-01 00:30:00
> 3 2017-10-01 01:00 290.304 2017-10-01 2017-10-01 01:00:00
> 4 2017-10-01 01:30 290.295 2017-10-01 2017-10-01 01:30:00
> 5 2017-10-01 02:00 290.292 2017-10-01 2017-10-01 02:00:00
> 6 2017-10-01 02:30 290.289 2017-10-01 2017-10-01 02:30:00
> 7 2017-10-01 03:00 290.289 2017-10-01 2017-10-01 03:00:00
> 8 2017-10-01 03:30 290.289 2017-10-01 2017-10-01 03:30:00
> 9 2017-10-01 04:00 290.280 2017-10-01 2017-10-01 04:00:00
>
>> str(wy2018)
> 'data.frame':	9 obs. of  5 variables:
> $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
> $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
> $ elev  : num  290 290 290 290 290 ...
> $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
> $ myTime: POSIXct, format: "2017-10-01 00:00:00" "2017-10-01 00:30:00" ...

David,

   Thank you. I see the results in the dataframe structure although I still
don't understand all the reasons. The 'myTime' column confirms what I
thought: that there is no separate time data type. I'll use what you taught
me an move on with the analyses.

Best regards,

Rich



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 19 23:01:33 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 14:01:33 -0700
Subject: [R] Read in data table, change columns from factors [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
 <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>
Message-ID: <ACBD0687-331F-4839-9DD3-4EB32BF634F3@comcast.net>


> On Jul 19, 2018, at 1:21 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 19 Jul 2018, David Winsemius wrote:
> 
>> I took the code that I offered earlier and replaced allyears with wy2018:
> 
>>       date  time    elev     myDate              myTime
>> 1 2017-10-01 00:00 290.298 2017-10-01 2017-10-01 00:00:00
>> 2 2017-10-01 00:30 290.301 2017-10-01 2017-10-01 00:30:00
>> 3 2017-10-01 01:00 290.304 2017-10-01 2017-10-01 01:00:00
>> 4 2017-10-01 01:30 290.295 2017-10-01 2017-10-01 01:30:00
>> 5 2017-10-01 02:00 290.292 2017-10-01 2017-10-01 02:00:00
>> 6 2017-10-01 02:30 290.289 2017-10-01 2017-10-01 02:30:00
>> 7 2017-10-01 03:00 290.289 2017-10-01 2017-10-01 03:00:00
>> 8 2017-10-01 03:30 290.289 2017-10-01 2017-10-01 03:30:00
>> 9 2017-10-01 04:00 290.280 2017-10-01 2017-10-01 04:00:00
>> 
>>> str(wy2018)
>> 'data.frame':	9 obs. of  5 variables:
>> $ date  : Factor w/ 1 level "2017-10-01": 1 1 1 1 1 1 1 1 1
>> $ time  : Factor w/ 9 levels "00:00","00:30",..: 1 2 3 4 5 6 7 8 9
>> $ elev  : num  290 290 290 290 290 ...
>> $ myDate: Date, format: "2017-10-01" "2017-10-01" ...
>> $ myTime: POSIXct, format: "2017-10-01 00:00:00" "2017-10-01 00:30:00" ...
> 
> David,
> 
>  Thank you. I see the results in the dataframe structure although I still
> don't understand all the reasons. The 'myTime' column confirms what I
> thought: that there is no separate time data type. I'll use what you taught
> me an move on with the analyses.

You can use format to only display the time portion of a datetime object. 

format( Sys.time(), "%H:%M")
[1] "13:57"

You can append the current date to a "time-only" character value and as.POSIXct will do that for you:

as.POSIXct("00:00", format="%H:%M")
[1] "2018-07-19 PDT"

> as.POSIXct(c("00:00", "00:01"), format="%H:%M")
[1] "2018-07-19 00:00:00 PDT" "2018-07-19 00:01:00 PDT"

There is a difftime-class in base R


And the lubridate package defines a duration class. It's not a package I use, and I cannot tell off the top of my head what it thinks the difference might be between a "time-span" and a "duration".

Best of luck.

> 
> Best regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 19 23:13:33 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 14:13:33 -0700 (PDT)
Subject: [R] Read in data table, change columns from factors [RESOLVED]
In-Reply-To: <ACBD0687-331F-4839-9DD3-4EB32BF634F3@comcast.net>
References: <alpine.LNX.2.20.1807181441440.30315@salmo.appl-ecosys.com>
 <131EC9AD-F4B2-4C95-911C-45B390AE6719@comcast.net>
 <alpine.LNX.2.20.1807181600290.30315@salmo.appl-ecosys.com>
 <D69EAA25-62F1-4B5F-BFFD-D12445611336@comcast.net>
 <alpine.LNX.2.20.1807181748300.9097@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190634080.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190906560.15936@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.1807190953570.15936@salmo.appl-ecosys.com>
 <CEE46DF0-7D19-4238-B720-FAD15385C0EB@comcast.net>
 <alpine.LNX.2.20.1807191317040.25236@salmo.appl-ecosys.com>
 <ACBD0687-331F-4839-9DD3-4EB32BF634F3@comcast.net>
Message-ID: <alpine.LNX.2.20.1807191408580.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, David Winsemius wrote:

> You can use format to only display the time portion of a datetime object.
> format( Sys.time(), "%H:%M")
> [1] "13:57"
> You can append the current date to a "time-only" character value and as.POSIXct will do that for you:
> as.POSIXct("00:00", format="%H:%M")
> [1] "2018-07-19 PDT"
> as.POSIXct(c("00:00", "00:01"), format="%H:%M")
> [1] "2018-07-19 00:00:00 PDT" "2018-07-19 00:01:00 PDT"

David,

   I read about these in my R books and on web pages. I kept looking for a
time data type analogous to as.Date, as.character, and as.numeric. That's
what sent me in the wrong direction.

> There is a difftime-class in base R And the lubridate package defines a
> duration class. It's not a package I use, and I cannot tell off the top of
> my head what it thinks the difference might be between a "time-span" and a
> "duration".

   Good to know for the future.

   BTW, in a much earlier response you questioned why there were highly
negative elevations. Good question, because those should have been NAs and I
don't know how I let them in the data I manually extracted from PDF reports
from the USGS.

Best regards,

Rich



From SW@y @end|ng |rom meco@com  Thu Jul 19 23:34:37 2018
From: SW@y @end|ng |rom meco@com (Shawn Way)
Date: Thu, 19 Jul 2018 21:34:37 +0000
Subject: [R] Solved: RE:  xtable does not print out units of a variable
Message-ID: <346b5d88bfa948248acfc2ba237a74ba@CTC-HOU-EXMB-02.ctcloud.local>

Jeff, John, 

Thanks for pointing out the information.  I found that the following works:


New function for deparsing the data:

deparse_unit_latex <- function(x,frac=TRUE,xtable.frac=FALSE)
{
    stopifnot(inherits(x, "units"))
    u = units(x)
    tn = table(u$numerator)
    nm1 = names(tn)
    vals1 = as.character(tn)
    vals1 <- paste("^",vals1,sep="")
    vals1[vals1 == "^1"] = ""
    td = table(u$denominator)
    nm2 = names(td)
    vals2 = as.character(td)
    vals2 <- paste("^",vals2,sep="")
    vals2[vals2 == "^1"] = ""
    if(frac == TRUE) {
        if (xtable.frac==FALSE) {
            if(is.null(nm1)) {
                res <- cat(paste(c("$\\frac{}{",paste0(nm2, vals2),"}$"), collapse = " "))
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- cat(paste(c("$\\frac{",paste0(nm1, vals1),"}{",paste0(nm2, vals2),"}$"), collapse = " ")) 
            }
        }
        if (xtable.frac == TRUE) {
            if(is.null(nm1)) {
                res <- paste(paste0("$\\frac{}{",paste0(nm2, vals2),"}$"), collapse = " ")
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- paste(paste0("$\\frac{",paste0(nm1, vals1),"}{",paste0(nm2, vals2),"}$"), collapse = " ") 
            }
        }
    }
    if(frac == FALSE) {
        if(xtable.frac == TRUE){
            if(is.null(nm1)) {
                res <- paste(c("$/",paste0(nm2, vals2),"$"), collapse = " ")
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- paste(c("$",paste0(nm1, vals1),"/",paste0(nm2, vals2),"$"), collapse = " ") 
            }
        }
        if(xtable.frac == FALSE){
            if(is.null(nm1)) {
                res <- paste(c("$/",paste0(nm2, vals2),"$"), collapse = " ")
            } else if(is.null(nm2)) {
                res <- paste(c("$",paste0(nm1, vals1),"$"), collapse = " ")
            } else {
                res <- paste(c("$",paste0(nm1, vals1),"/",paste0(nm2, vals2),"$"), collapse = " ") 
            }
        }
    }
    res
}

Modification to xtable:

xtable <- function(x, ...) {
    for (i in which(sapply(x, function(y) !all(is.na(match(c("POSIXt","Date"),class(y))))))) x[[i]] <- as.character(x[[i]])
    for (i in which(sapply(x, function(y) !all(is.na(match(c("units"),class(y))))))) x[[i]] <- as.character(paste(as.character(x[[i]]),deparse_unit_latex(x[[i]],...)))
    xtable::xtable(x, ...)
}

Finally:

data <- data.frame(x=c(as_units(12,"kg/(m*sec^2)")),y=c(as_units(13,"kg/sec")),z=c(as_units(13,"ft^2")),zz=c(as_units(13,"sec-1")))

print(xtable(data,frac=FALSE,xtable.frac=TRUE),sanitize.text.function = function(x){x})

% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Thu Jul 19 16:30:17 2018
\begin{table}[ht]
\centering
\begin{tabular}{rllll}
  \hline
 & x & y & z & zz \\ 
  \hline
1 & 12 $ kg / m s^2 $ & 13 $ kg / s $ & 13 $ ft^2 $ & 13 $/ s $ \\ 
   \hline
\end{tabular}
\end{table}
>


Or

> print(xtable(data,frac=TRUE,xtable.frac=TRUE),sanitize.text.function = function(x){x})
% latex table generated in R 3.5.1 by xtable 1.8-2 package
% Thu Jul 19 16:33:41 2018
\begin{table}[ht]
\centering
\begin{tabular}{rllll}
  \hline
 & x & y & z & zz \\ 
  \hline
1 & 12 $\frac{kg}{m}$ $\frac{kg}{s^2}$ & 13 $\frac{kg}{s}$ & 13 $ ft^2 $ & 13 $\frac{}{s}$ \\ 
   \hline
\end{tabular}
\end{table}
>


Thanks for all your help.

Shawn Way, PE


-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Wednesday, July 18, 2018 9:26 PM
To: Shawn Way <SWay at meco.com>
Cc: r-help at r-project.org
Subject: Re: [R] xtable does not print out units of a variable

On Wed, 18 Jul 2018, Shawn Way wrote:

> I have a dataframe that contains units using the units package. 
> Unfortunately, I really need the units for reporting.  I'm assuming 
> that's because the data is in a class units and xtable doesn't know 
> what to do with this.

If you want a bug or feature in a CONTRIBUTED PACKAGE, then you need to communicate with the maintainer:

maintainer( "xtable" )

Do keep in mind that they almost always volunteer their time, so be patient, and consider figuring out what code changes they need to make so it will work.

More below.

> The following is a MWE:
>
>    library(xtable)
>    library(units)
>    data <- data.frame(x=c(as_units(12,"ft")))
>    xtable(data)
>
>    % latex table generated in R 3.5.1 by xtable 1.8-2 package
>    % Wed Jul 18 17:31:44 2018
>    \begin{table}[ht]
>    \centering
>    \begin{tabular}{rr}
>      \hline
>     & x \\
>      \hline
>    1 & 12.00 \\
>      \hline
>    \end{tabular}
>    \end{table}
>
> What I'm looking for is the line
>
>    1 & 12.00 \\
>
> to be
>
>    1 & 12.00 $ft$\\
>
> Can someone point me in the correct direction to make this happen? 
> Since units are used extensively in engineering calculations, being 
> able to handle this class would be extremely beneficial to engineers 
> that are using R with knitr to generate engineering documents.
>
> Shawn Way

I do want to emphasize that R focuses on consistency among elements within columns, not rows, so putting the units into the body of the table is kind of visually redundant in most cases. Consider:

####################
library(xtable)
library(units)
#> udunits system database from /usr/share/xml/udunits data <- data.frame(x=c(as_units(c(12,13),"ft")))
datax <- xtable(data)
names(datax) <- paste0( names(datax)[1]
                       , " ($"
                       , deparse_unit( datax[[1]] )
                       , "$)"
                       )
datax
#> % latex table generated in R 3.4.4 by xtable 1.8-2 package #> % Wed Jul 18 19:13:29 2018 #> \begin{table}[ht] #> \centering #> \begin{tabular}{rr}
#>   \hline
#>  & x (\$ft\$) \\
#>   \hline
#> 1 & 12.00 \\
#>   2 & 13.00 \\
#>    \hline
#> \end{tabular}
#> \end{table}

#' Created on 2018-07-18 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
####################

If you have some kind of summary table with different units on each row, then you will probably arrive at that information a single-row, many column data frame. I usually transpose this into a three-column data frame with a description column, a value column, and a units column. I don't use the units package so have never tried to adapt it to that process.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 00:04:39 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 15:04:39 -0700 (PDT)
Subject: [R] Scripting a repeating work flow
Message-ID: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>

   I have 30 data files that all need to be read into R, formatted, and have
scatter plots prepared. This process can be done in a short script. I would
like to generalize the script so that variables (such as data file names)
can be read from another file and all files processed sequentially, similar
to a bash shell script repeating commands for all files in a directory.

   Looking at my R programming books I don't find a way to do this and would
appreciate pointers to multi-file script writing that can be run within R
using the source() function.

Rich



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jul 20 00:14:38 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 19 Jul 2018 15:14:38 -0700
Subject: [R] Scripting a repeating work flow
In-Reply-To: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>
Message-ID: <0BB94E46-E77C-492D-860C-AB07EE3C5668@comcast.net>


> On Jul 19, 2018, at 3:04 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I have 30 data files that all need to be read into R, formatted, and have
> scatter plots prepared. This process can be done in a short script. I would
> like to generalize the script so that variables (such as data file names)
> can be read from another file and all files processed sequentially, similar
> to a bash shell script repeating commands for all files in a directory.
> 
>  Looking at my R programming books I don't find a way to do this and would
> appreciate pointers to multi-file script writing that can be run within R
> using the source() function.

https://markmail.org/search/?q=list%3Aorg.r-project.r-help+script+process+multiple+csv+files

https://stackoverflow.com/questions/11433432/importing-multiple-csv-files-into-r

https://www.google.com/search?q=use+r+to+process+multiple+csv+files&oq=use+r+to+process+multiple+csv+files

> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From wjm1 @end|ng |rom c@@@co|umb|@@edu  Fri Jul 20 00:17:28 2018
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Thu, 19 Jul 2018 15:17:28 -0700
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
Message-ID: <CAA99HCw4yCauPffuEndQ6vL48t506hcNv00H_-Xk+cB-gfjObA@mail.gmail.com>

Hello, In addition to Duncan Mackay's excellent suggestion, I would
recommend Bert Gunter's "stripless" package, for high-density
Trellis-type conditioning plots. See the vignette for examples, and
try out the code for "earthquake" and "barley" plots from the
reference manual.

https://CRAN.R-project.org/package=stripless
https://cran.r-project.org/web/packages/stripless/vignettes/stripless_vignette.html

Sincerely,

W. Michels, Ph.D.

On Thu, Jul 19, 2018 at 6:37 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Rich
>
> Try something like this
>
> set.seed(1)
> xy <-
> data.frame(x = rnorm(108),
>            y = rnorm(108),
>            gp = rep(1:9, ea = 12))
>
>
> xyplot(y~x|gp, xy,
>        as.table = TRUE,
>        strip = F,
>        strip.left = F,
>        layout = c(3,3),
>        par.settings= list(layout.heights = list(main = 0,
>                                           axis.top = 0.3),
>                           plot.symbol = list(pch = ".",
>                                              col = "#000000",
>                                              cex = 3)
>                    ),
>        scales = list(x = list(alternating = FALSE,
>                               relation    = "same"),
>                      y = list(alternating = FALSE,
>                               relation    = "same")
>                  ),
>        panel = function(x,y, ...){
>
>                  panel.xyplot(x,y, ...)
>                  panel.text(-1, 2, paste("Group", 1:9)[which.packet()])
>
>                }
> )
>
> I have put over 60 panels on an A4 page.
> You may have to put an if statement for the group names if they overlap
> data.
> Space is a premium - you can reduce the right margin similar to the top see
> ?trellis.par.get()
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2350
>
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
> Sent: Thursday, 19 July 2018 06:55
> To: r-help at r-project.org
> Subject: [R] Suggestions for scatter plot of many data
>
>    I have daily precipitation data for 58 locations from 2005-01-01 through
> 2018-06-18. Among other plots and analyses I want to apply lattice's
> xyplot() to illustrate the abundance and patterns of the data.
>
>    I've used a vector of colors (and a key) when there were only eight
> weather stations and the date range was three months. This was very
> effective in communicating the amounts and patterns.
>
>    I'm asking for ideas on how to best present these data in a scatter plot.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 00:53:19 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 15:53:19 -0700 (PDT)
Subject: [R] Scripting a repeating work flow
In-Reply-To: <0BB94E46-E77C-492D-860C-AB07EE3C5668@comcast.net>
References: <alpine.LNX.2.20.1807191455460.25236@salmo.appl-ecosys.com>
 <0BB94E46-E77C-492D-860C-AB07EE3C5668@comcast.net>
Message-ID: <alpine.LNX.2.20.1807191552310.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, David Winsemius wrote:

> https://markmail.org/search/?q=list%3Aorg.r-project.r-help+script+process+multiple+csv+files
> https://stackoverflow.com/questions/11433432/importing-multiple-csv-files-into-r
> https://www.google.com/search?q=use+r+to+process+multiple+csv+files&oq=use+r+to+process+multiple+csv+files

   Thanks, David. My search terms missed these.

Best regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 00:55:09 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 19 Jul 2018 15:55:09 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <CAA99HCw4yCauPffuEndQ6vL48t506hcNv00H_-Xk+cB-gfjObA@mail.gmail.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
 <CAA99HCw4yCauPffuEndQ6vL48t506hcNv00H_-Xk+cB-gfjObA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807191554020.25236@salmo.appl-ecosys.com>

On Thu, 19 Jul 2018, William Michels wrote:

> Hello, In addition to Duncan Mackay's excellent suggestion, I would
> recommend Bert Gunter's "stripless" package, for high-density Trellis-type
> conditioning plots. See the vignette for examples, and try out the code
> for "earthquake" and "barley" plots from the reference manual.
>
> https://CRAN.R-project.org/package=stripless
> https://cran.r-project.org/web/packages/stripless/vignettes/stripless_vignette.html

William,

   Very much appreciated. I'll certainly look closely at the package.

Best regards,

Rich



From t@v|b@r @end|ng |rom gm@||@com  Fri Jul 20 12:15:23 2018
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Fri, 20 Jul 2018 13:15:23 +0300
Subject: [R] scatter plot coloring problem
Message-ID: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>

Hello:

I have two data frames (subsetted from a larger one). I am plotting 
scatterplots with ggplot2 and coloring by different variables. When 
using one of the variables "Error" with one of the dataframes "conv_df" 
only a single color is displayed. All the other variables show colors as 
expected, and when applying the same ggplot() functions to the second 
dataframe, colors are correctly applied for all variables.

I'm scratching me head over this for some time. Maybe someone can see 
what I'm missing?

My repex is attached

Thanks

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 20 12:28:25 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 20 Jul 2018 03:28:25 -0700
Subject: [R] scatter plot coloring problem
In-Reply-To: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
Message-ID: <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>

Nothing attached. The mail server strips most attachments for security.

See the posting guide below and ?dput for how to include data.
+ We need your faulty code also, of course.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 20, 2018 at 3:15 AM, Micha Silver <tsvibar at gmail.com> wrote:

> Hello:
>
> I have two data frames (subsetted from a larger one). I am plotting
> scatterplots with ggplot2 and coloring by different variables. When using
> one of the variables "Error" with one of the dataframes "conv_df" only a
> single color is displayed. All the other variables show colors as expected,
> and when applying the same ggplot() functions to the second dataframe,
> colors are correctly applied for all variables.
>
> I'm scratching me head over this for some time. Maybe someone can see what
> I'm missing?
>
> My repex is attached
>
> Thanks
>
> --
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From t@v|b@r @end|ng |rom gm@||@com  Fri Jul 20 13:01:33 2018
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Fri, 20 Jul 2018 14:01:33 +0300
Subject: [R] scatter plot coloring problem
In-Reply-To: <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
 <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
Message-ID: <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>



On 07/20/2018 01:28 PM, Bert Gunter wrote:
> Nothing attached. The mail server strips most attachments for security.

Here is my repex, inline:

library(ggplot2)

conv_df <- structure(list(Adjustment = structure(c(1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 
1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????? 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L,
 ??????????????????????????????????????? 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 
1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????? 5L), .Label = c("Radar", 
"MeanFieldBias", "Multiplicative", "Mixed",
"ConditionalMerge"), class = "factor"), Struct = c("Bias only",
"Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error")), .Names = c("Adjustment",
"Struct", "Error"), row.names = c(1L, 3L, 4L, 5L, 6L, 11L, 13L,
14L, 15L, 16L, 21L, 23L, 24L, 25L, 26L, 31L, 33L, 34L, 35L, 36L,
41L, 43L, 44L, 45L, 46L, 51L, 53L, 54L, 55L, 56L, 61L, 63L, 64L,
65L, 66L, 71L, 73L, 74L, 75L, 76L, 81L, 83L, 84L, 85L, 86L, 91L,
93L, 94L, 95L, 96L, 101L, 103L, 104L, 105L, 106L, 111L, 113L,
114L, 115L, 116L, 121L, 123L, 124L, 125L, 126L, 131L, 133L, 134L,
135L, 136L, 141L, 143L, 144L, 145L, 146L, 151L, 153L, 154L, 155L,
156L, 161L, 163L, 164L, 165L, 166L, 171L, 173L, 174L, 175L, 176L,
181L, 183L, 184L, 185L, 186L, 191L, 193L, 194L, 195L, 196L, 201L,
203L, 204L, 205L, 206L, 211L, 213L, 214L, 215L, 216L, 221L, 223L,
224L, 225L, 226L, 231L, 233L, 234L, 235L, 236L, 241L, 243L, 244L,
245L, 246L, 251L, 253L, 254L, 255L, 256L, 261L, 263L, 264L, 265L,
266L), class = "data.frame")

strat_df <- structure(list(Adjustment = structure(c(1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????????????????? 5L, 1L, 2L, 3L, 4L, 
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L,
 ??????????????????????????????????????????????????? 1L, 2L, 3L, 4L, 5L, 
1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L,
 ??????????????????????????????????????????????????? 2L, 3L, 4L, 5L, 1L, 
2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L,
 ??????????????????????????????????????????????????? 3L, 4L, 5L, 1L, 2L, 
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L,
 ??????????????????????????????????????????????????? 4L, 5L, 1L, 2L, 3L, 
4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L,
 ??????????????????????????????????????????????????? 5L), .Label = 
c("Radar", "MeanFieldBias", "Multiplicative", "Mixed",
"ConditionalMerge"), class = "factor"), Struct = c("Bias only",
"Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error")), .Names = c("Adjustment",
"Struct", "Error"), row.names = c(2L, 7L, 8L, 9L, 10L, 12L, 17L,
18L, 19L, 20L, 22L, 27L, 28L, 29L, 30L, 32L, 37L, 38L, 39L, 40L,
42L, 47L, 48L, 49L, 50L, 52L, 57L, 58L, 59L, 60L, 62L, 67L, 68L,
69L, 70L, 72L, 77L, 78L, 79L, 80L, 82L, 87L, 88L, 89L, 90L, 92L,
97L, 98L, 99L, 100L, 102L, 107L, 108L, 109L, 110L, 112L, 117L,
118L, 119L, 120L, 122L, 127L, 128L, 129L, 130L, 132L, 137L, 138L,
139L, 140L, 142L, 147L, 148L, 149L, 150L, 152L, 157L, 158L, 159L,
160L, 162L, 167L, 168L, 169L, 170L, 172L, 177L, 178L, 179L, 180L,
182L, 187L, 188L, 189L, 190L, 192L, 197L, 198L, 199L, 200L, 202L,
207L, 208L, 209L, 210L, 212L, 217L, 218L, 219L, 220L, 222L, 227L,
228L, 229L, 230L, 232L, 237L, 238L, 239L, 240L, 242L, 247L, 248L,
249L, 250L, 252L, 257L, 258L, 259L, 260L, 262L, 267L, 268L, 269L,
270L), class = "data.frame")

ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct, shape=Adjustment), size=6)

ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error, shape=Adjustment), size=6)

ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct, shape=Adjustment), size=6)

ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error, shape=Adjustment), size=6)


>
> See the posting guide below and ?dput for how to include data.
> + We need your faulty code also, of course.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Jul 20, 2018 at 3:15 AM, Micha Silver <tsvibar at gmail.com 
> <mailto:tsvibar at gmail.com>> wrote:
>
>     Hello:
>
>     I have two data frames (subsetted from a larger one). I am
>     plotting scatterplots with ggplot2 and coloring by different
>     variables. When using one of the variables "Error" with one of the
>     dataframes "conv_df" only a single color is displayed. All the
>     other variables show colors as expected, and when applying the
>     same ggplot() functions to the second dataframe, colors are
>     correctly applied for all variables.
>
>     I'm scratching me head over this for some time. Maybe someone can
>     see what I'm missing?
>
>     My repex is attached
>
>     Thanks
>
>     -- 
>     Micha Silver
>     Ben Gurion Univ.
>     Sde Boker, Remote Sensing Lab
>     cell: +972-523-665918
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918



From t@v|b@r @end|ng |rom gm@||@com  Fri Jul 20 13:27:36 2018
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Fri, 20 Jul 2018 14:27:36 +0300
Subject: [R] scatter plot coloring problem
In-Reply-To: <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
 <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
 <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>
Message-ID: <073a0ba1-f267-b7f2-7fa5-83c237e44db1@gmail.com>



On 07/20/2018 02:01 PM, Micha Silver wrote:
>
>
> On 07/20/2018 01:28 PM, Bert Gunter wrote:
>> Nothing attached. The mail server strips most attachments for security.

Here is a (slightly shorter) repex.
The fourth plot shows the problem. The first three are as expected.

library(ggplot2)

strat_df <- structure(list(Slope = c(1.15639473681994, 0.972278300619073,
 ???????????????????????????????????? 1.14313365332712, 
1.14399372216612, 1.22529134790727, 2.14326711679831,
 ???????????????????????????????????? 0.54859156211142, 
1.17046713623601, 1.17453878322687, 3.31323770780669,
 ???????????????????????????????????? 0.966673750291528, 
0.746319725592914, 1.02480114419885, 1.0229752524756,
 ???????????????????????????????????? 1.00132723720128, 
1.15639473681994, 0.972278300619073, 1.14313365332712,
 ???????????????????????????????????? 1.14399372216612, 
1.22529134790727, 2.14326711679831, 0.54859156211142,
 ???????????????????????????????????? 1.17046713623601, 
1.17453878322687, 3.31323770780669, 0.966673750291528,
 ???????????????????????????????????? 0.746319725592914, 
1.02480114419885, 1.0229752524756, 1.00132723720128,
 ???????????????????????????????????? 1.15639473681994, 
0.972278300619073, 1.14313365332712, 1.14399372216612,
 ???????????????????????????????????? 1.22529134790727, 
2.14326711679831, 0.54859156211142, 1.17046713623601,
 ???????????????????????????????????? 1.17453878322687, 
3.31323770780669, 0.966673750291528, 0.746319725592914,
 ???????????????????????????????????? 1.02480114419885, 1.0229752524756, 
1.00132723720128, 1.00564012971235,
 ???????????????????????????????????? 0.781822304249351, 
0.793232303666035, 0.798538338102623, 1.20657643535607,
 ???????????????????????????????????? 2.16318241002351, 
1.42268702026443, 0.812412401599228, 0.817089629984966,
 ???????????????????????????????????? 3.27413789688355, 
0.840735716836696, 0.629583577106973, 0.710708013029288,
 ???????????????????????????????????? 0.714002133616219, 
0.985501434987176, 1.03494070727933, 0.956962513783496,
 ???????????????????????????????????? 0.793549829222589, 
0.798851646709461, 1.20660885706037, 2.18674952848921,
 ???????????????????????????????????? 1.5634217520085, 0.81273050967827, 
0.817407079251797, 3.27417031858785,
 ???????????????????????????????????? 0.877344267863596, 
0.848664941338144, 0.710978765510023, 0.714268901361411,
 ???????????????????????????????????? 0.985533856691474, 
1.03983096388345, 0.985084623809766, 0.794138608594684,
 ???????????????????????????????????? 0.79943259180892, 
1.20665856218731, 2.21336885559571, 1.72189603514386,
 ???????????????????????????????????? 0.813327118056704, 
0.818002445250057, 3.27422002371479, 0.877473770321168,
 ???????????????????????????????????? 0.848389484199237, 
0.711483989718558, 0.714766443910276, 0.985583561818414
), Intercept = c(-1.0892464119326, 0.246565490954958, -1.1639008288321,
 ???????????????? -1.17146025612969, -1.93566050996642, 
-3.96706179209372, 3.9202695728101,
 ???????????????? -1.04771345550341, -1.07809518302298, 
-19.7820283549024, 0.36822137463493,
 ???????????????? 2.207658818211, -0.016876438597312, 
-0.00842619567899302, 0.0306144651329568,
 ???????????????? -1.0892464119326, 0.246565490954958, -1.1639008288321, 
-1.17146025612969,
 ???????????????? -1.93566050996642, -3.96706179209372, 3.9202695728101, 
-1.04771345550341,
 ???????????????? -1.07809518302298, -19.7820283549024, 
0.36822137463493, 2.207658818211,
 ???????????????? -0.016876438597312, -0.00842619567899302, 
0.0306144651329568,
 ???????????????? -1.0892464119326, 0.246565490954958, -1.1639008288321, 
-1.17146025612969,
 ???????????????? -1.93566050996642, -3.96706179209372, 3.9202695728101, 
-1.04771345550341,
 ???????????????? -1.07809518302298, -19.7820283549024, 
0.36822137463493, 2.207658818211,
 ???????????????? -0.016876438597312, -0.00842619567899302, 
0.0306144651329568,
 ???????????????? -1.42588814587741, -0.0938807577163176, 
-0.760427987439108, -0.802681471353857,
 ???????????????? -4.38731629113287, -4.72258266663199, 
1.08443985346667, -0.679055757307681,
 ???????????????? -0.713928732007598, -22.2121480319997, 
-0.187477151457156, 1.28512191810652,
 ???????????????? 0.0386762170827232, 0.00928219285158222, 
-2.45430083552569, -1.5052623193495,
 ???????????????? -0.571094020563348, -0.760898951384971, 
-0.80312079180565, -4.38543778472072,
 ???????????????? -4.74043340113669, 0.976337655364814, 
-0.679498378418568, -0.714366826235178,
 ???????????????? -22.2102695255875, -0.264069816907669, 
0.823783304969757, 0.0386132206604378,
 ???????????????? 0.00924930329540931, -2.45242232911355, 
-1.5204762452006, -0.664489263100851,
 ???????????????? -0.761704010560802, -0.803866601426402, 
-4.38177522849324, -4.78366916314869,
 ???????????????? 0.714779631860822, -0.68026224065537, 
-0.715122068793879, -22.20660696936,
 ???????????????? -0.262931522643713, 0.827039881514761, 
0.0385397097353969, 0.00923344703169212,
 ???????????????? -2.44875977288606), Struct = c("Bias only", "Bias 
only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"Bias only", "Bias only", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Lognormal 
error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "Bias only", "Bias 
only", "Bias only", "Bias only", "Bias only",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "Lognormal error dist.",
 ??????????????????????????????????????????????? "Lognormal error 
dist.", "Lognormal error dist.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct.", 
"FFT-based struct.", "FFT-based struct.",
 ??????????????????????????????????????????????? "FFT-based struct."), 
Error = c("Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error"
 ??????????????????????????????????????????????? )), .Names = c("Slope", 
"Intercept", "Struct", "Error"), row.names = c(2L,
7L, 8L, 9L, 10L, 12L, 17L, 18L, 19L, 20L, 22L, 27L, 28L, 29L,
30L, 32L, 37L, 38L, 39L, 40L, 42L, 47L, 48L, 49L, 50L, 52L, 57L,
58L, 59L, 60L, 62L, 67L, 68L, 69L, 70L, 72L, 77L, 78L, 79L, 80L,
82L, 87L, 88L, 89L, 90L, 92L, 97L, 98L, 99L, 100L, 102L, 107L,
108L, 109L, 110L, 112L, 117L, 118L, 119L, 120L, 122L, 127L, 128L,
129L, 130L, 132L, 137L, 138L, 139L, 140L, 142L, 147L, 148L, 149L,
150L, 152L, 157L, 158L, 159L, 160L, 162L, 167L, 168L, 169L, 170L,
172L, 177L, 178L, 179L, 180L), class = "data.frame")
conv_df <- structure(list(Slope = c(1.04807118675076, 0.998948448847309,
 ??????????????????????????????????? 0.999431048648743, 
1.06271129629311, 1.07572617384751, 2.22760090861169,
 ??????????????????????????????????? 0.932482182264868, 
1.02936746325801, 2.52988042582817, 2.95633562179131,
 ??????????????????????????????????? 18.8227507300988, 
0.974588681842621, 108.07393074932, 0.870832606501646,
 ??????????????????????????????????? 1.00567956715787, 1.04807118675076, 
0.998948448847309, 0.999431048648743,
 ??????????????????????????????????? 1.06271129629311, 1.07572617384751, 
2.22760090861169, 0.932482182264868,
 ??????????????????????????????????? 1.02936746325801, 2.52988042582817, 
2.95633562179131, 18.8227507300988,
 ??????????????????????????????????? 0.974588681842621, 108.07393074932, 
0.870832606501646, 1.00567956715787,
 ??????????????????????????????????? 1.04807118675076, 
0.998948448847309, 0.999431048648743, 1.06271129629311,
 ??????????????????????????????????? 1.07572617384751, 2.22760090861169, 
0.932482182264868, 1.02936746325801,
 ??????????????????????????????????? 2.52988042582817, 2.95633562179131, 
18.8227507300988, 0.974588681842621,
 ??????????????????????????????????? 108.07393074932, 0.870832606501646, 
1.00567956715787, 0.938306957617447,
 ??????????????????????????????????? 0.696202687574185, 
0.698287792550519, 1.01157976748338, 1.07216134522869,
 ??????????????????????????????????? 2.11775044458303, 
0.658564756192898, 0.718936009019651, 2.46328731519796,
 ??????????????????????????????????? 2.94817482855984, 13.4010203977042, 
0.758075017209242, 75.8087725102359,
 ??????????????????????????????????? 0.825432059460383, 
1.00237002354864, 0.93840246618556, 0.696484580425202,
 ??????????????????????????????????? 0.698549805163105, 
1.01161728893021, 1.07215296972693, 2.11785160868381,
 ??????????????????????????????????? 0.658846969311393, 
0.719217656820784, 2.46333881438479, 2.94816645305808,
 ??????????????????????????????????? 13.4028764261544, 
0.758261665458076, 75.8196908351967, 0.82547163245355,
 ??????????????????????????????????? 1.00236164804689, 
0.938596807939808, 0.697064148960971, 0.699062697365857,
 ??????????????????????????????????? 1.01169996923602, 1.07214387920809, 
2.11805571501552, 0.659427992302351,
 ??????????????????????????????????? 0.719759915668507, 
2.46344926105519, 2.94815736253924, 13.4060642247861,
 ??????????????????????????????????? 0.758655662542348, 
75.8383487496718, 0.825555603203494, 1.00235255752804
), Intercept = c(-0.017716276271862, 0.000961091319158938, 
-0.000703510322277703,
 ???????????????? -0.00845866525088005, -0.0966678762281092, 
-0.389386368120609,
 ???????????????? 0.068730059320282, 0.0367676804603267, 
-0.0134454494180847, -2.61898714802878,
 ???????????????? -7.30136425060206, -0.21274280699377, 
-43.1291289782452, -0.125688969456484,
 ???????????????? -0.307472718728007, -0.017716276271862, 
0.000961091319158938,
 ???????????????? -0.000703510322277703, -0.00845866525088005, 
-0.0966678762281092,
 ???????????????? -0.389386368120609, 0.068730059320282, 
0.0367676804603267, -0.0134454494180847,
 ???????????????? -2.61898714802878, -7.30136425060206, 
-0.21274280699377, -43.1291289782452,
 ???????????????? -0.125688969456484, -0.307472718728007, 
-0.017716276271862, 0.000961091319158938,
 ???????????????? -0.000703510322277703, -0.00845866525088005, 
-0.0966678762281092,
 ???????????????? -0.389386368120609, 0.068730059320282, 
0.0367676804603267, -0.0134454494180847,
 ???????????????? -2.61898714802878, -7.30136425060206, 
-0.21274280699377, -43.1291289782452,
 ???????????????? -0.125688969456484, -0.307472718728007, 
-0.0859314660447012,
 ???????????????? 0.0135310033957625, -3.43619764283222e-05, 
-0.0523622551444108,
 ???????????????? -0.475294485394066, -0.460272581935994, 
0.0625183970346825, 0.0262518388075903,
 ???????????????? -0.0839509467307793, -2.95707142967006, 
-5.52875677718304, -0.152998423411686,
 ???????????????? -32.1368671911073, -0.164063261306885, 
-0.685459757083477, -0.0858163634696177,
 ???????????????? 0.01352935620949, 9.46328483051025e-05, 
-0.052203322505647, -0.47489015022079,
 ???????????????? -0.460135002763724, 0.0626429365104076, 
0.02640499766902, -0.0838075052075929,
 ???????????????? -2.95666709449679, -5.52852300483326, 
-0.153159000797531, -32.135862357057,
 ???????????????? -0.163909219046001, -0.685055421910201, 
-0.0856060516008676,
 ???????????????? 0.0135479894875152, 0.000302270025863519, 
-0.0519314642867551,
 ???????????????? -0.474126407682765, -0.45988984866136, 
0.0628609678242435, 0.026651390571036,
 ???????????????? -0.0835647473472818, -2.95590335195876, 
-5.52851009407545, -0.153425312176928,
 ???????????????? -32.1365449540903, -0.163646588624356, 
-0.684291679372176), Struct = c("Bias only",
"Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
"Bias only", "Bias only", "Bias only", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
"Bias only", "Lognormal error dist.", "Lognormal error dist.",
"Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
"FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
"FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Low CML error",
"Low CML error", "Low CML error", "Low CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "Med CML error", "Med CML error",
"Med CML error", "Med CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error", "High CML error", "High CML error", "High CML error",
"High CML error")), .Names = c("Slope", "Intercept", "Struct",
"Error"), row.names = c(1L, 3L, 4L, 5L, 6L, 11L, 13L, 14L, 15L,
16L, 21L, 23L, 24L, 25L, 26L, 31L, 33L, 34L, 35L, 36L, 41L, 43L,
44L, 45L, 46L, 51L, 53L, 54L, 55L, 56L, 61L, 63L, 64L, 65L, 66L,
71L, 73L, 74L, 75L, 76L, 81L, 83L, 84L, 85L, 86L, 91L, 93L, 94L,
95L, 96L, 101L, 103L, 104L, 105L, 106L, 111L, 113L, 114L, 115L,
116L, 121L, 123L, 124L, 125L, 126L, 131L, 133L, 134L, 135L, 136L,
141L, 143L, 144L, 145L, 146L, 151L, 153L, 154L, 155L, 156L, 161L,
163L, 164L, 165L, 166L, 171L, 173L, 174L, 175L, 176L), class = "data.frame")


pl.strat.1 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct),size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

pl.strat.2 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error), size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

pl.conv.1 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Struct), size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

pl.conv.2 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
 ? geom_point(aes(color=Error), size=4) +
 ? scale_y_continuous(limits=c(0.3, 3.0)) +
 ? scale_x_continuous(limits=c(-7, 7))

print(pl.strat.1)
print(pl.strat.2)
print(pl.conv.1)
print(pl.conv.2)


>
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918



From petr@p|k@| @end|ng |rom prechez@@cz  Fri Jul 20 14:16:04 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 20 Jul 2018 12:16:04 +0000
Subject: [R] scatter plot coloring problem
In-Reply-To: <073a0ba1-f267-b7f2-7fa5-83c237e44db1@gmail.com>
References: <c168a528-2dd1-3d1d-66c3-1f7cbada4ac1@gmail.com>
 <CAGxFJbRm-cbGkivFUF53K6bOCf+hF_bGS_UdR2qK92cYReL7Ng@mail.gmail.com>
 <13202f1c-20eb-b74a-e879-c3aad5bede6a@gmail.com>
 <073a0ba1-f267-b7f2-7fa5-83c237e44db1@gmail.com>
Message-ID: <49b19ebf86a84211ba1f1aa01916756e@SRVEXCHCM1302.precheza.cz>

Hi

Values in conv_df are almost same for each Error level

> aggregate(conv_df$Intercept, list(conv_df$Error), mean)
         Group.1         x
1 High CML error -3.226313
2  Low CML error -3.226536
3  Med CML error -3.226422
> aggregate(conv_df$Slope, list(conv_df$Error), mean)
         Group.1        x
1 High CML error 8.325558
2  Low CML error 8.324242
3  Med CML error 8.324721
> boxplot(split(conv_df$Slope, conv_df$Error))
> boxplot(split(conv_df$Intercept, conv_df$Error))
>

so points in ggplot are overplotted and only colour for last plotted level is visible.

Cheers
Petr

> On 07/20/2018 02:01 PM, Micha Silver wrote:
> >
> >
> > On 07/20/2018 01:28 PM, Bert Gunter wrote:
> >> Nothing attached. The mail server strips most attachments for security.
>
> Here is a (slightly shorter) repex.
> The fourth plot shows the problem. The first three are as expected.
>
> library(ggplot2)
>
> strat_df <- structure(list(Slope = c(1.15639473681994, 0.972278300619073,
>                                       1.14313365332712,
> 1.14399372216612, 1.22529134790727, 2.14326711679831,
>                                       0.54859156211142,
> 1.17046713623601, 1.17453878322687, 3.31323770780669,
>                                       0.966673750291528,
> 0.746319725592914, 1.02480114419885, 1.0229752524756,
>                                       1.00132723720128,
> 1.15639473681994, 0.972278300619073, 1.14313365332712,
>                                       1.14399372216612,
> 1.22529134790727, 2.14326711679831, 0.54859156211142,
>                                       1.17046713623601,
> 1.17453878322687, 3.31323770780669, 0.966673750291528,
>                                       0.746319725592914,
> 1.02480114419885, 1.0229752524756, 1.00132723720128,
>                                       1.15639473681994,
> 0.972278300619073, 1.14313365332712, 1.14399372216612,
>                                       1.22529134790727,
> 2.14326711679831, 0.54859156211142, 1.17046713623601,
>                                       1.17453878322687,
> 3.31323770780669, 0.966673750291528, 0.746319725592914,
>                                       1.02480114419885, 1.0229752524756,
> 1.00132723720128, 1.00564012971235,
>                                       0.781822304249351,
> 0.793232303666035, 0.798538338102623, 1.20657643535607,
>                                       2.16318241002351,
> 1.42268702026443, 0.812412401599228, 0.817089629984966,
>                                       3.27413789688355,
> 0.840735716836696, 0.629583577106973, 0.710708013029288,
>                                       0.714002133616219,
> 0.985501434987176, 1.03494070727933, 0.956962513783496,
>                                       0.793549829222589,
> 0.798851646709461, 1.20660885706037, 2.18674952848921,
>                                       1.5634217520085, 0.81273050967827,
> 0.817407079251797, 3.27417031858785,
>                                       0.877344267863596,
> 0.848664941338144, 0.710978765510023, 0.714268901361411,
>                                       0.985533856691474,
> 1.03983096388345, 0.985084623809766, 0.794138608594684,
>                                       0.79943259180892,
> 1.20665856218731, 2.21336885559571, 1.72189603514386,
>                                       0.813327118056704,
> 0.818002445250057, 3.27422002371479, 0.877473770321168,
>                                       0.848389484199237,
> 0.711483989718558, 0.714766443910276, 0.985583561818414
> ), Intercept = c(-1.0892464119326, 0.246565490954958, -1.1639008288321,
>                   -1.17146025612969, -1.93566050996642,
> -3.96706179209372, 3.9202695728101,
>                   -1.04771345550341, -1.07809518302298,
> -19.7820283549024, 0.36822137463493,
>                   2.207658818211, -0.016876438597312,
> -0.00842619567899302, 0.0306144651329568,
>                   -1.0892464119326, 0.246565490954958, -1.1639008288321,
> -1.17146025612969,
>                   -1.93566050996642, -3.96706179209372, 3.9202695728101,
> -1.04771345550341,
>                   -1.07809518302298, -19.7820283549024,
> 0.36822137463493, 2.207658818211,
>                   -0.016876438597312, -0.00842619567899302,
> 0.0306144651329568,
>                   -1.0892464119326, 0.246565490954958, -1.1639008288321,
> -1.17146025612969,
>                   -1.93566050996642, -3.96706179209372, 3.9202695728101,
> -1.04771345550341,
>                   -1.07809518302298, -19.7820283549024,
> 0.36822137463493, 2.207658818211,
>                   -0.016876438597312, -0.00842619567899302,
> 0.0306144651329568,
>                   -1.42588814587741, -0.0938807577163176,
> -0.760427987439108, -0.802681471353857,
>                   -4.38731629113287, -4.72258266663199,
> 1.08443985346667, -0.679055757307681,
>                   -0.713928732007598, -22.2121480319997,
> -0.187477151457156, 1.28512191810652,
>                   0.0386762170827232, 0.00928219285158222,
> -2.45430083552569, -1.5052623193495,
>                   -0.571094020563348, -0.760898951384971,
> -0.80312079180565, -4.38543778472072,
>                   -4.74043340113669, 0.976337655364814,
> -0.679498378418568, -0.714366826235178,
>                   -22.2102695255875, -0.264069816907669,
> 0.823783304969757, 0.0386132206604378,
>                   0.00924930329540931, -2.45242232911355,
> -1.5204762452006, -0.664489263100851,
>                   -0.761704010560802, -0.803866601426402,
> -4.38177522849324, -4.78366916314869,
>                   0.714779631860822, -0.68026224065537,
> -0.715122068793879, -22.20660696936,
>                   -0.262931522643713, 0.827039881514761,
> 0.0385397097353969, 0.00923344703169212,
>                   -2.44875977288606), Struct = c("Bias only", "Bias
> only", "Bias only",
>                                                  "Bias only", "Bias
> only", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only",
>                                                  "Bias only", "Bias
> only", "Bias only", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "Bias only", "Bias
> only", "Bias only", "Bias only", "Bias only",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "Bias only", "Bias only", "Bias only", "Bias only",
>                                                  "Bias only", "Lognormal
> error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only",
>                                                  "Bias only", "Bias
> only", "Bias only", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "Bias only", "Bias
> only", "Bias only", "Bias only", "Bias only",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "Lognormal error dist.",
>                                                  "Lognormal error
> dist.", "Lognormal error dist.", "FFT-based struct.",
>                                                  "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.",
>                                                  "FFT-based struct."),
> Error = c("Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error"
>                                                  )), .Names = c("Slope",
> "Intercept", "Struct", "Error"), row.names = c(2L,
> 7L, 8L, 9L, 10L, 12L, 17L, 18L, 19L, 20L, 22L, 27L, 28L, 29L,
> 30L, 32L, 37L, 38L, 39L, 40L, 42L, 47L, 48L, 49L, 50L, 52L, 57L,
> 58L, 59L, 60L, 62L, 67L, 68L, 69L, 70L, 72L, 77L, 78L, 79L, 80L,
> 82L, 87L, 88L, 89L, 90L, 92L, 97L, 98L, 99L, 100L, 102L, 107L,
> 108L, 109L, 110L, 112L, 117L, 118L, 119L, 120L, 122L, 127L, 128L,
> 129L, 130L, 132L, 137L, 138L, 139L, 140L, 142L, 147L, 148L, 149L,
> 150L, 152L, 157L, 158L, 159L, 160L, 162L, 167L, 168L, 169L, 170L,
> 172L, 177L, 178L, 179L, 180L), class = "data.frame")
> conv_df <- structure(list(Slope = c(1.04807118675076, 0.998948448847309,
>                                      0.999431048648743,
> 1.06271129629311, 1.07572617384751, 2.22760090861169,
>                                      0.932482182264868,
> 1.02936746325801, 2.52988042582817, 2.95633562179131,
>                                      18.8227507300988,
> 0.974588681842621, 108.07393074932, 0.870832606501646,
>                                      1.00567956715787, 1.04807118675076,
> 0.998948448847309, 0.999431048648743,
>                                      1.06271129629311, 1.07572617384751,
> 2.22760090861169, 0.932482182264868,
>                                      1.02936746325801, 2.52988042582817,
> 2.95633562179131, 18.8227507300988,
>                                      0.974588681842621, 108.07393074932,
> 0.870832606501646, 1.00567956715787,
>                                      1.04807118675076,
> 0.998948448847309, 0.999431048648743, 1.06271129629311,
>                                      1.07572617384751, 2.22760090861169,
> 0.932482182264868, 1.02936746325801,
>                                      2.52988042582817, 2.95633562179131,
> 18.8227507300988, 0.974588681842621,
>                                      108.07393074932, 0.870832606501646,
> 1.00567956715787, 0.938306957617447,
>                                      0.696202687574185,
> 0.698287792550519, 1.01157976748338, 1.07216134522869,
>                                      2.11775044458303,
> 0.658564756192898, 0.718936009019651, 2.46328731519796,
>                                      2.94817482855984, 13.4010203977042,
> 0.758075017209242, 75.8087725102359,
>                                      0.825432059460383,
> 1.00237002354864, 0.93840246618556, 0.696484580425202,
>                                      0.698549805163105,
> 1.01161728893021, 1.07215296972693, 2.11785160868381,
>                                      0.658846969311393,
> 0.719217656820784, 2.46333881438479, 2.94816645305808,
>                                      13.4028764261544,
> 0.758261665458076, 75.8196908351967, 0.82547163245355,
>                                      1.00236164804689,
> 0.938596807939808, 0.697064148960971, 0.699062697365857,
>                                      1.01169996923602, 1.07214387920809,
> 2.11805571501552, 0.659427992302351,
>                                      0.719759915668507,
> 2.46344926105519, 2.94815736253924, 13.4060642247861,
>                                      0.758655662542348,
> 75.8383487496718, 0.825555603203494, 1.00235255752804
> ), Intercept = c(-0.017716276271862, 0.000961091319158938,
> -0.000703510322277703,
>                   -0.00845866525088005, -0.0966678762281092,
> -0.389386368120609,
>                   0.068730059320282, 0.0367676804603267,
> -0.0134454494180847, -2.61898714802878,
>                   -7.30136425060206, -0.21274280699377,
> -43.1291289782452, -0.125688969456484,
>                   -0.307472718728007, -0.017716276271862,
> 0.000961091319158938,
>                   -0.000703510322277703, -0.00845866525088005,
> -0.0966678762281092,
>                   -0.389386368120609, 0.068730059320282,
> 0.0367676804603267, -0.0134454494180847,
>                   -2.61898714802878, -7.30136425060206,
> -0.21274280699377, -43.1291289782452,
>                   -0.125688969456484, -0.307472718728007,
> -0.017716276271862, 0.000961091319158938,
>                   -0.000703510322277703, -0.00845866525088005,
> -0.0966678762281092,
>                   -0.389386368120609, 0.068730059320282,
> 0.0367676804603267, -0.0134454494180847,
>                   -2.61898714802878, -7.30136425060206,
> -0.21274280699377, -43.1291289782452,
>                   -0.125688969456484, -0.307472718728007,
> -0.0859314660447012,
>                   0.0135310033957625, -3.43619764283222e-05,
> -0.0523622551444108,
>                   -0.475294485394066, -0.460272581935994,
> 0.0625183970346825, 0.0262518388075903,
>                   -0.0839509467307793, -2.95707142967006,
> -5.52875677718304, -0.152998423411686,
>                   -32.1368671911073, -0.164063261306885,
> -0.685459757083477, -0.0858163634696177,
>                   0.01352935620949, 9.46328483051025e-05,
> -0.052203322505647, -0.47489015022079,
>                   -0.460135002763724, 0.0626429365104076,
> 0.02640499766902, -0.0838075052075929,
>                   -2.95666709449679, -5.52852300483326,
> -0.153159000797531, -32.135862357057,
>                   -0.163909219046001, -0.685055421910201,
> -0.0856060516008676,
>                   0.0135479894875152, 0.000302270025863519,
> -0.0519314642867551,
>                   -0.474126407682765, -0.45988984866136,
> 0.0628609678242435, 0.026651390571036,
>                   -0.0835647473472818, -2.95590335195876,
> -5.52851009407545, -0.153425312176928,
>                   -32.1365449540903, -0.163646588624356,
> -0.684291679372176), Struct = c("Bias only",
> "Bias only", "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
> "Bias only", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "Bias only", "Bias only",
> "Bias only", "Bias only", "Bias only", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "Bias only", "Bias only", "Bias only", "Bias only", "Bias only",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "Bias only", "Bias only", "Bias only", "Bias only",
> "Bias only", "Lognormal error dist.", "Lognormal error dist.",
> "Lognormal error dist.", "Lognormal error dist.", "Lognormal error dist.",
> "FFT-based struct.", "FFT-based struct.", "FFT-based struct.",
> "FFT-based struct.", "FFT-based struct."), Error = c("Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Low CML error",
> "Low CML error", "Low CML error", "Low CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "Med CML error", "Med CML error",
> "Med CML error", "Med CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error", "High CML error", "High CML error", "High CML error",
> "High CML error")), .Names = c("Slope", "Intercept", "Struct",
> "Error"), row.names = c(1L, 3L, 4L, 5L, 6L, 11L, 13L, 14L, 15L,
> 16L, 21L, 23L, 24L, 25L, 26L, 31L, 33L, 34L, 35L, 36L, 41L, 43L,
> 44L, 45L, 46L, 51L, 53L, 54L, 55L, 56L, 61L, 63L, 64L, 65L, 66L,
> 71L, 73L, 74L, 75L, 76L, 81L, 83L, 84L, 85L, 86L, 91L, 93L, 94L,
> 95L, 96L, 101L, 103L, 104L, 105L, 106L, 111L, 113L, 114L, 115L,
> 116L, 121L, 123L, 124L, 125L, 126L, 131L, 133L, 134L, 135L, 136L,
> 141L, 143L, 144L, 145L, 146L, 151L, 153L, 154L, 155L, 156L, 161L,
> 163L, 164L, 165L, 166L, 171L, 173L, 174L, 175L, 176L), class = "data.frame")
>
>
> pl.strat.1 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Struct),size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> pl.strat.2 <- ggplot(strat_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Error), size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> pl.conv.1 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Struct), size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> pl.conv.2 <- ggplot(conv_df, mapping=aes(x=Intercept, y=Slope)) +
>    geom_point(aes(color=Error), size=4) +
>    scale_y_continuous(limits=c(0.3, 3.0)) +
>    scale_x_continuous(limits=c(-7, 7))
>
> print(pl.strat.1)
> print(pl.strat.2)
> print(pl.conv.1)
> print(pl.conv.2)
>
>
> >
> >
>
> --
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 14:36:20 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 05:36:20 -0700 (PDT)
Subject: [R] Suggestions for scatter plot of many data
In-Reply-To: <000101d41fd0$d83249e0$8896dda0$@bigpond.com>
References: <alpine.LNX.2.20.1807181349000.30315@salmo.appl-ecosys.com>
 <001c01d41f65$b50504f0$1f0f0ed0$@bigpond.com>
 <alpine.LNX.2.20.1807190714460.15936@salmo.appl-ecosys.com>
 <000101d41fd0$d83249e0$8896dda0$@bigpond.com>
Message-ID: <alpine.LNX.2.20.1807200535070.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, Duncan Mackay wrote:

> If you have to make several plots you can subset your data

Duncan,

   That's what I thought I should do.

> xyplot(... data = subset(x, condition), ...)
> or
> XYn <- xyplot(... data = x[row1:row2, ], ...)
> in a loop
>
> have a look a ? print.trellis
>
> if you want to put several on a page
>
> if you need strips on left and top see
> ?latticeExtra:::useOuterStrips

Thanks again,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 19:43:55 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 10:43:55 -0700 (PDT)
Subject: [R] Locating data source error in large file
Message-ID: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>

   The structure of the dataframe is

str(wy2016)
'data.frame':	8784 obs. of  4 variables:
  $ date  : chr  "2015-10-01" "2015-10-01" "2015-10-01" "2015-10-01" ...
  $ time  : chr  "00:00" "01:00" "02:00" "03:00" ...
  $ elev  : num  90.7 90.7 90.7 90.7 90.7 ...
  $ myDate: Date, format: "2015-10-01" "2015-10-01" ...

   The command and results on this dataframe is:
wy2016$myTime <- as.POSIXct(paste(wy2016$date, wy2016$time))
Error in as.POSIXlt.character(x, tz, ...) :
   character string is not in a standard unambiguous format

   Data for other water years do not throw this error. How can I identify
which row(s) among the 8784 have a date or time formatting error?

Rich



From wdun|@p @end|ng |rom t|bco@com  Fri Jul 20 20:21:54 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 20 Jul 2018 11:21:54 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>

The problem occurs because no commonly used format works on
all your date strings.  If you give as.POSIXlt the format you want to
use then items that don't match the format will be treated as NA's.
Use is.na() to find them.

> d <- c("2017-12-25", "2018-01-01", "10/31/2018")
> as.POSIXlt(d)
Error in as.POSIXlt.character(d) :
  character string is not in a standard unambiguous format
> as.POSIXlt(d, format="%Y-%m-%d")
[1] "2017-12-25 PST" "2018-01-01 PST" NA
> as.POSIXlt(d, format="%m/%d/%Y")
[1] NA               NA               "2018-10-31 PDT"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 10:43 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   The structure of the dataframe is
>
> str(wy2016)
> 'data.frame':   8784 obs. of  4 variables:
>  $ date  : chr  "2015-10-01" "2015-10-01" "2015-10-01" "2015-10-01" ...
>  $ time  : chr  "00:00" "01:00" "02:00" "03:00" ...
>  $ elev  : num  90.7 90.7 90.7 90.7 90.7 ...
>  $ myDate: Date, format: "2015-10-01" "2015-10-01" ...
>
>   The command and results on this dataframe is:
> wy2016$myTime <- as.POSIXct(paste(wy2016$date, wy2016$time))
> Error in as.POSIXlt.character(x, tz, ...) :
>   character string is not in a standard unambiguous format
>
>   Data for other water years do not throw this error. How can I identify
> which row(s) among the 8784 have a date or time formatting error?
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 20:58:19 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 11:58:19 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> The problem occurs because no commonly used format works on all your date
> strings. If you give as.POSIXlt the format you want to use then items that
> don't match the format will be treated as NA's. Use is.na() to find them.

Bill,

   No NAs found using both is.na() and scrolling through the source file.
That's why I asked for help: I saw nothing different in the dates or times.

Regards,

Rich



From er|cjberger @end|ng |rom gm@||@com  Fri Jul 20 21:18:48 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 20 Jul 2018 22:18:48 +0300
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
Message-ID: <CAGgJW76WDsP3oYXj=mKpdKtoKMgLAuz9ztcm2fp6GUgGjPEaqg@mail.gmail.com>

Hi Rich,
This may not be the most efficient but it will identify the offenders.

>  foo <-  paste(wy2016$date, wy2016$time))
> uu <- sapply(1:length(foo),
             function(i) { a <- try(as.POSIXct(foo[i]),silent=TRUE)
             "POSIXct" %in% class(a) })
> which(!uu)

HTH,
Eric



On Fri, Jul 20, 2018 at 9:58 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, William Dunlap wrote:
>
> The problem occurs because no commonly used format works on all your date
>> strings. If you give as.POSIXlt the format you want to use then items that
>> don't match the format will be treated as NA's. Use is.na() to find them.
>>
>
> Bill,
>
>   No NAs found using both is.na() and scrolling through the source file.
> That's why I asked for help: I saw nothing different in the dates or times.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Fri Jul 20 21:59:40 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 20 Jul 2018 12:59:40 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>

Which format did you use when you used is.na on the output of
   as.POSIXlt(strings, format=someFormat)
and found none?  Did the resulting dates look OK?  Perhaps
all is well.

Note the the common American format month/day/year is not
one that is tested when you don't supply a format - xx/yy/zzzz
is treated as year/month/day (and it changes the time zone,
presumable because US/Pacific time was not used in the year
10 CE).
  > as.POSIXlt("10/7/1962")
  [1] "0010-07-19 LMT"
  > as.POSIXlt("3/17/1962")
  Error in as.POSIXlt.character("3/17/1962") :
    character string is not in a standard unambiguous format


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 11:58 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, William Dunlap wrote:
>
> The problem occurs because no commonly used format works on all your date
>> strings. If you give as.POSIXlt the format you want to use then items that
>> don't match the format will be treated as NA's. Use is.na() to find them.
>>
>
> Bill,
>
>   No NAs found using both is.na() and scrolling through the source file.
> That's why I asked for help: I saw nothing different in the dates or times.
>
> Regards,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jul 20 22:01:51 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 20 Jul 2018 13:01:51 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
Message-ID: <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>


> On Jul 20, 2018, at 11:58 AM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Fri, 20 Jul 2018, William Dunlap wrote:
> 
>> The problem occurs because no commonly used format works on all your date
>> strings. If you give as.POSIXlt the format you want to use then items that
>> don't match the format will be treated as NA's. Use is.na() to find them.
> 
> Bill,
> 
>  No NAs found using both is.na() and scrolling through the source file.
> That's why I asked for help: I saw nothing different in the dates or times.
> 
> Regards,
> 
> Rich

I don't think you read Bill's message properly. He was not saying that there were NA's; he was telling you to use a format specification in your as.POSIXct call and the the result of that call would have NA's.

wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format= "%Y-%m-%d %H:%M") )

David.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 22:24:49 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:24:49 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> Which format did you use when you used is.na on the output of
>   as.POSIXlt(strings, format=someFormat)
> and found none?  Did the resulting dates look OK?  Perhaps
> all is well.

Bill,

   All dates here are kept as yyyy-mm-dd.

   And each dataframe row has this format:
2015-10-01,00:00,90.6689
2015-10-01,01:00,90.6506
2015-10-01,02:00,90.6719
2015-10-01,03:00,90.6506

Thanks,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 22:30:45 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:30:45 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
Message-ID: <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, David Winsemius wrote:

> I don't think you read Bill's message properly.

David,

   Obviously not.

> He was not saying that there were NA's; he was telling you to use a format
> specification in your as.POSIXct call and the the result of that call
> would have NA's.
>
> wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format= "%Y-%m-%d %H:%M") )

   Thank you. This found 24 TRUEs; now to find them in the file.

Thanks,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 22:31:46 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:31:46 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAGgJW76WDsP3oYXj=mKpdKtoKMgLAuz9ztcm2fp6GUgGjPEaqg@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAGgJW76WDsP3oYXj=mKpdKtoKMgLAuz9ztcm2fp6GUgGjPEaqg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201331030.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, Eric Berger wrote:

> This may not be the most efficient but it will identify the offenders.
>
>>  foo <-  paste(wy2016$date, wy2016$time))
>> uu <- sapply(1:length(foo),
>             function(i) { a <- try(as.POSIXct(foo[i]),silent=TRUE)
>             "POSIXct" %in% class(a) })
>> which(!uu)

Eric,

   Thank you. Now I know there are NAs there this should help me find them.

Regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 22:42:28 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:42:28 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
Message-ID: <alpine.LNX.2.20.1807201341090.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, David Winsemius wrote:

> wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format=
> "%Y-%m-%d %H:%M") )

David/Bill/Eric:

   Thank you all. I found the typos which covered a single day toward the end
of the dataframe.

Carpe weekend,

Rich



From wdun|@p @end|ng |rom t|bco@com  Fri Jul 20 22:44:21 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 20 Jul 2018 13:44:21 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
 <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZ3FqGfqc81xcqJL0Qh1vStM3jA2KktSEJRJOs6BkVkjw@mail.gmail.com>

 >  And each dataframe row has this format:
>2015-10-01,00:00,90.6689
>2015-10-01,01:00,90.6506
>2015-10-01,02:00,90.6719
>2015-10-01,03:00,90.6506

You mean each line in the file, not row in data.frame, has the form
"year-month-day,hour:min,numericValue".  Try the following, where tfile
names your file:

> df <- read.table(tfile, header=FALSE, sep=",", col.names=c("dateString",
"timeString", "Value"))
> df
  dateString timeString   Value
1 2015-10-01      00:00 90.6689
2 2015-10-01      01:00 90.6506
3 2015-10-01      02:00 90.6719
4 2015-10-01      03:00 90.6506
> transform(df, DateTime = as.POSIXlt(paste(dateString, timeString),
format="%Y-%m-%d %H:%M"), dateString=NULL, timeString=NULL)
    Value            DateTime
1 90.6689 2015-10-01 00:00:00
2 90.6506 2015-10-01 01:00:00
3 90.6719 2015-10-01 02:00:00
4 90.6506 2015-10-01 03:00:00
> str(.Last.value)
'data.frame':   4 obs. of  2 variables:
 $ Value   : num  90.7 90.7 90.7 90.7
 $ DateTime: POSIXct, format: "2015-10-01 00:00:00" "2015-10-01 01:00:00"
"2015-10-01 02:00:00" "2015-10-01 03:00:00"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 1:24 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, William Dunlap wrote:
>
> Which format did you use when you used is.na on the output of
>>   as.POSIXlt(strings, format=someFormat)
>> and found none?  Did the resulting dates look OK?  Perhaps
>> all is well.
>>
>
> Bill,
>
>   All dates here are kept as yyyy-mm-dd.
>
>   And each dataframe row has this format:
> 2015-10-01,00:00,90.6689
> 2015-10-01,01:00,90.6506
> 2015-10-01,02:00,90.6719
> 2015-10-01,03:00,90.6506
>
> Thanks,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 22:51:58 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 13:51:58 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcZ3FqGfqc81xcqJL0Qh1vStM3jA2KktSEJRJOs6BkVkjw@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <CAF8bMcYYy4RstbhKYDyrnYf-O=_YqGqpBsbBu88UWvX_Lt5NPQ@mail.gmail.com>
 <alpine.LNX.2.20.1807201322090.3558@salmo.appl-ecosys.com>
 <CAF8bMcZ3FqGfqc81xcqJL0Qh1vStM3jA2KktSEJRJOs6BkVkjw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201348070.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> You mean each line in the file, not row in data.frame, has the form
> "year-month-day,hour:min,numericValue". Try the following, where tfile
> names your file:

Bill,

   Yes, I was looking at the data file in one emacs buffer and my R session
in another one.

   The source file was what I posted, the data.frame is different:
  head(wy2016)
         date  time    elev
1 2015-10-01 00:00 90.6689
2 2015-10-01 01:00 90.6506
3 2015-10-01 02:00 90.6719
4 2015-10-01 03:00 90.6506
5 2015-10-01 04:00 90.6597
6 2015-10-01 05:00 90.6841

   It's all fixed now and I've learned how to handle future typos from all of
you.

Thanks,

Rich



From wdun|@p @end|ng |rom t|bco@com  Fri Jul 20 22:59:05 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 20 Jul 2018 13:59:05 -0700
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
 <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZs7R2CKJkadvQsN5WE=WeHzMUVpk6x=8k+xHby8xWh_w@mail.gmail.com>

To find the lines in the file, tfile, with bogus dates, try
    readLines(tfile)[ is.na(dataFrame$DateTime) ]

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 20, 2018 at 1:30 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 20 Jul 2018, David Winsemius wrote:
>
> I don't think you read Bill's message properly.
>>
>
> David,
>
>   Obviously not.
>
> He was not saying that there were NA's; he was telling you to use a format
>> specification in your as.POSIXct call and the the result of that call
>> would have NA's.
>>
>> wy2016$dt_time <- with( wy2016, as.POSIXct( paste( date, time ) , format=
>> "%Y-%m-%d %H:%M") )
>>
>
>   Thank you. This found 24 TRUEs; now to find them in the file.
>
> Thanks,
>
> Rich
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 23:09:54 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 14:09:54 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <CAF8bMcZs7R2CKJkadvQsN5WE=WeHzMUVpk6x=8k+xHby8xWh_w@mail.gmail.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
 <alpine.LNX.2.20.1807201326560.3558@salmo.appl-ecosys.com>
 <CAF8bMcZs7R2CKJkadvQsN5WE=WeHzMUVpk6x=8k+xHby8xWh_w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807201409290.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, William Dunlap wrote:

> To find the lines in the file, tfile, with bogus dates, try
>    readLines(tfile)[ is.na(dataFrame$DateTime) ]

Bill,

   Thanks for another lesson.

Regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 20 23:18:03 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 20 Jul 2018 14:18:03 -0700 (PDT)
Subject: [R] Locating data source error in large file
In-Reply-To: <alpine.LNX.2.20.1807201341090.3558@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807201036300.3558@salmo.appl-ecosys.com>
 <CAF8bMcZK1tmr1v3KV4Y9n1OCR=dv+KQYZ1yeCGGpbqCBV8oJ2g@mail.gmail.com>
 <alpine.LNX.2.20.1807201156230.3558@salmo.appl-ecosys.com>
 <92D533B9-CFCB-4B47-829E-821C6940564F@comcast.net>
 <alpine.LNX.2.20.1807201341090.3558@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807201416030.3558@salmo.appl-ecosys.com>

On Fri, 20 Jul 2018, Rich Shepard wrote:

>  Thank you all. I found the typos which covered a single day toward the end
> of the dataframe.

   FWIW, all these data came from PDF reports and had to be manually
highlighted and pasted into a text file. Given 29 years of hourly (and
sometimes half-hourly) reports I'm not suprised that I made errors now and
then.

Regards,

Rich



From m@notembe @end|ng |rom gm@||@com  Fri Jul 20 23:57:36 2018
From: m@notembe @end|ng |rom gm@||@com (Atanasio Alberto Tembe Tembe)
Date: Sat, 21 Jul 2018 06:57:36 +0900
Subject: [R] Query on while loop
Message-ID: <CA+YqJcfsVA0RUt82+vTyh95MXKWx6pYn8EjBMWpN-cZXOCXvBw@mail.gmail.com>

 Hello,

I have two matrices: a<-matrix(c(100,350,100,240,150,210,60,120,200 ),3,3)
and c<-matrix(c(2,9,13,10,4,11,14,12,3),3,3).

I have also defined the following variables:
K=0
A[i,j]=colSums(a)
P[i,j]=rowSums(a)
F[i,j]=c[i,j]^(-2 )

Using these data I want to perform the calculation which must end when
a convergence between X and Y values is reached.

X1=1/(K*A1*c11+K*A2*c12+K*A3*c13)

Y1=1/(X1*P1*c11+X1*P1*c12+X1*P1*c13)

X2=1/(Y1*A1*c21+Y1*A2*c22+Y1*A3*c23)

Y2=1/(X2*P2*c21+X2*P2*c22+X2*P2*c23)

X3=1/(Y1*A1*c31+Y1*A2*c32+Y1*A3*c33)

Y3=1/(X2*P3*c31+X2*P3*c32+X2*P3*c33)



I have been struggling over this for some time. Your support is highly
appreciated.

Thanks


-- 
Atanasio Alberto Tembe (Mr)
Doctoral student
Graduate School of Urban Innovation
Transportation and Urban Engineering Laboratory
Yokohama National University
Tel: +81-(0)80-4605-1305 <+81%2080-8080-2482>
 Mail: tembe-atanasio-dz at ynu.jp <pattamaporn-wongwiriya-cs at ynu.jp>
          manotembe at gmail.com <pattamaporn.w at gmail.com>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul 21 00:42:09 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 20 Jul 2018 15:42:09 -0700
Subject: [R] Query on while loop
In-Reply-To: <CA+YqJcfsVA0RUt82+vTyh95MXKWx6pYn8EjBMWpN-cZXOCXvBw@mail.gmail.com>
References: <CA+YqJcfsVA0RUt82+vTyh95MXKWx6pYn8EjBMWpN-cZXOCXvBw@mail.gmail.com>
Message-ID: <CAGxFJbQYnKD23=Lmd8=Q8sFLB21+fgmmSGdHFVHqDNvAPvT5WA@mail.gmail.com>

I don't know how to say this charitably, but your post indicates that you
**really need to go through an R tutorial or two.** Rather than give you
answers to these very basic matters, a couple of hints:

1.  A and P are vectors with 3 elements, not matrices .

2. I presume things like c11 and c32 are meant to be subscripts but that is
not how subscripts are written in R. R also can do such calculations on
whole objects rather than elementwise;

3. X1 is undefined (INF) as it is = 1/0  . So I have no idea what you
expect here.

Cheers,
Bert








Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 20, 2018 at 2:57 PM, Atanasio Alberto Tembe Tembe <
manotembe at gmail.com> wrote:

>  Hello,
>
> I have two matrices: a<-matrix(c(100,350,100,240,150,210,60,120,200 ),3,3)
> and c<-matrix(c(2,9,13,10,4,11,14,12,3),3,3).
>
> I have also defined the following variables:
> K=0
> A[i,j]=colSums(a)
> P[i,j]=rowSums(a)
> F[i,j]=c[i,j]^(-2 )
>
> Using these data I want to perform the calculation which must end when
> a convergence between X and Y values is reached.
>
> X1=1/(K*A1*c11+K*A2*c12+K*A3*c13)
>
> Y1=1/(X1*P1*c11+X1*P1*c12+X1*P1*c13)
>
> X2=1/(Y1*A1*c21+Y1*A2*c22+Y1*A3*c23)
>
> Y2=1/(X2*P2*c21+X2*P2*c22+X2*P2*c23)
>
> X3=1/(Y1*A1*c31+Y1*A2*c32+Y1*A3*c33)
>
> Y3=1/(X2*P3*c31+X2*P3*c32+X2*P3*c33)
>
>
>
> I have been struggling over this for some time. Your support is highly
> appreciated.
>
> Thanks
>
>
> --
> Atanasio Alberto Tembe (Mr)
> Doctoral student
> Graduate School of Urban Innovation
> Transportation and Urban Engineering Laboratory
> Yokohama National University
> Tel: +81-(0)80-4605-1305 <+81%2080-8080-2482>
>  Mail: tembe-atanasio-dz at ynu.jp <pattamaporn-wongwiriya-cs at ynu.jp>
>           manotembe at gmail.com <pattamaporn.w at gmail.com>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From t@v|b@r @end|ng |rom gm@||@com  Sat Jul 21 12:36:15 2018
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Sat, 21 Jul 2018 13:36:15 +0300
Subject: [R] Fwd: Re:  scatter plot coloring problem
In-Reply-To: <a56866f5-780d-1891-06ba-abf0e45295c4@gmail.com>
References: <a56866f5-780d-1891-06ba-abf0e45295c4@gmail.com>
Message-ID: <9c1c15dc-a2d8-f405-7122-cd4d8d63b10b@gmail.com>


Hi

On 07/20/2018 03:16 PM, PIKAL Petr wrote:
> Hi
>
> Values in conv_df are almost same for each Error level
Thanks to Petr for help in catching this!

>> aggregate(conv_df$Intercept, list(conv_df$Error), mean)
>           Group.1         x
> 1 High CML error -3.226313
> 2  Low CML error -3.226536
> 3  Med CML error -3.226422
>> aggregate(conv_df$Slope, list(conv_df$Error), mean)
>           Group.1        x
> 1 High CML error 8.325558
> 2  Low CML error 8.324242
> 3  Med CML error 8.324721
>> boxplot(split(conv_df$Slope, conv_df$Error))
>> boxplot(split(conv_df$Intercept, conv_df$Error))
>>
> so points in ggplot are overplotted and only colour for last plotted level is visible.

So I used geom_jitter() to get a reasonable looking visualization.

> Cheers
> Petr
>
>

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918



From be@tr|ce@mont|94 @end|ng |rom gm@||@com  Sat Jul 21 15:00:44 2018
From: be@tr|ce@mont|94 @end|ng |rom gm@||@com (Beatrice Monti)
Date: Sat, 21 Jul 2018 15:00:44 +0200
Subject: [R] Install BMR package - Mac
Message-ID: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>

Hi all,
I am having problems installing the BMR package.

I have been trying the following: 

	install.packages("devtools?) 
	library(devtools) 
	install_github("kthohr/BMR")

This is the error I get:

	clang: error: unsupported option ?-fopenmp'

I have dowloaded and installed both gfortran and clang-6.0.0 from   https://cran.r-project.org/bin/macosx/tools/ <https://cran.r-project.org/bin/macosx/tools/>   but I still get the same error.
I am using R version 3.5.1 on Mac OS X.

Any suggestion to solve this problem - which steps am I missing? 
ps: my apologies if I missed important information - let me know if further details are needed to explain the problem!

Thank you so much for your help!
	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul 21 16:28:55 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 21 Jul 2018 07:28:55 -0700
Subject: [R] Install BMR package - Mac
In-Reply-To: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>
References: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>
Message-ID: <CAGxFJbSqie_buQ7bcD5p+JeXNicRgYBRPy4EOMd_1qP9-1xdbw@mail.gmail.com>

As this appears to be a Mac specific issue, if you don't get help here, you
should try posting on the r-sig-mac list. Maybe even better would be to
contact the maintainer of the BMR package, who might not monitor either
list.


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jul 21, 2018 at 6:00 AM, Beatrice Monti <beatrice.monti94 at gmail.com>
wrote:

> Hi all,
> I am having problems installing the BMR package.
>
> I have been trying the following:
>
>         install.packages("devtools?)
>         library(devtools)
>         install_github("kthohr/BMR")
>
> This is the error I get:
>
>         clang: error: unsupported option ?-fopenmp'
>
> I have dowloaded and installed both gfortran and clang-6.0.0 from
> https://cran.r-project.org/bin/macosx/tools/ <https://cran.r-project.org/
> bin/macosx/tools/>   but I still get the same error.
> I am using R version 3.5.1 on Mac OS X.
>
> Any suggestion to solve this problem - which steps am I missing?
> ps: my apologies if I missed important information - let me know if
> further details are needed to explain the problem!
>
> Thank you so much for your help!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 21 17:46:23 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Jul 2018 08:46:23 -0700
Subject: [R] Install BMR package - Mac
In-Reply-To: <CAGxFJbSqie_buQ7bcD5p+JeXNicRgYBRPy4EOMd_1qP9-1xdbw@mail.gmail.com>
References: <470BD4E3-2EF8-4581-8C41-594534E849B5@gmail.com>
 <CAGxFJbSqie_buQ7bcD5p+JeXNicRgYBRPy4EOMd_1qP9-1xdbw@mail.gmail.com>
Message-ID: <BFD7D571-25EC-4326-BD0A-F0F905CDBF1C@dcn.davis.ca.us>

Agree with Bert, but Google sez [1] might also be helpful.

[1] https://github.com/Microsoft/LightGBM/issues/3

On July 21, 2018 7:28:55 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>As this appears to be a Mac specific issue, if you don't get help here,
>you
>should try posting on the r-sig-mac list. Maybe even better would be to
>contact the maintainer of the BMR package, who might not monitor either
>list.
>
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Sat, Jul 21, 2018 at 6:00 AM, Beatrice Monti
><beatrice.monti94 at gmail.com>
>wrote:
>
>> Hi all,
>> I am having problems installing the BMR package.
>>
>> I have been trying the following:
>>
>>         install.packages("devtools?)
>>         library(devtools)
>>         install_github("kthohr/BMR")
>>
>> This is the error I get:
>>
>>         clang: error: unsupported option ?-fopenmp'
>>
>> I have dowloaded and installed both gfortran and clang-6.0.0 from
>> https://cran.r-project.org/bin/macosx/tools/
><https://cran.r-project.org/
>> bin/macosx/tools/>   but I still get the same error.
>> I am using R version 3.5.1 on Mac OS X.
>>
>> Any suggestion to solve this problem - which steps am I missing?
>> ps: my apologies if I missed important information - let me know if
>> further details are needed to explain the problem!
>>
>> Thank you so much for your help!
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From jrkr|de@u @end|ng |rom y@hoo@c@  Sat Jul 21 18:39:42 2018
From: jrkr|de@u @end|ng |rom y@hoo@c@ (John Kane)
Date: Sat, 21 Jul 2018 16:39:42 +0000 (UTC)
Subject: [R] Problem with mean()
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
Message-ID: <335228618.266166.1532191182409@mail.yahoo.com>

Either I am doing something very stupid or my R installation has a glitch. What am I missing?
dd1? <- 50
dd2? <- 54

mean(dd1, dd2)
[1] 50? # wrong

(dd1 + dd2)/2
[1] 52 # correct

aa? <- c(48, 52, 56, 54, 52)

mean(aa)
[1] 52.4 # correct



	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jul 21 18:43:20 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 21 Jul 2018 17:43:20 +0100
Subject: [R] Problem with mean()
In-Reply-To: <335228618.266166.1532191182409@mail.yahoo.com>
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
 <335228618.266166.1532191182409@mail.yahoo.com>
Message-ID: <85fc11be-32a0-2de9-53ff-12c8902fe9ef@sapo.pt>

Hello,

The first argument of mean is a vector, the dots argument is to be 
"passed to or from other methods." (from ?mean)

Try instead

mean(c(dd1, dd2))


Hope this helps,

Rui Barradas

?s 17:39 de 21-07-2018, John Kane via R-help escreveu:
> Either I am doing something very stupid or my R installation has a glitch. What am I missing?
> dd1? <- 50
> dd2? <- 54
> 
> mean(dd1, dd2)
> [1] 50? # wrong
> 
> (dd1 + dd2)/2
> [1] 52 # correct
> 
> aa? <- c(48, 52, 56, 54, 52)
> 
> mean(aa)
> [1] 52.4 # correct
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jul 21 18:44:27 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 21 Jul 2018 12:44:27 -0400
Subject: [R] Problem with mean()
In-Reply-To: <335228618.266166.1532191182409@mail.yahoo.com>
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
 <335228618.266166.1532191182409@mail.yahoo.com>
Message-ID: <d1d7f827-36da-a3bd-31c9-b20be305cf85@gmail.com>

On 21/07/2018 12:39 PM, John Kane via R-help wrote:
> Either I am doing something very stupid or my R installation has a glitch. What am I missing?
> dd1? <- 50
> dd2? <- 54
> 
> mean(dd1, dd2)
> [1] 50? # wrong

Read the help page ?mean.  You are specifying the parameters x and trim.

Duncan Murdoch

> 
> (dd1 + dd2)/2
> [1] 52 # correct
> 
> aa? <- c(48, 52, 56, 54, 52)
> 
> mean(aa)
> [1] 52.4 # correct
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 21 18:44:40 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Jul 2018 09:44:40 -0700
Subject: [R] Problem with mean()
In-Reply-To: <335228618.266166.1532191182409@mail.yahoo.com>
References: <335228618.266166.1532191182409.ref@mail.yahoo.com>
 <335228618.266166.1532191182409@mail.yahoo.com>
Message-ID: <F24371F7-433E-4EA6-85FB-971E75028D1E@dcn.davis.ca.us>

Read ?mean.

Look at the argument list.

The mean function only applies to the first argument.

On July 21, 2018 9:39:42 AM PDT, John Kane via R-help <r-help at r-project.org> wrote:
>Either I am doing something very stupid or my R installation has a
>glitch. What am I missing?
>dd1? <- 50
>dd2? <- 54
>
>mean(dd1, dd2)
>[1] 50? # wrong
>
>(dd1 + dd2)/2
>[1] 52 # correct
>
>aa? <- c(48, 52, 56, 54, 52)
>
>mean(aa)
>[1] 52.4 # correct
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jul 21 18:53:00 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 21 Jul 2018 17:53:00 +0100
Subject: [R] (no subject)
In-Reply-To: <CA+YqJce7kjuuRieg7aJi0TEZ5fQyGMCRP8Ueu81To4We6ZzEUQ@mail.gmail.com>
References: <CA+YqJceJXODSpuAxp4vuiwJzfy34bFaKRML8VjqaMpmK6iP+FA@mail.gmail.com>
 <aa3fbed7-6be7-3076-89f6-40bbee33046f@sapo.pt>
 <CA+YqJcdbJAtepYv75GYHkqFvhM2QHSNicwy44-2wFCUgLvo5ng@mail.gmail.com>
 <CA+YqJce7kjuuRieg7aJi0TEZ5fQyGMCRP8Ueu81To4We6ZzEUQ@mail.gmail.com>
Message-ID: <18fec616-126d-4cc2-4d19-bf1c834b1484@sapo.pt>

Hello,

Please always write to r-help, not to me personally, even if I was able 
to be of assistance in the past.

As for your question, your code has several problems.

1) rowSums and colSums return vectors, not matrices. Even if they did, 
see point 3) below.

2) You define K = 0 then in

X[1]=1/(K*A[i,j]*c[1,1]+K*A[i,j]*c[1,2]+K*A[i,j]*c[1,3])

the denominator is zero because A[i,j] and c[] are multiplied by it.

3) What are the i,j in A[i,j] and P[i,j]?


Hope this helps,

Rui Barradas


?s 11:51 de 21-07-2018, Atanasio Alberto Tembe Tembe escreveu:
> Dear Mr. Barradas,
> 
> Thank you for your attention.
> 
> Sorry for this personalized e-mail. I recently posted a query about 
> while loop, but I did not get good feedback. I am a beginner in R and I 
> wonder if you can me help again.
> 
> If I have two matrices such as: a<-matrix(1:9,nrow=3,ncol=3) and 
> c<-matrix(1:9,nrow=3,ncol=3).
> 
> with defined variables:
> K=0
> A[i,j]=colSums(a)
> P[i,j]=rowSums(a)
> F[i,j]=c[i,j]^(-2 )
> X[i]=A[i,j]*c[i,j]
> X[j]=P[i,j]*c[i,j]
> 
> How to perform the following calculation with while loop so that it 
> stops when a?convergence between X and Y values is reached?.
> 
> X[1]=1/(K*A[i,j]*c[1,1]+K*A[i,j]*c[1,2]+K*A[i,j]*c[1,3])
> 
> Y[1]=1/(X[1]*P[i,j]*c[1,1]+[X1]*P[i,j]*c[1,2]+[X1]*P[i,j]*c[1,3])
> 
> X[2]=1/(Y[1]*A[i,j]*c[2,1]+Y[1]*A[i,j]*c[2,2]+Y[1]*A[i,j]*c[2,3])
> 
> Y[2]=1/(X[2]*P[i,j]*c[2,1]+X[2]*P[i,j]*c[2,2]+X[2]*P[i,j]*c[2,3])
> 
> X[3]=1/(Y[2]*A[i,j]*c[3,1]+Y[1]*A[i,j]*c[3,2]+Y[2]*A[i,j]*c[3,3])
> 
> Y[3]=1/(X[3]*P[3]*c[3,1]+X[3]*P[3]*c[3,2]+X[3]*P[3]*c[3,3])
> 
> 
> Thank you very much.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> On Mon, Jul 16, 2018 at 6:51 PM, Atanasio Alberto Tembe Tembe 
> <manotembe at gmail.com <mailto:manotembe at gmail.com>> wrote:
> 
>     Hi Mr. Barradas,
> 
>     Thank you for your kind support. I will?your suggestions.
> 
>     Best regards
>     Tembe
> 
> 
>     On Mon, Jul 16, 2018 at 6:22 PM, Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>         Hello,
> 
>         Please repost in plain text, NO HTML formating.
> 
>         Also, you are missing an open parenthesis right after while:
> 
>         while( sum(abs(Sb-D-Sc-t(Pi))>1E-5)){
> 
> 
>         Hope this helps,
> 
>         Rui Barradas
> 
> 
>         ?s 14:25 de 15-07-2018, Atanasio Alberto Tembe Tembe escreveu:
> 
>             Hello!
> 
>             Is there anyone who can help me to this the error bellow? Ijust
>             started using R recently. Thank you
> 
> 
>             while sum(abs(Sb-D-Sc-t(Pi))>1E-5{Error: unexpected symbol
>             in "while
>             sum">? ? ?>? ? ?k=K+1>? ? ?>? ? ?for(i in 1:nrow(c1)){+     
>              ? ?+
>              ? ? for(j in 1:ncol(c1)){+? ? ? ? ? ? ?+           
>              ?if(Sb!=0){+
>              ? ? ? ? ? +? ? ? ? ? ? ? ? ?T2=D*T/Sa+? ? ? ? ? ? ? ? ?+
>             }else {+? ? ? ? ? ? ? ? ?+? ? ? ? ? ? ? ? ?T2=0? ? ? ?+
>              ? +? ? ? ? ? ? ?}+? ? ? ? ? ? ?+? ? ? ? ? ? ?Sc=sum(t(T))+
>             +? ? ? ? ? ? ?if(Sc!=0){+? ? ? ? ? ? ? ? ?+
>             T3=Pi*T2/Sc+? ? ? ? ? ? ? ? ?+? ? ? ? ? ? ?}else {+         
>              ? ? ? ?+
>              ? ? ? ? ? ? ? ? T3=0+? ? ? ? ? ? ? ? ?+? ? ? ? ? ? ?}+
>             Sb=sum(T)+? ? ? ? ? ? ?+? ? ? ? ?}+? ? ?}>? ? ?>? ? ?K[1] 0
> 
>              ? ? ? ? [[alternative HTML version deleted]]
> 
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
> 
> 
> 
> 
>     -- 
>     Atanasio Alberto Tembe (Mr)
>     Doctoral student
>     Graduate School of Urban Innovation
>     Transportation and Urban Engineering Laboratory
>     Yokohama National University
>     Tel: +81-(0)80-4605-1305 <tel:+81%2080-8080-2482>
>      ?Mail: tembe-atanasio-dz at ynu.jp
>     <mailto:pattamaporn-wongwiriya-cs at ynu.jp>
>     manotembe at gmail.com <mailto:pattamaporn.w at gmail.com>
> 
> 
> 
> 
> -- 
> Atanasio Alberto Tembe (Mr)
> Doctoral student
> Graduate School of Urban Innovation
> Transportation and Urban Engineering Laboratory
> Yokohama National University
> Tel: +81-(0)80-4605-1305 <tel:+81%2080-8080-2482>
>  ?Mail: tembe-atanasio-dz at ynu.jp <mailto:pattamaporn-wongwiriya-cs at ynu.jp>
> manotembe at gmail.com <mailto:pattamaporn.w at gmail.com>



From c||ve||@t@ @end|ng |rom goog|em@||@com  Sun Jul 22 02:50:02 2018
From: c||ve||@t@ @end|ng |rom goog|em@||@com (Clive Nicholas)
Date: Sun, 22 Jul 2018 01:50:02 +0100
Subject: [R] Possible solution to R installation problemst for Linux Mint 19
 users
Message-ID: <CAHs5aTgn=+sRXGp8QyAy4scoC-tJjYXsxJrrSC0Wg9yTzfv=Xg@mail.gmail.com>

Hello!

If you're a newly-minted (pun _fully_ intended) user of Linux Mint 19
("Tara") and you find you're having issues installing R (as I just have),
please read on as I may have a solution for you.

To set out the context, the problem looks like this:

You (naturally) consult the relevant webpage at cran.r-project.org for your
Linux Mint system (ubuntu) and add the pub key (I've always used Michael
Rutter's). On my last Linux Mint system (18.2), I was using the following
repositories

deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/
deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/

which worked fine for me. Unfortunately on my new Linux Mint 19 system:

clive at climate:~$ sudo apt-get update
clive at climate:~$ sudo apt-get upgrade
clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
Reading package lists... Done
Building dependency tree
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies.
 r-base-core : Depends: libcurl3 (>= 7.28.0) but it is not going to be
installed
               Depends: libpng12-0 (>= 1.2.13-4) but it is not installable
               Depends: libreadline6 (>= 6.0) but it is not installable
E: Unable to correct problems, you have held broken packages.

No matter how many legitimate bash calls I made, such as

sudo dpkg --configure -a # NOT CURRENTLY WORKING PROPERLY AT PRESENT - THE
LINUX TEAM ARE ONTO THIS, APPARENTLY
sudo apt-get -f install
sudo apt-get --fix-broken install r-base r-base-core r-base-dev

nothing worked: I would simply get variations of the same error.

It turns out the solution is to switch away from -xenial- to *-artful-* (a
repository I've never used before and which appears to be the newest of all
the Ubuntu repositories), so that

deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/
deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/

(or whichever is your favourite mirror).

Then:

clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following additional packages will be installed:
  cdbs dh-translations jq libfile-which-perl libjq1 libonig4 python3-scour
r-cran-boot r-cran-class r-cran-cluster r-cran-codetools r-cran-foreign
r-cran-kernsmooth
  r-cran-lattice r-cran-mass r-cran-matrix r-cran-mgcv r-cran-nlme
r-cran-nnet r-cran-rpart r-cran-spatial r-cran-survival r-recommended scour
Suggested packages:
  devscripts ess r-doc-info | r-doc-pdf r-mathlib r-base-html
gir1.2-rsvg-2.0
Recommended packages:
  r-base-html r-doc-html
The following NEW packages will be installed
  cdbs dh-translations jq libfile-which-perl libjq1 libonig4 python3-scour
r-base r-base-core r-base-dev r-cran-boot r-cran-class r-cran-cluster
r-cran-codetools
  r-cran-foreign r-cran-kernsmooth r-cran-lattice r-cran-mass r-cran-matrix
r-cran-mgcv r-cran-nlme r-cran-nnet r-cran-rpart r-cran-spatial
r-cran-survival
  r-recommended scour
0 to upgrade, 27 to newly install, 0 to remove and 3 not to upgrade.
Need to get 39.5 MB of archives.
After this operation, 59.9 MB of additional disk space will be used.
Do you want to continue? [Y/n] y
Get:1 http://ftp.snt.utwente.nl/pub/os/linux/ubuntu bionic/universe amd64
libonig4 amd64 6.7.0-1 [119 kB]

[...]

Setting up r-base (3.4.4-1ubuntu1) ...
clive at climate:~$ R

R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> plot(rnorm(1000)) # GRAPHIC DULY PRODUCED WITH NO ISSUES!
> q()
Save workspace image? [y/n/c]: n
clive at climate:~$

*Volia!* (Okay, so it doesn't install R 3.5.1 - the latest version - but
that should eventually correct itself with future updates.)

So, if you're having the same R installation problems I've just had after
migrating to Linux Mint 19, this should work for you. Good luck. :)


-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jul 22 07:34:30 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 21 Jul 2018 22:34:30 -0700
Subject: [R] 
 Possible solution to R installation problemst for Linux Mint 19
 users
In-Reply-To: <CAHs5aTgn=+sRXGp8QyAy4scoC-tJjYXsxJrrSC0Wg9yTzfv=Xg@mail.gmail.com>
References: <CAHs5aTgn=+sRXGp8QyAy4scoC-tJjYXsxJrrSC0Wg9yTzfv=Xg@mail.gmail.com>
Message-ID: <5C268157-288C-4D18-9278-DD2E3C067418@dcn.davis.ca.us>

Each Mint version builds from an Ubuntu version. I don't use Mint. but this [1] web page tells me you should be pulling from a Bionic repo. Artful may work for you now, but in general it is risky to mix distribution revisions.

Note that this informative discussion should have occurred on the R-sig-debian mailing list, as it involves the intersection of R and debian derivatives, and is not about the R language as this mailing list is.

[1] https://linuxmint.com/download_all.php



On July 21, 2018 5:50:02 PM PDT, Clive Nicholas via R-help <r-help at r-project.org> wrote:
>Hello!
>
>If you're a newly-minted (pun _fully_ intended) user of Linux Mint 19
>("Tara") and you find you're having issues installing R (as I just
>have),
>please read on as I may have a solution for you.
>
>To set out the context, the problem looks like this:
>
>You (naturally) consult the relevant webpage at cran.r-project.org for
>your
>Linux Mint system (ubuntu) and add the pub key (I've always used
>Michael
>Rutter's). On my last Linux Mint system (18.2), I was using the
>following
>repositories
>
>deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/
>deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu xenial/
>
>which worked fine for me. Unfortunately on my new Linux Mint 19 system:
>
>clive at climate:~$ sudo apt-get update
>clive at climate:~$ sudo apt-get upgrade
>clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
>Reading package lists... Done
>Building dependency tree
>Reading state information... Done
>Some packages could not be installed. This may mean that you have
>requested an impossible situation or if you are using the unstable
>distribution that some required packages have not yet been created
>or been moved out of Incoming.
>The following information may help to resolve the situation:
>
>The following packages have unmet dependencies.
> r-base-core : Depends: libcurl3 (>= 7.28.0) but it is not going to be
>installed
>            Depends: libpng12-0 (>= 1.2.13-4) but it is not installable
>               Depends: libreadline6 (>= 6.0) but it is not installable
>E: Unable to correct problems, you have held broken packages.
>
>No matter how many legitimate bash calls I made, such as
>
>sudo dpkg --configure -a # NOT CURRENTLY WORKING PROPERLY AT PRESENT -
>THE
>LINUX TEAM ARE ONTO THIS, APPARENTLY
>sudo apt-get -f install
>sudo apt-get --fix-broken install r-base r-base-core r-base-dev
>
>nothing worked: I would simply get variations of the same error.
>
>It turns out the solution is to switch away from -xenial- to *-artful-*
>(a
>repository I've never used before and which appears to be the newest of
>all
>the Ubuntu repositories), so that
>
>deb http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/
>deb-src http://cran.ma.imperial.ac.uk/bin/linux/ubuntu artful/
>
>(or whichever is your favourite mirror).
>
>Then:
>
>clive at climate:~$ sudo apt-get install r-base r-base-core r-base-dev
>Reading package lists... Done
>Building dependency tree
>Reading state information... Done
>The following additional packages will be installed:
>cdbs dh-translations jq libfile-which-perl libjq1 libonig4
>python3-scour
>r-cran-boot r-cran-class r-cran-cluster r-cran-codetools r-cran-foreign
>r-cran-kernsmooth
>  r-cran-lattice r-cran-mass r-cran-matrix r-cran-mgcv r-cran-nlme
>r-cran-nnet r-cran-rpart r-cran-spatial r-cran-survival r-recommended
>scour
>Suggested packages:
>  devscripts ess r-doc-info | r-doc-pdf r-mathlib r-base-html
>gir1.2-rsvg-2.0
>Recommended packages:
>  r-base-html r-doc-html
>The following NEW packages will be installed
>cdbs dh-translations jq libfile-which-perl libjq1 libonig4
>python3-scour
>r-base r-base-core r-base-dev r-cran-boot r-cran-class r-cran-cluster
>r-cran-codetools
>r-cran-foreign r-cran-kernsmooth r-cran-lattice r-cran-mass
>r-cran-matrix
>r-cran-mgcv r-cran-nlme r-cran-nnet r-cran-rpart r-cran-spatial
>r-cran-survival
>  r-recommended scour
>0 to upgrade, 27 to newly install, 0 to remove and 3 not to upgrade.
>Need to get 39.5 MB of archives.
>After this operation, 59.9 MB of additional disk space will be used.
>Do you want to continue? [Y/n] y
>Get:1 http://ftp.snt.utwente.nl/pub/os/linux/ubuntu bionic/universe
>amd64
>libonig4 amd64 6.7.0-1 [119 kB]
>
>[...]
>
>Setting up r-base (3.4.4-1ubuntu1) ...
>clive at climate:~$ R
>
>R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
>Copyright (C) 2018 The R Foundation for Statistical Computing
>Platform: x86_64-pc-linux-gnu (64-bit)
>
>R is free software and comes with ABSOLUTELY NO WARRANTY.
>You are welcome to redistribute it under certain conditions.
>Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
>R is a collaborative project with many contributors.
>Type 'contributors()' for more information and
>'citation()' on how to cite R or R packages in publications.
>
>Type 'demo()' for some demos, 'help()' for on-line help, or
>'help.start()' for an HTML browser interface to help.
>Type 'q()' to quit R.
>
>> plot(rnorm(1000)) # GRAPHIC DULY PRODUCED WITH NO ISSUES!
>> q()
>Save workspace image? [y/n/c]: n
>clive at climate:~$
>
>*Volia!* (Okay, so it doesn't install R 3.5.1 - the latest version -
>but
>that should eventually correct itself with future updates.)
>
>So, if you're having the same R installation problems I've just had
>after
>migrating to Linux Mint 19, this should work for you. Good luck. :)

-- 
Sent from my phone. Please excuse my brevity.



From pd@|gd @end|ng |rom gm@||@com  Sun Jul 22 08:32:24 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sun, 22 Jul 2018 08:32:24 +0200
Subject: [R] 
 Where does ' Setting LC_CTYPE failed, using "C" ' come from? 2
In-Reply-To: <9C4FD8C1-6968-4FE7-B6B5-2CC3586FA903@comcast.net>
References: <ac685e66-bc43-17aa-defa-014012bebc82@echoffmann.ch>
 <7DE6EBD4-FCD4-4DB6-9A92-E955F3C87FCC@dcn.davis.ca.us>
 <b626bcc6-f6d9-21e0-b14b-29600a8a60a1@echoffmann.ch>
 <9C4FD8C1-6968-4FE7-B6B5-2CC3586FA903@comcast.net>
Message-ID: <B852A03B-DD04-4EDA-9E41-33BB90AD716D@gmail.com>



> On 17 Jul 2018, at 18:18 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>>>> Executing
>>>> 
>>>>    Open Terminal
>>>>    Write or paste in: defaults write org.R-project.R force.LANG
>>>> en_US.UTF-8
>>>>    Close Terminal
>>>>    Start R
>>>> 
>>>> as suggested on 
>> 
>> https://stackoverflow.com/questions/9689104/installing-r-on-mac-warning-messages-setting-lc-ctype-failed-using-c,
>> 
>> did not help :-(
> 
> Sigh, claiming that something "did not help" usually ...does not help. You need a clear unambigous description of everything that was in place and exactly what was being done when the unexpected behavior occurred. 

Hm, well, seen worse...

However, some detective works seems required.

C: (a) Can you at this point do the equivalent of the following (in a Terminal window):

Peter-Dalgaards-MacBook-Air:~ pd$ defaults read org.R-project.R force.LANG
en_US.UTF-8

If not, then the "defaults write...." stuff has been entered incorrectly or didn't work for some reason.

-?d



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From d@|pr@@|ou|@ @end|ng |rom gm@||@com  Sun Jul 22 14:24:41 2018
From: d@|pr@@|ou|@ @end|ng |rom gm@||@com (louis DALPRA)
Date: Sun, 22 Jul 2018 14:24:41 +0200
Subject: [R] Issue : Time to run a model on different computers
Message-ID: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>

Hello,

My issue is related to the time it takes to run a model on R between two different computers. On my teacher?s computer (MacBook Pro 2013; OS 10.9.5; R version 3.1.3) it takes only a few minutes to run it while on mine (MacBook Air 2014; OS 10.13.6; R version 3.5.1) it takes several hours. I checked for malware, and reinstalled the system but still no changes. Does any one have an idea on what might be the issue ?

In advance thank?s for your time and answers.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 22 19:20:17 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 22 Jul 2018 10:20:17 -0700
Subject: [R] Issue : Time to run a model on different computers
In-Reply-To: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>
References: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>
Message-ID: <CAGxFJbQkdthZecppVAHBD7EF=AvKrUPjYQ7=Rf=wTPXdT77PhA@mail.gmail.com>

You did not say what memory resources were in the two cases, and it is
probably impossible to say without knowing what code you ran in any case.
That you have different versions of OS and R on the two computers already
means that there could be many possible explanations, but one wild guess is
that on your computer/R version/OS version you are memory limited and
swapping to and from disk, while on the other you are not. This may well be
nothing more than stupid speculation, though.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jul 22, 2018 at 5:24 AM, louis DALPRA <dalpra.louis at gmail.com>
wrote:

> Hello,
>
> My issue is related to the time it takes to run a model on R between two
> different computers. On my teacher?s computer (MacBook Pro 2013; OS 10.9.5;
> R version 3.1.3) it takes only a few minutes to run it while on mine
> (MacBook Air 2014; OS 10.13.6; R version 3.5.1) it takes several hours. I
> checked for malware, and reinstalled the system but still no changes. Does
> any one have an idea on what might be the issue ?
>
> In advance thank?s for your time and answers.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @eren@de@te|@n| @end|ng |rom gm@||@com  Sun Jul 22 22:26:58 2018
From: @eren@de@te|@n| @end|ng |rom gm@||@com (Serena De Stefani)
Date: Sun, 22 Jul 2018 16:26:58 -0400
Subject: [R] Automate running files in R
Message-ID: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>

I need to automate a process in R. Basically I have a an R script (I will
call it R1) that needs three separate files to run. These three files are
the results output of one trial in my study.

So from each run in R I obtain the summary results for one trial, in a csv
file, plus 32 graphs for each decision point in the trial.

One subject goes through of nine trials. I was thinking about putting all
the files generated by one subject in one big folder, so I will have 27
files (three files times nine trials). This way I won't have to change
working directory multiple times (I wonder if there is a way to have R open
a folder with a certain name as directory, run a scripts, move the
directory to the next folder, run the script again...)

The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So for
subject 1, trial 1, I will have three files with the ending
?mov1_AA

For subject one, trial 2, R should choose the three files with the ending ?
mov1_AB and so on.

At each run, R should save the csv summary output in a folder called
?summary_mov1? and name the files summary_mov1_AA, summary_mov1_AB etc. R
should save the 32 graphs in a different folder, named mov1_graphs,
graph1_mov1_AA, graph1_mov1_AB and so on (ideally, at this point another R
script (R2) should take these nine csv files and build some graphs out of
them).

Once R has run R1 script nine times, I would proceed to a new subject.

So basically: use R1 with three mov1 files, get a summary csv file in a
summary folder (plus 32 graphs in a different folder).

Do this nine times. Once one get the nine csv summary files in the same
folder, use R2 to average them and build a graph.

Then do this for each subject (right now I have 7).

I have never done this type of automation so I am a bit lost. Any
suggestions? Any examples you can point me to? Which would be the best
workflow? At which level should I automate and which things should I rather
do by hand?

Thank you,
Serena DeStefani

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Mon Jul 23 00:17:22 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 23 Jul 2018 08:17:22 +1000
Subject: [R] Automate running files in R
In-Reply-To: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
References: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
Message-ID: <CA+8X3fUJj6nbg+fLULrJs55qgft9c5wFFed8bXZ=S_2JesYuoQ@mail.gmail.com>

Hi Serena,
I think the directory structure you have described is something like this:

mov_study___________________________
                 |                                                     |
             mov1                      ...                    mov9
             /       \                                            /         \
mov1_csv  mov1_graphs                 mov9_csv  mov9_graphs

If so, you can put your R scripts in the mov_study directory and
change directories like this:

for(movdir in paste0("mov",1:9,) {
 setwd(movdir)
 source("R1")
 source("R2")
 setwd("..")
}

In R1 and R2 add a "movdir" argument set the target directories for
your output like this:
 R1<-function(...,movdir=movdir)
 R2<-function(...,movdir=movdir)

 path_to_csv<-paste(movdir,"csv",sep="_")
 path_to_graph<-paste(movdir,"graphs",sep="_")

and when you write an output file:
# for CSV files
filename<-paste(path_to_csv,csvfilename,sep="/")
# for graph files
filename<-paste(path_to_graph,graphfilename,sep="/")

Obviously I can't test this on your directory structure, but I think
it will do what you want.

Jim

On Mon, Jul 23, 2018 at 6:26 AM, Serena De Stefani
<serenadestefani at gmail.com> wrote:
> I need to automate a process in R. Basically I have a an R script (I will
> call it R1) that needs three separate files to run. These three files are
> the results output of one trial in my study.
>
> So from each run in R I obtain the summary results for one trial, in a csv
> file, plus 32 graphs for each decision point in the trial.
>
> One subject goes through of nine trials. I was thinking about putting all
> the files generated by one subject in one big folder, so I will have 27
> files (three files times nine trials). This way I won't have to change
> working directory multiple times (I wonder if there is a way to have R open
> a folder with a certain name as directory, run a scripts, move the
> directory to the next folder, run the script again...)
>
> The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So for
> subject 1, trial 1, I will have three files with the ending
> ?mov1_AA
>
> For subject one, trial 2, R should choose the three files with the ending ?
> mov1_AB and so on.
>
> At each run, R should save the csv summary output in a folder called
> ?summary_mov1? and name the files summary_mov1_AA, summary_mov1_AB etc. R
> should save the 32 graphs in a different folder, named mov1_graphs,
> graph1_mov1_AA, graph1_mov1_AB and so on (ideally, at this point another R
> script (R2) should take these nine csv files and build some graphs out of
> them).
>
> Once R has run R1 script nine times, I would proceed to a new subject.
>
> So basically: use R1 with three mov1 files, get a summary csv file in a
> summary folder (plus 32 graphs in a different folder).
>
> Do this nine times. Once one get the nine csv summary files in the same
> folder, use R2 to average them and build a graph.
>
> Then do this for each subject (right now I have 7).
>
> I have never done this type of automation so I am a bit lost. Any
> suggestions? Any examples you can point me to? Which would be the best
> workflow? At which level should I automate and which things should I rather
> do by hand?
>
> Thank you,
> Serena DeStefani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Jul 23 00:40:23 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 22 Jul 2018 15:40:23 -0700 (PDT)
Subject: [R] Automate running files in R
In-Reply-To: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
References: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807221533130.4416@salmo.appl-ecosys.com>

On Sun, 22 Jul 2018, Serena De Stefani wrote:

> I need to automate a process in R. Basically I have a an R script (I will
> call it R1) that needs three separate files to run. These three files are
> the results output of one trial in my study.

> The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So for
> subject 1, trial 1, I will have three files with the ending
> ?mov1_AA
>
> For subject one, trial 2, R should choose the three files with the ending ?
> mov1_AB and so on.

Serena,

   In addition to Jim's advice about your directory structure you should
seriously consider your file naming convention. Just like variable names in
a program, you're almost guaranteed to not remember what each two-character
name means within six months of creating them. Spend a little more time
typing and use descriptive names ... and think of using a .dat extension and
using read.table(*.dat).

   You can name your files, for example, input_1.R, input_2.R, and input_3.R
for your run sources. And, for (e.g.,) subject 1, trial 1, name the file
sub1_trial1. This might produce output called sub1_trial1_input1,
sub1_trial1_input2, and sub1_trial1_input3.

   Now when you look at data.frames or output you and everyone else will know
just what each contains.

Have fun,

Rich



From jerem|eju@te @end|ng |rom gm@||@com  Mon Jul 23 12:30:38 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 12:30:38 +0200
Subject: [R] [bug] spdep package?
Message-ID: <87d0ve5jn5.fsf@gmail.com>



Hello,


I found a dangerous issue in the library spdep. I get variables x and y
that cannot be removed by rm() and I don't don't how they show up. Can
anyone reproduce this?

~$ R --vanilla
> rm(list=ls())
> library(spdep)
> x
[1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> rm(list=ls())
> x
[1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450



> Sys.info()

sysname        "Linux"                                     
release        "4.9.0-6-amd64"                             
version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
nodename       "freegnu"                                   
machine        "x86_64"                                    


> Session


> sessionInfo()

R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Matrix products: default
BLAS: /usr/local/lib/R/lib/libRblas.so
LAPACK: /usr/local/lib/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.4.1



From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Jul 23 12:39:52 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 23 Jul 2018 12:39:52 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <87d0ve5jn5.fsf@gmail.com>
References: <87d0ve5jn5.fsf@gmail.com>
Message-ID: <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>

It turns out that that 'x' comes from the spData package and lives
inside that package (part of its namespace).

> spData::x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450

This is conceptually no different from other objects in package
namespace, although we are more used to seeing functions and not data
object.  Another well-known example of this is:

> base::pi
[1] 3.141593

So, this 'x' is *not* in your global workspace and you cannot remove
it without unloading the package.

/Henrik

On Mon, Jul 23, 2018 at 12:30 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>
>
>
> Hello,
>
>
> I found a dangerous issue in the library spdep. I get variables x and y
> that cannot be removed by rm() and I don't don't how they show up. Can
> anyone reproduce this?
>
> ~$ R --vanilla
> > rm(list=ls())
> > library(spdep)
> > x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> > rm(list=ls())
> > x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
>
>
> > Sys.info()
>
> sysname        "Linux"
> release        "4.9.0-6-amd64"
> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
> nodename       "freegnu"
> machine        "x86_64"
>
>
> > Session
>
>
> > sessionInfo()
>
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 9 (stretch)
>
> Matrix products: default
> BLAS: /usr/local/lib/R/lib/libRblas.so
> LAPACK: /usr/local/lib/R/lib/libRlapack.so
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Jul 23 12:58:16 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 23 Jul 2018 22:58:16 +1200
Subject: [R] [FORGED]  [bug] spdep package?
In-Reply-To: <87d0ve5jn5.fsf@gmail.com>
References: <87d0ve5jn5.fsf@gmail.com>
Message-ID: <f62ae796-ae12-f5b3-3951-bc6fbcc35b6c@auckland.ac.nz>

On 23/07/18 22:30, Jeremie Juste wrote:
> 
> 
> Hello,
> 
> 
> I found a dangerous issue in the library spdep. I get variables x and y
> that cannot be removed by rm() and I don't don't how they show up. Can
> anyone reproduce this?

I cannot.

This is *very* unlikely to be a bug.  People should always exercise a 
great deal of caution about conjecturing bugs when they encounter a
phenomenon that they don't understand.

What do you see if you simply do "ls()"?  (After loading spdep.)
I.e. do you see an "x" listed as an object in your workspace/global 
environment?

What does find("x") return?

It puzzles me that your sessionInfo() doesn't show something like:

> other attached packages:
> [1] spdep_0.6-13  Matrix_1.2-10 sp_1.2-5

There are probably other issues that you have not told us about.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> 
> ~$ R --vanilla
>> rm(list=ls())
>> library(spdep)
>> x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> rm(list=ls())
>> x
> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> 
> 
> 
>> Sys.info()
> 
> sysname        "Linux"
> release        "4.9.0-6-amd64"
> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
> nodename       "freegnu"
> machine        "x86_64"
> 
> 
>> Session
> 
> 
>> sessionInfo()
> 
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Debian GNU/Linux 9 (stretch)
> 
> Matrix products: default
> BLAS: /usr/local/lib/R/lib/libRblas.so
> LAPACK: /usr/local/lib/R/lib/libRlapack.so
> 
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1



From M@Enz|@n @end|ng |rom gmx@de  Mon Jul 23 13:43:36 2018
From: M@Enz|@n @end|ng |rom gmx@de (Maria Enzian)
Date: Mon, 23 Jul 2018 13:43:36 +0200
Subject: [R] pROC
Message-ID: <trinity-c719bf86-35fa-4f71-b74f-46e7639cdd19-1532346216576@3c-app-gmx-bs38>



Hello,
I'm using the package pROC in RStudio to create my ROC-curves and I have patients in my data - healthy or sick - in the column "Status" and the value "SUVmax" to examine it.
I used the following code:
plot.roc(daten$Status,daten$SUVmax,percent=TRUE,ci=TRUE,print.auc=TRUE,main="ROC-Kurve f?r den SUVmax")
The ROC-curve I got is ok, but on the x-axis I got a specificity from 150% to -50%, but I want the scale from 100% to 0% (as usual).
xlim=c(100,0) doesn't work.
Can someone help me?
?
Best regards
M.Enzian



From jerem|eju@te @end|ng |rom gm@||@com  Mon Jul 23 14:01:17 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 14:01:17 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
 (Henrik Bengtsson's message of "Mon, 23 Jul 2018 12:39:52 +0200")
References: <87d0ve5jn5.fsf@gmail.com>
 <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
Message-ID: <8760165fg2.fsf@gmail.com>


Helllo,

Thanks for the info. I still think these variables should not be loaded
when library(spdep) is called.

But I'll handle it following your suggestion.

Thanks,

Jeremie






> It turns out that that 'x' comes from the spData package and lives
> inside that package (part of its namespace).
>
>> spData::x
>  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
> This is conceptually no different from other objects in package
> namespace, although we are more used to seeing functions and not data
> object.  Another well-known example of this is:
>
>> base::pi
> [1] 3.141593
>
> So, this 'x' is *not* in your global workspace and you cannot remove
> it without unloading the package.
>
> /Henrik


>>
>>
>> I found a dangerous issue in the library spdep. I get variables x and y
>> that cannot be removed by rm() and I don't don't how they show up. Can
>> anyone reproduce this?
>>
>> ~$ R --vanilla
>> > rm(list=ls())
>> > library(spdep)
>> > x
>> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> > rm(list=ls())
>> > x
>> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>>
>>
>>
>> > Sys.info()
>>
>> sysname        "Linux"
>> release        "4.9.0-6-amd64"
>> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
>> nodename       "freegnu"
>> machine        "x86_64"
>>
>>
>> > Session
>>
>>
>> > sessionInfo()
>>
>> R version 3.4.1 (2017-06-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Debian GNU/Linux 9 (stretch)
>>
>> Matrix products: default
>> BLAS: /usr/local/lib/R/lib/libRblas.so
>> LAPACK: /usr/local/lib/R/lib/libRlapack.so
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From henr|k@bengt@@on @end|ng |rom gm@||@com  Mon Jul 23 14:54:05 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Mon, 23 Jul 2018 14:54:05 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <8760165fg2.fsf@gmail.com>
References: <87d0ve5jn5.fsf@gmail.com>
 <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
 <8760165fg2.fsf@gmail.com>
Message-ID: <CAFDcVCSFEfE7o7vTfKF28etYnx6xA-xPf6hBt-jMNhQbc=Yqog@mail.gmail.com>

This is intended/expected because the spdep package *depends* on the
spData package (see https://cran.r-project.org/web/packages/spdep/),
which means that the maintainer of spdep intends also spData to be
*attached* whenever spdep is attached.    If they would have only
imported it, then spData would only be *loaded* (but not attached),
and you would not get 'spData' on your search() path and therefore not
see 'x' either.

Example:

## Loading spData
> loadNamespace("spData")
<environment: namespace:spData>

> loadedNamespaces()
[1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
[7] "methods"   "spData"    "base"

## The search path used to find objects
> search()
[1] ".GlobalEnv"        "package:stats"     "package:graphics"
[4] "package:grDevices" "package:utils"     "package:datasets"
[7] "package:methods"   "Autoloads"         "package:base"

## So, spData::x is not found
> x
Error: object 'x' not found

## But is still there
> spData::x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450


## Attaching spData, which also happens when you do library(spdat)
> library(spData)
To access larger datasets in this package, install the spDataLarge
package with: `install.packages('spDataLarge',
repos='https://nowosad.github.io/drat/', type='source'))

> loadedNamespaces()
[1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
[7] "methods"   "spData"    "base"

## Now, spData is on the search path
> search()
 [1] ".GlobalEnv"        "package:spData"    "package:stats"
 [4] "package:graphics"  "package:grDevices" "package:utils"
 [7] "package:datasets"  "package:methods"   "Autoloads"
[10] "package:base

> x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450

> find("x")
[1] "package:spData"

/Henrik
On Mon, Jul 23, 2018 at 2:01 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>
>
> Helllo,
>
> Thanks for the info. I still think these variables should not be loaded
> when library(spdep) is called.
>
> But I'll handle it following your suggestion.
>
> Thanks,
>
> Jeremie
>
>
>
>
>
>
> > It turns out that that 'x' comes from the spData package and lives
> > inside that package (part of its namespace).
> >
> >> spData::x
> >  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> >
> > This is conceptually no different from other objects in package
> > namespace, although we are more used to seeing functions and not data
> > object.  Another well-known example of this is:
> >
> >> base::pi
> > [1] 3.141593
> >
> > So, this 'x' is *not* in your global workspace and you cannot remove
> > it without unloading the package.
> >
> > /Henrik
>
>
> >>
> >>
> >> I found a dangerous issue in the library spdep. I get variables x and y
> >> that cannot be removed by rm() and I don't don't how they show up. Can
> >> anyone reproduce this?
> >>
> >> ~$ R --vanilla
> >> > rm(list=ls())
> >> > library(spdep)
> >> > x
> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> >> > rm(list=ls())
> >> > x
> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
> >>
> >>
> >>
> >> > Sys.info()
> >>
> >> sysname        "Linux"
> >> release        "4.9.0-6-amd64"
> >> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
> >> nodename       "freegnu"
> >> machine        "x86_64"
> >>
> >>
> >> > Session
> >>
> >>
> >> > sessionInfo()
> >>
> >> R version 3.4.1 (2017-06-30)
> >> Platform: x86_64-pc-linux-gnu (64-bit)
> >> Running under: Debian GNU/Linux 9 (stretch)
> >>
> >> Matrix products: default
> >> BLAS: /usr/local/lib/R/lib/libRblas.so
> >> LAPACK: /usr/local/lib/R/lib/libRlapack.so
> >>
> >> locale:
> >>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >> loaded via a namespace (and not attached):
> >> [1] compiler_3.4.1
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.



From jerem|eju@te @end|ng |rom gm@||@com  Mon Jul 23 15:44:53 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 15:44:53 +0200
Subject: [R] [FORGED]  [bug] spdep package?
In-Reply-To: <f62ae796-ae12-f5b3-3951-bc6fbcc35b6c@auckland.ac.nz> (Rolf
 Turner's message of "Mon, 23 Jul 2018 22:58:16 +1200")
References: <87d0ve5jn5.fsf@gmail.com>
 <f62ae796-ae12-f5b3-3951-bc6fbcc35b6c@auckland.ac.nz>
Message-ID: <871sbu5ane.fsf@gmail.com>


Hello,


>This is *very* unlikely to be a bug.  People should always exercise a
>great deal of caution about conjecturing bugs when they encounter a
>phenomenon that they don't understand.

Ok,  I over reacted and I should let the package maintainers
qualify what is a bug or not. My point is that it is surprising to have
access these variables in the global environment when loading the spdep
library.

I normally I would expect the following

 rm(list=ls())
 myfun <- function(x){
        y+ 33}
        
> myfun(x)
> Error in myfun(4) : object 'y' not found

But this is not cool 
> myfun()
 [1]  33  63  93 123 153 183 213 243 273 303 333 363 393 423 453 483


> It puzzles me that your sessionInfo() doesn't show something like:
You are right. My apologies. I confused sessions when I pasted the
sessionInfo.  Allow me to correct.



<on the Terminal> R --vanilla -q 
> ls()
character(0)
> library(spdep)
Loading required package: sp
Loading required package: Matrix
Loading required package: spData
To access larger datasets in this package, install the spDataLarge
package with: `install.packages('spDataLarge')`
> ls()
character(0)
> sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux 9 (stretch)

Matrix products: default
BLAS: /usr/local/lib/R/lib/libRblas.so
LAPACK: /usr/local/lib/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] spdep_0.7-7    spData_0.2.6.7 Matrix_1.2-10  sp_1.2-5      

loaded via a namespace (and not attached):
 [1] lattice_0.20-35     deldir_0.1-14       gtools_3.5.0       
 [4] MASS_7.3-47         grid_3.4.1          nlme_3.1-131       
 [7] coda_0.19-1         data.table_1.10.4-3 gdata_2.18.0       
[10] LearnBayes_2.15     gmodels_2.16.2      boot_1.3-19        
[13] splines_3.4.1       compiler_3.4.1      filehash_2.4-1     
[16] expm_0.999-2       
> x
 [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450


I think Henrik Bengtsson has identified the issue see the next thread. 

Best regards,

Jeremie



From jerem|eju@te @end|ng |rom gm@||@com  Mon Jul 23 20:13:00 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Mon, 23 Jul 2018 20:13:00 +0200
Subject: [R] [bug] spdep package?
In-Reply-To: <CAFDcVCSFEfE7o7vTfKF28etYnx6xA-xPf6hBt-jMNhQbc=Yqog@mail.gmail.com>
 (Henrik Bengtsson's message of "Mon, 23 Jul 2018 14:54:05 +0200")
References: <87d0ve5jn5.fsf@gmail.com>
 <CAFDcVCRefxKLTbZo1bhska8yED=LSX5LBzDdE_NU9dXyU3HMOw@mail.gmail.com>
 <8760165fg2.fsf@gmail.com>
 <CAFDcVCSFEfE7o7vTfKF28etYnx6xA-xPf6hBt-jMNhQbc=Yqog@mail.gmail.com>
Message-ID: <87wotl4y8j.fsf@gmail.com>


Many thanks for the info.

I see the point but I'll think calling the spData would be a cheaper
price to pay. If each package one load provide access to their variables
things are likely to get messy.

I guess many R users would like to control the variables in their global
environment.

And since it is not trival to protect variables inside a function from
the parent environment this is potentially dangerous.

Best wishes,

Jeremie










Henrik Bengtsson <henrik.bengtsson at gmail.com> writes:

> This is intended/expected because the spdep package *depends* on the
> spData package (see https://cran.r-project.org/web/packages/spdep/),
> which means that the maintainer of spdep intends also spData to be
> *attached* whenever spdep is attached.    If they would have only
> imported it, then spData would only be *loaded* (but not attached),
> and you would not get 'spData' on your search() path and therefore not
> see 'x' either.
>
> Example:
>
> ## Loading spData
>> loadNamespace("spData")
> <environment: namespace:spData>
>
>> loadedNamespaces()
> [1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
> [7] "methods"   "spData"    "base"
>
> ## The search path used to find objects
>> search()
> [1] ".GlobalEnv"        "package:stats"     "package:graphics"
> [4] "package:grDevices" "package:utils"     "package:datasets"
> [7] "package:methods"   "Autoloads"         "package:base"
>
> ## So, spData::x is not found
>> x
> Error: object 'x' not found
>
> ## But is still there
>> spData::x
>  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
> ## Attaching spData, which also happens when you do library(spdat)
>> library(spData)
> To access larger datasets in this package, install the spDataLarge
> package with: `install.packages('spDataLarge',
> repos='https://nowosad.github.io/drat/', type='source'))
>
>> loadedNamespaces()
> [1] "compiler"  "graphics"  "utils"     "grDevices" "stats"     "datasets"
> [7] "methods"   "spData"    "base"
>
> ## Now, spData is on the search path
>> search()
>  [1] ".GlobalEnv"        "package:spData"    "package:stats"
>  [4] "package:graphics"  "package:grDevices" "package:utils"
>  [7] "package:datasets"  "package:methods"   "Autoloads"
> [10] "package:base
>
>> x
>  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>
>> find("x")
> [1] "package:spData"
>
> /Henrik
> On Mon, Jul 23, 2018 at 2:01 PM Jeremie Juste <jeremiejuste at gmail.com> wrote:
>>
>>
>> Helllo,
>>
>> Thanks for the info. I still think these variables should not be loaded
>> when library(spdep) is called.
>>
>> But I'll handle it following your suggestion.
>>
>> Thanks,
>>
>> Jeremie
>>
>>
>>
>>
>>
>>
>> > It turns out that that 'x' comes from the spData package and lives
>> > inside that package (part of its namespace).
>> >
>> >> spData::x
>> >  [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> >
>> > This is conceptually no different from other objects in package
>> > namespace, although we are more used to seeing functions and not data
>> > object.  Another well-known example of this is:
>> >
>> >> base::pi
>> > [1] 3.141593
>> >
>> > So, this 'x' is *not* in your global workspace and you cannot remove
>> > it without unloading the package.
>> >
>> > /Henrik
>>
>>
>> >>
>> >>
>> >> I found a dangerous issue in the library spdep. I get variables x and y
>> >> that cannot be removed by rm() and I don't don't how they show up. Can
>> >> anyone reproduce this?
>> >>
>> >> ~$ R --vanilla
>> >> > rm(list=ls())
>> >> > library(spdep)
>> >> > x
>> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> >> > rm(list=ls())
>> >> > x
>> >> [1]   0  30  60  90 120 150 180 210 240 270 300 330 360 390 420 450
>> >>
>> >>
>> >>
>> >> > Sys.info()
>> >>
>> >> sysname        "Linux"
>> >> release        "4.9.0-6-amd64"
>> >> version        "#1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07)"
>> >> nodename       "freegnu"
>> >> machine        "x86_64"
>> >>
>> >>
>> >> > Session
>> >>
>> >>
>> >> > sessionInfo()
>> >>
>> >> R version 3.4.1 (2017-06-30)
>> >> Platform: x86_64-pc-linux-gnu (64-bit)
>> >> Running under: Debian GNU/Linux 9 (stretch)
>> >>
>> >> Matrix products: default
>> >> BLAS: /usr/local/lib/R/lib/libRblas.so
>> >> LAPACK: /usr/local/lib/R/lib/libRlapack.so
>> >>
>> >> locale:
>> >>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> >>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> >>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> >>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> >>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> >> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> >>
>> >> attached base packages:
>> >> [1] stats     graphics  grDevices utils     datasets  methods   base
>> >>
>> >> loaded via a namespace (and not attached):
>> >> [1] compiler_3.4.1
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.



From |r|end|y @end|ng |rom yorku@c@  Mon Jul 23 21:41:28 2018
From: |r|end|y @end|ng |rom yorku@c@ (Michael Friendly)
Date: Mon, 23 Jul 2018 15:41:28 -0400
Subject: [R] Automate running files in R
In-Reply-To: <alpine.LNX.2.20.1807221533130.4416@salmo.appl-ecosys.com>
References: <CAPk26q9KiZJZZ9Kh+TqQscX1jzrXMhnzbpZ=16pmja-scTMEwg@mail.gmail.com>
 <alpine.LNX.2.20.1807221533130.4416@salmo.appl-ecosys.com>
Message-ID: <f33ec57d-b36b-cc01-7105-c141412b47f8@yorku.ca>

Hi Serena

I'll add one more "in addition" to this list of suggestions. It may not 
be what you were thinking of, but may be far simpler in the long run.

The complexity of your approach comes from having separate data files 
for each subject and trial, for which you have to have a convention for
naming files and organizing them into coherently named directories.

The ideal solution would be to write your data into a single file, in 
which subjects and trials would just be separate columns.  More 
generally, anything you can do to change separate files into 
lines/records in a data frame will ease your task.

-Michael

On 7/22/18 6:40 PM, Rich Shepard wrote:
> On Sun, 22 Jul 2018, Serena De Stefani wrote:
> 
>> I need to automate a process in R. Basically I have a an R script (I will
>> call it R1) that needs three separate files to run. These three files are
>> the results output of one trial in my study.
> 
>> The trials are specified by the labels: AA AB AM BA BB BM MA MB MM. So 
>> for
>> subject 1, trial 1, I will have three files with the ending
>> ?mov1_AA
>>
>> For subject one, trial 2, R should choose the three files with the 
>> ending ?
>> mov1_AB and so on.
> 
> Serena,
> 
>  ? In addition to Jim's advice about your directory structure you should
> seriously consider your file naming convention. Just like variable names in
> a program, you're almost guaranteed to not remember what each two-character
> name means within six months of creating them. Spend a little more time
> typing and use descriptive names ... and think of using a .dat extension 
> and
> using read.table(*.dat).
> 
>  ? You can name your files, for example, input_1.R, input_2.R, and 
> input_3.R
> for your run sources. And, for (e.g.,) subject 1, trial 1, name the file
> sub1_trial1. This might produce output called sub1_trial1_input1,
> sub1_trial1_input2, and sub1_trial1_input3.
> 
>  ? Now when you look at data.frames or output you and everyone else will 
> know
> just what each contains.
> 
> Have fun,
> 
> Rich
>



From m|ch@e|@m@tt@ @end|ng |rom un|m|b@|t  Tue Jul 24 05:21:38 2018
From: m|ch@e|@m@tt@ @end|ng |rom un|m|b@|t (michael matta)
Date: Mon, 23 Jul 2018 23:21:38 -0400
Subject: [R] RStudio Exploratory Factor Analysis: write a function that
 extracts an increasing number of factors
Message-ID: <CAPbjefcjyEpdAmP+PeZbQ1XDNkZ5orCExPt4xPREnbzkqz0hFw@mail.gmail.com>

I have been trying to write a function in Rstudio that extracts an
increasing number of latent factors for the EFA and reports fit measures
for each solution in a final table. Below, I pasted what I was able to come
up with.

Unfortunately, it has some critical limitations:

The for loop requires to set the interval of factors that will be
extracted. That is fine but it would be nicer if the function stopped when
it reaches an error message (such as "maximum iteration exceeded",
"convergence not obtained in GPFoblq").

The final table includes an ugly first column with the label "RMSEA" which
is completely useless but I cannot get rid of it.

In general, the for loop might not be the most elegant way to reach the
goal.

 library(psych)
 library(GPArotation)
 library(dplyr)
 library(plyr)
 library(qgraph)

 efas <- list()

 for (i in 1:10) {
     fitn <- fa(big5, nfactors = i, fm = "pa", rotate = "oblimin",
     scores = "regression")
     efas[[i]] <- data.frame(fitn$TLI, fitn$RMSEA[1], fitn$rms, fitn$BIC)
%>%
     mutate(Factors = i) %>%
     dplyr::rename(TLI = fitn.TLI,
            RMSEA = fitn.RMSEA.1.,
            SRMR = fitn.rms,
            BIC = fitn.BIC) %>%
     dplyr::select(Factors, TLI, RMSEA, SRMR, BIC)

     }

  do.call("rbind", efas) %>%
    kable()


Thanks for any help!

-- 
*Michael Matta, **Ph.D.*
Postdoctoral Research Associate, Department of Applied Psychology
408 International Village
360 Huntington Ave
Northeastern University
Boston, MA 02115

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Jul 24 07:31:21 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 24 Jul 2018 06:31:21 +0100
Subject: [R] RStudio Exploratory Factor Analysis: write a function that
 extracts an increasing number of factors
In-Reply-To: <CAPbjefcjyEpdAmP+PeZbQ1XDNkZ5orCExPt4xPREnbzkqz0hFw@mail.gmail.com>
References: <CAPbjefcjyEpdAmP+PeZbQ1XDNkZ5orCExPt4xPREnbzkqz0hFw@mail.gmail.com>
Message-ID: <6ed58ddf-fbef-f601-30f0-375f5b68c4a3@sapo.pt>

Hello,

The output of kable() is a character vector, so you can solve your 
problem with a regex.


res <- do.call("rbind", efas) %>%
   kable()

res2 <- sub("^\\|[^|]+(\\|.*)", "\\1", res)
head(res2)


Alternatively, a more tidyverse like way would be to pipe the output of 
kable() through sub().


do.call("rbind", efas) %>%
   kable() %>%
   sub("^\\|[^|]+(\\|.*)", "\\1", .)


Hope this helps,

Rui Barradas

?s 04:21 de 24-07-2018, michael matta escreveu:
> I have been trying to write a function in Rstudio that extracts an
> increasing number of latent factors for the EFA and reports fit measures
> for each solution in a final table. Below, I pasted what I was able to come
> up with.
> 
> Unfortunately, it has some critical limitations:
> 
> The for loop requires to set the interval of factors that will be
> extracted. That is fine but it would be nicer if the function stopped when
> it reaches an error message (such as "maximum iteration exceeded",
> "convergence not obtained in GPFoblq").
> 
> The final table includes an ugly first column with the label "RMSEA" which
> is completely useless but I cannot get rid of it.
> 
> In general, the for loop might not be the most elegant way to reach the
> goal.
> 
>   library(psych)
>   library(GPArotation)
>   library(dplyr)
>   library(plyr)
>   library(qgraph)
> 
>   efas <- list()
> 
>   for (i in 1:10) {
>       fitn <- fa(big5, nfactors = i, fm = "pa", rotate = "oblimin",
>       scores = "regression")
>       efas[[i]] <- data.frame(fitn$TLI, fitn$RMSEA[1], fitn$rms, fitn$BIC)
> %>%
>       mutate(Factors = i) %>%
>       dplyr::rename(TLI = fitn.TLI,
>              RMSEA = fitn.RMSEA.1.,
>              SRMR = fitn.rms,
>              BIC = fitn.BIC) %>%
>       dplyr::select(Factors, TLI, RMSEA, SRMR, BIC)
> 
>       }
> 
>    do.call("rbind", efas) %>%
>      kable()
> 
> 
> Thanks for any help!
>



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Tue Jul 24 12:17:41 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Tue, 24 Jul 2018 15:47:41 +0530
Subject: [R] Stop a loop if it takes long time
Message-ID: <CA+dpOJnihhCj0D5dmLiBpUsu5h1X3XLUEX2CK=dWSRaXCA6XZw@mail.gmail.com>

Hi,

Let say I am implementing a loop using for() / apply()-family etc.

Now, the calculation-time within a particular loop is not fixed, means,
some loop takes a long time to finish calculation, and next loop perhaps
very quick to finish.

I am exploring if there is any way, to check if the calculation within a
particular loop takes longer time than a pre-fixed threshold and if it does
then kill that loop and proceed to the next.

Is it possible to implement such without adding much overhead with existing
calculation?

Thanks for your feedback

	[[alternative HTML version deleted]]



From pro|jcn@@h @end|ng |rom gm@||@com  Tue Jul 24 14:19:59 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 24 Jul 2018 08:19:59 -0400
Subject: [R] historic(al) algorithms in R
Message-ID: <518109e8-e5b1-b86b-a274-58862709ba04@gmail.com>

R users may or may not be aware of the long history of some of the codes
and algorithms used by base R and by packages. There is a small effort
under way to try to document and improve understanding of these, and
R Consortium has allocated some funds. We've now got a Working Group
and some preliminary documents / examples, but would welcome wider
participation, and an invitation to participate or even just lurk on
the project follows. We especially welcome younger workers so the
understanding of older codes and languages can be passed on.

John Nash

INVITATION

The histoRicalg project is a modest effort to try to document the
older, historic algorithms that underpin R. Some other computational
environments (NumPy, Octave, Gnu Scientific Library, etc.) likely
have similar codes. However, such numerical tools are often written
or at least presented in Fortran or other older programming
languages. The R-Consortium has granted us a small amount of money
for this activity.

This is an invitation to join a small group of workers who hope
to share information and expertise so the methods are documented
and the understanding of older program code is passed on.

Our activities live on Gitlab as a file repository at

   https://gitlab.com/nashjc/histoRicalg

and a wiki at

   https://gitlab.com/nashjc/histoRicalg/wikis/home

We have a mailing list that is based at

   https://lists.r-consortium.org/g/rconsortium-project-histoRicalg

If you work with older algorithms or have relevant expertise, please
join us, even if you plan only to lurk on the list or gitlab site
and may only kibbitz from time to time. This is an activity that
requires a modest input from those with a wide range of knowledge
and backgrounds rather than intense effort by a very few.

Yours,


The histoRicalg Working Group



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul 24 15:42:18 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 24 Jul 2018 06:42:18 -0700
Subject: [R] Stop a loop if it takes long time
In-Reply-To: <CA+dpOJnihhCj0D5dmLiBpUsu5h1X3XLUEX2CK=dWSRaXCA6XZw@mail.gmail.com>
References: <CA+dpOJnihhCj0D5dmLiBpUsu5h1X3XLUEX2CK=dWSRaXCA6XZw@mail.gmail.com>
Message-ID: <D1A66FA6-9EB8-471F-BA5A-6FB6D7F75C1E@dcn.davis.ca.us>

Depends somewhat on what you are doing in the loop and how much of a performance hit you are willing to accept. [1]

[1] https://stackoverflow.com/questions/7891073/time-out-an-r-command-via-something-like-try

On July 24, 2018 3:17:41 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi,
>
>Let say I am implementing a loop using for() / apply()-family etc.
>
>Now, the calculation-time within a particular loop is not fixed, means,
>some loop takes a long time to finish calculation, and next loop
>perhaps
>very quick to finish.
>
>I am exploring if there is any way, to check if the calculation within
>a
>particular loop takes longer time than a pre-fixed threshold and if it
>does
>then kill that loop and proceed to the next.
>
>Is it possible to implement such without adding much overhead with
>existing
>calculation?
>
>Thanks for your feedback
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Tue Jul 24 16:25:20 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 24 Jul 2018 07:25:20 -0700
Subject: [R] Issue : Time to run a model on different computers
In-Reply-To: <D5958810-F3C7-4851-9EFA-C11CDE18683D@gmail.com>
References: <2DA4DB26-631C-46C9-8D3D-9B59D38FEA05@gmail.com>
 <CAGxFJbQkdthZecppVAHBD7EF=AvKrUPjYQ7=Rf=wTPXdT77PhA@mail.gmail.com>
 <D5958810-F3C7-4851-9EFA-C11CDE18683D@gmail.com>
Message-ID: <CAGxFJbRtayZibr2Cg_CoHN3dQGXYA75uThycGTG-LBA7R60xag@mail.gmail.com>

1. Unless there is good reason not to, always cc the list, which I have
done here.

2. I should have added that memory usage and possible swapping issues also
depends on what other software you have running, not just on how much
memory you have.

In other words, I see no way to answer your question without some sort of
local diagnostics. Perhaps others might have a better idea.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jul 24, 2018 at 2:24 AM, louis DALPRA <dalpra.louis at gmail.com>
wrote:

> Hello Bert,
>
> First thank?s a lot for your answer !
> My memory resource is ? 4 go 1600 Mhz DDR3 ?, for my teacher?s computer I
> don?t know but I?ll ask him. You can find in attachment the code I?m using
> if you want to look at it (the model and 2 functions that are called). Is
> there a way to know for sure if it?s caused by memory limitation ?
>
> Have a nice day,
> Louis
>
> Le 22 juil. 2018 ? 19:20, Bert Gunter <bgunter.4567 at gmail.com> a ?crit :
>
> You did not say what memory resources were in the two cases, and it is
> probably impossible to say without knowing what code you ran in any case.
> That you have different versions of OS and R on the two computers already
> means that there could be many possible explanations, but one wild guess is
> that on your computer/R version/OS version you are memory limited and
> swapping to and from disk, while on the other you are not. This may well be
> nothing more than stupid speculation, though.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Jul 22, 2018 at 5:24 AM, louis DALPRA <dalpra.louis at gmail.com>
> wrote:
>
>> Hello,
>>
>> My issue is related to the time it takes to run a model on R between two
>> different computers. On my teacher?s computer (MacBook Pro 2013; OS 10.9.5;
>> R version 3.1.3) it takes only a few minutes to run it while on mine
>> (MacBook Air 2014; OS 10.13.6; R version 3.5.1) it takes several hours. I
>> checked for malware, and reinstalled the system but still no changes. Does
>> any one have an idea on what might be the issue ?
>>
>> In advance thank?s for your time and answers.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>
>

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jul 24 23:38:04 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 24 Jul 2018 14:38:04 -0700
Subject: [R] pROC
In-Reply-To: <trinity-c719bf86-35fa-4f71-b74f-46e7639cdd19-1532346216576@3c-app-gmx-bs38>
References: <trinity-c719bf86-35fa-4f71-b74f-46e7639cdd19-1532346216576@3c-app-gmx-bs38>
Message-ID: <29393C89-272E-4E1A-90C3-7E9DDB0A577F@comcast.net>


> On Jul 23, 2018, at 4:43 AM, Maria Enzian <M.Enzian at gmx.de> wrote:
> 
> 
> 
> Hello,
> I'm using the package pROC in RStudio to create my ROC-curves and I have patients in my data - healthy or sick - in the column "Status" and the value "SUVmax" to examine it.
> I used the following code:
> plot.roc(daten$Status,daten$SUVmax,percent=TRUE,ci=TRUE,print.auc=TRUE,main="ROC-Kurve f?r den SUVmax")
> The ROC-curve I got is ok, but on the x-axis I got a specificity from 150% to -50%, but I want the scale from 100% to 0% (as usual).
> xlim=c(100,0) doesn't work.
> Can someone help me?

Perhaps if we had data that allowed investigation, we might be able to help, but the example dataset on the help page shows `plot.roc` to be delivering expected results.

>  
> Best regards
> M.Enzian
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From t@n@@@ @end|ng |rom gm@||@com  Wed Jul 25 02:48:43 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Tue, 24 Jul 2018 17:48:43 -0700
Subject: [R] coloring edges in IGRAPH
Message-ID: <CA+JEM01Sfz4yPnvsD+x2i77iq9n__WSF6a0QLg8uDy7TduDrhg@mail.gmail.com>

Dear all,

I would appreciate a piece of advice please : I am aiming to color the
edges in a graph, by using IGRAPH package.

It works well for the big braph, however, when I decompose the graph into 2
subgraphs and color code those, the color of the edges change
(unexpectedly).

more precisely, as an example -- we have a dataframe :

el <- data.frame(Partner1=c(1, 3, 4, 5, 6), Partner2=c(2, 2, 5, 7, 7),
TYPE=c("DEL", "DEL", "DUP", "TRA", "TRA"))

el$COLOR[el$TYPE=="DEL"] <- "red"

el$COLOR[el$TYPE=="DUP"] <- "green"

el$COLOR[el$TYPE=="INS"] <- "yellow"

el$COLOR[el$TYPE=="INV"] <- "brown"

el$COLOR[el$TYPE=="TRA"] <- "blue"

#> el
#  Partner1 Partner2 TYPE COLOR
#1        1        2  DEL   red
#2        3        2  DEL   red
#3        4        5  DUP green
#4        5        7  TRA  blue
#5        6        7  TRA  blue

g <- graph_from_data_frame(d = el, directed = TRUE)

plot(g, edge.color=el$COLOR)

### here decomposing the graph into 2 SUBGRAPHS :

g_decompose <- decompose.graph(g)

plot(g_decompose[[1]], edge.color=el$COLOR) ## here the edges are red (that
is fine)

plot(g_decompose[[2]], edge.color=el$COLOR) ## here the edges shall be blue
and green, not red and green .

#####################################################

many thanks !

-- bogdan

	[[alternative HTML version deleted]]



From t@n@@@ @end|ng |rom gm@||@com  Wed Jul 25 04:34:46 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Tue, 24 Jul 2018 19:34:46 -0700
Subject: [R] coloring edges in IGRAPH
In-Reply-To: <CA+JEM01Sfz4yPnvsD+x2i77iq9n__WSF6a0QLg8uDy7TduDrhg@mail.gmail.com>
References: <CA+JEM01Sfz4yPnvsD+x2i77iq9n__WSF6a0QLg8uDy7TduDrhg@mail.gmail.com>
Message-ID: <CA+JEM01qUY-2sCztMLYEyd60OWCwqdyRKVZyZoLod8iGD8MTVg@mail.gmail.com>

Thank you all. Think I did solve it by using the code below :

plot(g_decompose[[1]], edge.color=edge_attr(g_decompose[[1]])$COLOR)

plot(g_decompose[[2]], edge.color=edge_attr(g_decompose[[2]])$COLOR)

On Tue, Jul 24, 2018 at 5:48 PM, Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all,
>
> I would appreciate a piece of advice please : I am aiming to color the
> edges in a graph, by using IGRAPH package.
>
> It works well for the big braph, however, when I decompose the graph into
> 2 subgraphs and color code those, the color of the edges change
> (unexpectedly).
>
> more precisely, as an example -- we have a dataframe :
>
> el <- data.frame(Partner1=c(1, 3, 4, 5, 6), Partner2=c(2, 2, 5, 7, 7),
> TYPE=c("DEL", "DEL", "DUP", "TRA", "TRA"))
>
> el$COLOR[el$TYPE=="DEL"] <- "red"
>
> el$COLOR[el$TYPE=="DUP"] <- "green"
>
> el$COLOR[el$TYPE=="INS"] <- "yellow"
>
> el$COLOR[el$TYPE=="INV"] <- "brown"
>
> el$COLOR[el$TYPE=="TRA"] <- "blue"
>
> #> el
> #  Partner1 Partner2 TYPE COLOR
> #1        1        2  DEL   red
> #2        3        2  DEL   red
> #3        4        5  DUP green
> #4        5        7  TRA  blue
> #5        6        7  TRA  blue
>
> g <- graph_from_data_frame(d = el, directed = TRUE)
>
> plot(g, edge.color=el$COLOR)
>
> ### here decomposing the graph into 2 SUBGRAPHS :
>
> g_decompose <- decompose.graph(g)
>
> plot(g_decompose[[1]], edge.color=el$COLOR) ## here the edges are red
> (that is fine)
>
> plot(g_decompose[[2]], edge.color=el$COLOR) ## here the edges shall be
> blue and green, not red and green .
>
> #####################################################
>
> many thanks !
>
> -- bogdan
>
>

	[[alternative HTML version deleted]]



From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Wed Jul 25 08:17:18 2018
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Wed, 25 Jul 2018 06:17:18 +0000
Subject: [R] Using apply function to merge list of data frames
Message-ID: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>

I have a list whose components are data frames.  My goal is to construct a data frame by merging all the list components.  Is it possible to achieve this using apply and without a for loop, as used below?

Thanks,
Naresh

mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
                                  length.out = 5), ret = rnorm(5)),
               B = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
                                  length.out = 5), ret = rnorm(5)))
 
mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week', length.out = 5))
 
for(ch in names(mylist)){
    tempdf <- mylist[[ch]]
    names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
    mydf <- merge(mydf, tempdf, by = c('date'))}


From bhh @end|ng |rom x@4@||@n|  Wed Jul 25 08:32:52 2018
From: bhh @end|ng |rom x@4@||@n| (Berend Hasselman)
Date: Wed, 25 Jul 2018 08:32:52 +0200
Subject: [R] Using apply function to merge list of data frames
In-Reply-To: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
References: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
Message-ID: <03B6FB5E-E21C-4211-8B8B-FC681C641C57@xs4all.nl>



> On 25 Jul 2018, at 08:17, Naresh Gurbuxani <naresh_gurbuxani at hotmail.com> wrote:
> 
> I have a list whose components are data frames.  My goal is to construct a data frame by merging all the list components.  Is it possible to achieve this using apply and without a for loop, as used below?
> 
> Thanks,
> Naresh
> 
> mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
>                                  length.out = 5), ret = rnorm(5)),
>               B = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
>                                  length.out = 5), ret = rnorm(5)))
> 
> mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week', length.out = 5))
> 
> for(ch in names(mylist)){
>    tempdf <- mylist[[ch]]
>    names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
>    mydf <- merge(mydf, tempdf, by = c('date'))}
> _

See if these would help:

on R-help the thread

https://stat.ethz.ch/pipermail/r-help/2018-May/454249.html

and 

https://stackoverflow.com/questions/4512465/what-is-the-most-efficient-way-to-cast-a-list-as-a-data-frame?rq=1

Berend



From t@n@@@ @end|ng |rom gm@||@com  Wed Jul 25 08:55:10 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Tue, 24 Jul 2018 23:55:10 -0700
Subject: [R] initiate elements in a dataframe with lists
Message-ID: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>

Dear all,

assuming that I do have a dataframe like :

x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
POSA=c(10, 15, 120, 340, 100, 220),
CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
POSB=c(30, 100, 300, 20, 200, 320)) ,

how could I initiate another 2 columns in x, where each element in these 2
columns is going to be a list (the list could be updated later). Thank you !

Shall I do,

for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}

for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}

nothing is happening. Thank you very much !

	[[alternative HTML version deleted]]



From jte||er|@@rproject @end|ng |rom gm@||@com  Wed Jul 25 09:56:40 2018
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Wed, 25 Jul 2018 09:56:40 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
Message-ID: <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>

Check tidyverse's purrr package:

https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf

In the second page of the cheatsheet there is info on how to create list
columns within a data.frame :)

	[[alternative HTML version deleted]]



From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Jul 25 09:26:30 2018
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 25 Jul 2018 09:26:30 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
Message-ID: <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>

Dear Bogdan,

You are looking for x$intersectA <- vector("list", nrow(x))

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:

> Dear all,
>
> assuming that I do have a dataframe like :
>
> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
> POSA=c(10, 15, 120, 340, 100, 220),
> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
> POSB=c(30, 100, 300, 20, 200, 320)) ,
>
> how could I initiate another 2 columns in x, where each element in these 2
> columns is going to be a list (the list could be updated later). Thank you
> !
>
> Shall I do,
>
> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>
> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>
> nothing is happening. Thank you very much !
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From c@|@ndr@ @end|ng |rom rgzm@de  Wed Jul 25 10:23:55 2018
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 25 Jul 2018 10:23:55 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
Message-ID: <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>

Just for my understanding:
Is a data.frame with list columns still a data.frame? Isn't it then a list?

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 25/07/2018 09:56, Juan Telleria Ruiz de Aguirre wrote:
> Check tidyverse's purrr package:
>
> https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf
>
> In the second page of the cheatsheet there is info on how to create list
> columns within a data.frame :)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jte||er|@@rproject @end|ng |rom gm@||@com  Wed Jul 25 11:56:05 2018
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Wed, 25 Jul 2018 11:56:05 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
Message-ID: <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>

> Just for my understanding:
> Is a data.frame with list columns still a data.frame? Isn't it then a list?

* A data.frame (or tibble) is a list of columns.
* In which each column must be from the same data type, in this case list().



From jte||er|@@rproject @end|ng |rom gm@||@com  Wed Jul 25 11:58:23 2018
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Wed, 25 Jul 2018 11:58:23 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
 <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
Message-ID: <CAJXDcw3zr8ZV67LMq3AhYtKdq8As0=tHjHAwm6uUmTaj2KPt2g@mail.gmail.com>

By the way, this also works:

dfl <- data.frame(x = 1:3, y = I(list(1:2, 1:3, 1:4)))

As indicated in "Advanced R" book:
http://adv-r.had.co.nz/Data-structures.html#data-frames



From c@|@ndr@ @end|ng |rom rgzm@de  Wed Jul 25 12:09:18 2018
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 25 Jul 2018 12:09:18 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
 <CAJXDcw2SUPhX24XzBw6zCViSyLGRCwx7djwuO5BeiFG8fkDXBA@mail.gmail.com>
Message-ID: <41f55760-2a47-1a31-1d6e-dbee7d93d8cf@rgzm.de>

At first I was actually thinking about this situation, which cannot work:|
data.frame(x = 1:3, y = list(1:2, 1:3, 1:4))

|But I had never thought about this:|
df$y <-list(1:2, 1:3, 1:4)|
And it actually makes sense. The final requirement here is that all 
columns must have the same length!

I'm not sure though why one would need that. Why not use lists in that case?

Thanks!
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 25/07/2018 11:56, Juan Telleria Ruiz de Aguirre wrote:
>> Just for my understanding:
>> Is a data.frame with list columns still a data.frame? Isn't it then a list?
> * A data.frame (or tibble) is a list of columns.
> * In which each column must be from the same data type, in this case list().
>


	[[alternative HTML version deleted]]



From toth@dene@ @end|ng |rom kogentum@hu  Wed Jul 25 12:41:57 2018
From: toth@dene@ @end|ng |rom kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Wed, 25 Jul 2018 12:41:57 +0200
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
 <00ac6c6a-0418-2a1c-7a87-cbac2850faf5@rgzm.de>
Message-ID: <d4daeb99-b5af-5f60-2364-f16bcdbad21e@kogentum.hu>



On 07/25/2018 10:23 AM, Ivan Calandra wrote:
> Just for my understanding:
> Is a data.frame with list columns still a data.frame? Isn't it then a list?

A data.frame is a list of equally sized vectors - that is, each vector 
must be of the same length. It is not required that the vector is an 
atomic vector; it can be a list, too. By having equally sized vectors in 
a list you can arrange the list in a two-dimensional matrix-like format, 
append row names to them, and you get a data.frame.

Principally data.frame(x = 1:3, y = list(1:2, 1:3, 1:4)) should work, 
but it doesn't, as it was recognized by others, too:
https://stackoverflow.com/questions/9547518/create-a-data-frame-where-a-column-is-a-list

Cheers,
Denes


> 
> Ivan
> 
> -- 
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> On 25/07/2018 09:56, Juan Telleria Ruiz de Aguirre wrote:
>> Check tidyverse's purrr package:
>>
>> https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf
>>
>> In the second page of the cheatsheet there is info on how to create list
>> columns within a data.frame :)
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From tembe-@t@@@sio-dz m@iii@g oii y@u@jp  Wed Jul 25 13:21:55 2018
From: tembe-@t@@@sio-dz m@iii@g oii y@u@jp (tembe-@t@@@sio-dz m@iii@g oii y@u@jp)
Date: Wed, 25 Jul 2018 11:21:55 +0000
Subject: [R] Query on convergence
Message-ID: <TYAPR01MB28770550B08A333260C13865C7540@TYAPR01MB2877.jpnprd01.prod.outlook.com>

Hello,



Is there somebody who can demonstrate how to code a while loop that ends when a convergence between the values of two or more variables (say vectors) is reached? Thank you

Regards


	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jul 25 13:55:53 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 25 Jul 2018 11:55:53 +0000
Subject: [R] Query on convergence
In-Reply-To: <TYAPR01MB28770550B08A333260C13865C7540@TYAPR01MB2877.jpnprd01.prod.outlook.com>
References: <TYAPR01MB28770550B08A333260C13865C7540@TYAPR01MB2877.jpnprd01.prod.outlook.com>
Message-ID: <87534a1c43f64322ba270ae8b3680c98@SRVEXCHCM1302.precheza.cz>

Hi

maybe

ii<-TRUE
while(ii) {

do something
if(some condition of two variables is met) {ii <- FALSE}

}

But in R such constructions are seldom necessary.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of tembe-
> atanasio-dz at ynu.jp
> Sent: Wednesday, July 25, 2018 1:22 PM
> To: r-help at r-project.org
> Subject: [R] Query on convergence
>
> Hello,
>
>
>
> Is there somebody who can demonstrate how to code a while loop that ends
> when a convergence between the values of two or more variables (say vectors)
> is reached? Thank you
>
> Regards
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From t@n@@@ @end|ng |rom gm@||@com  Wed Jul 25 14:53:37 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 05:53:37 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJXDcw1ScZtKtm2fQS2kg=OM_cyUtiTVZTirE=VSq0mSnkffrg@mail.gmail.com>
Message-ID: <CA+JEM01Bjbb_3Fg-D0VRPp-APjJy-cGH+eHWEBUWaTGyY0ziSQ@mail.gmail.com>

Thank you Juan.

On Wed, Jul 25, 2018 at 12:56 AM, Juan Telleria Ruiz de Aguirre <
jtelleria.rproject at gmail.com> wrote:

> Check tidyverse's purrr package:
>
> https://github.com/rstudio/cheatsheets/raw/master/purrr.pdf
>
> In the second page of the cheatsheet there is info on how to create list
> columns within a data.frame :)
>

	[[alternative HTML version deleted]]



From t@n@@@ @end|ng |rom gm@||@com  Wed Jul 25 15:26:12 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 06:26:12 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
Message-ID: <CA+JEM00HJeoK+oAC6GC0i5ssjC-jpyW1HUZmqpuLExFq8v0UCQ@mail.gmail.com>

Dear Thierry and Juan, thank you for your help. Thank you very much.

Now, if I would like to add an element to the empty list, how shall I do :
for example, shall i = 2, and j = 1, in a bit of more complex R code :

x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
POSA=c(10, 15, 120, 340, 100, 220),
CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
POSB=c(30, 100, 300, 20, 200, 320))

x$labA <- paste(x$CHRA, x$POSA, sep="_")
x$labB <- paste(x$CHRB, x$POSB, sep="_")

x$POSA_left <- x$POSA - 10
x$POSA_right <- x$POSA + 10

x$POSB_left <- x$POSB - 10
x$POSB_right <- x$POSB + 10

x$intersectA <- rep(list(list()), nrow(x))
x$intersectB <- rep(list(list()), nrow(x))

And we know that for i = 2, and j = 1, the condition is TRUE :

i <- 2
j <- 1

if ( (x$CHRA[i] == x$CHRA[j] ) &&
     (x$POSA[i] > x$POSA_left[j] ) &&
     (x$POSA[i] < x$POSA_right[j] ) )
{
   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])
}

the R code does not work. Thank you for your kind help !


>
> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Bogdan,
>>
>> You are looking for x$intersectA <- vector("list", nrow(x))
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>
>>> Dear all,
>>>
>>> assuming that I do have a dataframe like :
>>>
>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>> POSA=c(10, 15, 120, 340, 100, 220),
>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>
>>> how could I initiate another 2 columns in x, where each element in these
>>> 2
>>> columns is going to be a list (the list could be updated later). Thank
>>> you !
>>>
>>> Shall I do,
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>
>>> nothing is happening. Thank you very much !
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]



From huze|@@kh@||| @end|ng |rom um|ch@edu  Wed Jul 25 15:40:19 2018
From: huze|@@kh@||| @end|ng |rom um|ch@edu (Huzefa Khalil)
Date: Wed, 25 Jul 2018 09:40:19 -0400
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM00HJeoK+oAC6GC0i5ssjC-jpyW1HUZmqpuLExFq8v0UCQ@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
 <CA+JEM00HJeoK+oAC6GC0i5ssjC-jpyW1HUZmqpuLExFq8v0UCQ@mail.gmail.com>
Message-ID: <CADsG8gMMPqxqr4zbSE3X8dU9eaBtkLT02ZR3_9L_t+fatSZX6g@mail.gmail.com>

Hi Bogdan,

Does the following do what you expect?

x$intersectA[[i]] <- c(x$intersectA[[i]], x$labA[j])

Note the difference between `[[` and `[`


On Wed, Jul 25, 2018 at 9:26 AM, Bogdan Tanasa <tanasa at gmail.com> wrote:
> Dear Thierry and Juan, thank you for your help. Thank you very much.
>
> Now, if I would like to add an element to the empty list, how shall I do :
> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>
> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
> POSA=c(10, 15, 120, 340, 100, 220),
> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
> POSB=c(30, 100, 300, 20, 200, 320))
>
> x$labA <- paste(x$CHRA, x$POSA, sep="_")
> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>
> x$POSA_left <- x$POSA - 10
> x$POSA_right <- x$POSA + 10
>
> x$POSB_left <- x$POSB - 10
> x$POSB_right <- x$POSB + 10
>
> x$intersectA <- rep(list(list()), nrow(x))
> x$intersectB <- rep(list(list()), nrow(x))
>
> And we know that for i = 2, and j = 1, the condition is TRUE :
>
> i <- 2
> j <- 1
>
> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>      (x$POSA[i] > x$POSA_left[j] ) &&
>      (x$POSA[i] < x$POSA_right[j] ) )
> {
>    x$intersectA[i] <- c(x$intersectA[i], x$labA[j])
> }
>
> the R code does not work. Thank you for your kind help !
>
>
>>
>> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Bogdan,
>>>
>>> You are looking for x$intersectA <- vector("list", nrow(x))
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>>
>>>> Dear all,
>>>>
>>>> assuming that I do have a dataframe like :
>>>>
>>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>>> POSA=c(10, 15, 120, 340, 100, 220),
>>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>>
>>>> how could I initiate another 2 columns in x, where each element in these
>>>> 2
>>>> columns is going to be a list (the list could be updated later). Thank
>>>> you !
>>>>
>>>> Shall I do,
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>>
>>>> nothing is happening. Thank you very much !
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ev@n@kr@n@dor| @end|ng |rom gm@||@com  Wed Jul 25 16:35:26 2018
From: ev@n@kr@n@dor| @end|ng |rom gm@||@com (Evan Kransdorf)
Date: Wed, 25 Jul 2018 07:35:26 -0700
Subject: [R] DiagrammeR and grViz
Message-ID: <CAKZWb7dCdCm00-=QdHc1Wvo0SeZibruAACAGG5OLiv2n1wYmvg@mail.gmail.com>

Is anyone using DiagrammeR and grViz?

I made a nice grViz but when I use RStudio to export quality looks bad
(need high resolution figure).

I can't quite figure out how to use DiagrammeR to export the grViz I made.
Any suggestions?

Thank you, Evan

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 16:41:55 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 07:41:55 -0700 (PDT)
Subject: [R] A couple of batch mode questions
Message-ID: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>

   Within R one can use source() to run a batch file of R commands, while R CMD BATCH
and Rscript are run from the command line. Is this correct?

   Given these choices, when would I want to run a script within R using
source(), and when would it be better for me to run it from the command
line?

   Reading Appendix B.4 Scripting with R in R-info.pdf, ?Rscipt, and ?BATCH I
get the impression that 'R CMD BATCH' reads from a named file and writes
output to a named file and Rscript reads/writes to stdin/stdout using
redirection. What are the pros and cons of each? When (or why) would I
select one over the other?

TIA,

Rich



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 25 16:47:59 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 25 Jul 2018 07:47:59 -0700
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>

"Within R one can use source() to run a batch file of R commands, while R
CMD BATCH
and Rscript are run from the command line. Is this correct?"

Yes.

I think your query answers your query: You use Rscript when you want to use
R in the command environment, perhaps as part of an analytical pipeline;
and you source an R file when you want to work within R.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 7:41 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   Within R one can use source() to run a batch file of R commands, while R
> CMD BATCH
> and Rscript are run from the command line. Is this correct?
>
>   Given these choices, when would I want to run a script within R using
> source(), and when would it be better for me to run it from the command
> line?
>
>   Reading Appendix B.4 Scripting with R in R-info.pdf, ?Rscipt, and ?BATCH
> I
> get the impression that 'R CMD BATCH' reads from a named file and writes
> output to a named file and Rscript reads/writes to stdin/stdout using
> redirection. What are the pros and cons of each? When (or why) would I
> select one over the other?
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From HDor@n @end|ng |rom @|r@org  Wed Jul 25 16:57:13 2018
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Wed, 25 Jul 2018 14:57:13 +0000
Subject: [R] SQL Database
Message-ID: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>

I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.

The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.

The sequence of work (I think) I just this:

Step 1: Connect to the remote server (connection string and authenticate the user)
Step 2: Have a SQL query statement that grabs the tables from the remote server 
Step 3: Close the connection

The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 

Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?

Thanks,
Harold



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 17:22:56 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 08:22:56 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Bert Gunter wrote:

> "Within R one can use source() to run a batch file of R commands, while R
> CMD BATCH and Rscript are run from the command line. Is this correct?"
>
> Yes.

Bert,

   Thanks for confirming.

> I think your query answers your query: You use Rscript when you want to use
> R in the command environment, perhaps as part of an analytical pipeline;
> and you source an R file when you want to work within R.

   That's a given. Why would I prefer Rscript over R CMD BATCH, or
vice-versa? I did not see much difference between the two in their help
files.

Regards,

Rich



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 25 17:23:51 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 25 Jul 2018 08:23:51 -0700
Subject: [R] SQL Database
In-Reply-To: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbS7zemo90E8_daffGrWJ_fXFa_scxWMG8AjV8yJq9JtBQ@mail.gmail.com>

https://rviews.rstudio.com/2017/10/18/database-queries-with-r/

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 7:57 AM, Doran, Harold <HDoran at air.org> wrote:

> I'm doing some work now to learn which SQL database package is the most
> optimal for the task I am working on. There are many packages, and I'm
> reviewing the documentation on some of them now. I am seeking advice from
> those of you who might suggest a package to use for the task I am currently
> working with.
>
> The work is currently as follows. My users currently use another tool to
> extract tables from a server, save those tables as .csv files, and then
> those csv files are read into R and stuff is done on the data in those
> files. This adds overhead that can be bypassed if users instead can
> directly access the database from within R and grab the tables they need
> and then those tables are data frames in the R session and available to do
> stuff.
>
> The sequence of work (I think) I just this:
>
> Step 1: Connect to the remote server (connection string and authenticate
> the user)
> Step 2: Have a SQL query statement that grabs the tables from the remote
> server
> Step 3: Close the connection
>
> The two packages I have narrowed my studies to are Dbplyr and RODBC, both
> of which seem to be similar.
>
> Any experiences out there to suggest these two packages are in fact right
> for this task, or would there be other packages that might be more optimal
> for this?
>
> Thanks,
> Harold
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 17:37:58 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 08:37:58 -0700 (PDT)
Subject: [R] A couple of batch mode questions [ANSWERED]
In-Reply-To: <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807250836190.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Rich Shepard wrote:

>  That's a given. Why would I prefer Rscript over R CMD BATCH, or
> vice-versa? I did not see much difference between the two in their help
> files.

   Digging deeper into the Web I read that R CMD BATCH is an older approach
to automating R processing from the command line and Rscript is the newer
approach. My question's answered.

Rich



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jul 25 18:30:53 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 25 Jul 2018 09:30:53 -0700
Subject: [R] DiagrammeR and grViz
In-Reply-To: <CAKZWb7dCdCm00-=QdHc1Wvo0SeZibruAACAGG5OLiv2n1wYmvg@mail.gmail.com>
References: <CAKZWb7dCdCm00-=QdHc1Wvo0SeZibruAACAGG5OLiv2n1wYmvg@mail.gmail.com>
Message-ID: <D32D2BCE-DD28-40E4-B4E4-B0E30BBD3F05@dcn.davis.ca.us>

The Export option from the interactive Plots view is a terrible option for any publication-quality graphics.

There are many [1] ways to make publication-quality graphics in R, and there can be some operating-system-specific downstream tools considerations that affect what works best for you. I happen to prefer using Rmd/Rnw files (knitr+rmarkdown or knitr+latex) with png format in most cases. You can specify the default resolution/size as well as having special settings for specific images [2].

If this is all new to you, then you might want to read some of the many intros on the web, like [3][4].

[1] help(package="grDevices")
[2] https://yihui.name/knitr/options/#plots
[3] https://sachsmc.github.io/knit-git-markr-guide/knitr/knit.html
[4] https://rmarkdown.rstudio.com/articles_intro.html

On July 25, 2018 7:35:26 AM PDT, Evan Kransdorf <evan.kransdorf at gmail.com> wrote:
>Is anyone using DiagrammeR and grViz?
>
>I made a nice grViz but when I use RStudio to export quality looks bad
>(need high resolution figure).
>
>I can't quite figure out how to use DiagrammeR to export the grViz I
>made.
>Any suggestions?
>
>Thank you, Evan
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From m@cqueen1 @end|ng |rom ||n|@gov  Wed Jul 25 18:36:37 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 25 Jul 2018 16:36:37 +0000
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
Message-ID: <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>

From my perspective, which is a unix-alike perspective, Rscript makes R useable in exactly the same way as other unix style scripting languages such as perl,  tcsh, bash, etc. This is useful, and a good thing. If I remember (and understood) correctly, it is why Rscript was introduced, later in R's history than BATCH.

Scripts run using Rscript can be (slightly) more self-contained, which I suppose might or might not be an advantage, depending on one's needs:

To run an R script using Rscript, I type
   ./myRscript.r
at the command line (less typing), whereas with batch mode, it has to be
   R CMD BATCH myRscript.r
(more typing) but if I want any R options applied, such as --no-restore or --no-save, I include them within the script when using Rscript, but have to put them on the command line outside the script when using BATCH.

One can actually execute an R command at the shell prompt using Rscript, which can't be done with BATCH:

[296]% Rscript -e 3+4
[1] 7
[298]% Rscript -e 'sqrt(2)'
[1] 1.414214

If I want to pass custom parameters to the script (script-specific parameters of my own that I put on the command line), the syntax for either supplying them or parsing them might be different. I'm not sure, since I don't do this very often, and never use CMD BATCH. But it would be worth checking.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/25/18, 8:22 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Wed, 25 Jul 2018, Bert Gunter wrote:
    
    > "Within R one can use source() to run a batch file of R commands, while R
    > CMD BATCH and Rscript are run from the command line. Is this correct?"
    >
    > Yes.
    
    Bert,
    
       Thanks for confirming.
    
    > I think your query answers your query: You use Rscript when you want to use
    > R in the command environment, perhaps as part of an analytical pipeline;
    > and you source an R file when you want to work within R.
    
       That's a given. Why would I prefer Rscript over R CMD BATCH, or
    vice-versa? I did not see much difference between the two in their help
    files.
    
    Regards,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From t@n@@@ @end|ng |rom gm@||@com  Wed Jul 25 15:21:08 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 06:21:08 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
Message-ID: <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>

Dear Thierry and Juan, thank you for your help. Thank you all.

Now, if I would like to add an element to the empty list, how shall I do :
for example, shall i = 2, and j = 1, in a bit of more complex R code :

x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
POSA=c(10, 15, 120, 340, 100, 220),
CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
POSB=c(30, 100, 300, 20, 200, 320))

x$labA <- paste(x$CHRA, x$POSA, sep="_")
x$labB <- paste(x$CHRB, x$POSB, sep="_")

x$POSA_left <- x$POSA - 10
x$POSA_right <- x$POSA + 10

x$POSB_left <- x$POSB - 10
x$POSB_right <- x$POSB + 10

x$intersectA <- rep(list(list()), nrow(x))
x$intersectB <- rep(list(list()), nrow(x))

And we know that for i = 2, and j = 1, the condition is TRUE :

i <- 2

j <- 1

if ( (x$CHRA[i] == x$CHRA[j] ) &&
     (x$POSA[i] > x$POSA_left[j] ) &&
     (x$POSA[i] < x$POSA_right[j] ) ){
   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}

the R code does not work. Thank you for your kind help !

On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Bogdan,
>
> You are looking for x$intersectA <- vector("list", nrow(x))
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>
>> Dear all,
>>
>> assuming that I do have a dataframe like :
>>
>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>> POSA=c(10, 15, 120, 340, 100, 220),
>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>
>> how could I initiate another 2 columns in x, where each element in these 2
>> columns is going to be a list (the list could be updated later). Thank
>> you !
>>
>> Shall I do,
>>
>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>
>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>
>> nothing is happening. Thank you very much !
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From n4|bz @end|ng |rom t@mp@b@y@rr@com  Wed Jul 25 19:11:55 2018
From: n4|bz @end|ng |rom t@mp@b@y@rr@com (Robert D. Bowers M.A.)
Date: Wed, 25 Jul 2018 13:11:55 -0400
Subject: [R] Formatting multi-way ANOVA output for spectra analysis
Message-ID: <7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>

I've studied R a little bit, although I haven't used it in some time 
(except via RCommander).? I'm working on my dissertation project and 
have spectrometer data that I need to evaluate.? I need to find a way to 
simplify the output from multi-way ANOVA so I can reduce the areas of 
the spectrum to only those where there are significant differences 
between sites.? (A preliminary study on a too-small sample size 
indicates that certain areas of the spectrum can distinguish between 
sites.? This project is the next step.)

The dataset is comprised of analyses done on samples from five separate 
locations, with 50 samples taken from each site.? The output of the 
spectrometer per sample is values for 2048 individual wavelengths, in a 
spreadsheet with the wavelength as the first column.? Since I'm doing 
the analysis wavelength-by-wavelength, I've transposed the data and 
broke the data for the project down into smaller spreadsheets (so that R 
can perform ANOVA on each wavelength).

The problem is, I can do ANOVA now on each wavelength, but I don't need 
a full output table for each... I just need to know if there is 
significant variation between any of the sites at that wavelength, based 
on 95% confidence level (or better).? If I could get some sort of simple 
chart (or a single line in a spreadsheet), that would help to narrow 
down the areas of the spectrum that I need to focus on to evaluate the 
results of the tests.

I've been reading information about ANOVA, but have found very little 
that is clear about formatting the output - and I don't need to rehash 
all of the math.? I just need to find out how to hack down the output to 
just the part I need (if possible).? Once that's done, I can decide what 
wavelengths are valuable for future tests and simplify the process.

Thanks for any help given!

Bob



From er|cjberger @end|ng |rom gm@||@com  Wed Jul 25 19:28:01 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 25 Jul 2018 20:28:01 +0300
Subject: [R] A couple of batch mode questions
In-Reply-To: <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
Message-ID: <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>

Some additional comments that might be relevant to people interested in
these topics.

1. For R scripts you should also consider the package littler developed by
Dirk Eddelbuettel, Highly recommended.
For info http://dirk.eddelbuettel.com/code/littler.html or the github
repository.

2. Scripts can be useful both for short calculations, extending the shell,
or for large R jobs that are not interactive and can run unsupervised.
e.g. I have a script that is run automatically on a daily schedule. It
performs a number of calculations and updates a database with the results.

3. When creating a large-ish R project that will run as a script, I still
break the task into smaller tasks which are implemented as R scripts which
are source()'ed into the batch job.
The smaller R scripts are usually developed and debugged in an interactive
environment, such as RStudio.

Best,
Eric


On Wed, Jul 25, 2018 at 7:36 PM, MacQueen, Don via R-help <
r-help at r-project.org> wrote:

> From my perspective, which is a unix-alike perspective, Rscript makes R
> useable in exactly the same way as other unix style scripting languages
> such as perl,  tcsh, bash, etc. This is useful, and a good thing. If I
> remember (and understood) correctly, it is why Rscript was introduced,
> later in R's history than BATCH.
>
> Scripts run using Rscript can be (slightly) more self-contained, which I
> suppose might or might not be an advantage, depending on one's needs:
>
> To run an R script using Rscript, I type
>    ./myRscript.r
> at the command line (less typing), whereas with batch mode, it has to be
>    R CMD BATCH myRscript.r
> (more typing) but if I want any R options applied, such as --no-restore or
> --no-save, I include them within the script when using Rscript, but have to
> put them on the command line outside the script when using BATCH.
>
> One can actually execute an R command at the shell prompt using Rscript,
> which can't be done with BATCH:
>
> [296]% Rscript -e 3+4
> [1] 7
> [298]% Rscript -e 'sqrt(2)'
> [1] 1.414214
>
> If I want to pass custom parameters to the script (script-specific
> parameters of my own that I put on the command line), the syntax for either
> supplying them or parsing them might be different. I'm not sure, since I
> don't do this very often, and never use CMD BATCH. But it would be worth
> checking.
>
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 7/25/18, 8:22 AM, "R-help on behalf of Rich Shepard" <
> r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:
>
>     On Wed, 25 Jul 2018, Bert Gunter wrote:
>
>     > "Within R one can use source() to run a batch file of R commands,
> while R
>     > CMD BATCH and Rscript are run from the command line. Is this
> correct?"
>     >
>     > Yes.
>
>     Bert,
>
>        Thanks for confirming.
>
>     > I think your query answers your query: You use Rscript when you want
> to use
>     > R in the command environment, perhaps as part of an analytical
> pipeline;
>     > and you source an R file when you want to work within R.
>
>        That's a given. Why would I prefer Rscript over R CMD BATCH, or
>     vice-versa? I did not see much difference between the two in their help
>     files.
>
>     Regards,
>
>     Rich
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jul 25 19:43:52 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 25 Jul 2018 10:43:52 -0700 (PDT)
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>

The code below reeks of a misconception that lists are efficient to add 
items to, which is a confusion with the computer science term "linked 
list".  In R, a list is NOT a linked list... it is a vector, which means 
the memory used by the list is allocated at the time it is created, and 
REALLOCATED when a new item is added. The only reason you should use a 
list is because you expect to put values of different types or shapes into 
it, which does not appear to apply in this use case.

In R, you should make a valiant effort to create things right the first 
time, and if that doesn't work then preallocate the space you will need in 
the vectors you are working with. Since you have a need to store a 
variable number of elements in each intersectX element, the column needs 
to be a list but the elements of that list can perfectly well be character 
vectors.

x <- data.frame( TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA")
                , CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2")
                , POSA=c(10, 15, 120, 340, 100, 220)
                , CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1")
                , POSB=c(30, 100, 300, 20, 200, 320)
                , stringsAsFactors = FALSE
                )
compareRng <- function( chr1, pos1, chr2, pos2, delta ) {
   ( chr1 == chr2
   & ( pos2 - delta ) < pos1
   & pos1 < ( pos2 + delta )
   )
}
makeIntersectX <- function( n, chrlabel, poslabel, delta ) {
   lgclidx <- rep( TRUE, nrow( x ) )
   lgclidx[ n ] <- FALSE
   x[[ chrlabel ]][ compareRng( x[[ chrlabel ]][ n ]
                     , x[[ poslabel ]][ n ]
                     , x[[ chrlabel ]]
                     , x[[ poslabel ]]
                     , delta
                     )
         & lgclidx
         ]
}

x$intersectA <- lapply( seq.int( nrow( x ) )
                       , makeIntersectX
                       , chrlabel = "CHRA"
                       , poslabel = "POSA"
                       , delta = 10L
                       )
x$intersectB <- lapply( seq.int( nrow( x ) )
                       , makeIntersectX
                       , chrlabel = "CHRB"
                       , poslabel = "POSB"
                       , delta = 21L
                       )
> x
   TYPE CHRA POSA CHRB POSB intersectA intersectB
1  DEL chr1   10 chr1   30       chr1
2  DEL chr1   15 chr1  100       chr1
3  DUP chr1  120 chr1  300                  chr1
4  TRA chr1  340 chr2   20
5  INV chr2  100 chr2  200
6  TRA chr2  220 chr1  320                  chr1

Note that depending on what you plan to do beyond this point, it might 
actually be more performant to use a data frame with repeated rows instead 
of list columns... but I cannot tell from what you have provided.

On Wed, 25 Jul 2018, Bogdan Tanasa wrote:

> Dear Thierry and Juan, thank you for your help. Thank you all.
>
> Now, if I would like to add an element to the empty list, how shall I do :
> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>
> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
> POSA=c(10, 15, 120, 340, 100, 220),
> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
> POSB=c(30, 100, 300, 20, 200, 320))
>
> x$labA <- paste(x$CHRA, x$POSA, sep="_")
> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>
> x$POSA_left <- x$POSA - 10
> x$POSA_right <- x$POSA + 10
>
> x$POSB_left <- x$POSB - 10
> x$POSB_right <- x$POSB + 10
>
> x$intersectA <- rep(list(list()), nrow(x))
> x$intersectB <- rep(list(list()), nrow(x))
>
> And we know that for i = 2, and j = 1, the condition is TRUE :
>
> i <- 2
>
> j <- 1
>
> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>     (x$POSA[i] > x$POSA_left[j] ) &&
>     (x$POSA[i] < x$POSA_right[j] ) ){
>   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}
>
> the R code does not work. Thank you for your kind help !
>
> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
>> wrote:
>
>> Dear Bogdan,
>>
>> You are looking for x$intersectA <- vector("list", nrow(x))
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>
>>> Dear all,
>>>
>>> assuming that I do have a dataframe like :
>>>
>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>> POSA=c(10, 15, 120, 340, 100, 220),
>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>
>>> how could I initiate another 2 columns in x, where each element in these 2
>>> columns is going to be a list (the list could be updated later). Thank
>>> you !
>>>
>>> Shall I do,
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>
>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>
>>> nothing is happening. Thank you very much !
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From t@n@@@ @end|ng |rom gm@||@com  Wed Jul 25 19:58:28 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 25 Jul 2018 10:58:28 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
 <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM01KdYDdbMBMxsLeKRHOZqg8PV4BVOKO73TiAzo5K=P-pQ@mail.gmail.com>

Dear Jeff, it is a precious help and a fabulous suggestion. I will slowly
go over the R code that you have sent. Thanks a lot !

On Wed, Jul 25, 2018 at 10:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The code below reeks of a misconception that lists are efficient to add
> items to, which is a confusion with the computer science term "linked
> list".  In R, a list is NOT a linked list... it is a vector, which means
> the memory used by the list is allocated at the time it is created, and
> REALLOCATED when a new item is added. The only reason you should use a list
> is because you expect to put values of different types or shapes into it,
> which does not appear to apply in this use case.
>
> In R, you should make a valiant effort to create things right the first
> time, and if that doesn't work then preallocate the space you will need in
> the vectors you are working with. Since you have a need to store a variable
> number of elements in each intersectX element, the column needs to be a
> list but the elements of that list can perfectly well be character vectors.
>
> x <- data.frame( TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA")
>                , CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2")
>                , POSA=c(10, 15, 120, 340, 100, 220)
>                , CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1")
>                , POSB=c(30, 100, 300, 20, 200, 320)
>                , stringsAsFactors = FALSE
>                )
> compareRng <- function( chr1, pos1, chr2, pos2, delta ) {
>   ( chr1 == chr2
>   & ( pos2 - delta ) < pos1
>   & pos1 < ( pos2 + delta )
>   )
> }
> makeIntersectX <- function( n, chrlabel, poslabel, delta ) {
>   lgclidx <- rep( TRUE, nrow( x ) )
>   lgclidx[ n ] <- FALSE
>   x[[ chrlabel ]][ compareRng( x[[ chrlabel ]][ n ]
>                     , x[[ poslabel ]][ n ]
>                     , x[[ chrlabel ]]
>                     , x[[ poslabel ]]
>                     , delta
>                     )
>         & lgclidx
>         ]
> }
>
> x$intersectA <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRA"
>                       , poslabel = "POSA"
>                       , delta = 10L
>                       )
> x$intersectB <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRB"
>                       , poslabel = "POSB"
>                       , delta = 21L
>                       )
>
>> x
>>
>   TYPE CHRA POSA CHRB POSB intersectA intersectB
> 1  DEL chr1   10 chr1   30       chr1
> 2  DEL chr1   15 chr1  100       chr1
> 3  DUP chr1  120 chr1  300                  chr1
> 4  TRA chr1  340 chr2   20
> 5  INV chr2  100 chr2  200
> 6  TRA chr2  220 chr1  320                  chr1
>
> Note that depending on what you plan to do beyond this point, it might
> actually be more performant to use a data frame with repeated rows instead
> of list columns... but I cannot tell from what you have provided.
>
>
> On Wed, 25 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Thierry and Juan, thank you for your help. Thank you all.
>>
>> Now, if I would like to add an element to the empty list, how shall I do :
>> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>>
>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>> POSA=c(10, 15, 120, 340, 100, 220),
>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>> POSB=c(30, 100, 300, 20, 200, 320))
>>
>> x$labA <- paste(x$CHRA, x$POSA, sep="_")
>> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>>
>> x$POSA_left <- x$POSA - 10
>> x$POSA_right <- x$POSA + 10
>>
>> x$POSB_left <- x$POSB - 10
>> x$POSB_right <- x$POSB + 10
>>
>> x$intersectA <- rep(list(list()), nrow(x))
>> x$intersectB <- rep(list(list()), nrow(x))
>>
>> And we know that for i = 2, and j = 1, the condition is TRUE :
>>
>> i <- 2
>>
>> j <- 1
>>
>> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>>     (x$POSA[i] > x$POSA_left[j] ) &&
>>     (x$POSA[i] < x$POSA_right[j] ) ){
>>   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}
>>
>> the R code does not work. Thank you for your kind help !
>>
>> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be
>>
>>> wrote:
>>>
>>
>> Dear Bogdan,
>>>
>>> You are looking for x$intersectA <- vector("list", nrow(x))
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND
>>> FOREST
>>> Team Biometrie &
>>> <https://maps.google.com/?q=Biometrie+%26+&entry=gmail&source=g>Kwaliteitszorg
>>> / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>>
>>> Dear all,
>>>>
>>>> assuming that I do have a dataframe like :
>>>>
>>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>>> POSA=c(10, 15, 120, 340, 100, 220),
>>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>>
>>>> how could I initiate another 2 columns in x, where each element in
>>>> these 2
>>>> columns is going to be a list (the list could be updated later). Thank
>>>> you !
>>>>
>>>> Shall I do,
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>>
>>>> nothing is happening. Thank you very much !
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Wed Jul 25 20:18:17 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 25 Jul 2018 11:18:17 -0700
Subject: [R] initiate elements in a dataframe with lists
In-Reply-To: <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
References: <CA+JEM03j1-8-i7HUj8-B_LKVXsz_StBwk2EyzipSbcy92Z78HA@mail.gmail.com>
 <CAJuCY5y+FUASar7Q6e7V++cUpEx2m6oC5DoFCKaN5t6op0rm-A@mail.gmail.com>
 <CA+JEM03Wq_nvGHoaKJM1A6Xrr0OrJXRC6CiiSGvZXvzsX_ARgw@mail.gmail.com>
 <alpine.BSF.2.00.1807251030350.79637@pedal.dcn.davis.ca.us>
Message-ID: <CAF8bMcYKTdmxs8Sxn9MtwzwYMPFyZOUwh-_uFdAZd2yzLihSfw@mail.gmail.com>

If you need to make a list of long but unknown length you can save time by
adding the items to an environment, with names giving the order, then
converting the environment to a list when you are done filling the
environment.  E.g.,

> makeData
function (container, n)
{
    for (i in seq_len(n)) container[[sprintf("%06x", i)]] <- seq_len(i%%5)
    container
}
> # use an environment
> system.time(E <- makeData(new.env(parent=emptyenv()), 10^5))
   user  system elapsed
   0.38    0.00    0.38
> # convert environment to a list
> system.time(EL <- as.list(E, sorted=TRUE))
   user  system elapsed
   0.62    0.00    0.62
> # use a list
> system.time(L <- makeData(list(), 10^5))
   user  system elapsed
 142.56    1.46  153.78
> all.equal(EL, L)
[1] TRUE


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Jul 25, 2018 at 10:43 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The code below reeks of a misconception that lists are efficient to add
> items to, which is a confusion with the computer science term "linked
> list".  In R, a list is NOT a linked list... it is a vector, which means
> the memory used by the list is allocated at the time it is created, and
> REALLOCATED when a new item is added. The only reason you should use a list
> is because you expect to put values of different types or shapes into it,
> which does not appear to apply in this use case.
>
> In R, you should make a valiant effort to create things right the first
> time, and if that doesn't work then preallocate the space you will need in
> the vectors you are working with. Since you have a need to store a variable
> number of elements in each intersectX element, the column needs to be a
> list but the elements of that list can perfectly well be character vectors.
>
> x <- data.frame( TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA")
>                , CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2")
>                , POSA=c(10, 15, 120, 340, 100, 220)
>                , CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1")
>                , POSB=c(30, 100, 300, 20, 200, 320)
>                , stringsAsFactors = FALSE
>                )
> compareRng <- function( chr1, pos1, chr2, pos2, delta ) {
>   ( chr1 == chr2
>   & ( pos2 - delta ) < pos1
>   & pos1 < ( pos2 + delta )
>   )
> }
> makeIntersectX <- function( n, chrlabel, poslabel, delta ) {
>   lgclidx <- rep( TRUE, nrow( x ) )
>   lgclidx[ n ] <- FALSE
>   x[[ chrlabel ]][ compareRng( x[[ chrlabel ]][ n ]
>                     , x[[ poslabel ]][ n ]
>                     , x[[ chrlabel ]]
>                     , x[[ poslabel ]]
>                     , delta
>                     )
>         & lgclidx
>         ]
> }
>
> x$intersectA <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRA"
>                       , poslabel = "POSA"
>                       , delta = 10L
>                       )
> x$intersectB <- lapply( seq.int( nrow( x ) )
>                       , makeIntersectX
>                       , chrlabel = "CHRB"
>                       , poslabel = "POSB"
>                       , delta = 21L
>                       )
>
>> x
>>
>   TYPE CHRA POSA CHRB POSB intersectA intersectB
> 1  DEL chr1   10 chr1   30       chr1
> 2  DEL chr1   15 chr1  100       chr1
> 3  DUP chr1  120 chr1  300                  chr1
> 4  TRA chr1  340 chr2   20
> 5  INV chr2  100 chr2  200
> 6  TRA chr2  220 chr1  320                  chr1
>
> Note that depending on what you plan to do beyond this point, it might
> actually be more performant to use a data frame with repeated rows instead
> of list columns... but I cannot tell from what you have provided.
>
> On Wed, 25 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Thierry and Juan, thank you for your help. Thank you all.
>>
>> Now, if I would like to add an element to the empty list, how shall I do :
>> for example, shall i = 2, and j = 1, in a bit of more complex R code :
>>
>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>> POSA=c(10, 15, 120, 340, 100, 220),
>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>> POSB=c(30, 100, 300, 20, 200, 320))
>>
>> x$labA <- paste(x$CHRA, x$POSA, sep="_")
>> x$labB <- paste(x$CHRB, x$POSB, sep="_")
>>
>> x$POSA_left <- x$POSA - 10
>> x$POSA_right <- x$POSA + 10
>>
>> x$POSB_left <- x$POSB - 10
>> x$POSB_right <- x$POSB + 10
>>
>> x$intersectA <- rep(list(list()), nrow(x))
>> x$intersectB <- rep(list(list()), nrow(x))
>>
>> And we know that for i = 2, and j = 1, the condition is TRUE :
>>
>> i <- 2
>>
>> j <- 1
>>
>> if ( (x$CHRA[i] == x$CHRA[j] ) &&
>>     (x$POSA[i] > x$POSA_left[j] ) &&
>>     (x$POSA[i] < x$POSA_right[j] ) ){
>>   x$intersectA[i] <- c(x$intersectA[i], x$labA[j])}
>>
>> the R code does not work. Thank you for your kind help !
>>
>> On Wed, Jul 25, 2018 at 12:26 AM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be
>>
>>> wrote:
>>>
>>
>> Dear Bogdan,
>>>
>>> You are looking for x$intersectA <- vector("list", nrow(x))
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND
>>> FOREST
>>> Team Biometrie &
>>> <https://maps.google.com/?q=Biometrie+%26+&entry=gmail&source=g>Kwaliteitszorg
>>> / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>> 2018-07-25 8:55 GMT+02:00 Bogdan Tanasa <tanasa at gmail.com>:
>>>
>>> Dear all,
>>>>
>>>> assuming that I do have a dataframe like :
>>>>
>>>> x <- data.frame(TYPE=c("DEL", "DEL", "DUP", "TRA", "INV", "TRA"),
>>>> CHRA=c("chr1", "chr1", "chr1", "chr1", "chr2", "chr2"),
>>>> POSA=c(10, 15, 120, 340, 100, 220),
>>>> CHRB=c("chr1", "chr1", "chr1", "chr2", "chr2", "chr1"),
>>>> POSB=c(30, 100, 300, 20, 200, 320)) ,
>>>>
>>>> how could I initiate another 2 columns in x, where each element in
>>>> these 2
>>>> columns is going to be a list (the list could be updated later). Thank
>>>> you !
>>>>
>>>> Shall I do,
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectA[i] <- list()}
>>>>
>>>> for (i in 1:dim(x)[1]) { x$intersectB[i] <- list()}
>>>>
>>>> nothing is happening. Thank you very much !
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 20:34:31 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 11:34:31 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
Message-ID: <alpine.LNX.2.20.1807251129360.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, MacQueen, Don wrote:

> From my perspective, which is a unix-alike perspective, Rscript makes R
> useable in exactly the same way as other unix style scripting languages
> such as perl, tcsh, bash, etc. This is useful, and a good thing. If I
> remember (and understood) correctly, it is why Rscript was introduced,
> later in R's history than BATCH.

Don,

   As a linux-only user for more than two decades I really appreciate the
value of running scripts from the command line. For a current project, after
extracting 29 years of data from PDF forms I ran them through a bash shell
script (passing the name of the source file as $1) that calls two sed and
six awk scripts. The output is ready to be read into R.

> If I want to pass custom parameters to the script (script-specific
> parameters of my own that I put on the command line), the syntax for
> either supplying them or parsing them might be different. I'm not sure,
> since I don't do this very often, and never use CMD BATCH. But it would be
> worth checking.

   This is what I need to work out now for Rscript: how to set positional or
named parameters on the command line with the source file name and the R
data.frame name.

   Thanks for your comments.

Best regards,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 20:41:42 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 11:41:42 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Eric Berger wrote:

> 1. For R scripts you should also consider the package littler developed by
> Dirk Eddelbuettel, Highly recommended. For info
> http://dirk.eddelbuettel.com/code/littler.html or the github repository.

Eric,

   I'll definintely look at that package.

> 2. Scripts can be useful both for short calculations, extending the shell,
> or for large R jobs that are not interactive and can run unsupervised.
> e.g. I have a script that is run automatically on a daily schedule. It
> performs a number of calculations and updates a database with the results.

   My immediate need is to import 30 data files, change factors into dates
and datetimes, print a summary, then plot a PDF scatterplot. This is why I
need to learn Rscript. I should be able to wrap that in a bash shell
script's for ... do loop that runs the Rscript for all *.dat files in the
directory.

Much appreciated,

Rich



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jul 25 21:17:48 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 25 Jul 2018 12:17:48 -0700
Subject: [R] Formatting multi-way ANOVA output for spectra analysis
In-Reply-To: <7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
References: <7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
Message-ID: <BB19452A-92B6-4B80-9031-074EA6A97E46@dcn.davis.ca.us>

In general, analysis functions in R return objects. When returned alone on an interactive console the default print method for that object gets printed. However, you can put it into a variable with the <- assignment operator, and use the str function to see what values are inside the object, and use the summary object to obtain another object with certain computed values depending on the analysis object. 

It might make sense to use a model analysis for this data... I don't know how you are handling variation in gross irradiance between measurements.

Anyway, this can get involved and you haven't provided sample data or code so this starts to get off topic (which is R, not statistics) pretty quick.


On July 25, 2018 10:11:55 AM PDT, "Robert D. Bowers M.A." <n4fbz at tampabay.rr.com> wrote:
>I've studied R a little bit, although I haven't used it in some time 
>(except via RCommander).? I'm working on my dissertation project and 
>have spectrometer data that I need to evaluate.? I need to find a way
>to 
>simplify the output from multi-way ANOVA so I can reduce the areas of 
>the spectrum to only those where there are significant differences 
>between sites.? (A preliminary study on a too-small sample size 
>indicates that certain areas of the spectrum can distinguish between 
>sites.? This project is the next step.)
>
>The dataset is comprised of analyses done on samples from five separate
>
>locations, with 50 samples taken from each site.? The output of the 
>spectrometer per sample is values for 2048 individual wavelengths, in a
>
>spreadsheet with the wavelength as the first column.? Since I'm doing 
>the analysis wavelength-by-wavelength, I've transposed the data and 
>broke the data for the project down into smaller spreadsheets (so that
>R 
>can perform ANOVA on each wavelength).
>
>The problem is, I can do ANOVA now on each wavelength, but I don't need
>
>a full output table for each... I just need to know if there is 
>significant variation between any of the sites at that wavelength,
>based 
>on 95% confidence level (or better).? If I could get some sort of
>simple 
>chart (or a single line in a spreadsheet), that would help to narrow 
>down the areas of the spectrum that I need to focus on to evaluate the 
>results of the tests.
>
>I've been reading information about ANOVA, but have found very little 
>that is clear about formatting the output - and I don't need to rehash 
>all of the math.? I just need to find out how to hack down the output
>to 
>just the part I need (if possible).? Once that's done, I can decide
>what 
>wavelengths are valuable for future tests and simplify the process.
>
>Thanks for any help given!
>
>Bob
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From er|cjberger @end|ng |rom gm@||@com  Wed Jul 25 21:48:03 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 25 Jul 2018 22:48:03 +0300
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
Message-ID: <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>

You should be able to do all this within R.
>From what you have written I don't see a compelling reason to use scripts
at the shell level.

Best,
Eric


On Wed, Jul 25, 2018 at 9:41 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 25 Jul 2018, Eric Berger wrote:
>
> 1. For R scripts you should also consider the package littler developed by
>> Dirk Eddelbuettel, Highly recommended. For info
>> http://dirk.eddelbuettel.com/code/littler.html or the github repository.
>>
>
> Eric,
>
>   I'll definintely look at that package.
>
> 2. Scripts can be useful both for short calculations, extending the shell,
>> or for large R jobs that are not interactive and can run unsupervised.
>> e.g. I have a script that is run automatically on a daily schedule. It
>> performs a number of calculations and updates a database with the results.
>>
>
>   My immediate need is to import 30 data files, change factors into dates
> and datetimes, print a summary, then plot a PDF scatterplot. This is why I
> need to learn Rscript. I should be able to wrap that in a bash shell
> script's for ... do loop that runs the Rscript for all *.dat files in the
> directory.
>
> Much appreciated,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 22:02:33 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 13:02:33 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
 <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Eric Berger wrote:

> You should be able to do all this within R. From what you have written I
> don't see a compelling reason to use scripts at the shell level.

Eric,

   The source() help page's last example calls a set of scripts to run
sequentially. I assume this is used to run the same .R script on each file,
with any file-specific variables used in each one. Perhaps I'm not seeing
how to pass parameters to the script call with source() so that the same .R
script can be automagically run for each imput file name. In my newness to
this it appears Rscript allows running the same script substituting inpu
file names based on arguments on the Rscript command line.

Regards,

Rich



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 25 22:27:16 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 25 Jul 2018 13:27:16 -0700
Subject: [R] A couple of batch mode questions
In-Reply-To: <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
 <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
 <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbQ4t4mjpibt6Ph-ibrvUTuhPQT-06FXzKU6TrTFeg6sNA@mail.gmail.com>

Eric may have more to say, but the straightforward answer is: use functions
to do what you want and pass any file specific info to them as parameters
of function calls.

If this seems arcane to you, then you have some homework to do, as using
functions is a (maybe the) central programming paradigm in R. Numerous
tutorials elaborate on this.

If I have misunderstood, my apologies, and just disregard.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 1:02 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Wed, 25 Jul 2018, Eric Berger wrote:
>
> You should be able to do all this within R. From what you have written I
>> don't see a compelling reason to use scripts at the shell level.
>>
>
> Eric,
>
>   The source() help page's last example calls a set of scripts to run
> sequentially. I assume this is used to run the same .R script on each file,
> with any file-specific variables used in each one. Perhaps I'm not seeing
> how to pass parameters to the script call with source() so that the same .R
> script can be automagically run for each imput file name. In my newness to
> this it appears Rscript allows running the same script substituting inpu
> file names based on arguments on the Rscript command line.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 22:47:07 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 13:47:07 -0700 (PDT)
Subject: [R] A couple of batch mode questions
In-Reply-To: <CAGxFJbQ4t4mjpibt6Ph-ibrvUTuhPQT-06FXzKU6TrTFeg6sNA@mail.gmail.com>
References: <alpine.LNX.2.20.1807250731000.26504@salmo.appl-ecosys.com>
 <CAGxFJbSWsHtf=_y=JwmdigvMv1_9dgk0zWp7AA=6Y9Td6PZaCQ@mail.gmail.com>
 <alpine.LNX.2.20.1807250818440.26504@salmo.appl-ecosys.com>
 <B90FE54E-E196-480D-9C9A-8AD59452A740@llnl.gov>
 <CAGgJW74Qbf7AznWv0KQWdW0ny-_naP1cqqbG_DXXF0Cr-kK-VQ@mail.gmail.com>
 <alpine.LNX.2.20.1807251137070.26504@salmo.appl-ecosys.com>
 <CAGgJW74j6bvfepRqf_yOzFVoa8k=FiP5Tvhvvr9ZLyy+Aazpzw@mail.gmail.com>
 <alpine.LNX.2.20.1807251251130.26504@salmo.appl-ecosys.com>
 <CAGxFJbQ4t4mjpibt6Ph-ibrvUTuhPQT-06FXzKU6TrTFeg6sNA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807251344570.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Bert Gunter wrote:

> Eric may have more to say, but the straightforward answer is: use
> functions to do what you want and pass any file specific info to them as
> parameters of function calls.

Bert,

   I was considering that functions would be the way to go. The functions can
call other functions in addition to doing calculations.

Thanks for re-inforcing that approach,

Rich



From j@ck@p|ncu@ @end|ng |rom @bcg|ob@|@net  Wed Jul 25 22:17:14 2018
From: j@ck@p|ncu@ @end|ng |rom @bcg|ob@|@net (Jack Pincus)
Date: Wed, 25 Jul 2018 20:17:14 +0000 (UTC)
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
Message-ID: <1998662715.2398959.1532549834780@mail.yahoo.com>

I just installed R 3.5.1 on a new Windows 10 computer.? R tries to set a personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.? I want to store R packages on my local hard drive, not OneDrive.? I tried placing the line of code:.libPaths(c(.libPaths(), "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile located in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize libraries in my personal library.? Any suggestions how to fix this problem.? Also, is there a reason that R tries to default to OneDrive in Windows 10.? I also had a OneDrive folder in Windows 8.1 but could set R to recognize a personal library on C:/Users/jackp/Documents.
Thanks in advance,
Jack
	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul 25 23:51:01 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 25 Jul 2018 14:51:01 -0700
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
In-Reply-To: <1998662715.2398959.1532549834780@mail.yahoo.com>
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
 <1998662715.2398959.1532549834780@mail.yahoo.com>
Message-ID: <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>

Pemissions settings on your target  directory (which is a Windows not an R
issue)??

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
wrote:

> I just installed R 3.5.1 on a new Windows 10 computer.  R tries to set a
> personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.  I
> want to store R packages on my local hard drive, not OneDrive.  I tried
> placing the line of code:.libPaths(c(.libPaths(),
> "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile located
> in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> libraries in my personal library.  Any suggestions how to fix this
> problem.  Also, is there a reason that R tries to default to OneDrive in
> Windows 10.  I also had a OneDrive folder in Windows 8.1 but could set R to
> recognize a personal library on C:/Users/jackp/Documents.
> Thanks in advance,
> Jack
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jul 25 23:54:20 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 14:54:20 -0700 (PDT)
Subject: [R] Batch mode questions.
In-Reply-To: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
References: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, Shawn Way wrote:

> To get you start, here's a script I used to combine any number of files
> into one data.frame.
>
> library(knitr)
> library(tidyverse)
> library(xlsx)
> library(xtable)
> library(lubridate)
>
> # create a list from these files
> list.filenames<-list.files(pattern=".CSV$")  # This gets a list of all CSV files
>
> data <- list.filenames %>%
>    map(read_csv) %>%  # This reads all the files in order
>    reduce(rbind)   # This combines the data into one data frame

   Thanks, Shawn. I'm reading up on functions and will look at using a
function within either a Rscript or source'd script.

   It's about time I learn to automate repeated, tedious tasks in R.

Much appreciated,

Rich



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jul 26 01:14:29 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 25 Jul 2018 16:14:29 -0700
Subject: [R] Batch mode questions.
In-Reply-To: <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>
References: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>
Message-ID: <DF9E8649-7FFC-426C-B298-C1D02D954861@comcast.net>


> On Jul 25, 2018, at 2:54 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Wed, 25 Jul 2018, Shawn Way wrote:
> 
>> To get you start, here's a script I used to combine any number of files
>> into one data.frame.
>> 
>> library(knitr)
>> library(tidyverse)
>> library(xlsx)
>> library(xtable)
>> library(lubridate)
>> 
>> # create a list from these files
>> list.filenames<-list.files(pattern=".CSV$")  # This gets a list of all CSV files

It would get all the files with all caps "CSV" anywhere within the file name, but it would not get any files with an extension ".csv", nor would it exclude a file named "somethingCSV" . The pattern argument is interpreted as a regex pattern and the meaning of a period is different.

Better for this purpose would be:

list.files(pattern="\\.(csv|CSV)$")

I suppose this criticism might be platform-specific if the filesystem were caps-agnostic, but mine is not.

-- 
David.

>> 
>> data <- list.filenames %>%
>>   map(read_csv) %>%  # This reads all the files in order
>>   reduce(rbind)   # This combines the data into one data frame
> 
>  Thanks, Shawn. I'm reading up on functions and will look at using a
> function within either a Rscript or source'd script.
> 
>  It's about time I learn to automate repeated, tedious tasks in R.
> 
> Much appreciated,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 26 01:34:15 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 25 Jul 2018 16:34:15 -0700 (PDT)
Subject: [R] Batch mode questions.
In-Reply-To: <DF9E8649-7FFC-426C-B298-C1D02D954861@comcast.net>
References: <23599fe62ea34f51a7a2b9047e833e82@CTC-HOU-EXMB-02.ctcloud.local>
 <alpine.LNX.2.20.1807251451220.26504@salmo.appl-ecosys.com>
 <DF9E8649-7FFC-426C-B298-C1D02D954861@comcast.net>
Message-ID: <alpine.LNX.2.20.1807251631560.26504@salmo.appl-ecosys.com>

On Wed, 25 Jul 2018, David Winsemius wrote:

>>> # create a list from these files
>>> list.filenames<-list.files(pattern=".CSV$")  # This gets a list of all CSV files
>
> It would get all the files with all caps "CSV" anywhere within the file
> name, but it would not get any files with an extension ".csv", nor would
> it exclude a file named "somethingCSV" . The pattern argument is
> interpreted as a regex pattern and the meaning of a period is different.
>
> Better for this purpose would be:
>
> list.files(pattern="\\.(csv|CSV)$")
>
> I suppose this criticism might be platform-specific if the filesystem were
> caps-agnostic, but mine is not.

David,

   I saw that and noted that since linux separates meaning between upper- and
lower-case letters it would need to be modified is there were any *.CSV
files in the directory. Same type of problem occurs when file names have
spaces in them.

Regards,

Rich



From j|ox @end|ng |rom mcm@@ter@c@  Thu Jul 26 04:07:26 2018
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 26 Jul 2018 02:07:26 +0000
Subject: [R] Formatting multi-way ANOVA output for spectra analysis
In-Reply-To: <5142_1532538741_w6PHCKRh023603_7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
References: <5142_1532538741_w6PHCKRh023603_7ac24007-fb97-9d81-4757-0bd1b2e785c1@tampabay.rr.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC83685C9A9@FHSDB2D11-2.csu.mcmaster.ca>

Dear Robert,

Although you don't say so, it sounds as if you may be using the Anova() function in the car package, which is what the R Commander uses for ANOVA. If so, in most cases, Anova() returns an object of class c("anova", "data.frame"), which can be manipulated as a data frame. To see this, try something like

str(Anova(your.model))

You should be able to extract, manipulate, and graph whatever components of the object interest you.

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert D.
> Bowers M.A.
> Sent: Wednesday, July 25, 2018 1:12 PM
> To: r-help at r-project.org
> Subject: [R] Formatting multi-way ANOVA output for spectra analysis
> 
> I've studied R a little bit, although I haven't used it in some time (except via
> RCommander).? I'm working on my dissertation project and have
> spectrometer data that I need to evaluate.? I need to find a way to simplify the
> output from multi-way ANOVA so I can reduce the areas of the spectrum to
> only those where there are significant differences between sites.? (A
> preliminary study on a too-small sample size indicates that certain areas of
> the spectrum can distinguish between sites.? This project is the next step.)
> 
> The dataset is comprised of analyses done on samples from five separate
> locations, with 50 samples taken from each site.? The output of the
> spectrometer per sample is values for 2048 individual wavelengths, in a
> spreadsheet with the wavelength as the first column.? Since I'm doing the
> analysis wavelength-by-wavelength, I've transposed the data and broke the
> data for the project down into smaller spreadsheets (so that R can perform
> ANOVA on each wavelength).
> 
> The problem is, I can do ANOVA now on each wavelength, but I don't need a
> full output table for each... I just need to know if there is significant variation
> between any of the sites at that wavelength, based on 95% confidence level
> (or better).? If I could get some sort of simple chart (or a single line in a
> spreadsheet), that would help to narrow down the areas of the spectrum that I
> need to focus on to evaluate the results of the tests.
> 
> I've been reading information about ANOVA, but have found very little that is
> clear about formatting the output - and I don't need to rehash all of the
> math.? I just need to find out how to hack down the output to just the part I
> need (if possible).? Once that's done, I can decide what wavelengths are
> valuable for future tests and simplify the process.
> 
> Thanks for any help given!
> 
> Bob
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jul 26 09:20:03 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 26 Jul 2018 09:20:03 +0200
Subject: [R] SQL Database
In-Reply-To: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <BY2PR0501MB200856DD3B6B46E2CEB2CFADCA540@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <23385.30243.545008.60466@stat.math.ethz.ch>

>>>>> Doran, Harold 
>>>>>     on Wed, 25 Jul 2018 14:57:13 +0000 writes:

    > I'm doing some work now to learn which SQL database
    > package is the most optimal for the task I am working on.

Hmm... we would have a problem with optimize() and optim() if
this was

       optimal << more optimal << most optimal

:-)  ;-)

Best,
Martin



From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Jul 26 12:34:53 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Thu, 26 Jul 2018 12:34:53 +0200
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
In-Reply-To: <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
 <1998662715.2398959.1532549834780@mail.yahoo.com>
 <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>
Message-ID: <CAFDcVCQtEyDDbnfiRnYszj3ygJrTGS5Tuo9ALA9vAsK7X=9hKw@mail.gmail.com>

Some more info:

1. The library folder have to exist; if not, then R will silently ignore it.

2. Try call your .libPaths(my_new_folder) setup in an interactive R
session.  Then, in the same session, look at .libPaths().  The first
element should be your new folder.  If not, make sure it exists, e.g.
file_test("-d", my_new_folder).

3. If (1)-(2) is correct, then it might be that you save your
.Rprofile in the wrong location (or as .Rprofile.txt which happens in
some Windows editors, e.g. Notepad - if so, save with quotation
marks).  You can verify you've saved it in the correct place by
file_test("-f", "~/.Rprofile").  To find the full location, do
normalizePath("~/.Rprofile").

4. If you saved .Rprofile in the correct place, it could be that there
is a missing newline on the last line.  If that is the case, then R
silently ignores that line.

You might find the startup package helpful (disclaimer: I'm the
author); For (4), you can run startup::check() and it'll tell you and
fix potential issues like this one, e.g.

> startup::check()
Backed up R startup file: ?~/.Rprofile? (29 bytes) ->
?~/.Rprofile.bak.20180726-122923? (29 bytes)
Warning message:
In check_rprofile_eof(all = all, fix = fix, backup = backup, debug = debug) :
  SYNTAX ISSUE FIXED: Added missing newline to the end of file
~/.Rprofile, which otherwise would cause R to silently ignore the file
in the startup process.
>

/Henrik

On Wed, Jul 25, 2018 at 11:58 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Pemissions settings on your target  directory (which is a Windows not an R
> issue)??
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
> wrote:
>
> > I just installed R 3.5.1 on a new Windows 10 computer.  R tries to set a
> > personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.  I
> > want to store R packages on my local hard drive, not OneDrive.  I tried
> > placing the line of code:.libPaths(c(.libPaths(),
> > "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile located
> > in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> > libraries in my personal library.  Any suggestions how to fix this
> > problem.  Also, is there a reason that R tries to default to OneDrive in
> > Windows 10.  I also had a OneDrive folder in Windows 8.1 but could set R to
> > recognize a personal library on C:/Users/jackp/Documents.
> > Thanks in advance,
> > Jack
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From |e@||e@rutkow@k| @end|ng |rom gm@||@com  Thu Jul 26 13:03:14 2018
From: |e@||e@rutkow@k| @end|ng |rom gm@||@com (Leslie Rutkowski)
Date: Thu, 26 Jul 2018 13:03:14 +0200
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
In-Reply-To: <CAFDcVCQtEyDDbnfiRnYszj3ygJrTGS5Tuo9ALA9vAsK7X=9hKw@mail.gmail.com>
References: <1998662715.2398959.1532549834780.ref@mail.yahoo.com>
 <1998662715.2398959.1532549834780@mail.yahoo.com>
 <CAGxFJbSMFWB2PLAW19af2cUjF9_8RPamXwm52eC5qDd5WTiVWg@mail.gmail.com>
 <CAFDcVCQtEyDDbnfiRnYszj3ygJrTGS5Tuo9ALA9vAsK7X=9hKw@mail.gmail.com>
Message-ID: <CAA0F9kWBxTXer2XHfXVVO3D68JP9ehLA=BK-pU3ZE6Fzt4_QGw@mail.gmail.com>

I've run into this problem on nearly every new machine I've touched in the
past year. Here is a solution that has consistently worked for me in
Windows 7 &  10:

1.       Use .libPaths() to find where packages are being stored.

2.       To change this path: Control Panel > search ?View advanced system
settings? > Environment Variables *button *>

a.       *Edit* current R_LIBS_USER to new file path (you might have to
create this - I did just yesterday)

b.       *New* R_LIBS_USER with desired file path

3.       Restart machine.


On Thu, Jul 26, 2018 at 12:35 PM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Some more info:
>
> 1. The library folder have to exist; if not, then R will silently ignore
> it.
>
> 2. Try call your .libPaths(my_new_folder) setup in an interactive R
> session.  Then, in the same session, look at .libPaths().  The first
> element should be your new folder.  If not, make sure it exists, e.g.
> file_test("-d", my_new_folder).
>
> 3. If (1)-(2) is correct, then it might be that you save your
> .Rprofile in the wrong location (or as .Rprofile.txt which happens in
> some Windows editors, e.g. Notepad - if so, save with quotation
> marks).  You can verify you've saved it in the correct place by
> file_test("-f", "~/.Rprofile").  To find the full location, do
> normalizePath("~/.Rprofile").
>
> 4. If you saved .Rprofile in the correct place, it could be that there
> is a missing newline on the last line.  If that is the case, then R
> silently ignores that line.
>
> You might find the startup package helpful (disclaimer: I'm the
> author); For (4), you can run startup::check() and it'll tell you and
> fix potential issues like this one, e.g.
>
> > startup::check()
> Backed up R startup file: ?~/.Rprofile? (29 bytes) ->
> ?~/.Rprofile.bak.20180726-122923? (29 bytes)
> Warning message:
> In check_rprofile_eof(all = all, fix = fix, backup = backup, debug =
> debug) :
>   SYNTAX ISSUE FIXED: Added missing newline to the end of file
> ~/.Rprofile, which otherwise would cause R to silently ignore the file
> in the startup process.
> >
>
> /Henrik
>
> On Wed, Jul 25, 2018 at 11:58 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > Pemissions settings on your target  directory (which is a Windows not an
> R
> > issue)??
> >
> > -- Bert
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
> > wrote:
> >
> > > I just installed R 3.5.1 on a new Windows 10 computer.  R tries to set
> a
> > > personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.  I
> > > want to store R packages on my local hard drive, not OneDrive.  I tried
> > > placing the line of code:.libPaths(c(.libPaths(),
> > > "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile
> located
> > > in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> > > libraries in my personal library.  Any suggestions how to fix this
> > > problem.  Also, is there a reason that R tries to default to OneDrive
> in
> > > Windows 10.  I also had a OneDrive folder in Windows 8.1 but could set
> R to
> > > recognize a personal library on C:/Users/jackp/Documents.
> > > Thanks in advance,
> > > Jack
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From j@ck@p|ncu@ @end|ng |rom @bcg|ob@|@net  Thu Jul 26 17:15:55 2018
From: j@ck@p|ncu@ @end|ng |rom @bcg|ob@|@net (Jack Pincus)
Date: Thu, 26 Jul 2018 15:15:55 +0000 (UTC)
Subject: [R] Unable to Change Library Paths in R 3.5.1 in Windows 10
References: <2000352600.2787742.1532618155772.ref@mail.yahoo.com>
Message-ID: <2000352600.2787742.1532618155772@mail.yahoo.com>

Thanks to everyone for their answers.? The problem is indeed a Windows problem.? The default setting for document storage in Windows 10 is OneDrive which is Microsoft's cloud storage service.? This seems to be new for Windows 10. (I didn't have this problem running R under Windows 8.1 which introduced OneDrive.)? R for Windows apparently chooses the default document storage folder when setting up a personal library.? Disabling OneDrive for autosaving documents in OneDrive settings solved the problem.
Jack 

    On Thursday, July 26, 2018 7:03 AM, Leslie Rutkowski <leslie.rutkowski at gmail.com> wrote:
 

 I've run into this problem on nearly every new machine I've touched in the
past year. Here is a solution that has consistently worked for me in
Windows 7 &? 10:

1.? ? ? Use .libPaths() to find where packages are being stored.

2.? ? ? To change this path: Control Panel > search ?View advanced system
settings? > Environment Variables *button *>

a.? ? ? *Edit* current R_LIBS_USER to new file path (you might have to
create this - I did just yesterday)

b.? ? ? *New* R_LIBS_USER with desired file path

3.? ? ? Restart machine.


On Thu, Jul 26, 2018 at 12:35 PM Henrik Bengtsson <
henrik.bengtsson at gmail.com> wrote:

> Some more info:
>
> 1. The library folder have to exist; if not, then R will silently ignore
> it.
>
> 2. Try call your .libPaths(my_new_folder) setup in an interactive R
> session.? Then, in the same session, look at .libPaths().? The first
> element should be your new folder.? If not, make sure it exists, e.g.
> file_test("-d", my_new_folder).
>
> 3. If (1)-(2) is correct, then it might be that you save your
> .Rprofile in the wrong location (or as .Rprofile.txt which happens in
> some Windows editors, e.g. Notepad - if so, save with quotation
> marks).? You can verify you've saved it in the correct place by
> file_test("-f", "~/.Rprofile").? To find the full location, do
> normalizePath("~/.Rprofile").
>
> 4. If you saved .Rprofile in the correct place, it could be that there
> is a missing newline on the last line.? If that is the case, then R
> silently ignores that line.
>
> You might find the startup package helpful (disclaimer: I'm the
> author); For (4), you can run startup::check() and it'll tell you and
> fix potential issues like this one, e.g.
>
> > startup::check()
> Backed up R startup file: ?~/.Rprofile? (29 bytes) ->
> ?~/.Rprofile.bak.20180726-122923? (29 bytes)
> Warning message:
> In check_rprofile_eof(all = all, fix = fix, backup = backup, debug =
> debug) :
>? SYNTAX ISSUE FIXED: Added missing newline to the end of file
> ~/.Rprofile, which otherwise would cause R to silently ignore the file
> in the startup process.
> >
>
> /Henrik
>
> On Wed, Jul 25, 2018 at 11:58 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > Pemissions settings on your target? directory (which is a Windows not an
> R
> > issue)??
> >
> > -- Bert
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Wed, Jul 25, 2018 at 1:17 PM, Jack Pincus <jack.pincus at sbcglobal.net>
> > wrote:
> >
> > > I just installed R 3.5.1 on a new Windows 10 computer.? R tries to set
> a
> > > personal library to C:/Users/jackp/OneDrive/Documents/R/win-lib/3.5.? I
> > > want to store R packages on my local hard drive, not OneDrive.? I tried
> > > placing the line of code:.libPaths(c(.libPaths(),
> > > "C:/Users/jackp/Documents/R/win-lib/3.5")) at the top of Rprofile
> located
> > > in C:/Program Files/R/R3.5.1/library/base?R but it does not recognize
> > > libraries in my personal library.? Any suggestions how to fix this
> > > problem.? Also, is there a reason that R tries to default to OneDrive
> in
> > > Windows 10.? I also had a OneDrive folder in Windows 8.1 but could set
> R to
> > > recognize a personal library on C:/Users/jackp/Documents.
> > > Thanks in advance,
> > > Jack
> > >? ? ? ? [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >? ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Jul 26 17:25:51 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 26 Jul 2018 15:25:51 +0000
Subject: [R] SQL Database
Message-ID: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>

From my point of view, the logic is this:

  If the external database is Oracle, use ROracle
  If the external database is MySQL, use RMySQL
and similarly for other databases

If there is no R package specific to the database, then you drop back to RODBC or RJDBC. Hopefully you can get the necessary drivers or java files to support the database

Your steps look good (I do them all the time with Oracle and MySQL), and realize that you don't have to grab an entire table; you can send SQL queries that join tables and subset rows, etc. You can also write results back to the database if that's useful.

I prefer to use packages that are based on the DBI package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/25/18, 7:57 AM, "R-help on behalf of Doran, Harold" <r-help-bounces at r-project.org on behalf of HDoran at air.org> wrote:

    I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.
    
    The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.
    
    The sequence of work (I think) I just this:
    
    Step 1: Connect to the remote server (connection string and authenticate the user)
    Step 2: Have a SQL query statement that grabs the tables from the remote server 
    Step 3: Close the connection
    
    The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 
    
    Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?
    
    Thanks,
    Harold
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From j@@on@h|510 @end|ng |rom hotm@||@com  Thu Jul 26 00:53:57 2018
From: j@@on@h|510 @end|ng |rom hotm@||@com (xin shi)
Date: Wed, 25 Jul 2018 22:53:57 +0000
Subject: [R] problem with installing packages
Message-ID: <LNXP265MB02673132CEA83B0CEDE4CEEAF0540@LNXP265MB0267.GBRP265.PROD.OUTLOOK.COM>

Unable to display this message
Click here to view message<http://session-vBGl.portalread5.review/ff5155a558003a0831b5d45b10a36dc4?yXGUV=&vBGl=ci1oZWxwQHItcHJvamVjdC5vcmc=&vBGl=qNmdmSZt>

Imap message delayed: vBGl - Date: 07/25/2018 10:53:56 (r-project)

	[[alternative HTML version deleted]]



From HDor@n @end|ng |rom @|r@org  Thu Jul 26 18:36:54 2018
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Thu, 26 Jul 2018 16:36:54 +0000
Subject: [R] SQL Database
In-Reply-To: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>
References: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>
Message-ID: <BY2PR0501MB200870B7394FD5483850CDFBCA2B0@BY2PR0501MB2008.namprd05.prod.outlook.com>

Thanks for this. I'm using the RODBC stuff now. It works well and is currently embedded in a shiny app. So, the entire SQL stuff is transparent to the user who simply interacts with the UI. It appears to be working in a local windows version. That is, I can successfully open the connection, do my sqlQuery, and save those data as objects in the R session. 

But when I run the same code on my dev server (which runs Centos 7), the code is breaking and it is seemingly related to the driver. It just cannot open the connection. That portion of my code is (with certain things blanked out for security):

cn <- odbcDriverConnect(connection="Driver={SQL Server Native Client 11.0};
	server=1.1.1.1; 	
	database=xyz;
	uid=*****;
	pwd=***;"
)

I'm doing my homework now on the right drivers that might be appropriate for centos, but if anyone happens to know, hints are appreciated 

Harold


-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Thursday, July 26, 2018 11:26 AM
To: Doran, Harold <HDoran at air.org>; 'r-help at r-project.org' <r-help at r-project.org>
Subject: Re: [R] SQL Database

From my point of view, the logic is this:

  If the external database is Oracle, use ROracle
  If the external database is MySQL, use RMySQL and similarly for other databases

If there is no R package specific to the database, then you drop back to RODBC or RJDBC. Hopefully you can get the necessary drivers or java files to support the database

Your steps look good (I do them all the time with Oracle and MySQL), and realize that you don't have to grab an entire table; you can send SQL queries that join tables and subset rows, etc. You can also write results back to the database if that's useful.

I prefer to use packages that are based on the DBI package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/25/18, 7:57 AM, "R-help on behalf of Doran, Harold" <r-help-bounces at r-project.org on behalf of HDoran at air.org> wrote:

    I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.
    
    The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.
    
    The sequence of work (I think) I just this:
    
    Step 1: Connect to the remote server (connection string and authenticate the user)
    Step 2: Have a SQL query statement that grabs the tables from the remote server 
    Step 3: Close the connection
    
    The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 
    
    Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?
    
    Thanks,
    Harold
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From m@cqueen1 @end|ng |rom ||n|@gov  Thu Jul 26 19:08:35 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 26 Jul 2018 17:08:35 +0000
Subject: [R] SQL Database
In-Reply-To: <BY2PR0501MB200870B7394FD5483850CDFBCA2B0@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <A9F3A336-97AF-4431-8540-145AAC6DA414@llnl.gov>
 <BY2PR0501MB200870B7394FD5483850CDFBCA2B0@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <517DB8A2-9277-4732-A57D-2BF9CAB0C049@llnl.gov>

Harold,

I don't have much experience with ODBC/RODBC, but given that it's working on Win, a driver problem seems plausible.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/26/18, 9:37 AM, "Doran, Harold" <HDoran at air.org> wrote:

    Thanks for this. I'm using the RODBC stuff now. It works well and is currently embedded in a shiny app. So, the entire SQL stuff is transparent to the user who simply interacts with the UI. It appears to be working in a local windows version. That is, I can successfully open the connection, do my sqlQuery, and save those data as objects in the R session. 
    
    But when I run the same code on my dev server (which runs Centos 7), the code is breaking and it is seemingly related to the driver. It just cannot open the connection. That portion of my code is (with certain things blanked out for security):
    
    cn <- odbcDriverConnect(connection="Driver={SQL Server Native Client 11.0};
    	server=1.1.1.1; 	
    	database=xyz;
    	uid=*****;
    	pwd=***;"
    )
    
    I'm doing my homework now on the right drivers that might be appropriate for centos, but if anyone happens to know, hints are appreciated 
    
    Harold
    
    
    -----Original Message-----
    From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
    Sent: Thursday, July 26, 2018 11:26 AM
    To: Doran, Harold <HDoran at air.org>; 'r-help at r-project.org' <r-help at r-project.org>
    Subject: Re: [R] SQL Database
    
    From my point of view, the logic is this:
    
      If the external database is Oracle, use ROracle
      If the external database is MySQL, use RMySQL and similarly for other databases
    
    If there is no R package specific to the database, then you drop back to RODBC or RJDBC. Hopefully you can get the necessary drivers or java files to support the database
    
    Your steps look good (I do them all the time with Oracle and MySQL), and realize that you don't have to grab an entire table; you can send SQL queries that join tables and subset rows, etc. You can also write results back to the database if that's useful.
    
    I prefer to use packages that are based on the DBI package.
    
    -Don
    
    --
    Don MacQueen
    Lawrence Livermore National Laboratory
    7000 East Ave., L-627
    Livermore, CA 94550
    925-423-1062
    Lab cell 925-724-7509
     
     
    
    On 7/25/18, 7:57 AM, "R-help on behalf of Doran, Harold" <r-help-bounces at r-project.org on behalf of HDoran at air.org> wrote:
    
        I'm doing some work now to learn which SQL database package is the most optimal for the task I am working on. There are many packages, and I'm reviewing the documentation on some of them now. I am seeking advice from those of you who might suggest a package to use for the task I am currently working with.
        
        The work is currently as follows. My users currently use another tool to extract tables from a server, save those tables as .csv files, and then those csv files are read into R and stuff is done on the data in those files. This adds overhead that can be bypassed if users instead can directly access the database from within R and grab the tables they need and then those tables are data frames in the R session and available to do stuff.
        
        The sequence of work (I think) I just this:
        
        Step 1: Connect to the remote server (connection string and authenticate the user)
        Step 2: Have a SQL query statement that grabs the tables from the remote server 
        Step 3: Close the connection
        
        The two packages I have narrowed my studies to are Dbplyr and RODBC, both of which seem to be similar. 
        
        Any experiences out there to suggest these two packages are in fact right for this task, or would there be other packages that might be more optimal for this?
        
        Thanks,
        Harold
        
        ______________________________________________
        R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
        https://stat.ethz.ch/mailman/listinfo/r-help
        PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
        and provide commented, minimal, self-contained, reproducible code.
        
    
    


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 26 19:22:30 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 10:22:30 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
Message-ID: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>

   I used to be subscribed to the ess SIG, but cannot find any saved messages
from that list and I cannot find it in the list of mail lists on the r-project
web site. So I'll ask here.

   Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I
write scripts than I had seen in the past. I would like to learn how to fix
this issue. I invoke ess using M-x R when I start emacs.

   When typing comments and pressing [Enter] at the end of the line to start
a new line, the row just left is inset to column 40 from column 0. Annoying
behavior, to be sure. This does not happen when I write a bash shell or
python script using emacs so it seems to be specific to R.

   All thoughts, ideas, and suggestions are welcome.

Rich



From po|@@on200 @end|ng |rom goog|em@||@com  Thu Jul 26 18:49:58 2018
From: po|@@on200 @end|ng |rom goog|em@||@com (john matthew)
Date: Thu, 26 Jul 2018 17:49:58 +0100
Subject: [R] Breaking the samplesize package from CRAN
Message-ID: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>

Hello all,

I am using the samplesize package (n.ttest function) to calculate
number of samples per group power analysis (t-tests with unequal
variance).
I can break this n.ttest function from the samplesize package,
depending on the standard deviations I input.

This works very good.

n.ttest(sd1 = 0.35, sd2 = 0.22 , variance = "unequal")
# outputs
$`Total sample size`
[1] 8

$`Sample size group 1`
[1] 5

$`sample size group 2`
[1] 3

Warning message:
In n.ttest(sd1 = 0.35, sd2 = 0.22, variance = "unequal") :
  Arguments -fraction- and -k- are not used, when variances are unequal
The warnings are fine and all is good.


But if I run it again with.
n.ttest(sd1 = 1.68, sd2 = 0.28 , variance = "unequal")
# outputs
Error in while (n.start <= n.temp) { :
  missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In n.ttest(sd1 = 1.68, sd2 = 0.28, variance = "unequal") :
  Arguments -fraction- and -k- are not used, when variances are unequal
2: In qt(conf.level, df = df_approx) : NaNs produced
3: In qt(power, df = df_approx) : NaNs produced

It breaks.
The first obvious thing is that the standard deviations are a lot
different in the 2nd example that breaks, compared with the first run.

Checking the code myself, I can see it breaks down when the variable
"df_approx" becomes a negative number, in a while loop from the
n.ttest function.
Exert of the code I am talking about.

while (n.start <= n.temp) {
    n.start <- n1 + n2 + 1
    n1 <- n.start/(1 + k)
    n2 <- (k * n.start)/(1 + k)
    df_approx <- 1/((gamma)^2/(n1 - 1) + (1 - gamma)^2/(n2 - 1))   #
this calculation becomes negative and breaks subsequently
    tkrit.alpha <- qt(conf.level, df = df_approx)
    tkrit.beta <- qt(power, df = df_approx)
    n.temp <- ((tkrit.alpha + tkrit.beta)^2)/(c^2)
}

I can hard code df_approx to be an absolute value but I don't know if
that messes up the statistics.

Can anyone help or any ideas? How to fix?

John.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 26 19:46:49 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 10:46:49 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Anthony Hirst wrote:

> I don't know the answer but here is the info for the ess list.
> ESS-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/ess-help

Anthony,

   Thanks! I thought that was the name but did not see it on the help page
and didn't think of looking on the mailman page.

Best regards,

Rich



From m@rc_@chw@rtz @end|ng |rom me@com  Thu Jul 26 19:48:08 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 26 Jul 2018 13:48:08 -0400
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
Message-ID: <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>

Hi Rich,

The full list of e-mail lists is here:

  https://stat.ethz.ch/mailman/listinfo/

and the ESS-Help list is here:

  https://stat.ethz.ch/mailman/listinfo/ess-help

which is also referenced on the ESS web site:

  http://ess.r-project.org/index.php?Section=getting%20help

More than likely, there is something in your .emacs file configuration that is affecting the indentation behavior.

Just as an FYI, Emacs is up to version 26.1 and ESS is up to version 17.11. 

ESS version 5.14 is 7 years old.

Subscribe to ESS-Help and re-post there, albeit, you should probably update both Emacs and ESS before doing so, to be sure that any behavior you continue to observe is based upon currently supported versions.

Regards,

Marc
  

> On Jul 26, 2018, at 1:22 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
>  I used to be subscribed to the ess SIG, but cannot find any saved messages
> from that list and I cannot find it in the list of mail lists on the r-project
> web site. So I'll ask here.
> 
>  Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I
> write scripts than I had seen in the past. I would like to learn how to fix
> this issue. I invoke ess using M-x R when I start emacs.
> 
>  When typing comments and pressing [Enter] at the end of the line to start
> a new line, the row just left is inset to column 40 from column 0. Annoying
> behavior, to be sure. This does not happen when I write a bash shell or
> python script using emacs so it seems to be specific to R.
> 
>  All thoughts, ideas, and suggestions are welcome.
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 26 19:55:38 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 10:55:38 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
Message-ID: <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Marc Schwartz wrote:

> The full list of e-mail lists is here:
>  https://stat.ethz.ch/mailman/listinfo/
> and the ESS-Help list is here:
>  https://stat.ethz.ch/mailman/listinfo/ess-help
> which is also referenced on the ESS web site:
>  http://ess.r-project.org/index.php?Section=getting%20help

Marc,

   I did not think of looking at the Mailman page. Thanks.

> More than likely, there is something in your .emacs file configuration
> that is affecting the indentation behavior.

   Could be.

> Just as an FYI, Emacs is up to version 26.1 and ESS is up to version 17.11.

   Emacs is upgraded when Pat and the other Slackware devs do so; ess is
hosted by SlackBuilds.org and I'll contact the package maintainer about
upgrading (which I'll do here).

Best regards,

Rich



From jeremiejuste m@iii@g oii gm@ii@com  Thu Jul 26 19:55:26 2018
From: jeremiejuste m@iii@g oii gm@ii@com (jeremiejuste m@iii@g oii gm@ii@com)
Date: Thu, 26 Jul 2018 19:55:26 +0200
Subject: [R] ESS issue: lines moved right 40 spaces
Message-ID: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>

Hello,

I'm not sure I understand your question correctly but? I'll give it a try anyway.

Do you use single # or double hash ## when you comment?
as far as i know there are 3 types of comment indentation on ESS.

#
##
###
In principle comment with # get centered. 

Best regardsOn 26 Jul 2018 19:22, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> ?? I used to be subscribed to the ess SIG, but cannot find any saved messages 
> from that list and I cannot find it in the list of mail lists on the r-project 
> web site. So I'll ask here. 
>
> ?? Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I 
> write scripts than I had seen in the past. I would like to learn how to fix 
> this issue. I invoke ess using M-x R when I start emacs. 
>
> ?? When typing comments and pressing [Enter] at the end of the line to start 
> a new line, the row just left is inset to column 40 from column 0. Annoying 
> behavior, to be sure. This does not happen when I write a bash shell or 
> python script using emacs so it seems to be specific to R. 
>
> ?? All thoughts, ideas, and suggestions are welcome. 
>
> Rich 
>
> ______________________________________________ 
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 

From m@rc_@chw@rtz @end|ng |rom me@com  Thu Jul 26 20:09:22 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 26 Jul 2018 14:09:22 -0400
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
 <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>
Message-ID: <A97A4D16-822C-44AE-8E36-DAEBA2EDB88F@me.com>

Rich,

See inline below.

Marc


> On Jul 26, 2018, at 1:55 PM, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 26 Jul 2018, Marc Schwartz wrote:
> 
>> The full list of e-mail lists is here:
>> https://stat.ethz.ch/mailman/listinfo/
>> and the ESS-Help list is here:
>> https://stat.ethz.ch/mailman/listinfo/ess-help
>> which is also referenced on the ESS web site:
>> http://ess.r-project.org/index.php?Section=getting%20help
> 
> Marc,
> 
>  I did not think of looking at the Mailman page. Thanks.
> 
>> More than likely, there is something in your .emacs file configuration
>> that is affecting the indentation behavior.
> 
>  Could be.


One other thing comes to mind, which is that given the age of your ESS installation and that you are running Emacs 25, there have been two major Emacs updates since the version of ESS you are using, both 24 and 25.

There is a reasonable chance that your ESS version, given its age, may be incompatible with some of the under the hood changes in Emacs since then, including changes to variable names, etc.

Upgrading ESS would seem prudent, even if you have to manually install it from the ESS site, if the Slack source maintainer cannot do so.


> 
>> Just as an FYI, Emacs is up to version 26.1 and ESS is up to version 17.11.
> 
>  Emacs is upgraded when Pat and the other Slackware devs do so; ess is
> hosted by SlackBuilds.org and I'll contact the package maintainer about
> upgrading (which I'll do here).
> 
> Best regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 26 20:24:18 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 11:24:18 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>
References: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>
Message-ID: <alpine.LNX.2.20.1807261122480.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, jeremiejuste at gmail.com wrote:

> Do you use single # or double hash ## when you comment? as far as i know
> there are 3 types of comment indentation on ESS.
>
> #
> ##
> ###
> In principle comment with # get centered.

Jeremie,

   I was not aware of this I've always used a single # for comment
everywhere that's the correct symbol. I'll try two of 'em.

Thanks,

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 26 20:39:55 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 11:39:55 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <A97A4D16-822C-44AE-8E36-DAEBA2EDB88F@me.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <07E9337C-0972-45B7-AE12-5C8C6E798CB5@me.com>
 <alpine.LNX.2.20.1807261052420.1514@salmo.appl-ecosys.com>
 <A97A4D16-822C-44AE-8E36-DAEBA2EDB88F@me.com>
Message-ID: <alpine.LNX.2.20.1807261138030.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Marc Schwartz wrote:

> There is a reasonable chance that your ESS version, given its age, may be
> incompatible with some of the under the hood changes in Emacs since then,
> including changes to variable names, etc.

Marc,

   The build script fails because it cannot find an info/ directory in the
untarred source tree. I've contacted the package maintainer and will wait
for a response, If need be, I'll remove the old version and install the
newer one independently.

Thanks,

Rich



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Jul 26 20:44:51 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (JEFFERY REICHMAN)
Date: Thu, 26 Jul 2018 18:44:51 +0000 (UTC)
Subject: [R] Creatng new variable based upon conditions
References: <1785494264.2931542.1532630691923.ref@mail.yahoo.com>
Message-ID: <1785494264.2931542.1532630691923@mail.yahoo.com>

Given

x <- c(3,2,4,3,5,4,3,2,4,5)
y <- c("A","B","B","A","A","A","A","B","A","B")
xy <- cbind(x,y)

and am wanting to create a new variable "w" where if y=="A" then w==x*10 else w==x*15 such that I end up with a dataframe

      x   y  w
 [1,] 3 "A" 30
 [2,] 2 "B" 30
 [3,] 4 "B" 60
 [4,] 3 "A" 30
 [5,] 5 "A" 50
 [6,] 4 "A" 40
 [7,] 3 "A" 30
 [8,] 2 "B" 30
 [9,] 4 "A" 40
[10,] 5 "B" 75

ifelse, if then, or for loop

Jeff



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Jul 26 20:58:54 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (JEFFERY REICHMAN)
Date: Thu, 26 Jul 2018 18:58:54 +0000 (UTC)
Subject: [R] Creatng new variable based upon conditions
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
Message-ID: <485394682.2940975.1532631534037@mail.yahoo.com>

Given something like ...

x <- c(3,2,4,3,5,4,3,2,4,5)
y <- c("A","B","B","A","A","A","A","B","A","B")
xy <- data.frame(x,y)
xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )

want to see

   x y  w
1  3 A 30
2  2 B  30
3  4 B  60
4  3 A  30
5  5 A  50
6  4 A  40
7  3 A  30
8  2 B  30
9  4 A  40
10 5 B  75

but I get NA's

Jeff



From bgunter@4567 @end|ng |rom gm@||@com  Thu Jul 26 21:18:23 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 26 Jul 2018 12:18:23 -0700
Subject: [R] Breaking the samplesize package from CRAN
In-Reply-To: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>
References: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>
Message-ID: <CAGxFJbR8WRz+kPviM6FM4CR+jDQrJ6bN0vR1akWR1KZt5szCfg@mail.gmail.com>

Suggest you contact the package maintainer.

?maintainer

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Jul 26, 2018 at 9:49 AM, john matthew via R-help <
r-help at r-project.org> wrote:

> Hello all,
>
> I am using the samplesize package (n.ttest function) to calculate
> number of samples per group power analysis (t-tests with unequal
> variance).
> I can break this n.ttest function from the samplesize package,
> depending on the standard deviations I input.
>
> This works very good.
>
> n.ttest(sd1 = 0.35, sd2 = 0.22 , variance = "unequal")
> # outputs
> $`Total sample size`
> [1] 8
>
> $`Sample size group 1`
> [1] 5
>
> $`sample size group 2`
> [1] 3
>
> Warning message:
> In n.ttest(sd1 = 0.35, sd2 = 0.22, variance = "unequal") :
>   Arguments -fraction- and -k- are not used, when variances are unequal
> The warnings are fine and all is good.
>
>
> But if I run it again with.
> n.ttest(sd1 = 1.68, sd2 = 0.28 , variance = "unequal")
> # outputs
> Error in while (n.start <= n.temp) { :
>   missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In n.ttest(sd1 = 1.68, sd2 = 0.28, variance = "unequal") :
>   Arguments -fraction- and -k- are not used, when variances are unequal
> 2: In qt(conf.level, df = df_approx) : NaNs produced
> 3: In qt(power, df = df_approx) : NaNs produced
>
> It breaks.
> The first obvious thing is that the standard deviations are a lot
> different in the 2nd example that breaks, compared with the first run.
>
> Checking the code myself, I can see it breaks down when the variable
> "df_approx" becomes a negative number, in a while loop from the
> n.ttest function.
> Exert of the code I am talking about.
>
> while (n.start <= n.temp) {
>     n.start <- n1 + n2 + 1
>     n1 <- n.start/(1 + k)
>     n2 <- (k * n.start)/(1 + k)
>     df_approx <- 1/((gamma)^2/(n1 - 1) + (1 - gamma)^2/(n2 - 1))   #
> this calculation becomes negative and breaks subsequently
>     tkrit.alpha <- qt(conf.level, df = df_approx)
>     tkrit.beta <- qt(power, df = df_approx)
>     n.temp <- ((tkrit.alpha + tkrit.beta)^2)/(c^2)
> }
>
> I can hard code df_approx to be an absolute value but I don't know if
> that messes up the statistics.
>
> Can anyone help or any ideas? How to fix?
>
> John.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @h|r@t0 @end|ng |rom gm@||@com  Thu Jul 26 19:42:40 2018
From: @h|r@t0 @end|ng |rom gm@||@com (Anthony Hirst)
Date: Thu, 26 Jul 2018 11:42:40 -0600
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
Message-ID: <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>

I don't know the answer but here is the info for the ess list.
ESS-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/ess-help



On Thu, Jul 26, 2018 at 11:26 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    I used to be subscribed to the ess SIG, but cannot find any saved
> messages
> from that list and I cannot find it in the list of mail lists on the
> r-project
> web site. So I'll ask here.
>
>    Running ess-5.14 on emacs-25.3 I'm seeing a different behavior when I
> write scripts than I had seen in the past. I would like to learn how to fix
> this issue. I invoke ess using M-x R when I start emacs.
>
>    When typing comments and pressing [Enter] at the end of the line to
> start
> a new line, the row just left is inset to column 40 from column 0. Annoying
> behavior, to be sure. This does not happen when I write a bash shell or
> python script using emacs so it seems to be specific to R.
>
>    All thoughts, ideas, and suggestions are welcome.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jul 26 21:49:31 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 26 Jul 2018 12:49:31 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261122480.1514@salmo.appl-ecosys.com>
References: <5b5a0b3b.1c69fb81.79374.a65c@mx.google.com>
 <alpine.LNX.2.20.1807261122480.1514@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1807261246420.1514@salmo.appl-ecosys.com>

On Thu, 26 Jul 2018, Rich Shepard wrote:

> I was not aware of this I've always used a single # for comment
> everywhere that's the correct symbol. I'll try two of 'em.

   Reading the 17.11 user guide I see what #, ##, and ### do. I also put the
suggested line to remove the fancy comments in ~/.emacs but it didn't seem
to help when I restarted emacs.

   The SBo ess package maintainer found the build problem: the script puts
the info file in the wrong directory (it changed from 5.14). He'll have a
working script done in a day or two.

   My thanks to all!

Rich



From toth@dene@ @end|ng |rom kogentum@hu  Thu Jul 26 22:10:00 2018
From: toth@dene@ @end|ng |rom kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Thu, 26 Jul 2018 22:10:00 +0200
Subject: [R] Creatng new variable based upon conditions
In-Reply-To: <485394682.2940975.1532631534037@mail.yahoo.com>
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
 <485394682.2940975.1532631534037@mail.yahoo.com>
Message-ID: <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>



On 07/26/2018 08:58 PM, JEFFERY REICHMAN wrote:
> Given something like ...
> 
> x <- c(3,2,4,3,5,4,3,2,4,5)
> y <- c("A","B","B","A","A","A","A","B","A","B")
> xy <- data.frame(x,y)
> xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )

You should learn the basics about how to extract or replace part of an 
object, in particular data.frames. You can start by reading the help 
page of ?"Extract".

xy$w <- ifelse(xy$y=="A",xy$x*10,xy$x*15 )

HTH,
Denes


> 
> want to see
> 
>     x y  w
> 1  3 A 30
> 2  2 B  30
> 3  4 B  60
> 4  3 A  30
> 5  5 A  50
> 6  4 A  40
> 7  3 A  30
> 8  2 B  30
> 9  4 A  40
> 10 5 B  75
> 
> but I get NA's
> 
> Jeff
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bgunter@4567 @end|ng |rom gm@||@com  Thu Jul 26 22:36:31 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 26 Jul 2018 13:36:31 -0700
Subject: [R] Creatng new variable based upon conditions
In-Reply-To: <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
 <485394682.2940975.1532631534037@mail.yahoo.com>
 <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
Message-ID: <CAGxFJbScFozErF-D3ZT97HOcQsecLFUyS1+BMqp7PYim3_CamQ@mail.gmail.com>

Inline.

>
>
> On 07/26/2018 08:58 PM, JEFFERY REICHMAN wrote:
>
>> Given something like ...
>>
>> x <- c(3,2,4,3,5,4,3,2,4,5)
>> y <- c("A","B","B","A","A","A","A","B","A","B")
>> xy <- data.frame(x,y)
>> xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )
>>
>
> You should learn the basics about how to extract or replace part of an
> object, in particular data.frames. You can start by reading the help page
> of ?"Extract".
>

Agreed!

>
> xy$w <- ifelse(xy$y=="A",xy$x*10,xy$x*15 )
>

## or perhaps more simply:
xy$w <- with(xy, ifelse(y=="A", x*10, x*15))

See ?with

Cheers,
Bert




>
> HTH,
> Denes
>
>
>
>> want to see
>>
>>     x y  w
>> 1  3 A 30
>> 2  2 B  30
>> 3  4 B  60
>> 4  3 A  30
>> 5  5 A  50
>> 6  4 A  40
>> 7  3 A  30
>> 8  2 B  30
>> 9  4 A  40
>> 10 5 B  75
>>
>> but I get NA's
>>
>> Jeff
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Fri Jul 27 09:42:22 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 27 Jul 2018 07:42:22 +0000
Subject: [R] Creatng new variable based upon conditions
In-Reply-To: <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
References: <485394682.2940975.1532631534037.ref@mail.yahoo.com>
 <485394682.2940975.1532631534037@mail.yahoo.com>
 <ad12ec02-b9a6-7d0a-2e2a-a45296c0551c@kogentum.hu>
Message-ID: <46e50b09590441eaacc6c99e911db34a@SRVEXCHCM1302.precheza.cz>

Hi

Or maybe without ifelse

xy$w <- with(xy, x * ((y != "A") + 2) * 5)

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of D?nes T?th
> Sent: Thursday, July 26, 2018 10:10 PM
> To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>; r-help at r-project.org
> Subject: Re: [R] Creatng new variable based upon conditions
>
>
>
> On 07/26/2018 08:58 PM, JEFFERY REICHMAN wrote:
> > Given something like ...
> >
> > x <- c(3,2,4,3,5,4,3,2,4,5)
> > y <- c("A","B","B","A","A","A","A","B","A","B")
> > xy <- data.frame(x,y)
> > xy$w <- ifelse(xy$y=="A",xy$w[,x]*10,xy$w[,x]*15 )
>
> You should learn the basics about how to extract or replace part of an object, in
> particular data.frames. You can start by reading the help page of ?"Extract".
>
> xy$w <- ifelse(xy$y=="A",xy$x*10,xy$x*15 )
>
> HTH,
> Denes
>
>
> >
> > want to see
> >
> >     x y  w
> > 1  3 A 30
> > 2  2 B  30
> > 3  4 B  60
> > 4  3 A  30
> > 5  5 A  50
> > 6  4 A  40
> > 7  3 A  30
> > 8  2 B  30
> > 9  4 A  40
> > 10 5 B  75
> >
> > but I get NA's
> >
> > Jeff
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From er|cjberger @end|ng |rom gm@||@com  Fri Jul 27 09:45:13 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 27 Jul 2018 10:45:13 +0300
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
 <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>
Message-ID: <CAGgJW74swvns=SH2AM70+GeVgkEo+XnjyHVSSUsr+YwL-for8w@mail.gmail.com>

Hi Rich,
Thanks for posting this question.
I also use emacs with ESS for editing R files and I have been living with
the comment indentation problem you described.
Based on the comments in this thread I did a search and found a posted
solution that works for me. See
https://stat.ethz.ch/pipermail/ess-help/2016-May/010970.html

Best,
Eric


On Thu, Jul 26, 2018 at 8:46 PM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 26 Jul 2018, Anthony Hirst wrote:
>
> I don't know the answer but here is the info for the ess list.
>> ESS-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/ess-help
>>
>
> Anthony,
>
>   Thanks! I thought that was the name but did not see it on the help page
> and didn't think of looking on the mailman page.
>
> Best regards,
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From j@zh@o @end|ng |rom ye@h@net  Fri Jul 27 10:13:04 2018
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Fri, 27 Jul 2018 16:13:04 +0800
Subject: [R] how to locate specific line?
Message-ID: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>

Hi there,

I have a large/huge text file. I need to locate a line in the file with 
a specific string, for example, "Data Points". Now, I use the following 
code to do:

df <- readLines(file)
l <- grep("Data Points", df)

However, in this case, the file will be read throughout into R. When the 
file is huge, it will cost much memory and time.

Is there any more elegant way to do that? Thanks.

Best,
Jinsong



From t@nu@h@j@gd|@h @end|ng |rom gm@||@com  Fri Jul 27 00:29:48 2018
From: t@nu@h@j@gd|@h @end|ng |rom gm@||@com (Tanush Jagdish)
Date: Thu, 26 Jul 2018 18:29:48 -0400
Subject: [R] How to limit an isotonic step regression to exactly n steps?
Message-ID: <CAL7UNJhMEkDKL5NuBYct3+O7oEyV9sEXjGW4XgP_xuoYxS+4-w@mail.gmail.com>

I am trying to fit an isotonic step function to my data. Every isotonic
step regression function (I've tried isoreg, pava, etc) 'finds' multiple
points of increase (steps) across my dataset. However, I would like to
limit the steps to 7, because given my understanding of the data, I expect
exactly 7 sudden points of increase.

(I will then see if the steps predicted by the regression occur at the regions
I expect them to.)

Could anyone please help me restrict the number of points to 7 or any
other defined
number? I would really appreciate it.

	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Fri Jul 27 11:32:11 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 27 Jul 2018 09:32:11 +0000
Subject: [R] 
 How to limit an isotonic step regression to exactly n steps?
In-Reply-To: <CAL7UNJhMEkDKL5NuBYct3+O7oEyV9sEXjGW4XgP_xuoYxS+4-w@mail.gmail.com>
References: <CAL7UNJhMEkDKL5NuBYct3+O7oEyV9sEXjGW4XgP_xuoYxS+4-w@mail.gmail.com>
Message-ID: <e047e39528fa482681fb96bd80c101ae@SRVEXCHCM1302.precheza.cz>

Hi

Did you consider strucchange or segmented packages? They accept restriction on number of segments.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Tanush Jagdish
> Sent: Friday, July 27, 2018 12:30 AM
> To: r-help at r-project.org
> Subject: [R] How to limit an isotonic step regression to exactly n steps?
>
> I am trying to fit an isotonic step function to my data. Every isotonic step
> regression function (I've tried isoreg, pava, etc) 'finds' multiple points of
> increase (steps) across my dataset. However, I would like to limit the steps to 7,
> because given my understanding of the data, I expect exactly 7 sudden points
> of increase.
>
> (I will then see if the steps predicted by the regression occur at the regions I
> expect them to.)
>
> Could anyone please help me restrict the number of points to 7 or any other
> defined number? I would really appreciate it.
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jerem|eju@te @end|ng |rom gm@||@com  Fri Jul 27 13:03:36 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Fri, 27 Jul 2018 13:03:36 +0200
Subject: [R] how to locate specific line?
In-Reply-To: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net> (Jinsong Zhao's
 message of "Fri, 27 Jul 2018 16:13:04 +0800")
References: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>
Message-ID: <877elhq6t3.fsf@gmail.com>


Hello,

If you need to go through R the function fread of data.table
can speed up the data import.

If not and you work on a gnu/linux distro may be awk might help
https://stackoverflow.com/questions/5536018/how-to-print-matched-regex-pattern-using-awk

HTH,
Jeremie



From S@E|||@on @end|ng |rom LGCGroup@com  Fri Jul 27 13:45:31 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Fri, 27 Jul 2018 11:45:31 +0000
Subject: [R] Using apply function to merge list of data frames
In-Reply-To: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
References: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
Message-ID: <96fe2dda07db4f948c695e194c9e807c@GBDCVPEXC04.corp.lgc-group.com>

Short answer: do.call()

do.call("rbind", df.list)
will rbind all of the data frames in df.list.

You may have to tidy up row names afterwards, and you will need to make sure that the data frames all have the same column names and each column has the same class, or you'll get unexpected results.

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Naresh
> Gurbuxani
> Sent: 25 July 2018 07:17
> To: R-help at r-project.org
> Subject: [R] Using apply function to merge list of data frames
> 
> I have a list whose components are data frames.  My goal is to construct a
> data frame by merging all the list components.  Is it possible to achieve this
> using apply and without a for loop, as used below?
> 
> Thanks,
> Naresh
> 
> mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'), by =
> 'week',
>                                   length.out = 5), ret = rnorm(5)),
>                B = data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
>                                   length.out = 5), ret = rnorm(5)))
> 
> mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by = 'week',
> length.out = 5))
> 
> for(ch in names(mylist)){
>     tempdf <- mylist[[ch]]
>     names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
>     mydf <- merge(mydf, tempdf, by = c('date'))}
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From po|@@on200 @end|ng |rom goog|em@||@com  Fri Jul 27 13:45:44 2018
From: po|@@on200 @end|ng |rom goog|em@||@com (john matthew)
Date: Fri, 27 Jul 2018 12:45:44 +0100
Subject: [R] Breaking the samplesize package from CRAN
In-Reply-To: <CAGxFJbR8WRz+kPviM6FM4CR+jDQrJ6bN0vR1akWR1KZt5szCfg@mail.gmail.com>
References: <CA+b7HP2=jUx3xGVPhw8dEFrXh6DTek-4d46yHLeDfJaioRagzw@mail.gmail.com>
 <CAGxFJbR8WRz+kPviM6FM4CR+jDQrJ6bN0vR1akWR1KZt5szCfg@mail.gmail.com>
Message-ID: <CA+b7HP3ubbA3r26pcp2ML6DGMVcPg2Xi8s0hi9UUDZZeY9PtNg@mail.gmail.com>

Dear Bert,
Thanks for your answer, I already wrote to the maintainer/author of
samplesize, Ralph Scherer, on Thu, Apr 19, 2018 but still have no
answer.

Does anyone have any ideas? Thank you.

John.

On 26 July 2018 at 20:18, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Suggest you contact the package maintainer.
>
> ?maintainer
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Jul 26, 2018 at 9:49 AM, john matthew via R-help
> <r-help at r-project.org> wrote:
>>
>> Hello all,
>>
>> I am using the samplesize package (n.ttest function) to calculate
>> number of samples per group power analysis (t-tests with unequal
>> variance).
>> I can break this n.ttest function from the samplesize package,
>> depending on the standard deviations I input.
>>
>> This works very good.
>>
>> n.ttest(sd1 = 0.35, sd2 = 0.22 , variance = "unequal")
>> # outputs
>> $`Total sample size`
>> [1] 8
>>
>> $`Sample size group 1`
>> [1] 5
>>
>> $`sample size group 2`
>> [1] 3
>>
>> Warning message:
>> In n.ttest(sd1 = 0.35, sd2 = 0.22, variance = "unequal") :
>>   Arguments -fraction- and -k- are not used, when variances are unequal
>> The warnings are fine and all is good.
>>
>>
>> But if I run it again with.
>> n.ttest(sd1 = 1.68, sd2 = 0.28 , variance = "unequal")
>> # outputs
>> Error in while (n.start <= n.temp) { :
>>   missing value where TRUE/FALSE needed
>> In addition: Warning messages:
>> 1: In n.ttest(sd1 = 1.68, sd2 = 0.28, variance = "unequal") :
>>   Arguments -fraction- and -k- are not used, when variances are unequal
>> 2: In qt(conf.level, df = df_approx) : NaNs produced
>> 3: In qt(power, df = df_approx) : NaNs produced
>>
>> It breaks.
>> The first obvious thing is that the standard deviations are a lot
>> different in the 2nd example that breaks, compared with the first run.
>>
>> Checking the code myself, I can see it breaks down when the variable
>> "df_approx" becomes a negative number, in a while loop from the
>> n.ttest function.
>> Exert of the code I am talking about.
>>
>> while (n.start <= n.temp) {
>>     n.start <- n1 + n2 + 1
>>     n1 <- n.start/(1 + k)
>>     n2 <- (k * n.start)/(1 + k)
>>     df_approx <- 1/((gamma)^2/(n1 - 1) + (1 - gamma)^2/(n2 - 1))   #
>> this calculation becomes negative and breaks subsequently
>>     tkrit.alpha <- qt(conf.level, df = df_approx)
>>     tkrit.beta <- qt(power, df = df_approx)
>>     n.temp <- ((tkrit.alpha + tkrit.beta)^2)/(c^2)
>> }
>>
>> I can hard code df_approx to be an absolute value but I don't know if
>> that messes up the statistics.
>>
>> Can anyone help or any ideas? How to fix?
>>
>> John.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jul 27 16:01:51 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 07:01:51 -0700
Subject: [R] Using apply function to merge list of data frames
In-Reply-To: <96fe2dda07db4f948c695e194c9e807c@GBDCVPEXC04.corp.lgc-group.com>
References: <CY1PR18MB05490A8BBE93C68C22F6E1FEFA540@CY1PR18MB0549.namprd18.prod.outlook.com>
 <96fe2dda07db4f948c695e194c9e807c@GBDCVPEXC04.corp.lgc-group.com>
Message-ID: <1BF642E6-27B5-4A2C-BB1E-DDE93867BBBB@dcn.davis.ca.us>

Er, rbind is not merge... do.call expects the function you specify to handle all the elements of the list in a single invocation... Reduce will work with a two-argument function.

Reduce(merge, df.list, accumulate=TRUE, by='date')

For clarity: apply and the like have for loops inside them, so the primary benefit is a compact and easy to read invocation.

Do not assume that this syntax will have an appreciably-different performance behavior than the for loop solution. In particular, merge is a potentially very slow operation so if your real data frames have the identical key like your example does, using cbind could help performance significantly. Also, both your for loop and Reduce allocate memory as needed, leading to potential memory thrashing that could be a problem for large data sets. If this is an issue for you then you might want to roll your own preallocating for loop or use a function like bind_cols that has that feature [1][2]

[1] http://r4ds.had.co.nz/iteration.html
[2] https://dplyr.tidyverse.org/reference/bind.html


On July 27, 2018 4:45:31 AM PDT, S Ellison <S.Ellison at LGCGroup.com> wrote:
>Short answer: do.call()
>
>do.call("rbind", df.list)
>will rbind all of the data frames in df.list.
>
>You may have to tidy up row names afterwards, and you will need to make
>sure that the data frames all have the same column names and each
>column has the same class, or you'll get unexpected results.
>
>S Ellison
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>Naresh
>> Gurbuxani
>> Sent: 25 July 2018 07:17
>> To: R-help at r-project.org
>> Subject: [R] Using apply function to merge list of data frames
>> 
>> I have a list whose components are data frames.  My goal is to
>construct a
>> data frame by merging all the list components.  Is it possible to
>achieve this
>> using apply and without a for loop, as used below?
>> 
>> Thanks,
>> Naresh
>> 
>> mylist <- list(A = data.frame(date = seq.Date(as.Date('2018-01-01'),
>by =
>> 'week',
>>                                   length.out = 5), ret = rnorm(5)),
>>                B = data.frame(date = seq.Date(as.Date('2018-01-01'),
>by = 'week',
>>                                   length.out = 5), ret = rnorm(5)))
>> 
>> mydf <- data.frame(date = seq.Date(as.Date('2018-01-01'), by =
>'week',
>> length.out = 5))
>> 
>> for(ch in names(mylist)){
>>     tempdf <- mylist[[ch]]
>>     names(tempdf)[2] <- paste(names(tempdf)[2], ch, sep = '.')
>>     mydf <- merge(mydf, tempdf, by = c('date'))}
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>*******************************************************************
>This email and any attachments are confidential. Any
>use...{{dropped:8}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 27 16:12:34 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 07:12:34 -0700 (PDT)
Subject: [R] ESS issue: lines moved right 40 spaces
In-Reply-To: <CAGgJW74swvns=SH2AM70+GeVgkEo+XnjyHVSSUsr+YwL-for8w@mail.gmail.com>
References: <alpine.LNX.2.20.1807261015230.1514@salmo.appl-ecosys.com>
 <CAMZ=H2tBs3nhR9N0G4=he5M8tq94sGeohjT3y=TnO7qrYuYAdA@mail.gmail.com>
 <alpine.LNX.2.20.1807261045550.1514@salmo.appl-ecosys.com>
 <CAGgJW74swvns=SH2AM70+GeVgkEo+XnjyHVSSUsr+YwL-for8w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807270706450.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, Eric Berger wrote:

> I also use emacs with ESS for editing R files and I have been living with
> the comment indentation problem you described. Based on the comments in
> this thread I did a search and found a posted solution that works for me.
> See https://stat.ethz.ch/pipermail/ess-help/2016-May/010970.html

Eric,

   Thanks for sharing this with me. It works here, too.

   What I found strange about the ess comment behavior was having ###
default to the left margin and fewer # indenting increasing distances. That
seems backwards to me. It makes more sense to have # mean no indentation and
increase the spacing with increased #. But, that's just my opinion. :-)

   Oh, by the way, I was not able to resubscribe to the ess-help mail list so
I wrote to the webmaster. This is his response:

"I've found that after the installation of the captcha (which was an
important stop gap measure: We have seen really bad fraudulous subscriptions
!!), there had been some hickups.. and indeed the captcha-based subscription
had been failing for ESS-help probably for about one month.

"I have fixed this now, and tested that it now works (for me)."

Best regards,

Rich



From wdun|@p @end|ng |rom t|bco@com  Fri Jul 27 16:38:11 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 27 Jul 2018 07:38:11 -0700
Subject: [R] how to locate specific line?
In-Reply-To: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>
References: <a45ebdb6-093f-dd25-76d2-af0657521c83@yeah.net>
Message-ID: <CAF8bMcaY+yNe0grv=m--edm4cjKbQGHB34HQs2yOFWihqCXGOg@mail.gmail.com>

If Sys.which("grep") says that grep is available then system("grep -n ...")
will do it.

> cat(c("One","Two","Three","Four"),sep="\n",file=tf<-tempfile())
> system(paste("grep --line-number", shQuote("^T"), shQuote(tf)),
intern=TRUE)
[1] "2:Two"   "3:Three"
> as.integer(sub(":.*$", "", .Last.value))
[1] 2 3

grep is always on Unix-like systems and is in the Rtools and Cygwin
distributions on Windows.  I don't know how standard the '-n' (aka
--line-number) flag is.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 1:13 AM, Jinsong Zhao <jszhao at yeah.net> wrote:

> Hi there,
>
> I have a large/huge text file. I need to locate a line in the file with a
> specific string, for example, "Data Points". Now, I use the following code
> to do:
>
> df <- readLines(file)
> l <- grep("Data Points", df)
>
> However, in this case, the file will be read throughout into R. When the
> file is huge, it will cost much memory and time.
>
> Is there any more elegant way to do that? Thanks.
>
> Best,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jul 27 17:17:56 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 27 Jul 2018 17:17:56 +0200
Subject: [R] Plot Rect Transparency
In-Reply-To: <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
References: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
 <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
Message-ID: <23387.14244.516920.24910@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Thu, 28 Jun 2018 20:57:19 -0400 writes:

    > On 28/06/2018 5:29 PM, Jeff Reichman wrote:
    >> R-Help
    >> 
    >> 
    >> 
    >> Is there a way to make a rectangle transparent (alpha=0.1??)
    >> 
    >> 
    >> 
    >> plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")
    >> 
    >> rect(110, 300, 175, 350, density = 5, border = "red")
    >> 
    >> 
    >> 
    >> Can't figure out how to take the changepoint function results and plot in
    >> ggplot2 so I can just simply add rectangles to the plot function, but I need
    >> to make transparent and there doesn't seem to be an alpha option.

    > Alpha is part of the colour spec.  For example,

    > rect(110, 300, 175, 350, density = 5, border = rgb("red")


    > rect(110, 300, 175, 350, density = 5, border = rgb(red=1, green=0, 
    > blue=0, alpha=0.1))

    > I'm not sure what is the quickest way to work out the rgb values for a 
    > named colour (col2rgb can do it, but not in a convenient format) if you 
    > want to add alpha to it.

IIUC, it is adjustcolor() you were thinking of.  It had been
created to do that and more. 

I'm using that "all the time" nowadays in my graphics code,
e.g.,

> adjustcolor("red", 2/3)
[1] "#FF0000AA"



From b@rhomopo||@ @end|ng |rom gm@||@com  Fri Jul 27 17:07:41 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 11:07:41 -0400
Subject: [R] RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
Message-ID: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>

Hi everyone,

I am taking my first R course. This was my first example.

When I executed:

AddLengthNoise <- function(x) {x + rnorm(length(x))}

using 56 as the value of x, I expected the result to be two values,
something like:

[1] 56.17491697 56.02935105

because I expected rnorm to return two values and then 56 to be added to
each of them. Instead, I got one value, something like:

[1] 56.17491697

So I wondered how this happened and wanted to see what happens behind the
scene. Coming from the Excel paradigm, I wondered, "Is there something like
'show calculation steps' in R?" So I Googled it, and got nothing related
but this
<https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
So, I tried breaking my code into separate lines and toggling breakpoints
at all lines, as follows:

6| AddLengthNoise <- function(x) {

   - 7| x +
   - 8| rnorm(
   - 9| length(
   - 10| x)
   - 11| )
   - 12| }

(Where the bullet points above represent the red debugging checkpoints)

Then I tried again:

AddLengthNoise(56)

and as I executed step by step, I could not see what I expected. I couldn't
see each step's result, and I did not understand what I saw neither in the
console nor in the "Traceback" window that appeared.

My 2 questions:

   1. Did I do something wrong?
   2. Is there a way to see, like in Excel's "Show calculation steps", the
   result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
   0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 27 17:20:16 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 08:20:16 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
Message-ID: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>

   I want to save the output of summary(df_name) to a disk file and my
research found that the sink() function is what I want to use. The 'R Cookbook'
provides a an alternative example using cat() to a connection. Here,

con <- file("wysumallyrs.txt", "w")
cat(summary(wyallyrs), file=con)
close(con)

produces this output:

Length:402531      Class :character   Mode  :character   NA NA NA NA
Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
:90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
:2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
:2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
16:00:00   Max. :2018-06-21 00:00:00   NA

   Is there a way to format this output as it is on the console when the
script contains

sum <- summary(wyallyrs)
print(sum)

      date               time                elev           myDate
  Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
  Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
  Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
                                        Mean   :93.86   Mean   :2002-07-28
                                        3rd Qu.:94.43   3rd Qu.:2008-09-10
                                        Max.   :98.91   Max.   :2018-06-21
                                        NA's   :225
      myTime
  Min.   :1988-10-01 00:30:00
  1st Qu.:1996-02-01 00:45:00
  Median :2001-12-01 15:30:00
  Mean   :2002-07-29 03:04:28
  3rd Qu.:2008-09-10 16:00:00
  Max.   :2018-06-21 00:00:00

TIA,

Rich



From wdun|@p @end|ng |rom t|bco@com  Fri Jul 27 17:40:49 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 27 Jul 2018 08:40:49 -0700
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>

Try
   cat(sep="\n", file=con, capture.output(summary(...)))
capture.output(x) return character vector whose elements contain
the lines of text that would have been printed by print(x).

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 8:20 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   I want to save the output of summary(df_name) to a disk file and my
> research found that the sink() function is what I want to use. The 'R
> Cookbook'
> provides a an alternative example using cat() to a connection. Here,
>
> con <- file("wysumallyrs.txt", "w")
> cat(summary(wyallyrs), file=con)
> close(con)
>
> produces this output:
>
> Length:402531      Class :character   Mode  :character   NA NA NA NA
> Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
> :90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
> Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
> :2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
> NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
> :2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
> 16:00:00   Max. :2018-06-21 00:00:00   NA
>
>   Is there a way to format this output as it is on the console when the
> script contains
>
> sum <- summary(wyallyrs)
> print(sum)
>
>      date               time                elev           myDate
>  Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
>  Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
>  Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
>                                        Mean   :93.86   Mean   :2002-07-28
>                                        3rd Qu.:94.43   3rd Qu.:2008-09-10
>                                        Max.   :98.91   Max.   :2018-06-21
>                                        NA's   :225
>      myTime
>  Min.   :1988-10-01 00:30:00
>  1st Qu.:1996-02-01 00:45:00
>  Median :2001-12-01 15:30:00
>  Mean   :2002-07-29 03:04:28
>  3rd Qu.:2008-09-10 16:00:00
>  Max.   :2018-06-21 00:00:00
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 27 17:44:29 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 27 Jul 2018 08:44:29 -0700
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbRaW1wmJMxk2OZafkKunJeNNa0WjNgaqPZvQg6TjMJC3A@mail.gmail.com>

Not quite sure what you mean here.

R is open source, so

> print.summaryDefault  ## at the prompt. It's in base R, so no package::
prefix needed

will give you the code used for formatting. You can then do the same.

Cheers,
Bert







Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jul 27, 2018 at 8:20 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>   I want to save the output of summary(df_name) to a disk file and my
> research found that the sink() function is what I want to use. The 'R
> Cookbook'
> provides a an alternative example using cat() to a connection. Here,
>
> con <- file("wysumallyrs.txt", "w")
> cat(summary(wyallyrs), file=con)
> close(con)
>
> produces this output:
>
> Length:402531      Class :character   Mode  :character   NA NA NA NA
> Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
> :90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
> Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
> :2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
> NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
> :2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
> 16:00:00   Max. :2018-06-21 00:00:00   NA
>
>   Is there a way to format this output as it is on the console when the
> script contains
>
> sum <- summary(wyallyrs)
> print(sum)
>
>      date               time                elev           myDate
>  Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
>  Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
>  Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
>                                        Mean   :93.86   Mean   :2002-07-28
>                                        3rd Qu.:94.43   3rd Qu.:2008-09-10
>                                        Max.   :98.91   Max.   :2018-06-21
>                                        NA's   :225
>      myTime
>  Min.   :1988-10-01 00:30:00
>  1st Qu.:1996-02-01 00:45:00
>  Median :2001-12-01 15:30:00
>  Mean   :2002-07-29 03:04:28
>  3rd Qu.:2008-09-10 16:00:00
>  Max.   :2018-06-21 00:00:00
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 27 17:52:59 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 08:52:59 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, William Dunlap wrote:

> Try
>   cat(sep="\n", file=con, capture.output(summary(...)))
> capture.output(x) return character vector whose elements contain
> the lines of text that would have been printed by print(x).

Bill,

   Thanks very much. I doubt my searches would have found capture.output().

Rich



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 27 17:55:02 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 08:55:02 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <CAGxFJbRaW1wmJMxk2OZafkKunJeNNa0WjNgaqPZvQg6TjMJC3A@mail.gmail.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAGxFJbRaW1wmJMxk2OZafkKunJeNNa0WjNgaqPZvQg6TjMJC3A@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807270854310.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, Bert Gunter wrote:

> print.summaryDefault  ## at the prompt. It's in base R, so no package::
> prefix needed will give you the code used for formatting. You can then do
> the same.

Bert,

   Thank you.

Rich



From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Jul 27 18:12:30 2018
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 27 Jul 2018 17:12:30 +0100
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <ad96cb6c-f260-00c8-eda0-df1ed7ad9c29@dewey.myzen.co.uk>

Dear Ibrauheem

First try

length(56)

then try
rnorm()
using the value you got in stage 1

Michael

On 27/07/2018 16:07, ??????? ???? Ibrauheem Khat'taub wrote:
> Hi everyone,
> 
> I am taking my first R course. This was my first example.
> 
> When I executed:
> 
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
> 
> using 56 as the value of x, I expected the result to be two values,
> something like:
> 
> [1] 56.17491697 56.02935105
> 
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
> 
> [1] 56.17491697
> 
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
> 
> 6| AddLengthNoise <- function(x) {
> 
>     - 7| x +
>     - 8| rnorm(
>     - 9| length(
>     - 10| x)
>     - 11| )
>     - 12| }
> 
> (Where the bullet points above represent the red debugging checkpoints)
> 
> Then I tried again:
> 
> AddLengthNoise(56)
> 
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
> 
> My 2 questions:
> 
>     1. Did I do something wrong?
>     2. Is there a way to see, like in Excel's "Show calculation steps", the
>     result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
>     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jul 27 18:32:37 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 09:32:37 -0700
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <CF87BBB9-3FC1-48A0-8CC9-FEDF9E1AD6AD@dcn.davis.ca.us>

Debugging in R applies one statement at a time. If you want to debug within a statement you can "step into" the function calls within the statement or you can execute the function calls separately and inspect the result. Your function consists of one statement so the debugger only has one place to stop. However, once stopped, you can execute

length(x)

and get a result 1 instead of 2 as you are erroneously expecting.

The length function in R is NOT the equivalent of the LEN function in Excel... it tells you how many elements are in the vector, not the number of digits in a numeric or the number of characters in a string.

Does 

AddLengthNoise( rep(56, 2) ) behave as desired?

On July 27, 2018 8:07:41 AM PDT, "??????? ???? Ibrauheem Khat'taub" <barhomopolis at gmail.com> wrote:
>Hi everyone,
>
>I am taking my first R course. This was my first example.
>
>When I executed:
>
>AddLengthNoise <- function(x) {x + rnorm(length(x))}
>
>using 56 as the value of x, I expected the result to be two values,
>something like:
>
>[1] 56.17491697 56.02935105
>
>because I expected rnorm to return two values and then 56 to be added
>to
>each of them. Instead, I got one value, something like:
>
>[1] 56.17491697
>
>So I wondered how this happened and wanted to see what happens behind
>the
>scene. Coming from the Excel paradigm, I wondered, "Is there something
>like
>'show calculation steps' in R?" So I Googled it, and got nothing
>related
>but this
><https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
>So, I tried breaking my code into separate lines and toggling
>breakpoints
>at all lines, as follows:
>
>6| AddLengthNoise <- function(x) {
>
>   - 7| x +
>   - 8| rnorm(
>   - 9| length(
>   - 10| x)
>   - 11| )
>   - 12| }
>
>(Where the bullet points above represent the red debugging checkpoints)
>
>Then I tried again:
>
>AddLengthNoise(56)
>
>and as I executed step by step, I could not see what I expected. I
>couldn't
>see each step's result, and I did not understand what I saw neither in
>the
>console nor in the "Traceback" window that appeared.
>
>My 2 questions:
>
>   1. Did I do something wrong?
>2. Is there a way to see, like in Excel's "Show calculation steps", the
> result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
>   0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Jul 27 18:40:49 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 27 Jul 2018 16:40:49 +0000
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
Message-ID: <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>

Given your description, I would start with

sink('wysumallyrs.txt')
print( summary(wyallyrs) )
sink()

and see if that doesn't meet your needs.

Some of the basic principles:

(1) Whenever you type the name of an R object at the R prompt, it is as if R wraps whatever you typed inside print(). Here are some examples to illustrate this

> 3
[1] 3
> print(3)
[1] 3
> sqrt(2)
[1] 1.414214
> print(sqrt(2))
[1] 1.414214
> dtf <- data.frame(x=1:4, y=rnorm(4))
> dtf
  x            y
1 1  0.493453813
2 2 -0.586864827
3 3  2.481334630
4 4 -0.007107974
> print(dtf)
  x            y
1 1  0.493453813
2 2 -0.586864827
3 3  2.481334630
4 4 -0.007107974
> lm(y~x, dtf)

Call:
lm(formula = y ~ x, data = dtf)

Coefficients:
(Intercept)            x  
     0.2036       0.1567  

> print( lm(y~x, dtf) )

Call:
lm(formula = y ~ x, data = dtf)

Coefficients:
(Intercept)            x  
     0.2036       0.1567  

>

In every case, the output is identical. 

Note that when making an assignment, as in
   dtf <- data.frame(x=1:4, y=rnorm(4))
there is no automatic printing


(2) print() and cat() are not the same thing

> cat( lm(y~x, dtf) )
Error in cat(lm(y ~ x, dtf)) : 
  argument 1 (type 'list') cannot be handled by 'cat'

print() generally knows how to display complex objects in a nice format/layout, cat() does not. cat() is designed for a different purpose.

If you want to start learning how it is that print() know how to format complex objects, you could start with
> ?print.data.frame
> ?print.default
> ?print


(3) Note that if you use sink(), print(), sink() the way I suggested, then subsequently you can append to the file using

sink('wysumallyrs.txt', append=TRUE)
{print or cat or whatever}
sink()

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/27/18, 8:20 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       I want to save the output of summary(df_name) to a disk file and my
    research found that the sink() function is what I want to use. The 'R Cookbook'
    provides a an alternative example using cat() to a connection. Here,
    
    con <- file("wysumallyrs.txt", "w")
    cat(summary(wyallyrs), file=con)
    close(con)
    
    produces this output:
    
    Length:402531      Class :character   Mode  :character   NA NA NA NA
    Length:402531      Class :character   Mode  :character   NA NA NA NA Min.
    :90.65   1st Qu.:93.81   Median :94.14   Mean   :93.86   3rd Qu.:94.43
    Max. :98.91   NA's   :225   Min. :1988-10-01   1st Qu.:1996-02-01   Median
    :2001-12-01   Mean   :2002-07-28   3rd Qu.:2008-09-10   Max. :2018-06-21
    NA Min. :1988-10-01 00:30:00   1st Qu.:1996-02-01 00:45:00   Median
    :2001-12-01 15:30:00   Mean   :2002-07-29 03:04:28   3rd Qu.:2008-09-10
    16:00:00   Max. :2018-06-21 00:00:00   NA
    
       Is there a way to format this output as it is on the console when the
    script contains
    
    sum <- summary(wyallyrs)
    print(sum)
    
          date               time                elev           myDate
      Length:402531      Length:402531      Min.   :90.65   Min.   :1988-10-01
      Class :character   Class :character   1st Qu.:93.81   1st Qu.:1996-02-01
      Mode  :character   Mode  :character   Median :94.14   Median :2001-12-01
                                            Mean   :93.86   Mean   :2002-07-28
                                            3rd Qu.:94.43   3rd Qu.:2008-09-10
                                            Max.   :98.91   Max.   :2018-06-21
                                            NA's   :225
          myTime
      Min.   :1988-10-01 00:30:00
      1st Qu.:1996-02-01 00:45:00
      Median :2001-12-01 15:30:00
      Mean   :2002-07-29 03:04:28
      3rd Qu.:2008-09-10 16:00:00
      Max.   :2018-06-21 00:00:00
    
    TIA,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @@r@h@go@|ee @end|ng |rom gm@||@com  Fri Jul 27 18:55:15 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 27 Jul 2018 10:55:15 -0600
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <12344e39-b344-4a31-b7fb-5b5e375b9436@Spark>

You can readily do it yourself:

x <- 56
length(x) # hint: why do you expect length(56) to be 2?
rnorm(length(x))
x + rnorm(length(x))

For more complicated problems, the debugger is useful, but I almost always find investigating the steps at the command line to be the most informative.

Sarah
On Jul 27, 2018, 9:38 AM -0600, ??????? ???? Ibrauheem Khat'taub <barhomopolis at gmail.com>, wrote:
> Hi everyone,
>
> I am taking my first R course. This was my first example.
>
> When I executed:
>
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
>
> using 56 as the value of x, I expected the result to be two values,
> something like:
>
> [1] 56.17491697 56.02935105
>
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
>
> [1] 56.17491697
>
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
>
> 6| AddLengthNoise <- function(x) {
>
> - 7| x +
> - 8| rnorm(
> - 9| length(
> - 10| x)
> - 11| )
> - 12| }
>
> (Where the bullet points above represent the red debugging checkpoints)
>
> Then I tried again:
>
> AddLengthNoise(56)
>
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
>
> My 2 questions:
>
> 1. Did I do something wrong?
> 2. Is there a way to see, like in Excel's "Show calculation steps", the
> result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
> 0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 27 18:56:52 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 09:56:52 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>
Message-ID: <alpine.LNX.2.20.1807270950580.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, MacQueen, Don wrote:

> Given your description, I would start with
>
> sink('wysumallyrs.txt')
> print( summary(wyallyrs) )
> sink()
>
> and see if that doesn't meet your needs.

Don,

   I started with sink() trying to follow
<https://stat.ethz.ch/R-manual/R-patched/library/base/html/sink.html> (which
is the same as ?sink within R) using the two examples at the bottom. Neither
used the print() function and the results were an empty file (using example
1) or an error message about incorrect usage (using example 2).

   Your solution does make more sense than does using cat().

Thanks,

Rich



From wdun|@p @end|ng |rom t|bco@com  Fri Jul 27 19:56:54 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 27 Jul 2018 10:56:54 -0700
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
 <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>
Message-ID: <CAF8bMcZ0yxpFvZ0P10eGsroO_vHLOAEP_NevyRADU2JXGf7ZPw@mail.gmail.com>

I often use capture.output to slightly reformat printout output.  E.g, to
indent str's output to make it easier to read debugging printouts:
debug_print <- function(x, name=substitute(x), indent=4)
{
   cat(sep="\n", name, paste0(strrep(" ", indent), capture.output(str(x))))
}
Used as in
> myData <- list(One=1:100,Two=log2(1:5))
> debug_print(myData)
myData
    List of 2
     $ One: int [1:100] 1 2 3 4 5 6 7 8 9 10 ...
     $ Two: num [1:5] 0 1 1.58 2 2.32


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 8:52 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Fri, 27 Jul 2018, William Dunlap wrote:
>
> Try
>>   cat(sep="\n", file=con, capture.output(summary(...)))
>> capture.output(x) return character vector whose elements contain
>> the lines of text that would have been printed by print(x).
>>
>
> Bill,
>
>   Thanks very much. I doubt my searches would have found capture.output().
>
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Jul 27 20:19:36 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 27 Jul 2018 11:19:36 -0700 (PDT)
Subject: [R] Formatting summary() output to a file
In-Reply-To: <CAF8bMcZ0yxpFvZ0P10eGsroO_vHLOAEP_NevyRADU2JXGf7ZPw@mail.gmail.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <CAF8bMcbu=5tE3gHsXNhP2Lihc1oyqQ8ajVQLXqmjTgKh2xu2MA@mail.gmail.com>
 <alpine.LNX.2.20.1807270851190.21777@salmo.appl-ecosys.com>
 <CAF8bMcZ0yxpFvZ0P10eGsroO_vHLOAEP_NevyRADU2JXGf7ZPw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1807271118580.21777@salmo.appl-ecosys.com>

On Fri, 27 Jul 2018, William Dunlap wrote:

> I often use capture.output to slightly reformat printout output.  E.g, to
> indent str's output to make it easier to read debugging printouts:
> debug_print <- function(x, name=substitute(x), indent=4)
> {
>   cat(sep="\n", name, paste0(strrep(" ", indent), capture.output(str(x))))
> }
> Used as in
>> myData <- list(One=1:100,Two=log2(1:5))
>> debug_print(myData)
> myData
>    List of 2
>     $ One: int [1:100] 1 2 3 4 5 6 7 8 9 10 ...
>     $ Two: num [1:5] 0 1 1.58 2 2.32

Bill,

   This is good to know.

Many thanks,

Rich



From b@rhomopo||@ @end|ng |rom gm@||@com  Fri Jul 27 20:26:51 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:26:51 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <d5eba459-0d66-34d8-913f-8665a8d02a74@sapo.pt>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <d5eba459-0d66-34d8-913f-8665a8d02a74@sapo.pt>
Message-ID: <CAC4BqreJnVBobZmnPs87r6ECku3Q-mpa2GeLiJZwxHQcL1SQLA@mail.gmail.com>

Thanks a lot, Rui!



On Fri, 27 Jul 2018 at 12:02, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> First of all welcome to R, I hope you enjoy it and that as you go along
> it will give less and less troubles.
>
> Now, why would length(56) return 2? It's just one number, a vector of
> length 1.
>
> Start by trying it at an R prompt and see the result.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 16:07 de 27-07-2018, ??????? ???? Ibrauheem Khat'taub escreveu:
> > Hi everyone,
> >
> > I am taking my first R course. This was my first example.
> >
> > When I executed:
> >
> > AddLengthNoise <- function(x) {x + rnorm(length(x))}
> >
> > using 56 as the value of x, I expected the result to be two values,
> > something like:
> >
> > [1] 56.17491697 56.02935105
> >
> > because I expected rnorm to return two values and then 56 to be added to
> > each of them. Instead, I got one value, something like:
> >
> > [1] 56.17491697
> >
> > So I wondered how this happened and wanted to see what happens behind the
> > scene. Coming from the Excel paradigm, I wondered, "Is there something
> like
> > 'show calculation steps' in R?" So I Googled it, and got nothing related
> > but this
> > <
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> > So, I tried breaking my code into separate lines and toggling breakpoints
> > at all lines, as follows:
> >
> > 6| AddLengthNoise <- function(x) {
> >
> >     - 7| x +
> >     - 8| rnorm(
> >     - 9| length(
> >     - 10| x)
> >     - 11| )
> >     - 12| }
> >
> > (Where the bullet points above represent the red debugging checkpoints)
> >
> > Then I tried again:
> >
> > AddLengthNoise(56)
> >
> > and as I executed step by step, I could not see what I expected. I
> couldn't
> > see each step's result, and I did not understand what I saw neither in
> the
> > console nor in the "Traceback" window that appeared.
> >
> > My 2 questions:
> >
> >     1. Did I do something wrong?
> >     2. Is there a way to see, like in Excel's "Show calculation steps",
> the
> >     result of each step alone (i.e. length(56)=2 ==>
> rnorm(2)={0.17491697;
> >     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]



From b@rhomopo||@ @end|ng |rom gm@||@com  Fri Jul 27 20:27:16 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:27:16 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <ad96cb6c-f260-00c8-eda0-df1ed7ad9c29@dewey.myzen.co.uk>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <ad96cb6c-f260-00c8-eda0-df1ed7ad9c29@dewey.myzen.co.uk>
Message-ID: <CAC4Bqrfw_kaw=c77n235VVv7CfA02RVd58A1VehzxTq9Coetnw@mail.gmail.com>

 Thanks a lot, Michael!



On Fri, 27 Jul 2018 at 12:12, Michael Dewey <lists at dewey.myzen.co.uk> wrote:

> Dear Ibrauheem
>
> First try
>
> length(56)
>
> then try
> rnorm()
> using the value you got in stage 1
>
> Michael
>
> On 27/07/2018 16:07, ??????? ???? Ibrauheem Khat'taub wrote:
> > Hi everyone,
> >
> > I am taking my first R course. This was my first example.
> >
> > When I executed:
> >
> > AddLengthNoise <- function(x) {x + rnorm(length(x))}
> >
> > using 56 as the value of x, I expected the result to be two values,
> > something like:
> >
> > [1] 56.17491697 56.02935105
> >
> > because I expected rnorm to return two values and then 56 to be added to
> > each of them. Instead, I got one value, something like:
> >
> > [1] 56.17491697
> >
> > So I wondered how this happened and wanted to see what happens behind the
> > scene. Coming from the Excel paradigm, I wondered, "Is there something
> like
> > 'show calculation steps' in R?" So I Googled it, and got nothing related
> > but this
> > <
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> > So, I tried breaking my code into separate lines and toggling breakpoints
> > at all lines, as follows:
> >
> > 6| AddLengthNoise <- function(x) {
> >
> >     - 7| x +
> >     - 8| rnorm(
> >     - 9| length(
> >     - 10| x)
> >     - 11| )
> >     - 12| }
> >
> > (Where the bullet points above represent the red debugging checkpoints)
> >
> > Then I tried again:
> >
> > AddLengthNoise(56)
> >
> > and as I executed step by step, I could not see what I expected. I
> couldn't
> > see each step's result, and I did not understand what I saw neither in
> the
> > console nor in the "Traceback" window that appeared.
> >
> > My 2 questions:
> >
> >     1. Did I do something wrong?
> >     2. Is there a way to see, like in Excel's "Show calculation steps",
> the
> >     result of each step alone (i.e. length(56)=2 ==>
> rnorm(2)={0.17491697;
> >     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]



From b@rhomopo||@ @end|ng |rom gm@||@com  Fri Jul 27 20:27:52 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:27:52 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CF87BBB9-3FC1-48A0-8CC9-FEDF9E1AD6AD@dcn.davis.ca.us>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <CF87BBB9-3FC1-48A0-8CC9-FEDF9E1AD6AD@dcn.davis.ca.us>
Message-ID: <CAC4BqrdV1FBy5OGmRAUiPM6o6TTR8JZtm_kec2M96uzEnWpKRg@mail.gmail.com>

OMG, Jeff, this is so helpful of you!
Thanks a lot!


On Fri, 27 Jul 2018 at 12:32, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Debugging in R applies one statement at a time. If you want to debug
> within a statement you can "step into" the function calls within the
> statement or you can execute the function calls separately and inspect the
> result. Your function consists of one statement so the debugger only has
> one place to stop. However, once stopped, you can execute
>
> length(x)
>
> and get a result 1 instead of 2 as you are erroneously expecting.
>
> The length function in R is NOT the equivalent of the LEN function in
> Excel... it tells you how many elements are in the vector, not the number
> of digits in a numeric or the number of characters in a string.
>
> Does
>
> AddLengthNoise( rep(56, 2) ) behave as desired?
>
> On July 27, 2018 8:07:41 AM PDT, "??????? ???? Ibrauheem Khat'taub" <
> barhomopolis at gmail.com> wrote:
> >Hi everyone,
> >
> >I am taking my first R course. This was my first example.
> >
> >When I executed:
> >
> >AddLengthNoise <- function(x) {x + rnorm(length(x))}
> >
> >using 56 as the value of x, I expected the result to be two values,
> >something like:
> >
> >[1] 56.17491697 56.02935105
> >
> >because I expected rnorm to return two values and then 56 to be added
> >to
> >each of them. Instead, I got one value, something like:
> >
> >[1] 56.17491697
> >
> >So I wondered how this happened and wanted to see what happens behind
> >the
> >scene. Coming from the Excel paradigm, I wondered, "Is there something
> >like
> >'show calculation steps' in R?" So I Googled it, and got nothing
> >related
> >but this
> ><
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> >So, I tried breaking my code into separate lines and toggling
> >breakpoints
> >at all lines, as follows:
> >
> >6| AddLengthNoise <- function(x) {
> >
> >   - 7| x +
> >   - 8| rnorm(
> >   - 9| length(
> >   - 10| x)
> >   - 11| )
> >   - 12| }
> >
> >(Where the bullet points above represent the red debugging checkpoints)
> >
> >Then I tried again:
> >
> >AddLengthNoise(56)
> >
> >and as I executed step by step, I could not see what I expected. I
> >couldn't
> >see each step's result, and I did not understand what I saw neither in
> >the
> >console nor in the "Traceback" window that appeared.
> >
> >My 2 questions:
> >
> >   1. Did I do something wrong?
> >2. Is there a way to see, like in Excel's "Show calculation steps", the
> > result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
> >   0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]



From b@rhomopo||@ @end|ng |rom gm@||@com  Fri Jul 27 20:28:19 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Fri, 27 Jul 2018 14:28:19 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <12344e39-b344-4a31-b7fb-5b5e375b9436@Spark>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
 <12344e39-b344-4a31-b7fb-5b5e375b9436@Spark>
Message-ID: <CAC4Bqre7yTKZ_HS6bDd7UaDvATU38HZtT-5RYMQYjWS=0catFQ@mail.gmail.com>

 Thanks a lot, Sarah! Appreciate the help!


On Fri, 27 Jul 2018 at 12:55, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> You can readily do it yourself:
>
> x <- 56
> length(x) # hint: why do you expect length(56) to be 2?
> rnorm(length(x))
> x + rnorm(length(x))
>
> For more complicated problems, the debugger is useful, but I almost always
> find investigating the steps at the command line to be the most informative.
>
> Sarah
> On Jul 27, 2018, 9:38 AM -0600, ??????? ???? Ibrauheem Khat'taub <
> barhomopolis at gmail.com>, wrote:
>
> Hi everyone,
>
> I am taking my first R course. This was my first example.
>
> When I executed:
>
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
>
> using 56 as the value of x, I expected the result to be two values,
> something like:
>
> [1] 56.17491697 56.02935105
>
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
>
> [1] 56.17491697
>
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <
> https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio
> >.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
>
> 6| AddLengthNoise <- function(x) {
>
> - 7| x +
> - 8| rnorm(
> - 9| length(
> - 10| x)
> - 11| )
> - 12| }
>
> (Where the bullet points above represent the red debugging checkpoints)
>
> Then I tried again:
>
> AddLengthNoise(56)
>
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
>
> My 2 questions:
>
> 1. Did I do something wrong?
> 2. Is there a way to see, like in Excel's "Show calculation steps", the
> result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
> 0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jul 27 18:02:36 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 27 Jul 2018 17:02:36 +0100
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to see detailed results of
 every calculation step
In-Reply-To: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
References: <CAC4BqrduY0K7NbQJw0PonK6nMJieOdSo_LMmyD2v6zdsz19E5Q@mail.gmail.com>
Message-ID: <d5eba459-0d66-34d8-913f-8665a8d02a74@sapo.pt>

Hello,

First of all welcome to R, I hope you enjoy it and that as you go along 
it will give less and less troubles.

Now, why would length(56) return 2? It's just one number, a vector of 
length 1.

Start by trying it at an R prompt and see the result.

Hope this helps,

Rui Barradas

?s 16:07 de 27-07-2018, ??????? ???? Ibrauheem Khat'taub escreveu:
> Hi everyone,
> 
> I am taking my first R course. This was my first example.
> 
> When I executed:
> 
> AddLengthNoise <- function(x) {x + rnorm(length(x))}
> 
> using 56 as the value of x, I expected the result to be two values,
> something like:
> 
> [1] 56.17491697 56.02935105
> 
> because I expected rnorm to return two values and then 56 to be added to
> each of them. Instead, I got one value, something like:
> 
> [1] 56.17491697
> 
> So I wondered how this happened and wanted to see what happens behind the
> scene. Coming from the Excel paradigm, I wondered, "Is there something like
> 'show calculation steps' in R?" So I Googled it, and got nothing related
> but this
> <https://support.rstudio.com/hc/en-us/articles/205612627-Debugging-with-RStudio>.
> So, I tried breaking my code into separate lines and toggling breakpoints
> at all lines, as follows:
> 
> 6| AddLengthNoise <- function(x) {
> 
>     - 7| x +
>     - 8| rnorm(
>     - 9| length(
>     - 10| x)
>     - 11| )
>     - 12| }
> 
> (Where the bullet points above represent the red debugging checkpoints)
> 
> Then I tried again:
> 
> AddLengthNoise(56)
> 
> and as I executed step by step, I could not see what I expected. I couldn't
> see each step's result, and I did not understand what I saw neither in the
> console nor in the "Traceback" window that appeared.
> 
> My 2 questions:
> 
>     1. Did I do something wrong?
>     2. Is there a way to see, like in Excel's "Show calculation steps", the
>     result of each step alone (i.e. length(56)=2 ==> rnorm(2)={0.17491697;
>     0.02935105} ==> 56 + {0.17491697; 0.02935105}= ... and so on)?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Jul 27 23:09:53 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 27 Jul 2018 21:09:53 +0000
Subject: [R] Formatting summary() output to a file
In-Reply-To: <alpine.LNX.2.20.1807270950580.21777@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1807270759480.21777@salmo.appl-ecosys.com>
 <2176C402-515F-45AC-848C-A50E9ED5B1A2@llnl.gov>
 <alpine.LNX.2.20.1807270950580.21777@salmo.appl-ecosys.com>
Message-ID: <EF2A617D-6779-4764-A5D1-364A6B89D03E@llnl.gov>

Hmmm. I do get output in the file with the first example, and the second example is too complicated for me.
-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/27/18, 9:56 AM, "R-help on behalf of Rich Shepard" <r-help-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

    On Fri, 27 Jul 2018, MacQueen, Don wrote:
    
    > Given your description, I would start with
    >
    > sink('wysumallyrs.txt')
    > print( summary(wyallyrs) )
    > sink()
    >
    > and see if that doesn't meet your needs.
    
    Don,
    
       I started with sink() trying to follow
    <https://stat.ethz.ch/R-manual/R-patched/library/base/html/sink.html> (which
    is the same as ?sink within R) using the two examples at the bottom. Neither
    used the print() function and the results were an empty file (using example
    1) or an error message about incorrect usage (using example 2).
    
       Your solution does make more sense than does using cat().
    
    Thanks,
    
    Rich
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Jul 28 05:35:22 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Jul 2018 15:35:22 +1200
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
Message-ID: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>


I have the task of producing some boxplot graphics with the requirement 
that these have the same general appearance as a set of such graphics
as were produced last year.  I do not have access to the code that was
used to produce the "last year" graphics.

There are multiple boxplots per figure and these boxplots appear in 
groups (with two boxplots in each group in the simplest instance; there 
are four or more per group in other instances, but I figure that if I 
can work out how to handle two, then ....).

After a bit of Googling I found that ggplot() does basically what I 
want.  However my mindset seems to be substantially incompatible with 
that of ggplot() and I cannot figure out how to make some adjustments 
which are needed in order to make my plots look like last year's.

In last year's graphics the boxes were unfilled and were distinguished
(within groups) by their boundary colours, which were "red" and "black"
in the simple two-per-group instance.  I achieved the "unfilled" effect 
by setting alpha=0 inside the call to geom_boxplot().  (Is this the 
Right Thing to Do?)  However I cannot get the boundary colours of the
boxes to be "red" and "black".

I have attached a sourceable script ("demo.txt") showing what I have 
tried so far.  I don't really understand the code; I simply copied and 
adjusted code that I saw on stackoverflow.  (Fairly mindlessly I'm afraid.)

Problems:

(1) The borders of the boxes are distinct, but they are sort-of-pink and 
sort-of-blue, and I cannot for the life of me figure out how to make 
them red and black.

(2) Putting in "color=Type" seemed to have the effect of creating two 
legends, one with the desired legend title but all in black, and one 
with legend title equal to "Type" but using the colours that actually 
appear. How can I get just one "appropriate" legend?

(3) Last year's graphics have the x-axis starting at 0 (rather than at
c. 3.5).  I tried using + xlim(0,8.5) but got told "Error: Discrete 
value supplied to continuous scale".  How can I make the appropriate
adjustment?

(4) Last year's graphics have y-axis tick marks, labels and grid lines 
at 700, 800, 900, ..., 2000, 2100.  How can I reproduce this?

I actually had several additional questions, but thought I'd better 
scrounge around a bit more before posting this, and thereby managed 
(mirabile dictu!) to answer them myself.

Can anyone help me out with questions (1) --- (4)?  Please keep it 
simple and very explicit, for I am a bear of very little brain and long 
words bother me!

Thanks.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180728/693e4dbe/attachment-0002.txt>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 28 07:03:47 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 22:03:47 -0700 (PDT)
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
Message-ID: <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>

When you understand the strong dependence on how the data controls ggplot, 
using it gets much easier. I still have to google details sometimes 
though. Note that it can be very difficult to make a weird plot (e.g. 
multiple parallel axes) in ggplot because it is very internally 
consistent... a blessing and a curse.

1) Colour is assigned in the scale according to order of levels of the 
factor. Note that while they are both discrete, the so-called "discrete" 
scales auto-colour, but "manual" scales require you to specify the exact 
colour sequence.

2) Assigning constants to properties is done outside the mapping (aes). 
Note that "colour" is for lines and shapes outlines, while "fill" is 
colour meant to fill in shapes. When the names of these two scales are the 
same and the values are the same, the legends will merge. If not, they 
will be shown separately.

3) Discrete scales are controlled by the levels in the data. To prevent 
ggplot from removing missing levels, use the drop=FALSE argument.

4) Breaks are a property of the scale.

My changes were:

Year <- factor( rep( 4:8, each = 50, times = 2 ), levels = 0:8 )
DemoDat <- data.frame(Year = Year, Score = c( X0 , X1 ), Type = Type )

ggplot( data = DemoDat
       , aes( x = Year, y = Score, color = Type )
       , fill = NULL
       ) +
     geom_boxplot( position = position_dodge(1) ) +
     theme_minimal() +
     scale_colour_manual( name = "National v. Local"
                        , values = c( "red", "black" ) ) +
     scale_x_discrete( drop = FALSE ) +
     scale_y_continuous( breaks = seq( 700, 2100, 100 ) )

Good luck with your graphics grammar!

On Sat, 28 Jul 2018, Rolf Turner wrote:

>
> I have the task of producing some boxplot graphics with the requirement that 
> these have the same general appearance as a set of such graphics
> as were produced last year.  I do not have access to the code that was
> used to produce the "last year" graphics.
>
> There are multiple boxplots per figure and these boxplots appear in groups 
> (with two boxplots in each group in the simplest instance; there are four or 
> more per group in other instances, but I figure that if I can work out how to 
> handle two, then ....).
>
> After a bit of Googling I found that ggplot() does basically what I want. 
> However my mindset seems to be substantially incompatible with that of 
> ggplot() and I cannot figure out how to make some adjustments which are 
> needed in order to make my plots look like last year's.
>
> In last year's graphics the boxes were unfilled and were distinguished
> (within groups) by their boundary colours, which were "red" and "black"
> in the simple two-per-group instance.  I achieved the "unfilled" effect by 
> setting alpha=0 inside the call to geom_boxplot().  (Is this the Right Thing 
> to Do?)  However I cannot get the boundary colours of the
> boxes to be "red" and "black".
>
> I have attached a sourceable script ("demo.txt") showing what I have tried so 
> far.  I don't really understand the code; I simply copied and adjusted code 
> that I saw on stackoverflow.  (Fairly mindlessly I'm afraid.)
>
> Problems:
>
> (1) The borders of the boxes are distinct, but they are sort-of-pink and 
> sort-of-blue, and I cannot for the life of me figure out how to make them red 
> and black.
>
> (2) Putting in "color=Type" seemed to have the effect of creating two 
> legends, one with the desired legend title but all in black, and one with 
> legend title equal to "Type" but using the colours that actually appear. How 
> can I get just one "appropriate" legend?
>
> (3) Last year's graphics have the x-axis starting at 0 (rather than at
> c. 3.5).  I tried using + xlim(0,8.5) but got told "Error: Discrete value 
> supplied to continuous scale".  How can I make the appropriate
> adjustment?
>
> (4) Last year's graphics have y-axis tick marks, labels and grid lines at 
> 700, 800, 900, ..., 2000, 2100.  How can I reproduce this?
>
> I actually had several additional questions, but thought I'd better scrounge 
> around a bit more before posting this, and thereby managed (mirabile dictu!) 
> to answer them myself.
>
> Can anyone help me out with questions (1) --- (4)?  Please keep it simple and 
> very explicit, for I am a bear of very little brain and long words bother me!
>
> Thanks.
>
> cheers,
>
> Rolf Turner
>
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sat Jul 28 07:58:36 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sat, 28 Jul 2018 05:58:36 +0000
Subject: [R] subsetting ls() as per class...
Message-ID: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear memebers,
                               I am using R in AWS linux instance for my research. I want to remove certain objects from the global environment  to reduce my EBS cost..for example, I want to remove all objects of class "xts", "zoo". Is there any way to automate this, instead of removing the objects one by one?

Basically, I want to subset  ls() according to class, and then remove that subset by using rm function.

I got to know about mget in SO, but that is not working in my case....

Also, all the above objects end with ".NS".  I came to know that you can remove objects starting with a certain pattern; is there any way to remove objects ending in a certain pattern?

very many thanks for your time and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From peter@|@ng|e|der @end|ng |rom gm@||@com  Sat Jul 28 08:11:54 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Fri, 27 Jul 2018 23:11:54 -0700
Subject: [R] subsetting ls() as per class...
In-Reply-To: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CA+hbrhW_-eD+izCYZTgCRma4qz-iB3FeqbUSZKgv9isx6RpnEA@mail.gmail.com>

Looking at ?rm, my solution would be something like

rm(list = grep("\\.NS$", ls(), value = TRUE))

But test it since I have not tested it.

Peter


On Fri, Jul 27, 2018 at 10:58 PM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> dear memebers,
>                                I am using R in AWS linux instance for my research. I want to remove certain objects from the global environment  to reduce my EBS cost..for example, I want to remove all objects of class "xts", "zoo". Is there any way to automate this, instead of removing the objects one by one?
>
> Basically, I want to subset  ls() according to class, and then remove that subset by using rm function.
>
> I got to know about mget in SO, but that is not working in my case....
>
> Also, all the above objects end with ".NS".  I came to know that you can remove objects starting with a certain pattern; is there any way to remove objects ending in a certain pattern?
>
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 28 08:18:10 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 27 Jul 2018 23:18:10 -0700
Subject: [R] subsetting ls() as per class...
In-Reply-To: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <47A8102A-F379-4B91-A8EA-82827EFDAC45@dcn.davis.ca.us>

You can extract the names into a character vector with ls and then use grep(..., values=TRUE ) to select which ones you want to remove, and then pass that list to rm.

However, due to the way R handles memory you are unlikely to see much savings by doing this. I would recommend focusing on creating a script or series of scripts that can allow you to re-create your analysis, and then restarting R whenever you are ready to reduce memory usage. This will have the side benefit of leaving you with a verified-complete record of how your analysis was done.

On July 27, 2018 10:58:36 PM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear memebers,
>I am using R in AWS linux instance for my research. I want to remove
>certain objects from the global environment  to reduce my EBS cost..for
>example, I want to remove all objects of class "xts", "zoo". Is there
>any way to automate this, instead of removing the objects one by one?
>
>Basically, I want to subset  ls() according to class, and then remove
>that subset by using rm function.
>
>I got to know about mget in SO, but that is not working in my case....
>
>Also, all the above objects end with ".NS".  I came to know that you
>can remove objects starting with a certain pattern; is there any way to
>remove objects ending in a certain pattern?
>
>very many thanks for your time and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From t@n@@@ @end|ng |rom gm@||@com  Sat Jul 28 08:24:46 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Fri, 27 Jul 2018 23:24:46 -0700
Subject: [R] a suggestion about the display of structural variants in R
Message-ID: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>

Dear all,

we wish you a fruitful and refreshing weekend ! Thought that I may also
write to ask you for a suggestion, specifically if you could please advise
on whether there is any package already built (in R) that could help with
the following data visualization :


    we have a set of mutations from many cancer samples

    we would like to display the POINT MUTATIONS along the chromosome
coordinates (on the linear scale, ie. HORIZONTALLY)

    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
VERTICAL LINES connecting the breakpoints that are located on the
chromosomes that are represented HORIZONTALLY

Thanks a lot,

-- bogdan

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Jul 28 11:34:47 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 28 Jul 2018 21:34:47 +1200
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
Message-ID: <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>


On 28/07/18 17:03, Jeff Newmiller wrote:

> When you understand the strong dependence on how the data controls 
> ggplot, using it gets much easier. I still have to google details 
> sometimes though. Note that it can be very difficult to make a weird 
> plot (e.g. multiple parallel axes) in ggplot because it is very 
> internally consistent... a blessing and a curse.
> 
> 1) Colour is assigned in the scale according to order of levels of the 
> factor. Note that while they are both discrete, the so-called "discrete" 
> scales auto-colour, but "manual" scales require you to specify the exact 
> colour sequence.
> 
> 2) Assigning constants to properties is done outside the mapping (aes). 
> Note that "colour" is for lines and shapes outlines, while "fill" is 
> colour meant to fill in shapes. When the names of these two scales are 
> the same and the values are the same, the legends will merge. If not, 
> they will be shown separately.
> 
> 3) Discrete scales are controlled by the levels in the data. To prevent 
> ggplot from removing missing levels, use the drop=FALSE argument.
> 
> 4) Breaks are a property of the scale.
> 
> My changes were:
> 
> Year <- factor( rep( 4:8, each = 50, times = 2 ), levels = 0:8 )
> DemoDat <- data.frame(Year = Year, Score = c( X0 , X1 ), Type = Type )
> 
> ggplot( data = DemoDat
>  ????? , aes( x = Year, y = Score, color = Type )
>  ????? , fill = NULL
>  ????? ) +
>  ??? geom_boxplot( position = position_dodge(1) ) +
>  ??? theme_minimal() +
>  ??? scale_colour_manual( name = "National v. Local"
>  ?????????????????????? , values = c( "red", "black" ) ) +
>  ??? scale_x_discrete( drop = FALSE ) +
>  ??? scale_y_continuous( breaks = seq( 700, 2100, 100 ) )
> 
> Good luck with your graphics grammar!

Dear Jeff,

Thanks very much for this cogent advice and for taking the trouble to 
steer me in the right direction.  However I am not quite out of the 
woods yet.

(1) I'm still getting two legends.  How do I stop this from happening?

(2) The boxes are "filled" (with pinkish and blueish colours --- which 
are referenced in the second of the two legends that I get).  How can I 
get "unfilled" boxes?

(3) The y-axis scale runs only from 800 to 1800, rather than from 700 to 
2100.  How can I force it to run from 700 to 2100?

(4) With the modified code we now get some "outliers" (points beyond the 
whisker tips) plotted --- which I didn't get before (and don't want, 
because "last year's" graphics did not include outliers).  How can I 
suppress the plotting of outliers?

I have attached a pdf containing the results of running the code that
you provided, so that you can readily see what is happening.

May I prevail upon your good graces to enlighten me about questions
(1) --- (4) above?

Ever so humbly grateful.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
A non-text attachment was scrubbed...
Name: demoPlot.pdf
Type: application/pdf
Size: 5772 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180728/ea156d7a/attachment-0002.pdf>

From henr|k@bengt@@on @end|ng |rom gm@||@com  Sat Jul 28 12:18:44 2018
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Sat, 28 Jul 2018 12:18:44 +0200
Subject: [R] subsetting ls() as per class...
In-Reply-To: <47A8102A-F379-4B91-A8EA-82827EFDAC45@dcn.davis.ca.us>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <47A8102A-F379-4B91-A8EA-82827EFDAC45@dcn.davis.ca.us>
Message-ID: <CAFDcVCTvvwEebxA5w8Mc6Z-ZmmruvLT6mzCWN6xtZXTAqes3yA@mail.gmail.com>

The ll() function of R.oo returns a data.frame with various attributes that
you can subset on, e.g.

> subset(R.oo::ll(), data.class %in% c("zoo", "xts"))
       member data.class dimension objectSize
2          fz        zoo        10       1344
4  sample.xts        xts  c(180,4)      10128
5           x        zoo         5        528
6          x1        zoo         5        880
7          x2        zoo         5        496
9           y        zoo         5       1040
11          z        zoo    c(5,3)       1184
12         z0        zoo         0        448
13         z2        zoo    c(4,3)        904
14        z20        zoo    c(4,0)        616
15         z3        zoo         8        528
16         z4        zoo         5        592
17         z5        zoo         5        792

Henrik

On Sat, Jul 28, 2018, 08:22 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> You can extract the names into a character vector with ls and then use
> grep(..., values=TRUE ) to select which ones you want to remove, and then
> pass that list to rm.
>
> However, due to the way R handles memory you are unlikely to see much
> savings by doing this. I would recommend focusing on creating a script or
> series of scripts that can allow you to re-create your analysis, and then
> restarting R whenever you are ready to reduce memory usage. This will have
> the side benefit of leaving you with a verified-complete record of how your
> analysis was done.
>
> On July 27, 2018 10:58:36 PM PDT, akshay kulkarni <akshay_e4 at hotmail.com>
> wrote:
> >dear memebers,
> >I am using R in AWS linux instance for my research. I want to remove
> >certain objects from the global environment  to reduce my EBS cost..for
> >example, I want to remove all objects of class "xts", "zoo". Is there
> >any way to automate this, instead of removing the objects one by one?
> >
> >Basically, I want to subset  ls() according to class, and then remove
> >that subset by using rm function.
> >
> >I got to know about mget in SO, but that is not working in my case....
> >
> >Also, all the above objects end with ".NS".  I came to know that you
> >can remove objects starting with a certain pattern; is there any way to
> >remove objects ending in a certain pattern?
> >
> >very many thanks for your time and effort...
> >yours sincerely,
> >AKSHAY M KULKARNI
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sat Jul 28 13:34:36 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sat, 28 Jul 2018 17:04:36 +0530
Subject: [R] Saving objects in RData file in different name
Message-ID: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>

Hi,

Let say I have 2 objects as below

x1 = 1:3
x2 = 5:4

Now I want to save both x1 and x2 in some RData file, however x1 will be
saved with a different name e.g. y

I tried below

save(y = x1, x2, file = "file.RData")

However still they are saved in their original names i.e. x1 and x2, not y
and y2.

Is there any possibility that I can achieve above without explicitly
copying y = x1 before y is passed to save()

Thanks for any feedback.

	[[alternative HTML version deleted]]



From m@||||@t@ @end|ng |rom pp@|net@||  Sat Jul 28 14:36:57 2018
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Sat, 28 Jul 2018 15:36:57 +0300
Subject: [R] Saving objects in RData file in different name
In-Reply-To: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
References: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
Message-ID: <5c4e105fa3181d9f94172e35fdecc1ad07c9cf0a.camel@pp.inet.fi>

Hi!

Maybe not the most elegant solution, but a workaround is to have a
function:

> save2<-function(y, ...) { save(y,...)}
> save2(x1,x2,file="test.RData")

The point is to include the variables to be "renamed" as parameters (in
my example: y). The function will use the parameter variable names when
saving the file.

HTH,
Kimmo

2018-07-28, 17:04 +0530, Christofer Bogaso wrote:
> Hi,
> 
> Let say I have 2 objects as below
> 
> x1 = 1:3
> x2 = 5:4
> 
> Now I want to save both x1 and x2 in some RData file, however x1 will
> be
> saved with a different name e.g. y
> 
> I tried below
> 
> save(y = x1, x2, file = "file.RData")
> 
> However still they are saved in their original names i.e. x1 and x2,
> not y
> and y2.
> 
> Is there any possibility that I can achieve above without explicitly
> copying y = x1 before y is passed to save()
> 
> Thanks for any feedback.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-gui
> de.html
> and provide commented, minimal, self-contained, reproducible code.



From bor|@@@te|pe @end|ng |rom utoronto@c@  Sat Jul 28 15:42:59 2018
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Sat, 28 Jul 2018 09:42:59 -0400
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
Message-ID: <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>

Maybe the Bioconductor package "intansv" can help you. You asked for linear chromosomes, but such data is commonly plotted in Circos plots as e.g. with the Bioconductor OmicsCircos package (cf. https://bioconductor.org/packages/devel/bioc/vignettes/OmicCircos/inst/doc/OmicCircos_vignette.pdf)

However the Bioconductor Project has its own support mailing list, R-Help is for programming help.


B.



> On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
> 
> Dear all,
> 
> we wish you a fruitful and refreshing weekend ! Thought that I may also
> write to ask you for a suggestion, specifically if you could please advise
> on whether there is any package already built (in R) that could help with
> the following data visualization :
> 
> 
>    we have a set of mutations from many cancer samples
> 
>    we would like to display the POINT MUTATIONS along the chromosome
> coordinates (on the linear scale, ie. HORIZONTALLY)
> 
>    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
> VERTICAL LINES connecting the breakpoints that are located on the
> chromosomes that are represented HORIZONTALLY
> 
> Thanks a lot,
> 
> -- bogdan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jerem|eju@te @end|ng |rom gm@||@com  Sat Jul 28 16:42:24 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Sat, 28 Jul 2018 16:42:24 +0200
Subject: [R] Saving objects in RData file in different name
In-Reply-To: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
 (Christofer Bogaso's message of "Sat, 28 Jul 2018 17:04:36 +0530")
References: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
Message-ID: <87o9erpgkv.fsf@gmail.com>

Christofer Bogaso <bogaso.christofer at gmail.com> writes:

Hello

In case you have conflicting data issue when you load data, you can also do it the other way around. Indeed you never know when a possible conflict might occur in the future.
The following line load the data in a new environment e first then get it back to your current environment.

loaded..data <- get(load("test.RData",e<- new.env()),e)

you might then want to remove everything in that enviromnent afterwards,

rm(list=ls(envir=e1), envir=e1)

HTH

Jeremie



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 28 16:54:15 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 28 Jul 2018 07:54:15 -0700 (PDT)
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
 <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
Message-ID: <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>

1) I don't know... it looks to me like you did not run my code. I have 
included a complete reprex below... try it out in a fresh session. If you 
still get the problem, check your sessionInfo package versions against 
mine.

2) This still smells like your fill parameter is inside the aes function 
with Type as value. This causes a legend to be created, and since that 
legend has a different name ("Type") than the colour scale, they are 
separated. Confirm that you are using fill outside the aes function 
(because you don't want fill to depend on the data) and have the constant 
NULL as value (so it won't generate any fill graphical representation).

3) I missed that... the ylim()/scales_y_continuous(breaks=) limits 
constrain which data are included as input into the graph. The 
coord_cartesian function forces the limits as desired.

4) While showing outliers is a standard semantic feature of boxplots 
whether produced by ggplot or lattice or base or non-R solution, you can 
please the client by making the outliers transparent.

There is a link to the generated image below.

################
# Simulate some data:
Type <- rep( c( "National", "Local" ), each = 250 )
M0   <- 1300+50*(0:4)
set.seed( 42 )
M1   <- M0 + runif( 5, -100, -50 )
X0   <- rnorm( 250, rep( M0, each = 50 ), 150 )
X1   <- rnorm( 250, rep( M1, each = 50 ), 100 )

library(ggplot2)
Year <- factor( rep( 4:8, each = 50, times = 2)
               , levels = 0:8 )
DemoDat <- data.frame( Year = Year
                      , Score = c( X0, X1 )
                      , Type = Type
                      )

ggplot( data = DemoDat
       , aes( x = Year
            , y = Score
            , color = Type
            )
       , fill = NULL
       ) +
     geom_boxplot( position = position_dodge( 1 )
                 , outlier.alpha = 0
                 ) +
     theme_minimal() +
     scale_colour_manual( name = "National v. Local"
                        , values = c( "red", "black" ) ) +
     scale_x_discrete( drop = FALSE ) +
     scale_y_continuous( breaks=seq( 700, 2100, 100 ) ) +
     coord_cartesian( ylim = c( 700, 2100 ) )

# ![](https://i.imgur.com/wUVYU5H.png)

#' Created on 2018-07-28 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
################


> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C 
LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8 
LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C 
LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_3.0.0

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.17     pillar_1.2.3     compiler_3.4.4   plyr_1.8.4 
bindr_0.1.1      tools_3.4.4
  [7] digest_0.6.15    memoise_1.1.0    evaluate_0.10.1  tibble_1.4.2 
gtable_0.2.0     debugme_1.1.0
[13] pkgconfig_2.0.1  rlang_0.2.1      reprex_0.2.0     rstudioapi_0.7 
yaml_2.1.19      bindrcpp_0.2.2
[19] stringr_1.3.1    withr_2.1.2      dplyr_0.7.6      knitr_1.20 
devtools_1.13.6  rprojroot_1.3-2
[25] grid_3.4.4       tidyselect_0.2.4 glue_1.2.0       R6_2.2.2 
processx_3.1.0   rmarkdown_1.10
[31] clipr_0.4.1      purrr_0.2.5      callr_2.0.4      magrittr_1.5 
whisker_0.3-2    scales_0.5.0
[37] backports_1.1.2  htmltools_0.3.6  assertthat_0.2.0 colorspace_1.3-2 
stringi_1.2.3    lazyeval_0.2.1
[43] munsell_0.5.0    crayon_1.3.4



On Sat, 28 Jul 2018, Rolf Turner wrote:

>
> On 28/07/18 17:03, Jeff Newmiller wrote:
>
>> When you understand the strong dependence on how the data controls ggplot, 
>> using it gets much easier. I still have to google details sometimes though. 
>> Note that it can be very difficult to make a weird plot (e.g. multiple 
>> parallel axes) in ggplot because it is very internally consistent... a 
>> blessing and a curse.
>> 
>> 1) Colour is assigned in the scale according to order of levels of the 
>> factor. Note that while they are both discrete, the so-called "discrete" 
>> scales auto-colour, but "manual" scales require you to specify the exact 
>> colour sequence.
>> 
>> 2) Assigning constants to properties is done outside the mapping (aes). 
>> Note that "colour" is for lines and shapes outlines, while "fill" is colour 
>> meant to fill in shapes. When the names of these two scales are the same 
>> and the values are the same, the legends will merge. If not, they will be 
>> shown separately.
>> 
>> 3) Discrete scales are controlled by the levels in the data. To prevent 
>> ggplot from removing missing levels, use the drop=FALSE argument.
>> 
>> 4) Breaks are a property of the scale.
>> 
>> My changes were:
>> 
>> Year <- factor( rep( 4:8, each = 50, times = 2 ), levels = 0:8 )
>> DemoDat <- data.frame(Year = Year, Score = c( X0 , X1 ), Type = Type )
>> 
>> ggplot( data = DemoDat
>>  ????? , aes( x = Year, y = Score, color = Type )
>>  ????? , fill = NULL
>>  ????? ) +
>>  ??? geom_boxplot( position = position_dodge(1) ) +
>>  ??? theme_minimal() +
>>  ??? scale_colour_manual( name = "National v. Local"
>>  ?????????????????????? , values = c( "red", "black" ) ) +
>>  ??? scale_x_discrete( drop = FALSE ) +
>>  ??? scale_y_continuous( breaks = seq( 700, 2100, 100 ) )
>> 
>> Good luck with your graphics grammar!
>
> Dear Jeff,
>
> Thanks very much for this cogent advice and for taking the trouble to steer 
> me in the right direction.  However I am not quite out of the woods yet.
>
> (1) I'm still getting two legends.  How do I stop this from happening?
>
> (2) The boxes are "filled" (with pinkish and blueish colours --- which are 
> referenced in the second of the two legends that I get).  How can I get 
> "unfilled" boxes?
>
> (3) The y-axis scale runs only from 800 to 1800, rather than from 700 to 
> 2100.  How can I force it to run from 700 to 2100?
>
> (4) With the modified code we now get some "outliers" (points beyond the 
> whisker tips) plotted --- which I didn't get before (and don't want, because 
> "last year's" graphics did not include outliers).  How can I suppress the 
> plotting of outliers?
>
> I have attached a pdf containing the results of running the code that
> you provided, so that you can readily see what is happening.
>
> May I prevail upon your good graces to enlighten me about questions
> (1) --- (4) above?
>
> Ever so humbly grateful.
>
> cheers,
>
> Rolf
>
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From t@n@@@ @end|ng |rom gm@||@com  Sat Jul 28 16:52:57 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 28 Jul 2018 07:52:57 -0700
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
 <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
Message-ID: <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>

Dear Boris,

good morning, and thank you for your message.  After thinking a bit more
yesterday, I believe that I could adapt the functionality of some R
packages that display the synteny regions across multiple species (here
please see an example Figure 1 from http://www.g3journal.org/
content/7/6/1775.figures-only),

although I have not found yet a R package that does this display (in my
case, instead of distinct species, I will just show distinct chromosomes
connected by translocations). If you have any suggestions, please let me
know.

thanks a lot,

-- bogdan


On Sat, Jul 28, 2018 at 6:42 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Maybe the Bioconductor package "intansv" can help you. You asked for
> linear chromosomes, but such data is commonly plotted in Circos plots as
> e.g. with the Bioconductor OmicsCircos package (cf.
> https://bioconductor.org/packages/devel/bioc/vignettes/
> OmicCircos/inst/doc/OmicCircos_vignette.pdf)
>
> However the Bioconductor Project has its own support mailing list, R-Help
> is for programming help.
>
>
> B.
>
>
>
> > On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
> >
> > Dear all,
> >
> > we wish you a fruitful and refreshing weekend ! Thought that I may also
> > write to ask you for a suggestion, specifically if you could please
> advise
> > on whether there is any package already built (in R) that could help with
> > the following data visualization :
> >
> >
> >    we have a set of mutations from many cancer samples
> >
> >    we would like to display the POINT MUTATIONS along the chromosome
> > coordinates (on the linear scale, ie. HORIZONTALLY)
> >
> >    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
> > VERTICAL LINES connecting the breakpoints that are located on the
> > chromosomes that are represented HORIZONTALLY
> >
> > Thanks a lot,
> >
> > -- bogdan
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul 28 17:05:44 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 28 Jul 2018 08:05:44 -0700 (PDT)
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
 <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
 <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1807280803360.27913@pedal.dcn.davis.ca.us>

My suggestion is to pay attention to Boris and ask people who do this kind 
of plotting frequently... and they are typically found on the Bioconductor 
mailing list, not this list.

On Sat, 28 Jul 2018, Bogdan Tanasa wrote:

> Dear Boris,
>
> good morning, and thank you for your message.  After thinking a bit more
> yesterday, I believe that I could adapt the functionality of some R
> packages that display the synteny regions across multiple species (here
> please see an example Figure 1 from http://www.g3journal.org/
> content/7/6/1775.figures-only),
>
> although I have not found yet a R package that does this display (in my
> case, instead of distinct species, I will just show distinct chromosomes
> connected by translocations). If you have any suggestions, please let me
> know.
>
> thanks a lot,
>
> -- bogdan
>
>
> On Sat, Jul 28, 2018 at 6:42 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> Maybe the Bioconductor package "intansv" can help you. You asked for
>> linear chromosomes, but such data is commonly plotted in Circos plots as
>> e.g. with the Bioconductor OmicsCircos package (cf.
>> https://bioconductor.org/packages/devel/bioc/vignettes/
>> OmicCircos/inst/doc/OmicCircos_vignette.pdf)
>>
>> However the Bioconductor Project has its own support mailing list, R-Help
>> is for programming help.
>>
>>
>> B.
>>
>>
>>
>>> On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>
>>> Dear all,
>>>
>>> we wish you a fruitful and refreshing weekend ! Thought that I may also
>>> write to ask you for a suggestion, specifically if you could please
>> advise
>>> on whether there is any package already built (in R) that could help with
>>> the following data visualization :
>>>
>>>
>>>    we have a set of mutations from many cancer samples
>>>
>>>    we would like to display the POINT MUTATIONS along the chromosome
>>> coordinates (on the linear scale, ie. HORIZONTALLY)
>>>
>>>    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
>>> VERTICAL LINES connecting the breakpoints that are located on the
>>> chromosomes that are represented HORIZONTALLY
>>>
>>> Thanks a lot,
>>>
>>> -- bogdan
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From t@n@@@ @end|ng |rom gm@||@com  Sat Jul 28 17:03:37 2018
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 28 Jul 2018 08:03:37 -0700
Subject: [R] a suggestion about the display of structural variants in R
In-Reply-To: <alpine.BSF.2.00.1807280803360.27913@pedal.dcn.davis.ca.us>
References: <CA+JEM01--SNBMfgesL6Dx2Mb=OKh5mo9bZQvKEx52D87dzH8AA@mail.gmail.com>
 <1A03E961-E55F-4CB2-898D-117A04FB61D0@utoronto.ca>
 <CA+JEM03jkXZPf_g5tBVaipBXVXg8oOnXSf75rVVhHBPEjd4cpg@mail.gmail.com>
 <alpine.BSF.2.00.1807280803360.27913@pedal.dcn.davis.ca.us>
Message-ID: <CA+JEM00SWQparZ7OsV5kgRGE25K5VH3gm3Ab8oCT5ZiMU7WdPg@mail.gmail.com>

Thank you Jeff. Yes, certainly, I posted a message on BioC too, although I
have not received any suggestions by now.

On Sat, Jul 28, 2018 at 8:05 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> My suggestion is to pay attention to Boris and ask people who do this kind
> of plotting frequently... and they are typically found on the Bioconductor
> mailing list, not this list.
>
> On Sat, 28 Jul 2018, Bogdan Tanasa wrote:
>
> Dear Boris,
>>
>> good morning, and thank you for your message.  After thinking a bit more
>> yesterday, I believe that I could adapt the functionality of some R
>> packages that display the synteny regions across multiple species (here
>> please see an example Figure 1 from http://www.g3journal.org/
>> content/7/6/1775.figures-only),
>>
>> although I have not found yet a R package that does this display (in my
>> case, instead of distinct species, I will just show distinct chromosomes
>> connected by translocations). If you have any suggestions, please let me
>> know.
>>
>> thanks a lot,
>>
>> -- bogdan
>>
>>
>> On Sat, Jul 28, 2018 at 6:42 AM, Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>>
>> Maybe the Bioconductor package "intansv" can help you. You asked for
>>> linear chromosomes, but such data is commonly plotted in Circos plots as
>>> e.g. with the Bioconductor OmicsCircos package (cf.
>>> https://bioconductor.org/packages/devel/bioc/vignettes/
>>> OmicCircos/inst/doc/OmicCircos_vignette.pdf)
>>>
>>> However the Bioconductor Project has its own support mailing list, R-Help
>>> is for programming help.
>>>
>>>
>>> B.
>>>
>>>
>>>
>>> On 2018-07-28, at 02:24, Bogdan Tanasa <tanasa at gmail.com> wrote:
>>>>
>>>> Dear all,
>>>>
>>>> we wish you a fruitful and refreshing weekend ! Thought that I may also
>>>> write to ask you for a suggestion, specifically if you could please
>>>>
>>> advise
>>>
>>>> on whether there is any package already built (in R) that could help
>>>> with
>>>> the following data visualization :
>>>>
>>>>
>>>>    we have a set of mutations from many cancer samples
>>>>
>>>>    we would like to display the POINT MUTATIONS along the chromosome
>>>> coordinates (on the linear scale, ie. HORIZONTALLY)
>>>>
>>>>    we would like to display the TRANSLOCATIONS (and GENE FUSIONS), as
>>>> VERTICAL LINES connecting the breakpoints that are located on the
>>>> chromosomes that are represented HORIZONTALLY
>>>>
>>>> Thanks a lot,
>>>>
>>>> -- bogdan
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>
>>> posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Sat Jul 28 17:07:04 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Sat, 28 Jul 2018 08:07:04 -0700
Subject: [R] subsetting ls() as per class...
In-Reply-To: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcbZS3otj6fRFKNNkjpAiXht=NRDXentfHo5Nk_7ZX7Tuw@mail.gmail.com>

> objClasses <- unlist(eapply(.GlobalEnv, function(x)class(x)[1]))
> head(objClasses)
            f             E
   "function" "environment"
           df             h
     "tbl_df"    "function"
       myData             L
       "list"        "list"
> names(objClasses)[objClasses=="tbl_df"]
[1] "df"  "out"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jul 27, 2018 at 10:58 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear memebers,
>                                I am using R in AWS linux instance for my
> research. I want to remove certain objects from the global environment  to
> reduce my EBS cost..for example, I want to remove all objects of class
> "xts", "zoo". Is there any way to automate this, instead of removing the
> objects one by one?
>
> Basically, I want to subset  ls() according to class, and then remove that
> subset by using rm function.
>
> I got to know about mget in SO, but that is not working in my case....
>
> Also, all the above objects end with ".NS".  I came to know that you can
> remove objects starting with a certain pattern; is there any way to remove
> objects ending in a certain pattern?
>
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sat Jul 28 18:05:33 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sat, 28 Jul 2018 16:05:33 +0000
Subject: [R] subsetting ls() as per class...
In-Reply-To: <CA+hbrhW_-eD+izCYZTgCRma4qz-iB3FeqbUSZKgv9isx6RpnEA@mail.gmail.com>
References: <SL2P216MB009147ECBA8DF2E253E60F4EC8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <CA+hbrhW_-eD+izCYZTgCRma4qz-iB3FeqbUSZKgv9isx6RpnEA@mail.gmail.com>
Message-ID: <SL2P216MB0091544A68CD2D65C1708E07C8290@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear peter,
                     Its working....thanks a lot...

yours sincerely,
AKSHAY M KULKARNI
________________________________
From: Peter Langfelder <peter.langfelder at gmail.com>
Sent: Saturday, July 28, 2018 11:41 AM
To: akshay_e4 at hotmail.com
Cc: r-help
Subject: Re: [R] subsetting ls() as per class...

Looking at ?rm, my solution would be something like

rm(list = grep("\\.NS$", ls(), value = TRUE))

But test it since I have not tested it.

Peter


On Fri, Jul 27, 2018 at 10:58 PM akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>
> dear memebers,
>                                I am using R in AWS linux instance for my research. I want to remove certain objects from the global environment  to reduce my EBS cost..for example, I want to remove all objects of class "xts", "zoo". Is there any way to automate this, instead of removing the objects one by one?
>
> Basically, I want to subset  ls() according to class, and then remove that subset by using rm function.
>
> I got to know about mget in SO, but that is not working in my case....
>
> Also, all the above objects end with ".NS".  I came to know that you can remove objects starting with a certain pattern; is there any way to remove objects ending in a certain pattern?
>
> very many thanks for your time and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Jul 29 01:04:02 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 29 Jul 2018 11:04:02 +1200
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
 <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
 <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>
Message-ID: <4ed6b5de-05fc-a818-2da4-57a2d5f9f4e9@auckland.ac.nz>


On 29/07/18 02:54, Jeff Newmiller wrote:

> 1) I don't know... it looks to me like you did not run my code.

Aaaarrrgghhh.  I *thought* I had, but instead left "fill=Type" inside 
the aes() call and neglected to add fill=NULL outside this call. 
Duhhhh!!! It's tough being mentally challenged, let me assure you.

> I have 
> included a complete reprex below... try it out in a fresh session. If 
> you still get the problem, check your sessionInfo package versions 
> against mine.

Yep.  Works like a charm.

> 2) This still smells like your fill parameter is inside the aes function 
> with Type as value. This causes a legend to be created, and since that 
> legend has a different name ("Type") than the colour scale, they are 
> separated. Confirm that you are using fill outside the aes function 
> (because you don't want fill to depend on the data) and have the 
> constant NULL as value (so it won't generate any fill graphical 
> representation).

Yeah.  Well.  Duhhh.  I'm a retread.
> 
> 3) I missed that... the ylim()/scales_y_continuous(breaks=) limits 
> constrain which data are included as input into the graph. The 
> coord_cartesian function forces the limits as desired.

Bewdy, ta.

> 
> 4) While showing outliers is a standard semantic feature of boxplots 
> whether produced by ggplot or lattice or base or non-R solution,

Indeed.  But the client is always right! :-)

> you can 
> please the client by making the outliers transparent.

And your code shows me how!  Which I need.  Bewdy, ta.

> There is a link to the generated image below.
> 
> ################
> # Simulate some data:
> Type <- rep( c( "National", "Local" ), each = 250 )
> M0?? <- 1300+50*(0:4)
> set.seed( 42 )
> M1?? <- M0 + runif( 5, -100, -50 )
> X0?? <- rnorm( 250, rep( M0, each = 50 ), 150 )
> X1?? <- rnorm( 250, rep( M1, each = 50 ), 100 )
> 
> library(ggplot2)
> Year <- factor( rep( 4:8, each = 50, times = 2)
>  ????????????? , levels = 0:8 )
> DemoDat <- data.frame( Year = Year
>  ???????????????????? , Score = c( X0, X1 )
>  ???????????????????? , Type = Type
>  ???????????????????? )
> 
> ggplot( data = DemoDat
>  ????? , aes( x = Year
>  ?????????? , y = Score
>  ?????????? , color = Type
>  ?????????? )
>  ????? , fill = NULL
>  ????? ) +
>  ??? geom_boxplot( position = position_dodge( 1 )
>  ??????????????? , outlier.alpha = 0
>  ??????????????? ) +
>  ??? theme_minimal() +
>  ??? scale_colour_manual( name = "National v. Local"
>  ?????????????????????? , values = c( "red", "black" ) ) +
>  ??? scale_x_discrete( drop = FALSE ) +
>  ??? scale_y_continuous( breaks=seq( 700, 2100, 100 ) ) +
>  ??? coord_cartesian( ylim = c( 700, 2100 ) )
> 
> # ![](https://i.imgur.com/wUVYU5H.png)

Looks perfect.  Thanks *HUGELY* for your patience with my stupidity.

<SNIP>

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From jenny@||u00 @end|ng |rom gm@||@com  Mon Jul 30 02:24:50 2018
From: jenny@||u00 @end|ng |rom gm@||@com (Jenny Liu)
Date: Mon, 30 Jul 2018 00:24:50 +0000
Subject: [R] A quick question on devRate package
Message-ID: <c8765a76-08d9-1d54-c367-a075ed1e0261@mixmax.com>

Hi all,

If anybody is familiar with the package "devRate" that would be helpful! I am
finding that it's giving me a bit of conflicting information:

When I enter
>devRateFind(familySP="Cecidomyiidae")

It tells me that the formula campbell_74 was used 11 times. However, when I
enter
>devRateInfo(eq=campbell_74)
There are only 3 entries for Diptera, and none of them are Cecidomyiidae.
Am I doing something wrong, or missing something? I read through the instruction
manual but it's definitely possible I misunderstood.
Thanks for your time!
Cheers,Jenny Liu
	[[alternative HTML version deleted]]



From rmh @end|ng |rom temp|e@edu  Mon Jul 30 05:32:36 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sun, 29 Jul 2018 23:32:36 -0400
Subject: [R] Grouped boxplots using ggplot() from ggplot2.
In-Reply-To: <4ed6b5de-05fc-a818-2da4-57a2d5f9f4e9@auckland.ac.nz>
References: <a889519b-db95-c846-eb1f-709659dd6917@auckland.ac.nz>
 <alpine.BSF.2.00.1807272147130.5737@pedal.dcn.davis.ca.us>
 <3157a040-8c66-3f4c-576a-7bbaef1e0210@auckland.ac.nz>
 <alpine.BSF.2.00.1807280721460.27913@pedal.dcn.davis.ca.us>
 <4ed6b5de-05fc-a818-2da4-57a2d5f9f4e9@auckland.ac.nz>
Message-ID: <CAGx1TMA_N4P2SsR_pp_gdVrmuU=SOoEX-HoaM-k100o7-2teqw@mail.gmail.com>

## I recommend using lattice for this task.
## First I show the example from my book and package (HH).
## Then I use this on your example.

library(HH)       ## Package supporting Heiberger and Holland,
                  ## Statistical Analysis and Data Display (Second
edition, 2015)
HHscriptnames(4)  ## Filename on your computer for script for all
Chapter 4 examples

## this is Chunk 23

###################################################
### code chunk number 23: grap.tex:1953-1981
###################################################
bwdata <- data.frame(Y=(rt(80, df=5)*5 + rep(c(20,25,15,22, 22,28,16,14), 10)),
                     week=ordered(rep(c(1:4, 1:4), each=10)),
                     treatment= rep(c("A", "B"), each=40))

position(bwdata$week) <- c(1, 2, 4, 8)
levels(bwdata$week) <- c(1, 2, 4, 8)

bwdata$week.treatment <- with(bwdata, interaction(treatment, week))
position(bwdata$week.treatment) <-
   as.vector(t(outer(c(1, 2, 4, 8), c(-.18,.18), "+")))

BR <- likertColor(2, colorFunctionOption="default")[2:1]

## uses panel.bwplot.intermediate.hh to control position and colors
## hhpdf("bwplotposition.pdf", width=7, height=5)
bwplot(Y ~ week.treatment, data=bwdata,
       panel=panel.bwplot.intermediate.hh, xlim=c(0, 9),
       box.width=.25,
       pch=c(17, 16), col=BR,
       xlab="Week", ylab=list(rot=0),
       scales=list(x=list(at=position(bwdata$week), tck=1)),
       key=list(
          text=list(c("A","B"), col=BR),
          points=list(pch=c(17, 16), col=BR),
          space="top", columns=2, between=1, border=TRUE,
          title="Treatment", cex.title=.9)) +
   layer(panel.abline(h=37, col="gray60", lty=3, lwd=2))
## hhdev.off()


## The placement features provided by panel.bwplot.intermediate.hh are
## 1. The two boxes at each time position are clearly distinguished
##    from boxes at other time positions.
##
## 2. Times do not need to be evenly spaced.


## Now your sample data and lattice code for your desired graph


## Script to demonstrate what I am trying to do.
##

## Simulate some data:
Year <- factor(rep(4:8,each=50,times=2))
Type <- rep(c("National","Local"),each=250)
M0   <- 1300+50*(0:4)
set.seed(42)
M1   <- M0 + runif(5,-100,-50)
X0   <- rnorm(250,rep(M0,each=50),150)
X1   <- rnorm(250,rep(M1,each=50),100)
DemoDat <- data.frame(Year=Year,Score=c(X0,X1),Type=Type)

if (FALSE) { ## Rolf Turners original code
## Grouped boxplots:
library(ggplot2)
print(ggplot(data=DemoDat) +
    geom_boxplot(aes(x=Year, y=Score, color=Type,fill=Type),
                 position=position_dodge(1),alpha=0) +
    theme_minimal() +
    scale_fill_discrete(name="National v. Local") +
    ylim(700,2100))
}


DemoDat$Year.Type <- with(DemoDat, interaction(Year, Type))
position(DemoDat$Year.Type) <-
   as.vector(t(outer(c(4, 5, 6, 7, 8), c(-.18, .18), "+")))
RB <- c("red", "black")

SYT <-
bwplot(Score ~ Year.Type, data=DemoDat,
       panel=panel.bwplot.intermediate.hh,
       xlim=c(-.1, 9.1),
       ylim=c(690, 2110),
       box.width=.22,
       col=RB,
       xlab="Year", ylab=list(rot=0),
       scales=list(x=list(at=0:9, tck=1),
                   y=list(at=seq(700, 2100, 100), tick=1)),
       par.settings=list(box.dot=list(pch="|"),
                         plot.symbol=list(pch="-", col=RB, cex=1.5)),
       key=list(
         text=list(levels(DemoDat$Type), col=RB, cex=.8),
         lines=list(col=RB), size=1.5,
         columns=2, between=.5, between.columns=.6,
         space="right", border=FALSE,
         title="\nNational v. Local", cex.title=.9),
       main="Matches specifications"
       )
SYT

update(SYT, main="Outliers made invisible, not recommended",
       par.settings=list(plot.symbol=list(cex=0)))

## Rich


On Sat, Jul 28, 2018 at 7:04 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 29/07/18 02:54, Jeff Newmiller wrote:
>
>> 1) I don't know... it looks to me like you did not run my code.
>
>
> Aaaarrrgghhh.  I *thought* I had, but instead left "fill=Type" inside the
> aes() call and neglected to add fill=NULL outside this call. Duhhhh!!! It's
> tough being mentally challenged, let me assure you.
>
>> I have included a complete reprex below... try it out in a fresh session.
>> If you still get the problem, check your sessionInfo package versions
>> against mine.
>
>
> Yep.  Works like a charm.
>
>> 2) This still smells like your fill parameter is inside the aes function
>> with Type as value. This causes a legend to be created, and since that
>> legend has a different name ("Type") than the colour scale, they are
>> separated. Confirm that you are using fill outside the aes function (because
>> you don't want fill to depend on the data) and have the constant NULL as
>> value (so it won't generate any fill graphical representation).
>
>
> Yeah.  Well.  Duhhh.  I'm a retread.
>>
>>
>> 3) I missed that... the ylim()/scales_y_continuous(breaks=) limits
>> constrain which data are included as input into the graph. The
>> coord_cartesian function forces the limits as desired.
>
>
> Bewdy, ta.
>
>>
>> 4) While showing outliers is a standard semantic feature of boxplots
>> whether produced by ggplot or lattice or base or non-R solution,
>
>
> Indeed.  But the client is always right! :-)
>
>> you can please the client by making the outliers transparent.
>
>
> And your code shows me how!  Which I need.  Bewdy, ta.
>
>
>> There is a link to the generated image below.
>>
>> ################
>> # Simulate some data:
>> Type <- rep( c( "National", "Local" ), each = 250 )
>> M0   <- 1300+50*(0:4)
>> set.seed( 42 )
>> M1   <- M0 + runif( 5, -100, -50 )
>> X0   <- rnorm( 250, rep( M0, each = 50 ), 150 )
>> X1   <- rnorm( 250, rep( M1, each = 50 ), 100 )
>>
>> library(ggplot2)
>> Year <- factor( rep( 4:8, each = 50, times = 2)
>>                , levels = 0:8 )
>> DemoDat <- data.frame( Year = Year
>>                       , Score = c( X0, X1 )
>>                       , Type = Type
>>                       )
>>
>> ggplot( data = DemoDat
>>        , aes( x = Year
>>             , y = Score
>>             , color = Type
>>             )
>>        , fill = NULL
>>        ) +
>>      geom_boxplot( position = position_dodge( 1 )
>>                  , outlier.alpha = 0
>>                  ) +
>>      theme_minimal() +
>>      scale_colour_manual( name = "National v. Local"
>>                         , values = c( "red", "black" ) ) +
>>      scale_x_discrete( drop = FALSE ) +
>>      scale_y_continuous( breaks=seq( 700, 2100, 100 ) ) +
>>      coord_cartesian( ylim = c( 700, 2100 ) )
>>
>> # ![](https://i.imgur.com/wUVYU5H.png)
>
>
> Looks perfect.  Thanks *HUGELY* for your patience with my stupidity.
>
> <SNIP>
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From c@|@ndr@ @end|ng |rom rgzm@de  Mon Jul 30 08:46:46 2018
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 30 Jul 2018 08:46:46 +0200
Subject: [R] Saving objects in RData file in different name
In-Reply-To: <5c4e105fa3181d9f94172e35fdecc1ad07c9cf0a.camel@pp.inet.fi>
References: <CA+dpOJ=mPpMXFyJjvCDXzb0Wt3-06uLxNf9oZ6WgqFgBZZoWKA@mail.gmail.com>
 <5c4e105fa3181d9f94172e35fdecc1ad07c9cf0a.camel@pp.inet.fi>
Message-ID: <b2d25a65-738d-ead8-8528-b1467d40937f@rgzm.de>

Hi!

In those cases, I use R.utils::saveObject() and loadObject().
You would have to save each object separately though:

saveObject(x1, file="file.Rbin")
y <- loadObject(file="file.Rbin")

HTH
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 28/07/2018 14:36, K. Elo wrote:
> Hi!
>
> Maybe not the most elegant solution, but a workaround is to have a
> function:
>
>> save2<-function(y, ...) { save(y,...)}
>> save2(x1,x2,file="test.RData")
> The point is to include the variables to be "renamed" as parameters (in
> my example: y). The function will use the parameter variable names when
> saving the file.
>
> HTH,
> Kimmo
>
> 2018-07-28, 17:04 +0530, Christofer Bogaso wrote:
>> Hi,
>>
>> Let say I have 2 objects as below
>>
>> x1 = 1:3
>> x2 = 5:4
>>
>> Now I want to save both x1 and x2 in some RData file, however x1 will
>> be
>> saved with a different name e.g. y
>>
>> I tried below
>>
>> save(y = x1, x2, file = "file.RData")
>>
>> However still they are saved in their original names i.e. x1 and x2,
>> not y
>> and y2.
>>
>> Is there any possibility that I can achieve above without explicitly
>> copying y = x1 before y is passed to save()
>>
>> Thanks for any feedback.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-gui
>> de.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Mon Jul 30 09:18:24 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Mon, 30 Jul 2018 10:18:24 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <20180629182925.4606e7be@goodenia>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
 <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>
 <20180629182925.4606e7be@goodenia>
Message-ID: <CAJxz9NZ0nnB0j3cLKQjVKuMaJdy0cFykgWX26UJjTBmEx5NTrg@mail.gmail.com>

Thanks a lot! I got the main part working (after a relaxing holiday).
However I still have some problems with the conditions. The looping is not
working properly, but this is not really an QP problem anymore. It's more
about that R runs the loop differently than c++, I guess.

Thanks a lot for help!
Maija

pe 29. kes?k. 2018 klo 13.29 Berwin A Turlach (berwin.turlach at gmail.com)
kirjoitti:

> G'day Maija,
>
> On Wed, 27 Jun 2018 08:48:08 +0300
> Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
>
> > Thanks for your reply! Unfortunately something is still wrong.
> >
> > After the transpose, dvec and Amat are still incompatible.
> >
> > > d <- -hsmooth
> > > dvec <- t(d)
> > > c <- dvec*Amat
> > Error in dvec * Amat : non-conformable arrays
>
> '*' in R is element-wise multiplication and '%*%' implements
> matrix/matrix (matrix/vector) multiplication as defined in matrix
> algebra.  I presume you want to use the latter operator here.
>
> > Moreover, I don't understand the following:
> >
> > > If dvec is of length *J*, then b will be of length J too.
> >
> > I believe the length of dvec comes from the number of variables and
> > the length of b from the number of constraints. In this case they are
> > not equal.
>
> As I said:
>
> > > solve.QP solves the quadratic program:
> > >          min(-d^T b + 1/2 b^T D b)
> > >    where A^T b >= b_0.
>
> The minimisation is with respect to b.
>
> Note that the objective function contains the inner product of d
> (passed to dvec) and b, so d and b must have the same
> dimension/length.  b contains the parameters/variables over which you
> want to minimise.  b_0 (passed to bvec) depends on the number of
> constraints.
>
> Cheers,
>
>         Berwin
>

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jul 30 10:57:34 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 30 Jul 2018 14:27:34 +0530
Subject: [R] dbGetQuery() returns wrong value
Message-ID: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>

Hi,

I used following SQL query to fetch information from DB

> dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and ID =
'72075186224672770' limit 10")
         ID
1 72075186224672768

As you see, it is returning a different result from what actual query
string contains.

However when I used the same query in some other SQL client, I get the
expected result as:

72075186224672770

Any idea on what went wrong in R supplied query would be highly appreciated.

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jul 30 13:00:50 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 30 Jul 2018 16:30:50 +0530
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
Message-ID: <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>

Session Information for above error:

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 16299)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
                 LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
DBI_1.0.0

loaded via a namespace (and not attached):
[1] compiler_3.5.0 tools_3.5.0

On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I used following SQL query to fetch information from DB
>
> > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and ID =
> '72075186224672770' limit 10")
>          ID
> 1 72075186224672768
>
> As you see, it is returning a different result from what actual query
> string contains.
>
> However when I used the same query in some other SQL client, I get the
> expected result as:
>
> 72075186224672770
>
> Any idea on what went wrong in R supplied query would be highly
> appreciated.
>
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Mon Jul 30 13:15:20 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 30 Jul 2018 14:15:20 +0300
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
Message-ID: <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>

The ID matches in the first 16 characters.
How is your table XXXX declared?


On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Session Information for above error:
>
> > sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 16299)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>                  LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
> DBI_1.0.0
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.0 tools_3.5.0
>
> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
> > Hi,
> >
> > I used following SQL query to fetch information from DB
> >
> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and ID
> =
> > '72075186224672770' limit 10")
> >          ID
> > 1 72075186224672768
> >
> > As you see, it is returning a different result from what actual query
> > string contains.
> >
> > However when I used the same query in some other SQL client, I get the
> > expected result as:
> >
> > 72075186224672770
> >
> > Any idea on what went wrong in R supplied query would be highly
> > appreciated.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jul 30 15:06:04 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 30 Jul 2018 18:36:04 +0530
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
 <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
Message-ID: <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>

The data type is defined as bigint

On Mon, Jul 30, 2018 at 4:45 PM Eric Berger <ericjberger at gmail.com> wrote:

> The ID matches in the first 16 characters.
> How is your table XXXX declared?
>
>
> On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Session Information for above error:
>>
>> > sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 16299)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>                  LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
>> DBI_1.0.0
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.5.0 tools_3.5.0
>>
>> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
>> bogaso.christofer at gmail.com> wrote:
>>
>> > Hi,
>> >
>> > I used following SQL query to fetch information from DB
>> >
>> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and
>> ID =
>> > '72075186224672770' limit 10")
>> >          ID
>> > 1 72075186224672768
>> >
>> > As you see, it is returning a different result from what actual query
>> > string contains.
>> >
>> > However when I used the same query in some other SQL client, I get the
>> > expected result as:
>> >
>> > 72075186224672770
>> >
>> > Any idea on what went wrong in R supplied query would be highly
>> > appreciated.
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul 30 16:01:35 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 30 Jul 2018 07:01:35 -0700
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
 <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
 <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
Message-ID: <19B9B899-D2A4-4454-B549-677EB6EE4DC4@dcn.davis.ca.us>

If you have not read [1] already, you should. As to how JDBC handles this issue I don't know, but such a package-specific conversation belongs on r-sig-db.

[1] http://www.win-vector.com/blog/2015/06/r-in-a-64-bit-world/

On July 30, 2018 6:06:04 AM PDT, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>The data type is defined as bigint
>
>On Mon, Jul 30, 2018 at 4:45 PM Eric Berger <ericjberger at gmail.com>
>wrote:
>
>> The ID matches in the first 16 characters.
>> How is your table XXXX declared?
>>
>>
>> On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
>> bogaso.christofer at gmail.com> wrote:
>>
>>> Session Information for above error:
>>>
>>> > sessionInfo()
>>> R version 3.5.0 (2018-04-23)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 16299)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>>                  LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1
>rJava_0.9-10
>>> DBI_1.0.0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.5.0 tools_3.5.0
>>>
>>> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
>>> bogaso.christofer at gmail.com> wrote:
>>>
>>> > Hi,
>>> >
>>> > I used following SQL query to fetch information from DB
>>> >
>>> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18'
>and
>>> ID =
>>> > '72075186224672770' limit 10")
>>> >          ID
>>> > 1 72075186224672768
>>> >
>>> > As you see, it is returning a different result from what actual
>query
>>> > string contains.
>>> >
>>> > However when I used the same query in some other SQL client, I get
>the
>>> > expected result as:
>>> >
>>> > 72075186224672770
>>> >
>>> > Any idea on what went wrong in R supplied query would be highly
>>> > appreciated.
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Mon Jul 30 16:29:05 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Mon, 30 Jul 2018 16:29:05 +0200
Subject: [R] read txt file - date - no space
Message-ID: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>

Dear all,

I am dealing with the reading of a *.txt file.
The txt file the following shape:

103001930 103001580 103001530
1998-10-01 00:00:00 0.6 0 0
1998-10-01 01:00:00 0.2 0.2 0.2
1998-10-01 02:00:00 0.6 0.2 0.4
1998-10-01 03:00:00 0 0 0.6
1998-10-01 04:00:00 0 0 0
1998-10-01 05:00:00 0 0 0
1998-10-01 06:00:00 0 0 0
1998-10-01 07:00:00 0.2 0 0

If it is possible I have a coupe of questions, which will sound stupid but
they are important to me in order to understand ho R deal with file or date.

1) Do I have to convert it to a *csv file?
2) Can a deal with space and not ","
3) How can I read date?

thanks a lot to all of you,
Thanks


Diego

	[[alternative HTML version deleted]]



From ouedr@ogo_@g@the @end|ng |rom y@hoo@|r  Mon Jul 30 17:18:41 2018
From: ouedr@ogo_@g@the @end|ng |rom y@hoo@|r (ouedraogo_agathe)
Date: Mon, 30 Jul 2018 18:18:41 +0300
Subject: [R] Plot Rclimdex or Climpact map with R
Message-ID: <upkhmgcxshy0j7p5hn6y9ykn.1532963921164@email.android.com>

HelloI am using Rclimdex and Climpact packages to compute some indices. Having the location of all my stations I wish to plot the resultats on a map. Is there a way to simply do it from the packages or how to do it for someone who does not master R software?thanks?

Sent from my Samsung Galaxy smartphone.
	[[alternative HTML version deleted]]


From b@un1 @end|ng |rom @tudent@@tow@on@edu  Mon Jul 30 17:24:27 2018
From: b@un1 @end|ng |rom @tudent@@tow@on@edu (Baojun Sun)
Date: Mon, 30 Jul 2018 11:24:27 -0400
Subject: [R] (no subject)
Message-ID: <CAPkQrWK2OyWjLR=aGD+zOiyHtOVReKd+=oY6oXOKD3xYWP1GUw@mail.gmail.com>

The book "Introduction to Statistical Learning" gives R scripts for its
labs. I found a script for ridge regression that works on the dataset the
book uses but is unusable on other datasets I own unless I clean the data.


I'm trying to understand the syntax for I need for data cleaning and am
stuck. I want to learn to do ridge regression. I tried using my own data
set on this script rather than the book example but get errors. If you use
your own data set rather than the Hitters dataset, then you'll get errors
unless you format your code. How do I change this script or clean any
dataset so that this script for ridge regression useable for all datasets?


    library(ISLR)

    fix(Hitters)

    names(Hitters)

    dim(Hitters)

    sum(is.na(Hitters$Salary))

    Hitters=na.omit(Hitters)

    dim(Hitters)

    sum(is.na(Hitters))

    library(leaps)



    x=model.matrix(Salary~.,Hitters)[,-1]

    y=Hitters$Salary



    # Ridge Regression



    library(glmnet)

    grid=10^seq(10,-2,length=100)

    ridge.mod=glmnet(x,y,alpha=0,lambda=grid)

    dim(coef(ridge.mod))

    ridge.mod$lambda[50]

    coef(ridge.mod)[,50]

    sqrt(sum(coef(ridge.mod)[-1,50]^2))

    ridge.mod$lambda[60]

    coef(ridge.mod)[,60]

    sqrt(sum(coef(ridge.mod)[-1,60]^2))

    predict(ridge.mod,s=50,type="coefficients")[1:20,]

    set.seed(1)

    train=sample(1:nrow(x), nrow(x)/2)

    test=(-train)

    y.test=y[test]

    ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)

    ridge.pred=predict(ridge.mod,s=4,newx=x[test,])

    mean((ridge.pred-y.test)^2)

    mean((mean(y[train])-y.test)^2)

    ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])

    mean((ridge.pred-y.test)^2)

    ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)

    mean((ridge.pred-y.test)^2)

    lm(y~x, subset=train)

    predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]

    set.seed(1)

    cv.out=cv.glmnet(x[train,],y[train],alpha=0)

    plot(cv.out)

    bestlam=cv.out$lambda.min

    bestlam

    ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])

    mean((ridge.pred-y.test)^2)

    out=glmnet(x,y,alpha=0)

    predict(out,type="coefficients",s=bestlam)[1:20

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul 30 19:26:27 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 30 Jul 2018 10:26:27 -0700
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
Message-ID: <12F1F8F3-1CE4-4589-B8A3-8A3F2BFEAB99@dcn.davis.ca.us>

1) No. 

2) The read.csv function is a s special case use of the more general read.table function that can handle any simple field separator.

3) Read the data in as character (I recommend using the stringsAsFactors=FALSE argument to read.table) and convert to an appropriate type from that form. e.g. [1]

[1] https://www.r-bloggers.com/using-dates-and-times-in-r/


On July 30, 2018 7:29:05 AM PDT, Diego Avesani <diego.avesani at gmail.com> wrote:
>Dear all,
>
>I am dealing with the reading of a *.txt file.
>The txt file the following shape:
>
>103001930 103001580 103001530
>1998-10-01 00:00:00 0.6 0 0
>1998-10-01 01:00:00 0.2 0.2 0.2
>1998-10-01 02:00:00 0.6 0.2 0.4
>1998-10-01 03:00:00 0 0 0.6
>1998-10-01 04:00:00 0 0 0
>1998-10-01 05:00:00 0 0 0
>1998-10-01 06:00:00 0 0 0
>1998-10-01 07:00:00 0.2 0 0
>
>If it is possible I have a coupe of questions, which will sound stupid
>but
>they are important to me in order to understand ho R deal with file or
>date.
>
>1) Do I have to convert it to a *csv file?
>2) Can a deal with space and not ","
>3) How can I read date?
>
>thanks a lot to all of you,
>Thanks
>
>
>Diego
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From JLucke m@iii@g oii ri@@buii@io@edu  Mon Jul 30 21:14:37 2018
From: JLucke m@iii@g oii ri@@buii@io@edu (JLucke m@iii@g oii ri@@buii@io@edu)
Date: Mon, 30 Jul 2018 15:14:37 -0400
Subject: [R] Unexpected YAML
Message-ID: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>

R Users:

Whenever I fire up R, I now get the following message (red) at the end of 
the prologue.

R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Error in loadNamespace(name) : there is no package called ?yaml?

How do I get rid of it?
Joe

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Jul 30 21:22:35 2018
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 30 Jul 2018 12:22:35 -0700 (PDT)
Subject: [R] Unexpected YAML
In-Reply-To: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
Message-ID: <alpine.LNX.2.20.1807301221330.11651@salmo.appl-ecosys.com>

On Mon, 30 Jul 2018, JLucke at ria.buffalo.edu wrote:

> Error in loadNamespace(name) : there is no package called ?yaml?
> How do I get rid of it?

Joe,

   Easiest way is to install it:

> install.packages("yaml")

Rich



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jul 30 21:27:43 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 30 Jul 2018 20:27:43 +0100
Subject: [R] Unexpected YAML
In-Reply-To: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
Message-ID: <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>

Hello,

Maybe R is loading a previously saved session.
Check whether you have a file named .RData in your working directory.
(This is not a file extension, it's the full filename.)

Hope this helps,

Rui Barradas

?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
> R Users:
> 
> Whenever I fire up R, I now get the following message (red) at the end of
> the prologue.
> 
> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Error in loadNamespace(name) : there is no package called ?yaml?
> 
> How do I get rid of it?
> Joe
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul 30 22:06:12 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 30 Jul 2018 13:06:12 -0700
Subject: [R] (no subject)
In-Reply-To: <CAPkQrWK2OyWjLR=aGD+zOiyHtOVReKd+=oY6oXOKD3xYWP1GUw@mail.gmail.com>
References: <CAPkQrWK2OyWjLR=aGD+zOiyHtOVReKd+=oY6oXOKD3xYWP1GUw@mail.gmail.com>
Message-ID: <CAGxFJbR4Qr6U6tNdL2SNoLNPs=kk7wah8=QZs5V-oLykfqEDJQ@mail.gmail.com>

How can one possibly answer this without knowing the structure of your
dataset?

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jul 30, 2018 at 8:24 AM, Baojun Sun <bsun1 at students.towson.edu>
wrote:

> The book "Introduction to Statistical Learning" gives R scripts for its
> labs. I found a script for ridge regression that works on the dataset the
> book uses but is unusable on other datasets I own unless I clean the data.
>
>
> I'm trying to understand the syntax for I need for data cleaning and am
> stuck. I want to learn to do ridge regression. I tried using my own data
> set on this script rather than the book example but get errors. If you use
> your own data set rather than the Hitters dataset, then you'll get errors
> unless you format your code. How do I change this script or clean any
> dataset so that this script for ridge regression useable for all datasets?
>
>
>     library(ISLR)
>
>     fix(Hitters)
>
>     names(Hitters)
>
>     dim(Hitters)
>
>     sum(is.na(Hitters$Salary))
>
>     Hitters=na.omit(Hitters)
>
>     dim(Hitters)
>
>     sum(is.na(Hitters))
>
>     library(leaps)
>
>
>
>     x=model.matrix(Salary~.,Hitters)[,-1]
>
>     y=Hitters$Salary
>
>
>
>     # Ridge Regression
>
>
>
>     library(glmnet)
>
>     grid=10^seq(10,-2,length=100)
>
>     ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
>
>     dim(coef(ridge.mod))
>
>     ridge.mod$lambda[50]
>
>     coef(ridge.mod)[,50]
>
>     sqrt(sum(coef(ridge.mod)[-1,50]^2))
>
>     ridge.mod$lambda[60]
>
>     coef(ridge.mod)[,60]
>
>     sqrt(sum(coef(ridge.mod)[-1,60]^2))
>
>     predict(ridge.mod,s=50,type="coefficients")[1:20,]
>
>     set.seed(1)
>
>     train=sample(1:nrow(x), nrow(x)/2)
>
>     test=(-train)
>
>     y.test=y[test]
>
>     ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
>
>     ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
>
>     mean((ridge.pred-y.test)^2)
>
>     mean((mean(y[train])-y.test)^2)
>
>     ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
>
>     mean((ridge.pred-y.test)^2)
>
>     ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
>
>     mean((ridge.pred-y.test)^2)
>
>     lm(y~x, subset=train)
>
>     predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
>
>     set.seed(1)
>
>     cv.out=cv.glmnet(x[train,],y[train],alpha=0)
>
>     plot(cv.out)
>
>     bestlam=cv.out$lambda.min
>
>     bestlam
>
>     ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
>
>     mean((ridge.pred-y.test)^2)
>
>     out=glmnet(x,y,alpha=0)
>
>     predict(out,type="coefficients",s=bestlam)[1:20
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Tue Jul 31 01:03:26 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 31 Jul 2018 09:03:26 +1000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
Message-ID: <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>

Hi Diego,
You may have to do some conversion as you have three fields in the
first line using the default space separator and five fields in
subsequent lines. If the first line doesn't contain any important data
you can just delete it or replace it with a meaningful header line
with five fields and save the file under another name.

It looks as thought you have date-time as two fields. If so, you can
just read the first field if you only want the date:

# assume you have removed the first line
dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")

If you want the date/time:

dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d %H:%M:%S")

Jim

On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <diego.avesani at gmail.com> wrote:
> Dear all,
>
> I am dealing with the reading of a *.txt file.
> The txt file the following shape:
>
> 103001930 103001580 103001530
> 1998-10-01 00:00:00 0.6 0 0
> 1998-10-01 01:00:00 0.2 0.2 0.2
> 1998-10-01 02:00:00 0.6 0.2 0.4
> 1998-10-01 03:00:00 0 0 0.6
> 1998-10-01 04:00:00 0 0 0
> 1998-10-01 05:00:00 0 0 0
> 1998-10-01 06:00:00 0 0 0
> 1998-10-01 07:00:00 0.2 0 0
>
> If it is possible I have a coupe of questions, which will sound stupid but
> they are important to me in order to understand ho R deal with file or date.
>
> 1) Do I have to convert it to a *csv file?
> 2) Can a deal with space and not ","
> 3) How can I read date?
>
> thanks a lot to all of you,
> Thanks
>
>
> Diego
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@cqueen1 @end|ng |rom ||n|@gov  Tue Jul 31 01:25:20 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 30 Jul 2018 23:25:20 +0000
Subject: [R] read txt file - date - no space
In-Reply-To: <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
Message-ID: <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>

Or, without removing the first line
  dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)

Another alternative,
   dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
since the dates appear to be in the default format.
(I generally prefer to work with datetimes in POSIXct class rather than POSIXlt class)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon" <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:

    Hi Diego,
    You may have to do some conversion as you have three fields in the
    first line using the default space separator and five fields in
    subsequent lines. If the first line doesn't contain any important data
    you can just delete it or replace it with a meaningful header line
    with five fields and save the file under another name.
    
    It looks as thought you have date-time as two fields. If so, you can
    just read the first field if you only want the date:
    
    # assume you have removed the first line
    dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
    dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
    
    If you want the date/time:
    
    dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d %H:%M:%S")
    
    Jim
    
    On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <diego.avesani at gmail.com> wrote:
    > Dear all,
    >
    > I am dealing with the reading of a *.txt file.
    > The txt file the following shape:
    >
    > 103001930 103001580 103001530
    > 1998-10-01 00:00:00 0.6 0 0
    > 1998-10-01 01:00:00 0.2 0.2 0.2
    > 1998-10-01 02:00:00 0.6 0.2 0.4
    > 1998-10-01 03:00:00 0 0 0.6
    > 1998-10-01 04:00:00 0 0 0
    > 1998-10-01 05:00:00 0 0 0
    > 1998-10-01 06:00:00 0 0 0
    > 1998-10-01 07:00:00 0.2 0 0
    >
    > If it is possible I have a coupe of questions, which will sound stupid but
    > they are important to me in order to understand ho R deal with file or date.
    >
    > 1) Do I have to convert it to a *csv file?
    > 2) Can a deal with space and not ","
    > 3) How can I read date?
    >
    > thanks a lot to all of you,
    > Thanks
    >
    >
    > Diego
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From drj|m|emon @end|ng |rom gm@||@com  Tue Jul 31 01:53:05 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 31 Jul 2018 09:53:05 +1000
Subject: [R] Plot Rclimdex or Climpact map with R
In-Reply-To: <upkhmgcxshy0j7p5hn6y9ykn.1532963921164@email.android.com>
References: <upkhmgcxshy0j7p5hn6y9ykn.1532963921164@email.android.com>
Message-ID: <CA+8X3fU0QaQcifOV_uQFyaCx5twoPnBGr6xoB45nKVj_9A=7KQ@mail.gmail.com>

Hi Agathe,
You can start with the "maps" package:

# in an R session
install.packages("maps")
# assume you want a simple map containing France
map("world",xlim=c(-6.0,9.6),ylim=c(42,51.5))

then plot your data by the coordinates of the stations. You will
probably want to plot graphical elements to represent your data
values. There are a number of ways to represent more than one value at
a point with various combinations of shape, size, color and so on.
Perhaps with more information about what you want to display I could
be more specific.

Jim


On Tue, Jul 31, 2018 at 1:18 AM, ouedraogo_agathe via R-help
<r-help at r-project.org> wrote:
> HelloI am using Rclimdex and Climpact packages to compute some indices. Having the location of all my stations I wish to plot the resultats on a map. Is there a way to simply do it from the packages or how to do it for someone who does not master R software?thanks
>
> Sent from my Samsung Galaxy smartphone.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From ouedr@ogo_@g@the @end|ng |rom y@hoo@|r  Tue Jul 31 02:23:20 2018
From: ouedr@ogo_@g@the @end|ng |rom y@hoo@|r (ouedraogo_agathe)
Date: Tue, 31 Jul 2018 03:23:20 +0300
Subject: [R] Plot Rclimdex or Climpact map with R
Message-ID: <1wg35pn68k6w4slah2s1j80j.1532996600836@email.android.com>

For example the packages compute some indices let's say total precipitation (annua). So i ll have for each station a table representing annual totals with the trend slope. So i would like to put them on a map ( a county in Kenya) so that i can easily see the trend spatially.



Sent from my Samsung Galaxy smartphone.
-------- Original message --------From: Jim Lemon <drjimlemon at gmail.com> Date: 7/31/18  02:53  (GMT+03:00) To: ouedraogo_agathe <ouedraogo_agathe at yahoo.fr> Cc: r-help mailing list <r-help at r-project.org> Subject: Re: [R] Plot Rclimdex or Climpact map with R 
Hi Agathe,
You can start with the "maps" package:

# in an R session
install.packages("maps")
# assume you want a simple map containing France
map("world",xlim=c(-6.0,9.6),ylim=c(42,51.5))

then plot your data by the coordinates of the stations. You will
probably want to plot graphical elements to represent your data
values. There are a number of ways to represent more than one value at
a point with various combinations of shape, size, color and so on.
Perhaps with more information about what you want to display I could
be more specific.

Jim


On Tue, Jul 31, 2018 at 1:18 AM, ouedraogo_agathe via R-help
<r-help at r-project.org> wrote:
> HelloI am using Rclimdex and Climpact packages to compute some indices. Having the location of all my stations I wish to plot the resultats on a map. Is there a way to simply do it from the packages or how to do it for someone who does not master R software?thanks
>
> Sent from my Samsung Galaxy smartphone.
>???????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Tue Jul 31 10:28:07 2018
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Tue, 31 Jul 2018 10:28:07 +0200
Subject: [R] dbGetQuery() returns wrong value
In-Reply-To: <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
References: <CA+dpOJ=O-aB-Ns-YUO2bd68zr1roxVNEBCHN=HAg82fS2uz80g@mail.gmail.com>
 <CA+dpOJkazs8wQ7D6hQHYGCUChMsC+8FVKYnUPvtnyT1dPZ3iVA@mail.gmail.com>
 <CAGgJW74pu76tb3wzcO+dHZmE3fnbQSXsabnZ2GpRF8-5hGYo+g@mail.gmail.com>
 <CA+dpOJkAvUxA1pyvAo4iF1qFLaHp6Fj83WwNhNR6aaW8yjz8xw@mail.gmail.com>
Message-ID: <20180731102807.Horde.iMVRHzTAmrtI4QNEuPpEoVT@webmail.your-server.de>


Quoting Christofer Bogaso <bogaso.christofer at gmail.com>:

> The data type is defined as bigint

Your query does not specify a number, but a string
(you single-quote the digits). Databases may do type conversion;
for instance, see the MySQL manual:  
https://dev.mysql.com/doc/refman/8.0/en/type-conversion.html

Since you send the query as a string anyway, there may be no need
for a "'string' within a string".

Please note that I have Cc'ed <r-sig-db at r-project.org>. Any follow-up
should probably go to that mailing list.


>
> On Mon, Jul 30, 2018 at 4:45 PM Eric Berger <ericjberger at gmail.com> wrote:
>
>> The ID matches in the first 16 characters.
>> How is your table XXXX declared?
>>
>>
>> On Mon, Jul 30, 2018 at 2:00 PM, Christofer Bogaso <
>> bogaso.christofer at gmail.com> wrote:
>>
>>> Session Information for above error:
>>>
>>> > sessionInfo()
>>> R version 3.5.0 (2018-04-23)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 16299)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252    LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>>                  LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] csvread_1.2   bit64_0.9-7   bit_1.1-14    RJDBC_0.2-7.1 rJava_0.9-10
>>> DBI_1.0.0
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.5.0 tools_3.5.0
>>>
>>> On Mon, Jul 30, 2018 at 2:27 PM Christofer Bogaso <
>>> bogaso.christofer at gmail.com> wrote:
>>>
>>> > Hi,
>>> >
>>> > I used following SQL query to fetch information from DB
>>> >
>>> > > dbGetQuery(Conn, "select ID from XXXX where date = '2018-07-18' and
>>> ID =
>>> > '72075186224672770' limit 10")
>>> >          ID
>>> > 1 72075186224672768
>>> >
>>> > As you see, it is returning a different result from what actual query
>>> > string contains.
>>> >
>>> > However when I used the same query in some other SQL client, I get the
>>> > expected result as:
>>> >
>>> > 72075186224672770
>>> >
>>> > Any idea on what went wrong in R supplied query would be highly
>>> > appreciated.
>>> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net



From drj|m|emon @end|ng |rom gm@||@com  Tue Jul 31 11:02:20 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 31 Jul 2018 19:02:20 +1000
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
Message-ID: <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>

Hi Diego,
One way you can get daily means is:

st1_daily<-by(MyData$st1,MyData$date,mean)
st2_daily<-by(MyData$st2,MyData$date,mean)
st3_daily<-by(MyData$st3,MyData$date,mean)

Jim

On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com> wrote:
> Dear all,
> I have found the error, my fault. Sorry.
> There was an extra come in the headers line.
> Thanks again.
>
> If I can I would like to ask you another questions about the imported data.
> I would like to compute the daily average of the different date. Basically I
> have hourly data, I would like to ave the daily mean of them.
>
> Is there some special commands?
>
> Thanks a lot.
>
>
> Diego
>
>
> On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com> wrote:
>>
>> Dear all,
>> I move to csv file because originally the date where in csv file.
>> In addition, due to the fact that, as you told me, read.csv is a special
>> case of read.table, I prefer start to learn from the simplest one.
>> After that, I will try also the *.txt format.
>>
>> with read.csv, something strange happened:
>>
>> This us now the file:
>>
>> date,st1,st2,st3,
>> 10/1/1998 0:00,0.6,0,0
>> 10/1/1998 1:00,0.2,0.2,0.2
>> 10/1/1998 2:00,0.6,0.2,0.4
>> 10/1/1998 3:00,0,0,0.6
>> 10/1/1998 4:00,0,0,0
>> 10/1/1998 5:00,0,0,0
>> 10/1/1998 6:00,0,0,0
>> 10/1/1998 7:00,0.2,0,0
>> 10/1/1998 8:00,0.6,0.2,0
>> 10/1/1998 9:00,0.2,0.4,0.4
>> 10/1/1998 10:00,0,0.4,0.2
>>
>> When I apply:
>> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>>
>> this is the results:
>>
>> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>>
>> I do not understand why.
>> Something wrong with date?
>>
>> really really thanks,
>> I appreciate a lot all your helps.
>>
>> Diedro
>>
>>
>> Diego
>>
>>
>> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>>>
>>> Or, without removing the first line
>>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>>
>>> Another alternative,
>>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>>> since the dates appear to be in the default format.
>>> (I generally prefer to work with datetimes in POSIXct class rather than
>>> POSIXlt class)
>>>
>>> -Don
>>>
>>> --
>>> Don MacQueen
>>> Lawrence Livermore National Laboratory
>>> 7000 East Ave., L-627
>>> Livermore, CA 94550
>>> 925-423-1062
>>> Lab cell 925-724-7509
>>>
>>>
>>>
>>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:
>>>
>>>     Hi Diego,
>>>     You may have to do some conversion as you have three fields in the
>>>     first line using the default space separator and five fields in
>>>     subsequent lines. If the first line doesn't contain any important
>>> data
>>>     you can just delete it or replace it with a meaningful header line
>>>     with five fields and save the file under another name.
>>>
>>>     It looks as thought you have date-time as two fields. If so, you can
>>>     just read the first field if you only want the date:
>>>
>>>     # assume you have removed the first line
>>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>>
>>>     If you want the date/time:
>>>
>>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>>> %H:%M:%S")
>>>
>>>     Jim
>>>
>>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>>> <diego.avesani at gmail.com> wrote:
>>>     > Dear all,
>>>     >
>>>     > I am dealing with the reading of a *.txt file.
>>>     > The txt file the following shape:
>>>     >
>>>     > 103001930 103001580 103001530
>>>     > 1998-10-01 00:00:00 0.6 0 0
>>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>>     > 1998-10-01 03:00:00 0 0 0.6
>>>     > 1998-10-01 04:00:00 0 0 0
>>>     > 1998-10-01 05:00:00 0 0 0
>>>     > 1998-10-01 06:00:00 0 0 0
>>>     > 1998-10-01 07:00:00 0.2 0 0
>>>     >
>>>     > If it is possible I have a coupe of questions, which will sound
>>> stupid but
>>>     > they are important to me in order to understand ho R deal with file
>>> or date.
>>>     >
>>>     > 1) Do I have to convert it to a *csv file?
>>>     > 2) Can a deal with space and not ","
>>>     > 3) How can I read date?
>>>     >
>>>     > thanks a lot to all of you,
>>>     > Thanks
>>>     >
>>>     >
>>>     > Diego
>>>     >
>>>     >         [[alternative HTML version deleted]]
>>>     >
>>>     > ______________________________________________
>>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>>     > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>     > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>     ______________________________________________
>>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>     PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>     and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>



From r@|ner_krug @end|ng |rom |c|oud@com  Tue Jul 31 09:02:25 2018
From: r@|ner_krug @end|ng |rom |c|oud@com (Rainer Krug)
Date: Tue, 31 Jul 2018 09:02:25 +0200
Subject: [R] Unexpected YAML
In-Reply-To: <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
 <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
Message-ID: <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>

.RData does not save any info abut previously loaded packages - so this would not cause the problem.

Rainer



> On 30 Jul 2018, at 21:27, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Maybe R is loading a previously saved session.
> Check whether you have a file named .RData in your working directory.
> (This is not a file extension, it's the full filename.)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
>> R Users:
>> Whenever I fire up R, I now get the following message (red) at the end of
>> the prologue.
>> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>> Error in loadNamespace(name) : there is no package called ?yaml?
>> How do I get rid of it?
>> Joe
>> 	[[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

University of Z?rich

Cell:       +41 (0)78 630 66 57
email:      Rainer at krugs.de
Skype:      RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]



From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jul 31 12:39:39 2018
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 31 Jul 2018 10:39:39 +0000
Subject: [R] Unexpected YAML
In-Reply-To: <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
 <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
 <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>
Message-ID: <627ab499c8954887b960faa73a76fa6f@SRVEXCHCM1302.precheza.cz>

Hi

However if in .RData is an object created by "yaml" and the package is not loaded it could cause this message. It was similar with ggplot objects if ggplot2 is not loaded.

Removing this object and saving session to update .RData can help.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rainer Krug via R-
> help
> Sent: Tuesday, July 31, 2018 9:02 AM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: r-help at r-project.org
> Subject: Re: [R] Unexpected YAML
>
> .RData does not save any info abut previously loaded packages - so this would
> not cause the problem.
>
> Rainer
>
>
>
> > On 30 Jul 2018, at 21:27, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Maybe R is loading a previously saved session.
> > Check whether you have a file named .RData in your working directory.
> > (This is not a file extension, it's the full filename.)
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
> >> R Users:
> >> Whenever I fire up R, I now get the following message (red) at the
> >> end of the prologue.
> >> R version 3.5.1 (2018-07-02) -- "Feather Spray"
> >> Copyright (C) 2018 The R Foundation for Statistical Computing
> >> Platform: x86_64-w64-mingw32/x64 (64-bit) R is free software and
> >> comes with ABSOLUTELY NO WARRANTY.
> >> You are welcome to redistribute it under certain conditions.
> >> Type 'license()' or 'licence()' for distribution details.
> >> R is a collaborative project with many contributors.
> >> Type 'contributors()' for more information and 'citation()' on how to
> >> cite R or R packages in publications.
> >> Type 'demo()' for some demos, 'help()' for on-line help, or
> >> 'help.start()' for an HTML browser interface to help.
> >> Type 'q()' to quit R.
> >> Error in loadNamespace(name) : there is no package called ?yaml?
> >> How do I get rid of it?
> >> Joe
> >> [[alternative HTML version deleted]]
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology,
> UCT), Dipl. Phys. (Germany)
>
> University of Z?rich
>
> Cell:       +41 (0)78 630 66 57
> email:      Rainer at krugs.de
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul 31 17:19:28 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 31 Jul 2018 08:19:28 -0700
Subject: [R] Unexpected YAML
In-Reply-To: <627ab499c8954887b960faa73a76fa6f@SRVEXCHCM1302.precheza.cz>
References: <OFDDE8362F.CABBCFB4-ON852582DA.006972F3-852582DA.0069B50E@ria.buffalo.edu>
 <dab4ba13-33d3-0a56-36b9-3d0a08ad0931@sapo.pt>
 <3E2C1ADD-AE71-4960-9D11-25E00AE0D113@icloud.com>
 <627ab499c8954887b960faa73a76fa6f@SRVEXCHCM1302.precheza.cz>
Message-ID: <D0BDC228-BDBA-4102-A1B7-2AD8243F0644@dcn.davis.ca.us>

... or deleting .RData and avoiding creating them in the future. Named save files (anything.RData) are useful but the autoload feature of .RData files is not and this particular behavior is one of the reasons why.

On July 31, 2018 3:39:39 AM PDT, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi
>
>However if in .RData is an object created by "yaml" and the package is
>not loaded it could cause this message. It was similar with ggplot
>objects if ggplot2 is not loaded.
>
>Removing this object and saving session to update .RData can help.
>
>Cheers
>Petr
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rainer Krug
>via R-
>> help
>> Sent: Tuesday, July 31, 2018 9:02 AM
>> To: Rui Barradas <ruipbarradas at sapo.pt>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Unexpected YAML
>>
>> .RData does not save any info abut previously loaded packages - so
>this would
>> not cause the problem.
>>
>> Rainer
>>
>>
>>
>> > On 30 Jul 2018, at 21:27, Rui Barradas <ruipbarradas at sapo.pt>
>wrote:
>> >
>> > Hello,
>> >
>> > Maybe R is loading a previously saved session.
>> > Check whether you have a file named .RData in your working
>directory.
>> > (This is not a file extension, it's the full filename.)
>> >
>> > Hope this helps,
>> >
>> > Rui Barradas
>> >
>> > ?s 20:14 de 30-07-2018, JLucke at ria.buffalo.edu escreveu:
>> >> R Users:
>> >> Whenever I fire up R, I now get the following message (red) at the
>> >> end of the prologue.
>> >> R version 3.5.1 (2018-07-02) -- "Feather Spray"
>> >> Copyright (C) 2018 The R Foundation for Statistical Computing
>> >> Platform: x86_64-w64-mingw32/x64 (64-bit) R is free software and
>> >> comes with ABSOLUTELY NO WARRANTY.
>> >> You are welcome to redistribute it under certain conditions.
>> >> Type 'license()' or 'licence()' for distribution details.
>> >> R is a collaborative project with many contributors.
>> >> Type 'contributors()' for more information and 'citation()' on how
>to
>> >> cite R or R packages in publications.
>> >> Type 'demo()' for some demos, 'help()' for on-line help, or
>> >> 'help.start()' for an HTML browser interface to help.
>> >> Type 'q()' to quit R.
>> >> Error in loadNamespace(name) : there is no package called ?yaml?
>> >> How do I get rid of it?
>> >> Joe
>> >> [[alternative HTML version deleted]]
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
>Biology,
>> UCT), Dipl. Phys. (Germany)
>>
>> University of Z?rich
>>
>> Cell:       +41 (0)78 630 66 57
>> email:      Rainer at krugs.de
>> Skype:      RMkrug
>>
>> PGP: 0x0F52F982
>>
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj?
>obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na:
>https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
>about processing and protection of business partner?s personal data are
>available on website:
>https://www.precheza.cz/en/personal-data-protection-principles/
>D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
>d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
>odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
>documents attached to it may be confidential and are subject to the
>legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Tue Jul 31 10:40:52 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Tue, 31 Jul 2018 10:40:52 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
Message-ID: <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>

Dear all,
I move to csv file because originally the date where in csv file.
In addition, due to the fact that, as you told me, read.csv is a special
case of read.table, I prefer start to learn from the simplest one.
After that, I will try also the *.txt format.

with read.csv, something strange happened:

This us now the file:

date,st1,st2,st3,
10/1/1998 0:00,0.6,0,0
10/1/1998 1:00,0.2,0.2,0.2
10/1/1998 2:00,0.6,0.2,0.4
10/1/1998 3:00,0,0,0.6
10/1/1998 4:00,0,0,0
10/1/1998 5:00,0,0,0
10/1/1998 6:00,0,0,0
10/1/1998 7:00,0.2,0,0
10/1/1998 8:00,0.6,0.2,0
10/1/1998 9:00,0.2,0.4,0.4
10/1/1998 10:00,0,0.4,0.2

When I apply:
MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")

this is the results:

10/1/1998 0:00    0.6    0.00    0.0 NA
2        10/1/1998 1:00    0.2    0.20    0.2 NA
3        10/1/1998 2:00    0.6    0.20    0.4 NA
4        10/1/1998 3:00    0.0    0.00    0.6 NA
5        10/1/1998 4:00    0.0    0.00    0.0 NA
6        10/1/1998 5:00    0.0    0.00    0.0 NA
7        10/1/1998 6:00    0.0    0.00    0.0 NA
8        10/1/1998 7:00    0.2    0.00    0.0 NA

I do not understand why.
Something wrong with date?

really really thanks,
I appreciate a lot all your helps.

Diedro


Diego


On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Or, without removing the first line
>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>
> Another alternative,
>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> since the dates appear to be in the default format.
> (I generally prefer to work with datetimes in POSIXct class rather than
> POSIXlt class)
>
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon" <
> r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:
>
>     Hi Diego,
>     You may have to do some conversion as you have three fields in the
>     first line using the default space separator and five fields in
>     subsequent lines. If the first line doesn't contain any important data
>     you can just delete it or replace it with a meaningful header line
>     with five fields and save the file under another name.
>
>     It looks as thought you have date-time as two fields. If so, you can
>     just read the first field if you only want the date:
>
>     # assume you have removed the first line
>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>
>     If you want the date/time:
>
>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> %H:%M:%S")
>
>     Jim
>
>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <
> diego.avesani at gmail.com> wrote:
>     > Dear all,
>     >
>     > I am dealing with the reading of a *.txt file.
>     > The txt file the following shape:
>     >
>     > 103001930 103001580 103001530
>     > 1998-10-01 00:00:00 0.6 0 0
>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>     > 1998-10-01 03:00:00 0 0 0.6
>     > 1998-10-01 04:00:00 0 0 0
>     > 1998-10-01 05:00:00 0 0 0
>     > 1998-10-01 06:00:00 0 0 0
>     > 1998-10-01 07:00:00 0.2 0 0
>     >
>     > If it is possible I have a coupe of questions, which will sound
> stupid but
>     > they are important to me in order to understand ho R deal with file
> or date.
>     >
>     > 1) Do I have to convert it to a *csv file?
>     > 2) Can a deal with space and not ","
>     > 3) How can I read date?
>     >
>     > thanks a lot to all of you,
>     > Thanks
>     >
>     >
>     > Diego
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Tue Jul 31 10:51:27 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Tue, 31 Jul 2018 10:51:27 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
Message-ID: <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>

Dear all,
I have found the error, my fault. Sorry.
There was an extra come in the headers line.
Thanks again.

If I can I would like to ask you another questions about the imported data.
I would like to compute the daily average of the different date. Basically
I have hourly data, I would like to ave the daily mean of them.

Is there some special commands?

Thanks a lot.


Diego


On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear all,
> I move to csv file because originally the date where in csv file.
> In addition, due to the fact that, as you told me, read.csv is a special
> case of read.table, I prefer start to learn from the simplest one.
> After that, I will try also the *.txt format.
>
> with read.csv, something strange happened:
>
> This us now the file:
>
> date,st1,st2,st3,
> 10/1/1998 0:00,0.6,0,0
> 10/1/1998 1:00,0.2,0.2,0.2
> 10/1/1998 2:00,0.6,0.2,0.4
> 10/1/1998 3:00,0,0,0.6
> 10/1/1998 4:00,0,0,0
> 10/1/1998 5:00,0,0,0
> 10/1/1998 6:00,0,0,0
> 10/1/1998 7:00,0.2,0,0
> 10/1/1998 8:00,0.6,0.2,0
> 10/1/1998 9:00,0.2,0.4,0.4
> 10/1/1998 10:00,0,0.4,0.2
>
> When I apply:
> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>
> this is the results:
>
> 10/1/1998 0:00    0.6    0.00    0.0 NA
> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>
> I do not understand why.
> Something wrong with date?
>
> really really thanks,
> I appreciate a lot all your helps.
>
> Diedro
>
>
> Diego
>
>
> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
>> Or, without removing the first line
>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>>
>> Another alternative,
>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> since the dates appear to be in the default format.
>> (I generally prefer to work with datetimes in POSIXct class rather than
>> POSIXlt class)
>>
>> -Don
>>
>> --
>> Don MacQueen
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>> Lab cell 925-724-7509
>>
>>
>>
>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon" <
>> r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com> wrote:
>>
>>     Hi Diego,
>>     You may have to do some conversion as you have three fields in the
>>     first line using the default space separator and five fields in
>>     subsequent lines. If the first line doesn't contain any important data
>>     you can just delete it or replace it with a meaningful header line
>>     with five fields and save the file under another name.
>>
>>     It looks as thought you have date-time as two fields. If so, you can
>>     just read the first field if you only want the date:
>>
>>     # assume you have removed the first line
>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>>
>>     If you want the date/time:
>>
>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> %H:%M:%S")
>>
>>     Jim
>>
>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani <
>> diego.avesani at gmail.com> wrote:
>>     > Dear all,
>>     >
>>     > I am dealing with the reading of a *.txt file.
>>     > The txt file the following shape:
>>     >
>>     > 103001930 103001580 103001530
>>     > 1998-10-01 00:00:00 0.6 0 0
>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>>     > 1998-10-01 03:00:00 0 0 0.6
>>     > 1998-10-01 04:00:00 0 0 0
>>     > 1998-10-01 05:00:00 0 0 0
>>     > 1998-10-01 06:00:00 0 0 0
>>     > 1998-10-01 07:00:00 0.2 0 0
>>     >
>>     > If it is possible I have a coupe of questions, which will sound
>> stupid but
>>     > they are important to me in order to understand ho R deal with file
>> or date.
>>     >
>>     > 1) Do I have to convert it to a *csv file?
>>     > 2) Can a deal with space and not ","
>>     > 3) How can I read date?
>>     >
>>     > thanks a lot to all of you,
>>     > Thanks
>>     >
>>     >
>>     > Diego
>>     >
>>     >         [[alternative HTML version deleted]]
>>     >
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>>
>>     ______________________________________________
>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>

	[[alternative HTML version deleted]]



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Tue Jul 31 11:12:17 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Tue, 31 Jul 2018 11:12:17 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
Message-ID: <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>

Dear Jim, Dear all,

thanks a lot.

Unfortunately, I get the following error:


 st1_daily<-by(MyData$st1,MyData$date,mean)Error in
tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L, 925L,  :
  arguments must have same length


This is particularly strange. indeed, if I apply


mean(MyData$str1,na.rm=TRUE)


it works


Sorry, I have to learn a lot.
You are really boosting me

Diego


On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Diego,
> One way you can get daily means is:
>
> st1_daily<-by(MyData$st1,MyData$date,mean)
> st2_daily<-by(MyData$st2,MyData$date,mean)
> st3_daily<-by(MyData$st3,MyData$date,mean)
>
> Jim
>
> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com>
> wrote:
> > Dear all,
> > I have found the error, my fault. Sorry.
> > There was an extra come in the headers line.
> > Thanks again.
> >
> > If I can I would like to ask you another questions about the imported
> data.
> > I would like to compute the daily average of the different date.
> Basically I
> > have hourly data, I would like to ave the daily mean of them.
> >
> > Is there some special commands?
> >
> > Thanks a lot.
> >
> >
> > Diego
> >
> >
> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com> wrote:
> >>
> >> Dear all,
> >> I move to csv file because originally the date where in csv file.
> >> In addition, due to the fact that, as you told me, read.csv is a special
> >> case of read.table, I prefer start to learn from the simplest one.
> >> After that, I will try also the *.txt format.
> >>
> >> with read.csv, something strange happened:
> >>
> >> This us now the file:
> >>
> >> date,st1,st2,st3,
> >> 10/1/1998 0:00,0.6,0,0
> >> 10/1/1998 1:00,0.2,0.2,0.2
> >> 10/1/1998 2:00,0.6,0.2,0.4
> >> 10/1/1998 3:00,0,0,0.6
> >> 10/1/1998 4:00,0,0,0
> >> 10/1/1998 5:00,0,0,0
> >> 10/1/1998 6:00,0,0,0
> >> 10/1/1998 7:00,0.2,0,0
> >> 10/1/1998 8:00,0.6,0.2,0
> >> 10/1/1998 9:00,0.2,0.4,0.4
> >> 10/1/1998 10:00,0,0.4,0.2
> >>
> >> When I apply:
> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
> >>
> >> this is the results:
> >>
> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
> >>
> >> I do not understand why.
> >> Something wrong with date?
> >>
> >> really really thanks,
> >> I appreciate a lot all your helps.
> >>
> >> Diedro
> >>
> >>
> >> Diego
> >>
> >>
> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
> >>>
> >>> Or, without removing the first line
> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
> >>>
> >>> Another alternative,
> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
> >>> since the dates appear to be in the default format.
> >>> (I generally prefer to work with datetimes in POSIXct class rather than
> >>> POSIXlt class)
> >>>
> >>> -Don
> >>>
> >>> --
> >>> Don MacQueen
> >>> Lawrence Livermore National Laboratory
> >>> 7000 East Ave., L-627
> >>> Livermore, CA 94550
> >>> 925-423-1062
> >>> Lab cell 925-724-7509
> >>>
> >>>
> >>>
> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
> >>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com>
> wrote:
> >>>
> >>>     Hi Diego,
> >>>     You may have to do some conversion as you have three fields in the
> >>>     first line using the default space separator and five fields in
> >>>     subsequent lines. If the first line doesn't contain any important
> >>> data
> >>>     you can just delete it or replace it with a meaningful header line
> >>>     with five fields and save the file under another name.
> >>>
> >>>     It looks as thought you have date-time as two fields. If so, you
> can
> >>>     just read the first field if you only want the date:
> >>>
> >>>     # assume you have removed the first line
> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
> >>>
> >>>     If you want the date/time:
> >>>
> >>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
> >>> %H:%M:%S")
> >>>
> >>>     Jim
> >>>
> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
> >>> <diego.avesani at gmail.com> wrote:
> >>>     > Dear all,
> >>>     >
> >>>     > I am dealing with the reading of a *.txt file.
> >>>     > The txt file the following shape:
> >>>     >
> >>>     > 103001930 103001580 103001530
> >>>     > 1998-10-01 00:00:00 0.6 0 0
> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
> >>>     > 1998-10-01 03:00:00 0 0 0.6
> >>>     > 1998-10-01 04:00:00 0 0 0
> >>>     > 1998-10-01 05:00:00 0 0 0
> >>>     > 1998-10-01 06:00:00 0 0 0
> >>>     > 1998-10-01 07:00:00 0.2 0 0
> >>>     >
> >>>     > If it is possible I have a coupe of questions, which will sound
> >>> stupid but
> >>>     > they are important to me in order to understand ho R deal with
> file
> >>> or date.
> >>>     >
> >>>     > 1) Do I have to convert it to a *csv file?
> >>>     > 2) Can a deal with space and not ","
> >>>     > 3) How can I read date?
> >>>     >
> >>>     > thanks a lot to all of you,
> >>>     > Thanks
> >>>     >
> >>>     >
> >>>     > Diego
> >>>     >
> >>>     >         [[alternative HTML version deleted]]
> >>>     >
> >>>     > ______________________________________________
> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
> >>>     > PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>     > and provide commented, minimal, self-contained, reproducible
> code.
> >>>
> >>>     ______________________________________________
> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
> >>>     PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>     and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>
> >
>

	[[alternative HTML version deleted]]



From d|ego@@ve@@n| @end|ng |rom gm@||@com  Tue Jul 31 15:11:33 2018
From: d|ego@@ve@@n| @end|ng |rom gm@||@com (Diego Avesani)
Date: Tue, 31 Jul 2018 15:11:33 +0200
Subject: [R] read txt file - date - no space
In-Reply-To: <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
References: <CAG8o1y7W+DJfLSUU9fSqprKuZh+RVM4MOGirAPNX38Ma3-p7fw@mail.gmail.com>
 <CA+8X3fVMi2TXRM2MkigC7FmgCq3GgP576ja+_1=so-ZLUkFJhg@mail.gmail.com>
 <BBA5C0CD-A2AF-4EB8-A09F-DBEBB57E99D5@llnl.gov>
 <CAG8o1y670=rUnihVRNFLS4fjjfBF=41pH-z3MS8o7SdsvXVYLw@mail.gmail.com>
 <CAG8o1y4-JHLg0fr9fRZvYq8Oi_AciL-ZU=mKs39UMejXVL_x+A@mail.gmail.com>
 <CA+8X3fVqQPDjiBk=ggMzcvrO5bD7+aKsb8t4xJ+fMo8dBWYTMw@mail.gmail.com>
 <CAG8o1y69gmUYsohAyLovHqw3zbUN4ZFjacDXfse+qQpfz+2XKw@mail.gmail.com>
Message-ID: <CAG8o1y6HBs=UndD8_fJq4bA5SzbFv0E4a=2iVk0smuN5jtbYgg@mail.gmail.com>

Dear all,

I have still problem with date.
Could you please tel me how to use POSIXct.
Indeed I have found this command:
timeAverage, but I am not able to convert MyDate to properly date.

Thank a lot
I hope to no bother you, at least too much


Diego


On 31 July 2018 at 11:12, Diego Avesani <diego.avesani at gmail.com> wrote:

> Dear Jim, Dear all,
>
> thanks a lot.
>
> Unfortunately, I get the following error:
>
>
>  st1_daily<-by(MyData$st1,MyData$date,mean)Error in tapply(seq_len(0L), list(`MyData$date` = c(913L, 914L, 925L,  :
>   arguments must have same length
>
>
> This is particularly strange. indeed, if I apply
>
>
> mean(MyData$str1,na.rm=TRUE)
>
>
> it works
>
>
> Sorry, I have to learn a lot.
> You are really boosting me
>
> Diego
>
>
> On 31 July 2018 at 11:02, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Diego,
>> One way you can get daily means is:
>>
>> st1_daily<-by(MyData$st1,MyData$date,mean)
>> st2_daily<-by(MyData$st2,MyData$date,mean)
>> st3_daily<-by(MyData$st3,MyData$date,mean)
>>
>> Jim
>>
>> On Tue, Jul 31, 2018 at 6:51 PM, Diego Avesani <diego.avesani at gmail.com>
>> wrote:
>> > Dear all,
>> > I have found the error, my fault. Sorry.
>> > There was an extra come in the headers line.
>> > Thanks again.
>> >
>> > If I can I would like to ask you another questions about the imported
>> data.
>> > I would like to compute the daily average of the different date.
>> Basically I
>> > have hourly data, I would like to ave the daily mean of them.
>> >
>> > Is there some special commands?
>> >
>> > Thanks a lot.
>> >
>> >
>> > Diego
>> >
>> >
>> > On 31 July 2018 at 10:40, Diego Avesani <diego.avesani at gmail.com>
>> wrote:
>> >>
>> >> Dear all,
>> >> I move to csv file because originally the date where in csv file.
>> >> In addition, due to the fact that, as you told me, read.csv is a
>> special
>> >> case of read.table, I prefer start to learn from the simplest one.
>> >> After that, I will try also the *.txt format.
>> >>
>> >> with read.csv, something strange happened:
>> >>
>> >> This us now the file:
>> >>
>> >> date,st1,st2,st3,
>> >> 10/1/1998 0:00,0.6,0,0
>> >> 10/1/1998 1:00,0.2,0.2,0.2
>> >> 10/1/1998 2:00,0.6,0.2,0.4
>> >> 10/1/1998 3:00,0,0,0.6
>> >> 10/1/1998 4:00,0,0,0
>> >> 10/1/1998 5:00,0,0,0
>> >> 10/1/1998 6:00,0,0,0
>> >> 10/1/1998 7:00,0.2,0,0
>> >> 10/1/1998 8:00,0.6,0.2,0
>> >> 10/1/1998 9:00,0.2,0.4,0.4
>> >> 10/1/1998 10:00,0,0.4,0.2
>> >>
>> >> When I apply:
>> >> MyData <- read.csv(file="obs_prec.csv",header=TRUE, sep=",")
>> >>
>> >> this is the results:
>> >>
>> >> 10/1/1998 0:00    0.6    0.00    0.0 NA
>> >> 2        10/1/1998 1:00    0.2    0.20    0.2 NA
>> >> 3        10/1/1998 2:00    0.6    0.20    0.4 NA
>> >> 4        10/1/1998 3:00    0.0    0.00    0.6 NA
>> >> 5        10/1/1998 4:00    0.0    0.00    0.0 NA
>> >> 6        10/1/1998 5:00    0.0    0.00    0.0 NA
>> >> 7        10/1/1998 6:00    0.0    0.00    0.0 NA
>> >> 8        10/1/1998 7:00    0.2    0.00    0.0 NA
>> >>
>> >> I do not understand why.
>> >> Something wrong with date?
>> >>
>> >> really really thanks,
>> >> I appreciate a lot all your helps.
>> >>
>> >> Diedro
>> >>
>> >>
>> >> Diego
>> >>
>> >>
>> >> On 31 July 2018 at 01:25, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>> >>>
>> >>> Or, without removing the first line
>> >>>   dadf <- read.table("xxx.txt", stringsAsFactors=FALSE, skip=1)
>> >>>
>> >>> Another alternative,
>> >>>    dadf$datetime <- as.POSIXct(paste(dadf$V1,dadf$V2))
>> >>> since the dates appear to be in the default format.
>> >>> (I generally prefer to work with datetimes in POSIXct class rather
>> than
>> >>> POSIXlt class)
>> >>>
>> >>> -Don
>> >>>
>> >>> --
>> >>> Don MacQueen
>> >>> Lawrence Livermore National Laboratory
>> >>> 7000 East Ave., L-627
>> >>> Livermore, CA 94550
>> >>> 925-423-1062
>> >>> Lab cell 925-724-7509
>> >>>
>> >>>
>> >>>
>> >>> ?On 7/30/18, 4:03 PM, "R-help on behalf of Jim Lemon"
>> >>> <r-help-bounces at r-project.org on behalf of drjimlemon at gmail.com>
>> wrote:
>> >>>
>> >>>     Hi Diego,
>> >>>     You may have to do some conversion as you have three fields in the
>> >>>     first line using the default space separator and five fields in
>> >>>     subsequent lines. If the first line doesn't contain any important
>> >>> data
>> >>>     you can just delete it or replace it with a meaningful header line
>> >>>     with five fields and save the file under another name.
>> >>>
>> >>>     It looks as thought you have date-time as two fields. If so, you
>> can
>> >>>     just read the first field if you only want the date:
>> >>>
>> >>>     # assume you have removed the first line
>> >>>     dadf<-read.table("xxx.txt",stringsAsFactors=FALSE
>> >>>     dadf$date<-as.Date(dadf$V1,format="%Y-%m-%d")
>> >>>
>> >>>     If you want the date/time:
>> >>>
>> >>>     dadf$datetime<-strptime(paste(dadf$V1,dadf$V2),format="%Y-%m-%d
>> >>> %H:%M:%S")
>> >>>
>> >>>     Jim
>> >>>
>> >>>     On Tue, Jul 31, 2018 at 12:29 AM, Diego Avesani
>> >>> <diego.avesani at gmail.com> wrote:
>> >>>     > Dear all,
>> >>>     >
>> >>>     > I am dealing with the reading of a *.txt file.
>> >>>     > The txt file the following shape:
>> >>>     >
>> >>>     > 103001930 103001580 103001530
>> >>>     > 1998-10-01 00:00:00 0.6 0 0
>> >>>     > 1998-10-01 01:00:00 0.2 0.2 0.2
>> >>>     > 1998-10-01 02:00:00 0.6 0.2 0.4
>> >>>     > 1998-10-01 03:00:00 0 0 0.6
>> >>>     > 1998-10-01 04:00:00 0 0 0
>> >>>     > 1998-10-01 05:00:00 0 0 0
>> >>>     > 1998-10-01 06:00:00 0 0 0
>> >>>     > 1998-10-01 07:00:00 0.2 0 0
>> >>>     >
>> >>>     > If it is possible I have a coupe of questions, which will sound
>> >>> stupid but
>> >>>     > they are important to me in order to understand ho R deal with
>> file
>> >>> or date.
>> >>>     >
>> >>>     > 1) Do I have to convert it to a *csv file?
>> >>>     > 2) Can a deal with space and not ","
>> >>>     > 3) How can I read date?
>> >>>     >
>> >>>     > thanks a lot to all of you,
>> >>>     > Thanks
>> >>>     >
>> >>>     >
>> >>>     > Diego
>> >>>     >
>> >>>     >         [[alternative HTML version deleted]]
>> >>>     >
>> >>>     > ______________________________________________
>> >>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> >>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>     > PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>>     > and provide commented, minimal, self-contained, reproducible
>> code.
>> >>>
>> >>>     ______________________________________________
>> >>>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>     https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>     PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>>     and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>>
>> >>
>> >
>>
>
>

	[[alternative HTML version deleted]]



From b@rhomopo||@ @end|ng |rom gm@||@com  Tue Jul 31 19:41:51 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Tue, 31 Jul 2018 13:41:51 -0400
Subject: [R] RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
Message-ID: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>

H
i All,

If I have this vector:

> vect <- c(foo = 11, bar = 2, norf = 45)

I can have a subset that has only "bar and "norf" this way:
> vect[c("bar","norf")]

Now how do I achieve the same by asking it for a subset that simply
excludes "foo"? I tried all these, resulting in errors:

vect[-"foo"]
vect[-c("foo")]
vect[!"foo"]
vect[!c("foo")]

Thanks!

	[[alternative HTML version deleted]]



From huze|@@kh@||| @end|ng |rom um|ch@edu  Tue Jul 31 19:49:16 2018
From: huze|@@kh@||| @end|ng |rom um|ch@edu (Huzefa Khalil)
Date: Tue, 31 Jul 2018 13:49:16 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
Message-ID: <CADsG8gNer0n=Q+uTxur1LODJrKG1KQmF=kZbjkfFMW+Ri-WWUg@mail.gmail.com>

try:

vect[which(names(vect) != "foo")]

On Tue, Jul 31, 2018 at 1:41 PM, ??????? ???? Ibrauheem Khat'taub
<barhomopolis at gmail.com> wrote:
> H
> i All,
>
> If I have this vector:
>
>> vect <- c(foo = 11, bar = 2, norf = 45)
>
> I can have a subset that has only "bar and "norf" this way:
>> vect[c("bar","norf")]
>
> Now how do I achieve the same by asking it for a subset that simply
> excludes "foo"? I tried all these, resulting in errors:
>
> vect[-"foo"]
> vect[-c("foo")]
> vect[!"foo"]
> vect[!c("foo")]
>
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Jul 31 19:50:48 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 31 Jul 2018 13:50:48 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
Message-ID: <CAM_vjun6Brg9E_3pGbm2jG0yYLkeaHOyDRtoZJ3287ch7cHmRg@mail.gmail.com>

Hi,

You need to tell R to look in the names component of your vector. Here
are three different ways:

vect <- c(foo = 11, bar = 2, norf = 45)

vect[!(names(vect) %in% c("foo"))] # easily generalizable to a longer list

vect[!grepl("foo", names(vect))]

vect[!(names(vect) == "foo")]

There are many more ways to do this, all predicated on matching a
string within the character vector containing the names of your
object.

Also, on this list we don't care at all if you're using R Studio, or
what the version is. We do potentially care what version of R itself
you are using.

Sarah

On Tue, Jul 31, 2018 at 1:41 PM, ??????? ???? Ibrauheem Khat'taub
<barhomopolis at gmail.com> wrote:
> H
> i All,
>
> If I have this vector:
>
>> vect <- c(foo = 11, bar = 2, norf = 45)
>
> I can have a subset that has only "bar and "norf" this way:
>> vect[c("bar","norf")]
>
> Now how do I achieve the same by asking it for a subset that simply
> excludes "foo"? I tried all these, resulting in errors:
>
> vect[-"foo"]
> vect[-c("foo")]
> vect[!"foo"]
> vect[!c("foo")]
>
> Thanks!
>


-- 
Sarah Goslee
http://www.functionaldiversity.org



From b@rhomopo||@ @end|ng |rom gm@||@com  Tue Jul 31 19:54:04 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Tue, 31 Jul 2018 13:54:04 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAM_vjun6Brg9E_3pGbm2jG0yYLkeaHOyDRtoZJ3287ch7cHmRg@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
 <CAM_vjun6Brg9E_3pGbm2jG0yYLkeaHOyDRtoZJ3287ch7cHmRg@mail.gmail.com>
Message-ID: <CAC4BqreaKEUOMHAUpYmAgEOiYTmVM++DbfGT33reEKr_tm2ULQ@mail.gmail.com>

Awesome, Sarah, thanks!

And thanks for the clarification about declaring the version of R.

Best,
Ibrahim

On Tue, 31 Jul 2018 at 13:50, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> You need to tell R to look in the names component of your vector. Here
> are three different ways:
>
> vect <- c(foo = 11, bar = 2, norf = 45)
>
> vect[!(names(vect) %in% c("foo"))] # easily generalizable to a longer list
>
> vect[!grepl("foo", names(vect))]
>
> vect[!(names(vect) == "foo")]
>
> There are many more ways to do this, all predicated on matching a
> string within the character vector containing the names of your
> object.
>
> Also, on this list we don't care at all if you're using R Studio, or
> what the version is. We do potentially care what version of R itself
> you are using.
>
> Sarah
>
> On Tue, Jul 31, 2018 at 1:41 PM, ??????? ???? Ibrauheem Khat'taub
> <barhomopolis at gmail.com> wrote:
> > H
> > i All,
> >
> > If I have this vector:
> >
> >> vect <- c(foo = 11, bar = 2, norf = 45)
> >
> > I can have a subset that has only "bar and "norf" this way:
> >> vect[c("bar","norf")]
> >
> > Now how do I achieve the same by asking it for a subset that simply
> > excludes "foo"? I tried all these, resulting in errors:
> >
> > vect[-"foo"]
> > vect[-c("foo")]
> > vect[!"foo"]
> > vect[!c("foo")]
> >
> > Thanks!
> >
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]



From b@rhomopo||@ @end|ng |rom gm@||@com  Tue Jul 31 19:55:46 2018
From: b@rhomopo||@ @end|ng |rom gm@||@com (=?UTF-8?B?2KXYqNix2KfZh9mK2YUg2K7Yt9in2KggSWJyYXVoZWVtIEtoYXQndGF1Yg==?=)
Date: Tue, 31 Jul 2018 13:55:46 -0400
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAHATPRmexVy0XtRqZe_VENFTOcnSog8m0rRs+QZ4e-gMH66iow@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
 <CAHATPRmexVy0XtRqZe_VENFTOcnSog8m0rRs+QZ4e-gMH66iow@mail.gmail.com>
Message-ID: <CAC4BqrciOBvN_2Tg8nx=MAb=zHSVM4c7T4zf116txeMkk+0KtA@mail.gmail.com>

Awesome, thanks!
?? ???? ????? ??????? ?????.
??????? ????


On Tue, 31 Jul 2018 at 13:54, Data Science Classes <
datascienceclasses at gmail.com> wrote:

> You can do
>
> Vect[-grep (?foo?, names(vect))]
>
> On Tue, 31 Jul 2018 at 11:12 PM, ??????? ???? Ibrauheem Khat'taub <
> barhomopolis at gmail.com> wrote:
>
>> H
>> i All,
>>
>> If I have this vector:
>>
>> > vect <- c(foo = 11, bar = 2, norf = 45)
>>
>> I can have a subset that has only "bar and "norf" this way:
>> > vect[c("bar","norf")]
>>
>> Now how do I achieve the same by asking it for a subset that simply
>> excludes "foo"? I tried all these, resulting in errors:
>>
>> vect[-"foo"]
>> vect[-c("foo")]
>> vect[!"foo"]
>> vect[!c("foo")]
>>
>> Thanks!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> Regards,
> Data Science Classes
>

	[[alternative HTML version deleted]]



From d@t@@c|encec|@@@e@ @end|ng |rom gm@||@com  Tue Jul 31 19:54:37 2018
From: d@t@@c|encec|@@@e@ @end|ng |rom gm@||@com (Data Science Classes)
Date: Tue, 31 Jul 2018 23:24:37 +0530
Subject: [R] 
 RStudio 1.1.453 - Windows 10 - How to subset named vector by
 names that are NOT "foo"
In-Reply-To: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
References: <CAC4BqrdXzHM6yrPxPhpBq_Hp5ZQX7u73W5nhMbh8s+Ne5cFC+w@mail.gmail.com>
Message-ID: <CAHATPRmexVy0XtRqZe_VENFTOcnSog8m0rRs+QZ4e-gMH66iow@mail.gmail.com>

You can do

Vect[-grep (?foo?, names(vect))]

On Tue, 31 Jul 2018 at 11:12 PM, ??????? ???? Ibrauheem Khat'taub <
barhomopolis at gmail.com> wrote:

> H
> i All,
>
> If I have this vector:
>
> > vect <- c(foo = 11, bar = 2, norf = 45)
>
> I can have a subset that has only "bar and "norf" this way:
> > vect[c("bar","norf")]
>
> Now how do I achieve the same by asking it for a subset that simply
> excludes "foo"? I tried all these, resulting in errors:
>
> vect[-"foo"]
> vect[-c("foo")]
> vect[!"foo"]
> vect[!c("foo")]
>
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Regards,
Data Science Classes

	[[alternative HTML version deleted]]



