From rb@er @end|ng |rom @t@u@edu  Fri Dec  1 01:04:39 2023
From: rb@er @end|ng |rom @t@u@edu (Robert Baer)
Date: Thu, 30 Nov 2023 18:04:39 -0600
Subject: [R] back tick names with predict function
In-Reply-To: <ca3d2bde-4426-4a41-9d9f-93e60fc66a55@sapo.pt>
References: <495ef0b7-b017-4aa2-afb0-5c2b6ab4e647@atsu.edu>
 <b25f20f0-c196-4897-8ea3-2a3e5f1a48ff@sapo.pt>
 <ca3d2bde-4426-4a41-9d9f-93e60fc66a55@sapo.pt>
Message-ID: <84461035-4232-4112-82cf-bba5e65d03eb@atsu.edu>

Thank you Rui.? I didn't know about the check.names = FALSE argument.? 
Another good reminder to always read help, but I'm not sure I understood 
what help to read in this case.? Since your clue, I've discovered that a 
tibble-based strategy could also work.

x = seq(min(cob_wt$`plant-density`), max(cob_wt$`plant-density`), length 
= 999)
xvals = tibble(`plant-density` = x)
CI.c = predict(mod2, newdata = xvals, interval = 'c')
CI.p = predict(mod2,? newdata = xvals,? interval = 'p')

Again, appreciate the solution.

On 11/30/2023 12:03 PM, Rui Barradas wrote:
> ?s 17:57 de 30/11/2023, Rui Barradas escreveu:
>> ?s 17:38 de 30/11/2023, Robert Baer escreveu:
>>> I am having trouble using back ticks with the R extractor function 
>>> 'predict' and an lm() model. I'm trying too construct some nice 
>>> vectors that can be used for plotting the two types of regression 
>>> intervals.? I think it works with normal column heading names but it 
>>> fails when I have "special" back-tick names.? Can anyone help with 
>>> how I would reference these?? Short of renaming my columns, is there 
>>> a way to accomplish this?
>>>
>>> Repex
>>>
>>> *# dataframe with dashes in column headings
>>> cob =
>>> ?? structure(list(`cob-wt` = c(212, 241, 215, 225, 250, 241, 237,
>>> ???????????????????????????? 282, 206, 246, 194, 241, 196, 193, 224, 
>>> 257, 200, 190, 208, 224
>>> ), `plant-density` = c(137, 107, 132, 135, 115, 103, 102, 65,
>>> ??????????????????????? 149, 85, 173, 124, 157, 184, 112, 80, 165, 
>>> 160, 157, 119)),
>>> class = c("tbl_df", "tbl", "data.frame"), row.names = c(NA, -20L))
>>>
>>> # regression model works
>>> mod2 = lm(`cob-wt` ~ `plant-density`, data = cob)
>>>
>>> # x sequence for plotting CI's
>>> # Set up x points
>>> x = seq(min(cob$`plant-density`), max(cob$`plant-density`), length = 
>>> 1000)
>>>
>>> # Use predict to get CIs for a plot
>>> # Add CI for regression line (y-hat uses 'c')
>>> # usual trick is to assign x to actual x-var name in middle 
>>> dataframe arguement
>>> CI.c = predict(mod2, data.frame( `plant-density` = x), interval = 
>>> 'c') # fail
>>>
>>> # Add CI for prediction value (y-tilde uses 'p')
>>> # usual trick is to assign x to actual x-var name in middle 
>>> dataframe arguement
>>> CI.p = predict(mod2, data.frame(`plant-density`? = x), interval = 
>>> 'p')??? # fail
>>> *
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> When creating the new data df, the default check.names = TRUE changes 
>> the column name, it is repaired and the hyphen is replaced by a legal 
>> dot.
>>
>>
>> # check.names defaults to TRUE
>> newd <- data.frame(`plant-density` = x)
>> # `plant-density` is not a column name
>> head(newd)
>>
>> # check.names set to FALSE
>> newd <- data.frame(`plant-density` = x, check.names = FALSE)
>> # `plant-density` is becomes a column name
>> head(newd)
>>
>>
>> # Use predict to get CIs for a plot
>> # Add CI for regression line (y-hat uses 'c')
>> # usual trick is to assign x to actual x-var name in middle dataframe 
>> arguement
>> CI.c = predict(mod2, newdata = newd, interval = 'confidence')? # fail
>>
>> # Add CI for prediction value (y-tilde uses 'p')
>> # usual trick is to assign x to actual x-var name in middle dataframe 
>> arguement
>> CI.p = predict(mod2, newdata = newd, interval = 'prediction') # fail
>>
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
> Hello,
>
> Sorry for the comments '# fail' in the last two instructions, I should 
> have changed them.
>
>
> CI.c <- predict(mod2, newdata = newd, interval = 'confidence') # works
> CI.p <- predict(mod2, newdata = newd, interval = 'prediction') # works
>
>
> Hoep this helps,
>
> Rui Barradas
>
>


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec  1 01:47:23 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 30 Nov 2023 16:47:23 -0800
Subject: [R] back tick names with predict function
In-Reply-To: <84461035-4232-4112-82cf-bba5e65d03eb@atsu.edu>
References: <495ef0b7-b017-4aa2-afb0-5c2b6ab4e647@atsu.edu>
 <b25f20f0-c196-4897-8ea3-2a3e5f1a48ff@sapo.pt>
 <ca3d2bde-4426-4a41-9d9f-93e60fc66a55@sapo.pt>
 <84461035-4232-4112-82cf-bba5e65d03eb@atsu.edu>
Message-ID: <CAGxFJbTbwg21cz+v4ooaD7BhuH8vD-Jj1fHtE-dDw+ChxZnKcg@mail.gmail.com>

"Thank you Rui.  I didn't know about the check.names = FALSE argument.
> Another good reminder to always read help, but I'm not sure I understood
> what help to read in this case"

?data.frame , of course, which says:

"check.names

logical. If TRUE then the names of the variables in the data frame are
checked to ensure that they are syntactically valid variable names and
are not duplicated. If necessary they are adjusted (by make.names) so
that they are. "

-- Bert


From n|ckmwr@y @end|ng |rom gm@||@com  Fri Dec  1 12:58:18 2023
From: n|ckmwr@y @end|ng |rom gm@||@com (Nick Wray)
Date: Fri, 1 Dec 2023 11:58:18 +0000
Subject: [R] Mann Kendall mutation package?
Message-ID: <CABxY9BOiviytVdHU0bhnTQ6jZrBr9Pyi2k9EOO7jfYfCeUFBBA@mail.gmail.com>

Hello - does anyone know whether there are any packages for Mann-Kendall
mutation tests in R available?  The only one I could find online is this
MK_mut_test: Mann-Kendall mutation test in Sibada/sibadaR: Sibada's
accumulated R scripts for next probably use to avoid reinventing the wheel.
(rdrr.io) <https://rdrr.io/github/Sibada/sibadaR/man/MK_mut_test.html> but
there doesn't seem to be a package corresponding to this.  I've tried
installing various permutations of the apparent name Sibada/sibadaR but
nothing comes up, so I'm not sure whether it even exists...

Thanks Nick Wray

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Dec  1 16:44:36 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 1 Dec 2023 15:44:36 +0000
Subject: [R] Mann Kendall mutation package?
In-Reply-To: <CABxY9BOiviytVdHU0bhnTQ6jZrBr9Pyi2k9EOO7jfYfCeUFBBA@mail.gmail.com>
References: <CABxY9BOiviytVdHU0bhnTQ6jZrBr9Pyi2k9EOO7jfYfCeUFBBA@mail.gmail.com>
Message-ID: <ea64fa78-db5b-4a49-a61b-a9481ef4bc25@sapo.pt>

?s 11:58 de 01/12/2023, Nick Wray escreveu:
> Hello - does anyone know whether there are any packages for Mann-Kendall
> mutation tests in R available?  The only one I could find online is this
> MK_mut_test: Mann-Kendall mutation test in Sibada/sibadaR: Sibada's
> accumulated R scripts for next probably use to avoid reinventing the wheel.
> (rdrr.io) <https://rdrr.io/github/Sibada/sibadaR/man/MK_mut_test.html> but
> there doesn't seem to be a package corresponding to this.  I've tried
> installing various permutations of the apparent name Sibada/sibadaR but
> nothing comes up, so I'm not sure whether it even exists...
> 
> Thanks Nick Wray
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Your link points to a GitHub repository, the package can be installed with


devtools::install_github(repo = "Sibada/sibadaR")



Hope this helps

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From pd@|gd @end|ng |rom gm@||@com  Fri Dec  1 18:47:04 2023
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 1 Dec 2023 18:47:04 +0100
Subject: [R] back tick names with predict function
In-Reply-To: <CAGxFJbTbwg21cz+v4ooaD7BhuH8vD-Jj1fHtE-dDw+ChxZnKcg@mail.gmail.com>
References: <495ef0b7-b017-4aa2-afb0-5c2b6ab4e647@atsu.edu>
 <b25f20f0-c196-4897-8ea3-2a3e5f1a48ff@sapo.pt>
 <ca3d2bde-4426-4a41-9d9f-93e60fc66a55@sapo.pt>
 <84461035-4232-4112-82cf-bba5e65d03eb@atsu.edu>
 <CAGxFJbTbwg21cz+v4ooaD7BhuH8vD-Jj1fHtE-dDw+ChxZnKcg@mail.gmail.com>
Message-ID: <240E71BB-E054-4F8A-99C1-8F905FAFBC49@gmail.com>

Also, and possibly more constructively, when you get an error like
 
> CI.c = predict(mod2, data.frame( `plant-density` = x), interval = 'c')  # fail
Error in eval(predvars, data, env) : object 'plant-density' not found

you should check your assumptions. Does "newdata" actually contain a columnn called "plant-density":

> head(data.frame( `plant-density` = x))
  plant.density
1      65.00000
2      65.11912
3      65.23824
4      65.35736
5      65.47648
6      65.59560
> 

I.e., it doesn't. So check help for data.frame and looking for something with names.

> On 1 Dec 2023, at 01:47 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> "Thank you Rui.  I didn't know about the check.names = FALSE argument.
>> Another good reminder to always read help, but I'm not sure I understood
>> what help to read in this case"
> 
> ?data.frame , of course, which says:
> 
> "check.names
> 
> logical. If TRUE then the names of the variables in the data frame are
> checked to ensure that they are syntactically valid variable names and
> are not duplicated. If necessary they are adjusted (by make.names) so
> that they are. "
> 
> -- Bert
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bbo|ker @end|ng |rom gm@||@com  Fri Dec  1 23:01:46 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 1 Dec 2023 17:01:46 -0500
Subject: [R] Mann Kendall mutation package?
In-Reply-To: <CABxY9BOiviytVdHU0bhnTQ6jZrBr9Pyi2k9EOO7jfYfCeUFBBA@mail.gmail.com>
References: <CABxY9BOiviytVdHU0bhnTQ6jZrBr9Pyi2k9EOO7jfYfCeUFBBA@mail.gmail.com>
Message-ID: <6f308f48-a604-4659-8cb6-5f36d2249f74@gmail.com>

   Have you looked at the Kendall package?

https://stackoverflow.com/questions/62288340/mann-kendall-in-r

  (you've cross-posted a version of this question to SO as well:

https://stackoverflow.com/questions/77587426/what-is-the-algorithm-for-the-mann-kendall-mutation-test

)

Please don't cross-post between the R help lists and other forums like 
SO -- it dilutes/duplicates effort.



On 2023-12-01 6:58 a.m., Nick Wray wrote:
> Hello - does anyone know whether there are any packages for Mann-Kendall
> mutation tests in R available?  The only one I could find online is this
> MK_mut_test: Mann-Kendall mutation test in Sibada/sibadaR: Sibada's
> accumulated R scripts for next probably use to avoid reinventing the wheel.
> (rdrr.io) <https://rdrr.io/github/Sibada/sibadaR/man/MK_mut_test.html> but
> there doesn't seem to be a package corresponding to this.  I've tried
> installing various permutations of the apparent name Sibada/sibadaR but
> nothing comes up, so I'm not sure whether it even exists...
> 
> Thanks Nick Wray
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ||@her @end|ng |rom p|e@@th@n@com  Fri Dec  1 21:53:25 2023
From: ||@her @end|ng |rom p|e@@th@n@com (Dennis Fisher)
Date: Fri, 1 Dec 2023 12:53:25 -0800
Subject: [R] adding "Page X of XX" to PDFs
Message-ID: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>

OS X
R 4.3.1

Colleagues

I often create multipage PDFs [pdf()] in which the text "Page X" appears in the margin.  These PDFs are created automatically using a massive R script.

One of my clients requested that I change this to:
	Page X of XX 
where XX is the total number of pages.  

I don't know the number of expected pages so I can't think of any clever way to do this.  I suppose that I could create the PDF, find out the number of pages, then have a second pass in which the R script was fed the number of pages.  However, there is one disadvantage to this -- the original PDF contains a timestamp on each page -- the new version would have a different timestamp -- so I would prefer to not use this approach.

Has anyone thought of some terribly clever way to solve this problem?

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t  Sat Dec  2 16:37:01 2023
From: er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t (Erich Subscriptions)
Date: Sat, 2 Dec 2023 16:37:01 +0100
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
Message-ID: <C624E96D-1306-4585-BAD1-66C01A3328C1@neuwirth.priv.at>

You need to use raw LaTeX

See section 4 here

Von meinem iPad gesendet

> Am 02.12.2023 um 15:39 schrieb Dennis Fisher <fisher at plessthan.com>:
> 
> ?OS X
> R 4.3.1
> 
> Colleagues
> 
> I often create multipage PDFs [pdf()] in which the text "Page X" appears in the margin.  These PDFs are created automatically using a massive R script.
> 
> One of my clients requested that I change this to:
>    Page X of XX
> where XX is the total number of pages.  
> 
> I don't know the number of expected pages so I can't think of any clever way to do this.  I suppose that I could create the PDF, find out the number of pages, then have a second pass in which the R script was fed the number of pages.  However, there is one disadvantage to this -- the original PDF contains a timestamp on each page -- the new version would have a different timestamp -- so I would prefer to not use this approach.
> 
> Has anyone thought of some terribly clever way to solve this problem?
> 
> Dennis
> 
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From po|c1410 @end|ng |rom gm@||@com  Sat Dec  2 17:12:30 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Sat, 2 Dec 2023 16:12:30 +0000
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
Message-ID: <CA+etgP=6QZZ0A-Amt0Es4iDxovDF==gqNUmLVqY6oV8ktXdfnw@mail.gmail.com>

Can you provide a very simplified version of how the PDF is created?



On Sat, 2 Dec 2023, 14:39 Dennis Fisher, <fisher at plessthan.com> wrote:

> OS X
> R 4.3.1
>
> Colleagues
>
> I often create multipage PDFs [pdf()] in which the text "Page X" appears
> in the margin.  These PDFs are created automatically using a massive R
> script.
>
> One of my clients requested that I change this to:
>         Page X of XX
> where XX is the total number of pages.
>
> I don't know the number of expected pages so I can't think of any clever
> way to do this.  I suppose that I could create the PDF, find out the number
> of pages, then have a second pass in which the R script was fed the number
> of pages.  However, there is one disadvantage to this -- the original PDF
> contains a timestamp on each page -- the new version would have a different
> timestamp -- so I would prefer to not use this approach.
>
> Has anyone thought of some terribly clever way to solve this problem?
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_grt @end|ng |rom y@hoo@|r  Sat Dec  2 17:36:18 2023
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Sat, 2 Dec 2023 17:36:18 +0100
Subject: [R] Try reproduce glmm by hand
References: <f0d28e51-b515-4880-aa55-70af47e8dbc9.ref@yahoo.fr>
Message-ID: <f0d28e51-b515-4880-aa55-70af47e8dbc9@yahoo.fr>

Dear all,

In order to be sure I understand glmm correctly, I try to reproduce by 
hand a simple result. Here is a reproducible code. The questions are in 
_________________

Of course I have tried to find the solution using internet but I was not 
able to find a solution. I have also tried to follow glmer but it is 
very complicated code!

Thanks for any help.

Marc


# Generate set of df with nb successes and failures
# and ID being A, B or C (the random effect)
# and x being the fixed effect
set.seed(1)
df <- rbind(matrix(data = c(sample(x=5:30, size=40, replace = TRUE), 
rep(10, 40)), ncol=2),
 ??????????? matrix(data = c(sample(x=10:30, size=40, replace = TRUE), 
rep(10, 40)), ncol=2),
 ??????????? matrix(data = c(sample(x=20:30, size=40, replace = TRUE), 
rep(10, 40)), ncol=2))
ID <- as.factor(c(rep("A", 40), rep("B", 40), rep("C", 40)))
x <- c(runif(40, min=10, max=30), runif(40, min=20, max=30), runif(40, 
min=40, max=60))
x <- (x-min(x))/(max(x)-min(x))

# In g0, I have the results of the glmm
library(lme4)
g0 <- glmer(formula = df ~ x + (1 | ID), family = 
binomial(link="logit"), nAGQ=1)
-logLik(g0) # 'log Lik.' 268.0188 (df=3)
# I get the fitted parameters
fixep <- fixef(g0)
par <- getME(g0, c("theta","beta"))
# _______________________________________________________________________
# Question 1: how theta is converted into the specific effect on 
(intercept) for the random effect ?
# Then how a theta parameter is converted into intercepts?
# _______________________________________________________________________
intercepts <- ranef(g0)$ID

# This part is ok, the predict is correct
pfit <- 1-c(1/(1+exp(fixep["(Intercept)"]+intercepts["A", 
1]+x[ID=="A"]*fixep["x"])),
 ? 1/(1+exp(fixep["(Intercept)"]+intercepts["B", 
1]+x[ID=="B"]*fixep["x"])),
 ? 1/(1+exp(fixep["(Intercept)"]+intercepts["C", 1]+x[ID=="C"]*fixep["x"])))

predict(g0, type = "response")

# _______________________________________________________________________
# Why I obtain 266.4874 and not 268.0188 as in -logLik(g0)?
# _______________________________________________________________________
-sum(dbinom(x=df[, 1], size=df[, 1]+df[, 2], prob=pfit, log=TRUE)) # 
266.4874


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Dec  2 17:45:36 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 02 Dec 2023 08:45:36 -0800
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
Message-ID: <A5CA1C96-298C-4AB4-9B17-BA30B40F6F90@dcn.davis.ca.us>

One of the most fundamental characteristics of R programming is the use of data frames of column vectors, and one of the very first challenges I had as a then-Perl-programmer was coming to grips with the fact that unknown-length CSV files would be read completely into memory as rows and once the entire CSV was in memory it would be transposed into column vectors. I was resistant to this philosophy at first, but the advantages in computation speed and simplicity eventually won me over.

I would say that if you want to know how many pages you are going to produce with R, then you are going to have to count them before you create them. Building a dataframe that describes (in terms of parameters to be passed to a page-generating function in each row) what you are going to put on each page before you actually print it can make this pre-counting problem trivial, and the code that does the printing is likely to be more modular and testable as well.

On December 1, 2023 12:53:25 PM PST, Dennis Fisher <fisher at plessthan.com> wrote:
>OS X
>R 4.3.1
>
>Colleagues
>
>I often create multipage PDFs [pdf()] in which the text "Page X" appears in the margin.  These PDFs are created automatically using a massive R script.
>
>One of my clients requested that I change this to:
>	Page X of XX 
>where XX is the total number of pages.  
>
>I don't know the number of expected pages so I can't think of any clever way to do this.  I suppose that I could create the PDF, find out the number of pages, then have a second pass in which the R script was fed the number of pages.  However, there is one disadvantage to this -- the original PDF contains a timestamp on each page -- the new version would have a different timestamp -- so I would prefer to not use this approach.
>
>Has anyone thought of some terribly clever way to solve this problem?
>
>Dennis
>
>Dennis Fisher MD
>P < (The "P Less Than" Company)
>Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>www.PLessThan.com
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jrkr|de@u @end|ng |rom gm@||@com  Sat Dec  2 18:10:28 2023
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sat, 2 Dec 2023 12:10:28 -0500
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
Message-ID: <CAKZQJMAt2vsxZOyxu4k0yS--4HXsBEGOea1heQVXbZ8xAOykBw@mail.gmail.com>

https://community.rstudio.com/t/total-number-of-pages-in-quarto-pdf/177316/2

On Sat, 2 Dec 2023 at 09:39, Dennis Fisher <fisher at plessthan.com> wrote:

> OS X
> R 4.3.1
>
> Colleagues
>
> I often create multipage PDFs [pdf()] in which the text "Page X" appears
> in the margin.  These PDFs are created automatically using a massive R
> script.
>
> One of my clients requested that I change this to:
>         Page X of XX
> where XX is the total number of pages.
>
> I don't know the number of expected pages so I can't think of any clever
> way to do this.  I suppose that I could create the PDF, find out the number
> of pages, then have a second pass in which the R script was fed the number
> of pages.  However, there is one disadvantage to this -- the original PDF
> contains a timestamp on each page -- the new version would have a different
> timestamp -- so I would prefer to not use this approach.
>
> Has anyone thought of some terribly clever way to solve this problem?
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Sat Dec  2 18:23:07 2023
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sat, 2 Dec 2023 17:23:07 +0000
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <A5CA1C96-298C-4AB4-9B17-BA30B40F6F90@dcn.davis.ca.us>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
 <A5CA1C96-298C-4AB4-9B17-BA30B40F6F90@dcn.davis.ca.us>
Message-ID: <CH3PR22MB45147EFE273414753339E1D8CF80A@CH3PR22MB4514.namprd22.prod.outlook.com>

Would this work in general? Say I have a document with figures, special equations, text, and tables. The text and tables are relatively easy. The figures would need a conversion from pixels to lines, and the equations maybe printed out, counted as a figure, and then added to the line count. It would also be tricky if a title line was at 32 point font and the text at 12, and the more complex the formatting the harder to deal with rows as related to page size.

Thankfully I do not think I will have to do this, so the question is for theoretical interest on my part (at least for now).

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller via R-help
Sent: Saturday, December 2, 2023 11:46 AM
To: r-help at r-project.org
Subject: Re: [R] adding "Page X of XX" to PDFs

[External Email]

One of the most fundamental characteristics of R programming is the use of data frames of column vectors, and one of the very first challenges I had as a then-Perl-programmer was coming to grips with the fact that unknown-length CSV files would be read completely into memory as rows and once the entire CSV was in memory it would be transposed into column vectors. I was resistant to this philosophy at first, but the advantages in computation speed and simplicity eventually won me over.

I would say that if you want to know how many pages you are going to produce with R, then you are going to have to count them before you create them. Building a dataframe that describes (in terms of parameters to be passed to a page-generating function in each row) what you are going to put on each page before you actually print it can make this pre-counting problem trivial, and the code that does the printing is likely to be more modular and testable as well.

On December 1, 2023 12:53:25 PM PST, Dennis Fisher <fisher at plessthan.com> wrote:
>OS X
>R 4.3.1
>
>Colleagues
>
>I often create multipage PDFs [pdf()] in which the text "Page X" appears in the margin.  These PDFs are created automatically using a massive R script.
>
>One of my clients requested that I change this to:
>       Page X of XX
>where XX is the total number of pages.
>
>I don't know the number of expected pages so I can't think of any clever way to do this.  I suppose that I could create the PDF, find out the number of pages, then have a second pass in which the R script was fed the number of pages.  However, there is one disadvantage to this -- the original PDF contains a timestamp on each page -- the new version would have a different timestamp -- so I would prefer to not use this approach.
>
>Has anyone thought of some terribly clever way to solve this problem?
>
>Dennis
>
>Dennis Fisher MD
>P < (The "P Less Than" Company)
>Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>http://www.plessthan.com/
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bbo|ker @end|ng |rom gm@||@com  Sat Dec  2 19:36:44 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 2 Dec 2023 13:36:44 -0500
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <CH3PR22MB45147EFE273414753339E1D8CF80A@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
 <A5CA1C96-298C-4AB4-9B17-BA30B40F6F90@dcn.davis.ca.us>
 <CH3PR22MB45147EFE273414753339E1D8CF80A@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <a1d9ac06-4d0f-43dd-afa8-d3ea434147b0@gmail.com>

   It's still not entirely clear to me what framework you're using to 
generate the PDF, but if it's rmarkdown/Rnw (Sweave)/Quarto-based, then 
as far as I know all of those frameworks use LaTeX as the last step in 
the script-to-PDF pipeline, and allow the inclusion of arbitrary LaTeX 
code, so the 'lastpage' package would do this for you:

https://stackoverflow.com/questions/70343001/how-to-show-the-total-number-of-pages-in-a-pdf-via-the-rmarkdown-i-e-display

https://tex.stackexchange.com/questions/227/how-can-i-add-page-of-on-my-document



On 2023-12-02 12:23 p.m., Ebert,Timothy Aaron wrote:
> Would this work in general? Say I have a document with figures, special equations, text, and tables. The text and tables are relatively easy. The figures would need a conversion from pixels to lines, and the equations maybe printed out, counted as a figure, and then added to the line count. It would also be tricky if a title line was at 32 point font and the text at 12, and the more complex the formatting the harder to deal with rows as related to page size.
> 
> Thankfully I do not think I will have to do this, so the question is for theoretical interest on my part (at least for now).
> 
> Tim
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller via R-help
> Sent: Saturday, December 2, 2023 11:46 AM
> To: r-help at r-project.org
> Subject: Re: [R] adding "Page X of XX" to PDFs
> 
> [External Email]
> 
> One of the most fundamental characteristics of R programming is the use of data frames of column vectors, and one of the very first challenges I had as a then-Perl-programmer was coming to grips with the fact that unknown-length CSV files would be read completely into memory as rows and once the entire CSV was in memory it would be transposed into column vectors. I was resistant to this philosophy at first, but the advantages in computation speed and simplicity eventually won me over.
> 
> I would say that if you want to know how many pages you are going to produce with R, then you are going to have to count them before you create them. Building a dataframe that describes (in terms of parameters to be passed to a page-generating function in each row) what you are going to put on each page before you actually print it can make this pre-counting problem trivial, and the code that does the printing is likely to be more modular and testable as well.
> 
> On December 1, 2023 12:53:25 PM PST, Dennis Fisher <fisher at plessthan.com> wrote:
>> OS X
>> R 4.3.1
>>
>> Colleagues
>>
>> I often create multipage PDFs [pdf()] in which the text "Page X" appears in the margin.  These PDFs are created automatically using a massive R script.
>>
>> One of my clients requested that I change this to:
>>        Page X of XX
>> where XX is the total number of pages.
>>
>> I don't know the number of expected pages so I can't think of any clever way to do this.  I suppose that I could create the PDF, find out the number of pages, then have a second pass in which the R script was fed the number of pages.  However, there is one disadvantage to this -- the original PDF contains a timestamp on each page -- the new version would have a different timestamp -- so I would prefer to not use this approach.
>>
>> Has anyone thought of some terribly clever way to solve this problem?
>>
>> Dennis
>>
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>> http://www.plessthan.com/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Dec  2 20:03:22 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 02 Dec 2023 11:03:22 -0800
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <a1d9ac06-4d0f-43dd-afa8-d3ea434147b0@gmail.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
 <A5CA1C96-298C-4AB4-9B17-BA30B40F6F90@dcn.davis.ca.us>
 <CH3PR22MB45147EFE273414753339E1D8CF80A@CH3PR22MB4514.namprd22.prod.outlook.com>
 <a1d9ac06-4d0f-43dd-afa8-d3ea434147b0@gmail.com>
Message-ID: <40E309E8-EC80-4461-9240-A438E545457B@dcn.davis.ca.us>

He clearly stated he was using the pdf() graphics device.

On December 2, 2023 10:36:44 AM PST, Ben Bolker <bbolker at gmail.com> wrote:
>  It's still not entirely clear to me what framework you're using to generate the PDF, but if it's rmarkdown/Rnw (Sweave)/Quarto-based, then as far as I know all of those frameworks use LaTeX as the last step in the script-to-PDF pipeline, and allow the inclusion of arbitrary LaTeX code, so the 'lastpage' package would do this for you:
>
>https://stackoverflow.com/questions/70343001/how-to-show-the-total-number-of-pages-in-a-pdf-via-the-rmarkdown-i-e-display
>
>https://tex.stackexchange.com/questions/227/how-can-i-add-page-of-on-my-document
>
>
>
>On 2023-12-02 12:23 p.m., Ebert,Timothy Aaron wrote:
>> Would this work in general? Say I have a document with figures, special equations, text, and tables. The text and tables are relatively easy. The figures would need a conversion from pixels to lines, and the equations maybe printed out, counted as a figure, and then added to the line count. It would also be tricky if a title line was at 32 point font and the text at 12, and the more complex the formatting the harder to deal with rows as related to page size.
>> 
>> Thankfully I do not think I will have to do this, so the question is for theoretical interest on my part (at least for now).
>> 
>> Tim
>> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller via R-help
>> Sent: Saturday, December 2, 2023 11:46 AM
>> To: r-help at r-project.org
>> Subject: Re: [R] adding "Page X of XX" to PDFs
>> 
>> [External Email]
>> 
>> One of the most fundamental characteristics of R programming is the use of data frames of column vectors, and one of the very first challenges I had as a then-Perl-programmer was coming to grips with the fact that unknown-length CSV files would be read completely into memory as rows and once the entire CSV was in memory it would be transposed into column vectors. I was resistant to this philosophy at first, but the advantages in computation speed and simplicity eventually won me over.
>> 
>> I would say that if you want to know how many pages you are going to produce with R, then you are going to have to count them before you create them. Building a dataframe that describes (in terms of parameters to be passed to a page-generating function in each row) what you are going to put on each page before you actually print it can make this pre-counting problem trivial, and the code that does the printing is likely to be more modular and testable as well.
>> 
>> On December 1, 2023 12:53:25 PM PST, Dennis Fisher <fisher at plessthan.com> wrote:
>>> OS X
>>> R 4.3.1
>>> 
>>> Colleagues
>>> 
>>> I often create multipage PDFs [pdf()] in which the text "Page X" appears in the margin.  These PDFs are created automatically using a massive R script.
>>> 
>>> One of my clients requested that I change this to:
>>>        Page X of XX
>>> where XX is the total number of pages.
>>> 
>>> I don't know the number of expected pages so I can't think of any clever way to do this.  I suppose that I could create the PDF, find out the number of pages, then have a second pass in which the R script was fed the number of pages.  However, there is one disadvantage to this -- the original PDF contains a timestamp on each page -- the new version would have a different timestamp -- so I would prefer to not use this approach.
>>> 
>>> Has anyone thought of some terribly clever way to solve this problem?
>>> 
>>> Dennis
>>> 
>>> Dennis Fisher MD
>>> P < (The "P Less Than" Company)
>>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>>> http://www.plessthan.com/
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Sent from my phone. Please excuse my brevity.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bbo|ker @end|ng |rom gm@||@com  Sat Dec  2 20:07:24 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 2 Dec 2023 14:07:24 -0500
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <40E309E8-EC80-4461-9240-A438E545457B@dcn.davis.ca.us>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
 <A5CA1C96-298C-4AB4-9B17-BA30B40F6F90@dcn.davis.ca.us>
 <CH3PR22MB45147EFE273414753339E1D8CF80A@CH3PR22MB4514.namprd22.prod.outlook.com>
 <a1d9ac06-4d0f-43dd-afa8-d3ea434147b0@gmail.com>
 <40E309E8-EC80-4461-9240-A438E545457B@dcn.davis.ca.us>
Message-ID: <70831495-43ec-491e-9947-1f214c6f0a2e@gmail.com>

    Sorry, jumped into the thread too late. (On the other hand, once the 
document gets complicated enough, it may be worth it in the long run to 
convert to something that actually has a document-generating back-end, 
rather than reinventing everything from scratch ...)

On 2023-12-02 2:03 p.m., Jeff Newmiller via R-help wrote:
> He clearly stated he was using the pdf() graphics device.
> 
> On December 2, 2023 10:36:44 AM PST, Ben Bolker <bbolker at gmail.com> wrote:
>>   It's still not entirely clear to me what framework you're using to generate the PDF, but if it's rmarkdown/Rnw (Sweave)/Quarto-based, then as far as I know all of those frameworks use LaTeX as the last step in the script-to-PDF pipeline, and allow the inclusion of arbitrary LaTeX code, so the 'lastpage' package would do this for you:
>>
>> https://stackoverflow.com/questions/70343001/how-to-show-the-total-number-of-pages-in-a-pdf-via-the-rmarkdown-i-e-display
>>
>> https://tex.stackexchange.com/questions/227/how-can-i-add-page-of-on-my-document
>>
>>
>>
>> On 2023-12-02 12:23 p.m., Ebert,Timothy Aaron wrote:
>>> Would this work in general? Say I have a document with figures, special equations, text, and tables. The text and tables are relatively easy. The figures would need a conversion from pixels to lines, and the equations maybe printed out, counted as a figure, and then added to the line count. It would also be tricky if a title line was at 32 point font and the text at 12, and the more complex the formatting the harder to deal with rows as related to page size.
>>>
>>> Thankfully I do not think I will have to do this, so the question is for theoretical interest on my part (at least for now).
>>>
>>> Tim
>>>
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Newmiller via R-help
>>> Sent: Saturday, December 2, 2023 11:46 AM
>>> To: r-help at r-project.org
>>> Subject: Re: [R] adding "Page X of XX" to PDFs
>>>
>>> [External Email]
>>>
>>> One of the most fundamental characteristics of R programming is the use of data frames of column vectors, and one of the very first challenges I had as a then-Perl-programmer was coming to grips with the fact that unknown-length CSV files would be read completely into memory as rows and once the entire CSV was in memory it would be transposed into column vectors. I was resistant to this philosophy at first, but the advantages in computation speed and simplicity eventually won me over.
>>>
>>> I would say that if you want to know how many pages you are going to produce with R, then you are going to have to count them before you create them. Building a dataframe that describes (in terms of parameters to be passed to a page-generating function in each row) what you are going to put on each page before you actually print it can make this pre-counting problem trivial, and the code that does the printing is likely to be more modular and testable as well.
>>>
>>> On December 1, 2023 12:53:25 PM PST, Dennis Fisher <fisher at plessthan.com> wrote:
>>>> OS X
>>>> R 4.3.1
>>>>
>>>> Colleagues
>>>>
>>>> I often create multipage PDFs [pdf()] in which the text "Page X" appears in the margin.  These PDFs are created automatically using a massive R script.
>>>>
>>>> One of my clients requested that I change this to:
>>>>         Page X of XX
>>>> where XX is the total number of pages.
>>>>
>>>> I don't know the number of expected pages so I can't think of any clever way to do this.  I suppose that I could create the PDF, find out the number of pages, then have a second pass in which the R script was fed the number of pages.  However, there is one disadvantage to this -- the original PDF contains a timestamp on each page -- the new version would have a different timestamp -- so I would prefer to not use this approach.
>>>>
>>>> Has anyone thought of some terribly clever way to solve this problem?
>>>>
>>>> Dennis
>>>>
>>>> Dennis Fisher MD
>>>> P < (The "P Less Than" Company)
>>>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>>>> http://www.plessthan.com/
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Dec  2 21:51:48 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 2 Dec 2023 15:51:48 -0500
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <70831495-43ec-491e-9947-1f214c6f0a2e@gmail.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
 <A5CA1C96-298C-4AB4-9B17-BA30B40F6F90@dcn.davis.ca.us>
 <CH3PR22MB45147EFE273414753339E1D8CF80A@CH3PR22MB4514.namprd22.prod.outlook.com>
 <a1d9ac06-4d0f-43dd-afa8-d3ea434147b0@gmail.com>
 <40E309E8-EC80-4461-9240-A438E545457B@dcn.davis.ca.us>
 <70831495-43ec-491e-9947-1f214c6f0a2e@gmail.com>
Message-ID: <66106ec2-191d-4860-8e53-3ae214112d2f@gmail.com>

On 02/12/2023 2:07 p.m., Ben Bolker wrote:
>      Sorry, jumped into the thread too late. (On the other hand, once the
> document gets complicated enough, it may be worth it in the long run to
> convert to something that actually has a document-generating back-end,
> rather than reinventing everything from scratch ...)
> 

I agree with that comment.  However, if one is stuck with a multipage 
PDF file, and wants to add page numbering, you could use the LaTeX 
pdfpages package.

For example, this R Markdown document includes all 10 plots from 
Rplots.pdf on pages with "x of y" page numbering.

   ---
   title: "Numbered"
   output:
     pdf_document:
       extra_dependencies: ["pdfpages", "fancyhdr", "lastpage"]
   ---

   \cfoot{Page \thepage\ of \pageref{LastPage}}

   \addtocounter{page}{-1}

   \includepdf[pages={1-10},pagecommand={\thispagestyle{fancy}}]{Rplots.pdf}


It would make more sense to do this in a LaTeX document, but I'm not 
sure if Dennis knows LaTeX...

Duncan Murdoch


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Dec  2 23:35:04 2023
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 2 Dec 2023 17:35:04 -0500
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
Message-ID: <010b01da256f$cb6ee150$624ca3f0$@gmail.com>

Having read all of the replies, it seems there are solutions for the
question and the OP points out that some solutions such as making the
document twice will affect the creation date.

I suspect the additional time to do so is seconds or at most minutes so it
may not be a big deal.

But what about the idea of creating a PDF with a placeholder like "Page N of
XXX" and after the file has been created, dates and all, perhaps edit it
programmatically and replace all instances of XXX with something of the same
length like " 23" as there seem to be tools like the pdftools package that
let you get the number of pages. I have no idea if some program, perhaps
external, can do that and retain the date you want.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Dennis Fisher
Sent: Friday, December 1, 2023 3:53 PM
To: r-help at r-project.org
Subject: [R] adding "Page X of XX" to PDFs

OS X
R 4.3.1

Colleagues

I often create multipage PDFs [pdf()] in which the text "Page X" appears in
the margin.  These PDFs are created automatically using a massive R script.

One of my clients requested that I change this to:
	Page X of XX 
where XX is the total number of pages.  

I don't know the number of expected pages so I can't think of any clever way
to do this.  I suppose that I could create the PDF, find out the number of
pages, then have a second pass in which the R script was fed the number of
pages.  However, there is one disadvantage to this -- the original PDF
contains a timestamp on each page -- the new version would have a different
timestamp -- so I would prefer to not use this approach.

Has anyone thought of some terribly clever way to solve this problem?

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From po|c1410 @end|ng |rom gm@||@com  Sat Dec  2 23:37:44 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Sat, 2 Dec 2023 22:37:44 +0000
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <010b01da256f$cb6ee150$624ca3f0$@gmail.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
 <010b01da256f$cb6ee150$624ca3f0$@gmail.com>
Message-ID: <CA+etgPntPL-1RSUreZZGr5YpaJQFJ+E8mk4ZswaLMmThEN4eHQ@mail.gmail.com>

You could easily omit the Page X of xX, but leave the timestamp

Then add Page X of XX programmatically using pdftools or some similar pdf
command line tools.

On Sat, 2 Dec 2023, 22:35 , <avi.e.gross at gmail.com> wrote:

> Having read all of the replies, it seems there are solutions for the
> question and the OP points out that some solutions such as making the
> document twice will affect the creation date.
>
> I suspect the additional time to do so is seconds or at most minutes so it
> may not be a big deal.
>
> But what about the idea of creating a PDF with a placeholder like "Page N
> of
> XXX" and after the file has been created, dates and all, perhaps edit it
> programmatically and replace all instances of XXX with something of the
> same
> length like " 23" as there seem to be tools like the pdftools package that
> let you get the number of pages. I have no idea if some program, perhaps
> external, can do that and retain the date you want.
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dennis Fisher
> Sent: Friday, December 1, 2023 3:53 PM
> To: r-help at r-project.org
> Subject: [R] adding "Page X of XX" to PDFs
>
> OS X
> R 4.3.1
>
> Colleagues
>
> I often create multipage PDFs [pdf()] in which the text "Page X" appears in
> the margin.  These PDFs are created automatically using a massive R script.
>
> One of my clients requested that I change this to:
>         Page X of XX
> where XX is the total number of pages.
>
> I don't know the number of expected pages so I can't think of any clever
> way
> to do this.  I suppose that I could create the PDF, find out the number of
> pages, then have a second pass in which the R script was fed the number of
> pages.  However, there is one disadvantage to this -- the original PDF
> contains a timestamp on each page -- the new version would have a different
> timestamp -- so I would prefer to not use this approach.
>
> Has anyone thought of some terribly clever way to solve this problem?
>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Dec  3 00:14:38 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 2 Dec 2023 18:14:38 -0500
Subject: [R] adding "Page X of XX" to PDFs
In-Reply-To: <CA+etgPntPL-1RSUreZZGr5YpaJQFJ+E8mk4ZswaLMmThEN4eHQ@mail.gmail.com>
References: <960162E8-0227-4745-AAF4-D8DF6BC36204@plessthan.com>
 <010b01da256f$cb6ee150$624ca3f0$@gmail.com>
 <CA+etgPntPL-1RSUreZZGr5YpaJQFJ+E8mk4ZswaLMmThEN4eHQ@mail.gmail.com>
Message-ID: <322220d8-aa51-48ea-a376-818e18394852@gmail.com>

On 02/12/2023 5:37 p.m., CALUM POLWART wrote:
> You could easily omit the Page X of xX, but leave the timestamp
> 
> Then add Page X of XX programmatically using pdftools or some similar pdf
> command line tools.

You don't need to use command line tools -- I showed how to do it by 
creating an R Markdown document with each page of the PDF on a numbered 
page of the result.

Here's a minor improvement of my post:

    ---
    title: "Numbered"
    output:
      pdf_document:
        extra_dependencies: ["pdfpages", "fancyhdr", "lastpage"]
    ---

    \cfoot{Page \thepage\ of \pageref{LastPage}}

    \addtocounter{page}{-1}

    \includepdf[pages={1-},pagecommand={\thispagestyle{fancy}}]{Rplots.pdf}


This works regardless of the number of pages in Rplots.pdf.

Duncan Murdoch

> 
> On Sat, 2 Dec 2023, 22:35 , <avi.e.gross at gmail.com> wrote:
> 
>> Having read all of the replies, it seems there are solutions for the
>> question and the OP points out that some solutions such as making the
>> document twice will affect the creation date.
>>
>> I suspect the additional time to do so is seconds or at most minutes so it
>> may not be a big deal.
>>
>> But what about the idea of creating a PDF with a placeholder like "Page N
>> of
>> XXX" and after the file has been created, dates and all, perhaps edit it
>> programmatically and replace all instances of XXX with something of the
>> same
>> length like " 23" as there seem to be tools like the pdftools package that
>> let you get the number of pages. I have no idea if some program, perhaps
>> external, can do that and retain the date you want.
>>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dennis Fisher
>> Sent: Friday, December 1, 2023 3:53 PM
>> To: r-help at r-project.org
>> Subject: [R] adding "Page X of XX" to PDFs
>>
>> OS X
>> R 4.3.1
>>
>> Colleagues
>>
>> I often create multipage PDFs [pdf()] in which the text "Page X" appears in
>> the margin.  These PDFs are created automatically using a massive R script.
>>
>> One of my clients requested that I change this to:
>>          Page X of XX
>> where XX is the total number of pages.
>>
>> I don't know the number of expected pages so I can't think of any clever
>> way
>> to do this.  I suppose that I could create the PDF, find out the number of
>> pages, then have a second pass in which the R script was fed the number of
>> pages.  However, there is one disadvantage to this -- the original PDF
>> contains a timestamp on each page -- the new version would have a different
>> timestamp -- so I would prefer to not use this approach.
>>
>> Has anyone thought of some terribly clever way to solve this problem?
>>
>> Dennis
>>
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Sun Dec  3 13:26:49 2023
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (NP))
Date: Sun, 3 Dec 2023 12:26:49 +0000
Subject: [R] Try reproduce glmm by hand
In-Reply-To: <f0d28e51-b515-4880-aa55-70af47e8dbc9@yahoo.fr>
References: <f0d28e51-b515-4880-aa55-70af47e8dbc9.ref@yahoo.fr>
 <f0d28e51-b515-4880-aa55-70af47e8dbc9@yahoo.fr>
Message-ID: <AS8PR08MB9193E36010607807831C8B408B87A@AS8PR08MB9193.eurprd08.prod.outlook.com>

Dear Marc,

Plugging the BLUPs into the likelihood isn't going to give you the ll of the model. You need to integrate over the random effect.

intfun <- function(nu, xi, mi, pred, theta)
   dbinom(xi, xi+mi, plogis(nu)) * dnorm(nu, pred, theta)

lli <- rep(NA, nrow(df))

for (i in 1:nrow(df)) {
   lli[i] <- log(integrate(intfun, xi=df[i,1], mi=df[i,2], pred=fixep[1] + fixep[2]*x[i], theta=par$theta, lower=-Inf, upper=Inf)$value)
}

-sum(lli)

Best,
Wolfgang

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Marc Girondot via R-
> help
> Sent: Saturday, December 2, 2023 17:36
> To: Marc Girondot via R-help <r-help at r-project.org>
> Subject: [R] Try reproduce glmm by hand
>
> Dear all,
>
> In order to be sure I understand glmm correctly, I try to reproduce by
> hand a simple result. Here is a reproducible code. The questions are in
> _________________
>
> Of course I have tried to find the solution using internet but I was not
> able to find a solution. I have also tried to follow glmer but it is
> very complicated code!
>
> Thanks for any help.
>
> Marc
>
> # Generate set of df with nb successes and failures
> # and ID being A, B or C (the random effect)
> # and x being the fixed effect
> set.seed(1)
> df <- rbind(matrix(data = c(sample(x=5:30, size=40, replace = TRUE),
> rep(10, 40)), ncol=2),
>              matrix(data = c(sample(x=10:30, size=40, replace = TRUE),
> rep(10, 40)), ncol=2),
>              matrix(data = c(sample(x=20:30, size=40, replace = TRUE),
> rep(10, 40)), ncol=2))
> ID <- as.factor(c(rep("A", 40), rep("B", 40), rep("C", 40)))
> x <- c(runif(40, min=10, max=30), runif(40, min=20, max=30), runif(40,
> min=40, max=60))
> x <- (x-min(x))/(max(x)-min(x))
>
> # In g0, I have the results of the glmm
> library(lme4)
> g0 <- glmer(formula = df ~ x + (1 | ID), family =
> binomial(link="logit"), nAGQ=1)
> -logLik(g0) # 'log Lik.' 268.0188 (df=3)
> # I get the fitted parameters
> fixep <- fixef(g0)
> par <- getME(g0, c("theta","beta"))
> # _______________________________________________________________________
> # Question 1: how theta is converted into the specific effect on
> (intercept) for the random effect ?
> # Then how a theta parameter is converted into intercepts?
> # _______________________________________________________________________
> intercepts <- ranef(g0)$ID
>
> # This part is ok, the predict is correct
> pfit <- 1-c(1/(1+exp(fixep["(Intercept)"]+intercepts["A",
> 1]+x[ID=="A"]*fixep["x"])),
>    1/(1+exp(fixep["(Intercept)"]+intercepts["B",
> 1]+x[ID=="B"]*fixep["x"])),
>    1/(1+exp(fixep["(Intercept)"]+intercepts["C", 1]+x[ID=="C"]*fixep["x"])))
>
> predict(g0, type = "response")
>
> # _______________________________________________________________________
> # Why I obtain 266.4874 and not 268.0188 as in -logLik(g0)?
> # _______________________________________________________________________
> -sum(dbinom(x=df[, 1], size=df[, 1]+df[, 2], prob=pfit, log=TRUE)) #
> 266.4874

From rb@er @end|ng |rom @t@u@edu  Sun Dec  3 17:38:55 2023
From: rb@er @end|ng |rom @t@u@edu (Robert Baer)
Date: Sun, 3 Dec 2023 10:38:55 -0600
Subject: [R] back tick names with predict function
In-Reply-To: <240E71BB-E054-4F8A-99C1-8F905FAFBC49@gmail.com>
References: <495ef0b7-b017-4aa2-afb0-5c2b6ab4e647@atsu.edu>
 <b25f20f0-c196-4897-8ea3-2a3e5f1a48ff@sapo.pt>
 <ca3d2bde-4426-4a41-9d9f-93e60fc66a55@sapo.pt>
 <84461035-4232-4112-82cf-bba5e65d03eb@atsu.edu>
 <CAGxFJbTbwg21cz+v4ooaD7BhuH8vD-Jj1fHtE-dDw+ChxZnKcg@mail.gmail.com>
 <240E71BB-E054-4F8A-99C1-8F905FAFBC49@gmail.com>
Message-ID: <fa5936f9-0df6-4ae4-a345-9dacc59cc343@atsu.edu>


On 12/1/2023 11:47 AM, peter dalgaard wrote:
> Also, and possibly more constructively, when you get an error like
>   
>> CI.c = predict(mod2, data.frame( `plant-density` = x), interval = 'c')  # fail
> Error in eval(predvars, data, env) : object 'plant-density' not found
>
> you should check your assumptions. Does "newdata" actually contain a columnn called "plant-density":

Great advice/strategy. Thanks!


>> head(data.frame( `plant-density` = x))
>    plant.density
> 1      65.00000
> 2      65.11912
> 3      65.23824
> 4      65.35736
> 5      65.47648
> 6      65.59560
> I.e., it doesn't. So check help for data.frame and looking for something with names.
>
>> On 1 Dec 2023, at 01:47 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> "Thank you Rui.  I didn't know about the check.names = FALSE argument.
>>> Another good reminder to always read help, but I'm not sure I understood
>>> what help to read in this case"
>> ?data.frame , of course, which says:
>>
>> "check.names
>>
>> logical. If TRUE then the names of the variables in the data frame are
>> checked to ensure that they are syntactically valid variable names and
>> are not duplicated. If necessary they are adjusted (by make.names) so
>> that they are. "
>>
>> -- Bert
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @gutreuter @end|ng |rom gm@||@com  Mon Dec  4 19:41:47 2023
From: @gutreuter @end|ng |rom gm@||@com (Steve Gutreuter)
Date: Mon, 04 Dec 2023 13:41:47 -0500
Subject: [R] Unable to add the CRAN apt repository
Message-ID: <7264967851e2e8abe381a5e52b5615e4a14d06f5.camel@gmail.com>

I just upgraded from Linux Mint 20 to 21 and am no longer able to add the CRAN
Ubuntu repository to my list of repositories. ?I am getting:

$> sudo /usr/bin/add-apt-repository "deb
https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/"
$> sudo apt update
Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease
Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease
Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease
Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease
Ign:5 http://packages.linuxmint.com victoria InRelease
Hit:6 http://packages.linuxmint.com victoria Release
Ign:8 https://cloud.r-project.org/bin/linux/ubuntu victoria-cran40/ InRelease
Err:9 https://cloud.r-project.org/bin/linux/ubuntu victoria-cran40/ Release
404 Not Found [IP: 108.139.15.91 443]
Reading package lists... Done
E: The repository 'https://cloud.r-project.org/bin/linux/ubuntu victoria-cran40/
Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore
disabled by default.

Any hints will be much appreciated!

-- 
Steve Gutreuter


	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Dec  4 19:57:26 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 4 Dec 2023 21:57:26 +0300
Subject: [R] Unable to add the CRAN apt repository
In-Reply-To: <7264967851e2e8abe381a5e52b5615e4a14d06f5.camel@gmail.com>
References: <7264967851e2e8abe381a5e52b5615e4a14d06f5.camel@gmail.com>
Message-ID: <20231204215726.67ec69e3@Tarkus>

On Mon, 04 Dec 2023 13:41:47 -0500
Steve Gutreuter <sgutreuter at gmail.com> wrote:

> $> sudo /usr/bin/add-apt-repository "deb  
> https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release
> -cs)-cran40/"

Looks like `lsb_release -cs` returns a Mint codename for you.
Thankfully, since we know that Linux Mint 21 is based on Ubuntu 22.04
"Jammy Jellyfish", it should be possible to replace $(lsb_release -cs)
with jammy when running the command. Does the jammy-cran40/
subdirectory work for you?

-- 
Best regards,
Ivan


From edd @end|ng |rom deb|@n@org  Mon Dec  4 19:58:37 2023
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 4 Dec 2023 12:58:37 -0600
Subject: [R] Unable to add the CRAN apt repository
In-Reply-To: <7264967851e2e8abe381a5e52b5615e4a14d06f5.camel@gmail.com>
References: <7264967851e2e8abe381a5e52b5615e4a14d06f5.camel@gmail.com>
Message-ID: <25966.8541.656984.67304@rob.eddelbuettel.com>


Steve,

The better list for such questions is r-sig-debian.

On 4 December 2023 at 13:41, Steve Gutreuter wrote:
| I just upgraded from Linux Mint 20 to 21 and am no longer able to add the CRAN
| Ubuntu repository to my list of repositories. ?I am getting:
| 
| $> sudo /usr/bin/add-apt-repository "deb
| https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/"
| $> sudo apt update
| Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease
| Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease
| Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease
| Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease
| Ign:5 http://packages.linuxmint.com victoria InRelease
| Hit:6 http://packages.linuxmint.com victoria Release
| Ign:8 https://cloud.r-project.org/bin/linux/ubuntu victoria-cran40/ InRelease
| Err:9 https://cloud.r-project.org/bin/linux/ubuntu victoria-cran40/ Release
| 404 Not Found [IP: 108.139.15.91 443]
| Reading package lists... Done
| E: The repository 'https://cloud.r-project.org/bin/linux/ubuntu victoria-cran40/
| Release' does not have a Release file.
| N: Updating from such a repository can't be done securely, and is therefore
| disabled by default.

There is no such thing as 'victoria-cran40' at these servers.

Use jammy-cran40 if you want the Ubuntu 22.04 binaries, otherwise use
focal-cran40 for Ubuntu 20.04.

Dirk


| Any hints will be much appreciated!
| 
| -- 
| Steve Gutreuter
| 
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
| and provide commented, minimal, self-contained, reproducible code.

-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From @gutreuter @end|ng |rom gm@||@com  Mon Dec  4 20:08:52 2023
From: @gutreuter @end|ng |rom gm@||@com (Steve Gutreuter)
Date: Mon, 04 Dec 2023 14:08:52 -0500
Subject: [R] Unable to add the CRAN apt repository
In-Reply-To: <20231204215726.67ec69e3@Tarkus>
References: <7264967851e2e8abe381a5e52b5615e4a14d06f5.camel@gmail.com>
 <20231204215726.67ec69e3@Tarkus>
Message-ID: <6af0a64de4cff479bdf11e5b3890ff4ed09537d2.camel@gmail.com>

Thanks! ?"jammy" made it work. ?

For some reason, ?lsb_release -cs is returning "victoria" rather than "jammy",
and

$> sudo apt update
Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease 
Ign:2 http://packages.linuxmint.com victoria InRelease 
Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB] 
Hit:4 http://packages.linuxmint.com victoria Release 
Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB] 
Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease 
Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease
[3,626 B] 
Get:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [41.2
kB]

A Mint problem?

?
On Mon, 2023-12-04 at 21:57 +0300, Ivan Krylov wrote:
> On Mon, 04 Dec 2023 13:41:47 -0500
> Steve Gutreuter <sgutreuter at gmail.com> wrote:
> 
> > $> sudo /usr/bin/add-apt-repository "deb? 
> > https://cloud.r-project.org/bin/linux/ubuntu?$(lsb_release
> > -cs)-cran40/"
> 
> Looks like `lsb_release -cs` returns a Mint codename for you.
> Thankfully, since we know that Linux Mint 21 is based on Ubuntu 22.04
> "Jammy Jellyfish", it should be possible to replace $(lsb_release -cs)
> with jammy when running the command. Does the jammy-cran40/
> subdirectory work for you?
> 

	[[alternative HTML version deleted]]


From @gutreuter @end|ng |rom gm@||@com  Mon Dec  4 21:14:52 2023
From: @gutreuter @end|ng |rom gm@||@com (Steve Gutreuter)
Date: Mon, 04 Dec 2023 15:14:52 -0500
Subject: [R] Unable to add the CRAN apt repository
In-Reply-To: <6af0a64de4cff479bdf11e5b3890ff4ed09537d2.camel@gmail.com>
References: <7264967851e2e8abe381a5e52b5615e4a14d06f5.camel@gmail.com>
 <20231204215726.67ec69e3@Tarkus>
 <6af0a64de4cff479bdf11e5b3890ff4ed09537d2.camel@gmail.com>
Message-ID: <8e112823ebb81df281e97a29765768dc71f9a4ea.camel@gmail.com>

Yes, thanks.

On Mon, 2023-12-04 at 14:08 -0500, Steve Gutreuter wrote:
> Thanks! ?"jammy" made it work. ?
> 
> For some reason, ?lsb_release -cs is returning "victoria" rather than "jammy",
> and
> 
> $> sudo apt update
> Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease 
> Ign:2 http://packages.linuxmint.com victoria InRelease 
> Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB] 
> Hit:4 http://packages.linuxmint.com victoria Release 
> Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB] 
> Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease 
> Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease
> [3,626 B] 
> Get:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages
> [41.2 kB]
> 
> A Mint problem?
> 
> ?
> On Mon, 2023-12-04 at 21:57 +0300, Ivan Krylov wrote:
> > On Mon, 04 Dec 2023 13:41:47 -0500
> > Steve Gutreuter <sgutreuter at gmail.com> wrote:
> > 
> > > $> sudo /usr/bin/add-apt-repository "deb? 
> > > https://cloud.r-project.org/bin/linux/ubuntu?$(lsb_release
> > > -cs)-cran40/"
> > 
> > Looks like `lsb_release -cs` returns a Mint codename for you.
> > Thankfully, since we know that Linux Mint 21 is based on Ubuntu 22.04
> > "Jammy Jellyfish", it should be possible to replace $(lsb_release -cs)
> > with jammy when running the command. Does the jammy-cran40/
> > subdirectory work for you?
> > 

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Dec  4 23:10:49 2023
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leo Mada)
Date: Mon, 4 Dec 2023 22:10:49 +0000
Subject: [R] Fit NLE - was:  computer algebra in R
Message-ID: <HE1P192MB0089CF9BF4C34E3C92BAEEC38486A@HE1P192MB0089.EURP192.PROD.OUTLOOK.COM>

Fit NLE - was: [R] computer algebra in R
Original post:
https://stat.ethz.ch/pipermail/r-help/2023-November/478619.html

Dear Kornad,

I think I have started to understand what you try to achieve. The problem is to fit a NLE and compute the parameters of the NL-Eq. I have included the R Help-list back in the loop, as I am not an expert in optimization.

Goal:
y ~ I0 +  IHD * hd + ID * d;
where:
y = given vector of measurements;
x = given vector of values;
I0, IHD, ID, kd = parameters to optimize;
hd = satisfies a polynomial of order 3;

As d = d0 - hd, the previous formula can be written:
y ~ I0 + ID * d0 +  (IHD - ID) * hd;

f(x, hd, kd) = 0,
where f = a polynomial of order 3 in hd and order 2 in kd;
d0 (and other components of the polynomial) = given constants;

1) First Approach
I would back-substitute hd into the polynomial:
hd = (y - I0 - ID*d0) / (IHD - ID);

f(x, hd, kd) becomes then f(x, y, kd, I0, ID, IHD) = 0;
- f is order 3 in y;

You could fit:
(y^3) ~ f(x, y, kd, I0, ID, IHD) - y^3,
where you subtract the y^3 term from the function f, and add the (y^3) values as a new columng to the data.frame:
data.frame(y3 = y^3, y=y, x=x)

If the values of y are versy small (abs(y) << 1), then it may be wiser to fit:
y ~ f(x, y^2, y^3, kd, I0, ID, IHD) - (y-term);

But I am not an expert in these problems. Other R-users may be more helpful.

2.) Approach 2: Math
I feel that the problem can be solved quasy-exactly as well. It is much harder with 4 parameters to optimize:
- one needs to compute the 4 partial derivatives;
- solve the resulting system of 4 polynomial equations;

The system is polynomial; although it looks ugly and I am not inclined to do such calculations myself.

I hope that you can get more useful answers from the R help-list.

Sincerely,

Leonard

	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Wed Dec  6 05:13:34 2023
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Wed, 6 Dec 2023 07:43:34 +0330
Subject: [R] Volume of polygon
Message-ID: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>

 Dear all;
I am trying to calculate the volume of a polygon shapefile according to a
DEM raster. I have provided some codes at the end of this email.I dont know
if the codes are correct or not. Following this, I have another question
too.
I want to know if the volume of the reservoir rises or doubles, what would
be the elevation?
I would be more than happy if anyone could help me.
Sincerely

"
library(raster)
library(terra)
library(exactextractr)
library(dplyr)
library(sf)
r <- raster("Base.tif")
p <- shapefile("p.shp")
r <- crop(r, p)
r <- mask(r, p)
x <- exact_extract(r, p, coverage_area = TRUE)

x1 = as.data.frame(x[1])
head(x1)
x1 = na.omit(x1)

x1$Height = max(x1[,1]) - x1[,1]

x1$Vol = x1[,2] * x1[,3]

sum(x1$Vol)

"

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Dec  6 06:09:12 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 5 Dec 2023 21:09:12 -0800
Subject: [R] Volume of polygon
In-Reply-To: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>
References: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>
Message-ID: <CAGxFJbRYrXTh5aTWcNDcZv+vg4ah01eKedCnXDuMonEyUTpbig@mail.gmail.com>

The volume of a polygon  = 0.  Polyhedra  have volumes.

This may be irrelevant, but if the lake is cylindrical == constant cross
sectional area at all depths, then height doubles when the volume does and
vice versa.  Otherwise you have to know how area varies with height or use
more sensible approximations thereto.

Cheers,
Bert

On Tue, Dec 5, 2023, 20:13 javad bayat <j.bayat194 at gmail.com> wrote:

>  Dear all;
> I am trying to calculate the volume of a polygon shapefile according to a
> DEM raster. I have provided some codes at the end of this email.I dont know
> if the codes are correct or not. Following this, I have another question
> too.
> I want to know if the volume of the reservoir rises or doubles, what would
> be the elevation?
> I would be more than happy if anyone could help me.
> Sincerely
>
> "
> library(raster)
> library(terra)
> library(exactextractr)
> library(dplyr)
> library(sf)
> r <- raster("Base.tif")
> p <- shapefile("p.shp")
> r <- crop(r, p)
> r <- mask(r, p)
> x <- exact_extract(r, p, coverage_area = TRUE)
>
> x1 = as.data.frame(x[1])
> head(x1)
> x1 = na.omit(x1)
>
> x1$Height = max(x1[,1]) - x1[,1]
>
> x1$Vol = x1[,2] * x1[,3]
>
> sum(x1$Vol)
>
> "
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Wed Dec  6 06:24:30 2023
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Wed, 6 Dec 2023 08:54:30 +0330
Subject: [R] Volume of polygon
In-Reply-To: <CAGxFJbRYrXTh5aTWcNDcZv+vg4ah01eKedCnXDuMonEyUTpbig@mail.gmail.com>
References: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>
 <CAGxFJbRYrXTh5aTWcNDcZv+vg4ah01eKedCnXDuMonEyUTpbig@mail.gmail.com>
Message-ID: <CANTxAm+7p8gqAiL6LLLNFWCxd4a-XZLoqHtoUa-7A+FNQcH9kQ@mail.gmail.com>

Dear Bert;
Thank you for your reply. The reservoir is not cylindrica. This is the
table I have created from the data extracted.
Maybe there is a way to get the relation between Elevation, Area and Volume
to get the elevation at a specific Volume.
Sincerely

    value        Area       Height      Vol
3   2183      89.52593    125 11190.74
5   2181      98.92991    127 12564.10
6   2180     154.64484    128 19794.54
7   2181     123.92825    127 15738.89
9   2183      82.42211    125 10302.76
10  2183     150.12180    125 18765.23

On Wed, Dec 6, 2023 at 8:39?AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> The volume of a polygon  = 0.  Polyhedra  have volumes.
>
> This may be irrelevant, but if the lake is cylindrical == constant cross
> sectional area at all depths, then height doubles when the volume does and
> vice versa.  Otherwise you have to know how area varies with height or use
> more sensible approximations thereto.
>
> Cheers,
> Bert
>
> On Tue, Dec 5, 2023, 20:13 javad bayat <j.bayat194 at gmail.com> wrote:
>
>>  Dear all;
>> I am trying to calculate the volume of a polygon shapefile according to a
>> DEM raster. I have provided some codes at the end of this email.I dont
>> know
>> if the codes are correct or not. Following this, I have another question
>> too.
>> I want to know if the volume of the reservoir rises or doubles, what would
>> be the elevation?
>> I would be more than happy if anyone could help me.
>> Sincerely
>>
>> "
>> library(raster)
>> library(terra)
>> library(exactextractr)
>> library(dplyr)
>> library(sf)
>> r <- raster("Base.tif")
>> p <- shapefile("p.shp")
>> r <- crop(r, p)
>> r <- mask(r, p)
>> x <- exact_extract(r, p, coverage_area = TRUE)
>>
>> x1 = as.data.frame(x[1])
>> head(x1)
>> x1 = na.omit(x1)
>>
>> x1$Height = max(x1[,1]) - x1[,1]
>>
>> x1$Vol = x1[,2] * x1[,3]
>>
>> sum(x1$Vol)
>>
>> "
>>
>> --
>> Best Regards
>> Javad Bayat
>> M.Sc. Environment Engineering
>> Alternative Mail: bayat194 at yahoo.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Dec  6 06:38:56 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 05 Dec 2023 21:38:56 -0800
Subject: [R] Volume of polygon
In-Reply-To: <CAGxFJbRYrXTh5aTWcNDcZv+vg4ah01eKedCnXDuMonEyUTpbig@mail.gmail.com>
References: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>
 <CAGxFJbRYrXTh5aTWcNDcZv+vg4ah01eKedCnXDuMonEyUTpbig@mail.gmail.com>
Message-ID: <BFAC5A36-2435-4DA5-BA56-3E365D070677@dcn.davis.ca.us>

A raster is just a matrix of elevations. Each element of that matrix has a horizontal area. If you subtract that elevation from a reference elevation and zero out all negative values then you are left with a bunch of rectangular parallelopipeds of varying height. Add those heights up and multiply by the scalar area of the parallelopipeds and you have the volume. Repeat this for various elevations and form a set of estimates of volume vs elevation. You can use approxfun or splinefun to create a function from those points for more general use.

There are some subtleties such as converting between elevation and depth, and whether you are concerned about disjoint depressions (they would not drain)... but OP really should have read the posting guide and asked this question on R-sig-geo mailing list.

On December 5, 2023 9:09:12 PM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>The volume of a polygon  = 0.  Polyhedra  have volumes.
>
>This may be irrelevant, but if the lake is cylindrical == constant cross
>sectional area at all depths, then height doubles when the volume does and
>vice versa.  Otherwise you have to know how area varies with height or use
>more sensible approximations thereto.
>
>Cheers,
>Bert
>
>On Tue, Dec 5, 2023, 20:13 javad bayat <j.bayat194 at gmail.com> wrote:
>
>>  Dear all;
>> I am trying to calculate the volume of a polygon shapefile according to a
>> DEM raster. I have provided some codes at the end of this email.I dont know
>> if the codes are correct or not. Following this, I have another question
>> too.
>> I want to know if the volume of the reservoir rises or doubles, what would
>> be the elevation?
>> I would be more than happy if anyone could help me.
>> Sincerely
>>
>> "
>> library(raster)
>> library(terra)
>> library(exactextractr)
>> library(dplyr)
>> library(sf)
>> r <- raster("Base.tif")
>> p <- shapefile("p.shp")
>> r <- crop(r, p)
>> r <- mask(r, p)
>> x <- exact_extract(r, p, coverage_area = TRUE)
>>
>> x1 = as.data.frame(x[1])
>> head(x1)
>> x1 = na.omit(x1)
>>
>> x1$Height = max(x1[,1]) - x1[,1]
>>
>> x1$Vol = x1[,2] * x1[,3]
>>
>> sum(x1$Vol)
>>
>> "
>>
>> --
>> Best Regards
>> Javad Bayat
>> M.Sc. Environment Engineering
>> Alternative Mail: bayat194 at yahoo.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Dec  6 14:52:21 2023
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 6 Dec 2023 08:52:21 -0500
Subject: [R] Volume of polygon
In-Reply-To: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>
References: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>
Message-ID: <CAM_vjukykiHT=QE_0LZeFwdhfUkem9iQ=+VTyYBEiVfuJkhUiQ@mail.gmail.com>

Hi,

As already mentioned, this is a great topic for R-sig-geo, where you'd
probably get specialist answers like the lake morphology package
https://cran.r-project.org/web/packages/lakemorpho/index.html which is
explicitly designed for this kind of question.

Sarah

On Tue, Dec 5, 2023 at 11:13?PM javad bayat <j.bayat194 at gmail.com> wrote:
>
>  Dear all;
> I am trying to calculate the volume of a polygon shapefile according to a
> DEM raster. I have provided some codes at the end of this email.I dont know
> if the codes are correct or not. Following this, I have another question
> too.
> I want to know if the volume of the reservoir rises or doubles, what would
> be the elevation?
> I would be more than happy if anyone could help me.
> Sincerely
>
> "
> library(raster)
> library(terra)
> library(exactextractr)
> library(dplyr)
> library(sf)
> r <- raster("Base.tif")
> p <- shapefile("p.shp")
> r <- crop(r, p)
> r <- mask(r, p)
> x <- exact_extract(r, p, coverage_area = TRUE)
>
> x1 = as.data.frame(x[1])
> head(x1)
> x1 = na.omit(x1)
>
> x1$Height = max(x1[,1]) - x1[,1]
>
> x1$Vol = x1[,2] * x1[,3]
>
> sum(x1$Vol)
>
> "
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Dec  6 14:55:01 2023
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 6 Dec 2023 08:55:01 -0500
Subject: [R] Volume of polygon
In-Reply-To: <CAM_vjukykiHT=QE_0LZeFwdhfUkem9iQ=+VTyYBEiVfuJkhUiQ@mail.gmail.com>
References: <CANTxAm+oRDseOwO+mOx9K4CuirQ3XrkgLAG46qBxuHvhAZT7xA@mail.gmail.com>
 <CAM_vjukykiHT=QE_0LZeFwdhfUkem9iQ=+VTyYBEiVfuJkhUiQ@mail.gmail.com>
Message-ID: <CAM_vjuk9zLR7V-wXr4wFxX7etjdrrW6G5TQz6dFGUdFGRikbbg@mail.gmail.com>

There's also an excellent discussion of various methods with R code
here: https://dewey.dunnington.ca/post/2019/bathymetry-lake-volume-estimation-using-r/


On Wed, Dec 6, 2023 at 8:52?AM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
> Hi,
>
> As already mentioned, this is a great topic for R-sig-geo, where you'd
> probably get specialist answers like the lake morphology package
> https://cran.r-project.org/web/packages/lakemorpho/index.html which is
> explicitly designed for this kind of question.
>
> Sarah
>
> On Tue, Dec 5, 2023 at 11:13?PM javad bayat <j.bayat194 at gmail.com> wrote:
> >
> >  Dear all;
> > I am trying to calculate the volume of a polygon shapefile according to a
> > DEM raster. I have provided some codes at the end of this email.I dont know
> > if the codes are correct or not. Following this, I have another question
> > too.
> > I want to know if the volume of the reservoir rises or doubles, what would
> > be the elevation?
> > I would be more than happy if anyone could help me.
> > Sincerely
> >
> > "
> > library(raster)
> > library(terra)
> > library(exactextractr)
> > library(dplyr)
> > library(sf)
> > r <- raster("Base.tif")
> > p <- shapefile("p.shp")
> > r <- crop(r, p)
> > r <- mask(r, p)
> > x <- exact_extract(r, p, coverage_area = TRUE)
> >
> > x1 = as.data.frame(x[1])
> > head(x1)
> > x1 = na.omit(x1)
> >
> > x1$Height = max(x1[,1]) - x1[,1]
> >
> > x1$Vol = x1[,2] * x1[,3]
> >
> > sum(x1$Vol)
> >
> > "
> >
> > --
> > Best Regards
> > Javad Bayat
> > M.Sc. Environment Engineering
> > Alternative Mail: bayat194 at yahoo.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.sarahgoslee.com



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From y@||neren42 @end|ng |rom gm@||@com  Wed Dec  6 14:52:03 2023
From: y@||neren42 @end|ng |rom gm@||@com (=?UTF-8?Q?Eren_Yal=C4=B1n?=)
Date: Wed, 6 Dec 2023 16:52:03 +0300
Subject: [R] How to calculate relative risk from GAM model in mgcv package?
Message-ID: <CAEEWTq+1oprpVmFVw5+8cUr-6KoJF63Cht9qyvmR1hq55dGz6A@mail.gmail.com>

Hi R users,I am a beginner in the use of R. I need urgent help for my
thesis study.
<https://stats.stackexchange.com/posts/633206/timeline>

I have daily air pollution parameters PM10, PM2.5 CO, NO2, SO2, and O3. I
also have daily hospital admission numbers. Taking into account the effect
of weekends and holidays, I would like to used generalised additive model
(GAM) to explore the relationship between daily patients admissions, and
air pollution parameters. I would like tu use mgcv package. How to get
overall relative risk and 95%CI for every pollutant?

I don't know if it's correct but here are the codes I used:

install.packages("mgcv")

library(mgcv)

data=read.csv2(file.choose(),header=TRUE)

data$date <- as.Date(data$date, format="%d.%m.%Y")


data$weekend <- factor(data$weekend)


data$holiday <- factor(data$holiday)


model <- gam(adm ~ s(PM10, k = 5) + s(PM2.5, k = 5) + s(CO, k = 5) + s(NO2,
k = 5) + s(SO2, k = 5) + s(O3, k = 5) + weekend + holiday, family =
quasipoisson(link = "log"), data = data, method = "REML")

pred <- predict.gam (model, type = "response")

relative_risk <- exp(pred$fit)

However, when I look at the results, it calculates RR for 365 days
separately.

How can I get a result like the table 4 in this article (
https://pubmed.ncbi.nlm.nih.gov/36161569/)? There is only one RR
calculation for each pollutant.

I would be very grateful if you could help me. Thank you.


Eren YALIN M.D., Research Assistant

 . University, Medical Faculty,  Department of Public Health

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Thu Dec  7 17:21:59 2023
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Thu, 7 Dec 2023 16:21:59 +0000
Subject: [R] Convert character date time to R date-time variable.
Message-ID: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>

Colleagues,

I have a matrix of character data that represents date and time. The format of each element of the matrix is 
"2020-09-17_00:00:00"
How can I convert the elements into a valid R date-time constant?

Thank you,
John



John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;

Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?

PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;

Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




From tebert @end|ng |rom u||@edu  Thu Dec  7 17:29:09 2023
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 7 Dec 2023 16:29:09 +0000
Subject: [R] Convert character date time to R date-time variable.
In-Reply-To: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <CH3PR22MB45145C7A9CD905524B849FE3CF8BA@CH3PR22MB4514.namprd22.prod.outlook.com>

Look at the lubridate package in R.
Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
Sent: Thursday, December 7, 2023 11:22 AM
To: r-help at r-project.org (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] Convert character date time to R date-time variable.

[External Email]

Colleagues,

I have a matrix of character data that represents date and time. The format of each element of the matrix is "2020-09-17_00:00:00"
How can I convert the elements into a valid R date-time constant?

Thank you,
John



John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;

Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;

PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;

Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Dec  7 17:30:54 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 7 Dec 2023 16:30:54 +0000
Subject: [R] Convert character date time to R date-time variable.
In-Reply-To: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <4512d1f1-a973-4c98-9116-3e767b2fcece@sapo.pt>

?s 16:21 de 07/12/2023, Sorkin, John escreveu:
> Colleagues,
> 
> I have a matrix of character data that represents date and time. The format of each element of the matrix is
> "2020-09-17_00:00:00"
> How can I convert the elements into a valid R date-time constant?
> 
> Thank you,
> John
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> 
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
> 
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
> 
> Senior Statistician University of Maryland Center for Vascular Research;
> 
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Coerce with ?as.POSIXct
Don't forget the underscore in the format.


as.POSIXct("2020-09-17_00:00:00", format = "%Y-%m-%d_%H:%M:%S")


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Dec  7 17:36:06 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 7 Dec 2023 16:36:06 +0000
Subject: [R] Convert character date time to R date-time variable.
In-Reply-To: <4512d1f1-a973-4c98-9116-3e767b2fcece@sapo.pt>
References: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
 <4512d1f1-a973-4c98-9116-3e767b2fcece@sapo.pt>
Message-ID: <16182ab5-3314-42a0-984f-c6623041901f@sapo.pt>

?s 16:30 de 07/12/2023, Rui Barradas escreveu:
> ?s 16:21 de 07/12/2023, Sorkin, John escreveu:
>> Colleagues,
>>
>> I have a matrix of character data that represents date and time. The 
>> format of each element of the matrix is
>> "2020-09-17_00:00:00"
>> How can I convert the elements into a valid R date-time constant?
>>
>> Thank you,
>> John
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine, University of Maryland School of Medicine;
>>
>> Associate Director for Biostatistics and Informatics, Baltimore VA 
>> Medical Center Geriatrics Research, Education, and Clinical Center;
>>
>> PI?Biostatistics and Informatics Core, University of Maryland School 
>> of Medicine Claude D. Pepper Older Americans Independence Center;
>>
>> Senior Statistician University of Maryland Center for Vascular Research;
>>
>> Division of Gerontology and Paliative Care,
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> Cell phone 443-418-5382
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
> 
> Coerce with ?as.POSIXct
> Don't forget the underscore in the format.
> 
> 
> as.POSIXct("2020-09-17_00:00:00", format = "%Y-%m-%d_%H:%M:%S")
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
Sorry, I forgot:


lubridate::ymd_hms("2020-09-17_00:00:00")


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From edd @end|ng |rom deb|@n@org  Thu Dec  7 17:59:20 2023
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Thu, 7 Dec 2023 10:59:20 -0600
Subject: [R] Convert character date time to R date-time variable.
In-Reply-To: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <25969.63976.169836.954059@rob.eddelbuettel.com>


`anytime` was written for this:

  > anytime::anytime("2020-09-17_00:00:00")
  [1] "2020-09-17 CDT"
  > class(anytime::anytime("2020-09-17_00:00:00"))
  [1] "POSIXct" "POSIXt" 
  > 

Dirk


-- 
dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From konr@d_kr@emer @end|ng |rom y@hoo@de  Fri Dec  8 08:21:16 2023
From: konr@d_kr@emer @end|ng |rom y@hoo@de (Konrad)
Date: Fri, 8 Dec 2023 08:21:16 +0100
Subject: [R] Fit NLE - was:  computer algebra in R
In-Reply-To: <HE1P192MB0089CF9BF4C34E3C92BAEEC38486A@HE1P192MB0089.EURP192.PROD.OUTLOOK.COM>
References: <HE1P192MB0089CF9BF4C34E3C92BAEEC38486A@HE1P192MB0089.EURP192.PROD.OUTLOOK.COM>
Message-ID: <850fb7b0-3e69-4615-a540-d86a94fad011@yahoo.de>

Dear all,


first I would like to thank Leo for his help and advice. My sincere 
apologies for the delayed response; regrettably, I overlooked the email.


In order to characterize the problem a bit better I want to give 
additional information and clarify the point where I have problems.


First of all the equation system is defined as:

h0 = h + hd + hg,
d0 = d + hd,
ga0 = ga + hg,
kga = hg/(h*ga),
kd = hd/(h*d)


The aim is to fit a non-linear equation in the form: signal ~ I0 + IHD * 
hd + ID * d.


The parameters which should be identified/optimized are: I0, ID, IHD and 
kd. However, the only information known is kga (33600.0), h0 
(0.0000208), d0 (0.000079) and the guest concentration (= ga0).

In Mathematica the equation system is repeatedly solved for hd and d. 
First the system 0 = h + hd + hga, 33600. = d + hd, ga0 = ga + hga, 
0.000079 = hga/(ga*h), 0.0000208 = hd/(d*h) is passed to the Eliminate 
function which eliminates four variables. In the case for hd the 
variables h, d, hga and ga are eliminated. The resulting system is:? 
3.71035392*^12 + 2.635566*^8*hd - 3783.*hd^2 == ga0*(-1.72536*^8 + 
5135.*hd). Afterwards this system is used by a numerical solver to get 
the result of hd.

My problem is how to replicate the Eliminate function in R. Or is it 
possible to solely solve the system numerically?


Thanks a lot in advance.

All the best,

Konrad


On 04.12.23 23:10, Leo Mada wrote:
> Fit NLE - was: [R] computer algebra in R
> Original post:
> https://stat.ethz.ch/pipermail/r-help/2023-November/478619.html
>
> Dear Kornad,
>
> I think I have started to understand what you try to achieve. The 
> problem is to fit a NLE and compute the parameters of the NL-Eq. I 
> have included the R Help-list back in the loop, as I am not an expert 
> in optimization.
>
> Goal:
> y ~ I0 + ?IHD * hd + ID * d;
> where:
> y = given vector of measurements;
> x = given vector of values;
> I0, IHD, ID, kd = parameters to optimize;
> hd = satisfies a polynomial of order 3;
>
> As d = d0 - hd, the previous formula can be written:
> y ~ I0 + ID * d0 + ?(IHD - ID) * hd;
>
> f(x, hd, kd) = 0,
> where f = a polynomial of order 3 in hd and order 2 in kd;
> d0 (and other components of the polynomial) = given constants;
>
> 1) First Approach
> I would back-substitute hd into the polynomial:
> hd = (y - I0 - ID*d0) / (IHD - ID);
>
> f(x, hd, kd) becomes then f(x, y, kd, I0, ID, IHD) = 0;
> - f is order 3 in y;
>
> You could fit:
> (y^3) ~ f(x, y, kd, I0, ID, IHD) - y^3,
> where you subtract the y^3 term from the function f, and add the (y^3) 
> values as a new columng to the data.frame:
> data.frame(y3 = y^3, y=y, x=x)
>
> If the values of y are versy small (abs(y) << 1), then it may be wiser 
> to fit:
> y ~ f(x, y^2, y^3, kd, I0, ID, IHD) - (y-term);
>
> But I am not an expert in these problems. Other R-users may be more 
> helpful.
>
> 2.) Approach 2: Math
> I feel that the problem can be solved quasy-exactly as well. It is 
> much harder with 4 parameters to optimize:
> - one needs to compute the 4 partial derivatives;
> - solve the resulting system of 4 polynomial equations;
>
> The system is polynomial; although it looks ugly and I am not inclined 
> to do such calculations myself.
>
> I hope that you can get more useful answers from the R help-list.
>
> Sincerely,
>
> Leonard
	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Dec  8 09:09:24 2023
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 8 Dec 2023 09:09:24 +0100
Subject: [R] Convert character date time to R date-time variable.
In-Reply-To: <CH3PR22MB45145C7A9CD905524B849FE3CF8BA@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
 <CH3PR22MB45145C7A9CD905524B849FE3CF8BA@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <25970.53044.912449.243759@stat.math.ethz.ch>

>>>>> Ebert,Timothy Aaron 
>>>>>     on Thu, 7 Dec 2023 16:29:09 +0000 writes:

    > Look at the lubridate package in R.  Regards, Tim

Absolutely *un*needed here !! - as others mention in this
thread.

Very simple with base R:

  > strptime("2020-09-17_00:00:00", format = "%Y-%m-%d_%H:%M:%S")
  [1] "2020-09-17 CEST"
  > 

(in my time zone).
 
    > -----Original Message----- From: R-help
    > <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
    > Sent: Thursday, December 7, 2023 11:22 AM To:
    > r-help at r-project.org (r-help at r-project.org)
    > <r-help at r-project.org> Subject: [R] Convert character date
    > time to R date-time variable.

    > [External Email]

    > Colleagues,

    > I have a matrix of character data that represents date and
    > time. The format of each element of the matrix is
    > "2020-09-17_00:00:00" How can I convert the elements into
    > a valid R date-time constant?

    > Thank you, John



    > John David Sorkin M.D., Ph.D.  Professor of Medicine,
    > University of Maryland School of Medicine;

    > Associate Director for Biostatistics and Informatics,
    > Baltimore VA Medical Center Geriatrics Research,
    > Education, and Clinical Center;

    > PI Biostatistics and Informatics Core, University of
    > Maryland School of Medicine Claude D. Pepper Older
    > Americans Independence Center;

    > Senior Statistician University of Maryland Center for
    > Vascular Research;

    > Division of Gerontology and Paliative Care, 10 North
    > Greene Street GRECC (BT/18/GR) Baltimore, MD 21201-1524
    > Cell phone 443-418-5382



    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.r-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Dec  8 22:30:07 2023
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 8 Dec 2023 13:30:07 -0800
Subject: [R] Convert character date time to R date-time variable.
In-Reply-To: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <4d9c6da9-4b31-f8d0-c4cd-e9de8f4e464e@comcast.net>


On 12/7/23 08:21, Sorkin, John wrote:
> Colleagues,
>
> I have a matrix of character data that represents date and time. The format of each element of the matrix is
> "2020-09-17_00:00:00"
> How can I convert the elements into a valid R date-time constant?

You will not be able to store these datetime values in an R matrix, at 
least as class POSIXct. You could with class POSIXlt, but I've not seen 
it used before but it does appear possible since matrices can contain 
lists.

R matrices do no provide the capability to assign attributes, so only 
atomic types and lists can be elements. If you wanted to maintain the 
same structure, your first step might be to coerce to a data.frame and 
then proceed, or to first construct a vector and then use as the first 
argument to `matrix`.


Best;

David

>
> Thank you,
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
>
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
>
> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
>
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Dec  8 22:56:10 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 8 Dec 2023 16:56:10 -0500
Subject: [R] Convert character date time to R date-time variable.
In-Reply-To: <4d9c6da9-4b31-f8d0-c4cd-e9de8f4e464e@comcast.net>
References: <DM6PR03MB5049EA075B8AB0D040AB0FBEE28BA@DM6PR03MB5049.namprd03.prod.outlook.com>
 <4d9c6da9-4b31-f8d0-c4cd-e9de8f4e464e@comcast.net>
Message-ID: <ed18cc13-7836-416d-bd72-1a9bc03798ea@gmail.com>

On 08/12/2023 4:30 p.m., David Winsemius wrote:
> 
> On 12/7/23 08:21, Sorkin, John wrote:
>> Colleagues,
>>
>> I have a matrix of character data that represents date and time. The format of each element of the matrix is
>> "2020-09-17_00:00:00"
>> How can I convert the elements into a valid R date-time constant?
> 
> You will not be able to store these datetime values in an R matrix, at
> least as class POSIXct. You could with class POSIXlt, but I've not seen
> it used before but it does appear possible since matrices can contain
> lists.
> 
> R matrices do no provide the capability to assign attributes, so only
> atomic types and lists can be elements. If you wanted to maintain the
> same structure, your first step might be to coerce to a data.frame and
> then proceed, or to first construct a vector and then use as the first
> argument to `matrix`.

The general sentiment is correct (it's hard to put POSIXct elements in 
matrices), but it's not impossible.  Almost all R objects can have 
attributes.

For example,

   m <- matrix(Sys.time(), 2,2)

converts the time to a numerical value, but you can view it as a POSIXlt 
object using

   class(m) <- c("POSIXct", class(m))

Subsetting works, e.g. m[1,1] is a time, etc.

Duncan Murdoch
> 
> 
> Best;
> 
> David
> 
>>
>> Thank you,
>> John
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine, University of Maryland School of Medicine;
>>
>> Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
>>
>> PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
>>
>> Senior Statistician University of Maryland Center for Vascular Research;
>>
>> Division of Gerontology and Paliative Care,
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> Cell phone 443-418-5382
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Dec  8 23:57:45 2023
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 8 Dec 2023 22:57:45 +0000
Subject: [R] Convert two-dimensional array into a three-dimensional array.
Message-ID: <DM6PR03MB504979641A471930217570CCE28AA@DM6PR03MB5049.namprd03.prod.outlook.com>

Colleagues

I want to convert a 10x2 array:
# create a 10x2 matrix.
datavals <- matrix(nrow=10,ncol=2)
datavals[,] <- rep(c(1,2),10)+c(rnorm(10),rnorm(10))
datavals

into a 10x3 array, ThreeDArray, dim(10,2,10).

The values storede in  ThreeDArray's first dimensions will be the data stored in datavalues.
ThreeDArray[i,,] <- datavals[i,]

The values storede in  ThreeDArray's second dimensions will be the data stored in datavalues.
ThreeDArray[,j,] <- datavals[,j]

The data stored in ThreeDArray[,,1] will be 1, 
The data stored in ThreeDArray[,,2] will be 2.
 . . . 
The data stored in ThreeDArray[,,10] will be 10.

I have no idea how to code the coversion of the 10x2 matrix into a 10,2,10 array.
I may be able to acomplish my mission by coding each line of the plan described above,
but there has to be a more efficient and elegant way to accompish my goal.

Many thanks for your help!
John




John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;

Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;?

PI?Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;

Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




From bgunter@4567 @end|ng |rom gm@||@com  Sat Dec  9 00:51:04 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 8 Dec 2023 15:51:04 -0800
Subject: [R] 
 Convert two-dimensional array into a three-dimensional array.
In-Reply-To: <DM6PR03MB504979641A471930217570CCE28AA@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <DM6PR03MB504979641A471930217570CCE28AA@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <CAGxFJbQCTczZjuh+CAupi2gtZ_yYLkkzRQq6OJesu7Kp51JYww@mail.gmail.com>

OK. I'm not getting what you want, so feel free to ignore this if you think
I've missed the point completely and don't want to waste your time. Won't
be my first time clueless.

A 3-D array can be  thought of as as a "pile" of 2-D flats, so a 10 x 2 x
10 array consists of 10 2-d flats, each 10 x 2. So tell me what you want
the first 10x2 flat to contain, then the second, etc.  Here is a print
representation of a 2 x 4 x 3 array that might help:

> array(1:24, dim = c(2,4,3))
, , 1

     [,1] [,2] [,3] [,4]
[1,]    1    3    5    7
[2,]    2    4    6    8

, , 2

     [,1] [,2] [,3] [,4]
[1,]    9   11   13   15
[2,]   10   12   14   16

, , 3

     [,1] [,2] [,3] [,4]
[1,]   17   19   21   23
[2,]   18   20   22   24

FWIW, it sounds to me like you just do something like:

> dval <- matrix(1:8, nrow = 2)
> dval
     [,1] [,2] [,3] [,4]
[1,]    1    3    5    7
[2,]    2    4    6    8
> ar <- array(dval, dim = c(2,4,3))
> ar
, , 1

     [,1] [,2] [,3] [,4]
[1,]    1    3    5    7
[2,]    2    4    6    8

, , 2

     [,1] [,2] [,3] [,4]
[1,]    1    3    5    7
[2,]    2    4    6    8

, , 3

     [,1] [,2] [,3] [,4]
[1,]    1    3    5    7
[2,]    2    4    6    8

since the 3rd array index itself provides the values you refer to. But this
doesn't make sense to me, so I've probably misinterpreted.

Cheers,
Bert


On Fri, Dec 8, 2023 at 2:58?PM Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> Colleagues
>
> I want to convert a 10x2 array:
> # create a 10x2 matrix.
> datavals <- matrix(nrow=10,ncol=2)
> datavals[,] <- rep(c(1,2),10)+c(rnorm(10),rnorm(10))
> datavals
>
> into a 10x3 array, ThreeDArray, dim(10,2,10).
>
> The values storede in  ThreeDArray's first dimensions will be the data
> stored in datavalues.
> ThreeDArray[i,,] <- datavals[i,]
>
> The values storede in  ThreeDArray's second dimensions will be the data
> stored in datavalues.
> ThreeDArray[,j,] <- datavals[,j]
>
> The data stored in ThreeDArray[,,1] will be 1,
> The data stored in ThreeDArray[,,2] will be 2.
>  . . .
> The data stored in ThreeDArray[,,10] will be 10.
>
> I have no idea how to code the coversion of the 10x2 matrix into a 10,2,10
> array.
> I may be able to acomplish my mission by coding each line of the plan
> described above,
> but there has to be a more efficient and elegant way to accompish my goal.
>
> Many thanks for your help!
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
>
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical
> Center Geriatrics Research, Education, and Clinical Center;
>
> PI Biostatistics and Informatics Core, University of Maryland School of
> Medicine Claude D. Pepper Older Americans Independence Center;
>
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@|@h@||endr@9 @end|ng |rom gm@||@com  Fri Dec  8 11:38:51 2023
From: p@|@h@||endr@9 @end|ng |rom gm@||@com (shailendra pal)
Date: Fri, 8 Dec 2023 16:08:51 +0530
Subject: [R] regarding CCA plot
Message-ID: <CADXfUh3jtFrvKcsfKhyCaPcGq=k82j8yNQo_AUuwuYMHJ6j=ew@mail.gmail.com>

Hii rstudio members
I am learning rstudio, For my manuscript I am trying to plot CCA using
species and environmental data. But I am getting error like
Error in cca.default(sptrans, envtrans) :

  all row sums must be >0 in the community data matrix


*My code is like *
library(vegan)
library(ggplot2)
library(dplyr)
rassspec<-read.csv("C:/Users/hp/Desktop/R_data/rassspec.csv", header=T,
stringsAsFactors=T)
rassevee<-read.csv("C:/Users/hp/Desktop/R_data/rassenv.csv", header=T,
stringsAsFactors=T)
sptrans <- decostand(rassspec, "hellinger")
envtrans <- decostand(rassevee, "hellinger")

vare.cca <- cca(sptrans, envtrans)


Any kind of help will be appreciable
Thanking you
regards

Shailendra Pal

Research Scholar
Plant Ecology Lab
(Prof. S.C. Garkoti)
School of Environmental Sciences
JNU, New Delhi
110067

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Dec  9 15:38:38 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 9 Dec 2023 17:38:38 +0300
Subject: [R] regarding CCA plot
In-Reply-To: <CADXfUh3jtFrvKcsfKhyCaPcGq=k82j8yNQo_AUuwuYMHJ6j=ew@mail.gmail.com>
References: <CADXfUh3jtFrvKcsfKhyCaPcGq=k82j8yNQo_AUuwuYMHJ6j=ew@mail.gmail.com>
Message-ID: <20231209173838.1f1f8a0b@Tarkus>

Dear Shailendra Pal,

Welcome to the R-help mailing list! Most of us are not members of
RStudio in any way. Your problem is also purely about programming in R,
so you've come to the right place. You have also done the right thing
by showing us the code.

On Fri, 8 Dec 2023 16:08:51 +0530
shailendra pal <palshailendra9 at gmail.com> wrote:

> vare.cca <- cca(sptrans, envtrans)

> Error in cca.default(sptrans, envtrans) :
>   all row sums must be >0 in the community data matrix

One of the most important tools provided by R is its online help
system. Use it to look up the documentation for the function you're
having problems with. You can prepend a question mark to most function
calls and get a help page in response; failing that, help('cca') should
also work. Here's what it says:

>> ## Default S3 method:
>> cca(X, Y, Z, ...)

>> X Community data matrix.
>> Y Constraining matrix, typically of environmental variables

In other words, the "community data matrix" mentioned in the error
message is your `sptrans` data.frame. The function complains that at
least some of the rows don't have a positive sum, which is a
requirement of the method. Can you spot the problem by looking at the
data or using rowSums()? 

-- 
Best regards,
Ivan


From b|og||@on @end|ng |rom gm@||@com  Sat Dec  9 15:58:22 2023
From: b|og||@on @end|ng |rom gm@||@com (Gilson Correia de Carvalho)
Date: Sat, 9 Dec 2023 11:58:22 -0300
Subject: [R] regarding CCA plot
In-Reply-To: <CADXfUh3jtFrvKcsfKhyCaPcGq=k82j8yNQo_AUuwuYMHJ6j=ew@mail.gmail.com>
References: <CADXfUh3jtFrvKcsfKhyCaPcGq=k82j8yNQo_AUuwuYMHJ6j=ew@mail.gmail.com>
Message-ID: <CAJ8F2HHtm=CLeeumfoyzoZ_Lza87WZWnYQOu-vDiwErQmksqYg@mail.gmail.com>

Dear Shailendra,

For me the problem is not related to R or Rstudio or even vegan. The CCA
analysis can not be done with denuded site, as the sum will be zero.

"all row sums must be >0 in the community data matrix"

Best regards,

GCC

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
N?o
cont?m v?rus.www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

Em s?b., 9 de dez. de 2023 ?s 06:50, shailendra pal <
palshailendra9 at gmail.com> escreveu:

> Hii rstudio members
> I am learning rstudio, For my manuscript I am trying to plot CCA using
> species and environmental data. But I am getting error like
> Error in cca.default(sptrans, envtrans) :
>
>   all row sums must be >0 in the community data matrix
>
>
> *My code is like *
> library(vegan)
> library(ggplot2)
> library(dplyr)
> rassspec<-read.csv("C:/Users/hp/Desktop/R_data/rassspec.csv", header=T,
> stringsAsFactors=T)
> rassevee<-read.csv("C:/Users/hp/Desktop/R_data/rassenv.csv", header=T,
> stringsAsFactors=T)
> sptrans <- decostand(rassspec, "hellinger")
> envtrans <- decostand(rassevee, "hellinger")
>
> vare.cca <- cca(sptrans, envtrans)
>
>
> Any kind of help will be appreciable
> Thanking you
> regards
>
> Shailendra Pal
>
> Research Scholar
> Plant Ecology Lab
> (Prof. S.C. Garkoti)
> School of Environmental Sciences
> JNU, New Delhi
> 110067
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Gilson Correia de Carvalho
----------------------------------------------------
Doutor em Ecologia *(PhD. in Ecology)*
Mestre em Ecologia e Biomonitoramento* (Master in Ecology and
Biomonitoring) *
Bacharel em Ci?ncias Biol?gicas *(Bachelor in Biological Sciences)*
CV Lattes: http://lattes.cnpq.br/8361386734266580
ResearcherID: F-8051-2014
Scopus Author ID: 35236290200
ORCID ID: https://orcid.org/0000-0003-1800-888X
Google Scholar: Rj5FlvYAAAAJ&hl
----------------------------------------------------
Chefe do Departamento de Biotecnologia (Head of the Department of
Biotechnology)
----------------------------------------------------
Professor Associado I *(Associate Professor Level I of IV)*
Departamento de Biotecnologia *(Department of Biotechnology)*
Instituto de Ci?ncias da Sa?de *(Institute of Health Sciences)*
Universidade Federal da Bahia
*(Federal University of Bahia)*
-----------------------------------------------------
S?cio-Cotista *(Shareholder)*
Holos Solu??es Ambientais Ltda
-----------------------------------------------------
Skype: bio_gilson
Hangouts: biogilson

	[[alternative HTML version deleted]]


From j@b@y@t194 @end|ng |rom gm@||@com  Sat Dec  9 19:50:18 2023
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Sat, 9 Dec 2023 22:20:18 +0330
Subject: [R] Linear model and approx function
Message-ID: <CANTxAm+gK=LLQ40_cQd+D3eEpO31Ki5UNk=+-33KB2i27oH22w@mail.gmail.com>

Dear all;

I have a dataframe with several columns. The columns are the elevation,
volume  and the area of the cells (which were placed inside a polygon). I
have extracted them from DEM raster to calculate the volume under polygon
and the elevation for a specific volume of the reservoir.

> head(x6,2)
  Elevation       Vol      Area     V_sum      A_sum
1 2145  13990.38  85.83053  13990.38   85.83053
2 2147  43129.18 267.88312  57119.56  353.71365

> tail(x6,2)
 Elevation      Vol      Area      V_sum    A_sum
158  2307 233.0276 233.02756 1771806968 15172603
159  2308   0.0000  71.65642 1771806968 15172674

I used a linear model to estimate the elevation for a specific volume, but
the codes do not work properly.

lm1 = lm(x6[,1]~x6[,4])
new_volume <- 3,000,000,000
pred_elev <- predict(lm1, newdata = data.frame(volume = new_volume))
pred_elev

The results just estimated for the 159 rows of the dataframe, not the new
volume.

> tail(pred_elev)
     154      155      156      157      158      159
2254.296 2254.296 2254.296 2254.296 2254.296 2254.296

Also I have used the approx function, but it does not work for the new
volume, too.

> a = x6[,1]
> b = x6[,4]
> estimate <- 3,000,000,000
> appro <- approx(b,a, xout = estimate)
> appro
$x
[1] 3e+09

$y
[1] NA

I do not know why it has happened.

Is there any way to do this?
Or maybe there is another way to do that.
I would be more than happy if anyone help me.

Sincerely

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Dec  9 20:11:33 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 9 Dec 2023 11:11:33 -0800
Subject: [R] Linear model and approx function
In-Reply-To: <CANTxAm+gK=LLQ40_cQd+D3eEpO31Ki5UNk=+-33KB2i27oH22w@mail.gmail.com>
References: <CANTxAm+gK=LLQ40_cQd+D3eEpO31Ki5UNk=+-33KB2i27oH22w@mail.gmail.com>
Message-ID: <CAGxFJbRAehDW2JtjEMkYdn-kJiZ0em1x+YYirojK99+=ZyaAEQ@mail.gmail.com>

1. You should regress Elevation on Volume, no?

2. You are calling lm incorrectly for prediction. Please read ?lm and
related links carefully and/or consult a tutorial. R-Help is really not the
first place you should look for this sort of detailed info.

3. I think this is what you want:

lm1 <- lm(Elevation ~ Vol, data = x6)  ## assuming (1) above is correct
d <- data.frame(Vol = 3000)  ## assuming (1) above is correct
predict(lm1, newdata = d)

Cheers,
Bert


On Sat, Dec 9, 2023 at 10:50?AM javad bayat <j.bayat194 at gmail.com> wrote:

> Dear all;
>
> I have a dataframe with several columns. The columns are the elevation,
> volume  and the area of the cells (which were placed inside a polygon). I
> have extracted them from DEM raster to calculate the volume under polygon
> and the elevation for a specific volume of the reservoir.
>
> > head(x6,2)
>   Elevation       Vol      Area     V_sum      A_sum
> 1 2145  13990.38  85.83053  13990.38   85.83053
> 2 2147  43129.18 267.88312  57119.56  353.71365
>
> > tail(x6,2)
>  Elevation      Vol      Area      V_sum    A_sum
> 158  2307 233.0276 233.02756 1771806968 15172603
> 159  2308   0.0000  71.65642 1771806968 15172674
>
> I used a linear model to estimate the elevation for a specific volume, but
> the codes do not work properly.
>
> lm1 = lm(x6[,1]~x6[,4])
> new_volume <- 3,000,000,000
> pred_elev <- predict(lm1, newdata = data.frame(volume = new_volume))
> pred_elev
>
> The results just estimated for the 159 rows of the dataframe, not the new
> volume.
>
> > tail(pred_elev)
>      154      155      156      157      158      159
> 2254.296 2254.296 2254.296 2254.296 2254.296 2254.296
>
> Also I have used the approx function, but it does not work for the new
> volume, too.
>
> > a = x6[,1]
> > b = x6[,4]
> > estimate <- 3,000,000,000
> > appro <- approx(b,a, xout = estimate)
> > appro
> $x
> [1] 3e+09
>
> $y
> [1] NA
>
> I do not know why it has happened.
>
> Is there any way to do this?
> Or maybe there is another way to do that.
> I would be more than happy if anyone help me.
>
> Sincerely
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sun Dec 10 09:59:48 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sun, 10 Dec 2023 11:59:48 +0300
Subject: [R] Fit NLE - was:  computer algebra in R
In-Reply-To: <850fb7b0-3e69-4615-a540-d86a94fad011@yahoo.de>
References: <HE1P192MB0089CF9BF4C34E3C92BAEEC38486A@HE1P192MB0089.EURP192.PROD.OUTLOOK.COM>
 <850fb7b0-3e69-4615-a540-d86a94fad011@yahoo.de>
Message-ID: <20231210115948.7cb70600@Tarkus>

? Fri, 8 Dec 2023 08:21:16 +0100
Konrad via R-help <r-help at r-project.org> ?????:

> My problem is how to replicate the Eliminate function in R.

While R does invite the user to "compute on the language", i.e. take R
expressions and function calls and work with them as with ordinary
variables [*], so far nobody wrote a complete computer algebra system in
R. Interfaces for other CASes do exist, but I haven't tried them.

> Or is it possible to solely solve the system numerically?

While it's less efficient to do so, it must be possible. For example,
the https://CRAN.R-project.org/package=nleqslv package does exactly
that.

> h0 = h + hd + hg,
> d0 = d + hd,
> ga0 = ga + hg,
> kga = hg/(h*ga),
> kd = hd/(h*d)
 
> The aim is to fit a non-linear equation in the form: signal ~ I0 +
> IHD * hd + ID * d.

> The parameters which should be identified/optimized are: I0, ID, IHD
> and kd. However, the only information known is kga (33600.0), h0 
> (0.0000208), d0 (0.000079) and the guest concentration (= ga0).

This doesn't quite agree with

> 0 = h + hd + hga,
> 33600. = d + hd,
> 0.000079 = hga/(ga*h),

...that you gave to Mathematica. Is it d0 = d + hd or kga = 33600. = d +
hd? kga = hg/(h*ga) or d0 = 0.000079 = hga/(ga*h)? What other equations
are missing?

The general approach is to take all the equations and write them down
as a vector of expressions that should be evaluate to 0 at solution,
then substitute() in the values of the constants and x[i] for
sequential values of `i` for variables:

fn <- function(x) NULL
body(fn) <- substitute(
 c( # equations go here
  h0  - h + hd + hg,
  d0  - d + hd,
  ga0 - ga + hg,
  kga - hg/(h*ga),
  kd  - hd/(h*d),
  # ...more equations...
  signal - I0 + IHD * hd + ID * d
 ),
 list(
  # knowns
  kga = 33600.0,
  h0 = 0.0000208,
  d0 = 0.000079,
  # assuming two more knowns live in same-named variables
  ga0 = ga0,
  signal = signal,
  # variables named so far
  I0 = quote(x[1]), ID = quote(x[2]),
  IHD = quote(x[3]), kd = quote(x[4])
  # ...more variables...
 )
)

The resulting function fn() takes a vector of variables and should
return a vector of zeroes at the solution. Try to solve it using
nleqslv::nleqslv(starting_guess, fn) or some of the functions from the
BB package.

-- 
Best regards,
Ivan

[*] For example, see this R package automatically differentiate
expressions when solving nonlinear least squares problems:
https://cran.r-project.org/package=nlsr/vignettes/nlsr-derivs.pdf


From rn|@boh @end|ng |rom gm@||@com  Sun Dec 10 11:38:02 2023
From: rn|@boh @end|ng |rom gm@||@com (Bob O'Hara)
Date: Sun, 10 Dec 2023 11:38:02 +0100
Subject: [R] reshape() not dropping varaibles
Message-ID: <CAN-Z0xX0ouaS3Njh12K6GVdxZ2j7vOnA8+Wb_yrAVtv=UYnrUA@mail.gmail.com>

Hi all!

I1m trying to re-format some data from long to wide format with reshape().
Specifically, the data has SURVEYDATE, which I want to be in the rows, and
COMMON_NAME which should be the columns. The entries should be TOTAL_CATCH.
The data has a bunch of other variables, which can be ignored.

When I run reshape(), it includes all of the variables, not just
TOTAL_CATCH:

Data <- read.csv("
https://conservancy.umn.edu/bitstream/handle/11299/227105/fish_data_raw.csv?sequence=6&isAllowed=y
")
Data.wide <- reshape(Data, direction = "wide",
                idvar = "SURVEYDATE", timevar = "COMMON_NAME",
                v.names = "TOTAL_CATCH")
names(Data.wide)

I tried with the example on the help page, which works fine:

# this works
Indometh$thing <- 1:nrow(Indometh)
wide <- reshape(Indometh, direction = "wide", idvar = "Subject",
                timevar = "time", v.names = "conc", sep= "_")
names(wide)

There are some obvious work-arounds and alternatives, but it would be nice
to have this sorted. Can anyone help?

Bob

Bob

-- 
Bob O'Hara
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +47 915 54 416
Journal of Negative Results - EEB: www.jnr-eeb.org

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Dec 10 16:35:17 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 10 Dec 2023 07:35:17 -0800
Subject: [R] reshape() not dropping varaibles
In-Reply-To: <CAN-Z0xX0ouaS3Njh12K6GVdxZ2j7vOnA8+Wb_yrAVtv=UYnrUA@mail.gmail.com>
References: <CAN-Z0xX0ouaS3Njh12K6GVdxZ2j7vOnA8+Wb_yrAVtv=UYnrUA@mail.gmail.com>
Message-ID: <CAGxFJbQj+-=qfT0-_mWV_FoFxxkzeA8B=oADFq9XnTeBvLfV5w@mail.gmail.com>

Posting a few rows, say 5, of your data using dput() along with the result
that you would like to get for those rows would help get you a quicker and
more accurate response, I believe. This is as suggested by the posting
guide, linked below, which you should read if you have not already.

-- Bert



On Sun, Dec 10, 2023 at 2:38?AM Bob O'Hara <rni.boh at gmail.com> wrote:

> Hi all!
>
> I1m trying to re-format some data from long to wide format with reshape().
> Specifically, the data has SURVEYDATE, which I want to be in the rows, and
> COMMON_NAME which should be the columns. The entries should be TOTAL_CATCH.
> The data has a bunch of other variables, which can be ignored.
>
> When I run reshape(), it includes all of the variables, not just
> TOTAL_CATCH:
>
> Data <- read.csv("
>
> https://conservancy.umn.edu/bitstream/handle/11299/227105/fish_data_raw.csv?sequence=6&isAllowed=y
> ")
> Data.wide <- reshape(Data, direction = "wide",
>                 idvar = "SURVEYDATE", timevar = "COMMON_NAME",
>                 v.names = "TOTAL_CATCH")
> names(Data.wide)
>
> I tried with the example on the help page, which works fine:
>
> # this works
> Indometh$thing <- 1:nrow(Indometh)
> wide <- reshape(Indometh, direction = "wide", idvar = "Subject",
>                 timevar = "time", v.names = "conc", sep= "_")
> names(wide)
>
> There are some obvious work-arounds and alternatives, but it would be nice
> to have this sorted. Can anyone help?
>
> Bob
>
> Bob
>
> --
> Bob O'Hara
> Institutt for matematiske fag
> NTNU
> 7491 Trondheim
> Norway
>
> Mobile: +47 915 54 416
> Journal of Negative Results - EEB: www.jnr-eeb.org
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Dec 10 18:21:24 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 10 Dec 2023 09:21:24 -0800
Subject: [R] reshape() not dropping varaibles
In-Reply-To: <CAGxFJbQj+-=qfT0-_mWV_FoFxxkzeA8B=oADFq9XnTeBvLfV5w@mail.gmail.com>
References: <CAN-Z0xX0ouaS3Njh12K6GVdxZ2j7vOnA8+Wb_yrAVtv=UYnrUA@mail.gmail.com>
 <CAGxFJbQj+-=qfT0-_mWV_FoFxxkzeA8B=oADFq9XnTeBvLfV5w@mail.gmail.com>
Message-ID: <E42E7629-1FF8-444B-8837-379B5A7C86E5@dcn.davis.ca.us>

It would be nice to see what OP wanted to end up with, but the link contained input data to experiment with.

The first problem is that if you are not interested in working with the whole set of columns then you need to only give a data frame with the columns you want to work with:

dta.wide <- reshape(
  Data[, c( "SURVEYDATE", "COMMON_NAME", "TOTAL_CATCH" ) ]
  , direction = "wide"
  , idvar = "SURVEYDATE"
  , timevar = "COMMON_NAME"
  , v.names = "TOTAL_CATCH"
)

Second, there are multiple rows of TOTAL_CATCH for each combination of SURVEYDATE and COMMON_NAME. reshape does not do math on the data... you have to resolve that yourself first by choosing how you want to turn a bunch of numbers into one... in this case I chose to sum them up:

Data.agg <- aggregate(
  TOTAL_CATCH ~ SURVEYDATE + COMMON_NAME
  , data = Data
  , FUN = sum
)
# the aggregate calculation implicitly leaves out columns you don't specify

dta.wide <- reshape(
  Data.agg
  , direction = "wide"
  , idvar = "SURVEYDATE"
  , timevar = "COMMON_NAME"
  , v.names = "TOTAL_CATCH"
)
Data.wide

On December 10, 2023 7:35:17 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Posting a few rows, say 5, of your data using dput() along with the result
>that you would like to get for those rows would help get you a quicker and
>more accurate response, I believe. This is as suggested by the posting
>guide, linked below, which you should read if you have not already.
>
>-- Bert
>
>
>
>On Sun, Dec 10, 2023 at 2:38?AM Bob O'Hara <rni.boh at gmail.com> wrote:
>
>> Hi all!
>>
>> I1m trying to re-format some data from long to wide format with reshape().
>> Specifically, the data has SURVEYDATE, which I want to be in the rows, and
>> COMMON_NAME which should be the columns. The entries should be TOTAL_CATCH.
>> The data has a bunch of other variables, which can be ignored.
>>
>> When I run reshape(), it includes all of the variables, not just
>> TOTAL_CATCH:
>>
>> Data <- read.csv("
>>
>> https://conservancy.umn.edu/bitstream/handle/11299/227105/fish_data_raw.csv?sequence=6&isAllowed=y
>> ")
>> Data.wide <- reshape(Data, direction = "wide",
>>                 idvar = "SURVEYDATE", timevar = "COMMON_NAME",
>>                 v.names = "TOTAL_CATCH")
>> names(Data.wide)
>>
>> I tried with the example on the help page, which works fine:
>>
>> # this works
>> Indometh$thing <- 1:nrow(Indometh)
>> wide <- reshape(Indometh, direction = "wide", idvar = "Subject",
>>                 timevar = "time", v.names = "conc", sep= "_")
>> names(wide)
>>
>> There are some obvious work-arounds and alternatives, but it would be nice
>> to have this sorted. Can anyone help?
>>
>> Bob
>>
>> Bob
>>
>> --
>> Bob O'Hara
>> Institutt for matematiske fag
>> NTNU
>> 7491 Trondheim
>> Norway
>>
>> Mobile: +47 915 54 416
>> Journal of Negative Results - EEB: www.jnr-eeb.org
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Dec 10 23:35:31 2023
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 10 Dec 2023 22:35:31 +0000 (UTC)
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
Message-ID: <1684699562.3682096.1702247731199@mail.yahoo.com>


Dear R-experts,

Here below my R code, as my X-axis is "year", I must be missing one or more steps! I am trying to get the regression line with the 95% confidence bands around the regression line. Any help would be appreciated.

Best,
S.


#############################################
library(ggplot2)
?
df=data.frame(year=factor(c("2012","2015","2018","2022")), score=c(495,493, 495, 474))
?
ggplot(df, aes(x=year, y=score)) + geom_point( ) + geom_smooth(method="lm", formula = score ~ factor(year), data = df) + labs(title="Standard linear regression for France", y="PISA score in mathematics") + ylim(470, 500)
#############################################


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Dec 10 23:50:56 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 10 Dec 2023 22:50:56 +0000
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <1684699562.3682096.1702247731199@mail.yahoo.com>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
Message-ID: <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>

?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
> 
> Dear R-experts,
> 
> Here below my R code, as my X-axis is "year", I must be missing one or more steps! I am trying to get the regression line with the 95% confidence bands around the regression line. Any help would be appreciated.
> 
> Best,
> S.
> 
> 
> #############################################
> library(ggplot2)
>   
> df=data.frame(year=factor(c("2012","2015","2018","2022")), score=c(495,493, 495, 474))
>   
> ggplot(df, aes(x=year, y=score)) + geom_point( ) + geom_smooth(method="lm", formula = score ~ factor(year), data = df) + labs(title="Standard linear regression for France", y="PISA score in mathematics") + ylim(470, 500)
> #############################################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

I don't see a reason why year should be a factor and the formula in 
geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
It still doesn't plot the CI's though. There's a warning and I am not 
understanding where it comes from. But the regression line is plotted.



ggplot(df, aes(x = as.numeric(year), y = score)) +
   geom_point() +
   geom_smooth(method = "lm", formula = y ~ x) +
   labs(
     title = "Standard linear regression for France",
     x = "Year",
     y = "PISA score in mathematics"
   ) +
   ylim(470, 500)
#> Warning message:
#> In max(ids, na.rm = TRUE) : no non-missing arguments to max; 
returning -Inf



Hope this helps,

Rui Barradas



-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 11 00:52:42 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 10 Dec 2023 15:52:42 -0800
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
Message-ID: <CAGxFJbQOaPgv9AcjE=+GDEF8+JuxKw6j3JtNNgSx1gn3KZCcPQ@mail.gmail.com>

This can easily be done using predict.lm to get the intervals (confidence
or prediction).
?predict.lm contains a plotting example using ?matplot from the graphics
package. Here's a somewhat verbose version for your example (first
converting Year to numeric, of course):

df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))

fitted <- lm(score ~ year, data = df)
with(df,
   matplot(x = year, y = cbind(score,predict(fitted,interval = 'conf',
level = .95))
            ,type = c('p', rep('l',3))
            ,pch = 16
            ,lty = c('blank','solid', 'dashed','dashed') ## or use numeric
values of 0,1,2,2
            ,lwd = c(0,2,1,1)
            ,col = c('black','darkblue', 'red','red')
            ,xlab = 'Year'
            ,ylab = 'Data with Fitted Line and Conf Intervals'

   )
)

Cheers,
Bert



On Sun, Dec 10, 2023 at 2:51?PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
> >
> > Dear R-experts,
> >
> > Here below my R code, as my X-axis is "year", I must be missing one or
> more steps! I am trying to get the regression line with the 95% confidence
> bands around the regression line. Any help would be appreciated.
> >
> > Best,
> > S.
> >
> >
> > #############################################
> > library(ggplot2)
> >
> > df=data.frame(year=factor(c("2012","2015","2018","2022")),
> score=c(495,493, 495, 474))
> >
> > ggplot(df, aes(x=year, y=score)) + geom_point( ) +
> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
> labs(title="Standard linear regression for France", y="PISA score in
> mathematics") + ylim(470, 500)
> > #############################################
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> I don't see a reason why year should be a factor and the formula in
> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
> It still doesn't plot the CI's though. There's a warning and I am not
> understanding where it comes from. But the regression line is plotted.
>
>
>
> ggplot(df, aes(x = as.numeric(year), y = score)) +
>    geom_point() +
>    geom_smooth(method = "lm", formula = y ~ x) +
>    labs(
>      title = "Standard linear regression for France",
>      x = "Year",
>      y = "PISA score in mathematics"
>    ) +
>    ylim(470, 500)
> #> Warning message:
> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
> returning -Inf
>
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From djnord|und @end|ng |rom gm@||@com  Mon Dec 11 23:27:35 2023
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Mon, 11 Dec 2023 14:27:35 -0800
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
Message-ID: <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>

On 12/10/2023 2:50 PM, Rui Barradas wrote:
> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>
>> Dear R-experts,
>>
>> Here below my R code, as my X-axis is "year", I must be missing one 
>> or more steps! I am trying to get the regression line with the 95% 
>> confidence bands around the regression line. Any help would be 
>> appreciated.
>>
>> Best,
>> S.
>>
>>
>> #############################################
>> library(ggplot2)
>> ? df=data.frame(year=factor(c("2012","2015","2018","2022")), 
>> score=c(495,493, 495, 474))
>> ? ggplot(df, aes(x=year, y=score)) + geom_point( ) + 
>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) + 
>> labs(title="Standard linear regression for France", y="PISA score in 
>> mathematics") + ylim(470, 500)
>> #############################################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> I don't see a reason why year should be a factor and the formula in 
> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
> It still doesn't plot the CI's though. There's a warning and I am not 
> understanding where it comes from. But the regression line is plotted.
>
>
>
> ggplot(df, aes(x = as.numeric(year), y = score)) +
> ? geom_point() +
> ? geom_smooth(method = "lm", formula = y ~ x) +
> ? labs(
> ??? title = "Standard linear regression for France",
> ??? x = "Year",
> ??? y = "PISA score in mathematics"
> ? ) +
> ? ylim(470, 500)
> #> Warning message:
> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max; 
> returning -Inf
>
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
After playing with this for a little while, I realized that the problem 
with plotting the confidence limits is the addition of ylim(470, 500).? 
The confidence values are outside the ylim values.? Remove the limits, 
or increase the range, and the confidence curves will plot.

Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


-- 
This email has been checked for viruses by Avast antivirus software.
www.avast.com


From bbo|ker @end|ng |rom gm@||@com  Mon Dec 11 23:31:40 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 11 Dec 2023 17:31:40 -0500
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
 <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>
Message-ID: <fb94049a-2822-4678-855f-3bf9abe04832@gmail.com>



On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>
>>> Dear R-experts,
>>>
>>> Here below my R code, as my X-axis is "year", I must be missing one 
>>> or more steps! I am trying to get the regression line with the 95% 
>>> confidence bands around the regression line. Any help would be 
>>> appreciated.
>>>
>>> Best,
>>> S.
>>>
>>>
>>> #############################################
>>> library(ggplot2)
>>> ? df=data.frame(year=factor(c("2012","2015","2018","2022")), 
>>> score=c(495,493, 495, 474))
>>> ? ggplot(df, aes(x=year, y=score)) + geom_point( ) + 
>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) + 
>>> labs(title="Standard linear regression for France", y="PISA score in 
>>> mathematics") + ylim(470, 500)
>>> #############################################
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> I don't see a reason why year should be a factor and the formula in 
>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>> It still doesn't plot the CI's though. There's a warning and I am not 
>> understanding where it comes from. But the regression line is plotted.
>>
>>
>>
>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>> ? geom_point() +
>> ? geom_smooth(method = "lm", formula = y ~ x) +
>> ? labs(
>> ??? title = "Standard linear regression for France",
>> ??? x = "Year",
>> ??? y = "PISA score in mathematics"
>> ? ) +
>> ? ylim(470, 500)
>> #> Warning message:
>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max; 
>> returning -Inf
>>
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
> After playing with this for a little while, I realized that the problem 
> with plotting the confidence limits is the addition of ylim(470, 500). 
> The confidence values are outside the ylim values.? Remove the limits, 
> or increase the range, and the confidence curves will plot.
> 
> Hope this is helpful,
> 
> Dan
> 

  Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)


From kev|n @end|ng |rom zembower@org  Tue Dec 12 12:15:31 2023
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Tue, 12 Dec 2023 11:15:31 +0000
Subject: [R] Advice on starting to analyze smokestack emissions?
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org>
Message-ID: <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>

Hello, all,

[Originally sent to r-sig-geo list, with no response. Cross-posting
here, in the hope of a wider audience. Anyone with any experience in
this topic? Thanks.]

I'm trying to get started analyzing the concentrations of smokestack
emissions. I don't have any professional background or training for
this; I'm just an old, retired guy who thinks playing with numbers is
fun.

A local funeral home in my neighborhood (less than 1200 ft from my
home) is proposing to construct a crematorium for human remains. I have
some experience with the tidycensus package and thought it might be
interesting to construct a model for the changes in concentrations of
the pollutants from the smokestack and, using recorded wind speeds and
directions, see which US Census blocks would be affected.

I have the US Government EPA SCREEN3 output on how concentration varies
with distance from the smokestack.
See?https://www.epa.gov/scram/air-quality-dispersion-modeling-screening-models#screen3
if curious. As a first task, I'd like to see if I can calculate similar
results in R. I'm aware of the 'plume' steady-state Gaussian dispersion
package
(https://rdrr.io/github/holstius/plume/f/inst/doc/plume-intro.pdf), but
am a little concerned that this package was last updated 11 years ago.

Do you have any recommendations for me on how to get started analyzing
this problem? Is 'plume' still the way to go? I'm aware that there are
many atmospheric dispersion models from the US EPA, but I was hoping to
keep my work within R, which I'm really enjoying using and learning
about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
ask questions about this topic?

Thanks for any advice or guidance you have for me.

-Kevin





From bgunter@4567 @end|ng |rom gm@||@com  Tue Dec 12 16:52:59 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 12 Dec 2023 07:52:59 -0800
Subject: [R] Advice on starting to analyze smokestack emissions?
In-Reply-To: <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org>
 <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
Message-ID: <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com>

You might also try the R-Sig-ecology list, though I would agree that it's
not clearly related. Still, air pollution effects...?

-- Bert

On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
r-help at r-project.org> wrote:

> Hello, all,
>
> [Originally sent to r-sig-geo list, with no response. Cross-posting
> here, in the hope of a wider audience. Anyone with any experience in
> this topic? Thanks.]
>
> I'm trying to get started analyzing the concentrations of smokestack
> emissions. I don't have any professional background or training for
> this; I'm just an old, retired guy who thinks playing with numbers is
> fun.
>
> A local funeral home in my neighborhood (less than 1200 ft from my
> home) is proposing to construct a crematorium for human remains. I have
> some experience with the tidycensus package and thought it might be
> interesting to construct a model for the changes in concentrations of
> the pollutants from the smokestack and, using recorded wind speeds and
> directions, see which US Census blocks would be affected.
>
> I have the US Government EPA SCREEN3 output on how concentration varies
> with distance from the smokestack.
> See
> https://www.epa.gov/scram/air-quality-dispersion-modeling-screening-models#screen3
> if curious. As a first task, I'd like to see if I can calculate similar
> results in R. I'm aware of the 'plume' steady-state Gaussian dispersion
> package
> (https://rdrr.io/github/holstius/plume/f/inst/doc/plume-intro.pdf), but
> am a little concerned that this package was last updated 11 years ago.
>
> Do you have any recommendations for me on how to get started analyzing
> this problem? Is 'plume' still the way to go? I'm aware that there are
> many atmospheric dispersion models from the US EPA, but I was hoping to
> keep my work within R, which I'm really enjoying using and learning
> about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> ask questions about this topic?
>
> Thanks for any advice or guidance you have for me.
>
> -Kevin
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Dec 12 22:19:12 2023
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 12 Dec 2023 21:19:12 +0000 (UTC)
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <fb94049a-2822-4678-855f-3bf9abe04832@gmail.com>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
 <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>
 <fb94049a-2822-4678-855f-3bf9abe04832@gmail.com>
Message-ID: <68588390.888662.1702415952477@mail.yahoo.com>

Dear Ben,
Dear Daniel,
Dear Rui,
Dear Bert,

Here below my R code.
I really appreciate all your comments. My R code is perfectly working but there is still something I would like to improve. The X-axis is showing ? 2012.5 ; ? 2015.0 ? ; ? 2017.5 ? ; ?2020.0
I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020). How to do??


#########
library(ggplot2)
?
df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))

ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +
?labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") + scale_y_continuous(limits=c(470,500),oob=scales::squish)
#########









Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com> a ?crit : 







On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>
>>> Dear R-experts,
>>>
>>> Here below my R code, as my X-axis is "year", I must be missing one 
>>> or more steps! I am trying to get the regression line with the 95% 
>>> confidence bands around the regression line. Any help would be 
>>> appreciated.
>>>
>>> Best,
>>> S.
>>>
>>>
>>> #############################################
>>> library(ggplot2)
>>> ? df=data.frame(year=factor(c("2012","2015","2018","2022")), 
>>> score=c(495,493, 495, 474))
>>> ? ggplot(df, aes(x=year, y=score)) + geom_point( ) + 
>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) + 
>>> labs(title="Standard linear regression for France", y="PISA score in 
>>> mathematics") + ylim(470, 500)
>>> #############################################
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> I don't see a reason why year should be a factor and the formula in 
>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>> It still doesn't plot the CI's though. There's a warning and I am not 
>> understanding where it comes from. But the regression line is plotted.
>>
>>
>>
>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>> ? geom_point() +
>> ? geom_smooth(method = "lm", formula = y ~ x) +
>> ? labs(
>> ??? title = "Standard linear regression for France",
>> ??? x = "Year",
>> ??? y = "PISA score in mathematics"
>> ? ) +
>> ? ylim(470, 500)
>> #> Warning message:
>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max; 
>> returning -Inf
>>
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
> After playing with this for a little while, I realized that the problem 
> with plotting the confidence limits is the addition of ylim(470, 500). 
> The confidence values are outside the ylim values.? Remove the limits, 
> or increase the range, and the confidence curves will plot.
> 
> Hope this is helpful,
> 
> Dan
> 

? Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bbo|ker @end|ng |rom gm@||@com  Tue Dec 12 23:14:39 2023
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 12 Dec 2023 17:14:39 -0500
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <68588390.888662.1702415952477@mail.yahoo.com>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
 <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>
 <fb94049a-2822-4678-855f-3bf9abe04832@gmail.com>
 <68588390.888662.1702415952477@mail.yahoo.com>
Message-ID: <CABghstQELa+tyiLQYwivChiuen-YzyE3OGBo9gQUJ_hF7MDx+g@mail.gmail.com>

Use scale_x_continuous() and specify your desired breaks

On Tue, Dec 12, 2023, 4:19 PM varin sacha <varinsacha at yahoo.fr> wrote:

> Dear Ben,
> Dear Daniel,
> Dear Rui,
> Dear Bert,
>
> Here below my R code.
> I really appreciate all your comments. My R code is perfectly working but
> there is still something I would like to improve. The X-axis is showing
> 2012.5 ;   2015.0   ;   2017.5   ;  2020.0
> I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020).
> How to do?
>
>
> #########
> library(ggplot2)
>
> df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))
>
> ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method =
> "lm", formula = y ~ x) +
>  labs(title = "Standard linear regression for France", x = "Year", y =
> "PISA score in mathematics") +
> scale_y_continuous(limits=c(470,500),oob=scales::squish)
> #########
>
>
>
>
>
>
>
>
>
> Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com>
> a ?crit :
>
>
>
>
>
>
>
> On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
> > On 12/10/2023 2:50 PM, Rui Barradas wrote:
> >> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
> >>>
> >>> Dear R-experts,
> >>>
> >>> Here below my R code, as my X-axis is "year", I must be missing one
> >>> or more steps! I am trying to get the regression line with the 95%
> >>> confidence bands around the regression line. Any help would be
> >>> appreciated.
> >>>
> >>> Best,
> >>> S.
> >>>
> >>>
> >>> #############################################
> >>> library(ggplot2)
> >>>   df=data.frame(year=factor(c("2012","2015","2018","2022")),
> >>> score=c(495,493, 495, 474))
> >>>   ggplot(df, aes(x=year, y=score)) + geom_point( ) +
> >>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
> >>> labs(title="Standard linear regression for France", y="PISA score in
> >>> mathematics") + ylim(470, 500)
> >>> #############################################
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >> Hello,
> >>
> >> I don't see a reason why year should be a factor and the formula in
> >> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
> >> It still doesn't plot the CI's though. There's a warning and I am not
> >> understanding where it comes from. But the regression line is plotted.
> >>
> >>
> >>
> >> ggplot(df, aes(x = as.numeric(year), y = score)) +
> >>   geom_point() +
> >>   geom_smooth(method = "lm", formula = y ~ x) +
> >>   labs(
> >>     title = "Standard linear regression for France",
> >>     x = "Year",
> >>     y = "PISA score in mathematics"
> >>   ) +
> >>   ylim(470, 500)
> >> #> Warning message:
> >> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
> >> returning -Inf
> >>
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >>
> > After playing with this for a little while, I realized that the problem
> > with plotting the confidence limits is the addition of ylim(470, 500).
> > The confidence values are outside the ylim values.  Remove the limits,
> > or increase the range, and the confidence curves will plot.
> >
> > Hope this is helpful,
> >
> > Dan
> >
>
>   Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rb@er @end|ng |rom @t@u@edu  Wed Dec 13 01:36:38 2023
From: rb@er @end|ng |rom @t@u@edu (Robert Baer)
Date: Tue, 12 Dec 2023 18:36:38 -0600
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <68588390.888662.1702415952477@mail.yahoo.com>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
 <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>
 <fb94049a-2822-4678-855f-3bf9abe04832@gmail.com>
 <68588390.888662.1702415952477@mail.yahoo.com>
Message-ID: <352cddfd-6db4-4715-bad1-2f5690d8dc29@atsu.edu>

coord_cartesian also seems to work for y, and including the breaks = .? 
How about:

df=data.frame(year= c(2012,2015,2018,2022),
 ????????????? score=c(495,493, 495, 474))

ggplot(df, aes(x = year, y = score)) +
 ? geom_point() +
 ? geom_smooth(method = "lm", formula = y ~ x) +
 ? labs(title = "Standard linear regression for France", x = "Year", y = 
"PISA score in mathematics") +
 ? coord_cartesian(ylim=c(470,500)) +
 ? scale_x_continuous(breaks = 2012:2022)

On 12/12/2023 3:19 PM, varin sacha via R-help wrote:
> Dear Ben,
> Dear Daniel,
> Dear Rui,
> Dear Bert,
>
> Here below my R code.
> I really appreciate all your comments. My R code is perfectly working but there is still something I would like to improve. The X-axis is showing ? 2012.5 ; ? 2015.0 ? ; ? 2017.5 ? ; ?2020.0
> I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020). How to do?
>
>
> #########
> library(ggplot2)
>   
> df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))
>
> ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +
>  ?labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") + scale_y_continuous(limits=c(470,500),oob=scales::squish)
> #########
>
>
>
>
>
>
>
>
>
> Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com> a ?crit :
>
>
>
>
>
>
>
> On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
>> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>> Dear R-experts,
>>>>
>>>> Here below my R code, as my X-axis is "year", I must be missing one
>>>> or more steps! I am trying to get the regression line with the 95%
>>>> confidence bands around the regression line. Any help would be
>>>> appreciated.
>>>>
>>>> Best,
>>>> S.
>>>>
>>>>
>>>> #############################################
>>>> library(ggplot2)
>>>>  ? df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>>> score=c(495,493, 495, 474))
>>>>  ? ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
>>>> labs(title="Standard linear regression for France", y="PISA score in
>>>> mathematics") + ylim(470, 500)
>>>> #############################################
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> Hello,
>>>
>>> I don't see a reason why year should be a factor and the formula in
>>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>>> It still doesn't plot the CI's though. There's a warning and I am not
>>> understanding where it comes from. But the regression line is plotted.
>>>
>>>
>>>
>>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>>  ? geom_point() +
>>>  ? geom_smooth(method = "lm", formula = y ~ x) +
>>>  ? labs(
>>>  ??? title = "Standard linear regression for France",
>>>  ??? x = "Year",
>>>  ??? y = "PISA score in mathematics"
>>>  ? ) +
>>>  ? ylim(470, 500)
>>> #> Warning message:
>>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>>> returning -Inf
>>>
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>> After playing with this for a little while, I realized that the problem
>> with plotting the confidence limits is the addition of ylim(470, 500).
>> The confidence values are outside the ylim values.? Remove the limits,
>> or increase the range, and the confidence curves will plot.
>>
>> Hope this is helpful,
>>
>> Dan
>>
>  ? Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Wed Dec 13 03:43:36 2023
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 13 Dec 2023 02:43:36 +0000
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <68588390.888662.1702415952477@mail.yahoo.com>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
 <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>
 <fb94049a-2822-4678-855f-3bf9abe04832@gmail.com>
 <68588390.888662.1702415952477@mail.yahoo.com>
Message-ID: <CH3PR22MB45144A83E3804933F8110101CF8DA@CH3PR22MB4514.namprd22.prod.outlook.com>

Change year to a factor. Doing it in ggplot will not change the original data.

ggplot(df, aes(x = as.factor(year), y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +  labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") +
scale_y_continuous(limits=c(470,500),oob=scales::squish)

Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of varin sacha via R-help
Sent: Tuesday, December 12, 2023 4:19 PM
To: r-help at r-project.org; Ben Bolker <bbolker at gmail.com>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence bands

[External Email]

Dear Ben,
Dear Daniel,
Dear Rui,
Dear Bert,

Here below my R code.
I really appreciate all your comments. My R code is perfectly working but there is still something I would like to improve. The X-axis is showing   2012.5 ;   2015.0   ;   2017.5   ;  2020.0
I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020). How to do?


#########
library(ggplot2)

df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))

ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +  labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") + scale_y_continuous(limits=c(470,500),oob=scales::squish)
#########









Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com> a ?crit :







On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>
>>> Dear R-experts,
>>>
>>> Here below my R code, as my X-axis is "year", I must be missing one
>>> or more steps! I am trying to get the regression line with the 95%
>>> confidence bands around the regression line. Any help would be
>>> appreciated.
>>>
>>> Best,
>>> S.
>>>
>>>
>>> #############################################
>>> library(ggplot2)
>>>   df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>> score=c(495,493, 495, 474))
>>>   ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df)
>>> + labs(title="Standard linear regression for France", y="PISA score
>>> in
>>> mathematics") + ylim(470, 500)
>>> #############################################
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://st/
>>> at.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl
>>> .edu%7C104a304ff93043a854a408dbfb5809c1%7C0d4da0f84a314d76ace60a6233
>>> 1e1b84%7C0%7C0%7C638380127776926039%7CUnknown%7CTWFpbGZsb3d8eyJWIjoi
>>> MC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C
>>> %7C%7C&sdata=vDkrWWPIys%2FfrA00nTpEHWiYps3U6L6g4ACFkRs%2Fcmw%3D&rese
>>> rved=0
>>> PLEASE do read the posting guide
>>> http://www/
>>> .r-project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%
>>> 7C104a304ff93043a854a408dbfb5809c1%7C0d4da0f84a314d76ace60a62331e1b8
>>> 4%7C0%7C0%7C638380127776926039%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wL
>>> jAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7
>>> C&sdata=hcvic6lEhrl4XpgEIctV4zhjz6ZgI9nWAHF4vLUbJyc%3D&reserved=0
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> I don't see a reason why year should be a factor and the formula in
>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>> It still doesn't plot the CI's though. There's a warning and I am not
>> understanding where it comes from. But the regression line is plotted.
>>
>>
>>
>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>   geom_point() +
>>   geom_smooth(method = "lm", formula = y ~ x) +
>>   labs(
>>     title = "Standard linear regression for France",
>>     x = "Year",
>>     y = "PISA score in mathematics"
>>   ) +
>>   ylim(470, 500)
>> #> Warning message:
>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>> returning -Inf
>>
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
> After playing with this for a little while, I realized that the
> problem with plotting the confidence limits is the addition of ylim(470, 500).
> The confidence values are outside the ylim values.  Remove the limits,
> or increase the range, and the confidence curves will plot.
>
> Hope this is helpful,
>
> Dan
>

  Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tebert @end|ng |rom u||@edu  Wed Dec 13 04:37:10 2023
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Wed, 13 Dec 2023 03:37:10 +0000
Subject: [R] Advice on starting to analyze smokestack emissions?
In-Reply-To: <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com>
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org>
 <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
 <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com>
Message-ID: <CH3PR22MB45145A73122C44FD69FD2547CF8DA@CH3PR22MB4514.namprd22.prod.outlook.com>

That depends on how exactly everything must match your primary question. The ecology group might be helpful for how biodiversity changes with proximity to a smokestack. They might have a better idea if the smokestack was from a coal fired powerplant or oil refinery. The modeling process would be similar, though the abundance of individual contaminants would be quite different. Just my thought for what it is worth.
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Tuesday, December 12, 2023 10:53 AM
To: Kevin Zembower <kevin at zembower.org>
Cc: R-help email list <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?

[External Email]

You might also try the R-Sig-ecology list, though I would agree that it's not clearly related. Still, air pollution effects...?

-- Bert

On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help < r-help at r-project.org> wrote:

> Hello, all,
>
> [Originally sent to r-sig-geo list, with no response. Cross-posting
> here, in the hope of a wider audience. Anyone with any experience in
> this topic? Thanks.]
>
> I'm trying to get started analyzing the concentrations of smokestack
> emissions. I don't have any professional background or training for
> this; I'm just an old, retired guy who thinks playing with numbers is
> fun.
>
> A local funeral home in my neighborhood (less than 1200 ft from my
> home) is proposing to construct a crematorium for human remains. I
> have some experience with the tidycensus package and thought it might
> be interesting to construct a model for the changes in concentrations
> of the pollutants from the smokestack and, using recorded wind speeds
> and directions, see which US Census blocks would be affected.
>
> I have the US Government EPA SCREEN3 output on how concentration
> varies with distance from the smokestack.
> See
> https://www/.
> epa.gov%2Fscram%2Fair-quality-dispersion-modeling-screening-models%23s
> creen3&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7
> ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7C
> Unknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1h
> aWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QgsYQ9w28caBmEGwJ9Kei2x0fSkH3
> 4v3%2BfAo37GdcYQ%3D&reserved=0 if curious. As a first task, I'd like
> to see if I can calculate similar results in R. I'm aware of the
> 'plume' steady-state Gaussian dispersion package
> (https://rdr/
> r.io%2Fgithub%2Fholstius%2Fplume%2Ff%2Finst%2Fdoc%2Fplume-intro.pdf&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=DN9oxiJnDFvvmY968G9t9Sagr8UfJ2ySZiGWV1%2F9AC8%3D&reserved=0), but am a little concerned that this package was last updated 11 years ago.
>
> Do you have any recommendations for me on how to get started analyzing
> this problem? Is 'plume' still the way to go? I'm aware that there are
> many atmospheric dispersion models from the US EPA, but I was hoping
> to keep my work within R, which I'm really enjoying using and learning
> about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> ask questions about this topic?
>
> Thanks for any advice or guidance you have for me.
>
> -Kevin
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sda
> ta=dxsuLWVRx8wNnu49SJ34AAh7oRECvDIrQh9%2Bpx48SL0%3D&reserved=0
> PLEASE do read the posting guide
> http://www.r/
> -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7C30
> 97c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> 7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QY
> AiKA8xDhcPyQmRZ6Vqcr5mdszE8WSRyFmCqzQ7Rog%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From r@oknz @end|ng |rom gm@||@com  Wed Dec 13 05:38:43 2023
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 13 Dec 2023 17:38:43 +1300
Subject: [R] Advice on starting to analyze smokestack emissions?
In-Reply-To: <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com>
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org>
 <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
 <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com>
Message-ID: <CABcYAdLBgCy2b-QTOaedQ6dAo-LfuCHsDS6LgufbE1S0SByP3A@mail.gmail.com>

This https://ncceh.ca/resources/evidence-reviews/crematoria-emissions-and-air-quality-impacts
might provide some useful information.

On Wed, 13 Dec 2023 at 04:53, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You might also try the R-Sig-ecology list, though I would agree that it's
> not clearly related. Still, air pollution effects...?
>
> -- Bert
>
> On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
> r-help at r-project.org> wrote:
>
> > Hello, all,
> >
> > [Originally sent to r-sig-geo list, with no response. Cross-posting
> > here, in the hope of a wider audience. Anyone with any experience in
> > this topic? Thanks.]
> >
> > I'm trying to get started analyzing the concentrations of smokestack
> > emissions. I don't have any professional background or training for
> > this; I'm just an old, retired guy who thinks playing with numbers is
> > fun.
> >
> > A local funeral home in my neighborhood (less than 1200 ft from my
> > home) is proposing to construct a crematorium for human remains. I have
> > some experience with the tidycensus package and thought it might be
> > interesting to construct a model for the changes in concentrations of
> > the pollutants from the smokestack and, using recorded wind speeds and
> > directions, see which US Census blocks would be affected.
> >
> > I have the US Government EPA SCREEN3 output on how concentration varies
> > with distance from the smokestack.
> > See
> > https://www.epa.gov/scram/air-quality-dispersion-modeling-screening-models#screen3
> > if curious. As a first task, I'd like to see if I can calculate similar
> > results in R. I'm aware of the 'plume' steady-state Gaussian dispersion
> > package
> > (https://rdrr.io/github/holstius/plume/f/inst/doc/plume-intro.pdf), but
> > am a little concerned that this package was last updated 11 years ago.
> >
> > Do you have any recommendations for me on how to get started analyzing
> > this problem? Is 'plume' still the way to go? I'm aware that there are
> > many atmospheric dispersion models from the US EPA, but I was hoping to
> > keep my work within R, which I'm really enjoying using and learning
> > about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> > ask questions about this topic?
> >
> > Thanks for any advice or guidance you have for me.
> >
> > -Kevin
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Dec 13 05:38:54 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 12 Dec 2023 20:38:54 -0800
Subject: [R] Advice on starting to analyze smokestack emissions?
In-Reply-To: <CH3PR22MB45145A73122C44FD69FD2547CF8DA@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org>
 <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
 <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com>
 <CH3PR22MB45145A73122C44FD69FD2547CF8DA@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <CAGxFJbRZ6L8XWGWOm404j2R2GvHtdy+TEPgTrTrW_ngPFvMS=Q@mail.gmail.com>

My point was only that there might be functionality there that might be
relevant to his concerns. .. with help on how to use it.

Bert

On Tue, Dec 12, 2023, 19:37 Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> That depends on how exactly everything must match your primary question.
> The ecology group might be helpful for how biodiversity changes with
> proximity to a smokestack. They might have a better idea if the smokestack
> was from a coal fired powerplant or oil refinery. The modeling process
> would be similar, though the abundance of individual contaminants would be
> quite different. Just my thought for what it is worth.
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
> Sent: Tuesday, December 12, 2023 10:53 AM
> To: Kevin Zembower <kevin at zembower.org>
> Cc: R-help email list <r-help at r-project.org>
> Subject: Re: [R] Advice on starting to analyze smokestack emissions?
>
> [External Email]
>
> You might also try the R-Sig-ecology list, though I would agree that it's
> not clearly related. Still, air pollution effects...?
>
> -- Bert
>
> On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
> r-help at r-project.org> wrote:
>
> > Hello, all,
> >
> > [Originally sent to r-sig-geo list, with no response. Cross-posting
> > here, in the hope of a wider audience. Anyone with any experience in
> > this topic? Thanks.]
> >
> > I'm trying to get started analyzing the concentrations of smokestack
> > emissions. I don't have any professional background or training for
> > this; I'm just an old, retired guy who thinks playing with numbers is
> > fun.
> >
> > A local funeral home in my neighborhood (less than 1200 ft from my
> > home) is proposing to construct a crematorium for human remains. I
> > have some experience with the tidycensus package and thought it might
> > be interesting to construct a model for the changes in concentrations
> > of the pollutants from the smokestack and, using recorded wind speeds
> > and directions, see which US Census blocks would be affected.
> >
> > I have the US Government EPA SCREEN3 output on how concentration
> > varies with distance from the smokestack.
> > See
> > https://www/.
> > epa.gov%2Fscram%2Fair-quality-dispersion-modeling-screening-models%23s
> > creen3&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7
> > ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7C
> > Unknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1h
> > aWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QgsYQ9w28caBmEGwJ9Kei2x0fSkH3
> > 4v3%2BfAo37GdcYQ%3D&reserved=0 if curious. As a first task, I'd like
> > to see if I can calculate similar results in R. I'm aware of the
> > 'plume' steady-state Gaussian dispersion package
> > (https://rdr/
> > r.io
> %2Fgithub%2Fholstius%2Fplume%2Ff%2Finst%2Fdoc%2Fplume-intro.pdf&data=05%7C02%7Ctebert%
> 40ufl.edu%7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=DN9oxiJnDFvvmY968G9t9Sagr8UfJ2ySZiGWV1%2F9AC8%3D&reserved=0),
> but am a little concerned that this package was last updated 11 years ago.
> >
> > Do you have any recommendations for me on how to get started analyzing
> > this problem? Is 'plume' still the way to go? I'm aware that there are
> > many atmospheric dispersion models from the US EPA, but I was hoping
> > to keep my work within R, which I'm really enjoying using and learning
> > about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> > ask questions about this topic?
> >
> > Thanks for any advice or guidance you have for me.
> >
> > -Kevin
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat/
> > .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> > %7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84
> > %7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> > MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sda
> > ta=dxsuLWVRx8wNnu49SJ34AAh7oRECvDIrQh9%2Bpx48SL0%3D&reserved=0
> > PLEASE do read the posting guide
> > http://www.r/
> > -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7C30
> > 97c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> > 7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> > CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QY
> > AiKA8xDhcPyQmRZ6Vqcr5mdszE8WSRyFmCqzQ7Rog%3D&reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Dec 13 07:28:26 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 13 Dec 2023 06:28:26 +0000
Subject: [R] ggplot2: Get the regression line with 95% confidence bands
In-Reply-To: <352cddfd-6db4-4715-bad1-2f5690d8dc29@atsu.edu>
References: <1684699562.3682096.1702247731199.ref@mail.yahoo.com>
 <1684699562.3682096.1702247731199@mail.yahoo.com>
 <8cca3bae-a729-448d-9e43-dbfc92ccefed@sapo.pt>
 <ddbb1346-f7a9-4b1b-b7fd-61ea2cfdf131@gmail.com>
 <fb94049a-2822-4678-855f-3bf9abe04832@gmail.com>
 <68588390.888662.1702415952477@mail.yahoo.com>
 <352cddfd-6db4-4715-bad1-2f5690d8dc29@atsu.edu>
Message-ID: <42a94897-80e8-4a89-918d-769b1b2eeadd@sapo.pt>

?s 00:36 de 13/12/2023, Robert Baer escreveu:
> coord_cartesian also seems to work for y, and including the breaks = . 
> How about:
> 
> df=data.frame(year= c(2012,2015,2018,2022),
>  ????????????? score=c(495,493, 495, 474))
> 
> ggplot(df, aes(x = year, y = score)) +
>  ? geom_point() +
>  ? geom_smooth(method = "lm", formula = y ~ x) +
>  ? labs(title = "Standard linear regression for France", x = "Year", y = 
> "PISA score in mathematics") +
>  ? coord_cartesian(ylim=c(470,500)) +
>  ? scale_x_continuous(breaks = 2012:2022)
> 
> On 12/12/2023 3:19 PM, varin sacha via R-help wrote:
>> Dear Ben,
>> Dear Daniel,
>> Dear Rui,
>> Dear Bert,
>>
>> Here below my R code.
>> I really appreciate all your comments. My R code is perfectly working 
>> but there is still something I would like to improve. The X-axis is 
>> showing ? 2012.5 ; ? 2015.0 ? ; ? 2017.5 ? ; ?2020.0
>> I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 
>> 2020). How to do?
>>
>>
>> #########
>> library(ggplot2)
>> df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))
>>
>> ggplot(df, aes(x = year, y = score)) + geom_point() + 
>> geom_smooth(method = "lm", formula = y ~ x) +
>> ??labs(title = "Standard linear regression for France", x = "Year", y 
>> = "PISA score in mathematics") + 
>> scale_y_continuous(limits=c(470,500),oob=scales::squish)
>> #########
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker 
>> <bbolker at gmail.com> a ?crit :
>>
>>
>>
>>
>>
>>
>>
>> On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
>>> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>>>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>>> Dear R-experts,
>>>>>
>>>>> Here below my R code, as my X-axis is "year", I must be missing one
>>>>> or more steps! I am trying to get the regression line with the 95%
>>>>> confidence bands around the regression line. Any help would be
>>>>> appreciated.
>>>>>
>>>>> Best,
>>>>> S.
>>>>>
>>>>>
>>>>> #############################################
>>>>> library(ggplot2)
>>>>> ?? df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>>>> score=c(495,493, 495, 474))
>>>>> ?? ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
>>>>> labs(title="Standard linear regression for France", y="PISA score in
>>>>> mathematics") + ylim(470, 500)
>>>>> #############################################
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> Hello,
>>>>
>>>> I don't see a reason why year should be a factor and the formula in
>>>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>>>> It still doesn't plot the CI's though. There's a warning and I am not
>>>> understanding where it comes from. But the regression line is plotted.
>>>>
>>>>
>>>>
>>>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>>> ?? geom_point() +
>>>> ?? geom_smooth(method = "lm", formula = y ~ x) +
>>>> ?? labs(
>>>> ???? title = "Standard linear regression for France",
>>>> ???? x = "Year",
>>>> ???? y = "PISA score in mathematics"
>>>> ?? ) +
>>>> ?? ylim(470, 500)
>>>> #> Warning message:
>>>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>>>> returning -Inf
>>>>
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>>
>>> After playing with this for a little while, I realized that the problem
>>> with plotting the confidence limits is the addition of ylim(470, 500).
>>> The confidence values are outside the ylim values.? Remove the limits,
>>> or increase the range, and the confidence curves will plot.
>>>
>>> Hope this is helpful,
>>>
>>> Dan
>>>
>> ?? Or use + scale_y_continuous(limits = c(470, 500), oob = 
>> scales::squish)
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

In the code below I don't use coord_cartesian because to set ylim will 
cut part of the confidence intervals.

To have labels only in the years present in the data set, get them from 
the data.



library(ggplot2)

df <- data.frame(year= c(2012,2015,2018,2022),
                  score=c(495,493, 495, 474))

# in this case unique is not needed, it's here
# because it might with some data sets
brks_year <- df$year # |> unique()

ggplot(df, aes(x = year, y = score)) +
   geom_point() +
   geom_smooth(method = "lm", formula = y ~ x) +
   labs(title = "Standard linear regression for France",
        x = "Year", y = "PISA score in mathematics") +
   scale_x_continuous(breaks = brks_year)



Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From me @end|ng |rom n@nx@me  Wed Dec 13 06:09:06 2023
From: me @end|ng |rom n@nx@me (Nan Xiao)
Date: Wed, 13 Dec 2023 00:09:06 -0500
Subject: [R] [R-pkgs] simtrial: Clinical Trial Simulation
Message-ID: <79834370-a2ad-4a6a-8b55-19b29e998f8a@app.fastmail.com>

Dear all,

I am happy to announce that {simtrial} is now on CRAN (https://cran.r-project.org/package=simtrial). simtrial is a fast and extensible clinical trial simulation framework for time-to-event endpoints.

This release brings a new tabular data processing engine powered by data.table for 3x to 5x faster simulations, a new parallelization adaptor with %dofuture%, a refreshed API that aligns with the gsDesign2 style guide, and new functions for zero early weight and analysis date. For a summary of the updates, please see the announcement: https://keaven.github.io/blog/simtrial-0-3-2/.

I hope you find simtrial helpful. Please feel free to reach out with feedback or questions.

Best regards,
-Nan

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From tr@xp|@yer @end|ng |rom gm@||@com  Thu Dec 14 09:00:12 2023
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 14 Dec 2023 09:00:12 +0100
Subject: [R] Sorting based a custom sorting function
Message-ID: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>

Hi,

  I need to sort a data.frame based on a custom sorting function.
  It is easy in many languages but I can't find a way to do it in R.

  In many cases I could just use an ordered factor but my data.frame
contains poker hands and
I need to rank these hands. I already got a function that compares two hands.

Here is a MRE (Minimal, Reproducible Example):


df <- data.frame(person = c("Alice", "Bob", "Charlie"), value =
c("Medium", "Small", "Large"))

# 0 means equal, -1 means left before right, 1 means right before left
custom_sort <- function(left, right) {
  if (left == right) return(0)
  if (left == "Small") return(-1)
  if (left == "Medium" & right == "Large") return(-1)
  return(1)
}

#  sort df according to custom_soft
# expect output is a data.frame:
#     name   size
# 1     Bob Medium
# 2   Alice  Small
# 3 Charlie  Large

In this simple case I can just use an ordered factor but what about
the poker hands situation?

Regards
Martin


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Dec 14 10:51:41 2023
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 14 Dec 2023 01:51:41 -0800
Subject: [R] Sorting based a custom sorting function
In-Reply-To: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
References: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
Message-ID: <42BD3849-DBEA-4B3F-BC38-19A6FD6E92BD@dcn.davis.ca.us>

This sounds suspiciously like homework (which is off-topic... see the Posting Guide), and you haven't indicated how you plan to encode your poker hands, and most core features of other languages are possible in R so if you really understand these other techniques and R then you should be able to do this already.

If this is not homework, then please show your work so far instead of showing a completely different example.

On December 14, 2023 12:00:12 AM PST, "Martin M?ller Skarbiniks Pedersen" <traxplayer at gmail.com> wrote:
>Hi,
>
>  I need to sort a data.frame based on a custom sorting function.
>  It is easy in many languages but I can't find a way to do it in R.
>
>  In many cases I could just use an ordered factor but my data.frame
>contains poker hands and
>I need to rank these hands. I already got a function that compares two hands.
>
>Here is a MRE (Minimal, Reproducible Example):
>
>
>df <- data.frame(person = c("Alice", "Bob", "Charlie"), value =
>c("Medium", "Small", "Large"))
>
># 0 means equal, -1 means left before right, 1 means right before left
>custom_sort <- function(left, right) {
>  if (left == right) return(0)
>  if (left == "Small") return(-1)
>  if (left == "Medium" & right == "Large") return(-1)
>  return(1)
>}
>
>#  sort df according to custom_soft
># expect output is a data.frame:
>#     name   size
># 1     Bob Medium
># 2   Alice  Small
># 3 Charlie  Large
>
>In this simple case I can just use an ordered factor but what about
>the poker hands situation?
>
>Regards
>Martin
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Dec 14 12:02:09 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 14 Dec 2023 06:02:09 -0500
Subject: [R] Sorting based a custom sorting function
In-Reply-To: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
References: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
Message-ID: <a65df2e0-3399-4b03-963a-8b9565604528@gmail.com>

On 14/12/2023 3:00 a.m., Martin M?ller Skarbiniks Pedersen wrote:
> Hi,
> 
>    I need to sort a data.frame based on a custom sorting function.
>    It is easy in many languages but I can't find a way to do it in R.
> 
>    In many cases I could just use an ordered factor but my data.frame
> contains poker hands and
> I need to rank these hands. I already got a function that compares two hands.
> 
> Here is a MRE (Minimal, Reproducible Example):
> 
> 
> df <- data.frame(person = c("Alice", "Bob", "Charlie"), value =
> c("Medium", "Small", "Large"))
> 
> # 0 means equal, -1 means left before right, 1 means right before left
> custom_sort <- function(left, right) {
>    if (left == right) return(0)
>    if (left == "Small") return(-1)
>    if (left == "Medium" & right == "Large") return(-1)
>    return(1)
> }
> 
> #  sort df according to custom_soft
> # expect output is a data.frame:
> #     name   size
> # 1     Bob Medium
> # 2   Alice  Small
> # 3 Charlie  Large
> 
> In this simple case I can just use an ordered factor but what about
> the poker hands situation?
> 

The general way in base R is to put the objects in a vector (which might 
be a list if they are complex objects), assign a class to that vector, 
and define either an xtfrm method or methods for ==, >, is.na, and 
extraction for that vector.  The xtfrm method is basically
the same as using an ordered factor, so I'll skip that, and show you the 
other way:

For your example, you could do it like this:

class(df$value) <- "sizeclass"

`>.sizeclass` <- function(left, right) custom_sort(unclass(left), 
unclass(right)) == 1

`==.sizeclass` <- function(left, right) custom_sort(unclass(left), 
unclass(right)) == 0

`[.sizeclass` <- function(x, i) structure(unclass(x)[i], class="sizeclass")

df[order(df$value),]

All the "unclass()" calls are needed to avoid infinite recursion.  For a 
more complex kind of object where you are extracting attributes to 
compare, you probably wouldn't need so many of those.

There are likely other ways to do this in particular packages such as 
dplyr or data.table.

Duncan Murdoch


From tr@xp|@yer @end|ng |rom gm@||@com  Thu Dec 14 12:31:57 2023
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 14 Dec 2023 12:31:57 +0100
Subject: [R] Sorting based a custom sorting function
In-Reply-To: <42BD3849-DBEA-4B3F-BC38-19A6FD6E92BD@dcn.davis.ca.us>
References: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
 <42BD3849-DBEA-4B3F-BC38-19A6FD6E92BD@dcn.davis.ca.us>
Message-ID: <CAGAA5bdHxgaBrb=sd9YA9qeA3_7XUECLYjE6P_UdokutZRhN-A@mail.gmail.com>

> This sounds suspiciously like homework (which is off-topic... see the Posting Guide)

It is not homework.
Currently I am trying to solve this: https://adventofcode.com/2023/day/7

But it is something that has puzzled me for a long time.
In many programming languages, you can give a "less" function to the
sorting function.

The "less" function normally takes two arguments and tells which is
greater. The sorting function then uses that.
Eg. in perl:
@products = sort { $a->{price} <=> $b->{price} || $b->{discount} <=>
$a->{discount} } @products;

>  and you haven't indicated how you plan to encode your poker hands
> If this is not homework, then please show your work so far instead of showing a completely different example.

I believe a MRE is better than a lot of code with many details that
are not related to the precise problem.
See https://stackoverflow.com/help/minimal-reproducible-example

My encoding of poker hands doesn't matter for the general problem of
providing a custom sorting function to any of the many
sorting functions in R.

> Most core features of other languages are possible in R so if you really understand these other techniques and R then you should be able to do this already.

I understand R quite well and implemented my own quicksort but I was
wondering for a better solution.

Here is my current solution.

quicksort <- function(arr, compare_func) {
  if (length(arr) <= 1) {
    return(arr)
  } else {
    pivot <- arr[1]
    less <- arr[-1][compare_func(arr[-1], pivot) <= 0]
    greater <- arr[-1][compare_func(arr[-1], pivot) > 0]
    return(c(quicksort(less, compare_func), pivot, quicksort(greater,
compare_func)))
  }
}

Regards
Martin



Martin


From tr@xp|@yer @end|ng |rom gm@||@com  Thu Dec 14 12:38:18 2023
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 14 Dec 2023 12:38:18 +0100
Subject: [R] Sorting based a custom sorting function
In-Reply-To: <CAGAA5bcMax7YPB5J5Qtzi-SxY1ayJR0NdQB=vqOdkCsG_mEicw@mail.gmail.com>
References: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
 <a65df2e0-3399-4b03-963a-8b9565604528@gmail.com>
 <CAGAA5bcMax7YPB5J5Qtzi-SxY1ayJR0NdQB=vqOdkCsG_mEicw@mail.gmail.com>
Message-ID: <CAGAA5bfSu6TyrLie6EzC0pB6kS_X=wwLaJaBqLgojG+2i3SrSw@mail.gmail.com>

On Thu, 14 Dec 2023 at 12:02, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>

> class(df$value) <- "sizeclass"
>
> `>.sizeclass` <- function(left, right) custom_sort(unclass(left),
> unclass(right)) == 1
>
> `==.sizeclass` <- function(left, right) custom_sort(unclass(left),
> unclass(right)) == 0
>
> `[.sizeclass` <- function(x, i) structure(unclass(x)[i], class="sizeclass")
>
> df[order(df$value),]
>
> All the "unclass()" calls are needed to avoid infinite recursion.  For a
> more complex kind of object where you are extracting attributes to
> compare, you probably wouldn't need so many of those.

Great! Just what I need. I will create a class and overwrite > and ==.
I didn't know that order() used these exact methods.

My best solution was something like this:

quicksort <- function(arr, compare_func) {
  if (length(arr) <= 1) {
    return(arr)
  } else {
    pivot <- arr[[1]]
    less <- arr[-1][compare_func(arr[-1], pivot) <= 0]
    greater <- arr[-1][compare_func(arr[-1], pivot) > 0]
    return(c(quicksort(less, compare_func), pivot, quicksort(greater,
compare_func)))
  }
}

persons <- c("alfa", "bravo", "charlie", "delta", "echo", "foxtrot", "golf",
             "hotel", "india", "juliett", "kilo", "lima", "mike", "november",
             "oscar", "papa", "quebec", "romeo", "sierra", "tango", "uniform",
             "victor", "whiskey", "x-ray", "yankee", "zulu")

quicksort(persons, function(left, right) {
  nchar(left) - nchar(right)
})

Regards
Martin


From tr@xp|@yer @end|ng |rom gm@||@com  Thu Dec 14 12:41:36 2023
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 14 Dec 2023 12:41:36 +0100
Subject: [R] Suggestion for list - change reply-to
Message-ID: <CAGAA5bdUygO6Off-6YPiiqe5sKhtt+aJo_-kakC=AM_jjsVF3Q@mail.gmail.com>

Hi,

  I suggest that reply-to is changed to r-help at r-project.org and not
the original sender.

  The reason for my suggestion:
  I just made a mistake when replying to a message.
  I forgot to change the reply address from the sender to the r-help
and I think that happens quite often for others also.

  Any reason to keep it to the original sender?

Regards
Martin


From mtmorg@n@xyz @end|ng |rom gm@||@com  Thu Dec 14 17:37:58 2023
From: mtmorg@n@xyz @end|ng |rom gm@||@com (Martin Morgan)
Date: Thu, 14 Dec 2023 16:37:58 +0000
Subject: [R] Sorting based a custom sorting function
In-Reply-To: <CAGAA5bfSu6TyrLie6EzC0pB6kS_X=wwLaJaBqLgojG+2i3SrSw@mail.gmail.com>
References: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
 <a65df2e0-3399-4b03-963a-8b9565604528@gmail.com>
 <CAGAA5bcMax7YPB5J5Qtzi-SxY1ayJR0NdQB=vqOdkCsG_mEicw@mail.gmail.com>
 <CAGAA5bfSu6TyrLie6EzC0pB6kS_X=wwLaJaBqLgojG+2i3SrSw@mail.gmail.com>
Message-ID: <DS7PR10MB727747D84EA8275F23B736C9FA8CA@DS7PR10MB7277.namprd10.prod.outlook.com>

In the spirit of 'advent of code', maybe it is better to exploit the features of the particular language you've chosen? Then the use of factors seems very relevant.

value_levels <- c("Small", "Medium", "Large")
df <- data.frame(
    person = c("Alice", "Bob", "Bob", "Charlie"),
    value = factor(
        c("Medium", "Large", "Small", "Large"),
        levels = value_levels
    )
)
df[with(df, order(person, value)),]

Likely this is more efficient than the hints of your existing solution, because it will act on vectors rather than iterating through individual elements of the 'person' and 'value' vectors.

For a more general solution, I don't think I'd follow the low-level approach Duncan suggests (maybe see also ?Math for S3 generics), but rather define a class (e.g., that requires vectors person and value) and implement a corresponding `xtfrm()` method.

Have fun with the remainder of the advent!

Another Martin

From: R-help <r-help-bounces at r-project.org> on behalf of Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com>
Date: Thursday, December 14, 2023 at 6:42?AM
To: R mailing list <r-help at r-project.org>
Subject: Re: [R] Sorting based a custom sorting function
On Thu, 14 Dec 2023 at 12:02, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>

> class(df$value) <- "sizeclass"
>
> `>.sizeclass` <- function(left, right) custom_sort(unclass(left),
> unclass(right)) == 1
>
> `==.sizeclass` <- function(left, right) custom_sort(unclass(left),
> unclass(right)) == 0
>
> `[.sizeclass` <- function(x, i) structure(unclass(x)[i], class="sizeclass")
>
> df[order(df$value),]
>
> All the "unclass()" calls are needed to avoid infinite recursion.  For a
> more complex kind of object where you are extracting attributes to
> compare, you probably wouldn't need so many of those.

Great! Just what I need. I will create a class and overwrite > and ==.
I didn't know that order() used these exact methods.

My best solution was something like this:

quicksort <- function(arr, compare_func) {
  if (length(arr) <= 1) {
    return(arr)
  } else {
    pivot <- arr[[1]]
    less <- arr[-1][compare_func(arr[-1], pivot) <= 0]
    greater <- arr[-1][compare_func(arr[-1], pivot) > 0]
    return(c(quicksort(less, compare_func), pivot, quicksort(greater,
compare_func)))
  }
}

persons <- c("alfa", "bravo", "charlie", "delta", "echo", "foxtrot", "golf",
             "hotel", "india", "juliett", "kilo", "lima", "mike", "november",
             "oscar", "papa", "quebec", "romeo", "sierra", "tango", "uniform",
             "victor", "whiskey", "x-ray", "yankee", "zulu")

quicksort(persons, function(left, right) {
  nchar(left) - nchar(right)
})

Regards
Martin

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Dec 14 20:30:27 2023
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 14 Dec 2023 14:30:27 -0500
Subject: [R] Sorting based a custom sorting function
In-Reply-To: <DS7PR10MB727747D84EA8275F23B736C9FA8CA@DS7PR10MB7277.namprd10.prod.outlook.com>
References: <CAGAA5bebEpHNWw9iduHAWJGs_9hK_+pYzcHfPNF8uH2sh1NXEQ@mail.gmail.com>
 <a65df2e0-3399-4b03-963a-8b9565604528@gmail.com>
 <CAGAA5bcMax7YPB5J5Qtzi-SxY1ayJR0NdQB=vqOdkCsG_mEicw@mail.gmail.com>
 <CAGAA5bfSu6TyrLie6EzC0pB6kS_X=wwLaJaBqLgojG+2i3SrSw@mail.gmail.com>
 <DS7PR10MB727747D84EA8275F23B736C9FA8CA@DS7PR10MB7277.namprd10.prod.outlook.com>
Message-ID: <e231d2d1-fa03-4631-bd64-39c7b8c7ea19@gmail.com>

On 14/12/2023 11:37 a.m., Martin Morgan wrote:
> In the spirit of 'advent of code', maybe it is better to exploit the features of the particular language you've chosen? Then the use of factors seems very relevant.
> 
> value_levels <- c("Small", "Medium", "Large")
> df <- data.frame(
>      person = c("Alice", "Bob", "Bob", "Charlie"),
>      value = factor(
>          c("Medium", "Large", "Small", "Large"),
>          levels = value_levels
>      )
> )
> df[with(df, order(person, value)),]
> 
> Likely this is more efficient than the hints of your existing solution, because it will act on vectors rather than iterating through individual elements of the 'person' and 'value' vectors.
> 
> For a more general solution, I don't think I'd follow the low-level approach Duncan suggests (maybe see also ?Math for S3 generics), but rather define a class (e.g., that requires vectors person and value) and implement a corresponding `xtfrm()` method.

I'd agree, in cases where it's feasible to implement one.  But there are 
cases where the pairwise comparison is obvious, while the numeric 
conversion isn't.

A simple one would be a list of string vectors of different lengths, 
where you want to sort lexicographically.

Duncan

> 
> Have fun with the remainder of the advent!
> 
> Another Martin
> 
> From: R-help <r-help-bounces at r-project.org> on behalf of Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com>
> Date: Thursday, December 14, 2023 at 6:42?AM
> To: R mailing list <r-help at r-project.org>
> Subject: Re: [R] Sorting based a custom sorting function
> On Thu, 14 Dec 2023 at 12:02, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
> 
>> class(df$value) <- "sizeclass"
>>
>> `>.sizeclass` <- function(left, right) custom_sort(unclass(left),
>> unclass(right)) == 1
>>
>> `==.sizeclass` <- function(left, right) custom_sort(unclass(left),
>> unclass(right)) == 0
>>
>> `[.sizeclass` <- function(x, i) structure(unclass(x)[i], class="sizeclass")
>>
>> df[order(df$value),]
>>
>> All the "unclass()" calls are needed to avoid infinite recursion.  For a
>> more complex kind of object where you are extracting attributes to
>> compare, you probably wouldn't need so many of those.
> 
> Great! Just what I need. I will create a class and overwrite > and ==.
> I didn't know that order() used these exact methods.
> 
> My best solution was something like this:
> 
> quicksort <- function(arr, compare_func) {
>    if (length(arr) <= 1) {
>      return(arr)
>    } else {
>      pivot <- arr[[1]]
>      less <- arr[-1][compare_func(arr[-1], pivot) <= 0]
>      greater <- arr[-1][compare_func(arr[-1], pivot) > 0]
>      return(c(quicksort(less, compare_func), pivot, quicksort(greater,
> compare_func)))
>    }
> }
> 
> persons <- c("alfa", "bravo", "charlie", "delta", "echo", "foxtrot", "golf",
>               "hotel", "india", "juliett", "kilo", "lima", "mike", "november",
>               "oscar", "papa", "quebec", "romeo", "sierra", "tango", "uniform",
>               "victor", "whiskey", "x-ray", "yankee", "zulu")
> 
> quicksort(persons, function(left, right) {
>    nchar(left) - nchar(right)
> })
> 
> Regards
> Martin
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Den|@@Cou@|ne@u @end|ng |rom uott@w@@c@  Wed Dec 13 13:54:07 2023
From: Den|@@Cou@|ne@u @end|ng |rom uott@w@@c@ (Denis Cousineau)
Date: Wed, 13 Dec 2023 12:54:07 +0000
Subject: [R] [R-pkgs] ANOFA: Analysis of frequency data
Message-ID: <aaeefcc6-8c10-4248-8db2-393c12e460e7@uottawa.ca>

A package for the analysis of frequency data, ANOFA, has been released 
on CRAN.

With this package, it is now possible to analyze frequencies following 
the logic of ANOVAs, by examining interaction effects and main effects, 
or explore simple effects (with expected marginal frequencies) or 
analyze one-degree-of-freedom orthogonal contrasts.

If you were planning on doing a chi-square test on a contingency table, 
think twice and read Sharpe (2015) https://*doi*.org/10.7275/tbfa-x148 . 
Then you will consider running an ANOFA . Examples are given in 
Laurencelle & Cousineau (2023) https://doi.org/10.20982/tqmp.19.2.p173

Also, a simple function for plotting the frequencies along with 
confidence intervals is shipped with the package.

See the main documentation on https://dcousin3.github.io/ANOFA/

Denis Cousineau.


_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @|ddh@rth@dortmund @end|ng |rom goog|em@||@com  Thu Dec 14 18:00:17 2023
From: @|ddh@rth@dortmund @end|ng |rom goog|em@||@com (siddharth sahasrabudhe)
Date: Thu, 14 Dec 2023 22:30:17 +0530
Subject: [R] Error while installing the R from CRAN website!
Message-ID: <CAO0h10BTfOV6uH+WZSwmXN7oQB=tEzwk34_JbWFxboDPLC7bdA@mail.gmail.com>

Hello,

I have installed R on my machine. After I open the R program I am getting
the following message on the console:
Error: evaluation nested too deeply: infinite recursion /
options(expressions=)?

Can anyone please let me know what this message is? Is there any issue
while installing R and how to get rid of this message?

A same error message is also popping up in my RStudio workspace!

Best,
Siddharth
-- 

Regards
Siddharth Sahasrabudhe

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Dec 15 12:49:51 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 15 Dec 2023 14:49:51 +0300
Subject: [R] Error while installing the R from CRAN website!
In-Reply-To: <CAO0h10BTfOV6uH+WZSwmXN7oQB=tEzwk34_JbWFxboDPLC7bdA@mail.gmail.com>
References: <CAO0h10BTfOV6uH+WZSwmXN7oQB=tEzwk34_JbWFxboDPLC7bdA@mail.gmail.com>
Message-ID: <20231215144951.4d56bcd7@arachnoid>

? Thu, 14 Dec 2023 22:30:17 +0530
siddharth sahasrabudhe via R-help <r-help at r-project.org> ?????:

> I have installed R on my machine.

What operating system does your machine run? Was it the latest version
of R that you installed?

> After I open the R program I am getting the following message on the
> console:
> Error: evaluation nested too deeply: infinite recursion /
> options(expressions=)?

Can you run traceback() after you receive this message? What are the
last few lines of the output?

Do you have a file named .Rprofile or .RData in the home directory or
the current directory? Try moving them away (or deleting them if you're
sure they don't contain anything useful). See
https://search.r-project.org/R/refmans/base/html/Startup.html for more
information on things that may cause R to run code when you start it.

-- 
Best regards,
Ivan


From kev|n @end|ng |rom zembower@org  Fri Dec 15 14:29:36 2023
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Fri, 15 Dec 2023 13:29:36 +0000
Subject: [R] Advice on starting to analyze smokestack emissions?
In-Reply-To: <CABcYAdLBgCy2b-QTOaedQ6dAo-LfuCHsDS6LgufbE1S0SByP3A@mail.gmail.com>
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org> 
 <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
 <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com> 
 <CABcYAdLBgCy2b-QTOaedQ6dAo-LfuCHsDS6LgufbE1S0SByP3A@mail.gmail.com> 
 <23083e67b7fae00d31d8dc4871eaf4b8517419c3.camel@zembower.org>
Message-ID: <0100018c6dab10c0-a6da3643-a9f2-44af-8a69-9303ea534749-000000@email.amazonses.com>

Bert, Tim, Karl and Richard, thank you all for your suggestions and
help.

I will try the R-sig-ecology list.

Karl, I wasn't aware of the RAQSAPI package, but it looked promising.
However, when I went to the source of the data it uses, the United
States Environmental Protection Agency?s (US EPA) Air Quality System
(AQS) Data Mart database, it looks like interactive access to the data
is restricted to those who can document a professional agency
affiliation. I don't have that. I'll work with the package to see if
this is true regarding obtaining the data through it. Thanks for the
suggestion.

Richard, the Canada study of crematoriums was very useful. Thanks.

Thanks, again, all, for your help.

-Kevin



From K@Ropk|n@ @end|ng |rom |eed@@@c@uk  Thu Dec 14 11:22:10 2023
From: K@Ropk|n@ @end|ng |rom |eed@@@c@uk (Karl Ropkins)
Date: Thu, 14 Dec 2023 10:22:10 +0000
Subject: [R] R-help Digest, Vol 250, Issue 13
In-Reply-To: <mailman.370706.1.1702465202.65413.r-help@r-project.org>
References: <mailman.370706.1.1702465202.65413.r-help@r-project.org>
Message-ID: <VI1PR03MB993799598E59C8A1B82ABBDCAA8CA@VI1PR03MB9937.eurprd03.prod.outlook.com>

Kevin,
Maybe also look at what air quality monitoring is being done in area.
https://cran.r-project.org/web/packages/RAQSAPI/vignettes/RAQSAPIvignette.html
Depends what and how near, but might be something relevant there?

Karl

Dr Karl Ropkins
Transport Studies | Environment | University of Leeds

------------------------------

Message: 2
Date: Tue, 12 Dec 2023 07:52:59 -0800
From: Bert Gunter <bgunter.4567 at gmail.com>
To: Kevin Zembower <kevin at zembower.org>
Cc: R-help email list <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?
Message-ID:
        <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

You might also try the R-Sig-ecology list, though I would agree that it's
not clearly related. Still, air pollution effects...?

-- Bert

On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
r-help at r-project.org> wrote:

> Hello, all,
>
> [Originally sent to r-sig-geo list, with no response. Cross-posting
> here, in the hope of a wider audience. Anyone with any experience in
> this topic? Thanks.]
>
> I'm trying to get started analyzing the concentrations of smokestack
> emissions. I don't have any professional background or training for
> this; I'm just an old, retired guy who thinks playing with numbers is
> fun.
>
> A local funeral home in my neighborhood (less than 1200 ft from my
> home) is proposing to construct a crematorium for human remains. I have
> some experience with the tidycensus package and thought it might be
> interesting to construct a model for the changes in concentrations of
> the pollutants from the smokestack and, using recorded wind speeds and
> directions, see which US Census blocks would be affected.
>
> I have the US Government EPA SCREEN3 output on how concentration varies
> with distance from the smokestack.
> See
> https://www.epa.gov/scram/air-quality-dispersion-modeling-screening-models#screen3
> if curious. As a first task, I'd like to see if I can calculate similar
> results in R. I'm aware of the 'plume' steady-state Gaussian dispersion
> package
> (https://rdrr.io/github/holstius/plume/f/inst/doc/plume-intro.pdf), but
> am a little concerned that this package was last updated 11 years ago.
>
> Do you have any recommendations for me on how to get started analyzing
> this problem? Is 'plume' still the way to go? I'm aware that there are
> many atmospheric dispersion models from the US EPA, but I was hoping to
> keep my work within R, which I'm really enjoying using and learning
> about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> ask questions about this topic?
>
> Thanks for any advice or guidance you have for me.
>
> -Kevin
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]




------------------------------

Message: 3
Date: Tue, 12 Dec 2023 21:19:12 +0000 (UTC)
From: varin sacha <varinsacha at yahoo.fr>
To: "r-help at r-project.org" <r-help at r-project.org>,  Ben Bolker
        <bbolker at gmail.com>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence
        bands
Message-ID: <68588390.888662.1702415952477 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

Dear Ben,
Dear Daniel,
Dear Rui,
Dear Bert,

Here below my R code.
I really appreciate all your comments. My R code is perfectly working but there is still something I would like to improve. The X-axis is showing   2012.5 ;   2015.0   ;   2017.5   ;  2020.0
I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020). How to do?


#########
library(ggplot2)

df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))

ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +
 labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") + scale_y_continuous(limits=c(470,500),oob=scales::squish)
#########









Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com> a ?crit :







On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>
>>> Dear R-experts,
>>>
>>> Here below my R code, as my X-axis is "year", I must be missing one
>>> or more steps! I am trying to get the regression line with the 95%
>>> confidence bands around the regression line. Any help would be
>>> appreciated.
>>>
>>> Best,
>>> S.
>>>
>>>
>>> #############################################
>>> library(ggplot2)
>>>   df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>> score=c(495,493, 495, 474))
>>>   ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
>>> labs(title="Standard linear regression for France", y="PISA score in
>>> mathematics") + ylim(470, 500)
>>> #############################################
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.r-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> I don't see a reason why year should be a factor and the formula in
>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>> It still doesn't plot the CI's though. There's a warning and I am not
>> understanding where it comes from. But the regression line is plotted.
>>
>>
>>
>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>   geom_point() +
>>   geom_smooth(method = "lm", formula = y ~ x) +
>>   labs(
>>     title = "Standard linear regression for France",
>>     x = "Year",
>>     y = "PISA score in mathematics"
>>   ) +
>>   ylim(470, 500)
>> #> Warning message:
>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>> returning -Inf
>>
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
> After playing with this for a little while, I realized that the problem
> with plotting the confidence limits is the addition of ylim(470, 500).
> The confidence values are outside the ylim values.  Remove the limits,
> or increase the range, and the confidence curves will plot.
>
> Hope this is helpful,
>
> Dan
>

  Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




------------------------------

Message: 4
Date: Tue, 12 Dec 2023 17:14:39 -0500
From: Ben Bolker <bbolker at gmail.com>
To: varin sacha <varinsacha at yahoo.fr>
Cc: R-Help <r-help at r-project.org>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence
        bands
Message-ID:
        <CABghstQELa+tyiLQYwivChiuen-YzyE3OGBo9gQUJ_hF7MDx+g at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Use scale_x_continuous() and specify your desired breaks

On Tue, Dec 12, 2023, 4:19 PM varin sacha <varinsacha at yahoo.fr> wrote:

> Dear Ben,
> Dear Daniel,
> Dear Rui,
> Dear Bert,
>
> Here below my R code.
> I really appreciate all your comments. My R code is perfectly working but
> there is still something I would like to improve. The X-axis is showing
> 2012.5 ;   2015.0   ;   2017.5   ;  2020.0
> I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020).
> How to do?
>
>
> #########
> library(ggplot2)
>
> df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))
>
> ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method =
> "lm", formula = y ~ x) +
>  labs(title = "Standard linear regression for France", x = "Year", y =
> "PISA score in mathematics") +
> scale_y_continuous(limits=c(470,500),oob=scales::squish)
> #########
>
>
>
>
>
>
>
>
>
> Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com>
> a ?crit :
>
>
>
>
>
>
>
> On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
> > On 12/10/2023 2:50 PM, Rui Barradas wrote:
> >> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
> >>>
> >>> Dear R-experts,
> >>>
> >>> Here below my R code, as my X-axis is "year", I must be missing one
> >>> or more steps! I am trying to get the regression line with the 95%
> >>> confidence bands around the regression line. Any help would be
> >>> appreciated.
> >>>
> >>> Best,
> >>> S.
> >>>
> >>>
> >>> #############################################
> >>> library(ggplot2)
> >>>   df=data.frame(year=factor(c("2012","2015","2018","2022")),
> >>> score=c(495,493, 495, 474))
> >>>   ggplot(df, aes(x=year, y=score)) + geom_point( ) +
> >>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
> >>> labs(title="Standard linear regression for France", y="PISA score in
> >>> mathematics") + ylim(470, 500)
> >>> #############################################
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.r-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >> Hello,
> >>
> >> I don't see a reason why year should be a factor and the formula in
> >> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
> >> It still doesn't plot the CI's though. There's a warning and I am not
> >> understanding where it comes from. But the regression line is plotted.
> >>
> >>
> >>
> >> ggplot(df, aes(x = as.numeric(year), y = score)) +
> >>   geom_point() +
> >>   geom_smooth(method = "lm", formula = y ~ x) +
> >>   labs(
> >>     title = "Standard linear regression for France",
> >>     x = "Year",
> >>     y = "PISA score in mathematics"
> >>   ) +
> >>   ylim(470, 500)
> >> #> Warning message:
> >> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
> >> returning -Inf
> >>
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >>
> > After playing with this for a little while, I realized that the problem
> > with plotting the confidence limits is the addition of ylim(470, 500).
> > The confidence values are outside the ylim values.  Remove the limits,
> > or increase the range, and the confidence curves will plot.
> >
> > Hope this is helpful,
> >
> > Dan
> >
>
>   Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]




------------------------------

Message: 5
Date: Tue, 12 Dec 2023 18:36:38 -0600
From: Robert Baer <rbaer at atsu.edu>
To: varin sacha <varinsacha at yahoo.fr>, "r-help at r-project.org"
        <r-help at r-project.org>, Ben Bolker <bbolker at gmail.com>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence
        bands
Message-ID: <352cddfd-6db4-4715-bad1-2f5690d8dc29 at atsu.edu>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

coord_cartesian also seems to work for y, and including the breaks = .
How about:

df=data.frame(year= c(2012,2015,2018,2022),
               score=c(495,493, 495, 474))

ggplot(df, aes(x = year, y = score)) +
   geom_point() +
   geom_smooth(method = "lm", formula = y ~ x) +
   labs(title = "Standard linear regression for France", x = "Year", y =
"PISA score in mathematics") +
   coord_cartesian(ylim=c(470,500)) +
   scale_x_continuous(breaks = 2012:2022)

On 12/12/2023 3:19 PM, varin sacha via R-help wrote:
> Dear Ben,
> Dear Daniel,
> Dear Rui,
> Dear Bert,
>
> Here below my R code.
> I really appreciate all your comments. My R code is perfectly working but there is still something I would like to improve. The X-axis is showing   2012.5 ;   2015.0   ;   2017.5   ;  2020.0
> I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020). How to do?
>
>
> #########
> library(ggplot2)
>
> df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))
>
> ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +
>   labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") + scale_y_continuous(limits=c(470,500),oob=scales::squish)
> #########
>
>
>
>
>
>
>
>
>
> Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com> a ?crit :
>
>
>
>
>
>
>
> On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
>> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>> Dear R-experts,
>>>>
>>>> Here below my R code, as my X-axis is "year", I must be missing one
>>>> or more steps! I am trying to get the regression line with the 95%
>>>> confidence bands around the regression line. Any help would be
>>>> appreciated.
>>>>
>>>> Best,
>>>> S.
>>>>
>>>>
>>>> #############################################
>>>> library(ggplot2)
>>>>    df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>>> score=c(495,493, 495, 474))
>>>>    ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
>>>> labs(title="Standard linear regression for France", y="PISA score in
>>>> mathematics") + ylim(470, 500)
>>>> #############################################
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.r-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> Hello,
>>>
>>> I don't see a reason why year should be a factor and the formula in
>>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>>> It still doesn't plot the CI's though. There's a warning and I am not
>>> understanding where it comes from. But the regression line is plotted.
>>>
>>>
>>>
>>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>>    geom_point() +
>>>    geom_smooth(method = "lm", formula = y ~ x) +
>>>    labs(
>>>      title = "Standard linear regression for France",
>>>      x = "Year",
>>>      y = "PISA score in mathematics"
>>>    ) +
>>>    ylim(470, 500)
>>> #> Warning message:
>>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>>> returning -Inf
>>>
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>> After playing with this for a little while, I realized that the problem
>> with plotting the confidence limits is the addition of ylim(470, 500).
>> The confidence values are outside the ylim values.  Remove the limits,
>> or increase the range, and the confidence curves will plot.
>>
>> Hope this is helpful,
>>
>> Dan
>>
>    Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




------------------------------

Message: 6
Date: Wed, 13 Dec 2023 02:43:36 +0000
From: "Ebert,Timothy Aaron" <tebert at ufl.edu>
To: varin sacha <varinsacha at yahoo.fr>, "r-help at r-project.org"
        <r-help at r-project.org>, Ben Bolker <bbolker at gmail.com>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence
        bands
Message-ID:
        <CH3PR22MB45144A83E3804933F8110101CF8DA at CH3PR22MB4514.namprd22.prod.outlook.com>

Content-Type: text/plain; charset="iso-8859-1"

Change year to a factor. Doing it in ggplot will not change the original data.

ggplot(df, aes(x = as.factor(year), y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +  labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") +
scale_y_continuous(limits=c(470,500),oob=scales::squish)

Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of varin sacha via R-help
Sent: Tuesday, December 12, 2023 4:19 PM
To: r-help at r-project.org; Ben Bolker <bbolker at gmail.com>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence bands

[External Email]

Dear Ben,
Dear Daniel,
Dear Rui,
Dear Bert,

Here below my R code.
I really appreciate all your comments. My R code is perfectly working but there is still something I would like to improve. The X-axis is showing   2012.5 ;   2015.0   ;   2017.5   ;  2020.0
I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ; 2020). How to do?


#########
library(ggplot2)

df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))

ggplot(df, aes(x = year, y = score)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) +  labs(title = "Standard linear regression for France", x = "Year", y = "PISA score in mathematics") + scale_y_continuous(limits=c(470,500),oob=scales::squish)
#########









Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker <bbolker at gmail.com> a ?crit :







On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>
>>> Dear R-experts,
>>>
>>> Here below my R code, as my X-axis is "year", I must be missing one
>>> or more steps! I am trying to get the regression line with the 95%
>>> confidence bands around the regression line. Any help would be
>>> appreciated.
>>>
>>> Best,
>>> S.
>>>
>>>
>>> #############################################
>>> library(ggplot2)
>>>   df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>> score=c(495,493, 495, 474))
>>>   ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df)
>>> + labs(title="Standard linear regression for France", y="PISA score
>>> in
>>> mathematics") + ylim(470, 500)
>>> #############################################
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://st/
>>> at.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl
>>> .edu%7C104a304ff93043a854a408dbfb5809c1%7C0d4da0f84a314d76ace60a6233
>>> 1e1b84%7C0%7C0%7C638380127776926039%7CUnknown%7CTWFpbGZsb3d8eyJWIjoi
>>> MC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C
>>> %7C%7C&sdata=vDkrWWPIys%2FfrA00nTpEHWiYps3U6L6g4ACFkRs%2Fcmw%3D&rese
>>> rved=0
>>> PLEASE do read the posting guide
>>> http://www/
>>> .r-project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%
>>> 7C104a304ff93043a854a408dbfb5809c1%7C0d4da0f84a314d76ace60a62331e1b8
>>> 4%7C0%7C0%7C638380127776926039%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wL
>>> jAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7
>>> C&sdata=hcvic6lEhrl4XpgEIctV4zhjz6ZgI9nWAHF4vLUbJyc%3D&reserved=0
>>> and provide commented, minimal, self-contained, reproducible code.
>> Hello,
>>
>> I don't see a reason why year should be a factor and the formula in
>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>> It still doesn't plot the CI's though. There's a warning and I am not
>> understanding where it comes from. But the regression line is plotted.
>>
>>
>>
>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>   geom_point() +
>>   geom_smooth(method = "lm", formula = y ~ x) +
>>   labs(
>>     title = "Standard linear regression for France",
>>     x = "Year",
>>     y = "PISA score in mathematics"
>>   ) +
>>   ylim(470, 500)
>> #> Warning message:
>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>> returning -Inf
>>
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
> After playing with this for a little while, I realized that the
> problem with plotting the confidence limits is the addition of ylim(470, 500).
> The confidence values are outside the ylim values.  Remove the limits,
> or increase the range, and the confidence curves will plot.
>
> Hope this is helpful,
>
> Dan
>

  Or use + scale_y_continuous(limits = c(470, 500), oob = scales::squish)


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




------------------------------

Message: 7
Date: Wed, 13 Dec 2023 03:37:10 +0000
From: "Ebert,Timothy Aaron" <tebert at ufl.edu>
To: Bert Gunter <bgunter.4567 at gmail.com>, Kevin Zembower
        <kevin at zembower.org>
Cc: R-help email list <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?
Message-ID:
        <CH3PR22MB45145A73122C44FD69FD2547CF8DA at CH3PR22MB4514.namprd22.prod.outlook.com>

Content-Type: text/plain; charset="utf-8"

That depends on how exactly everything must match your primary question. The ecology group might be helpful for how biodiversity changes with proximity to a smokestack. They might have a better idea if the smokestack was from a coal fired powerplant or oil refinery. The modeling process would be similar, though the abundance of individual contaminants would be quite different. Just my thought for what it is worth.
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Tuesday, December 12, 2023 10:53 AM
To: Kevin Zembower <kevin at zembower.org>
Cc: R-help email list <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?

[External Email]

You might also try the R-Sig-ecology list, though I would agree that it's not clearly related. Still, air pollution effects...?

-- Bert

On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help < r-help at r-project.org> wrote:

> Hello, all,
>
> [Originally sent to r-sig-geo list, with no response. Cross-posting
> here, in the hope of a wider audience. Anyone with any experience in
> this topic? Thanks.]
>
> I'm trying to get started analyzing the concentrations of smokestack
> emissions. I don't have any professional background or training for
> this; I'm just an old, retired guy who thinks playing with numbers is
> fun.
>
> A local funeral home in my neighborhood (less than 1200 ft from my
> home) is proposing to construct a crematorium for human remains. I
> have some experience with the tidycensus package and thought it might
> be interesting to construct a model for the changes in concentrations
> of the pollutants from the smokestack and, using recorded wind speeds
> and directions, see which US Census blocks would be affected.
>
> I have the US Government EPA SCREEN3 output on how concentration
> varies with distance from the smokestack.
> See
> https://www/.
> epa.gov%2Fscram%2Fair-quality-dispersion-modeling-screening-models%23s
> creen3&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7
> ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7C
> Unknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1h
> aWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QgsYQ9w28caBmEGwJ9Kei2x0fSkH3
> 4v3%2BfAo37GdcYQ%3D&reserved=0 if curious. As a first task, I'd like
> to see if I can calculate similar results in R. I'm aware of the
> 'plume' steady-state Gaussian dispersion package
> (https://rdr/
> r.io%2Fgithub%2Fholstius%2Fplume%2Ff%2Finst%2Fdoc%2Fplume-intro.pdf&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=DN9oxiJnDFvvmY968G9t9Sagr8UfJ2ySZiGWV1%2F9AC8%3D&reserved=0), but am a little concerned that this package was last updated 11 years ago.
>
> Do you have any recommendations for me on how to get started analyzing
> this problem? Is 'plume' still the way to go? I'm aware that there are
> many atmospheric dispersion models from the US EPA, but I was hoping
> to keep my work within R, which I'm really enjoying using and learning
> about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> ask questions about this topic?
>
> Thanks for any advice or guidance you have for me.
>
> -Kevin
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sda
> ta=dxsuLWVRx8wNnu49SJ34AAh7oRECvDIrQh9%2Bpx48SL0%3D&reserved=0
> PLEASE do read the posting guide
> http://www.r/
> -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7C30
> 97c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> 7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QY
> AiKA8xDhcPyQmRZ6Vqcr5mdszE8WSRyFmCqzQ7Rog%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


------------------------------

Message: 8
Date: Wed, 13 Dec 2023 17:38:43 +1300
From: "Richard O'Keefe" <raoknz at gmail.com>
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: Kevin Zembower <kevin at zembower.org>, R-help email list
        <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?
Message-ID:
        <CABcYAdLBgCy2b-QTOaedQ6dAo-LfuCHsDS6LgufbE1S0SByP3A at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

This https://ncceh.ca/resources/evidence-reviews/crematoria-emissions-and-air-quality-impacts
might provide some useful information.

On Wed, 13 Dec 2023 at 04:53, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You might also try the R-Sig-ecology list, though I would agree that it's
> not clearly related. Still, air pollution effects...?
>
> -- Bert
>
> On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
> r-help at r-project.org> wrote:
>
> > Hello, all,
> >
> > [Originally sent to r-sig-geo list, with no response. Cross-posting
> > here, in the hope of a wider audience. Anyone with any experience in
> > this topic? Thanks.]
> >
> > I'm trying to get started analyzing the concentrations of smokestack
> > emissions. I don't have any professional background or training for
> > this; I'm just an old, retired guy who thinks playing with numbers is
> > fun.
> >
> > A local funeral home in my neighborhood (less than 1200 ft from my
> > home) is proposing to construct a crematorium for human remains. I have
> > some experience with the tidycensus package and thought it might be
> > interesting to construct a model for the changes in concentrations of
> > the pollutants from the smokestack and, using recorded wind speeds and
> > directions, see which US Census blocks would be affected.
> >
> > I have the US Government EPA SCREEN3 output on how concentration varies
> > with distance from the smokestack.
> > See
> > https://www.epa.gov/scram/air-quality-dispersion-modeling-screening-models#screen3
> > if curious. As a first task, I'd like to see if I can calculate similar
> > results in R. I'm aware of the 'plume' steady-state Gaussian dispersion
> > package
> > (https://rdrr.io/github/holstius/plume/f/inst/doc/plume-intro.pdf), but
> > am a little concerned that this package was last updated 11 years ago.
> >
> > Do you have any recommendations for me on how to get started analyzing
> > this problem? Is 'plume' still the way to go? I'm aware that there are
> > many atmospheric dispersion models from the US EPA, but I was hoping to
> > keep my work within R, which I'm really enjoying using and learning
> > about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> > ask questions about this topic?
> >
> > Thanks for any advice or guidance you have for me.
> >
> > -Kevin
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.r-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




------------------------------

Message: 9
Date: Tue, 12 Dec 2023 20:38:54 -0800
From: Bert Gunter <bgunter.4567 at gmail.com>
To: "Ebert,Timothy Aaron" <tebert at ufl.edu>
Cc: Kevin Zembower <kevin at zembower.org>, R-help email list
        <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?
Message-ID:
        <CAGxFJbRZ6L8XWGWOm404j2R2GvHtdy+TEPgTrTrW_ngPFvMS=Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

My point was only that there might be functionality there that might be
relevant to his concerns. .. with help on how to use it.

Bert

On Tue, Dec 12, 2023, 19:37 Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> That depends on how exactly everything must match your primary question.
> The ecology group might be helpful for how biodiversity changes with
> proximity to a smokestack. They might have a better idea if the smokestack
> was from a coal fired powerplant or oil refinery. The modeling process
> would be similar, though the abundance of individual contaminants would be
> quite different. Just my thought for what it is worth.
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
> Sent: Tuesday, December 12, 2023 10:53 AM
> To: Kevin Zembower <kevin at zembower.org>
> Cc: R-help email list <r-help at r-project.org>
> Subject: Re: [R] Advice on starting to analyze smokestack emissions?
>
> [External Email]
>
> You might also try the R-Sig-ecology list, though I would agree that it's
> not clearly related. Still, air pollution effects...?
>
> -- Bert
>
> On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
> r-help at r-project.org> wrote:
>
> > Hello, all,
> >
> > [Originally sent to r-sig-geo list, with no response. Cross-posting
> > here, in the hope of a wider audience. Anyone with any experience in
> > this topic? Thanks.]
> >
> > I'm trying to get started analyzing the concentrations of smokestack
> > emissions. I don't have any professional background or training for
> > this; I'm just an old, retired guy who thinks playing with numbers is
> > fun.
> >
> > A local funeral home in my neighborhood (less than 1200 ft from my
> > home) is proposing to construct a crematorium for human remains. I
> > have some experience with the tidycensus package and thought it might
> > be interesting to construct a model for the changes in concentrations
> > of the pollutants from the smokestack and, using recorded wind speeds
> > and directions, see which US Census blocks would be affected.
> >
> > I have the US Government EPA SCREEN3 output on how concentration
> > varies with distance from the smokestack.
> > See
> > https://www/.
> > epa.gov%2Fscram%2Fair-quality-dispersion-modeling-screening-models%23s
> > creen3&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7
> > ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7C
> > Unknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1h
> > aWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QgsYQ9w28caBmEGwJ9Kei2x0fSkH3
> > 4v3%2BfAo37GdcYQ%3D&reserved=0 if curious. As a first task, I'd like
> > to see if I can calculate similar results in R. I'm aware of the
> > 'plume' steady-state Gaussian dispersion package
> > (https://rdr/
> > r.io
> %2Fgithub%2Fholstius%2Fplume%2Ff%2Finst%2Fdoc%2Fplume-intro.pdf&data=05%7C02%7Ctebert%
> 40ufl.edu%7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=DN9oxiJnDFvvmY968G9t9Sagr8UfJ2ySZiGWV1%2F9AC8%3D&reserved=0),
> but am a little concerned that this package was last updated 11 years ago.
> >
> > Do you have any recommendations for me on how to get started analyzing
> > this problem? Is 'plume' still the way to go? I'm aware that there are
> > many atmospheric dispersion models from the US EPA, but I was hoping
> > to keep my work within R, which I'm really enjoying using and learning
> > about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> > ask questions about this topic?
> >
> > Thanks for any advice or guidance you have for me.
> >
> > -Kevin
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat/
> > .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> > %7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84
> > %7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> > MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sda
> > ta=dxsuLWVRx8wNnu49SJ34AAh7oRECvDIrQh9%2Bpx48SL0%3D&reserved=0
> > PLEASE do read the posting guide
> > http://www.r/
> > -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7C30
> > 97c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> > 7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> > CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QY
> > AiKA8xDhcPyQmRZ6Vqcr5mdszE8WSRyFmCqzQ7Rog%3D&reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]




------------------------------

Message: 10
Date: Wed, 13 Dec 2023 06:28:26 +0000
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Robert Baer <rbaer at atsu.edu>, varin sacha <varinsacha at yahoo.fr>,
        "r-help at r-project.org" <r-help at r-project.org>, Ben Bolker
        <bbolker at gmail.com>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence
        bands
Message-ID: <42a94897-80e8-4a89-918d-769b1b2eeadd at sapo.pt>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

?s 00:36 de 13/12/2023, Robert Baer escreveu:
> coord_cartesian also seems to work for y, and including the breaks = .
> How about:
>
> df=data.frame(year= c(2012,2015,2018,2022),
>                score=c(495,493, 495, 474))
>
> ggplot(df, aes(x = year, y = score)) +
>    geom_point() +
>    geom_smooth(method = "lm", formula = y ~ x) +
>    labs(title = "Standard linear regression for France", x = "Year", y =
> "PISA score in mathematics") +
>    coord_cartesian(ylim=c(470,500)) +
>    scale_x_continuous(breaks = 2012:2022)
>
> On 12/12/2023 3:19 PM, varin sacha via R-help wrote:
>> Dear Ben,
>> Dear Daniel,
>> Dear Rui,
>> Dear Bert,
>>
>> Here below my R code.
>> I really appreciate all your comments. My R code is perfectly working
>> but there is still something I would like to improve. The X-axis is
>> showing   2012.5 ;   2015.0   ;   2017.5   ;  2020.0
>> I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ;
>> 2020). How to do?
>>
>>
>> #########
>> library(ggplot2)
>> df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))
>>
>> ggplot(df, aes(x = year, y = score)) + geom_point() +
>> geom_smooth(method = "lm", formula = y ~ x) +
>>   labs(title = "Standard linear regression for France", x = "Year", y
>> = "PISA score in mathematics") +
>> scale_y_continuous(limits=c(470,500),oob=scales::squish)
>> #########
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker
>> <bbolker at gmail.com> a ?crit :
>>
>>
>>
>>
>>
>>
>>
>> On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
>>> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>>>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>>> Dear R-experts,
>>>>>
>>>>> Here below my R code, as my X-axis is "year", I must be missing one
>>>>> or more steps! I am trying to get the regression line with the 95%
>>>>> confidence bands around the regression line. Any help would be
>>>>> appreciated.
>>>>>
>>>>> Best,
>>>>> S.
>>>>>
>>>>>
>>>>> #############################################
>>>>> library(ggplot2)
>>>>>    df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>>>> score=c(495,493, 495, 474))
>>>>>    ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
>>>>> labs(title="Standard linear regression for France", y="PISA score in
>>>>> mathematics") + ylim(470, 500)
>>>>> #############################################
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.r-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> Hello,
>>>>
>>>> I don't see a reason why year should be a factor and the formula in
>>>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>>>> It still doesn't plot the CI's though. There's a warning and I am not
>>>> understanding where it comes from. But the regression line is plotted.
>>>>
>>>>
>>>>
>>>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>>>    geom_point() +
>>>>    geom_smooth(method = "lm", formula = y ~ x) +
>>>>    labs(
>>>>      title = "Standard linear regression for France",
>>>>      x = "Year",
>>>>      y = "PISA score in mathematics"
>>>>    ) +
>>>>    ylim(470, 500)
>>>> #> Warning message:
>>>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>>>> returning -Inf
>>>>
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>>
>>> After playing with this for a little while, I realized that the problem
>>> with plotting the confidence limits is the addition of ylim(470, 500).
>>> The confidence values are outside the ylim values.  Remove the limits,
>>> or increase the range, and the confidence curves will plot.
>>>
>>> Hope this is helpful,
>>>
>>> Dan
>>>
>>    Or use + scale_y_continuous(limits = c(470, 500), oob =
>> scales::squish)
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

In the code below I don't use coord_cartesian because to set ylim will
cut part of the confidence intervals.

To have labels only in the years present in the data set, get them from
the data.



library(ggplot2)

df <- data.frame(year= c(2012,2015,2018,2022),
                  score=c(495,493, 495, 474))

# in this case unique is not needed, it's here
# because it might with some data sets
brks_year <- df$year # |> unique()

ggplot(df, aes(x = year, y = score)) +
   geom_point() +
   geom_smooth(method = "lm", formula = y ~ x) +
   labs(title = "Standard linear regression for France",
        x = "Year", y = "PISA score in mathematics") +
   scale_x_continuous(breaks = brks_year)



Hope this helps,

Rui Barradas


--
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
http://www.avg.com/




------------------------------

Message: 11
Date: Wed, 13 Dec 2023 00:09:06 -0500
From: "Nan Xiao" <me at nanx.me>
To: r-packages at r-project.org
Subject: [R] [R-pkgs] simtrial: Clinical Trial Simulation
Message-ID: <79834370-a2ad-4a6a-8b55-19b29e998f8a at app.fastmail.com>
Content-Type: text/plain; charset="us-ascii"

Dear all,

I am happy to announce that {simtrial} is now on CRAN (https://cran.r-project.org/package=simtrial). simtrial is a fast and extensible clinical trial simulation framework for time-to-event endpoints.

This release brings a new tabular data processing engine powered by data.table for 3x to 5x faster simulations, a new parallelization adaptor with %dofuture%, a refreshed API that aligns with the gsDesign2 style guide, and new functions for zero early weight and analysis date. For a summary of the updates, please see the announcement: https://keaven.github.io/blog/simtrial-0-3-2/.

I hope you find simtrial helpful. Please feel free to reach out with feedback or questions.

Best regards,
-Nan

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages




------------------------------

Subject: Digest Footer

_______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


------------------------------

End of R-help Digest, Vol 250, Issue 13
***************************************

From kev|n @end|ng |rom zembower@org  Sat Dec 16 20:06:46 2023
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Sat, 16 Dec 2023 19:06:46 +0000
Subject: [R] Advice on starting to analyze smokestack emissions?
In-Reply-To: <23083e67b7fae00d31d8dc4871eaf4b8517419c3.camel@zembower.org>
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org> 
 <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
 <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com> 
 <CABcYAdLBgCy2b-QTOaedQ6dAo-LfuCHsDS6LgufbE1S0SByP3A@mail.gmail.com> 
 <23083e67b7fae00d31d8dc4871eaf4b8517419c3.camel@zembower.org> 
 <42108d3acfed25ad63fe0dfdc0ce4d4daad00f48.camel@zembower.org>
Message-ID: <0100018c74061d39-a7dd7b9b-0c47-4b85-8b8f-d0da78c448eb-000000@email.amazonses.com>

Just to follow up on this thread, I didn't experience any problems
accessing the air monitoring data with the RAQSAPI package that I
anticipated from the US EPA's Air Quality System (AQS) Data Mart
database website. I didn't have to qualify with an agency affiliation
at all, just an email address.

Thanks again, Karl, for suggesting this.

-Kevin

On Fri, 2023-12-15 at 08:29 -0500, Kevin Zembower wrote:
> Bert, Tim, Karl and Richard, thank you all for your suggestions and
> help.
> 
> I will try the R-sig-ecology list.
> 
> Karl, I wasn't aware of the RAQSAPI package, but it looked promising.
> However, when I went to the source of the data it uses, the United
> States Environmental Protection Agency?s (US EPA) Air Quality System
> (AQS) Data Mart database, it looks like interactive access to the
> data
> is restricted to those who can document a professional agency
> affiliation. I don't have that. I'll work with the package to see if
> this is true regarding obtaining the data through it. Thanks for the
> suggestion.
> 
> Richard, the Canada study of crematoriums was very useful. Thanks.
> 
> Thanks, again, all, for your help.
> 
> -Kevin




From sibyiie@stoeckii m@iii@g oii gmx@ch  Sat Dec 16 12:16:01 2023
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Sat, 16 Dec 2023 12:16:01 +0100
Subject: [R] ggplot 3-dimensions
Message-ID: <01a001da3011$4072bed0$c1583c70$@gmx.ch>

Dear R-user

Does anybody now, if ggplot allows to use two x-axis including two
dimensions (similar to excel plot (picture 1 in the pdf attachmet). If yes,
how should I adapt my code? The parameters are presented in the input file
(attachment: Input).

Fig2b = read.delim("BFF_Fig-2b.txt", na.strings="NA")
names(Fig2b)
head(Fig2b)
summary(Fig2b)
str(Fig2b)
Fig2b$Aspekt<-factor(Fig2b$Aspekt, levels=(c("Voegel", "Kleinsaeuger",
"Schnecken", "Regenwuermer_Asseln", "Pilze")))

### Figure 2b
  ggplot(Fig2b,aes(Aspekt,Wert,fill=Effekt))+
    geom_bar(stat="identity",position='fill')+
    scale_y_continuous(limits=c(0,14), expand=c(0,0))+
    labs(x="", y="Anzahl Studien pro Effekt")

Kind regards
Sibylle


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Picture1.pdf
Type: application/pdf
Size: 161275 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231216/d0705931/attachment.pdf>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Input.pdf
Type: application/pdf
Size: 70289 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231216/d0705931/attachment-0001.pdf>

From K@Ropk|n@ @end|ng |rom |eed@@@c@uk  Sat Dec 16 13:21:23 2023
From: K@Ropk|n@ @end|ng |rom |eed@@@c@uk (Karl Ropkins)
Date: Sat, 16 Dec 2023 12:21:23 +0000
Subject: [R] Advice on starting to analyze smokestack emissions?
Message-ID: <AS8PR03MB99334652DC20A3F9EDDBEC49AA92A@AS8PR03MB9933.eurprd03.prod.outlook.com>

Kevin,
Sorry, was not aware of any access-restriction, but if you have problems and were interested in local AQ maybe
https://www.epa.gov/outdoor-air-quality-data

Karl

------------------------------------------------------------------
[EXTERNAL]
Message: 3
Date: Fri, 15 Dec 2023 13:29:36 +0000
From: Kevin Zembower <kevin at zembower.org>
To: R-help email list <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?
Message-ID:
        <0100018c6dab10c0-a6da3643-a9f2-44af-8a69-9303ea534749-000000 at email.amazonses.com>

Content-Type: text/plain; charset="utf-8"

Bert, Tim, Karl and Richard, thank you all for your suggestions and
help.

I will try the R-sig-ecology list.

Karl, I wasn't aware of the RAQSAPI package, but it looked promising.
However, when I went to the source of the data it uses, the United
States Environmental Protection Agency?s (US EPA) Air Quality System
(AQS) Data Mart database, it looks like interactive access to the data
is restricted to those who can document a professional agency
affiliation. I don't have that. I'll work with the package to see if
this is true regarding obtaining the data through it. Thanks for the
suggestion.

Richard, the Canada study of crematoriums was very useful. Thanks.

Thanks, again, all, for your help.

-Kevin

You might also try the R-Sig-ecology list, though I would agree that it's not clearly related. Still, air pollution effects...?

-- Bert

On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help < r-help at r-project.org> wrote:

> Hello, all,
>
> [Originally sent to r-sig-geo list, with no response. Cross-posting
> here, in the hope of a wider audience. Anyone with any experience in
> this topic? Thanks.]
>
> I'm trying to get started analyzing the concentrations of smokestack
> emissions. I don't have any professional background or training for
> this; I'm just an old, retired guy who thinks playing with numbers is
> fun.
>
> A local funeral home in my neighborhood (less than 1200 ft from my
> home) is proposing to construct a crematorium for human remains. I
> have some experience with the tidycensus package and thought it might
> be interesting to construct a model for the changes in concentrations
> of the pollutants from the smokestack and, using recorded wind speeds
> and directions, see which US Census blocks would be affected.
>
> I have the US Government EPA SCREEN3 output on how concentration
> varies with distance from the smokestack.
> See
> https://www/.
> epa.gov%2Fscram%2Fair-quality-dispersion-modeling-screening-models%23s
> creen3&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7
> ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7C
> Unknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1h
> aWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QgsYQ9w28caBmEGwJ9Kei2x0fSkH3
> 4v3%2BfAo37GdcYQ%3D&reserved=0 if curious. As a first task, I'd like
> to see if I can calculate similar results in R. I'm aware of the
> 'plume' steady-state Gaussian dispersion package
> (https://rdr/
> r.io%2Fgithub%2Fholstius%2Fplume%2Ff%2Finst%2Fdoc%2Fplume-intro.pdf&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=DN9oxiJnDFvvmY968G9t9Sagr8UfJ2ySZiGWV1%2F9AC8%3D&reserved=0), but am a little concerned that this package was last updated 11 years ago.
>
> Do you have any recommendations for me on how to get started analyzing
> this problem? Is 'plume' still the way to go? I'm aware that there are
> many atmospheric dispersion models from the US EPA, but I was hoping
> to keep my work within R, which I'm really enjoying using and learning
> about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> ask questions about this topic?
>
> Thanks for any advice or guidance you have for me.
>
> -Kevin
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sda
> ta=dxsuLWVRx8wNnu49SJ34AAh7oRECvDIrQh9%2Bpx48SL0%3D&reserved=0
> PLEASE do read the posting guide
> http://www.r/
> -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7C30
> 97c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> 7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QY
> AiKA8xDhcPyQmRZ6Vqcr5mdszE8WSRyFmCqzQ7Rog%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


------------------------------

Message: 8
Date: Wed, 13 Dec 2023 17:38:43 +1300
From: "Richard O'Keefe" <raoknz at gmail.com>
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: Kevin Zembower <kevin at zembower.org>, R-help email list
        <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?
Message-ID:
        <CABcYAdLBgCy2b-QTOaedQ6dAo-LfuCHsDS6LgufbE1S0SByP3A at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

This https://ncceh.ca/resources/evidence-reviews/crematoria-emissions-and-air-quality-impacts
might provide some useful information.

On Wed, 13 Dec 2023 at 04:53, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You might also try the R-Sig-ecology list, though I would agree that it's
> not clearly related. Still, air pollution effects...?
>
> -- Bert
>
> On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
> r-help at r-project.org> wrote:
>
> > Hello, all,
> >
> > [Originally sent to r-sig-geo list, with no response. Cross-posting
> > here, in the hope of a wider audience. Anyone with any experience in
> > this topic? Thanks.]
> >
> > I'm trying to get started analyzing the concentrations of smokestack
> > emissions. I don't have any professional background or training for
> > this; I'm just an old, retired guy who thinks playing with numbers is
> > fun.
> >
> > A local funeral home in my neighborhood (less than 1200 ft from my
> > home) is proposing to construct a crematorium for human remains. I have
> > some experience with the tidycensus package and thought it might be
> > interesting to construct a model for the changes in concentrations of
> > the pollutants from the smokestack and, using recorded wind speeds and
> > directions, see which US Census blocks would be affected.
> >
> > I have the US Government EPA SCREEN3 output on how concentration varies
> > with distance from the smokestack.
> > See
> > https://www.epa.gov/scram/air-quality-dispersion-modeling-screening-models#screen3
> > if curious. As a first task, I'd like to see if I can calculate similar
> > results in R. I'm aware of the 'plume' steady-state Gaussian dispersion
> > package
> > (https://rdrr.io/github/holstius/plume/f/inst/doc/plume-intro.pdf), but
> > am a little concerned that this package was last updated 11 years ago.
> >
> > Do you have any recommendations for me on how to get started analyzing
> > this problem? Is 'plume' still the way to go? I'm aware that there are
> > many atmospheric dispersion models from the US EPA, but I was hoping to
> > keep my work within R, which I'm really enjoying using and learning
> > about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> > ask questions about this topic?
> >
> > Thanks for any advice or guidance you have for me.
> >
> > -Kevin
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.r-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




------------------------------

Message: 9
Date: Tue, 12 Dec 2023 20:38:54 -0800
From: Bert Gunter <bgunter.4567 at gmail.com>
To: "Ebert,Timothy Aaron" <tebert at ufl.edu>
Cc: Kevin Zembower <kevin at zembower.org>, R-help email list
        <r-help at r-project.org>
Subject: Re: [R] Advice on starting to analyze smokestack emissions?
Message-ID:
        <CAGxFJbRZ6L8XWGWOm404j2R2GvHtdy+TEPgTrTrW_ngPFvMS=Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

My point was only that there might be functionality there that might be
relevant to his concerns. .. with help on how to use it.

Bert

On Tue, Dec 12, 2023, 19:37 Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> That depends on how exactly everything must match your primary question.
> The ecology group might be helpful for how biodiversity changes with
> proximity to a smokestack. They might have a better idea if the smokestack
> was from a coal fired powerplant or oil refinery. The modeling process
> would be similar, though the abundance of individual contaminants would be
> quite different. Just my thought for what it is worth.
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
> Sent: Tuesday, December 12, 2023 10:53 AM
> To: Kevin Zembower <kevin at zembower.org>
> Cc: R-help email list <r-help at r-project.org>
> Subject: Re: [R] Advice on starting to analyze smokestack emissions?
>
> [External Email]
>
> You might also try the R-Sig-ecology list, though I would agree that it's
> not clearly related. Still, air pollution effects...?
>
> -- Bert
>
> On Tue, Dec 12, 2023 at 3:15?AM Kevin Zembower via R-help <
> r-help at r-project.org> wrote:
>
> > Hello, all,
> >
> > [Originally sent to r-sig-geo list, with no response. Cross-posting
> > here, in the hope of a wider audience. Anyone with any experience in
> > this topic? Thanks.]
> >
> > I'm trying to get started analyzing the concentrations of smokestack
> > emissions. I don't have any professional background or training for
> > this; I'm just an old, retired guy who thinks playing with numbers is
> > fun.
> >
> > A local funeral home in my neighborhood (less than 1200 ft from my
> > home) is proposing to construct a crematorium for human remains. I
> > have some experience with the tidycensus package and thought it might
> > be interesting to construct a model for the changes in concentrations
> > of the pollutants from the smokestack and, using recorded wind speeds
> > and directions, see which US Census blocks would be affected.
> >
> > I have the US Government EPA SCREEN3 output on how concentration
> > varies with distance from the smokestack.
> > See
> > https://www/.
> > epa.gov%2Fscram%2Fair-quality-dispersion-modeling-screening-models%23s
> > creen3&data=05%7C02%7Ctebert%40ufl.edu%7C3097c182143c47a6789c08dbfb2a7
> > ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7C
> > Unknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1h
> > aWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QgsYQ9w28caBmEGwJ9Kei2x0fSkH3
> > 4v3%2BfAo37GdcYQ%3D&reserved=0 if curious. As a first task, I'd like
> > to see if I can calculate similar results in R. I'm aware of the
> > 'plume' steady-state Gaussian dispersion package
> > (https://rdr/
> > r.io
> %2Fgithub%2Fholstius%2Fplume%2Ff%2Finst%2Fdoc%2Fplume-intro.pdf&data=05%7C02%7Ctebert%
> 40ufl.edu%7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=DN9oxiJnDFvvmY968G9t9Sagr8UfJ2ySZiGWV1%2F9AC8%3D&reserved=0),
> but am a little concerned that this package was last updated 11 years ago.
> >
> > Do you have any recommendations for me on how to get started analyzing
> > this problem? Is 'plume' still the way to go? I'm aware that there are
> > many atmospheric dispersion models from the US EPA, but I was hoping
> > to keep my work within R, which I'm really enjoying using and learning
> > about. Are SCREEN3 and 'plume' comparable? Is this the best R list to
> > ask questions about this topic?
> >
> > Thanks for any advice or guidance you have for me.
> >
> > -Kevin
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat/
> > .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> > %7C3097c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84
> > %7C0%7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> > MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sda
> > ta=dxsuLWVRx8wNnu49SJ34AAh7oRECvDIrQh9%2Bpx48SL0%3D&reserved=0
> > PLEASE do read the posting guide
> > http://www.r/
> > -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7C30
> > 97c182143c47a6789c08dbfb2a7ed2%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> > 7C0%7C638379932467260671%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> > CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=QY
> > AiKA8xDhcPyQmRZ6Vqcr5mdszE8WSRyFmCqzQ7Rog%3D&reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]




------------------------------

Message: 10
Date: Wed, 13 Dec 2023 06:28:26 +0000
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Robert Baer <rbaer at atsu.edu>, varin sacha <varinsacha at yahoo.fr>,
        "r-help at r-project.org" <r-help at r-project.org>, Ben Bolker
        <bbolker at gmail.com>
Subject: Re: [R] ggplot2: Get the regression line with 95% confidence
        bands
Message-ID: <42a94897-80e8-4a89-918d-769b1b2eeadd at sapo.pt>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

?s 00:36 de 13/12/2023, Robert Baer escreveu:
> coord_cartesian also seems to work for y, and including the breaks = .
> How about:
>
> df=data.frame(year= c(2012,2015,2018,2022),
>                score=c(495,493, 495, 474))
>
> ggplot(df, aes(x = year, y = score)) +
>    geom_point() +
>    geom_smooth(method = "lm", formula = y ~ x) +
>    labs(title = "Standard linear regression for France", x = "Year", y =
> "PISA score in mathematics") +
>    coord_cartesian(ylim=c(470,500)) +
>    scale_x_continuous(breaks = 2012:2022)
>
> On 12/12/2023 3:19 PM, varin sacha via R-help wrote:
>> Dear Ben,
>> Dear Daniel,
>> Dear Rui,
>> Dear Bert,
>>
>> Here below my R code.
>> I really appreciate all your comments. My R code is perfectly working
>> but there is still something I would like to improve. The X-axis is
>> showing   2012.5 ;   2015.0   ;   2017.5   ;  2020.0
>> I would like to see on X-axis only the year (2012 ; 2015 ; 2017 ;
>> 2020). How to do?
>>
>>
>> #########
>> library(ggplot2)
>> df=data.frame(year= c(2012,2015,2018,2022), score=c(495,493, 495, 474))
>>
>> ggplot(df, aes(x = year, y = score)) + geom_point() +
>> geom_smooth(method = "lm", formula = y ~ x) +
>>   labs(title = "Standard linear regression for France", x = "Year", y
>> = "PISA score in mathematics") +
>> scale_y_continuous(limits=c(470,500),oob=scales::squish)
>> #########
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Le lundi 11 d?cembre 2023 ? 23:38:06 UTC+1, Ben Bolker
>> <bbolker at gmail.com> a ?crit :
>>
>>
>>
>>
>>
>>
>>
>> On 2023-12-11 5:27 p.m., Daniel Nordlund wrote:
>>> On 12/10/2023 2:50 PM, Rui Barradas wrote:
>>>> ?s 22:35 de 10/12/2023, varin sacha via R-help escreveu:
>>>>> Dear R-experts,
>>>>>
>>>>> Here below my R code, as my X-axis is "year", I must be missing one
>>>>> or more steps! I am trying to get the regression line with the 95%
>>>>> confidence bands around the regression line. Any help would be
>>>>> appreciated.
>>>>>
>>>>> Best,
>>>>> S.
>>>>>
>>>>>
>>>>> #############################################
>>>>> library(ggplot2)
>>>>>    df=data.frame(year=factor(c("2012","2015","2018","2022")),
>>>>> score=c(495,493, 495, 474))
>>>>>    ggplot(df, aes(x=year, y=score)) + geom_point( ) +
>>>>> geom_smooth(method="lm", formula = score ~ factor(year), data = df) +
>>>>> labs(title="Standard linear regression for France", y="PISA score in
>>>>> mathematics") + ylim(470, 500)
>>>>> #############################################
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.r-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> Hello,
>>>>
>>>> I don't see a reason why year should be a factor and the formula in
>>>> geom_smooth is wrong, it should be y ~ x, the aesthetics envolved.
>>>> It still doesn't plot the CI's though. There's a warning and I am not
>>>> understanding where it comes from. But the regression line is plotted.
>>>>
>>>>
>>>>
>>>> ggplot(df, aes(x = as.numeric(year), y = score)) +
>>>>    geom_point() +
>>>>    geom_smooth(method = "lm", formula = y ~ x) +
>>>>    labs(
>>>>      title = "Standard linear regression for France",
>>>>      x = "Year",
>>>>      y = "PISA score in mathematics"
>>>>    ) +
>>>>    ylim(470, 500)
>>>> #> Warning message:
>>>> #> In max(ids, na.rm = TRUE) : no non-missing arguments to max;
>>>> returning -Inf
>>>>
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>>
>>>>
>>> After playing with this for a little while, I realized that the problem
>>> with plotting the confidence limits is the addition of ylim(470, 500).
>>> The confidence values are outside the ylim values.  Remove the limits,
>>> or increase the range, and the confidence curves will plot.
>>>
>>> Hope this is helpful,
>>>
>>> Dan
>>>
>>    Or use + scale_y_continuous(limits = c(470, 500), oob =
>> scales::squish)
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

In the code below I don't use coord_cartesian because to set ylim will
cut part of the confidence intervals.

To have labels only in the years present in the data set, get them from
the data.



library(ggplot2)

df <- data.frame(year= c(2012,2015,2018,2022),
                  score=c(495,493, 495, 474))

# in this case unique is not needed, it's here
# because it might with some data sets
brks_year <- df$year # |> unique()

ggplot(df, aes(x = year, y = score)) +
   geom_point() +
   geom_smooth(method = "lm", formula = y ~ x) +
   labs(title = "Standard linear regression for France",
        x = "Year", y = "PISA score in mathematics") +
   scale_x_continuous(breaks = brks_year)



Hope this helps,

Rui Barradas


--
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
http://www.avg.com/




------------------------------

Message: 11
Date: Wed, 13 Dec 2023 00:09:06 -0500
From: "Nan Xiao" <me at nanx.me>
To: r-packages at r-project.org
Subject: [R] [R-pkgs] simtrial: Clinical Trial Simulation
Message-ID: <79834370-a2ad-4a6a-8b55-19b29e998f8a at app.fastmail.com>
Content-Type: text/plain; charset="us-ascii"

Dear all,

I am happy to announce that {simtrial} is now on CRAN (https://cran.r-project.org/package=simtrial). simtrial is a fast and extensible clinical trial simulation framework for time-to-event endpoints.

This release brings a new tabular data processing engine powered by data.table for 3x to 5x faster simulations, a new parallelization adaptor with %dofuture%, a refreshed API that aligns with the gsDesign2 style guide, and new functions for zero early weight and analysis date. For a summary of the updates, please see the announcement: https://keaven.github.io/blog/simtrial-0-3-2/.

I hope you find simtrial helpful. Please feel free to reach out with feedback or questions.

Best regards,
-Nan

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages




------------------------------

Subject: Digest Footer

_______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


------------------------------

End of R-help Digest, Vol 250, Issue 13
***************************************


------------------------------

Subject: Digest Footer

_______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


------------------------------

End of R-help Digest, Vol 250, Issue 16
***************************************

From moh@med@ezz@t@@bde|@zez @end|ng |rom gm@||@com  Sat Dec 16 19:39:50 2023
From: moh@med@ezz@t@@bde|@zez @end|ng |rom gm@||@com (Mohamed Ezzat)
Date: Sat, 16 Dec 2023 20:39:50 +0200
Subject: [R] Exponential Autoregressive time series model EAR(1)
Message-ID: <CAO2Ue7d2dak6eGH0d3zsz=yhy2qDd04jMVv3iSv1Ym9=XrGZzA@mail.gmail.com>

Dears,

I hope that email finds you well.

I'm sending you this email to ask if there is any built in R code for
simulating the Exponential Autoregressive time series model of order 1
EAR(1).

So, please provide me with the code if the code already exists


Thanks in advance.

	[[alternative HTML version deleted]]


From @zhr|e|1 @end|ng |rom gm@||@com  Sat Dec 16 21:39:16 2023
From: @zhr|e|1 @end|ng |rom gm@||@com (Alipio Galiana)
Date: Sat, 16 Dec 2023 21:39:16 +0100
Subject: [R] call: file.exists("~/.Rtk2theme") error: file name conversion
 problem -- name too long?
Message-ID: <CA+QV77Gxt33YYpALPii897Vop=iDy05EVA2=XPaddS5s_X+F3w@mail.gmail.com>

I'm trying to study with r-commander but for a few days now I've been
getting this error.

> library (Rcmdr)
Error: package or namespace load failed for ?Rcmdr?:
 .onLoad failed in loadNamespace() for 'tcltk2', details:
  call: file.exists("~/.Rtk2theme")
  error: file name conversion problem -- name too long?



I have uninstalled, deleted, reinstalled several times and always the same
error. can anybody help me?
i'm work under R version 4.3.2

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sun Dec 17 08:38:36 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sun, 17 Dec 2023 10:38:36 +0300
Subject: [R] 
 call: file.exists("~/.Rtk2theme") error: file name conversion
 problem -- name too long?
In-Reply-To: <CA+QV77Gxt33YYpALPii897Vop=iDy05EVA2=XPaddS5s_X+F3w@mail.gmail.com>
References: <CA+QV77Gxt33YYpALPii897Vop=iDy05EVA2=XPaddS5s_X+F3w@mail.gmail.com>
Message-ID: <20231217103836.0e776e5c@Tarkus>

On Sat, 16 Dec 2023 21:39:16 +0100
Alipio Galiana <azhriel1 at gmail.com> wrote:

>   call: file.exists("~/.Rtk2theme")
>   error: file name conversion problem -- name too long?

When you type file.exists('~/.Rtk2theme') into R, do you get the same
error? Does such file actually exist in your home directory?

> i'm work under R version 4.3.2

What's the output of sessionInfo() and path.expand('~')? Feel free to
redact the user name, but please preserve the number of characters and
let us know whether they are non-ASCII.

-- 
Best regards,
Ivan


From sibyiie@stoeckii m@iii@g oii gmx@ch  Sun Dec 17 10:13:24 2023
From: sibyiie@stoeckii m@iii@g oii gmx@ch (sibyiie@stoeckii m@iii@g oii gmx@ch)
Date: Sun, 17 Dec 2023 10:13:24 +0100
Subject: [R] ggplot 3-dimensions
In-Reply-To: <01a001da3011$4072bed0$c1583c70$@gmx.ch>
References: <01a001da3011$4072bed0$c1583c70$@gmx.ch>
Message-ID: <010e01da30c9$4a1598a0$de40c9e0$@gmx.ch>

Dear R community

In the meantime I made some progress:
  ggplot(data = Fig2b, aes(x = BFF, y = Wert, fill = Effekt))+theme_bw()+ 
    geom_bar(stat = "identity", width = 0.95) +
    scale_y_continuous(limits=c(0,13), expand=c(0,0))+
    facet_wrap(~Aspekt, strip.position = "bottom", scales = "free_x") +
    theme(panel.spacing = unit(0, "lines"), 
          strip.background = element_blank(),
          strip.placement = "outside")+
    theme(axis.title.x=element_blank())+
    scale_fill_manual("Effekt", values = c("Neg" = "red", "Neu" =
"darkgrey", "Pos" = "blue"), labels=c("Negativ", "Nicht sign.", "Positiv"))
  
  
Question
- Is it possible to present all the subpolots in one graph (not to "lines")?

- I tried to change the angel of the x-axis. However, I was able to change
the first x-axis (BB...), but not the second one (Voegel....). Maybe this
would solve the problem.
- If not, is there another possibility to fix the number of subplots per
line?

Kind regards
Sibylle

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of SIBYLLE ST?CKLI via
R-help
Sent: Saturday, December 16, 2023 12:16 PM
To: R-help at r-project.org
Subject: [R] ggplot 3-dimensions

Dear R-user

Does anybody now, if ggplot allows to use two x-axis including two
dimensions (similar to excel plot (picture 1 in the pdf attachmet). If yes,
how should I adapt my code? The parameters are presented in the input file
(attachment: Input).

Fig2b = read.delim("BFF_Fig-2b.txt", na.strings="NA")
names(Fig2b)
head(Fig2b)
summary(Fig2b)
str(Fig2b)
Fig2b$Aspekt<-factor(Fig2b$Aspekt, levels=(c("Voegel", "Kleinsaeuger",
"Schnecken", "Regenwuermer_Asseln", "Pilze")))

### Figure 2b
  ggplot(Fig2b,aes(Aspekt,Wert,fill=Effekt))+
    geom_bar(stat="identity",position='fill')+
    scale_y_continuous(limits=c(0,14), expand=c(0,0))+
    labs(x="", y="Anzahl Studien pro Effekt")

Kind regards
Sibylle


-------------- next part --------------
A non-text attachment was scrubbed...
Name: ggplot_3dim.pdf
Type: application/pdf
Size: 5687 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20231217/c543c7de/attachment.pdf>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Dec 17 14:08:45 2023
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 17 Dec 2023 13:08:45 +0000
Subject: [R] ggplot 3-dimensions
In-Reply-To: <010e01da30c9$4a1598a0$de40c9e0$@gmx.ch>
References: <01a001da3011$4072bed0$c1583c70$@gmx.ch>
 <010e01da30c9$4a1598a0$de40c9e0$@gmx.ch>
Message-ID: <156c796a-16db-41e0-a9da-0577f51ebc87@sapo.pt>

?s 09:13 de 17/12/2023, SIBYLLE ST?CKLI via R-help escreveu:
> Dear R community
> 
> In the meantime I made some progress:
>    ggplot(data = Fig2b, aes(x = BFF, y = Wert, fill = Effekt))+theme_bw()+
>      geom_bar(stat = "identity", width = 0.95) +
>      scale_y_continuous(limits=c(0,13), expand=c(0,0))+
>      facet_wrap(~Aspekt, strip.position = "bottom", scales = "free_x") +
>      theme(panel.spacing = unit(0, "lines"),
>            strip.background = element_blank(),
>            strip.placement = "outside")+
>      theme(axis.title.x=element_blank())+
>      scale_fill_manual("Effekt", values = c("Neg" = "red", "Neu" =
> "darkgrey", "Pos" = "blue"), labels=c("Negativ", "Nicht sign.", "Positiv"))
>    
>    
> Question
> - Is it possible to present all the subpolots in one graph (not to "lines")?
> 
> - I tried to change the angel of the x-axis. However, I was able to change
> the first x-axis (BB...), but not the second one (Voegel....). Maybe this
> would solve the problem.
> - If not, is there another possibility to fix the number of subplots per
> line?
> 
> Kind regards
> Sibylle
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of SIBYLLE ST?CKLI via
> R-help
> Sent: Saturday, December 16, 2023 12:16 PM
> To: R-help at r-project.org
> Subject: [R] ggplot 3-dimensions
> 
> Dear R-user
> 
> Does anybody now, if ggplot allows to use two x-axis including two
> dimensions (similar to excel plot (picture 1 in the pdf attachmet). If yes,
> how should I adapt my code? The parameters are presented in the input file
> (attachment: Input).
> 
> Fig2b = read.delim("BFF_Fig-2b.txt", na.strings="NA")
> names(Fig2b)
> head(Fig2b)
> summary(Fig2b)
> str(Fig2b)
> Fig2b$Aspekt<-factor(Fig2b$Aspekt, levels=(c("Voegel", "Kleinsaeuger",
> "Schnecken", "Regenwuermer_Asseln", "Pilze")))
> 
> ### Figure 2b
>    ggplot(Fig2b,aes(Aspekt,Wert,fill=Effekt))+
>      geom_bar(stat="identity",position='fill')+
>      scale_y_continuous(limits=c(0,14), expand=c(0,0))+
>      labs(x="", y="Anzahl Studien pro Effekt")
> 
> Kind regards
> Sibylle
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

You are posting the data as image once again, please don't do this.
Paste the output of

dput(Fig2b)            # if small data
dput(head(Fig2b, 20))  # if too big to fit in an e-mail


in your mails. Here it is.



Aspekt <- c("Flora", "Flora", "Flora", "Tagfalter", "Tagfalter", 
"Tagfalter",
             "Heuschre", "Heuschre", "Heuschre", "Kaefer_Sp", 
"Kaefer_Sp", "Kaefer_Sp",
             "Schwebfli", "Schwebfli", "Schwebfli", "Bienen_F", 
"Bienen_F", "Bienen_F")
Aspekt <- c(Aspekt, Aspekt)
BFF <- rep(c("BB", "SA", "NE"), times = 12)
Effekt <- c(rep("Neg", times = 18), rep("Pos", times = 18))
Wert <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,
           2, 1, 0, 0, 1, 0, 9, 4, 6, 0, 0, 3, 0, 0, 4)
Fig2b <- data.frame(Aspekt, BFF, Effekt, Wert)



As for the question, you can use facet_wrap argument nrow to have all 
plots in one row only, see the comment before facet_wrap. I don't know 
if this solves the problem.
Also, I define a custom theme to make the code clearer later.



library(ggplot2)

theme_sibylle <- function() {
   theme_bw(base_size = 10) %+replace%
     theme(
       panel.spacing = unit(0, "lines"),
       strip.background = element_blank(),
       strip.placement = "outside",
       # this line was added by me, remove if not wanted
       strip.text.x.bottom = element_text(face = "bold", size = 10),
       axis.title.x = element_blank()
     )
}

ggplot(data = Fig2b, aes(x = BFF, y = Wert, fill = Effekt)) +
   geom_bar(stat = "identity", width = 0.95) +
   scale_y_continuous(limits=c(0,13), expand=c(0,0)) +
   # here I use nrow = 1L to put everything in one row only
   facet_wrap(~ Aspekt, nrow = 1L, strip.position = "bottom", scales = 
"free_x") +
   scale_fill_manual(
     name = "Effekt",
     values = c("Neg" = "red", "Neu" = "darkgrey", "Pos" = "blue"),
     labels = c("Negativ", "Nicht sign.", "Positiv")) +
   theme_sibylle()



Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From kry|ov@r00t @end|ng |rom gm@||@com  Sun Dec 17 15:25:38 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sun, 17 Dec 2023 17:25:38 +0300
Subject: [R] 
 call: file.exists("~/.Rtk2theme") error: file name conversion
 problem -- name too long?
In-Reply-To: <005c01da30f2$e60c5e00$b2251a00$@gmail.com>
References: <CA+QV77Gxt33YYpALPii897Vop=iDy05EVA2=XPaddS5s_X+F3w@mail.gmail.com>
 <20231217103836.0e776e5c@Tarkus>
 <005c01da30f2$e60c5e00$b2251a00$@gmail.com>
Message-ID: <20231217172538.01349830@Tarkus>

Dear Alipio Galiana,

Please keep the mailing list in the "copy" field of your messages. This
way other people can chime in with advice too.

On Sun, 17 Dec 2023 15:11:14 +0100
<azhriel1 at gmail.com> wrote:

> > sessionInfo()  
> R version 4.3.2 (2023-10-31 ucrt)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 11 x64 (build 22631)
> 
> Matrix products: default
> 
> 
> locale:
> [1] LC_COLLATE=Spanish_Spain.utf8  LC_CTYPE=Spanish_Spain.utf8   
> [3] LC_MONETARY=Spanish_Spain.utf8 LC_NUMERIC=C                  
> [5] LC_TIME=Spanish_Spain.utf8    

> > path.expand('~')  
> [1] "C:\\Users\\Alipio\\OneDrive - Universitat de
> Val\xe8ncia\\Documentos"

The problem here is that R thinks that your "Documents" directory has
a path that contains invalid UTF-8 bytes. This causes file.exists(...)
to fail when it tries to decode the path as UTF-8.

Can you at least temporarily disable OneDrive so that your Documents
directory would be "C:\\Users\\Alipio\\Documentos"? This should keep R
happy.

The proper solution would be to figure out why R is getting an
ANSI-encoded path to the Documents directory instead of it being in
UTF-8. I don't have Windows 11 installed or OneDrive set up to keep my
data, so you might need the help of someone else with this.

-- 
Best regards,
Ivan


From bgunter@4567 @end|ng |rom gm@||@com  Sun Dec 17 16:27:59 2023
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 17 Dec 2023 07:27:59 -0800
Subject: [R] Exponential Autoregressive time series model EAR(1)
In-Reply-To: <CAO2Ue7d2dak6eGH0d3zsz=yhy2qDd04jMVv3iSv1Ym9=XrGZzA@mail.gmail.com>
References: <CAO2Ue7d2dak6eGH0d3zsz=yhy2qDd04jMVv3iSv1Ym9=XrGZzA@mail.gmail.com>
Message-ID: <CAGxFJbSRpLBP2awD+LtaU2RdAS9+MZAPrSgnfevH=6u3nsX-Rw@mail.gmail.com>

If you have not already done so, I suggest you look here:
https://cran.r-project.org/web/views/TimeSeries.html

(R task views are an excellent place to look for such queries)

Or a web search here:
https://rseek.org/

-- Bert

On Sat, Dec 16, 2023 at 11:31?PM Mohamed Ezzat <
mohamed.ezzat.abdelazez at gmail.com> wrote:

> Dears,
>
> I hope that email finds you well.
>
> I'm sending you this email to ask if there is any built in R code for
> simulating the Exponential Autoregressive time series model of order 1
> EAR(1).
>
> So, please provide me with the code if the code already exists
>
>
> Thanks in advance.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sun Dec 17 17:27:07 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sun, 17 Dec 2023 19:27:07 +0300
Subject: [R] 
 call: file.exists("~/.Rtk2theme") error: file name conversion
 problem -- name too long?
In-Reply-To: <20231217172538.01349830@Tarkus>
References: <CA+QV77Gxt33YYpALPii897Vop=iDy05EVA2=XPaddS5s_X+F3w@mail.gmail.com>
 <20231217103836.0e776e5c@Tarkus>
 <005c01da30f2$e60c5e00$b2251a00$@gmail.com>
 <20231217172538.01349830@Tarkus>
Message-ID: <20231217192707.5ac0203a@Tarkus>

Sorry for the double e-mail.

On Sun, 17 Dec 2023 17:25:38 +0300
Ivan Krylov <krylov.r00t at gmail.com> wrote:

> Can you at least temporarily disable OneDrive so that your Documents
> directory would be "C:\\Users\\Alipio\\Documentos"? This should keep R
> happy.

It should also work if you set the environment variable R_USER to
some ASCII-representable path:

(in cmd.exe):
> set R_USER=C:\Users\Alipio\R_USER
> "C:\Program Files\R\R-4.3.2\bin\R.exe" CMD Rgui

Please let me know if setting the environment variable helps.

I suspect that getenv() may be returning ANSI-encoded bytes even when
the UCRT locale encoding is set to UTF-8.

-- 
Best regards,
Ivan


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Mon Dec 18 00:20:44 2023
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sun, 17 Dec 2023 23:20:44 +0000
Subject: [R] Advice on starting to analyze smokestack emissions?
In-Reply-To: <0100018c74061d39-a7dd7b9b-0c47-4b85-8b8f-d0da78c448eb-000000@email.amazonses.com>
References: <9471c973394eca9937309cbdb29edae86a755696.camel@zembower.org>
 <0100018c5dbd39ea-006d9250-2a70-41ec-9bfb-507dbd7b1c0b-000000@email.amazonses.com>
 <CAGxFJbTox2EW5kaZ1Y3KS9=kvndjP-tWFzp8YThbuNLyQmARNg@mail.gmail.com>
 <CABcYAdLBgCy2b-QTOaedQ6dAo-LfuCHsDS6LgufbE1S0SByP3A@mail.gmail.com>
 <23083e67b7fae00d31d8dc4871eaf4b8517419c3.camel@zembower.org>
 <42108d3acfed25ad63fe0dfdc0ce4d4daad00f48.camel@zembower.org>
 <0100018c74061d39-a7dd7b9b-0c47-4b85-8b8f-d0da78c448eb-000000@email.amazonses.com>
Message-ID: <DM6PR03MB5049D5EF1D7A1F6256A12130E291A@DM6PR03MB5049.namprd03.prod.outlook.com>

Kevin,
I would like to be in touch with you. I am pursuing a research project similar to yours. Perhaps we can help each other.
John
JSorkin at som.umaryland.edu

John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;

Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;

PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;

Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Kevin Zembower via R-help <r-help at r-project.org>
Sent: Saturday, December 16, 2023 2:06 PM
To: R-help email list
Subject: Re: [R] Advice on starting to analyze smokestack emissions?

Just to follow up on this thread, I didn't experience any problems
accessing the air monitoring data with the RAQSAPI package that I
anticipated from the US EPA's Air Quality System (AQS) Data Mart
database website. I didn't have to qualify with an agency affiliation
at all, just an email address.

Thanks again, Karl, for suggesting this.

-Kevin

On Fri, 2023-12-15 at 08:29 -0500, Kevin Zembower wrote:
> Bert, Tim, Karl and Richard, thank you all for your suggestions and
> help.
>
> I will try the R-sig-ecology list.
>
> Karl, I wasn't aware of the RAQSAPI package, but it looked promising.
> However, when I went to the source of the data it uses, the United
> States Environmental Protection Agency?s (US EPA) Air Quality System
> (AQS) Data Mart database, it looks like interactive access to the
> data
> is restricted to those who can document a professional agency
> affiliation. I don't have that. I'll work with the package to see if
> this is true regarding obtaining the data through it. Thanks for the
> suggestion.
>
> Richard, the Canada study of crematoriums was very useful. Thanks.
>
> Thanks, again, all, for your help.
>
> -Kevin



______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @zhr|e|1 @end|ng |rom gm@||@com  Sun Dec 17 18:16:37 2023
From: @zhr|e|1 @end|ng |rom gm@||@com (Alipio Galiana)
Date: Sun, 17 Dec 2023 18:16:37 +0100
Subject: [R] 
 call: file.exists("~/.Rtk2theme") error: file name conversion
 problem -- name too long?
In-Reply-To: <20231217192707.5ac0203a@Tarkus>
References: <CA+QV77Gxt33YYpALPii897Vop=iDy05EVA2=XPaddS5s_X+F3w@mail.gmail.com>
 <20231217103836.0e776e5c@Tarkus> <005c01da30f2$e60c5e00$b2251a00$@gmail.com>
 <20231217172538.01349830@Tarkus> <20231217192707.5ac0203a@Tarkus>
Message-ID: <CA+QV77Huv7gxgb3tpvd7Foii-yr9A0+OVyqfz8Nr8v-ymUUg4w@mail.gmail.com>

Thank you, I finally downloaded a portable version that I found and it
works correctly, so I can, at least, do the exercises for the subject.
Greetings and thank you very much for your time.


El dom, 17 dic 2023 a las 17:27, Ivan Krylov (<krylov.r00t at gmail.com>)
escribi?:

> Sorry for the double e-mail.
>
> On Sun, 17 Dec 2023 17:25:38 +0300
> Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> > Can you at least temporarily disable OneDrive so that your Documents
> > directory would be "C:\\Users\\Alipio\\Documentos"? This should keep R
> > happy.
>
> It should also work if you set the environment variable R_USER to
> some ASCII-representable path:
>
> (in cmd.exe):
> > set R_USER=C:\Users\Alipio\R_USER
> > "C:\Program Files\R\R-4.3.2\bin\R.exe" CMD Rgui
>
> Please let me know if setting the environment variable helps.
>
> I suspect that getenv() may be returning ANSI-encoded bytes even when
> the UCRT locale encoding is set to UTF-8.
>
> --
> Best regards,
> Ivan
>

	[[alternative HTML version deleted]]


From em||yb@kker @end|ng |rom out|ook@com  Mon Dec 18 10:56:16 2023
From: em||yb@kker @end|ng |rom out|ook@com (Emily Bakker)
Date: Mon, 18 Dec 2023 09:56:16 +0000
Subject: [R] Function with large nested list
Message-ID: <AM9P195MB096574A3342894802CF270B5BC8DA@AM9P195MB0965.EURP195.PROD.OUTLOOK.COM>

Hello list,

I want to make a large rulebased algorithm, to provide decision support for drug prescriptions. I have defined the algorithm in a function, with a for loop and many if statements. The structure should be as follows:
1. Iterate over a list of drug names. For each drug:
2. Get some drug related data (external dataset). Row of a dataframe.
3.  Check if adaptions should be made to standard dosage and safety information in case of contraindications. If patient has an indication, update current dosage and safety information with the value from the dataframe row. 
4. Save dosage and safety information in some lists and continue to the next drug. 
5. When the iteration over all drugs is done, return the lists.

ISSUE:
So it is a very large function with many nested if statements. I have checked the code structure multiple times, but i run into some issues. When i try to run the function definiton, the command never "completes" in de console. Instead of ">", the console shows "+". No errors are raised.

As I said, i have checked the structure multiple times, but cant find an error. I have tried rebuilding it and testing each time i add a part. Each part functions isolated, but not together in the same function. I can't find any infinite loops either. 
I suspect the function may be too large, and i have to define functions for each part separately. That isn't an issue necessarily, but i would still like to know why my code won't run. And whether there are any downsides or considerations for using many small functions.

Below is my code. I have left part of it out. There are six more parts like the diabetes part that are similar.
I also use a lot of data/variabeles not included here, to try and keep things compact. But I can provide additional information if helpful.
Thanks it advance for thinking along!!
Kind regards,
Emily

The code:

decision_algorithm <- function(AB_list, dataset_ab = data.frame(), diagnose = 'cystitis', diabetes_status = "nee", katheter_status = "nee", 
                               lang_QT_status = "nee", obesitas_status = "nee", zwangerschap_status = "nee", 
                               medicatie_actief = data.frame(dict[["med_AB"]]), geslacht = "man", gfr=90){
  
  
  
  # vars
  list_AB_status <- setNames(as.list(rep("green", length(AB_list))), names(AB_list)) #make a dict of all AB's and assign status green as deafault for status
  list_AB_remarks <- setNames(as.list(rep("Geen opmerkingen", length(AB_list))), names(AB_list)) #make a dict of all AB's and assign "Geen" as default for remarks #Try empty list
  list_AB_dosering <- setNames(as.list(rep("Geen informatie", length(AB_list))), names(AB_list)) # make named list of all AB's and assign "Geen informatie", will be replaced with actual information in algorithm
  list_AB_duur <- setNames(as.list(rep("Geen informatie", length(AB_list))), names(AB_list)) # make named list of all AB's and assign "Geen informatie", will be replaced with actual information in algorithm
  
  ##### CULTURES #####
  for (i in names(AB_list)) {
    
    ab_data <- dataset_ab[dataset_ab$middel == i,] #get info for this AB from dataset_ab
    
    # Extract and split the diagnoses, dosering, and duur info for the current antibiotic
    ab_diagnoses <- str_split(ab_data$diagnoses, pattern = " \\| ")[[1]]
    ab_diagnose_dosering <- str_split(ab_data$`diagnose dosering`, pattern = " \\| ")[[1]]
    ab_diagnose_duur <- str_split(ab_data$`diagnose duur`, pattern = " \\| ")[[1]]
    
    # Find the index of the current diagnose in the ab_diagnoses list
    diagnose_index <- match(diagnose, ab_diagnoses)
    
    # Determine dosering and duur based on the diagnose_index
    if (!is.na(diagnose_index)) {
      dosering <- ifelse(ab_diagnose_dosering[diagnose_index] == "standaard", ab_data$dosering, ab_diagnose_dosering[diagnose_index])
      duur <- ifelse(ab_diagnose_duur[diagnose_index] == "standaard", ab_data$duur, ab_diagnose_duur[diagnose_index])
    } else {
      # Use general dosering and duur as fallback if diagnose is not found
      dosering <- ab_data$dosering
      duur <- ab_data$duur
    }
    
    list_AB_dosering[[i]] <- dosering
    list_AB_duur[[i]] <- duur
    
    if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "I")) {
      list_AB_status[[i]] <- "yellow"
        list_AB_remarks[[i]] <- "Kweek verminderd gevoelig"
    } else if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "R")) {
      list_AB_status[[i]] <- "red"
        list_AB_remarks[[i]] <- "Kweek resistent"
    }else if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "S")) {
      next
    } else {
      list_AB_status[[i]] <- "yellow"
        list_AB_remarks[[i]] <- "Geen kweekgegevens"
    }
  
    
    # counters, for check if dosering / duur are updated more than once
    dosering_update_count <- 0
    duur_update_count <- 0
    
    ##### DIABETES #####
    if (diabetes_status == "ja") {
      if (ab_data$'diabetes veiligheid' == "ja") {
        list_AB_status[[i]] <- "red"
          list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Niet veilig met diabetes")
      }

      if (ab_data$'diabetes effectiviteit' == "aanpassing") {
        dosering <- ifelse(ab_data$'diabetes dosering' != "standaard", ab_data$'diabetes dosering', dosering) # if dosering does not equal standaard, apply dosering in column, otherwise keep initial dosering
        duur <- ifelse(ab_data$'diabetes duur' != "standaard", ab_data$'diabetes duur', duur) # if dosering does not equal standaard, apply dosering in column, otherwise keep initial dosering
        dosering_update_count <- dosering_update_count + 1
        duur_update_count <- duur_update_count + 1
        list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], ab_data$'diabetes opmerkingen')
      }

    } else if (diabetes_status == "?") {
      if (ab_data$'diabetes veiligheid' == "ja") {
        list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Waarschuwing: Dit middel kan veiligheidsimplicaties hebben bij diabetes.")
      }
      if (ab_data$'diabetes effectiviteit' == "aanpassing") {
        list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Waarschuwing: Dit middel kan dosisaanpassingen vereisen bij diabetes.")
      }
    }

    list_AB_dosering[[i]] <- dosering
    list_AB_duur[[i]] <- duur
    
    # within for loop
    
  }
  # within function
  return(list(status = list_AB_status, remarks = list_AB_remarks, duur = list_AB_duur, dosering = list_AB_dosering))
}
    





From kry|ov@r00t @end|ng |rom gm@||@com  Mon Dec 18 11:17:39 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 18 Dec 2023 13:17:39 +0300
Subject: [R] Function with large nested list
In-Reply-To: <AM9P195MB096574A3342894802CF270B5BC8DA@AM9P195MB0965.EURP195.PROD.OUTLOOK.COM>
References: <AM9P195MB096574A3342894802CF270B5BC8DA@AM9P195MB0965.EURP195.PROD.OUTLOOK.COM>
Message-ID: <20231218131739.08e92d98@Tarkus>

? Mon, 18 Dec 2023 09:56:16 +0000
Emily Bakker <emilybakker at outlook.com> ?????:

> When i try to run the function definiton, the command never
> "completes" in de console.

How do you run the function definition? I copied and pasted your
example into a character variable and gave it to parse(text = ...). It
parsed successfully.

Splitting the function into multiple smaller functions is the usual
advice. It should help here too. When you decompose a large function
into a set of smaller functions, it becomes easier to reason about them
and test them individually. (It is also possible to have too many small
functions; it is important to find a balanced solution.)

If you find yourself making a decision based on a fixed set of strings,
consider switch() and match.arg(). If a set of possible values for a
factor is limited to true / false / don't know, it may help to switch
to R's native TRUE / FALSE / NA_logical_ values instead of strings
(which may contain typos).

-- 
Best regards,
Ivan


From z|v@n@k@r@m@n @end|ng |rom gm@||@com  Sat Dec 16 19:04:25 2023
From: z|v@n@k@r@m@n @end|ng |rom gm@||@com (Zivan Karaman)
Date: Sat, 16 Dec 2023 19:04:25 +0100
Subject: [R] [R-pkgs] Copernicus Data Space Ecosystem API Wrapper
Message-ID: <CAKtE6yMQVy4xQYjMWBaj7NkDk5Py8k2QNSt8zwDqH2=fnWYx1g@mail.gmail.com>

Dear all,

I am pleased to announce the release of a new package named 'CDSE' on CRAN.

It provides direct access to the 'Copernicus Data Space Ecosystem' for
R users. With this package, you can efficiently access the imagery
from Sentinel-1, Sentinel-2, Sentinel-3, and Sentinel-5 missions and
process and download data from the R environment.

One of the significant benefits of this package is that you can
download the satellite data that is limited to your area of interest
instead of the entire image tiles (100 x 100 km) that are usually
distributed by Copernicus.

Although the software is compatible with any satellite images
available in CDSE, it has been primarily tested with Sentinel-2
images.

This is the first version of the package, and your feedback and
suggestions are welcome

Please find more details and download the package from the following
link: https://cran.r-project.org/package=CDSE

Best regards,
Zivan

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Dec 18 17:30:38 2023
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 18 Dec 2023 16:30:38 +0000
Subject: [R] Function with large nested list
In-Reply-To: <AM9P195MB096574A3342894802CF270B5BC8DA@AM9P195MB0965.EURP195.PROD.OUTLOOK.COM>
References: <AM9P195MB096574A3342894802CF270B5BC8DA@AM9P195MB0965.EURP195.PROD.OUTLOOK.COM>
Message-ID: <d9418bee-72a7-f537-9245-152028ef20e7@dewey.myzen.co.uk>

Dear Emily

Comment in-line

On 18/12/2023 09:56, Emily Bakker wrote:
> Hello list,
> 
> I want to make a large rulebased algorithm, to provide decision support for drug prescriptions. I have defined the algorithm in a function, with a for loop and many if statements. The structure should be as follows:
> 1. Iterate over a list of drug names. For each drug:
> 2. Get some drug related data (external dataset). Row of a dataframe.
> 3.  Check if adaptions should be made to standard dosage and safety information in case of contraindications. If patient has an indication, update current dosage and safety information with the value from the dataframe row.
> 4. Save dosage and safety information in some lists and continue to the next drug.
> 5. When the iteration over all drugs is done, return the lists.
> 
> ISSUE:
> So it is a very large function with many nested if statements. I have checked the code structure multiple times, but i run into some issues. When i try to run the function definiton, the command never "completes" in de console. Instead of ">", the console shows "+". No errors are raised.

When my console returns a + is usually means I have left off the final 
parenthesis or given it an incomplete line.

Michael
> 
> As I said, i have checked the structure multiple times, but cant find an error. I have tried rebuilding it and testing each time i add a part. Each part functions isolated, but not together in the same function. I can't find any infinite loops either.
> I suspect the function may be too large, and i have to define functions for each part separately. That isn't an issue necessarily, but i would still like to know why my code won't run. And whether there are any downsides or considerations for using many small functions.
> 
> Below is my code. I have left part of it out. There are six more parts like the diabetes part that are similar.
> I also use a lot of data/variabeles not included here, to try and keep things compact. But I can provide additional information if helpful.
> Thanks it advance for thinking along!!
> Kind regards,
> Emily
> 
> The code:
> 
> decision_algorithm <- function(AB_list, dataset_ab = data.frame(), diagnose = 'cystitis', diabetes_status = "nee", katheter_status = "nee",
>                                 lang_QT_status = "nee", obesitas_status = "nee", zwangerschap_status = "nee",
>                                 medicatie_actief = data.frame(dict[["med_AB"]]), geslacht = "man", gfr=90){
>    
>    
>    
>    # vars
>    list_AB_status <- setNames(as.list(rep("green", length(AB_list))), names(AB_list)) #make a dict of all AB's and assign status green as deafault for status
>    list_AB_remarks <- setNames(as.list(rep("Geen opmerkingen", length(AB_list))), names(AB_list)) #make a dict of all AB's and assign "Geen" as default for remarks #Try empty list
>    list_AB_dosering <- setNames(as.list(rep("Geen informatie", length(AB_list))), names(AB_list)) # make named list of all AB's and assign "Geen informatie", will be replaced with actual information in algorithm
>    list_AB_duur <- setNames(as.list(rep("Geen informatie", length(AB_list))), names(AB_list)) # make named list of all AB's and assign "Geen informatie", will be replaced with actual information in algorithm
>    
>    ##### CULTURES #####
>    for (i in names(AB_list)) {
>      
>      ab_data <- dataset_ab[dataset_ab$middel == i,] #get info for this AB from dataset_ab
>      
>      # Extract and split the diagnoses, dosering, and duur info for the current antibiotic
>      ab_diagnoses <- str_split(ab_data$diagnoses, pattern = " \\| ")[[1]]
>      ab_diagnose_dosering <- str_split(ab_data$`diagnose dosering`, pattern = " \\| ")[[1]]
>      ab_diagnose_duur <- str_split(ab_data$`diagnose duur`, pattern = " \\| ")[[1]]
>      
>      # Find the index of the current diagnose in the ab_diagnoses list
>      diagnose_index <- match(diagnose, ab_diagnoses)
>      
>      # Determine dosering and duur based on the diagnose_index
>      if (!is.na(diagnose_index)) {
>        dosering <- ifelse(ab_diagnose_dosering[diagnose_index] == "standaard", ab_data$dosering, ab_diagnose_dosering[diagnose_index])
>        duur <- ifelse(ab_diagnose_duur[diagnose_index] == "standaard", ab_data$duur, ab_diagnose_duur[diagnose_index])
>      } else {
>        # Use general dosering and duur as fallback if diagnose is not found
>        dosering <- ab_data$dosering
>        duur <- ab_data$duur
>      }
>      
>      list_AB_dosering[[i]] <- dosering
>      list_AB_duur[[i]] <- duur
>      
>      if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "I")) {
>        list_AB_status[[i]] <- "yellow"
>          list_AB_remarks[[i]] <- "Kweek verminderd gevoelig"
>      } else if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "R")) {
>        list_AB_status[[i]] <- "red"
>          list_AB_remarks[[i]] <- "Kweek resistent"
>      }else if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "S")) {
>        next
>      } else {
>        list_AB_status[[i]] <- "yellow"
>          list_AB_remarks[[i]] <- "Geen kweekgegevens"
>      }
>    
>      
>      # counters, for check if dosering / duur are updated more than once
>      dosering_update_count <- 0
>      duur_update_count <- 0
>      
>      ##### DIABETES #####
>      if (diabetes_status == "ja") {
>        if (ab_data$'diabetes veiligheid' == "ja") {
>          list_AB_status[[i]] <- "red"
>            list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Niet veilig met diabetes")
>        }
> 
>        if (ab_data$'diabetes effectiviteit' == "aanpassing") {
>          dosering <- ifelse(ab_data$'diabetes dosering' != "standaard", ab_data$'diabetes dosering', dosering) # if dosering does not equal standaard, apply dosering in column, otherwise keep initial dosering
>          duur <- ifelse(ab_data$'diabetes duur' != "standaard", ab_data$'diabetes duur', duur) # if dosering does not equal standaard, apply dosering in column, otherwise keep initial dosering
>          dosering_update_count <- dosering_update_count + 1
>          duur_update_count <- duur_update_count + 1
>          list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], ab_data$'diabetes opmerkingen')
>        }
> 
>      } else if (diabetes_status == "?") {
>        if (ab_data$'diabetes veiligheid' == "ja") {
>          list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Waarschuwing: Dit middel kan veiligheidsimplicaties hebben bij diabetes.")
>        }
>        if (ab_data$'diabetes effectiviteit' == "aanpassing") {
>          list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Waarschuwing: Dit middel kan dosisaanpassingen vereisen bij diabetes.")
>        }
>      }
> 
>      list_AB_dosering[[i]] <- dosering
>      list_AB_duur[[i]] <- duur
>      
>      # within for loop
>      
>    }
>    # within function
>    return(list(status = list_AB_status, remarks = list_AB_remarks, duur = list_AB_duur, dosering = list_AB_dosering))
> }
>      
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael


From @vi@e@gross m@iii@g oii gm@ii@com  Mon Dec 18 22:57:02 2023
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Mon, 18 Dec 2023 16:57:02 -0500
Subject: [R] Function with large nested list
In-Reply-To: <AM9P195MB096574A3342894802CF270B5BC8DA@AM9P195MB0965.EURP195.PROD.OUTLOOK.COM>
References: <AM9P195MB096574A3342894802CF270B5BC8DA@AM9P195MB0965.EURP195.PROD.OUTLOOK.COM>
Message-ID: <00d301da31fd$2225a3f0$6670ebd0$@gmail.com>

Emily,

I too copied/pasted your code in and it worked fine. I then asked for the
function definition and got it.

Did you put the entire text in? I mean nothing extra above or below except
maybe whitespace or comments?

What sometimes happens to make the code incomplete is to leave out a
matching parentheses of brace or bracket or sometimes quotes or using the
wrong kind of quote as in copying from a program like Microsoft Word.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Emily Bakker
Sent: Monday, December 18, 2023 4:56 AM
To: r-help at r-project.org
Subject: [R] Function with large nested list

Hello list,

I want to make a large rulebased algorithm, to provide decision support for
drug prescriptions. I have defined the algorithm in a function, with a for
loop and many if statements. The structure should be as follows:
1. Iterate over a list of drug names. For each drug:
2. Get some drug related data (external dataset). Row of a dataframe.
3.  Check if adaptions should be made to standard dosage and safety
information in case of contraindications. If patient has an indication,
update current dosage and safety information with the value from the
dataframe row. 
4. Save dosage and safety information in some lists and continue to the next
drug. 
5. When the iteration over all drugs is done, return the lists.

ISSUE:
So it is a very large function with many nested if statements. I have
checked the code structure multiple times, but i run into some issues. When
i try to run the function definiton, the command never "completes" in de
console. Instead of ">", the console shows "+". No errors are raised.

As I said, i have checked the structure multiple times, but cant find an
error. I have tried rebuilding it and testing each time i add a part. Each
part functions isolated, but not together in the same function. I can't find
any infinite loops either. 
I suspect the function may be too large, and i have to define functions for
each part separately. That isn't an issue necessarily, but i would still
like to know why my code won't run. And whether there are any downsides or
considerations for using many small functions.

Below is my code. I have left part of it out. There are six more parts like
the diabetes part that are similar.
I also use a lot of data/variabeles not included here, to try and keep
things compact. But I can provide additional information if helpful.
Thanks it advance for thinking along!!
Kind regards,
Emily

The code:

decision_algorithm <- function(AB_list, dataset_ab = data.frame(), diagnose
= 'cystitis', diabetes_status = "nee", katheter_status = "nee", 
                               lang_QT_status = "nee", obesitas_status =
"nee", zwangerschap_status = "nee", 
                               medicatie_actief =
data.frame(dict[["med_AB"]]), geslacht = "man", gfr=90){
  
  
  
  # vars
  list_AB_status <- setNames(as.list(rep("green", length(AB_list))),
names(AB_list)) #make a dict of all AB's and assign status green as deafault
for status
  list_AB_remarks <- setNames(as.list(rep("Geen opmerkingen",
length(AB_list))), names(AB_list)) #make a dict of all AB's and assign
"Geen" as default for remarks #Try empty list
  list_AB_dosering <- setNames(as.list(rep("Geen informatie",
length(AB_list))), names(AB_list)) # make named list of all AB's and assign
"Geen informatie", will be replaced with actual information in algorithm
  list_AB_duur <- setNames(as.list(rep("Geen informatie", length(AB_list))),
names(AB_list)) # make named list of all AB's and assign "Geen informatie",
will be replaced with actual information in algorithm
  
  ##### CULTURES #####
  for (i in names(AB_list)) {
    
    ab_data <- dataset_ab[dataset_ab$middel == i,] #get info for this AB
from dataset_ab
    
    # Extract and split the diagnoses, dosering, and duur info for the
current antibiotic
    ab_diagnoses <- str_split(ab_data$diagnoses, pattern = " \\| ")[[1]]
    ab_diagnose_dosering <- str_split(ab_data$`diagnose dosering`, pattern =
" \\| ")[[1]]
    ab_diagnose_duur <- str_split(ab_data$`diagnose duur`, pattern = " \\|
")[[1]]
    
    # Find the index of the current diagnose in the ab_diagnoses list
    diagnose_index <- match(diagnose, ab_diagnoses)
    
    # Determine dosering and duur based on the diagnose_index
    if (!is.na(diagnose_index)) {
      dosering <- ifelse(ab_diagnose_dosering[diagnose_index] ==
"standaard", ab_data$dosering, ab_diagnose_dosering[diagnose_index])
      duur <- ifelse(ab_diagnose_duur[diagnose_index] == "standaard",
ab_data$duur, ab_diagnose_duur[diagnose_index])
    } else {
      # Use general dosering and duur as fallback if diagnose is not found
      dosering <- ab_data$dosering
      duur <- ab_data$duur
    }
    
    list_AB_dosering[[i]] <- dosering
    list_AB_duur[[i]] <- duur
    
    if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "I")) {
      list_AB_status[[i]] <- "yellow"
        list_AB_remarks[[i]] <- "Kweek verminderd gevoelig"
    } else if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "R")) {
      list_AB_status[[i]] <- "red"
        list_AB_remarks[[i]] <- "Kweek resistent"
    }else if ((!is.null(AB_list[[i]]) && AB_list[[i]] == "S")) {
      next
    } else {
      list_AB_status[[i]] <- "yellow"
        list_AB_remarks[[i]] <- "Geen kweekgegevens"
    }
  
    
    # counters, for check if dosering / duur are updated more than once
    dosering_update_count <- 0
    duur_update_count <- 0
    
    ##### DIABETES #####
    if (diabetes_status == "ja") {
      if (ab_data$'diabetes veiligheid' == "ja") {
        list_AB_status[[i]] <- "red"
          list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Niet veilig
met diabetes")
      }

      if (ab_data$'diabetes effectiviteit' == "aanpassing") {
        dosering <- ifelse(ab_data$'diabetes dosering' != "standaard",
ab_data$'diabetes dosering', dosering) # if dosering does not equal
standaard, apply dosering in column, otherwise keep initial dosering
        duur <- ifelse(ab_data$'diabetes duur' != "standaard",
ab_data$'diabetes duur', duur) # if dosering does not equal standaard, apply
dosering in column, otherwise keep initial dosering
        dosering_update_count <- dosering_update_count + 1
        duur_update_count <- duur_update_count + 1
        list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]],
ab_data$'diabetes opmerkingen')
      }

    } else if (diabetes_status == "?") {
      if (ab_data$'diabetes veiligheid' == "ja") {
        list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Waarschuwing:
Dit middel kan veiligheidsimplicaties hebben bij diabetes.")
      }
      if (ab_data$'diabetes effectiviteit' == "aanpassing") {
        list_AB_remarks[[i]] <- paste(list_AB_remarks[[i]], "Waarschuwing:
Dit middel kan dosisaanpassingen vereisen bij diabetes.")
      }
    }

    list_AB_dosering[[i]] <- dosering
    list_AB_duur[[i]] <- duur
    
    # within for loop
    
  }
  # within function
  return(list(status = list_AB_status, remarks = list_AB_remarks, duur =
list_AB_duur, dosering = list_AB_dosering))
}
    




______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ph@edru@v @end|ng |rom gm@||@com  Fri Dec 29 19:14:02 2023
From: ph@edru@v @end|ng |rom gm@||@com (Andy)
Date: Fri, 29 Dec 2023 18:14:02 +0000
Subject: [R] Help request: Parsing docx files for key words and appending to
 a spreadsheet
Message-ID: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>

Hello

I am trying to work through a problem, but feel like I've gone down a 
rabbit hole. I'd very much appreciate any help.

The task: I have several directories of multiple (some directories, up 
to 2,500+) *.docx files (newspaper articles downloaded from Lexis+) that 
I want to iterate through to append to a spreadsheet only those articles 
that satisfy a condition (i.e., a specific keyword is present for >= 50% 
coverage of the subject matter). Lexis+ has a very specific structure 
and keywords are given in the row "Subject".

I'd like to be able to accomplish the following:

(1) Append the title, the month, the author, the number of words, and 
page number(s) to a spreadsheet

(2) Read each article and extract keywords (in the docs, these are 
listed in 'Subject' section as a list of keywords with a percentage 
showing the extent to which the keyword features in the article (e.g., 
FAST FASHION (72%)) and to append the keyword and the % coverage to the 
same row in the spreadsheet. However, I want to ensure that the keyword 
coverage meets the threshold of >= 50%; if not, then pass onto the next 
article in the directory. Rinse and repeat for the entire directory.

So far, I've tried working through some Stack Overflow-based solutions, 
but most seem to use the textreadr package, which is now deprecated; 
others use either the officer or the officedown packages. However, these 
packages don't appear to do what I want the program to do, at least not 
in any of the examples I have found, nor in the vignettes and relevant 
package manuals I've looked at.

The first point is, is what I am intending to do even possible using R? 
If it is, then where do I start with this? If these docx files were 
converted to UTF-8 plain text, would that make the task easier?

I am not a confident coder, and am really only just getting my head 
around R so appreciate a steep learning curve ahead, but of course, I 
don't know what I don't know, so any pointers in the right direction 
would be a big help.

Many thanks in anticipation

Andy


From roy@mende|@@ohn @end|ng |rom no@@@gov  Fri Dec 29 19:25:16 2023
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 29 Dec 2023 10:25:16 -0800
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
Message-ID: <2921616F-A02E-4C00-89B3-3E0A6FE077B3@noaa.gov>

Hi Andy:

I don?t have an answer but I do have what I hope is some friendly advice.  Generally the more information you can provide,  the more likely you will get help that is useful.  In your case you say that you tried several packages and they didn?t do what you wanted.  Providing that code,  as well as why they didn?t do what you wanted (be specific)  would greatly facilitate things.

Happy new year,

-Roy


> On Dec 29, 2023, at 10:14 AM, Andy <phaedrusv at gmail.com> wrote:
> 
> Hello
> 
> I am trying to work through a problem, but feel like I've gone down a rabbit hole. I'd very much appreciate any help.
> 
> The task: I have several directories of multiple (some directories, up to 2,500+) *.docx files (newspaper articles downloaded from Lexis+) that I want to iterate through to append to a spreadsheet only those articles that satisfy a condition (i.e., a specific keyword is present for >= 50% coverage of the subject matter). Lexis+ has a very specific structure and keywords are given in the row "Subject".
> 
> I'd like to be able to accomplish the following:
> 
> (1) Append the title, the month, the author, the number of words, and page number(s) to a spreadsheet
> 
> (2) Read each article and extract keywords (in the docs, these are listed in 'Subject' section as a list of keywords with a percentage showing the extent to which the keyword features in the article (e.g., FAST FASHION (72%)) and to append the keyword and the % coverage to the same row in the spreadsheet. However, I want to ensure that the keyword coverage meets the threshold of >= 50%; if not, then pass onto the next article in the directory. Rinse and repeat for the entire directory.
> 
> So far, I've tried working through some Stack Overflow-based solutions, but most seem to use the textreadr package, which is now deprecated; others use either the officer or the officedown packages. However, these packages don't appear to do what I want the program to do, at least not in any of the examples I have found, nor in the vignettes and relevant package manuals I've looked at.
> 
> The first point is, is what I am intending to do even possible using R? If it is, then where do I start with this? If these docx files were converted to UTF-8 plain text, would that make the task easier?
> 
> I am not a confident coder, and am really only just getting my head around R so appreciate a steep learning curve ahead, but of course, I don't know what I don't know, so any pointers in the right direction would be a big help.
> 
> Many thanks in anticipation
> 
> Andy
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jho|tm@n @end|ng |rom gm@||@com  Fri Dec 29 19:33:22 2023
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Fri, 29 Dec 2023 10:33:22 -0800
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
Message-ID: <CAAxdm-5VwQZ+Cpb+mXZXGTkh5eoTFpgxKwf6D+ZMXosxgTjcBQ@mail.gmail.com>

checkout the 'officer' package

Thanks

Jim Holtman
*Data Munger Guru*


*What is the problem that you are trying to solve?Tell me what you want to
do, not how you want to do it.*


On Fri, Dec 29, 2023 at 10:14?AM Andy <phaedrusv at gmail.com> wrote:

> Hello
>
> I am trying to work through a problem, but feel like I've gone down a
> rabbit hole. I'd very much appreciate any help.
>
> The task: I have several directories of multiple (some directories, up
> to 2,500+) *.docx files (newspaper articles downloaded from Lexis+) that
> I want to iterate through to append to a spreadsheet only those articles
> that satisfy a condition (i.e., a specific keyword is present for >= 50%
> coverage of the subject matter). Lexis+ has a very specific structure
> and keywords are given in the row "Subject".
>
> I'd like to be able to accomplish the following:
>
> (1) Append the title, the month, the author, the number of words, and
> page number(s) to a spreadsheet
>
> (2) Read each article and extract keywords (in the docs, these are
> listed in 'Subject' section as a list of keywords with a percentage
> showing the extent to which the keyword features in the article (e.g.,
> FAST FASHION (72%)) and to append the keyword and the % coverage to the
> same row in the spreadsheet. However, I want to ensure that the keyword
> coverage meets the threshold of >= 50%; if not, then pass onto the next
> article in the directory. Rinse and repeat for the entire directory.
>
> So far, I've tried working through some Stack Overflow-based solutions,
> but most seem to use the textreadr package, which is now deprecated;
> others use either the officer or the officedown packages. However, these
> packages don't appear to do what I want the program to do, at least not
> in any of the examples I have found, nor in the vignettes and relevant
> package manuals I've looked at.
>
> The first point is, is what I am intending to do even possible using R?
> If it is, then where do I start with this? If these docx files were
> converted to UTF-8 plain text, would that make the task easier?
>
> I am not a confident coder, and am really only just getting my head
> around R so appreciate a steep learning curve ahead, but of course, I
> don't know what I don't know, so any pointers in the right direction
> would be a big help.
>
> Many thanks in anticipation
>
> Andy
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From po|c1410 @end|ng |rom gm@||@com  Fri Dec 29 19:50:14 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Fri, 29 Dec 2023 18:50:14 +0000
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <2921616F-A02E-4C00-89B3-3E0A6FE077B3@noaa.gov>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <2921616F-A02E-4C00-89B3-3E0A6FE077B3@noaa.gov>
Message-ID: <CA+etgP=eR9txPjPU-bz9jkuu5Ea_XLD=9+SMjHpT+WfpztLDHw@mail.gmail.com>

textreadr would be the obvious approach.

When you say it is depreciated do you mean it's not available on cran?
Sometimes maintaining a package on cran in just a pain in the ass.

devtools::install_github("trinker/textreadr")


Should let you install it.

In theory docx files are actually just zip files (you can unzip them) and
you may find there is then a specific file in the zip that is readable with
on of R's General text file readers.

Alternatively, read_docx from:
https://www.rdocumentation.org/packages/qdapTools

May be worth a look.

What platform are you on. Certainly options to command line convert files
to txt and do from there.


On Fri, 29 Dec 2023, 18:25 Roy Mendelssohn - NOAA Federal via R-help, <
r-help at r-project.org> wrote:

> Hi Andy:
>
> I don?t have an answer but I do have what I hope is some friendly advice.
> Generally the more information you can provide,  the more likely you will
> get help that is useful.  In your case you say that you tried several
> packages and they didn?t do what you wanted.  Providing that code,  as well
> as why they didn?t do what you wanted (be specific)  would greatly
> facilitate things.
>
> Happy new year,
>
> -Roy
>
>
> > On Dec 29, 2023, at 10:14 AM, Andy <phaedrusv at gmail.com> wrote:
> >
> > Hello
> >
> > I am trying to work through a problem, but feel like I've gone down a
> rabbit hole. I'd very much appreciate any help.
> >
> > The task: I have several directories of multiple (some directories, up
> to 2,500+) *.docx files (newspaper articles downloaded from Lexis+) that I
> want to iterate through to append to a spreadsheet only those articles that
> satisfy a condition (i.e., a specific keyword is present for >= 50%
> coverage of the subject matter). Lexis+ has a very specific structure and
> keywords are given in the row "Subject".
> >
> > I'd like to be able to accomplish the following:
> >
> > (1) Append the title, the month, the author, the number of words, and
> page number(s) to a spreadsheet
> >
> > (2) Read each article and extract keywords (in the docs, these are
> listed in 'Subject' section as a list of keywords with a percentage showing
> the extent to which the keyword features in the article (e.g., FAST FASHION
> (72%)) and to append the keyword and the % coverage to the same row in the
> spreadsheet. However, I want to ensure that the keyword coverage meets the
> threshold of >= 50%; if not, then pass onto the next article in the
> directory. Rinse and repeat for the entire directory.
> >
> > So far, I've tried working through some Stack Overflow-based solutions,
> but most seem to use the textreadr package, which is now deprecated; others
> use either the officer or the officedown packages. However, these packages
> don't appear to do what I want the program to do, at least not in any of
> the examples I have found, nor in the vignettes and relevant package
> manuals I've looked at.
> >
> > The first point is, is what I am intending to do even possible using R?
> If it is, then where do I start with this? If these docx files were
> converted to UTF-8 plain text, would that make the task easier?
> >
> > I am not a confident coder, and am really only just getting my head
> around R so appreciate a steep learning curve ahead, but of course, I don't
> know what I don't know, so any pointers in the right direction would be a
> big help.
> >
> > Many thanks in anticipation
> >
> > Andy
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From po|c1410 @end|ng |rom gm@||@com  Fri Dec 29 20:01:09 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Fri, 29 Dec 2023 19:01:09 +0000
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <CAAxdm-5VwQZ+Cpb+mXZXGTkh5eoTFpgxKwf6D+ZMXosxgTjcBQ@mail.gmail.com>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <CAAxdm-5VwQZ+Cpb+mXZXGTkh5eoTFpgxKwf6D+ZMXosxgTjcBQ@mail.gmail.com>
Message-ID: <CA+etgPnMiZ_ZcG41Z31ERSv1NJOrRa8bvR2=CjN+H5aCYpBmwQ@mail.gmail.com>

It sounded like he looked at officeR but I would agree

content <- officer::docx_summary("filename.docx")

Would get the text content into an object called content.

That object is a data.frame so you can then manipulate it.  To be more
specific, we might need an example of the DF

You can loop this easily with a for statement although there are people who
prefer a non-for approach to iteration in R. For can be slow. But if you
don't need to do this very quickly I'd stick with for if you are used to
programming

On Fri, 29 Dec 2023, 18:35 jim holtman, <jholtman at gmail.com> wrote:

> checkout the 'officer' package
>
> Thanks
>
> Jim Holtman
> *Data Munger Guru*
>
>
> *What is the problem that you are trying to solve?Tell me what you want to
> do, not how you want to do it.*
>
>
> On Fri, Dec 29, 2023 at 10:14?AM Andy <phaedrusv at gmail.com> wrote:
>
> > Hello
> >
> > I am trying to work through a problem, but feel like I've gone down a
> > rabbit hole. I'd very much appreciate any help.
> >
> > The task: I have several directories of multiple (some directories, up
> > to 2,500+) *.docx files (newspaper articles downloaded from Lexis+) that
> > I want to iterate through to append to a spreadsheet only those articles
> > that satisfy a condition (i.e., a specific keyword is present for >= 50%
> > coverage of the subject matter). Lexis+ has a very specific structure
> > and keywords are given in the row "Subject".
> >
> > I'd like to be able to accomplish the following:
> >
> > (1) Append the title, the month, the author, the number of words, and
> > page number(s) to a spreadsheet
> >
> > (2) Read each article and extract keywords (in the docs, these are
> > listed in 'Subject' section as a list of keywords with a percentage
> > showing the extent to which the keyword features in the article (e.g.,
> > FAST FASHION (72%)) and to append the keyword and the % coverage to the
> > same row in the spreadsheet. However, I want to ensure that the keyword
> > coverage meets the threshold of >= 50%; if not, then pass onto the next
> > article in the directory. Rinse and repeat for the entire directory.
> >
> > So far, I've tried working through some Stack Overflow-based solutions,
> > but most seem to use the textreadr package, which is now deprecated;
> > others use either the officer or the officedown packages. However, these
> > packages don't appear to do what I want the program to do, at least not
> > in any of the examples I have found, nor in the vignettes and relevant
> > package manuals I've looked at.
> >
> > The first point is, is what I am intending to do even possible using R?
> > If it is, then where do I start with this? If these docx files were
> > converted to UTF-8 plain text, would that make the task easier?
> >
> > I am not a confident coder, and am really only just getting my head
> > around R so appreciate a steep learning curve ahead, but of course, I
> > don't know what I don't know, so any pointers in the right direction
> > would be a big help.
> >
> > Many thanks in anticipation
> >
> > Andy
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ph@edru@v @end|ng |rom gm@||@com  Fri Dec 29 21:17:41 2023
From: ph@edru@v @end|ng |rom gm@||@com (Andy)
Date: Fri, 29 Dec 2023 20:17:41 +0000
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <2921616F-A02E-4C00-89B3-3E0A6FE077B3@noaa.gov>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <2921616F-A02E-4C00-89B3-3E0A6FE077B3@noaa.gov>
Message-ID: <956d7fcc-e643-0bc4-b438-e13a903bbbbf@gmail.com>

Hi Roy (& others)

Many thanks for the advice - well taken. Thanks also to the others who 
have responded so quickly - I thought I might have to wait days!! :-)

I'm on a Linux (Mint) machine. Below, I document three attempts, two 
using officer and the last now using textreadr

My attempts so far using 'officer':

##################

(1) First Attempt:

# Load libraries
library(tcltk)
library(tidyverse)
library(officer)

setwd(tk_choose.dir())

doc_path <- list.files(getwd(), pattern = ".docx", full.names = TRUE)

files <- list.files(getwd(), ".docx")
files
length(files)

## This works to here - obtain a list of docx files in directory 'TEST 
with 9 files'. However, the next line
doc_in <- read_docx(files)

Results in this error:Error in filetype %in% c("docx") && 
grepl("^([fh]ttp)", file) :'length = 9' in coercion to 'logical(1)'

No idea how to debug that.

Even when trying Calum's suggestion with officer:

content <- officer::docx_summary("Now they want us to charge our 
electric cars from litter bins.docx") # A title of one of the articles

The error returned is:Error in x$doc_obj : $ operator is invalid for 
atomic vectors


##################
(2) Second Attempt:

# Load libraries
library(tcltk)
library(tidyverse)
library(officer)

setwd(tk_choose.dir())

doc_path <- list.files(getwd(), pattern = ".docx", full.names = TRUE)

files <- list.files(getwd(), ".docx")
files
length(files)

docx_summary(doc_path, preserve = FALSE)
## At this point, the error is:Error in x$doc_obj : $ operator is 
invalid for atomic vectors

So, not sure how I am passing an atomic vector or if there is something 
I am supposed to set to make this something else?

##################
(3) Third attempt - now trying with textreadr (Thanks for the help on 
installing this, Calum):

# Load libraries
library(tcltk)
library(tidyverse)
library(textreadr)

folder <- setwd(tk_choose.dir())

files <- list.files(folder, ".docx")
files
length(files)

doc <- read_docx("Now they want us to charge our electric cars from 
litter bins.docx") # One of the 9 files in the folder

read_docx(doc, skip = 0, remove.empty = TRUE, trim = TRUE) # To test 
against one file

## The last line returns the following error:Error in filetype %in% 
c("docx") && grepl("^([fh]ttp)", file) :'length = 38' in coercion to 
'logical(1)'

##################
And so I am going around in circles and not at all clear on how I can 
make progress.

I am sure that there must be a way, but the suggestions on-line each 
lead to the above errors.

Thanks for any further help.

Best wishes, and thanks
Andy


On 29/12/2023 18:25, Roy Mendelssohn - NOAA Federal wrote:
> Hi Andy:
>
> I don?t have an answer but I do have what I hope is some friendly advice.  Generally the more information you can provide,  the more likely you will get help that is useful.  In your case you say that you tried several packages and they didn?t do what you wanted.  Providing that code,  as well as why they didn?t do what you wanted (be specific)  would greatly facilitate things.
>
> Happy new year,
>
> -Roy
>
>
>> On Dec 29, 2023, at 10:14 AM, Andy<phaedrusv at gmail.com>  wrote:
>>
>> Hello
>>
>> I am trying to work through a problem, but feel like I've gone down a rabbit hole. I'd very much appreciate any help.
>>
>> The task: I have several directories of multiple (some directories, up to 2,500+) *.docx files (newspaper articles downloaded from Lexis+) that I want to iterate through to append to a spreadsheet only those articles that satisfy a condition (i.e., a specific keyword is present for >= 50% coverage of the subject matter). Lexis+ has a very specific structure and keywords are given in the row "Subject".
>>
>> I'd like to be able to accomplish the following:
>>
>> (1) Append the title, the month, the author, the number of words, and page number(s) to a spreadsheet
>>
>> (2) Read each article and extract keywords (in the docs, these are listed in 'Subject' section as a list of keywords with a percentage showing the extent to which the keyword features in the article (e.g., FAST FASHION (72%)) and to append the keyword and the % coverage to the same row in the spreadsheet. However, I want to ensure that the keyword coverage meets the threshold of >= 50%; if not, then pass onto the next article in the directory. Rinse and repeat for the entire directory.
>>
>> So far, I've tried working through some Stack Overflow-based solutions, but most seem to use the textreadr package, which is now deprecated; others use either the officer or the officedown packages. However, these packages don't appear to do what I want the program to do, at least not in any of the examples I have found, nor in the vignettes and relevant package manuals I've looked at.
>>
>> The first point is, is what I am intending to do even possible using R? If it is, then where do I start with this? If these docx files were converted to UTF-8 plain text, would that make the task easier?
>>
>> I am not a confident coder, and am really only just getting my head around R so appreciate a steep learning curve ahead, but of course, I don't know what I don't know, so any pointers in the right direction would be a big help.
>>
>> Many thanks in anticipation
>>
>> Andy
>>
>> ______________________________________________
>> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Fri Dec 29 21:25:06 2023
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Fri, 29 Dec 2023 22:25:06 +0200
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <CA+etgPnMiZ_ZcG41Z31ERSv1NJOrRa8bvR2=CjN+H5aCYpBmwQ@mail.gmail.com>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <CAAxdm-5VwQZ+Cpb+mXZXGTkh5eoTFpgxKwf6D+ZMXosxgTjcBQ@mail.gmail.com>
 <CA+etgPnMiZ_ZcG41Z31ERSv1NJOrRa8bvR2=CjN+H5aCYpBmwQ@mail.gmail.com>
Message-ID: <umn9v5$la8$1@ciao.gmane.io>

I would also look at https://pandoc.org perhaps which can
export a number of formats...

And for spreadsheets https://github.com/jqnatividad/qsv is my
goto weapon.  Can also read and write XLSX and others.

A sample document or two would always be helpful...

el

On 29/12/2023 21:01, CALUM POLWART wrote:
> It sounded like he looked at officeR but I would agree
> 
> content <- officer::docx_summary("filename.docx")
> 
> Would get the text content into an object called content.
> 
> That object is a data.frame so you can then manipulate it.
> To be more specific, we might need an example of the DF
[...]
>> On Fri, Dec 29, 2023 at 10:14 AM Andy <phaedrusv at gmail.com>
>> wrote:
[...]
>>> I'd like to be able to accomplish the following:
>>>
>>> (1) Append the title, the month, the author, the number of
>>> words, and page number(s) to a spreadsheet
>>>
>>> (2) Read each article and extract keywords (in the docs,
>>> these are listed in 'Subject' section as a list of
>>> keywords with a percentage showing the extent to which the
>>> keyword features in the article (e.g., FAST FASHION (72%))
>>> and to append the keyword and the % coverage to the same
>>> row in the spreadsheet.  However, I want to ensure that
>>> the keyword coverage meets the threshold of >= 50%; if
>>> not, then pass onto the next article in the directory.
>>> Rinse and repeat for the entire directory.
[...]


From ph@edru@v @end|ng |rom gm@||@com  Fri Dec 29 21:37:38 2023
From: ph@edru@v @end|ng |rom gm@||@com (Andy)
Date: Fri, 29 Dec 2023 20:37:38 +0000
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <umn9v5$la8$1@ciao.gmane.io>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <CAAxdm-5VwQZ+Cpb+mXZXGTkh5eoTFpgxKwf6D+ZMXosxgTjcBQ@mail.gmail.com>
 <CA+etgPnMiZ_ZcG41Z31ERSv1NJOrRa8bvR2=CjN+H5aCYpBmwQ@mail.gmail.com>
 <umn9v5$la8$1@ciao.gmane.io>
Message-ID: <26efc752-9e23-c00c-3881-e04b94852945@gmail.com>

Thanks - I'll have a look at these options too.

I'm happy to send over a sample document, but wasn't aware if 
attachments are allowed. The documents come Lexis+, so require user 
credentials to log in, but I could upload the file somewhere if that 
would help? Any ideas for a good location to do so?


On 29/12/2023 20:25, Dr Eberhard W Lisse wrote:
> I would also look at https://pandoc.org perhaps which can
> export a number of formats...
>
> And for spreadsheets https://github.com/jqnatividad/qsv is my
> goto weapon.  Can also read and write XLSX and others.
>
> A sample document or two would always be helpful...
>
> el
>
> On 29/12/2023 21:01, CALUM POLWART wrote:
>> It sounded like he looked at officeR but I would agree
>>
>> content <- officer::docx_summary("filename.docx")
>>
>> Would get the text content into an object called content.
>>
>> That object is a data.frame so you can then manipulate it.
>> To be more specific, we might need an example of the DF
> [...]
>>> On Fri, Dec 29, 2023 at 10:14 AM Andy <phaedrusv at gmail.com>
>>> wrote:
> [...]
>>>> I'd like to be able to accomplish the following:
>>>>
>>>> (1) Append the title, the month, the author, the number of
>>>> words, and page number(s) to a spreadsheet
>>>>
>>>> (2) Read each article and extract keywords (in the docs,
>>>> these are listed in 'Subject' section as a list of
>>>> keywords with a percentage showing the extent to which the
>>>> keyword features in the article (e.g., FAST FASHION (72%))
>>>> and to append the keyword and the % coverage to the same
>>>> row in the spreadsheet.  However, I want to ensure that
>>>> the keyword coverage meets the threshold of >= 50%; if
>>>> not, then pass onto the next article in the directory.
>>>> Rinse and repeat for the entire directory.
> [...]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Dec 29 21:59:00 2023
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 29 Dec 2023 23:59:00 +0300
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <956d7fcc-e643-0bc4-b438-e13a903bbbbf@gmail.com>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <2921616F-A02E-4C00-89B3-3E0A6FE077B3@noaa.gov>
 <956d7fcc-e643-0bc4-b438-e13a903bbbbf@gmail.com>
Message-ID: <20231229235900.2a21ecd5@Tarkus>

? Fri, 29 Dec 2023 20:17:41 +0000
Andy <phaedrusv at gmail.com> ?????:

> doc_in <- read_docx(files)
> 
> Results in this error:Error in filetype %in% c("docx") && 
> grepl("^([fh]ttp)", file) :'length = 9' in coercion to 'logical(1)'

help(read_docx) says that the function only imports one docx file. In
order to read multiple files, use a for loop or the lapply function.

> content <- officer::docx_summary("Now they want us to charge our 
> electric cars from litter bins.docx") # A title of one of the articles
> 
> The error returned is:Error in x$doc_obj : $ operator is invalid for 
> atomic vectors

A similar problem here. help(docx_summary) says that the function
accepts "rdocx" objects returned by read_docx, not file paths. A string
in R is indeed an atomic vector of type character, length 1.

docx_summary(read_docx("Now they want us to charge our electric cars
from litter bins.docx")) should work.

-- 
Best regards,
Ivan


From po|c1410 @end|ng |rom gm@||@com  Fri Dec 29 23:25:07 2023
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Fri, 29 Dec 2023 22:25:07 +0000
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <20231229235900.2a21ecd5@Tarkus>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <2921616F-A02E-4C00-89B3-3E0A6FE077B3@noaa.gov>
 <956d7fcc-e643-0bc4-b438-e13a903bbbbf@gmail.com>
 <20231229235900.2a21ecd5@Tarkus>
Message-ID: <CA+etgPmSrnsyUNcn0uAiA2ssHj7-XVGvG-omvtckaxBOEK_D0Q@mail.gmail.com>

help(read_docx) says that the function only imports one docx file. In
> order to read multiple files, use a for loop or the lapply function.
>

I told you people will suggest better ways to loop!!


>
> docx_summary(read_docx("Now they want us to charge our electric cars
> from litter bins.docx")) should work.
>

Ivan thanks for spotting my fail! Since the OP is new to all this I'm going
to suggest a little tweak to this code which we can then build into a for
loop:

filepath <- getwd() #you will want to change this later. You are doing
something with tcl to pick a directory which seems rather fancy! But keep
doing it for now or set the directory here ending in a /

filename <- "Now they want us to charge our electric cars from litter
bins.docx"

full_filename <- paste0(filepath, filename)

#lets double check the file does exist!
if (!file.exists(full_filename)) {
  message("File missing")
} else {
  content <- read_docx(full_filename) |>
    docx_summary()
    # this reads docx for the full filename and
    # passes it ( |> command) to the next line
    # which summarises it.
    # the result is saved in a data frame object
    # called content which we shall show some
    # heading into from

   head(content)
}

Let's get this bit working before we try and loop

>

	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Sat Dec 30 01:08:59 2023
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Sat, 30 Dec 2023 02:08:59 +0200
Subject: [R] 
 Help request: Parsing docx files for key words and appending to
 a spreadsheet
In-Reply-To: <26efc752-9e23-c00c-3881-e04b94852945@gmail.com>
References: <e2368e9b-b11b-89a3-34cd-a7cf51fa8288@gmail.com>
 <CAAxdm-5VwQZ+Cpb+mXZXGTkh5eoTFpgxKwf6D+ZMXosxgTjcBQ@mail.gmail.com>
 <CA+etgPnMiZ_ZcG41Z31ERSv1NJOrRa8bvR2=CjN+H5aCYpBmwQ@mail.gmail.com>
 <umn9v5$la8$1@ciao.gmane.io> <26efc752-9e23-c00c-3881-e04b94852945@gmail.com>
Message-ID: <umnn2r$13pq$1@ciao.gmane.io>

Andy,

you can always open a public Dropbox or Google folder and post the link.

el

On 29/12/2023 22:37, Andy wrote:
> Thanks - I'll have a look at these options too.
>
> I'm happy to send over a sample document, but wasn't aware if
> attachments are allowed. The documents come Lexis+, so require user
>  credentials to log in, but I could upload the file somewhere if
> that would help? Any ideas for a good location to do so?
[...]


